{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "586134b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# Add the current directory to path to import local modules\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from model.architecture import IMDN\n",
    "from data.custom_dataset import ThermalDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3fdd5150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed=42):\n",
    "    \"\"\"Set random seed for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3bf9de6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThermalLoss(nn.Module):\n",
    "  \"\"\"\n",
    "  Custom loss function optimized for thermal images\n",
    "  Combines L1 loss with thermal-specific perceptual components\n",
    "  \"\"\"\n",
    "  def __init__(self, l1_weight=1.0, gradient_weight=0.1, thermal_weight=0.05):\n",
    "    super(ThermalLoss, self).__init__()\n",
    "    self.l1_weight = l1_weight\n",
    "    self.gradient_weight = gradient_weight\n",
    "    self.thermal_weight = thermal_weight\n",
    "    self.l1_loss = nn.L1Loss()\n",
    "    \n",
    "  def gradient_loss(self, pred, target):\n",
    "    \"\"\"Calculate gradient loss to preserve thermal edges\"\"\"\n",
    "    # Sobel operators for gradient calculation\n",
    "    sobel_x = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=torch.float32).view(1, 1, 3, 3).to(pred.device)\n",
    "    sobel_y = torch.tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=torch.float32).view(1, 1, 3, 3).to(pred.device)\n",
    "    \n",
    "    # Calculate gradients\n",
    "    pred_grad_x = F.conv2d(pred, sobel_x, padding=1)\n",
    "    pred_grad_y = F.conv2d(pred, sobel_y, padding=1)\n",
    "    target_grad_x = F.conv2d(target, sobel_x, padding=1)\n",
    "    target_grad_y = F.conv2d(target, sobel_y, padding=1)\n",
    "    \n",
    "    # L1 loss on gradients\n",
    "    grad_loss = self.l1_loss(pred_grad_x, target_grad_x) + self.l1_loss(pred_grad_y, target_grad_y)\n",
    "    return grad_loss\n",
    "  \n",
    "  def thermal_contrast_loss(self, pred, target):\n",
    "    \"\"\"Loss to preserve thermal contrast characteristics\"\"\"\n",
    "    # Calculate local variance to preserve thermal texture\n",
    "    kernel = torch.ones(1, 1, 3, 3).to(pred.device) / 9.0\n",
    "    \n",
    "    pred_mean = F.conv2d(pred, kernel, padding=1)\n",
    "    target_mean = F.conv2d(target, kernel, padding=1)\n",
    "    \n",
    "    pred_var = F.conv2d((pred - pred_mean)**2, kernel, padding=1)\n",
    "    target_var = F.conv2d((target - target_mean)**2, kernel, padding=1)\n",
    "    \n",
    "    contrast_loss = self.l1_loss(pred_var, target_var)\n",
    "    return contrast_loss\n",
    "  \n",
    "  def forward(self, pred, target):\n",
    "    # Main L1 loss\n",
    "    l1 = self.l1_loss(pred, target)\n",
    "    \n",
    "    # Gradient preservation loss\n",
    "    grad = self.gradient_loss(pred, target)\n",
    "    \n",
    "    # Thermal contrast loss\n",
    "    thermal = self.thermal_contrast_loss(pred, target)\n",
    "    \n",
    "    total_loss = (self.l1_weight * l1 + \n",
    "           self.gradient_weight * grad + \n",
    "           self.thermal_weight * thermal)\n",
    "    \n",
    "    return total_loss, {'l1': l1.item(), 'gradient': grad.item(), 'thermal': thermal.item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "55d91488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_layers(model, freeze_backbone=True):\n",
    "  \"\"\"Freeze/unfreeze model layers for gradual training\"\"\"\n",
    "  for name, param in model.named_parameters():\n",
    "    if freeze_backbone and not any(layer in name.lower() for layer in ['upsampler', 'lr_conv', 'fea_conv']):\n",
    "      param.requires_grad = False\n",
    "    else:\n",
    "      param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "297c2212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psnr(img1, img2, max_val=1.0):\n",
    "  \"\"\"Calculate PSNR between two images\"\"\"\n",
    "  mse = torch.mean((img1 - img2)**2)\n",
    "  if mse == 0:\n",
    "    return float('inf')\n",
    "  return 20 * torch.log10(max_val / torch.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e958504a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, val_loader, criterion, device, max_batches=50):\n",
    "  \"\"\"Validate the model on validation set\"\"\"\n",
    "  model.eval()\n",
    "  total_loss = 0\n",
    "  total_psnr = 0\n",
    "  num_batches = 0\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    for batch_idx, (lr, hr) in enumerate(val_loader):\n",
    "      if batch_idx >= max_batches:\n",
    "        break\n",
    "        \n",
    "      lr, hr = lr.to(device), hr.to(device)\n",
    "      \n",
    "      # Forward pass\n",
    "      with autocast():\n",
    "        sr = model(lr)\n",
    "        loss, loss_components = criterion(sr, hr)\n",
    "      \n",
    "      # Calculate PSNR\n",
    "      psnr = calculate_psnr(sr, hr)\n",
    "      \n",
    "      total_loss += loss.item()\n",
    "      total_psnr += psnr.item()\n",
    "      num_batches += 1\n",
    "  \n",
    "  avg_loss = total_loss / num_batches\n",
    "  avg_psnr = total_psnr / num_batches\n",
    "  \n",
    "  return avg_loss, avg_psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "620b2c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, epoch, loss, psnr, checkpoint_dir, is_best=False):\n",
    "  \"\"\"Save model checkpoint\"\"\"\n",
    "  checkpoint = {\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': loss,\n",
    "    'psnr': psnr,\n",
    "  }\n",
    "  \n",
    "  # Save regular checkpoint\n",
    "  checkpoint_path = os.path.join(checkpoint_dir, f'thermal_epoch_{epoch}.pth')\n",
    "  torch.save(checkpoint, checkpoint_path)\n",
    "  \n",
    "  # Save best model\n",
    "  if is_best:\n",
    "    best_path = os.path.join(checkpoint_dir, 'thermal_best.pth')\n",
    "    torch.save(checkpoint, best_path)\n",
    "    print(f\"üí´ New best model saved! PSNR: {psnr:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7f70239e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_info(model, sample_input):\n",
    "  \"\"\"Print model information\"\"\"\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    output = model(sample_input)\n",
    "  \n",
    "  total_params = sum(p.numel() for p in model.parameters())\n",
    "  trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "  \n",
    "  print(f\"üìä Model Information:\")\n",
    "  print(f\"   ‚Ä¢ Total parameters: {total_params:,}\")\n",
    "  print(f\"   ‚Ä¢ Trainable parameters: {trainable_params:,}\")\n",
    "  print(f\"   ‚Ä¢ Input shape: {sample_input.shape}\")\n",
    "  print(f\"   ‚Ä¢ Output shape: {output.shape}\")\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "03b9075a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Configuration for 2x upscaling:\n",
      "   üìÅ Dataset: /home/kronbii/repos/thermal-super-resolution/datasets/flir_thermal_x2\n",
      "   üèãÔ∏è Pretrained: /home/kronbii/repos/thermal-super-resolution/checkpoints/pretrained/IMDN_x2.pth\n",
      "   üíæ Checkpoints: checkpoints/thermal_x2\n",
      "   üß† Memory optimized: Batch=4, Patch=128, Accumulation=2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configuration - set these parameters directly\n",
    "SCALE = 2  # Change this to any scale factor (2, 3, 4, or even custom values)\n",
    "DATASET_DIR = '/home/kronbii/repos/thermal-super-resolution/datasets/flir_thermal_x2'  # Auto-update based on scale\n",
    "PRETRAINED_MODEL_DIR = f'/home/kronbii/repos/thermal-super-resolution/checkpoints/pretrained/IMDN_x{SCALE}.pth'  # Fixed: Added f-string\n",
    "\n",
    "# Training parameters\n",
    "EPOCHS = 80\n",
    "BATCH_SIZE = 4  # Reduced for memory optimization\n",
    "LR = 1e-5\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "# Training strategy\n",
    "GRADUAL_UNFREEZE = True\n",
    "FREEZE_EPOCHS = 20\n",
    "\n",
    "# Loss function weights\n",
    "L1_WEIGHT = 1.0\n",
    "GRADIENT_WEIGHT = 0.1\n",
    "THERMAL_WEIGHT = 0.05\n",
    "\n",
    "# System settings\n",
    "NUM_WORKERS = 2  # Reduced for memory optimization  \n",
    "DEVICE = 'auto'\n",
    "MIXED_PRECISION = True\n",
    "\n",
    "# Memory optimization settings\n",
    "PATCH_SIZE = 128  # Reduced from 192 for memory\n",
    "GRADIENT_ACCUMULATION_STEPS = 2  # To maintain effective batch size\n",
    "\n",
    "# Output settings\n",
    "CHECKPOINT_DIR = f'checkpoints/thermal_x{SCALE}'  # Auto-update based on scale\n",
    "LOG_INTERVAL = 50\n",
    "VAL_INTERVAL = 5\n",
    "\n",
    "# Other settings\n",
    "SEED = 42\n",
    "\n",
    "print(f\"üéØ Configuration for {SCALE}x upscaling:\")\n",
    "print(f\"   üìÅ Dataset: {DATASET_DIR}\")\n",
    "print(f\"   üèãÔ∏è Pretrained: {PRETRAINED_MODEL_DIR}\")\n",
    "print(f\"   üíæ Checkpoints: {CHECKPOINT_DIR}\")\n",
    "print(f\"   üß† Memory optimized: Batch={BATCH_SIZE}, Patch={PATCH_SIZE}, Accumulation={GRADIENT_ACCUMULATION_STEPS}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bc24b9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Debugging dataset paths...\n",
      "DATASET_DIR: /home/kronbii/repos/thermal-super-resolution/datasets/flir_thermal_x2\n",
      "\n",
      "üìÅ Expected directory structure:\n",
      "   ‚úÖ /home/kronbii/repos/thermal-super-resolution/datasets/flir_thermal_x2/train/HR - 10697 files\n",
      "   ‚úÖ /home/kronbii/repos/thermal-super-resolution/datasets/flir_thermal_x2/train/LR_bicubic/X2 - 10697 files\n",
      "   ‚úÖ /home/kronbii/repos/thermal-super-resolution/datasets/flir_thermal_x2/val/HR - 1189 files\n",
      "   ‚úÖ /home/kronbii/repos/thermal-super-resolution/datasets/flir_thermal_x2/val/LR_bicubic/X2 - 1189 files\n",
      "\n",
      "üìÇ Actual directory structure:\n",
      "flir_thermal_x2/\n",
      "   val/\n",
      "      HR/\n",
      "         (1189 image files)\n",
      "      LR_bicubic/\n",
      "         X2/\n",
      "            (1189 image files)\n"
     ]
    }
   ],
   "source": [
    "# Debug dataset structure before running training\n",
    "print(\"üîç Debugging dataset paths...\")\n",
    "print(f\"DATASET_DIR: {DATASET_DIR}\")\n",
    "print()\n",
    "\n",
    "# Check expected paths\n",
    "expected_paths = [\n",
    "    os.path.join(DATASET_DIR, 'train', 'HR'),\n",
    "    os.path.join(DATASET_DIR, 'train', f'LR_bicubic', f'X{SCALE}'),\n",
    "    os.path.join(DATASET_DIR, 'val', 'HR'),\n",
    "    os.path.join(DATASET_DIR, 'val', f'LR_bicubic', f'X{SCALE}')\n",
    "]\n",
    "\n",
    "print(\"üìÅ Expected directory structure:\")\n",
    "for path in expected_paths:\n",
    "    exists = os.path.exists(path)\n",
    "    if exists:\n",
    "        file_count = len([f for f in os.listdir(path) if f.endswith('.png')])\n",
    "        print(f\"   ‚úÖ {path} - {file_count} files\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå {path} - NOT FOUND\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Show actual directory structure\n",
    "if os.path.exists(DATASET_DIR):\n",
    "    print(\"üìÇ Actual directory structure:\")\n",
    "    for root, dirs, files in os.walk(DATASET_DIR):\n",
    "        level = root.replace(DATASET_DIR, '').count(os.sep)\n",
    "        indent = '   ' * level\n",
    "        print(f\"{indent}{os.path.basename(root)}/\")\n",
    "        \n",
    "        # Show image files count\n",
    "        image_files = [f for f in files if f.endswith(('.png', '.jpg'))]\n",
    "        if image_files:\n",
    "            subindent = '   ' * (level + 1)\n",
    "            print(f\"{subindent}({len(image_files)} image files)\")\n",
    "        \n",
    "        if level >= 3:  # Don't go too deep\n",
    "            break\n",
    "else:\n",
    "    print(f\"‚ùå Dataset directory doesn't exist: {DATASET_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ab4595e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Debugging ThermalDataset loading...\n",
      "Train HR dir: /home/kronbii/repos/thermal-super-resolution/datasets/flir_thermal_x2/train/HR\n",
      "Train LR dir: /home/kronbii/repos/thermal-super-resolution/datasets/flir_thermal_x2/train/LR_bicubic/X2\n",
      "Directories exist: HR=True, LR=True\n",
      "üß™ Testing dataset creation...\n",
      "   ‚úÖ TestTrainOpt created successfully\n",
      "   ‚Ä¢ hr_dir: /home/kronbii/repos/thermal-super-resolution/datasets/flir_thermal_x2/train/HR\n",
      "   ‚Ä¢ lr_dir: /home/kronbii/repos/thermal-super-resolution/datasets/flir_thermal_x2/train/LR_bicubic/X2\n",
      "   ‚Ä¢ scale: 2\n",
      "   ‚Ä¢ phase: train\n",
      "Loaded 10697 thermal images for training\n",
      "   ‚úÖ ThermalDataset created successfully\n",
      "   ‚Ä¢ Dataset length: 0\n",
      "   ‚Ä¢ images_hr length: 10697\n",
      "   ‚Ä¢ Sample HR files: ['/home/kronbii/repos/thermal-super-resolution/datasets/flir_thermal_x2/train/HR/video-24ysbPEGoEKKDvRt6-frame-000000-4C4FHWxwNaMyohLZt.png', '/home/kronbii/repos/thermal-super-resolution/datasets/flir_thermal_x2/train/HR/video-24ysbPEGoEKKDvRt6-frame-000015-ceXK8kdaSPB6ojqyZ.png', '/home/kronbii/repos/thermal-super-resolution/datasets/flir_thermal_x2/train/HR/video-24ysbPEGoEKKDvRt6-frame-000030-JqzDhfF6nR2wLt5dh.png']\n",
      "   ‚Ä¢ images_lr length: 10697\n",
      "   ‚Ä¢ Sample LR files: ['/home/kronbii/repos/thermal-super-resolution/datasets/flir_thermal_x2/train/LR_bicubic/X2/video-24ysbPEGoEKKDvRt6-frame-000000-4C4FHWxwNaMyohLZt.png', '/home/kronbii/repos/thermal-super-resolution/datasets/flir_thermal_x2/train/LR_bicubic/X2/video-24ysbPEGoEKKDvRt6-frame-000015-ceXK8kdaSPB6ojqyZ.png', '/home/kronbii/repos/thermal-super-resolution/datasets/flir_thermal_x2/train/LR_bicubic/X2/video-24ysbPEGoEKKDvRt6-frame-000030-JqzDhfF6nR2wLt5dh.png']\n"
     ]
    }
   ],
   "source": [
    "# Debug ThermalDataset loading issue\n",
    "print(\"üîß Debugging ThermalDataset loading...\")\n",
    "\n",
    "# Test dataset initialization step by step\n",
    "train_hr_dir = os.path.join(DATASET_DIR, 'train', 'HR')\n",
    "train_lr_dir = os.path.join(DATASET_DIR, 'train', f'LR_bicubic', f'X{SCALE}')\n",
    "\n",
    "print(f\"Train HR dir: {train_hr_dir}\")\n",
    "print(f\"Train LR dir: {train_lr_dir}\")\n",
    "print(f\"Directories exist: HR={os.path.exists(train_hr_dir)}, LR={os.path.exists(train_lr_dir)}\")\n",
    "\n",
    "# Test TrainOpt class\n",
    "class TestTrainOpt:\n",
    "    def __init__(self):\n",
    "        self.scale = SCALE\n",
    "        self.phase = 'train'\n",
    "        self.hr_dir = train_hr_dir\n",
    "        self.lr_dir = train_lr_dir\n",
    "        self.ext = '.png'\n",
    "        self.augment = True\n",
    "        self.thermal_augment = True\n",
    "        self.patch_size = PATCH_SIZE\n",
    "        self.n_colors = 1  \n",
    "        self.rgb_range = 1\n",
    "        self.batch_size = BATCH_SIZE\n",
    "        self.test_every = 1000\n",
    "\n",
    "print(\"üß™ Testing dataset creation...\")\n",
    "try:\n",
    "    test_opt = TestTrainOpt()\n",
    "    print(f\"   ‚úÖ TestTrainOpt created successfully\")\n",
    "    print(f\"   ‚Ä¢ hr_dir: {test_opt.hr_dir}\")\n",
    "    print(f\"   ‚Ä¢ lr_dir: {test_opt.lr_dir}\")\n",
    "    print(f\"   ‚Ä¢ scale: {test_opt.scale}\")\n",
    "    print(f\"   ‚Ä¢ phase: {test_opt.phase}\")\n",
    "    \n",
    "    # Try creating dataset\n",
    "    test_dataset = ThermalDataset(test_opt)\n",
    "    print(f\"   ‚úÖ ThermalDataset created successfully\")\n",
    "    print(f\"   ‚Ä¢ Dataset length: {len(test_dataset)}\")\n",
    "    \n",
    "    # Check if dataset has images_hr attribute\n",
    "    if hasattr(test_dataset, 'images_hr'):\n",
    "        print(f\"   ‚Ä¢ images_hr length: {len(test_dataset.images_hr)}\")\n",
    "        if test_dataset.images_hr:\n",
    "            print(f\"   ‚Ä¢ Sample HR files: {test_dataset.images_hr[:3]}\")\n",
    "    \n",
    "    if hasattr(test_dataset, 'images_lr'):\n",
    "        print(f\"   ‚Ä¢ images_lr length: {len(test_dataset.images_lr) if test_dataset.images_lr else 'None'}\")\n",
    "        if test_dataset.images_lr:\n",
    "            print(f\"   ‚Ä¢ Sample LR files: {test_dataset.images_lr[:3]}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Error creating ThermalDataset: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e1127e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî• IMDN Thermal Fine-tuning - FLIR ADAS v2 Optimized\n",
      "============================================================\n",
      "üñ•Ô∏è  Device: cuda\n",
      "üìä Scale factor: 2x\n",
      "üìÅ Dataset: /home/kronbii/repos/thermal-super-resolution/datasets/flir_thermal_x2\n",
      "üèãÔ∏è Pretrained model: /home/kronbii/repos/thermal-super-resolution/checkpoints/pretrained/IMDN_x2.pth\n",
      "\n",
      "üìÇ Loading FLIR thermal dataset...\n",
      "Loaded 10697 thermal images for training\n",
      "Loaded 1189 thermal images for testing\n",
      "   ‚Ä¢ Training samples: 42788\n",
      "   ‚Ä¢ Validation samples: 1189\n",
      "üèóÔ∏è Setting up IMDN model...\n",
      "üì• Loading pretrained weights from /home/kronbii/repos/thermal-super-resolution/checkpoints/pretrained/IMDN_x2.pth\n",
      "   ‚Ä¢ Adapted fea_conv.weight: torch.Size([64, 3, 3, 3]) -> torch.Size([64, 1, 3, 3])\n",
      "   ‚Ä¢ Adapted upsampler.0.weight: torch.Size([12, 64, 3, 3]) -> torch.Size([4, 64, 3, 3])\n",
      "   ‚Ä¢ Adapted upsampler.0.bias: torch.Size([12]) -> torch.Size([4])\n",
      "   ‚úÖ Successfully adapted pretrained model from RGB to thermal with 2x scaling\n",
      "üìä Model Information:\n",
      "   ‚Ä¢ Total parameters: 688,636\n",
      "   ‚Ä¢ Trainable parameters: 688,636\n",
      "   ‚Ä¢ Input shape: torch.Size([1, 1, 64, 64])\n",
      "   ‚Ä¢ Output shape: torch.Size([1, 1, 128, 128])\n",
      "\n",
      "üîê Starting with frozen backbone (gradual unfreezing enabled)\n",
      "üß† Memory optimization enabled:\n",
      "   ‚Ä¢ Batch size: 4\n",
      "   ‚Ä¢ Patch size: 128\n",
      "   ‚Ä¢ Gradient accumulation: 2\n",
      "   ‚Ä¢ Mixed precision: True\n",
      "üöÄ Starting training...\n",
      "\n",
      "üì• Loading pretrained weights from /home/kronbii/repos/thermal-super-resolution/checkpoints/pretrained/IMDN_x2.pth\n",
      "   ‚Ä¢ Adapted fea_conv.weight: torch.Size([64, 3, 3, 3]) -> torch.Size([64, 1, 3, 3])\n",
      "   ‚Ä¢ Adapted upsampler.0.weight: torch.Size([12, 64, 3, 3]) -> torch.Size([4, 64, 3, 3])\n",
      "   ‚Ä¢ Adapted upsampler.0.bias: torch.Size([12]) -> torch.Size([4])\n",
      "   ‚úÖ Successfully adapted pretrained model from RGB to thermal with 2x scaling\n",
      "üìä Model Information:\n",
      "   ‚Ä¢ Total parameters: 688,636\n",
      "   ‚Ä¢ Trainable parameters: 688,636\n",
      "   ‚Ä¢ Input shape: torch.Size([1, 1, 64, 64])\n",
      "   ‚Ä¢ Output shape: torch.Size([1, 1, 128, 128])\n",
      "\n",
      "üîê Starting with frozen backbone (gradual unfreezing enabled)\n",
      "üß† Memory optimization enabled:\n",
      "   ‚Ä¢ Batch size: 4\n",
      "   ‚Ä¢ Patch size: 128\n",
      "   ‚Ä¢ Gradient accumulation: 2\n",
      "   ‚Ä¢ Mixed precision: True\n",
      "üöÄ Starting training...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87215/2976006835.py:241: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler() if MIXED_PRECISION and device.type == 'cuda' else None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 [   0/10697 (  0.0%)] Loss: 0.348732 L1: 0.332129 Grad: 0.165539 Thermal: 0.000976 LR: 1.00e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87215/2976006835.py:285: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 [  50/10697 (  0.5%)] Loss: 0.420157 L1: 0.400713 Grad: 0.193820 Thermal: 0.001246 LR: 1.00e-05\n",
      "Epoch   0 [ 100/10697 (  0.9%)] Loss: 0.342165 L1: 0.321835 Grad: 0.202793 Thermal: 0.001014 LR: 1.00e-05\n",
      "Epoch   0 [ 100/10697 (  0.9%)] Loss: 0.342165 L1: 0.321835 Grad: 0.202793 Thermal: 0.001014 LR: 1.00e-05\n",
      "Epoch   0 [ 150/10697 (  1.4%)] Loss: 0.355883 L1: 0.336165 Grad: 0.196638 Thermal: 0.001088 LR: 1.00e-05\n",
      "Epoch   0 [ 150/10697 (  1.4%)] Loss: 0.355883 L1: 0.336165 Grad: 0.196638 Thermal: 0.001088 LR: 1.00e-05\n",
      "Epoch   0 [ 200/10697 (  1.9%)] Loss: 0.252374 L1: 0.236624 Grad: 0.157144 Thermal: 0.000716 LR: 1.00e-05\n",
      "Epoch   0 [ 200/10697 (  1.9%)] Loss: 0.252374 L1: 0.236624 Grad: 0.157144 Thermal: 0.000716 LR: 1.00e-05\n",
      "Epoch   0 [ 250/10697 (  2.3%)] Loss: 0.352354 L1: 0.332043 Grad: 0.202533 Thermal: 0.001149 LR: 1.00e-05\n",
      "Epoch   0 [ 250/10697 (  2.3%)] Loss: 0.352354 L1: 0.332043 Grad: 0.202533 Thermal: 0.001149 LR: 1.00e-05\n",
      "Epoch   0 [ 300/10697 (  2.8%)] Loss: 0.270103 L1: 0.250260 Grad: 0.197977 Thermal: 0.000903 LR: 1.00e-05\n",
      "Epoch   0 [ 300/10697 (  2.8%)] Loss: 0.270103 L1: 0.250260 Grad: 0.197977 Thermal: 0.000903 LR: 1.00e-05\n",
      "Epoch   0 [ 350/10697 (  3.3%)] Loss: 0.328990 L1: 0.304243 Grad: 0.246821 Thermal: 0.001301 LR: 1.00e-05\n",
      "Epoch   0 [ 350/10697 (  3.3%)] Loss: 0.328990 L1: 0.304243 Grad: 0.246821 Thermal: 0.001301 LR: 1.00e-05\n",
      "Epoch   0 [ 400/10697 (  3.7%)] Loss: 0.316934 L1: 0.302876 Grad: 0.140123 Thermal: 0.000906 LR: 1.00e-05\n",
      "Epoch   0 [ 400/10697 (  3.7%)] Loss: 0.316934 L1: 0.302876 Grad: 0.140123 Thermal: 0.000906 LR: 1.00e-05\n",
      "Epoch   0 [ 450/10697 (  4.2%)] Loss: 0.222650 L1: 0.201284 Grad: 0.213188 Thermal: 0.000945 LR: 1.00e-05\n",
      "Epoch   0 [ 450/10697 (  4.2%)] Loss: 0.222650 L1: 0.201284 Grad: 0.213188 Thermal: 0.000945 LR: 1.00e-05\n",
      "Epoch   0 [ 500/10697 (  4.7%)] Loss: 0.265523 L1: 0.249086 Grad: 0.163903 Thermal: 0.000931 LR: 1.00e-05\n",
      "Epoch   0 [ 500/10697 (  4.7%)] Loss: 0.265523 L1: 0.249086 Grad: 0.163903 Thermal: 0.000931 LR: 1.00e-05\n",
      "Epoch   0 [ 550/10697 (  5.1%)] Loss: 0.182239 L1: 0.161643 Grad: 0.205509 Thermal: 0.000901 LR: 1.00e-05\n",
      "Epoch   0 [ 550/10697 (  5.1%)] Loss: 0.182239 L1: 0.161643 Grad: 0.205509 Thermal: 0.000901 LR: 1.00e-05\n",
      "Epoch   0 [ 600/10697 (  5.6%)] Loss: 0.210449 L1: 0.189024 Grad: 0.213611 Thermal: 0.001283 LR: 1.00e-05\n",
      "Epoch   0 [ 600/10697 (  5.6%)] Loss: 0.210449 L1: 0.189024 Grad: 0.213611 Thermal: 0.001283 LR: 1.00e-05\n",
      "Epoch   0 [ 650/10697 (  6.1%)] Loss: 0.078235 L1: 0.062090 Grad: 0.161179 Thermal: 0.000558 LR: 1.00e-05\n",
      "Epoch   0 [ 650/10697 (  6.1%)] Loss: 0.078235 L1: 0.062090 Grad: 0.161179 Thermal: 0.000558 LR: 1.00e-05\n",
      "Epoch   0 [ 700/10697 (  6.5%)] Loss: 0.088022 L1: 0.060719 Grad: 0.272471 Thermal: 0.001124 LR: 1.00e-05\n",
      "Epoch   0 [ 700/10697 (  6.5%)] Loss: 0.088022 L1: 0.060719 Grad: 0.272471 Thermal: 0.001124 LR: 1.00e-05\n",
      "Epoch   0 [ 750/10697 (  7.0%)] Loss: 0.076492 L1: 0.055090 Grad: 0.213664 Thermal: 0.000712 LR: 1.00e-05\n",
      "Epoch   0 [ 750/10697 (  7.0%)] Loss: 0.076492 L1: 0.055090 Grad: 0.213664 Thermal: 0.000712 LR: 1.00e-05\n",
      "Epoch   0 [ 800/10697 (  7.5%)] Loss: 0.065938 L1: 0.048350 Grad: 0.175532 Thermal: 0.000681 LR: 1.00e-05\n",
      "Epoch   0 [ 800/10697 (  7.5%)] Loss: 0.065938 L1: 0.048350 Grad: 0.175532 Thermal: 0.000681 LR: 1.00e-05\n",
      "Epoch   0 [ 850/10697 (  7.9%)] Loss: 0.071678 L1: 0.054205 Grad: 0.174203 Thermal: 0.001039 LR: 1.00e-05\n",
      "Epoch   0 [ 850/10697 (  7.9%)] Loss: 0.071678 L1: 0.054205 Grad: 0.174203 Thermal: 0.001039 LR: 1.00e-05\n",
      "Epoch   0 [ 900/10697 (  8.4%)] Loss: 0.068181 L1: 0.052666 Grad: 0.154776 Thermal: 0.000755 LR: 1.00e-05\n",
      "Epoch   0 [ 900/10697 (  8.4%)] Loss: 0.068181 L1: 0.052666 Grad: 0.154776 Thermal: 0.000755 LR: 1.00e-05\n",
      "Epoch   0 [ 950/10697 (  8.9%)] Loss: 0.079180 L1: 0.058311 Grad: 0.208256 Thermal: 0.000866 LR: 1.00e-05\n",
      "Epoch   0 [ 950/10697 (  8.9%)] Loss: 0.079180 L1: 0.058311 Grad: 0.208256 Thermal: 0.000866 LR: 1.00e-05\n",
      "Epoch   0 [1000/10697 (  9.3%)] Loss: 0.069352 L1: 0.050800 Grad: 0.185166 Thermal: 0.000697 LR: 1.00e-05\n",
      "Epoch   0 [1000/10697 (  9.3%)] Loss: 0.069352 L1: 0.050800 Grad: 0.185166 Thermal: 0.000697 LR: 1.00e-05\n",
      "Epoch   0 [1050/10697 (  9.8%)] Loss: 0.060258 L1: 0.040128 Grad: 0.200886 Thermal: 0.000825 LR: 1.00e-05\n",
      "Epoch   0 [1050/10697 (  9.8%)] Loss: 0.060258 L1: 0.040128 Grad: 0.200886 Thermal: 0.000825 LR: 1.00e-05\n",
      "Epoch   0 [1100/10697 ( 10.3%)] Loss: 0.080051 L1: 0.055082 Grad: 0.249082 Thermal: 0.001220 LR: 1.00e-05\n",
      "Epoch   0 [1100/10697 ( 10.3%)] Loss: 0.080051 L1: 0.055082 Grad: 0.249082 Thermal: 0.001220 LR: 1.00e-05\n",
      "Epoch   0 [1150/10697 ( 10.8%)] Loss: 0.053788 L1: 0.038509 Grad: 0.152436 Thermal: 0.000710 LR: 1.00e-05\n",
      "Epoch   0 [1150/10697 ( 10.8%)] Loss: 0.053788 L1: 0.038509 Grad: 0.152436 Thermal: 0.000710 LR: 1.00e-05\n",
      "Epoch   0 [1200/10697 ( 11.2%)] Loss: 0.055676 L1: 0.040137 Grad: 0.155061 Thermal: 0.000649 LR: 1.00e-05\n",
      "Epoch   0 [1200/10697 ( 11.2%)] Loss: 0.055676 L1: 0.040137 Grad: 0.155061 Thermal: 0.000649 LR: 1.00e-05\n",
      "Epoch   0 [1250/10697 ( 11.7%)] Loss: 0.063917 L1: 0.045252 Grad: 0.186229 Thermal: 0.000842 LR: 1.00e-05\n",
      "Epoch   0 [1250/10697 ( 11.7%)] Loss: 0.063917 L1: 0.045252 Grad: 0.186229 Thermal: 0.000842 LR: 1.00e-05\n",
      "Epoch   0 [1300/10697 ( 12.2%)] Loss: 0.052612 L1: 0.035715 Grad: 0.168529 Thermal: 0.000887 LR: 1.00e-05\n",
      "Epoch   0 [1300/10697 ( 12.2%)] Loss: 0.052612 L1: 0.035715 Grad: 0.168529 Thermal: 0.000887 LR: 1.00e-05\n",
      "Epoch   0 [1350/10697 ( 12.6%)] Loss: 0.065003 L1: 0.045159 Grad: 0.198019 Thermal: 0.000830 LR: 1.00e-05\n",
      "Epoch   0 [1350/10697 ( 12.6%)] Loss: 0.065003 L1: 0.045159 Grad: 0.198019 Thermal: 0.000830 LR: 1.00e-05\n",
      "Epoch   0 [1400/10697 ( 13.1%)] Loss: 0.070807 L1: 0.052217 Grad: 0.185590 Thermal: 0.000629 LR: 1.00e-05\n",
      "Epoch   0 [1400/10697 ( 13.1%)] Loss: 0.070807 L1: 0.052217 Grad: 0.185590 Thermal: 0.000629 LR: 1.00e-05\n",
      "Epoch   0 [1450/10697 ( 13.6%)] Loss: 0.047691 L1: 0.031187 Grad: 0.164660 Thermal: 0.000770 LR: 1.00e-05\n",
      "Epoch   0 [1450/10697 ( 13.6%)] Loss: 0.047691 L1: 0.031187 Grad: 0.164660 Thermal: 0.000770 LR: 1.00e-05\n",
      "Epoch   0 [1500/10697 ( 14.0%)] Loss: 0.041299 L1: 0.027605 Grad: 0.136589 Thermal: 0.000700 LR: 1.00e-05\n",
      "Epoch   0 [1500/10697 ( 14.0%)] Loss: 0.041299 L1: 0.027605 Grad: 0.136589 Thermal: 0.000700 LR: 1.00e-05\n",
      "Epoch   0 [1550/10697 ( 14.5%)] Loss: 0.050386 L1: 0.033946 Grad: 0.163983 Thermal: 0.000826 LR: 1.00e-05\n",
      "Epoch   0 [1550/10697 ( 14.5%)] Loss: 0.050386 L1: 0.033946 Grad: 0.163983 Thermal: 0.000826 LR: 1.00e-05\n",
      "Epoch   0 [1600/10697 ( 15.0%)] Loss: 0.045861 L1: 0.030300 Grad: 0.155226 Thermal: 0.000769 LR: 1.00e-05\n",
      "Epoch   0 [1600/10697 ( 15.0%)] Loss: 0.045861 L1: 0.030300 Grad: 0.155226 Thermal: 0.000769 LR: 1.00e-05\n",
      "Epoch   0 [1650/10697 ( 15.4%)] Loss: 0.061853 L1: 0.044611 Grad: 0.172069 Thermal: 0.000701 LR: 1.00e-05\n",
      "Epoch   0 [1650/10697 ( 15.4%)] Loss: 0.061853 L1: 0.044611 Grad: 0.172069 Thermal: 0.000701 LR: 1.00e-05\n",
      "Epoch   0 [1700/10697 ( 15.9%)] Loss: 0.038697 L1: 0.024719 Grad: 0.139390 Thermal: 0.000783 LR: 1.00e-05\n",
      "Epoch   0 [1700/10697 ( 15.9%)] Loss: 0.038697 L1: 0.024719 Grad: 0.139390 Thermal: 0.000783 LR: 1.00e-05\n",
      "Epoch   0 [1750/10697 ( 16.4%)] Loss: 0.040735 L1: 0.025612 Grad: 0.150809 Thermal: 0.000827 LR: 1.00e-05\n",
      "Epoch   0 [1750/10697 ( 16.4%)] Loss: 0.040735 L1: 0.025612 Grad: 0.150809 Thermal: 0.000827 LR: 1.00e-05\n",
      "Epoch   0 [1800/10697 ( 16.8%)] Loss: 0.038044 L1: 0.023895 Grad: 0.141089 Thermal: 0.000812 LR: 1.00e-05\n",
      "Epoch   0 [1800/10697 ( 16.8%)] Loss: 0.038044 L1: 0.023895 Grad: 0.141089 Thermal: 0.000812 LR: 1.00e-05\n",
      "Epoch   0 [1850/10697 ( 17.3%)] Loss: 0.040645 L1: 0.025961 Grad: 0.146541 Thermal: 0.000603 LR: 1.00e-05\n",
      "Epoch   0 [1850/10697 ( 17.3%)] Loss: 0.040645 L1: 0.025961 Grad: 0.146541 Thermal: 0.000603 LR: 1.00e-05\n",
      "Epoch   0 [1900/10697 ( 17.8%)] Loss: 0.050961 L1: 0.035878 Grad: 0.150499 Thermal: 0.000666 LR: 1.00e-05\n",
      "Epoch   0 [1900/10697 ( 17.8%)] Loss: 0.050961 L1: 0.035878 Grad: 0.150499 Thermal: 0.000666 LR: 1.00e-05\n",
      "Epoch   0 [1950/10697 ( 18.2%)] Loss: 0.044382 L1: 0.028615 Grad: 0.157343 Thermal: 0.000657 LR: 1.00e-05\n",
      "Epoch   0 [1950/10697 ( 18.2%)] Loss: 0.044382 L1: 0.028615 Grad: 0.157343 Thermal: 0.000657 LR: 1.00e-05\n",
      "Epoch   0 [2000/10697 ( 18.7%)] Loss: 0.045783 L1: 0.028774 Grad: 0.169757 Thermal: 0.000654 LR: 1.00e-05\n",
      "Epoch   0 [2000/10697 ( 18.7%)] Loss: 0.045783 L1: 0.028774 Grad: 0.169757 Thermal: 0.000654 LR: 1.00e-05\n",
      "Epoch   0 [2050/10697 ( 19.2%)] Loss: 0.042048 L1: 0.027144 Grad: 0.148686 Thermal: 0.000709 LR: 1.00e-05\n",
      "Epoch   0 [2050/10697 ( 19.2%)] Loss: 0.042048 L1: 0.027144 Grad: 0.148686 Thermal: 0.000709 LR: 1.00e-05\n",
      "Epoch   0 [2100/10697 ( 19.6%)] Loss: 0.047500 L1: 0.030564 Grad: 0.169034 Thermal: 0.000651 LR: 1.00e-05\n",
      "Epoch   0 [2100/10697 ( 19.6%)] Loss: 0.047500 L1: 0.030564 Grad: 0.169034 Thermal: 0.000651 LR: 1.00e-05\n",
      "Epoch   0 [2150/10697 ( 20.1%)] Loss: 0.048528 L1: 0.031297 Grad: 0.171977 Thermal: 0.000662 LR: 1.00e-05\n",
      "Epoch   0 [2150/10697 ( 20.1%)] Loss: 0.048528 L1: 0.031297 Grad: 0.171977 Thermal: 0.000662 LR: 1.00e-05\n",
      "Epoch   0 [2200/10697 ( 20.6%)] Loss: 0.047066 L1: 0.030522 Grad: 0.165039 Thermal: 0.000804 LR: 1.00e-05\n",
      "Epoch   0 [2200/10697 ( 20.6%)] Loss: 0.047066 L1: 0.030522 Grad: 0.165039 Thermal: 0.000804 LR: 1.00e-05\n",
      "Epoch   0 [2250/10697 ( 21.0%)] Loss: 0.050483 L1: 0.032558 Grad: 0.178876 Thermal: 0.000740 LR: 1.00e-05\n",
      "Epoch   0 [2250/10697 ( 21.0%)] Loss: 0.050483 L1: 0.032558 Grad: 0.178876 Thermal: 0.000740 LR: 1.00e-05\n",
      "Epoch   0 [2300/10697 ( 21.5%)] Loss: 0.054870 L1: 0.037420 Grad: 0.174137 Thermal: 0.000727 LR: 1.00e-05\n",
      "Epoch   0 [2300/10697 ( 21.5%)] Loss: 0.054870 L1: 0.037420 Grad: 0.174137 Thermal: 0.000727 LR: 1.00e-05\n",
      "Epoch   0 [2350/10697 ( 22.0%)] Loss: 0.037626 L1: 0.023627 Grad: 0.139655 Thermal: 0.000678 LR: 1.00e-05\n",
      "Epoch   0 [2350/10697 ( 22.0%)] Loss: 0.037626 L1: 0.023627 Grad: 0.139655 Thermal: 0.000678 LR: 1.00e-05\n",
      "Epoch   0 [2400/10697 ( 22.4%)] Loss: 0.048539 L1: 0.030913 Grad: 0.175914 Thermal: 0.000689 LR: 1.00e-05\n",
      "Epoch   0 [2400/10697 ( 22.4%)] Loss: 0.048539 L1: 0.030913 Grad: 0.175914 Thermal: 0.000689 LR: 1.00e-05\n",
      "Epoch   0 [2450/10697 ( 22.9%)] Loss: 0.036238 L1: 0.022228 Grad: 0.139788 Thermal: 0.000625 LR: 1.00e-05\n",
      "Epoch   0 [2450/10697 ( 22.9%)] Loss: 0.036238 L1: 0.022228 Grad: 0.139788 Thermal: 0.000625 LR: 1.00e-05\n",
      "Epoch   0 [2500/10697 ( 23.4%)] Loss: 0.045755 L1: 0.029003 Grad: 0.167220 Thermal: 0.000596 LR: 1.00e-05\n",
      "Epoch   0 [2500/10697 ( 23.4%)] Loss: 0.045755 L1: 0.029003 Grad: 0.167220 Thermal: 0.000596 LR: 1.00e-05\n",
      "Epoch   0 [2550/10697 ( 23.8%)] Loss: 0.036864 L1: 0.023214 Grad: 0.136200 Thermal: 0.000593 LR: 1.00e-05\n",
      "Epoch   0 [2550/10697 ( 23.8%)] Loss: 0.036864 L1: 0.023214 Grad: 0.136200 Thermal: 0.000593 LR: 1.00e-05\n",
      "Epoch   0 [2600/10697 ( 24.3%)] Loss: 0.033797 L1: 0.021931 Grad: 0.118452 Thermal: 0.000411 LR: 1.00e-05\n",
      "Epoch   0 [2600/10697 ( 24.3%)] Loss: 0.033797 L1: 0.021931 Grad: 0.118452 Thermal: 0.000411 LR: 1.00e-05\n",
      "Epoch   0 [2650/10697 ( 24.8%)] Loss: 0.035535 L1: 0.022548 Grad: 0.129575 Thermal: 0.000584 LR: 1.00e-05\n",
      "Epoch   0 [2650/10697 ( 24.8%)] Loss: 0.035535 L1: 0.022548 Grad: 0.129575 Thermal: 0.000584 LR: 1.00e-05\n",
      "Epoch   0 [2700/10697 ( 25.2%)] Loss: 0.042589 L1: 0.026164 Grad: 0.163860 Thermal: 0.000781 LR: 1.00e-05\n",
      "Epoch   0 [2700/10697 ( 25.2%)] Loss: 0.042589 L1: 0.026164 Grad: 0.163860 Thermal: 0.000781 LR: 1.00e-05\n",
      "Epoch   0 [2750/10697 ( 25.7%)] Loss: 0.035172 L1: 0.021423 Grad: 0.137182 Thermal: 0.000598 LR: 1.00e-05\n",
      "Epoch   0 [2750/10697 ( 25.7%)] Loss: 0.035172 L1: 0.021423 Grad: 0.137182 Thermal: 0.000598 LR: 1.00e-05\n",
      "Epoch   0 [2800/10697 ( 26.2%)] Loss: 0.051750 L1: 0.031752 Grad: 0.199539 Thermal: 0.000882 LR: 1.00e-05\n",
      "Epoch   0 [2800/10697 ( 26.2%)] Loss: 0.051750 L1: 0.031752 Grad: 0.199539 Thermal: 0.000882 LR: 1.00e-05\n",
      "Epoch   0 [2850/10697 ( 26.6%)] Loss: 0.032031 L1: 0.019315 Grad: 0.126864 Thermal: 0.000602 LR: 1.00e-05\n",
      "Epoch   0 [2850/10697 ( 26.6%)] Loss: 0.032031 L1: 0.019315 Grad: 0.126864 Thermal: 0.000602 LR: 1.00e-05\n",
      "Epoch   0 [2900/10697 ( 27.1%)] Loss: 0.035737 L1: 0.022474 Grad: 0.132358 Thermal: 0.000552 LR: 1.00e-05\n",
      "Epoch   0 [2900/10697 ( 27.1%)] Loss: 0.035737 L1: 0.022474 Grad: 0.132358 Thermal: 0.000552 LR: 1.00e-05\n",
      "Epoch   0 [2950/10697 ( 27.6%)] Loss: 0.043005 L1: 0.026569 Grad: 0.164015 Thermal: 0.000688 LR: 1.00e-05\n",
      "Epoch   0 [2950/10697 ( 27.6%)] Loss: 0.043005 L1: 0.026569 Grad: 0.164015 Thermal: 0.000688 LR: 1.00e-05\n",
      "Epoch   0 [3000/10697 ( 28.0%)] Loss: 0.041321 L1: 0.025307 Grad: 0.159771 Thermal: 0.000744 LR: 1.00e-05\n",
      "Epoch   0 [3000/10697 ( 28.0%)] Loss: 0.041321 L1: 0.025307 Grad: 0.159771 Thermal: 0.000744 LR: 1.00e-05\n",
      "Epoch   0 [3050/10697 ( 28.5%)] Loss: 0.040465 L1: 0.025831 Grad: 0.145996 Thermal: 0.000691 LR: 1.00e-05\n",
      "Epoch   0 [3050/10697 ( 28.5%)] Loss: 0.040465 L1: 0.025831 Grad: 0.145996 Thermal: 0.000691 LR: 1.00e-05\n",
      "Epoch   0 [3100/10697 ( 29.0%)] Loss: 0.032545 L1: 0.019726 Grad: 0.127935 Thermal: 0.000522 LR: 1.00e-05\n",
      "Epoch   0 [3100/10697 ( 29.0%)] Loss: 0.032545 L1: 0.019726 Grad: 0.127935 Thermal: 0.000522 LR: 1.00e-05\n",
      "Epoch   0 [3150/10697 ( 29.4%)] Loss: 0.033872 L1: 0.020444 Grad: 0.133983 Thermal: 0.000586 LR: 1.00e-05\n",
      "Epoch   0 [3150/10697 ( 29.4%)] Loss: 0.033872 L1: 0.020444 Grad: 0.133983 Thermal: 0.000586 LR: 1.00e-05\n",
      "Epoch   0 [3200/10697 ( 29.9%)] Loss: 0.033725 L1: 0.020509 Grad: 0.131953 Thermal: 0.000425 LR: 1.00e-05\n",
      "Epoch   0 [3200/10697 ( 29.9%)] Loss: 0.033725 L1: 0.020509 Grad: 0.131953 Thermal: 0.000425 LR: 1.00e-05\n",
      "Epoch   0 [3250/10697 ( 30.4%)] Loss: 0.048451 L1: 0.031280 Grad: 0.171197 Thermal: 0.001036 LR: 1.00e-05\n",
      "Epoch   0 [3250/10697 ( 30.4%)] Loss: 0.048451 L1: 0.031280 Grad: 0.171197 Thermal: 0.001036 LR: 1.00e-05\n",
      "Epoch   0 [3300/10697 ( 30.8%)] Loss: 0.045302 L1: 0.027734 Grad: 0.175302 Thermal: 0.000748 LR: 1.00e-05\n",
      "Epoch   0 [3300/10697 ( 30.8%)] Loss: 0.045302 L1: 0.027734 Grad: 0.175302 Thermal: 0.000748 LR: 1.00e-05\n",
      "Epoch   0 [3350/10697 ( 31.3%)] Loss: 0.035414 L1: 0.021565 Grad: 0.138192 Thermal: 0.000582 LR: 1.00e-05\n",
      "Epoch   0 [3350/10697 ( 31.3%)] Loss: 0.035414 L1: 0.021565 Grad: 0.138192 Thermal: 0.000582 LR: 1.00e-05\n",
      "Epoch   0 [3400/10697 ( 31.8%)] Loss: 0.039306 L1: 0.024313 Grad: 0.149609 Thermal: 0.000648 LR: 1.00e-05\n",
      "Epoch   0 [3400/10697 ( 31.8%)] Loss: 0.039306 L1: 0.024313 Grad: 0.149609 Thermal: 0.000648 LR: 1.00e-05\n",
      "Epoch   0 [3450/10697 ( 32.3%)] Loss: 0.035376 L1: 0.021960 Grad: 0.133993 Thermal: 0.000335 LR: 1.00e-05\n",
      "Epoch   0 [3450/10697 ( 32.3%)] Loss: 0.035376 L1: 0.021960 Grad: 0.133993 Thermal: 0.000335 LR: 1.00e-05\n",
      "Epoch   0 [3500/10697 ( 32.7%)] Loss: 0.036257 L1: 0.022172 Grad: 0.140553 Thermal: 0.000590 LR: 1.00e-05\n",
      "Epoch   0 [3500/10697 ( 32.7%)] Loss: 0.036257 L1: 0.022172 Grad: 0.140553 Thermal: 0.000590 LR: 1.00e-05\n",
      "Epoch   0 [3550/10697 ( 33.2%)] Loss: 0.032617 L1: 0.019934 Grad: 0.126607 Thermal: 0.000442 LR: 1.00e-05\n",
      "Epoch   0 [3550/10697 ( 33.2%)] Loss: 0.032617 L1: 0.019934 Grad: 0.126607 Thermal: 0.000442 LR: 1.00e-05\n",
      "Epoch   0 [3600/10697 ( 33.7%)] Loss: 0.035579 L1: 0.021360 Grad: 0.141902 Thermal: 0.000587 LR: 1.00e-05\n",
      "Epoch   0 [3600/10697 ( 33.7%)] Loss: 0.035579 L1: 0.021360 Grad: 0.141902 Thermal: 0.000587 LR: 1.00e-05\n",
      "Epoch   0 [3650/10697 ( 34.1%)] Loss: 0.037808 L1: 0.023916 Grad: 0.138615 Thermal: 0.000606 LR: 1.00e-05\n",
      "Epoch   0 [3650/10697 ( 34.1%)] Loss: 0.037808 L1: 0.023916 Grad: 0.138615 Thermal: 0.000606 LR: 1.00e-05\n",
      "Epoch   0 [3700/10697 ( 34.6%)] Loss: 0.040449 L1: 0.024005 Grad: 0.164069 Thermal: 0.000737 LR: 1.00e-05\n",
      "Epoch   0 [3700/10697 ( 34.6%)] Loss: 0.040449 L1: 0.024005 Grad: 0.164069 Thermal: 0.000737 LR: 1.00e-05\n",
      "Epoch   0 [3750/10697 ( 35.1%)] Loss: 0.043644 L1: 0.025583 Grad: 0.180294 Thermal: 0.000618 LR: 1.00e-05\n",
      "Epoch   0 [3750/10697 ( 35.1%)] Loss: 0.043644 L1: 0.025583 Grad: 0.180294 Thermal: 0.000618 LR: 1.00e-05\n",
      "Epoch   0 [3800/10697 ( 35.5%)] Loss: 0.034475 L1: 0.020505 Grad: 0.139459 Thermal: 0.000480 LR: 1.00e-05\n",
      "Epoch   0 [3800/10697 ( 35.5%)] Loss: 0.034475 L1: 0.020505 Grad: 0.139459 Thermal: 0.000480 LR: 1.00e-05\n",
      "Epoch   0 [3850/10697 ( 36.0%)] Loss: 0.035315 L1: 0.021098 Grad: 0.141902 Thermal: 0.000540 LR: 1.00e-05\n",
      "Epoch   0 [3850/10697 ( 36.0%)] Loss: 0.035315 L1: 0.021098 Grad: 0.141902 Thermal: 0.000540 LR: 1.00e-05\n",
      "Epoch   0 [3900/10697 ( 36.5%)] Loss: 0.037007 L1: 0.022048 Grad: 0.149244 Thermal: 0.000679 LR: 1.00e-05\n",
      "Epoch   0 [3900/10697 ( 36.5%)] Loss: 0.037007 L1: 0.022048 Grad: 0.149244 Thermal: 0.000679 LR: 1.00e-05\n",
      "Epoch   0 [3950/10697 ( 36.9%)] Loss: 0.035449 L1: 0.021506 Grad: 0.139139 Thermal: 0.000594 LR: 1.00e-05\n",
      "Epoch   0 [3950/10697 ( 36.9%)] Loss: 0.035449 L1: 0.021506 Grad: 0.139139 Thermal: 0.000594 LR: 1.00e-05\n",
      "Epoch   0 [4000/10697 ( 37.4%)] Loss: 0.027605 L1: 0.016470 Grad: 0.111156 Thermal: 0.000382 LR: 1.00e-05\n",
      "Epoch   0 [4000/10697 ( 37.4%)] Loss: 0.027605 L1: 0.016470 Grad: 0.111156 Thermal: 0.000382 LR: 1.00e-05\n",
      "Epoch   0 [4050/10697 ( 37.9%)] Loss: 0.041378 L1: 0.024354 Grad: 0.169962 Thermal: 0.000556 LR: 1.00e-05\n",
      "Epoch   0 [4050/10697 ( 37.9%)] Loss: 0.041378 L1: 0.024354 Grad: 0.169962 Thermal: 0.000556 LR: 1.00e-05\n",
      "Epoch   0 [4100/10697 ( 38.3%)] Loss: 0.030911 L1: 0.018274 Grad: 0.126123 Thermal: 0.000481 LR: 1.00e-05\n",
      "Epoch   0 [4100/10697 ( 38.3%)] Loss: 0.030911 L1: 0.018274 Grad: 0.126123 Thermal: 0.000481 LR: 1.00e-05\n",
      "Epoch   0 [4150/10697 ( 38.8%)] Loss: 0.028394 L1: 0.017161 Grad: 0.112088 Thermal: 0.000486 LR: 1.00e-05\n",
      "Epoch   0 [4150/10697 ( 38.8%)] Loss: 0.028394 L1: 0.017161 Grad: 0.112088 Thermal: 0.000486 LR: 1.00e-05\n",
      "Epoch   0 [4200/10697 ( 39.3%)] Loss: 0.039283 L1: 0.023633 Grad: 0.156138 Thermal: 0.000729 LR: 1.00e-05\n",
      "Epoch   0 [4200/10697 ( 39.3%)] Loss: 0.039283 L1: 0.023633 Grad: 0.156138 Thermal: 0.000729 LR: 1.00e-05\n",
      "Epoch   0 [4250/10697 ( 39.7%)] Loss: 0.043740 L1: 0.027044 Grad: 0.166629 Thermal: 0.000672 LR: 1.00e-05\n",
      "Epoch   0 [4250/10697 ( 39.7%)] Loss: 0.043740 L1: 0.027044 Grad: 0.166629 Thermal: 0.000672 LR: 1.00e-05\n",
      "Epoch   0 [4300/10697 ( 40.2%)] Loss: 0.033518 L1: 0.020658 Grad: 0.128347 Thermal: 0.000496 LR: 1.00e-05\n",
      "Epoch   0 [4300/10697 ( 40.2%)] Loss: 0.033518 L1: 0.020658 Grad: 0.128347 Thermal: 0.000496 LR: 1.00e-05\n",
      "Epoch   0 [4350/10697 ( 40.7%)] Loss: 0.034266 L1: 0.020345 Grad: 0.138956 Thermal: 0.000507 LR: 1.00e-05\n",
      "Epoch   0 [4350/10697 ( 40.7%)] Loss: 0.034266 L1: 0.020345 Grad: 0.138956 Thermal: 0.000507 LR: 1.00e-05\n",
      "Epoch   0 [4400/10697 ( 41.1%)] Loss: 0.033832 L1: 0.020011 Grad: 0.137954 Thermal: 0.000500 LR: 1.00e-05\n",
      "Epoch   0 [4400/10697 ( 41.1%)] Loss: 0.033832 L1: 0.020011 Grad: 0.137954 Thermal: 0.000500 LR: 1.00e-05\n",
      "Epoch   0 [4450/10697 ( 41.6%)] Loss: 0.031380 L1: 0.018612 Grad: 0.127499 Thermal: 0.000365 LR: 1.00e-05\n",
      "Epoch   0 [4450/10697 ( 41.6%)] Loss: 0.031380 L1: 0.018612 Grad: 0.127499 Thermal: 0.000365 LR: 1.00e-05\n",
      "Epoch   0 [4500/10697 ( 42.1%)] Loss: 0.033244 L1: 0.020231 Grad: 0.129948 Thermal: 0.000355 LR: 1.00e-05\n",
      "Epoch   0 [4500/10697 ( 42.1%)] Loss: 0.033244 L1: 0.020231 Grad: 0.129948 Thermal: 0.000355 LR: 1.00e-05\n",
      "Epoch   0 [4550/10697 ( 42.5%)] Loss: 0.033373 L1: 0.020093 Grad: 0.132545 Thermal: 0.000503 LR: 1.00e-05\n",
      "Epoch   0 [4550/10697 ( 42.5%)] Loss: 0.033373 L1: 0.020093 Grad: 0.132545 Thermal: 0.000503 LR: 1.00e-05\n",
      "Epoch   0 [4600/10697 ( 43.0%)] Loss: 0.031908 L1: 0.019106 Grad: 0.127804 Thermal: 0.000444 LR: 1.00e-05\n",
      "Epoch   0 [4600/10697 ( 43.0%)] Loss: 0.031908 L1: 0.019106 Grad: 0.127804 Thermal: 0.000444 LR: 1.00e-05\n",
      "Epoch   0 [4650/10697 ( 43.5%)] Loss: 0.035100 L1: 0.020613 Grad: 0.144663 Thermal: 0.000429 LR: 1.00e-05\n",
      "Epoch   0 [4650/10697 ( 43.5%)] Loss: 0.035100 L1: 0.020613 Grad: 0.144663 Thermal: 0.000429 LR: 1.00e-05\n",
      "Epoch   0 [4700/10697 ( 43.9%)] Loss: 0.036215 L1: 0.021685 Grad: 0.144977 Thermal: 0.000658 LR: 1.00e-05\n",
      "Epoch   0 [4700/10697 ( 43.9%)] Loss: 0.036215 L1: 0.021685 Grad: 0.144977 Thermal: 0.000658 LR: 1.00e-05\n",
      "Epoch   0 [4750/10697 ( 44.4%)] Loss: 0.030373 L1: 0.018054 Grad: 0.122962 Thermal: 0.000461 LR: 1.00e-05\n",
      "Epoch   0 [4750/10697 ( 44.4%)] Loss: 0.030373 L1: 0.018054 Grad: 0.122962 Thermal: 0.000461 LR: 1.00e-05\n",
      "Epoch   0 [4800/10697 ( 44.9%)] Loss: 0.034040 L1: 0.020528 Grad: 0.134882 Thermal: 0.000483 LR: 1.00e-05\n",
      "Epoch   0 [4800/10697 ( 44.9%)] Loss: 0.034040 L1: 0.020528 Grad: 0.134882 Thermal: 0.000483 LR: 1.00e-05\n",
      "Epoch   0 [4850/10697 ( 45.3%)] Loss: 0.032494 L1: 0.019128 Grad: 0.133396 Thermal: 0.000522 LR: 1.00e-05\n",
      "Epoch   0 [4850/10697 ( 45.3%)] Loss: 0.032494 L1: 0.019128 Grad: 0.133396 Thermal: 0.000522 LR: 1.00e-05\n",
      "Epoch   0 [4900/10697 ( 45.8%)] Loss: 0.038289 L1: 0.023034 Grad: 0.152236 Thermal: 0.000614 LR: 1.00e-05\n",
      "Epoch   0 [4900/10697 ( 45.8%)] Loss: 0.038289 L1: 0.023034 Grad: 0.152236 Thermal: 0.000614 LR: 1.00e-05\n",
      "Epoch   0 [4950/10697 ( 46.3%)] Loss: 0.026098 L1: 0.015562 Grad: 0.105193 Thermal: 0.000349 LR: 1.00e-05\n",
      "Epoch   0 [4950/10697 ( 46.3%)] Loss: 0.026098 L1: 0.015562 Grad: 0.105193 Thermal: 0.000349 LR: 1.00e-05\n",
      "Epoch   0 [5000/10697 ( 46.7%)] Loss: 0.028803 L1: 0.017393 Grad: 0.113890 Thermal: 0.000424 LR: 1.00e-05\n",
      "Epoch   0 [5000/10697 ( 46.7%)] Loss: 0.028803 L1: 0.017393 Grad: 0.113890 Thermal: 0.000424 LR: 1.00e-05\n",
      "Epoch   0 [5050/10697 ( 47.2%)] Loss: 0.038224 L1: 0.022675 Grad: 0.155175 Thermal: 0.000649 LR: 1.00e-05\n",
      "Epoch   0 [5050/10697 ( 47.2%)] Loss: 0.038224 L1: 0.022675 Grad: 0.155175 Thermal: 0.000649 LR: 1.00e-05\n",
      "Epoch   0 [5100/10697 ( 47.7%)] Loss: 0.035753 L1: 0.020934 Grad: 0.147888 Thermal: 0.000606 LR: 1.00e-05\n",
      "Epoch   0 [5100/10697 ( 47.7%)] Loss: 0.035753 L1: 0.020934 Grad: 0.147888 Thermal: 0.000606 LR: 1.00e-05\n",
      "Epoch   0 [5150/10697 ( 48.1%)] Loss: 0.031344 L1: 0.018690 Grad: 0.126324 Thermal: 0.000430 LR: 1.00e-05\n",
      "Epoch   0 [5150/10697 ( 48.1%)] Loss: 0.031344 L1: 0.018690 Grad: 0.126324 Thermal: 0.000430 LR: 1.00e-05\n",
      "Epoch   0 [5200/10697 ( 48.6%)] Loss: 0.030630 L1: 0.018441 Grad: 0.121635 Thermal: 0.000519 LR: 1.00e-05\n",
      "Epoch   0 [5200/10697 ( 48.6%)] Loss: 0.030630 L1: 0.018441 Grad: 0.121635 Thermal: 0.000519 LR: 1.00e-05\n",
      "Epoch   0 [5250/10697 ( 49.1%)] Loss: 0.037186 L1: 0.022028 Grad: 0.151268 Thermal: 0.000632 LR: 1.00e-05\n",
      "Epoch   0 [5250/10697 ( 49.1%)] Loss: 0.037186 L1: 0.022028 Grad: 0.151268 Thermal: 0.000632 LR: 1.00e-05\n",
      "Epoch   0 [5300/10697 ( 49.5%)] Loss: 0.026087 L1: 0.015575 Grad: 0.104912 Thermal: 0.000410 LR: 1.00e-05\n",
      "Epoch   0 [5300/10697 ( 49.5%)] Loss: 0.026087 L1: 0.015575 Grad: 0.104912 Thermal: 0.000410 LR: 1.00e-05\n",
      "Epoch   0 [5350/10697 ( 50.0%)] Loss: 0.044150 L1: 0.025935 Grad: 0.181801 Thermal: 0.000709 LR: 1.00e-05\n",
      "Epoch   0 [5350/10697 ( 50.0%)] Loss: 0.044150 L1: 0.025935 Grad: 0.181801 Thermal: 0.000709 LR: 1.00e-05\n",
      "Epoch   0 [5400/10697 ( 50.5%)] Loss: 0.039705 L1: 0.023259 Grad: 0.164072 Thermal: 0.000767 LR: 1.00e-05\n",
      "Epoch   0 [5400/10697 ( 50.5%)] Loss: 0.039705 L1: 0.023259 Grad: 0.164072 Thermal: 0.000767 LR: 1.00e-05\n",
      "Epoch   0 [5450/10697 ( 50.9%)] Loss: 0.028008 L1: 0.016806 Grad: 0.111808 Thermal: 0.000427 LR: 1.00e-05\n",
      "Epoch   0 [5450/10697 ( 50.9%)] Loss: 0.028008 L1: 0.016806 Grad: 0.111808 Thermal: 0.000427 LR: 1.00e-05\n",
      "Epoch   0 [5500/10697 ( 51.4%)] Loss: 0.033755 L1: 0.019652 Grad: 0.140783 Thermal: 0.000502 LR: 1.00e-05\n",
      "Epoch   0 [5500/10697 ( 51.4%)] Loss: 0.033755 L1: 0.019652 Grad: 0.140783 Thermal: 0.000502 LR: 1.00e-05\n",
      "Epoch   0 [5550/10697 ( 51.9%)] Loss: 0.029443 L1: 0.017432 Grad: 0.119884 Thermal: 0.000465 LR: 1.00e-05\n",
      "Epoch   0 [5550/10697 ( 51.9%)] Loss: 0.029443 L1: 0.017432 Grad: 0.119884 Thermal: 0.000465 LR: 1.00e-05\n",
      "Epoch   0 [5600/10697 ( 52.4%)] Loss: 0.033336 L1: 0.019674 Grad: 0.136357 Thermal: 0.000524 LR: 1.00e-05\n",
      "Epoch   0 [5600/10697 ( 52.4%)] Loss: 0.033336 L1: 0.019674 Grad: 0.136357 Thermal: 0.000524 LR: 1.00e-05\n",
      "Epoch   0 [5650/10697 ( 52.8%)] Loss: 0.029672 L1: 0.017324 Grad: 0.123245 Thermal: 0.000461 LR: 1.00e-05\n",
      "Epoch   0 [5650/10697 ( 52.8%)] Loss: 0.029672 L1: 0.017324 Grad: 0.123245 Thermal: 0.000461 LR: 1.00e-05\n",
      "Epoch   0 [5700/10697 ( 53.3%)] Loss: 0.032979 L1: 0.019341 Grad: 0.136129 Thermal: 0.000491 LR: 1.00e-05\n",
      "Epoch   0 [5700/10697 ( 53.3%)] Loss: 0.032979 L1: 0.019341 Grad: 0.136129 Thermal: 0.000491 LR: 1.00e-05\n",
      "Epoch   0 [5750/10697 ( 53.8%)] Loss: 0.027172 L1: 0.016284 Grad: 0.108659 Thermal: 0.000445 LR: 1.00e-05\n",
      "Epoch   0 [5750/10697 ( 53.8%)] Loss: 0.027172 L1: 0.016284 Grad: 0.108659 Thermal: 0.000445 LR: 1.00e-05\n",
      "Epoch   0 [5800/10697 ( 54.2%)] Loss: 0.031061 L1: 0.018453 Grad: 0.125830 Thermal: 0.000509 LR: 1.00e-05\n",
      "Epoch   0 [5800/10697 ( 54.2%)] Loss: 0.031061 L1: 0.018453 Grad: 0.125830 Thermal: 0.000509 LR: 1.00e-05\n",
      "Epoch   0 [5850/10697 ( 54.7%)] Loss: 0.032792 L1: 0.019507 Grad: 0.132581 Thermal: 0.000541 LR: 1.00e-05\n",
      "Epoch   0 [5850/10697 ( 54.7%)] Loss: 0.032792 L1: 0.019507 Grad: 0.132581 Thermal: 0.000541 LR: 1.00e-05\n",
      "Epoch   0 [5900/10697 ( 55.2%)] Loss: 0.034306 L1: 0.020109 Grad: 0.141622 Thermal: 0.000708 LR: 1.00e-05\n",
      "Epoch   0 [5900/10697 ( 55.2%)] Loss: 0.034306 L1: 0.020109 Grad: 0.141622 Thermal: 0.000708 LR: 1.00e-05\n",
      "Epoch   0 [5950/10697 ( 55.6%)] Loss: 0.043003 L1: 0.025257 Grad: 0.177053 Thermal: 0.000811 LR: 1.00e-05\n",
      "Epoch   0 [5950/10697 ( 55.6%)] Loss: 0.043003 L1: 0.025257 Grad: 0.177053 Thermal: 0.000811 LR: 1.00e-05\n",
      "Epoch   0 [6000/10697 ( 56.1%)] Loss: 0.035620 L1: 0.021314 Grad: 0.142760 Thermal: 0.000598 LR: 1.00e-05\n",
      "Epoch   0 [6000/10697 ( 56.1%)] Loss: 0.035620 L1: 0.021314 Grad: 0.142760 Thermal: 0.000598 LR: 1.00e-05\n",
      "Epoch   0 [6050/10697 ( 56.6%)] Loss: 0.024592 L1: 0.014585 Grad: 0.099870 Thermal: 0.000394 LR: 1.00e-05\n",
      "Epoch   0 [6050/10697 ( 56.6%)] Loss: 0.024592 L1: 0.014585 Grad: 0.099870 Thermal: 0.000394 LR: 1.00e-05\n",
      "Epoch   0 [6100/10697 ( 57.0%)] Loss: 0.032222 L1: 0.019110 Grad: 0.130840 Thermal: 0.000562 LR: 1.00e-05\n",
      "Epoch   0 [6100/10697 ( 57.0%)] Loss: 0.032222 L1: 0.019110 Grad: 0.130840 Thermal: 0.000562 LR: 1.00e-05\n",
      "Epoch   0 [6150/10697 ( 57.5%)] Loss: 0.028969 L1: 0.017304 Grad: 0.116416 Thermal: 0.000469 LR: 1.00e-05\n",
      "Epoch   0 [6150/10697 ( 57.5%)] Loss: 0.028969 L1: 0.017304 Grad: 0.116416 Thermal: 0.000469 LR: 1.00e-05\n",
      "Epoch   0 [6200/10697 ( 58.0%)] Loss: 0.039473 L1: 0.022907 Grad: 0.165247 Thermal: 0.000815 LR: 1.00e-05\n",
      "Epoch   0 [6200/10697 ( 58.0%)] Loss: 0.039473 L1: 0.022907 Grad: 0.165247 Thermal: 0.000815 LR: 1.00e-05\n",
      "Epoch   0 [6250/10697 ( 58.4%)] Loss: 0.031127 L1: 0.018748 Grad: 0.123476 Thermal: 0.000623 LR: 1.00e-05\n",
      "Epoch   0 [6250/10697 ( 58.4%)] Loss: 0.031127 L1: 0.018748 Grad: 0.123476 Thermal: 0.000623 LR: 1.00e-05\n",
      "Epoch   0 [6300/10697 ( 58.9%)] Loss: 0.036331 L1: 0.021224 Grad: 0.150742 Thermal: 0.000656 LR: 1.00e-05\n",
      "Epoch   0 [6300/10697 ( 58.9%)] Loss: 0.036331 L1: 0.021224 Grad: 0.150742 Thermal: 0.000656 LR: 1.00e-05\n",
      "Epoch   0 [6350/10697 ( 59.4%)] Loss: 0.030293 L1: 0.018138 Grad: 0.121280 Thermal: 0.000538 LR: 1.00e-05\n",
      "Epoch   0 [6350/10697 ( 59.4%)] Loss: 0.030293 L1: 0.018138 Grad: 0.121280 Thermal: 0.000538 LR: 1.00e-05\n",
      "Epoch   0 [6400/10697 ( 59.8%)] Loss: 0.023513 L1: 0.013703 Grad: 0.097925 Thermal: 0.000337 LR: 1.00e-05\n",
      "Epoch   0 [6400/10697 ( 59.8%)] Loss: 0.023513 L1: 0.013703 Grad: 0.097925 Thermal: 0.000337 LR: 1.00e-05\n",
      "Epoch   0 [6450/10697 ( 60.3%)] Loss: 0.026467 L1: 0.014969 Grad: 0.114783 Thermal: 0.000385 LR: 1.00e-05\n",
      "Epoch   0 [6450/10697 ( 60.3%)] Loss: 0.026467 L1: 0.014969 Grad: 0.114783 Thermal: 0.000385 LR: 1.00e-05\n",
      "Epoch   0 [6500/10697 ( 60.8%)] Loss: 0.032792 L1: 0.019567 Grad: 0.131877 Thermal: 0.000746 LR: 1.00e-05\n",
      "Epoch   0 [6500/10697 ( 60.8%)] Loss: 0.032792 L1: 0.019567 Grad: 0.131877 Thermal: 0.000746 LR: 1.00e-05\n",
      "Epoch   0 [6550/10697 ( 61.2%)] Loss: 0.031915 L1: 0.018499 Grad: 0.133885 Thermal: 0.000553 LR: 1.00e-05\n",
      "Epoch   0 [6550/10697 ( 61.2%)] Loss: 0.031915 L1: 0.018499 Grad: 0.133885 Thermal: 0.000553 LR: 1.00e-05\n",
      "Epoch   0 [6600/10697 ( 61.7%)] Loss: 0.032837 L1: 0.019515 Grad: 0.132907 Thermal: 0.000629 LR: 1.00e-05\n",
      "Epoch   0 [6600/10697 ( 61.7%)] Loss: 0.032837 L1: 0.019515 Grad: 0.132907 Thermal: 0.000629 LR: 1.00e-05\n",
      "Epoch   0 [6650/10697 ( 62.2%)] Loss: 0.033370 L1: 0.019554 Grad: 0.137865 Thermal: 0.000579 LR: 1.00e-05\n",
      "Epoch   0 [6650/10697 ( 62.2%)] Loss: 0.033370 L1: 0.019554 Grad: 0.137865 Thermal: 0.000579 LR: 1.00e-05\n",
      "Epoch   0 [6700/10697 ( 62.6%)] Loss: 0.039352 L1: 0.022505 Grad: 0.168103 Thermal: 0.000742 LR: 1.00e-05\n",
      "Epoch   0 [6700/10697 ( 62.6%)] Loss: 0.039352 L1: 0.022505 Grad: 0.168103 Thermal: 0.000742 LR: 1.00e-05\n",
      "Epoch   0 [6750/10697 ( 63.1%)] Loss: 0.026908 L1: 0.015769 Grad: 0.111167 Thermal: 0.000440 LR: 1.00e-05\n",
      "Epoch   0 [6750/10697 ( 63.1%)] Loss: 0.026908 L1: 0.015769 Grad: 0.111167 Thermal: 0.000440 LR: 1.00e-05\n",
      "Epoch   0 [6800/10697 ( 63.6%)] Loss: 0.030661 L1: 0.017948 Grad: 0.126848 Thermal: 0.000560 LR: 1.00e-05\n",
      "Epoch   0 [6800/10697 ( 63.6%)] Loss: 0.030661 L1: 0.017948 Grad: 0.126848 Thermal: 0.000560 LR: 1.00e-05\n",
      "Epoch   0 [6850/10697 ( 64.0%)] Loss: 0.035985 L1: 0.021335 Grad: 0.146139 Thermal: 0.000718 LR: 1.00e-05\n",
      "Epoch   0 [6850/10697 ( 64.0%)] Loss: 0.035985 L1: 0.021335 Grad: 0.146139 Thermal: 0.000718 LR: 1.00e-05\n",
      "Epoch   0 [6900/10697 ( 64.5%)] Loss: 0.023997 L1: 0.014264 Grad: 0.097172 Thermal: 0.000318 LR: 1.00e-05\n",
      "Epoch   0 [6900/10697 ( 64.5%)] Loss: 0.023997 L1: 0.014264 Grad: 0.097172 Thermal: 0.000318 LR: 1.00e-05\n",
      "Epoch   0 [6950/10697 ( 65.0%)] Loss: 0.036017 L1: 0.021044 Grad: 0.149397 Thermal: 0.000654 LR: 1.00e-05\n",
      "Epoch   0 [6950/10697 ( 65.0%)] Loss: 0.036017 L1: 0.021044 Grad: 0.149397 Thermal: 0.000654 LR: 1.00e-05\n",
      "Epoch   0 [7000/10697 ( 65.4%)] Loss: 0.035031 L1: 0.020583 Grad: 0.144170 Thermal: 0.000627 LR: 1.00e-05\n",
      "Epoch   0 [7000/10697 ( 65.4%)] Loss: 0.035031 L1: 0.020583 Grad: 0.144170 Thermal: 0.000627 LR: 1.00e-05\n",
      "Epoch   0 [7050/10697 ( 65.9%)] Loss: 0.029187 L1: 0.017035 Grad: 0.121311 Thermal: 0.000416 LR: 1.00e-05\n",
      "Epoch   0 [7050/10697 ( 65.9%)] Loss: 0.029187 L1: 0.017035 Grad: 0.121311 Thermal: 0.000416 LR: 1.00e-05\n",
      "Epoch   0 [7100/10697 ( 66.4%)] Loss: 0.034768 L1: 0.020030 Grad: 0.147044 Thermal: 0.000676 LR: 1.00e-05\n",
      "Epoch   0 [7100/10697 ( 66.4%)] Loss: 0.034768 L1: 0.020030 Grad: 0.147044 Thermal: 0.000676 LR: 1.00e-05\n",
      "Epoch   0 [7150/10697 ( 66.8%)] Loss: 0.031627 L1: 0.018544 Grad: 0.130555 Thermal: 0.000544 LR: 1.00e-05\n",
      "Epoch   0 [7150/10697 ( 66.8%)] Loss: 0.031627 L1: 0.018544 Grad: 0.130555 Thermal: 0.000544 LR: 1.00e-05\n",
      "Epoch   0 [7200/10697 ( 67.3%)] Loss: 0.030534 L1: 0.017967 Grad: 0.125396 Thermal: 0.000543 LR: 1.00e-05\n",
      "Epoch   0 [7200/10697 ( 67.3%)] Loss: 0.030534 L1: 0.017967 Grad: 0.125396 Thermal: 0.000543 LR: 1.00e-05\n",
      "Epoch   0 [7250/10697 ( 67.8%)] Loss: 0.027261 L1: 0.016109 Grad: 0.111298 Thermal: 0.000449 LR: 1.00e-05\n",
      "Epoch   0 [7250/10697 ( 67.8%)] Loss: 0.027261 L1: 0.016109 Grad: 0.111298 Thermal: 0.000449 LR: 1.00e-05\n",
      "Epoch   0 [7300/10697 ( 68.2%)] Loss: 0.027006 L1: 0.016281 Grad: 0.107022 Thermal: 0.000453 LR: 1.00e-05\n",
      "Epoch   0 [7300/10697 ( 68.2%)] Loss: 0.027006 L1: 0.016281 Grad: 0.107022 Thermal: 0.000453 LR: 1.00e-05\n",
      "Epoch   0 [7350/10697 ( 68.7%)] Loss: 0.036554 L1: 0.021045 Grad: 0.154721 Thermal: 0.000733 LR: 1.00e-05\n",
      "Epoch   0 [7350/10697 ( 68.7%)] Loss: 0.036554 L1: 0.021045 Grad: 0.154721 Thermal: 0.000733 LR: 1.00e-05\n",
      "Epoch   0 [7400/10697 ( 69.2%)] Loss: 0.030319 L1: 0.018011 Grad: 0.122812 Thermal: 0.000532 LR: 1.00e-05\n",
      "Epoch   0 [7400/10697 ( 69.2%)] Loss: 0.030319 L1: 0.018011 Grad: 0.122812 Thermal: 0.000532 LR: 1.00e-05\n",
      "Epoch   0 [7450/10697 ( 69.6%)] Loss: 0.033507 L1: 0.019213 Grad: 0.142649 Thermal: 0.000568 LR: 1.00e-05\n",
      "Epoch   0 [7450/10697 ( 69.6%)] Loss: 0.033507 L1: 0.019213 Grad: 0.142649 Thermal: 0.000568 LR: 1.00e-05\n",
      "Epoch   0 [7500/10697 ( 70.1%)] Loss: 0.035654 L1: 0.020698 Grad: 0.149192 Thermal: 0.000723 LR: 1.00e-05\n",
      "Epoch   0 [7500/10697 ( 70.1%)] Loss: 0.035654 L1: 0.020698 Grad: 0.149192 Thermal: 0.000723 LR: 1.00e-05\n",
      "Epoch   0 [7550/10697 ( 70.6%)] Loss: 0.035825 L1: 0.020883 Grad: 0.149055 Thermal: 0.000731 LR: 1.00e-05\n",
      "Epoch   0 [7550/10697 ( 70.6%)] Loss: 0.035825 L1: 0.020883 Grad: 0.149055 Thermal: 0.000731 LR: 1.00e-05\n",
      "Epoch   0 [7600/10697 ( 71.0%)] Loss: 0.026410 L1: 0.015371 Grad: 0.110187 Thermal: 0.000418 LR: 1.00e-05\n",
      "Epoch   0 [7600/10697 ( 71.0%)] Loss: 0.026410 L1: 0.015371 Grad: 0.110187 Thermal: 0.000418 LR: 1.00e-05\n",
      "Epoch   0 [7650/10697 ( 71.5%)] Loss: 0.027805 L1: 0.016492 Grad: 0.112893 Thermal: 0.000475 LR: 1.00e-05\n",
      "Epoch   0 [7650/10697 ( 71.5%)] Loss: 0.027805 L1: 0.016492 Grad: 0.112893 Thermal: 0.000475 LR: 1.00e-05\n",
      "Epoch   0 [7700/10697 ( 72.0%)] Loss: 0.033285 L1: 0.018400 Grad: 0.148618 Thermal: 0.000481 LR: 1.00e-05\n",
      "Epoch   0 [7700/10697 ( 72.0%)] Loss: 0.033285 L1: 0.018400 Grad: 0.148618 Thermal: 0.000481 LR: 1.00e-05\n",
      "Epoch   0 [7750/10697 ( 72.5%)] Loss: 0.029034 L1: 0.017187 Grad: 0.118192 Thermal: 0.000553 LR: 1.00e-05\n",
      "Epoch   0 [7750/10697 ( 72.5%)] Loss: 0.029034 L1: 0.017187 Grad: 0.118192 Thermal: 0.000553 LR: 1.00e-05\n",
      "Epoch   0 [7800/10697 ( 72.9%)] Loss: 0.027278 L1: 0.016138 Grad: 0.111180 Thermal: 0.000434 LR: 1.00e-05\n",
      "Epoch   0 [7800/10697 ( 72.9%)] Loss: 0.027278 L1: 0.016138 Grad: 0.111180 Thermal: 0.000434 LR: 1.00e-05\n",
      "Epoch   0 [7850/10697 ( 73.4%)] Loss: 0.033920 L1: 0.019480 Grad: 0.144091 Thermal: 0.000629 LR: 1.00e-05\n",
      "Epoch   0 [7850/10697 ( 73.4%)] Loss: 0.033920 L1: 0.019480 Grad: 0.144091 Thermal: 0.000629 LR: 1.00e-05\n",
      "Epoch   0 [7900/10697 ( 73.9%)] Loss: 0.036367 L1: 0.020626 Grad: 0.157106 Thermal: 0.000604 LR: 1.00e-05\n",
      "Epoch   0 [7900/10697 ( 73.9%)] Loss: 0.036367 L1: 0.020626 Grad: 0.157106 Thermal: 0.000604 LR: 1.00e-05\n",
      "Epoch   0 [7950/10697 ( 74.3%)] Loss: 0.034626 L1: 0.019912 Grad: 0.146784 Thermal: 0.000695 LR: 1.00e-05\n",
      "Epoch   0 [7950/10697 ( 74.3%)] Loss: 0.034626 L1: 0.019912 Grad: 0.146784 Thermal: 0.000695 LR: 1.00e-05\n",
      "Epoch   0 [8000/10697 ( 74.8%)] Loss: 0.031571 L1: 0.017697 Grad: 0.138440 Thermal: 0.000583 LR: 1.00e-05\n",
      "Epoch   0 [8000/10697 ( 74.8%)] Loss: 0.031571 L1: 0.017697 Grad: 0.138440 Thermal: 0.000583 LR: 1.00e-05\n",
      "Epoch   0 [8050/10697 ( 75.3%)] Loss: 0.029433 L1: 0.017729 Grad: 0.116773 Thermal: 0.000528 LR: 1.00e-05\n",
      "Epoch   0 [8050/10697 ( 75.3%)] Loss: 0.029433 L1: 0.017729 Grad: 0.116773 Thermal: 0.000528 LR: 1.00e-05\n",
      "Epoch   0 [8100/10697 ( 75.7%)] Loss: 0.031121 L1: 0.017904 Grad: 0.131859 Thermal: 0.000636 LR: 1.00e-05\n",
      "Epoch   0 [8100/10697 ( 75.7%)] Loss: 0.031121 L1: 0.017904 Grad: 0.131859 Thermal: 0.000636 LR: 1.00e-05\n",
      "Epoch   0 [8150/10697 ( 76.2%)] Loss: 0.027468 L1: 0.015902 Grad: 0.115426 Thermal: 0.000471 LR: 1.00e-05\n",
      "Epoch   0 [8150/10697 ( 76.2%)] Loss: 0.027468 L1: 0.015902 Grad: 0.115426 Thermal: 0.000471 LR: 1.00e-05\n",
      "Epoch   0 [8200/10697 ( 76.7%)] Loss: 0.033783 L1: 0.019696 Grad: 0.140532 Thermal: 0.000680 LR: 1.00e-05\n",
      "Epoch   0 [8200/10697 ( 76.7%)] Loss: 0.033783 L1: 0.019696 Grad: 0.140532 Thermal: 0.000680 LR: 1.00e-05\n",
      "Epoch   0 [8250/10697 ( 77.1%)] Loss: 0.028405 L1: 0.016958 Grad: 0.114236 Thermal: 0.000473 LR: 1.00e-05\n",
      "Epoch   0 [8250/10697 ( 77.1%)] Loss: 0.028405 L1: 0.016958 Grad: 0.114236 Thermal: 0.000473 LR: 1.00e-05\n",
      "Epoch   0 [8300/10697 ( 77.6%)] Loss: 0.028968 L1: 0.016779 Grad: 0.121646 Thermal: 0.000487 LR: 1.00e-05\n",
      "Epoch   0 [8300/10697 ( 77.6%)] Loss: 0.028968 L1: 0.016779 Grad: 0.121646 Thermal: 0.000487 LR: 1.00e-05\n",
      "Epoch   0 [8350/10697 ( 78.1%)] Loss: 0.032378 L1: 0.019235 Grad: 0.131135 Thermal: 0.000601 LR: 1.00e-05\n",
      "Epoch   0 [8350/10697 ( 78.1%)] Loss: 0.032378 L1: 0.019235 Grad: 0.131135 Thermal: 0.000601 LR: 1.00e-05\n",
      "Epoch   0 [8400/10697 ( 78.5%)] Loss: 0.033624 L1: 0.019277 Grad: 0.143162 Thermal: 0.000630 LR: 1.00e-05\n",
      "Epoch   0 [8400/10697 ( 78.5%)] Loss: 0.033624 L1: 0.019277 Grad: 0.143162 Thermal: 0.000630 LR: 1.00e-05\n",
      "Epoch   0 [8450/10697 ( 79.0%)] Loss: 0.024518 L1: 0.014019 Grad: 0.104764 Thermal: 0.000442 LR: 1.00e-05\n",
      "Epoch   0 [8450/10697 ( 79.0%)] Loss: 0.024518 L1: 0.014019 Grad: 0.104764 Thermal: 0.000442 LR: 1.00e-05\n",
      "Epoch   0 [8500/10697 ( 79.5%)] Loss: 0.026988 L1: 0.016198 Grad: 0.107674 Thermal: 0.000446 LR: 1.00e-05\n",
      "Epoch   0 [8500/10697 ( 79.5%)] Loss: 0.026988 L1: 0.016198 Grad: 0.107674 Thermal: 0.000446 LR: 1.00e-05\n",
      "Epoch   0 [8550/10697 ( 79.9%)] Loss: 0.028043 L1: 0.016193 Grad: 0.118276 Thermal: 0.000453 LR: 1.00e-05\n",
      "Epoch   0 [8550/10697 ( 79.9%)] Loss: 0.028043 L1: 0.016193 Grad: 0.118276 Thermal: 0.000453 LR: 1.00e-05\n",
      "Epoch   0 [8600/10697 ( 80.4%)] Loss: 0.031355 L1: 0.018392 Grad: 0.129344 Thermal: 0.000582 LR: 1.00e-05\n",
      "Epoch   0 [8600/10697 ( 80.4%)] Loss: 0.031355 L1: 0.018392 Grad: 0.129344 Thermal: 0.000582 LR: 1.00e-05\n",
      "Epoch   0 [8650/10697 ( 80.9%)] Loss: 0.026711 L1: 0.015493 Grad: 0.111945 Thermal: 0.000463 LR: 1.00e-05\n",
      "Epoch   0 [8650/10697 ( 80.9%)] Loss: 0.026711 L1: 0.015493 Grad: 0.111945 Thermal: 0.000463 LR: 1.00e-05\n",
      "Epoch   0 [8700/10697 ( 81.3%)] Loss: 0.030016 L1: 0.017470 Grad: 0.125209 Thermal: 0.000499 LR: 1.00e-05\n",
      "Epoch   0 [8700/10697 ( 81.3%)] Loss: 0.030016 L1: 0.017470 Grad: 0.125209 Thermal: 0.000499 LR: 1.00e-05\n",
      "Epoch   0 [8750/10697 ( 81.8%)] Loss: 0.027038 L1: 0.015537 Grad: 0.114793 Thermal: 0.000436 LR: 1.00e-05\n",
      "Epoch   0 [8750/10697 ( 81.8%)] Loss: 0.027038 L1: 0.015537 Grad: 0.114793 Thermal: 0.000436 LR: 1.00e-05\n",
      "Epoch   0 [8800/10697 ( 82.3%)] Loss: 0.032533 L1: 0.018179 Grad: 0.143191 Thermal: 0.000705 LR: 1.00e-05\n",
      "Epoch   0 [8800/10697 ( 82.3%)] Loss: 0.032533 L1: 0.018179 Grad: 0.143191 Thermal: 0.000705 LR: 1.00e-05\n",
      "Epoch   0 [8850/10697 ( 82.7%)] Loss: 0.025729 L1: 0.014940 Grad: 0.107686 Thermal: 0.000397 LR: 1.00e-05\n",
      "Epoch   0 [8850/10697 ( 82.7%)] Loss: 0.025729 L1: 0.014940 Grad: 0.107686 Thermal: 0.000397 LR: 1.00e-05\n",
      "Epoch   0 [8900/10697 ( 83.2%)] Loss: 0.028220 L1: 0.016279 Grad: 0.119147 Thermal: 0.000519 LR: 1.00e-05\n",
      "Epoch   0 [8900/10697 ( 83.2%)] Loss: 0.028220 L1: 0.016279 Grad: 0.119147 Thermal: 0.000519 LR: 1.00e-05\n",
      "Epoch   0 [8950/10697 ( 83.7%)] Loss: 0.027562 L1: 0.016459 Grad: 0.110814 Thermal: 0.000430 LR: 1.00e-05\n",
      "Epoch   0 [8950/10697 ( 83.7%)] Loss: 0.027562 L1: 0.016459 Grad: 0.110814 Thermal: 0.000430 LR: 1.00e-05\n",
      "Epoch   0 [9000/10697 ( 84.1%)] Loss: 0.029869 L1: 0.017254 Grad: 0.125887 Thermal: 0.000511 LR: 1.00e-05\n",
      "Epoch   0 [9000/10697 ( 84.1%)] Loss: 0.029869 L1: 0.017254 Grad: 0.125887 Thermal: 0.000511 LR: 1.00e-05\n",
      "Epoch   0 [9050/10697 ( 84.6%)] Loss: 0.024338 L1: 0.013937 Grad: 0.103832 Thermal: 0.000369 LR: 1.00e-05\n",
      "Epoch   0 [9050/10697 ( 84.6%)] Loss: 0.024338 L1: 0.013937 Grad: 0.103832 Thermal: 0.000369 LR: 1.00e-05\n",
      "Epoch   0 [9100/10697 ( 85.1%)] Loss: 0.024720 L1: 0.014094 Grad: 0.106085 Thermal: 0.000368 LR: 1.00e-05\n",
      "Epoch   0 [9100/10697 ( 85.1%)] Loss: 0.024720 L1: 0.014094 Grad: 0.106085 Thermal: 0.000368 LR: 1.00e-05\n",
      "Epoch   0 [9150/10697 ( 85.5%)] Loss: 0.023446 L1: 0.013489 Grad: 0.099389 Thermal: 0.000348 LR: 1.00e-05\n",
      "Epoch   0 [9150/10697 ( 85.5%)] Loss: 0.023446 L1: 0.013489 Grad: 0.099389 Thermal: 0.000348 LR: 1.00e-05\n",
      "Epoch   0 [9200/10697 ( 86.0%)] Loss: 0.039640 L1: 0.022856 Grad: 0.167365 Thermal: 0.000965 LR: 1.00e-05\n",
      "Epoch   0 [9200/10697 ( 86.0%)] Loss: 0.039640 L1: 0.022856 Grad: 0.167365 Thermal: 0.000965 LR: 1.00e-05\n",
      "Epoch   0 [9250/10697 ( 86.5%)] Loss: 0.029770 L1: 0.017165 Grad: 0.125779 Thermal: 0.000542 LR: 1.00e-05\n",
      "Epoch   0 [9250/10697 ( 86.5%)] Loss: 0.029770 L1: 0.017165 Grad: 0.125779 Thermal: 0.000542 LR: 1.00e-05\n",
      "Epoch   0 [9300/10697 ( 86.9%)] Loss: 0.027991 L1: 0.016379 Grad: 0.115885 Thermal: 0.000468 LR: 1.00e-05\n",
      "Epoch   0 [9300/10697 ( 86.9%)] Loss: 0.027991 L1: 0.016379 Grad: 0.115885 Thermal: 0.000468 LR: 1.00e-05\n",
      "Epoch   0 [9350/10697 ( 87.4%)] Loss: 0.032734 L1: 0.018849 Grad: 0.138520 Thermal: 0.000653 LR: 1.00e-05\n",
      "Epoch   0 [9350/10697 ( 87.4%)] Loss: 0.032734 L1: 0.018849 Grad: 0.138520 Thermal: 0.000653 LR: 1.00e-05\n",
      "Epoch   0 [9400/10697 ( 87.9%)] Loss: 0.031923 L1: 0.018781 Grad: 0.131128 Thermal: 0.000591 LR: 1.00e-05\n",
      "Epoch   0 [9400/10697 ( 87.9%)] Loss: 0.031923 L1: 0.018781 Grad: 0.131128 Thermal: 0.000591 LR: 1.00e-05\n",
      "Epoch   0 [9450/10697 ( 88.3%)] Loss: 0.030884 L1: 0.017919 Grad: 0.129378 Thermal: 0.000544 LR: 1.00e-05\n",
      "Epoch   0 [9450/10697 ( 88.3%)] Loss: 0.030884 L1: 0.017919 Grad: 0.129378 Thermal: 0.000544 LR: 1.00e-05\n",
      "Epoch   0 [9500/10697 ( 88.8%)] Loss: 0.027555 L1: 0.016059 Grad: 0.114710 Thermal: 0.000518 LR: 1.00e-05\n",
      "Epoch   0 [9500/10697 ( 88.8%)] Loss: 0.027555 L1: 0.016059 Grad: 0.114710 Thermal: 0.000518 LR: 1.00e-05\n",
      "Epoch   0 [9550/10697 ( 89.3%)] Loss: 0.036362 L1: 0.020687 Grad: 0.156381 Thermal: 0.000727 LR: 1.00e-05\n",
      "Epoch   0 [9550/10697 ( 89.3%)] Loss: 0.036362 L1: 0.020687 Grad: 0.156381 Thermal: 0.000727 LR: 1.00e-05\n",
      "Epoch   0 [9600/10697 ( 89.7%)] Loss: 0.033236 L1: 0.019151 Grad: 0.140563 Thermal: 0.000587 LR: 1.00e-05\n",
      "Epoch   0 [9600/10697 ( 89.7%)] Loss: 0.033236 L1: 0.019151 Grad: 0.140563 Thermal: 0.000587 LR: 1.00e-05\n",
      "Epoch   0 [9650/10697 ( 90.2%)] Loss: 0.031770 L1: 0.018475 Grad: 0.132646 Thermal: 0.000611 LR: 1.00e-05\n",
      "Epoch   0 [9650/10697 ( 90.2%)] Loss: 0.031770 L1: 0.018475 Grad: 0.132646 Thermal: 0.000611 LR: 1.00e-05\n",
      "Epoch   0 [9700/10697 ( 90.7%)] Loss: 0.028324 L1: 0.017039 Grad: 0.112603 Thermal: 0.000480 LR: 1.00e-05\n",
      "Epoch   0 [9700/10697 ( 90.7%)] Loss: 0.028324 L1: 0.017039 Grad: 0.112603 Thermal: 0.000480 LR: 1.00e-05\n",
      "Epoch   0 [9750/10697 ( 91.1%)] Loss: 0.028603 L1: 0.016546 Grad: 0.120302 Thermal: 0.000525 LR: 1.00e-05\n",
      "Epoch   0 [9750/10697 ( 91.1%)] Loss: 0.028603 L1: 0.016546 Grad: 0.120302 Thermal: 0.000525 LR: 1.00e-05\n",
      "Epoch   0 [9800/10697 ( 91.6%)] Loss: 0.026624 L1: 0.015567 Grad: 0.110363 Thermal: 0.000410 LR: 1.00e-05\n",
      "Epoch   0 [9800/10697 ( 91.6%)] Loss: 0.026624 L1: 0.015567 Grad: 0.110363 Thermal: 0.000410 LR: 1.00e-05\n",
      "Epoch   0 [9850/10697 ( 92.1%)] Loss: 0.026926 L1: 0.015649 Grad: 0.112532 Thermal: 0.000464 LR: 1.00e-05\n",
      "Epoch   0 [9850/10697 ( 92.1%)] Loss: 0.026926 L1: 0.015649 Grad: 0.112532 Thermal: 0.000464 LR: 1.00e-05\n",
      "Epoch   0 [9900/10697 ( 92.5%)] Loss: 0.027027 L1: 0.015537 Grad: 0.114673 Thermal: 0.000438 LR: 1.00e-05\n",
      "Epoch   0 [9900/10697 ( 92.5%)] Loss: 0.027027 L1: 0.015537 Grad: 0.114673 Thermal: 0.000438 LR: 1.00e-05\n",
      "Epoch   0 [9950/10697 ( 93.0%)] Loss: 0.021936 L1: 0.012845 Grad: 0.090753 Thermal: 0.000329 LR: 1.00e-05\n",
      "Epoch   0 [9950/10697 ( 93.0%)] Loss: 0.021936 L1: 0.012845 Grad: 0.090753 Thermal: 0.000329 LR: 1.00e-05\n",
      "Epoch   0 [10000/10697 ( 93.5%)] Loss: 0.037650 L1: 0.022550 Grad: 0.150534 Thermal: 0.000933 LR: 1.00e-05\n",
      "Epoch   0 [10000/10697 ( 93.5%)] Loss: 0.037650 L1: 0.022550 Grad: 0.150534 Thermal: 0.000933 LR: 1.00e-05\n",
      "Epoch   0 [10050/10697 ( 94.0%)] Loss: 0.029829 L1: 0.017052 Grad: 0.127497 Thermal: 0.000542 LR: 1.00e-05\n",
      "Epoch   0 [10050/10697 ( 94.0%)] Loss: 0.029829 L1: 0.017052 Grad: 0.127497 Thermal: 0.000542 LR: 1.00e-05\n",
      "Epoch   0 [10100/10697 ( 94.4%)] Loss: 0.029372 L1: 0.017685 Grad: 0.116599 Thermal: 0.000541 LR: 1.00e-05\n",
      "Epoch   0 [10100/10697 ( 94.4%)] Loss: 0.029372 L1: 0.017685 Grad: 0.116599 Thermal: 0.000541 LR: 1.00e-05\n",
      "Epoch   0 [10150/10697 ( 94.9%)] Loss: 0.029627 L1: 0.017457 Grad: 0.121434 Thermal: 0.000526 LR: 1.00e-05\n",
      "Epoch   0 [10150/10697 ( 94.9%)] Loss: 0.029627 L1: 0.017457 Grad: 0.121434 Thermal: 0.000526 LR: 1.00e-05\n",
      "Epoch   0 [10200/10697 ( 95.4%)] Loss: 0.028716 L1: 0.016841 Grad: 0.118503 Thermal: 0.000487 LR: 1.00e-05\n",
      "Epoch   0 [10200/10697 ( 95.4%)] Loss: 0.028716 L1: 0.016841 Grad: 0.118503 Thermal: 0.000487 LR: 1.00e-05\n",
      "Epoch   0 [10250/10697 ( 95.8%)] Loss: 0.028419 L1: 0.017057 Grad: 0.113391 Thermal: 0.000466 LR: 1.00e-05\n",
      "Epoch   0 [10250/10697 ( 95.8%)] Loss: 0.028419 L1: 0.017057 Grad: 0.113391 Thermal: 0.000466 LR: 1.00e-05\n",
      "Epoch   0 [10300/10697 ( 96.3%)] Loss: 0.040279 L1: 0.023292 Grad: 0.169378 Thermal: 0.000990 LR: 1.00e-05\n",
      "Epoch   0 [10300/10697 ( 96.3%)] Loss: 0.040279 L1: 0.023292 Grad: 0.169378 Thermal: 0.000990 LR: 1.00e-05\n",
      "Epoch   0 [10350/10697 ( 96.8%)] Loss: 0.028180 L1: 0.015986 Grad: 0.121739 Thermal: 0.000411 LR: 1.00e-05\n",
      "Epoch   0 [10350/10697 ( 96.8%)] Loss: 0.028180 L1: 0.015986 Grad: 0.121739 Thermal: 0.000411 LR: 1.00e-05\n",
      "Epoch   0 [10400/10697 ( 97.2%)] Loss: 0.031499 L1: 0.018391 Grad: 0.130806 Thermal: 0.000552 LR: 1.00e-05\n",
      "Epoch   0 [10400/10697 ( 97.2%)] Loss: 0.031499 L1: 0.018391 Grad: 0.130806 Thermal: 0.000552 LR: 1.00e-05\n",
      "Epoch   0 [10450/10697 ( 97.7%)] Loss: 0.024695 L1: 0.014567 Grad: 0.101102 Thermal: 0.000359 LR: 1.00e-05\n",
      "Epoch   0 [10450/10697 ( 97.7%)] Loss: 0.024695 L1: 0.014567 Grad: 0.101102 Thermal: 0.000359 LR: 1.00e-05\n",
      "Epoch   0 [10500/10697 ( 98.2%)] Loss: 0.029483 L1: 0.017094 Grad: 0.123650 Thermal: 0.000481 LR: 1.00e-05\n",
      "Epoch   0 [10500/10697 ( 98.2%)] Loss: 0.029483 L1: 0.017094 Grad: 0.123650 Thermal: 0.000481 LR: 1.00e-05\n",
      "Epoch   0 [10550/10697 ( 98.6%)] Loss: 0.032536 L1: 0.019124 Grad: 0.133797 Thermal: 0.000656 LR: 1.00e-05\n",
      "Epoch   0 [10550/10697 ( 98.6%)] Loss: 0.032536 L1: 0.019124 Grad: 0.133797 Thermal: 0.000656 LR: 1.00e-05\n",
      "Epoch   0 [10600/10697 ( 99.1%)] Loss: 0.033423 L1: 0.019272 Grad: 0.141218 Thermal: 0.000587 LR: 1.00e-05\n",
      "Epoch   0 [10600/10697 ( 99.1%)] Loss: 0.033423 L1: 0.019272 Grad: 0.141218 Thermal: 0.000587 LR: 1.00e-05\n",
      "Epoch   0 [10650/10697 ( 99.6%)] Loss: 0.025296 L1: 0.015012 Grad: 0.102624 Thermal: 0.000439 LR: 1.00e-05\n",
      "Epoch   0 [10650/10697 ( 99.6%)] Loss: 0.025296 L1: 0.015012 Grad: 0.102624 Thermal: 0.000439 LR: 1.00e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87215/2119361091.py:16: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí´ New best model saved! PSNR: 33.17\n",
      "Epoch   0 Summary: Loss=0.052123 (L1:0.0375, Grad:0.1454, Thermal:0.0006) Val_PSNR=33.17dB Best=33.17dB Time=3.7min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch   1 [   0/10697 (  0.0%)] Loss: 0.025870 L1: 0.015421 Grad: 0.104272 Thermal: 0.000437 LR: 1.00e-05\n",
      "Epoch   1 [   0/10697 (  0.0%)] Loss: 0.025870 L1: 0.015421 Grad: 0.104272 Thermal: 0.000437 LR: 1.00e-05\n",
      "Epoch   1 [  50/10697 (  0.5%)] Loss: 0.031579 L1: 0.018379 Grad: 0.131691 Thermal: 0.000620 LR: 1.00e-05\n",
      "Epoch   1 [  50/10697 (  0.5%)] Loss: 0.031579 L1: 0.018379 Grad: 0.131691 Thermal: 0.000620 LR: 1.00e-05\n",
      "Epoch   1 [ 100/10697 (  0.9%)] Loss: 0.026705 L1: 0.015846 Grad: 0.108375 Thermal: 0.000424 LR: 1.00e-05\n",
      "Epoch   1 [ 100/10697 (  0.9%)] Loss: 0.026705 L1: 0.015846 Grad: 0.108375 Thermal: 0.000424 LR: 1.00e-05\n",
      "Epoch   1 [ 150/10697 (  1.4%)] Loss: 0.028454 L1: 0.016538 Grad: 0.118875 Thermal: 0.000571 LR: 1.00e-05\n",
      "Epoch   1 [ 150/10697 (  1.4%)] Loss: 0.028454 L1: 0.016538 Grad: 0.118875 Thermal: 0.000571 LR: 1.00e-05\n",
      "Epoch   1 [ 200/10697 (  1.9%)] Loss: 0.030986 L1: 0.017823 Grad: 0.131348 Thermal: 0.000548 LR: 1.00e-05\n",
      "Epoch   1 [ 200/10697 (  1.9%)] Loss: 0.030986 L1: 0.017823 Grad: 0.131348 Thermal: 0.000548 LR: 1.00e-05\n",
      "Epoch   1 [ 250/10697 (  2.3%)] Loss: 0.027348 L1: 0.015153 Grad: 0.121729 Thermal: 0.000435 LR: 1.00e-05\n",
      "Epoch   1 [ 250/10697 (  2.3%)] Loss: 0.027348 L1: 0.015153 Grad: 0.121729 Thermal: 0.000435 LR: 1.00e-05\n",
      "Epoch   1 [ 300/10697 (  2.8%)] Loss: 0.030059 L1: 0.017120 Grad: 0.129143 Thermal: 0.000507 LR: 1.00e-05\n",
      "Epoch   1 [ 300/10697 (  2.8%)] Loss: 0.030059 L1: 0.017120 Grad: 0.129143 Thermal: 0.000507 LR: 1.00e-05\n",
      "Epoch   1 [ 350/10697 (  3.3%)] Loss: 0.025418 L1: 0.014746 Grad: 0.106524 Thermal: 0.000382 LR: 1.00e-05\n",
      "Epoch   1 [ 350/10697 (  3.3%)] Loss: 0.025418 L1: 0.014746 Grad: 0.106524 Thermal: 0.000382 LR: 1.00e-05\n",
      "Epoch   1 [ 400/10697 (  3.7%)] Loss: 0.027289 L1: 0.015715 Grad: 0.115524 Thermal: 0.000442 LR: 1.00e-05\n",
      "Epoch   1 [ 400/10697 (  3.7%)] Loss: 0.027289 L1: 0.015715 Grad: 0.115524 Thermal: 0.000442 LR: 1.00e-05\n",
      "Epoch   1 [ 450/10697 (  4.2%)] Loss: 0.028423 L1: 0.016364 Grad: 0.120306 Thermal: 0.000559 LR: 1.00e-05\n",
      "Epoch   1 [ 450/10697 (  4.2%)] Loss: 0.028423 L1: 0.016364 Grad: 0.120306 Thermal: 0.000559 LR: 1.00e-05\n",
      "Epoch   1 [ 500/10697 (  4.7%)] Loss: 0.030106 L1: 0.018013 Grad: 0.120648 Thermal: 0.000568 LR: 1.00e-05\n",
      "Epoch   1 [ 500/10697 (  4.7%)] Loss: 0.030106 L1: 0.018013 Grad: 0.120648 Thermal: 0.000568 LR: 1.00e-05\n",
      "Epoch   1 [ 550/10697 (  5.1%)] Loss: 0.030044 L1: 0.017227 Grad: 0.127908 Thermal: 0.000525 LR: 1.00e-05\n",
      "Epoch   1 [ 550/10697 (  5.1%)] Loss: 0.030044 L1: 0.017227 Grad: 0.127908 Thermal: 0.000525 LR: 1.00e-05\n",
      "Epoch   1 [ 600/10697 (  5.6%)] Loss: 0.033468 L1: 0.019547 Grad: 0.138862 Thermal: 0.000698 LR: 1.00e-05\n",
      "Epoch   1 [ 600/10697 (  5.6%)] Loss: 0.033468 L1: 0.019547 Grad: 0.138862 Thermal: 0.000698 LR: 1.00e-05\n",
      "Epoch   1 [ 650/10697 (  6.1%)] Loss: 0.029591 L1: 0.016946 Grad: 0.126192 Thermal: 0.000515 LR: 1.00e-05\n",
      "Epoch   1 [ 650/10697 (  6.1%)] Loss: 0.029591 L1: 0.016946 Grad: 0.126192 Thermal: 0.000515 LR: 1.00e-05\n",
      "Epoch   1 [ 700/10697 (  6.5%)] Loss: 0.028079 L1: 0.015653 Grad: 0.124013 Thermal: 0.000501 LR: 1.00e-05\n",
      "Epoch   1 [ 700/10697 (  6.5%)] Loss: 0.028079 L1: 0.015653 Grad: 0.124013 Thermal: 0.000501 LR: 1.00e-05\n",
      "Epoch   1 [ 750/10697 (  7.0%)] Loss: 0.030355 L1: 0.017689 Grad: 0.126385 Thermal: 0.000533 LR: 1.00e-05\n",
      "Epoch   1 [ 750/10697 (  7.0%)] Loss: 0.030355 L1: 0.017689 Grad: 0.126385 Thermal: 0.000533 LR: 1.00e-05\n",
      "Epoch   1 [ 800/10697 (  7.5%)] Loss: 0.032438 L1: 0.018608 Grad: 0.137984 Thermal: 0.000634 LR: 1.00e-05\n",
      "Epoch   1 [ 800/10697 (  7.5%)] Loss: 0.032438 L1: 0.018608 Grad: 0.137984 Thermal: 0.000634 LR: 1.00e-05\n",
      "Epoch   1 [ 850/10697 (  7.9%)] Loss: 0.027205 L1: 0.015624 Grad: 0.115576 Thermal: 0.000460 LR: 1.00e-05\n",
      "Epoch   1 [ 850/10697 (  7.9%)] Loss: 0.027205 L1: 0.015624 Grad: 0.115576 Thermal: 0.000460 LR: 1.00e-05\n",
      "Epoch   1 [ 900/10697 (  8.4%)] Loss: 0.024520 L1: 0.014047 Grad: 0.104557 Thermal: 0.000362 LR: 1.00e-05\n",
      "Epoch   1 [ 900/10697 (  8.4%)] Loss: 0.024520 L1: 0.014047 Grad: 0.104557 Thermal: 0.000362 LR: 1.00e-05\n",
      "Epoch   1 [ 950/10697 (  8.9%)] Loss: 0.038805 L1: 0.021966 Grad: 0.167936 Thermal: 0.000907 LR: 1.00e-05\n",
      "Epoch   1 [ 950/10697 (  8.9%)] Loss: 0.038805 L1: 0.021966 Grad: 0.167936 Thermal: 0.000907 LR: 1.00e-05\n",
      "Epoch   1 [1000/10697 (  9.3%)] Loss: 0.025975 L1: 0.014941 Grad: 0.110129 Thermal: 0.000408 LR: 1.00e-05\n",
      "Epoch   1 [1000/10697 (  9.3%)] Loss: 0.025975 L1: 0.014941 Grad: 0.110129 Thermal: 0.000408 LR: 1.00e-05\n",
      "Epoch   1 [1050/10697 (  9.8%)] Loss: 0.023120 L1: 0.013313 Grad: 0.097901 Thermal: 0.000333 LR: 1.00e-05\n",
      "Epoch   1 [1050/10697 (  9.8%)] Loss: 0.023120 L1: 0.013313 Grad: 0.097901 Thermal: 0.000333 LR: 1.00e-05\n",
      "Epoch   1 [1100/10697 ( 10.3%)] Loss: 0.030104 L1: 0.017343 Grad: 0.127370 Thermal: 0.000480 LR: 1.00e-05\n",
      "Epoch   1 [1100/10697 ( 10.3%)] Loss: 0.030104 L1: 0.017343 Grad: 0.127370 Thermal: 0.000480 LR: 1.00e-05\n",
      "Epoch   1 [1150/10697 ( 10.8%)] Loss: 0.023793 L1: 0.013828 Grad: 0.099476 Thermal: 0.000345 LR: 1.00e-05\n",
      "Epoch   1 [1150/10697 ( 10.8%)] Loss: 0.023793 L1: 0.013828 Grad: 0.099476 Thermal: 0.000345 LR: 1.00e-05\n",
      "Epoch   1 [1200/10697 ( 11.2%)] Loss: 0.032556 L1: 0.018699 Grad: 0.138288 Thermal: 0.000570 LR: 1.00e-05\n",
      "Epoch   1 [1200/10697 ( 11.2%)] Loss: 0.032556 L1: 0.018699 Grad: 0.138288 Thermal: 0.000570 LR: 1.00e-05\n",
      "Epoch   1 [1250/10697 ( 11.7%)] Loss: 0.036923 L1: 0.021289 Grad: 0.155942 Thermal: 0.000792 LR: 1.00e-05\n",
      "Epoch   1 [1250/10697 ( 11.7%)] Loss: 0.036923 L1: 0.021289 Grad: 0.155942 Thermal: 0.000792 LR: 1.00e-05\n",
      "Epoch   1 [1300/10697 ( 12.2%)] Loss: 0.036301 L1: 0.020921 Grad: 0.153420 Thermal: 0.000752 LR: 1.00e-05\n",
      "Epoch   1 [1300/10697 ( 12.2%)] Loss: 0.036301 L1: 0.020921 Grad: 0.153420 Thermal: 0.000752 LR: 1.00e-05\n",
      "Epoch   1 [1350/10697 ( 12.6%)] Loss: 0.031621 L1: 0.018425 Grad: 0.131663 Thermal: 0.000590 LR: 1.00e-05\n",
      "Epoch   1 [1350/10697 ( 12.6%)] Loss: 0.031621 L1: 0.018425 Grad: 0.131663 Thermal: 0.000590 LR: 1.00e-05\n",
      "Epoch   1 [1400/10697 ( 13.1%)] Loss: 0.027729 L1: 0.015980 Grad: 0.117267 Thermal: 0.000443 LR: 1.00e-05\n",
      "Epoch   1 [1400/10697 ( 13.1%)] Loss: 0.027729 L1: 0.015980 Grad: 0.117267 Thermal: 0.000443 LR: 1.00e-05\n",
      "Epoch   1 [1450/10697 ( 13.6%)] Loss: 0.028394 L1: 0.016592 Grad: 0.117769 Thermal: 0.000504 LR: 1.00e-05\n",
      "Epoch   1 [1450/10697 ( 13.6%)] Loss: 0.028394 L1: 0.016592 Grad: 0.117769 Thermal: 0.000504 LR: 1.00e-05\n",
      "Epoch   1 [1500/10697 ( 14.0%)] Loss: 0.032894 L1: 0.019146 Grad: 0.137123 Thermal: 0.000704 LR: 1.00e-05\n",
      "Epoch   1 [1500/10697 ( 14.0%)] Loss: 0.032894 L1: 0.019146 Grad: 0.137123 Thermal: 0.000704 LR: 1.00e-05\n",
      "Epoch   1 [1550/10697 ( 14.5%)] Loss: 0.029751 L1: 0.017437 Grad: 0.122889 Thermal: 0.000511 LR: 1.00e-05\n",
      "Epoch   1 [1550/10697 ( 14.5%)] Loss: 0.029751 L1: 0.017437 Grad: 0.122889 Thermal: 0.000511 LR: 1.00e-05\n",
      "Epoch   1 [1600/10697 ( 15.0%)] Loss: 0.028629 L1: 0.016261 Grad: 0.123415 Thermal: 0.000521 LR: 1.00e-05\n",
      "Epoch   1 [1600/10697 ( 15.0%)] Loss: 0.028629 L1: 0.016261 Grad: 0.123415 Thermal: 0.000521 LR: 1.00e-05\n",
      "Epoch   1 [1650/10697 ( 15.4%)] Loss: 0.028974 L1: 0.016828 Grad: 0.121218 Thermal: 0.000483 LR: 1.00e-05\n",
      "Epoch   1 [1650/10697 ( 15.4%)] Loss: 0.028974 L1: 0.016828 Grad: 0.121218 Thermal: 0.000483 LR: 1.00e-05\n",
      "Epoch   1 [1700/10697 ( 15.9%)] Loss: 0.028629 L1: 0.016320 Grad: 0.122826 Thermal: 0.000536 LR: 1.00e-05\n",
      "Epoch   1 [1700/10697 ( 15.9%)] Loss: 0.028629 L1: 0.016320 Grad: 0.122826 Thermal: 0.000536 LR: 1.00e-05\n",
      "Epoch   1 [1750/10697 ( 16.4%)] Loss: 0.027910 L1: 0.016480 Grad: 0.114063 Thermal: 0.000482 LR: 1.00e-05\n",
      "Epoch   1 [1750/10697 ( 16.4%)] Loss: 0.027910 L1: 0.016480 Grad: 0.114063 Thermal: 0.000482 LR: 1.00e-05\n",
      "Epoch   1 [1800/10697 ( 16.8%)] Loss: 0.038213 L1: 0.021503 Grad: 0.166626 Thermal: 0.000945 LR: 1.00e-05\n",
      "Epoch   1 [1800/10697 ( 16.8%)] Loss: 0.038213 L1: 0.021503 Grad: 0.166626 Thermal: 0.000945 LR: 1.00e-05\n",
      "Epoch   1 [1850/10697 ( 17.3%)] Loss: 0.027432 L1: 0.016141 Grad: 0.112672 Thermal: 0.000467 LR: 1.00e-05\n",
      "Epoch   1 [1850/10697 ( 17.3%)] Loss: 0.027432 L1: 0.016141 Grad: 0.112672 Thermal: 0.000467 LR: 1.00e-05\n",
      "Epoch   1 [1900/10697 ( 17.8%)] Loss: 0.027273 L1: 0.015285 Grad: 0.119666 Thermal: 0.000424 LR: 1.00e-05\n",
      "Epoch   1 [1900/10697 ( 17.8%)] Loss: 0.027273 L1: 0.015285 Grad: 0.119666 Thermal: 0.000424 LR: 1.00e-05\n",
      "Epoch   1 [1950/10697 ( 18.2%)] Loss: 0.029570 L1: 0.017033 Grad: 0.125113 Thermal: 0.000506 LR: 1.00e-05\n",
      "Epoch   1 [1950/10697 ( 18.2%)] Loss: 0.029570 L1: 0.017033 Grad: 0.125113 Thermal: 0.000506 LR: 1.00e-05\n",
      "Epoch   1 [2000/10697 ( 18.7%)] Loss: 0.027157 L1: 0.015605 Grad: 0.115272 Thermal: 0.000488 LR: 1.00e-05\n",
      "Epoch   1 [2000/10697 ( 18.7%)] Loss: 0.027157 L1: 0.015605 Grad: 0.115272 Thermal: 0.000488 LR: 1.00e-05\n",
      "Epoch   1 [2050/10697 ( 19.2%)] Loss: 0.027856 L1: 0.016385 Grad: 0.114482 Thermal: 0.000465 LR: 1.00e-05\n",
      "Epoch   1 [2050/10697 ( 19.2%)] Loss: 0.027856 L1: 0.016385 Grad: 0.114482 Thermal: 0.000465 LR: 1.00e-05\n",
      "Epoch   1 [2100/10697 ( 19.6%)] Loss: 0.022503 L1: 0.012511 Grad: 0.099753 Thermal: 0.000331 LR: 1.00e-05\n",
      "Epoch   1 [2100/10697 ( 19.6%)] Loss: 0.022503 L1: 0.012511 Grad: 0.099753 Thermal: 0.000331 LR: 1.00e-05\n",
      "Epoch   1 [2150/10697 ( 20.1%)] Loss: 0.025303 L1: 0.014388 Grad: 0.108965 Thermal: 0.000373 LR: 1.00e-05\n",
      "Epoch   1 [2150/10697 ( 20.1%)] Loss: 0.025303 L1: 0.014388 Grad: 0.108965 Thermal: 0.000373 LR: 1.00e-05\n",
      "Epoch   1 [2200/10697 ( 20.6%)] Loss: 0.030976 L1: 0.018649 Grad: 0.122977 Thermal: 0.000586 LR: 1.00e-05\n",
      "Epoch   1 [2200/10697 ( 20.6%)] Loss: 0.030976 L1: 0.018649 Grad: 0.122977 Thermal: 0.000586 LR: 1.00e-05\n",
      "Epoch   1 [2250/10697 ( 21.0%)] Loss: 0.024323 L1: 0.014300 Grad: 0.100044 Thermal: 0.000376 LR: 1.00e-05\n",
      "Epoch   1 [2250/10697 ( 21.0%)] Loss: 0.024323 L1: 0.014300 Grad: 0.100044 Thermal: 0.000376 LR: 1.00e-05\n",
      "Epoch   1 [2300/10697 ( 21.5%)] Loss: 0.029898 L1: 0.017355 Grad: 0.125184 Thermal: 0.000490 LR: 1.00e-05\n",
      "Epoch   1 [2300/10697 ( 21.5%)] Loss: 0.029898 L1: 0.017355 Grad: 0.125184 Thermal: 0.000490 LR: 1.00e-05\n",
      "Epoch   1 [2350/10697 ( 22.0%)] Loss: 0.033971 L1: 0.019727 Grad: 0.142098 Thermal: 0.000689 LR: 1.00e-05\n",
      "Epoch   1 [2350/10697 ( 22.0%)] Loss: 0.033971 L1: 0.019727 Grad: 0.142098 Thermal: 0.000689 LR: 1.00e-05\n",
      "Epoch   1 [2400/10697 ( 22.4%)] Loss: 0.023212 L1: 0.013791 Grad: 0.094006 Thermal: 0.000395 LR: 1.00e-05\n",
      "Epoch   1 [2400/10697 ( 22.4%)] Loss: 0.023212 L1: 0.013791 Grad: 0.094006 Thermal: 0.000395 LR: 1.00e-05\n",
      "Epoch   1 [2450/10697 ( 22.9%)] Loss: 0.024006 L1: 0.014250 Grad: 0.097381 Thermal: 0.000374 LR: 1.00e-05\n",
      "Epoch   1 [2450/10697 ( 22.9%)] Loss: 0.024006 L1: 0.014250 Grad: 0.097381 Thermal: 0.000374 LR: 1.00e-05\n",
      "Epoch   1 [2500/10697 ( 23.4%)] Loss: 0.031012 L1: 0.018155 Grad: 0.128279 Thermal: 0.000581 LR: 1.00e-05\n",
      "Epoch   1 [2500/10697 ( 23.4%)] Loss: 0.031012 L1: 0.018155 Grad: 0.128279 Thermal: 0.000581 LR: 1.00e-05\n",
      "Epoch   1 [2550/10697 ( 23.8%)] Loss: 0.027817 L1: 0.015858 Grad: 0.119357 Thermal: 0.000461 LR: 1.00e-05\n",
      "Epoch   1 [2550/10697 ( 23.8%)] Loss: 0.027817 L1: 0.015858 Grad: 0.119357 Thermal: 0.000461 LR: 1.00e-05\n",
      "Epoch   1 [2600/10697 ( 24.3%)] Loss: 0.027366 L1: 0.016514 Grad: 0.108262 Thermal: 0.000511 LR: 1.00e-05\n",
      "Epoch   1 [2600/10697 ( 24.3%)] Loss: 0.027366 L1: 0.016514 Grad: 0.108262 Thermal: 0.000511 LR: 1.00e-05\n",
      "Epoch   1 [2650/10697 ( 24.8%)] Loss: 0.030020 L1: 0.017304 Grad: 0.126900 Thermal: 0.000505 LR: 1.00e-05\n",
      "Epoch   1 [2650/10697 ( 24.8%)] Loss: 0.030020 L1: 0.017304 Grad: 0.126900 Thermal: 0.000505 LR: 1.00e-05\n",
      "Epoch   1 [2700/10697 ( 25.2%)] Loss: 0.033019 L1: 0.018716 Grad: 0.142716 Thermal: 0.000623 LR: 1.00e-05\n",
      "Epoch   1 [2700/10697 ( 25.2%)] Loss: 0.033019 L1: 0.018716 Grad: 0.142716 Thermal: 0.000623 LR: 1.00e-05\n",
      "Epoch   1 [2750/10697 ( 25.7%)] Loss: 0.031439 L1: 0.018320 Grad: 0.130887 Thermal: 0.000594 LR: 1.00e-05\n",
      "Epoch   1 [2750/10697 ( 25.7%)] Loss: 0.031439 L1: 0.018320 Grad: 0.130887 Thermal: 0.000594 LR: 1.00e-05\n",
      "Epoch   1 [2800/10697 ( 26.2%)] Loss: 0.025469 L1: 0.014644 Grad: 0.108040 Thermal: 0.000418 LR: 1.00e-05\n",
      "Epoch   1 [2800/10697 ( 26.2%)] Loss: 0.025469 L1: 0.014644 Grad: 0.108040 Thermal: 0.000418 LR: 1.00e-05\n",
      "Epoch   1 [2850/10697 ( 26.6%)] Loss: 0.030029 L1: 0.017299 Grad: 0.127010 Thermal: 0.000578 LR: 1.00e-05\n",
      "Epoch   1 [2850/10697 ( 26.6%)] Loss: 0.030029 L1: 0.017299 Grad: 0.127010 Thermal: 0.000578 LR: 1.00e-05\n",
      "Epoch   1 [2900/10697 ( 27.1%)] Loss: 0.036310 L1: 0.020482 Grad: 0.157919 Thermal: 0.000733 LR: 1.00e-05\n",
      "Epoch   1 [2900/10697 ( 27.1%)] Loss: 0.036310 L1: 0.020482 Grad: 0.157919 Thermal: 0.000733 LR: 1.00e-05\n",
      "Epoch   1 [2950/10697 ( 27.6%)] Loss: 0.029600 L1: 0.017622 Grad: 0.119484 Thermal: 0.000578 LR: 1.00e-05\n",
      "Epoch   1 [2950/10697 ( 27.6%)] Loss: 0.029600 L1: 0.017622 Grad: 0.119484 Thermal: 0.000578 LR: 1.00e-05\n",
      "Epoch   1 [3000/10697 ( 28.0%)] Loss: 0.020462 L1: 0.011682 Grad: 0.087656 Thermal: 0.000279 LR: 1.00e-05\n",
      "Epoch   1 [3000/10697 ( 28.0%)] Loss: 0.020462 L1: 0.011682 Grad: 0.087656 Thermal: 0.000279 LR: 1.00e-05\n",
      "Epoch   1 [3050/10697 ( 28.5%)] Loss: 0.026447 L1: 0.015367 Grad: 0.110570 Thermal: 0.000458 LR: 1.00e-05\n",
      "Epoch   1 [3050/10697 ( 28.5%)] Loss: 0.026447 L1: 0.015367 Grad: 0.110570 Thermal: 0.000458 LR: 1.00e-05\n",
      "Epoch   1 [3100/10697 ( 29.0%)] Loss: 0.027989 L1: 0.016165 Grad: 0.118013 Thermal: 0.000458 LR: 1.00e-05\n",
      "Epoch   1 [3100/10697 ( 29.0%)] Loss: 0.027989 L1: 0.016165 Grad: 0.118013 Thermal: 0.000458 LR: 1.00e-05\n",
      "Epoch   1 [3150/10697 ( 29.4%)] Loss: 0.027579 L1: 0.016373 Grad: 0.111825 Thermal: 0.000465 LR: 1.00e-05\n",
      "Epoch   1 [3150/10697 ( 29.4%)] Loss: 0.027579 L1: 0.016373 Grad: 0.111825 Thermal: 0.000465 LR: 1.00e-05\n",
      "Epoch   1 [3200/10697 ( 29.9%)] Loss: 0.021983 L1: 0.012708 Grad: 0.092588 Thermal: 0.000329 LR: 1.00e-05\n",
      "Epoch   1 [3200/10697 ( 29.9%)] Loss: 0.021983 L1: 0.012708 Grad: 0.092588 Thermal: 0.000329 LR: 1.00e-05\n",
      "Epoch   1 [3250/10697 ( 30.4%)] Loss: 0.031976 L1: 0.018986 Grad: 0.129619 Thermal: 0.000579 LR: 1.00e-05\n",
      "Epoch   1 [3250/10697 ( 30.4%)] Loss: 0.031976 L1: 0.018986 Grad: 0.129619 Thermal: 0.000579 LR: 1.00e-05\n",
      "Epoch   1 [3300/10697 ( 30.8%)] Loss: 0.022952 L1: 0.013176 Grad: 0.097600 Thermal: 0.000310 LR: 1.00e-05\n",
      "Epoch   1 [3300/10697 ( 30.8%)] Loss: 0.022952 L1: 0.013176 Grad: 0.097600 Thermal: 0.000310 LR: 1.00e-05\n",
      "Epoch   1 [3350/10697 ( 31.3%)] Loss: 0.027626 L1: 0.015607 Grad: 0.119973 Thermal: 0.000421 LR: 1.00e-05\n",
      "Epoch   1 [3350/10697 ( 31.3%)] Loss: 0.027626 L1: 0.015607 Grad: 0.119973 Thermal: 0.000421 LR: 1.00e-05\n",
      "Epoch   1 [3400/10697 ( 31.8%)] Loss: 0.024831 L1: 0.014577 Grad: 0.102342 Thermal: 0.000392 LR: 1.00e-05\n",
      "Epoch   1 [3400/10697 ( 31.8%)] Loss: 0.024831 L1: 0.014577 Grad: 0.102342 Thermal: 0.000392 LR: 1.00e-05\n",
      "Epoch   1 [3450/10697 ( 32.3%)] Loss: 0.028858 L1: 0.016973 Grad: 0.118606 Thermal: 0.000487 LR: 1.00e-05\n",
      "Epoch   1 [3450/10697 ( 32.3%)] Loss: 0.028858 L1: 0.016973 Grad: 0.118606 Thermal: 0.000487 LR: 1.00e-05\n",
      "Epoch   1 [3500/10697 ( 32.7%)] Loss: 0.030251 L1: 0.017361 Grad: 0.128620 Thermal: 0.000560 LR: 1.00e-05\n",
      "Epoch   1 [3500/10697 ( 32.7%)] Loss: 0.030251 L1: 0.017361 Grad: 0.128620 Thermal: 0.000560 LR: 1.00e-05\n",
      "Epoch   1 [3550/10697 ( 33.2%)] Loss: 0.029007 L1: 0.016912 Grad: 0.120690 Thermal: 0.000514 LR: 1.00e-05\n",
      "Epoch   1 [3550/10697 ( 33.2%)] Loss: 0.029007 L1: 0.016912 Grad: 0.120690 Thermal: 0.000514 LR: 1.00e-05\n",
      "Epoch   1 [3600/10697 ( 33.7%)] Loss: 0.016802 L1: 0.009438 Grad: 0.073552 Thermal: 0.000172 LR: 1.00e-05\n",
      "Epoch   1 [3600/10697 ( 33.7%)] Loss: 0.016802 L1: 0.009438 Grad: 0.073552 Thermal: 0.000172 LR: 1.00e-05\n",
      "Epoch   1 [3650/10697 ( 34.1%)] Loss: 0.027577 L1: 0.016253 Grad: 0.112995 Thermal: 0.000475 LR: 1.00e-05\n",
      "Epoch   1 [3650/10697 ( 34.1%)] Loss: 0.027577 L1: 0.016253 Grad: 0.112995 Thermal: 0.000475 LR: 1.00e-05\n",
      "Epoch   1 [3700/10697 ( 34.6%)] Loss: 0.031166 L1: 0.018719 Grad: 0.124170 Thermal: 0.000615 LR: 1.00e-05\n",
      "Epoch   1 [3700/10697 ( 34.6%)] Loss: 0.031166 L1: 0.018719 Grad: 0.124170 Thermal: 0.000615 LR: 1.00e-05\n",
      "Epoch   1 [3750/10697 ( 35.1%)] Loss: 0.030017 L1: 0.016935 Grad: 0.130551 Thermal: 0.000538 LR: 1.00e-05\n",
      "Epoch   1 [3750/10697 ( 35.1%)] Loss: 0.030017 L1: 0.016935 Grad: 0.130551 Thermal: 0.000538 LR: 1.00e-05\n",
      "Epoch   1 [3800/10697 ( 35.5%)] Loss: 0.037935 L1: 0.021653 Grad: 0.162387 Thermal: 0.000872 LR: 1.00e-05\n",
      "Epoch   1 [3800/10697 ( 35.5%)] Loss: 0.037935 L1: 0.021653 Grad: 0.162387 Thermal: 0.000872 LR: 1.00e-05\n",
      "Epoch   1 [3850/10697 ( 36.0%)] Loss: 0.029608 L1: 0.017416 Grad: 0.121651 Thermal: 0.000532 LR: 1.00e-05\n",
      "Epoch   1 [3850/10697 ( 36.0%)] Loss: 0.029608 L1: 0.017416 Grad: 0.121651 Thermal: 0.000532 LR: 1.00e-05\n",
      "Epoch   1 [3900/10697 ( 36.5%)] Loss: 0.025981 L1: 0.014483 Grad: 0.114779 Thermal: 0.000405 LR: 1.00e-05\n",
      "Epoch   1 [3900/10697 ( 36.5%)] Loss: 0.025981 L1: 0.014483 Grad: 0.114779 Thermal: 0.000405 LR: 1.00e-05\n",
      "Epoch   1 [3950/10697 ( 36.9%)] Loss: 0.020644 L1: 0.011399 Grad: 0.092323 Thermal: 0.000255 LR: 1.00e-05\n",
      "Epoch   1 [3950/10697 ( 36.9%)] Loss: 0.020644 L1: 0.011399 Grad: 0.092323 Thermal: 0.000255 LR: 1.00e-05\n",
      "Epoch   1 [4000/10697 ( 37.4%)] Loss: 0.028826 L1: 0.017064 Grad: 0.117358 Thermal: 0.000526 LR: 1.00e-05\n",
      "Epoch   1 [4000/10697 ( 37.4%)] Loss: 0.028826 L1: 0.017064 Grad: 0.117358 Thermal: 0.000526 LR: 1.00e-05\n",
      "Epoch   1 [4050/10697 ( 37.9%)] Loss: 0.021079 L1: 0.012295 Grad: 0.087664 Thermal: 0.000348 LR: 1.00e-05\n",
      "Epoch   1 [4050/10697 ( 37.9%)] Loss: 0.021079 L1: 0.012295 Grad: 0.087664 Thermal: 0.000348 LR: 1.00e-05\n",
      "Epoch   1 [4100/10697 ( 38.3%)] Loss: 0.032355 L1: 0.018829 Grad: 0.134934 Thermal: 0.000649 LR: 1.00e-05\n",
      "Epoch   1 [4100/10697 ( 38.3%)] Loss: 0.032355 L1: 0.018829 Grad: 0.134934 Thermal: 0.000649 LR: 1.00e-05\n",
      "Epoch   1 [4150/10697 ( 38.8%)] Loss: 0.028589 L1: 0.016900 Grad: 0.116628 Thermal: 0.000515 LR: 1.00e-05\n",
      "Epoch   1 [4150/10697 ( 38.8%)] Loss: 0.028589 L1: 0.016900 Grad: 0.116628 Thermal: 0.000515 LR: 1.00e-05\n",
      "Epoch   1 [4200/10697 ( 39.3%)] Loss: 0.027164 L1: 0.015575 Grad: 0.115666 Thermal: 0.000444 LR: 1.00e-05\n",
      "Epoch   1 [4200/10697 ( 39.3%)] Loss: 0.027164 L1: 0.015575 Grad: 0.115666 Thermal: 0.000444 LR: 1.00e-05\n",
      "Epoch   1 [4250/10697 ( 39.7%)] Loss: 0.022972 L1: 0.013644 Grad: 0.093090 Thermal: 0.000378 LR: 1.00e-05\n",
      "Epoch   1 [4250/10697 ( 39.7%)] Loss: 0.022972 L1: 0.013644 Grad: 0.093090 Thermal: 0.000378 LR: 1.00e-05\n",
      "Epoch   1 [4300/10697 ( 40.2%)] Loss: 0.024889 L1: 0.014440 Grad: 0.104312 Thermal: 0.000362 LR: 1.00e-05\n",
      "Epoch   1 [4300/10697 ( 40.2%)] Loss: 0.024889 L1: 0.014440 Grad: 0.104312 Thermal: 0.000362 LR: 1.00e-05\n",
      "Epoch   1 [4350/10697 ( 40.7%)] Loss: 0.025728 L1: 0.015026 Grad: 0.106811 Thermal: 0.000412 LR: 1.00e-05\n",
      "Epoch   1 [4350/10697 ( 40.7%)] Loss: 0.025728 L1: 0.015026 Grad: 0.106811 Thermal: 0.000412 LR: 1.00e-05\n",
      "Epoch   1 [4400/10697 ( 41.1%)] Loss: 0.022214 L1: 0.012552 Grad: 0.096442 Thermal: 0.000349 LR: 1.00e-05\n",
      "Epoch   1 [4400/10697 ( 41.1%)] Loss: 0.022214 L1: 0.012552 Grad: 0.096442 Thermal: 0.000349 LR: 1.00e-05\n",
      "Epoch   1 [4450/10697 ( 41.6%)] Loss: 0.029664 L1: 0.017185 Grad: 0.124530 Thermal: 0.000515 LR: 1.00e-05\n",
      "Epoch   1 [4450/10697 ( 41.6%)] Loss: 0.029664 L1: 0.017185 Grad: 0.124530 Thermal: 0.000515 LR: 1.00e-05\n",
      "Epoch   1 [4500/10697 ( 42.1%)] Loss: 0.030443 L1: 0.017161 Grad: 0.132541 Thermal: 0.000569 LR: 1.00e-05\n",
      "Epoch   1 [4500/10697 ( 42.1%)] Loss: 0.030443 L1: 0.017161 Grad: 0.132541 Thermal: 0.000569 LR: 1.00e-05\n",
      "Epoch   1 [4550/10697 ( 42.5%)] Loss: 0.028828 L1: 0.016414 Grad: 0.123914 Thermal: 0.000442 LR: 1.00e-05\n",
      "Epoch   1 [4550/10697 ( 42.5%)] Loss: 0.028828 L1: 0.016414 Grad: 0.123914 Thermal: 0.000442 LR: 1.00e-05\n",
      "Epoch   1 [4600/10697 ( 43.0%)] Loss: 0.025138 L1: 0.014468 Grad: 0.106504 Thermal: 0.000391 LR: 1.00e-05\n",
      "Epoch   1 [4600/10697 ( 43.0%)] Loss: 0.025138 L1: 0.014468 Grad: 0.106504 Thermal: 0.000391 LR: 1.00e-05\n",
      "Epoch   1 [4650/10697 ( 43.5%)] Loss: 0.026308 L1: 0.015452 Grad: 0.108339 Thermal: 0.000429 LR: 1.00e-05\n",
      "Epoch   1 [4650/10697 ( 43.5%)] Loss: 0.026308 L1: 0.015452 Grad: 0.108339 Thermal: 0.000429 LR: 1.00e-05\n",
      "Epoch   1 [4700/10697 ( 43.9%)] Loss: 0.024636 L1: 0.014379 Grad: 0.102369 Thermal: 0.000422 LR: 1.00e-05\n",
      "Epoch   1 [4700/10697 ( 43.9%)] Loss: 0.024636 L1: 0.014379 Grad: 0.102369 Thermal: 0.000422 LR: 1.00e-05\n",
      "Epoch   1 [4750/10697 ( 44.4%)] Loss: 0.025626 L1: 0.014981 Grad: 0.106253 Thermal: 0.000399 LR: 1.00e-05\n",
      "Epoch   1 [4750/10697 ( 44.4%)] Loss: 0.025626 L1: 0.014981 Grad: 0.106253 Thermal: 0.000399 LR: 1.00e-05\n",
      "Epoch   1 [4800/10697 ( 44.9%)] Loss: 0.028905 L1: 0.016623 Grad: 0.122573 Thermal: 0.000479 LR: 1.00e-05\n",
      "Epoch   1 [4800/10697 ( 44.9%)] Loss: 0.028905 L1: 0.016623 Grad: 0.122573 Thermal: 0.000479 LR: 1.00e-05\n",
      "Epoch   1 [4850/10697 ( 45.3%)] Loss: 0.031531 L1: 0.018024 Grad: 0.134783 Thermal: 0.000578 LR: 1.00e-05\n",
      "Epoch   1 [4850/10697 ( 45.3%)] Loss: 0.031531 L1: 0.018024 Grad: 0.134783 Thermal: 0.000578 LR: 1.00e-05\n",
      "Epoch   1 [4900/10697 ( 45.8%)] Loss: 0.028603 L1: 0.016278 Grad: 0.122978 Thermal: 0.000527 LR: 1.00e-05\n",
      "Epoch   1 [4900/10697 ( 45.8%)] Loss: 0.028603 L1: 0.016278 Grad: 0.122978 Thermal: 0.000527 LR: 1.00e-05\n",
      "Epoch   1 [4950/10697 ( 46.3%)] Loss: 0.027895 L1: 0.016597 Grad: 0.112718 Thermal: 0.000506 LR: 1.00e-05\n",
      "Epoch   1 [4950/10697 ( 46.3%)] Loss: 0.027895 L1: 0.016597 Grad: 0.112718 Thermal: 0.000506 LR: 1.00e-05\n",
      "Epoch   1 [5000/10697 ( 46.7%)] Loss: 0.032451 L1: 0.018821 Grad: 0.136007 Thermal: 0.000598 LR: 1.00e-05\n",
      "Epoch   1 [5000/10697 ( 46.7%)] Loss: 0.032451 L1: 0.018821 Grad: 0.136007 Thermal: 0.000598 LR: 1.00e-05\n",
      "Epoch   1 [5050/10697 ( 47.2%)] Loss: 0.025637 L1: 0.015152 Grad: 0.104628 Thermal: 0.000442 LR: 1.00e-05\n",
      "Epoch   1 [5050/10697 ( 47.2%)] Loss: 0.025637 L1: 0.015152 Grad: 0.104628 Thermal: 0.000442 LR: 1.00e-05\n",
      "Epoch   1 [5100/10697 ( 47.7%)] Loss: 0.030519 L1: 0.017458 Grad: 0.130326 Thermal: 0.000555 LR: 1.00e-05\n",
      "Epoch   1 [5100/10697 ( 47.7%)] Loss: 0.030519 L1: 0.017458 Grad: 0.130326 Thermal: 0.000555 LR: 1.00e-05\n",
      "Epoch   1 [5150/10697 ( 48.1%)] Loss: 0.035092 L1: 0.020044 Grad: 0.150096 Thermal: 0.000764 LR: 1.00e-05\n",
      "Epoch   1 [5150/10697 ( 48.1%)] Loss: 0.035092 L1: 0.020044 Grad: 0.150096 Thermal: 0.000764 LR: 1.00e-05\n",
      "Epoch   1 [5200/10697 ( 48.6%)] Loss: 0.027430 L1: 0.016097 Grad: 0.113095 Thermal: 0.000461 LR: 1.00e-05\n",
      "Epoch   1 [5200/10697 ( 48.6%)] Loss: 0.027430 L1: 0.016097 Grad: 0.113095 Thermal: 0.000461 LR: 1.00e-05\n",
      "Epoch   1 [5250/10697 ( 49.1%)] Loss: 0.028584 L1: 0.016430 Grad: 0.121300 Thermal: 0.000479 LR: 1.00e-05\n",
      "Epoch   1 [5250/10697 ( 49.1%)] Loss: 0.028584 L1: 0.016430 Grad: 0.121300 Thermal: 0.000479 LR: 1.00e-05\n",
      "Epoch   1 [5300/10697 ( 49.5%)] Loss: 0.026799 L1: 0.015443 Grad: 0.113329 Thermal: 0.000455 LR: 1.00e-05\n",
      "Epoch   1 [5300/10697 ( 49.5%)] Loss: 0.026799 L1: 0.015443 Grad: 0.113329 Thermal: 0.000455 LR: 1.00e-05\n",
      "Epoch   1 [5350/10697 ( 50.0%)] Loss: 0.027345 L1: 0.015842 Grad: 0.114804 Thermal: 0.000462 LR: 1.00e-05\n",
      "Epoch   1 [5350/10697 ( 50.0%)] Loss: 0.027345 L1: 0.015842 Grad: 0.114804 Thermal: 0.000462 LR: 1.00e-05\n",
      "Epoch   1 [5400/10697 ( 50.5%)] Loss: 0.023646 L1: 0.013851 Grad: 0.097768 Thermal: 0.000361 LR: 1.00e-05\n",
      "Epoch   1 [5400/10697 ( 50.5%)] Loss: 0.023646 L1: 0.013851 Grad: 0.097768 Thermal: 0.000361 LR: 1.00e-05\n",
      "Epoch   1 [5450/10697 ( 50.9%)] Loss: 0.031393 L1: 0.018020 Grad: 0.133424 Thermal: 0.000628 LR: 1.00e-05\n",
      "Epoch   1 [5450/10697 ( 50.9%)] Loss: 0.031393 L1: 0.018020 Grad: 0.133424 Thermal: 0.000628 LR: 1.00e-05\n",
      "Epoch   1 [5500/10697 ( 51.4%)] Loss: 0.026275 L1: 0.015749 Grad: 0.105043 Thermal: 0.000441 LR: 1.00e-05\n",
      "Epoch   1 [5500/10697 ( 51.4%)] Loss: 0.026275 L1: 0.015749 Grad: 0.105043 Thermal: 0.000441 LR: 1.00e-05\n",
      "Epoch   1 [5550/10697 ( 51.9%)] Loss: 0.030436 L1: 0.017561 Grad: 0.128471 Thermal: 0.000554 LR: 1.00e-05\n",
      "Epoch   1 [5550/10697 ( 51.9%)] Loss: 0.030436 L1: 0.017561 Grad: 0.128471 Thermal: 0.000554 LR: 1.00e-05\n",
      "Epoch   1 [5600/10697 ( 52.4%)] Loss: 0.026187 L1: 0.015123 Grad: 0.110399 Thermal: 0.000487 LR: 1.00e-05\n",
      "Epoch   1 [5600/10697 ( 52.4%)] Loss: 0.026187 L1: 0.015123 Grad: 0.110399 Thermal: 0.000487 LR: 1.00e-05\n",
      "Epoch   1 [5650/10697 ( 52.8%)] Loss: 0.021661 L1: 0.012915 Grad: 0.087290 Thermal: 0.000344 LR: 1.00e-05\n",
      "Epoch   1 [5650/10697 ( 52.8%)] Loss: 0.021661 L1: 0.012915 Grad: 0.087290 Thermal: 0.000344 LR: 1.00e-05\n",
      "Epoch   1 [5700/10697 ( 53.3%)] Loss: 0.024539 L1: 0.014262 Grad: 0.102579 Thermal: 0.000379 LR: 1.00e-05\n",
      "Epoch   1 [5700/10697 ( 53.3%)] Loss: 0.024539 L1: 0.014262 Grad: 0.102579 Thermal: 0.000379 LR: 1.00e-05\n",
      "Epoch   1 [5750/10697 ( 53.8%)] Loss: 0.026474 L1: 0.015732 Grad: 0.107180 Thermal: 0.000476 LR: 1.00e-05\n",
      "Epoch   1 [5750/10697 ( 53.8%)] Loss: 0.026474 L1: 0.015732 Grad: 0.107180 Thermal: 0.000476 LR: 1.00e-05\n",
      "Epoch   1 [5800/10697 ( 54.2%)] Loss: 0.028851 L1: 0.016528 Grad: 0.122980 Thermal: 0.000500 LR: 1.00e-05\n",
      "Epoch   1 [5800/10697 ( 54.2%)] Loss: 0.028851 L1: 0.016528 Grad: 0.122980 Thermal: 0.000500 LR: 1.00e-05\n",
      "Epoch   1 [5850/10697 ( 54.7%)] Loss: 0.031281 L1: 0.017983 Grad: 0.132692 Thermal: 0.000563 LR: 1.00e-05\n",
      "Epoch   1 [5850/10697 ( 54.7%)] Loss: 0.031281 L1: 0.017983 Grad: 0.132692 Thermal: 0.000563 LR: 1.00e-05\n",
      "Epoch   1 [5900/10697 ( 55.2%)] Loss: 0.035249 L1: 0.019863 Grad: 0.153487 Thermal: 0.000743 LR: 1.00e-05\n",
      "Epoch   1 [5900/10697 ( 55.2%)] Loss: 0.035249 L1: 0.019863 Grad: 0.153487 Thermal: 0.000743 LR: 1.00e-05\n",
      "Epoch   1 [5950/10697 ( 55.6%)] Loss: 0.033443 L1: 0.019401 Grad: 0.140091 Thermal: 0.000653 LR: 1.00e-05\n",
      "Epoch   1 [5950/10697 ( 55.6%)] Loss: 0.033443 L1: 0.019401 Grad: 0.140091 Thermal: 0.000653 LR: 1.00e-05\n",
      "Epoch   1 [6000/10697 ( 56.1%)] Loss: 0.029037 L1: 0.016581 Grad: 0.124292 Thermal: 0.000537 LR: 1.00e-05\n",
      "Epoch   1 [6000/10697 ( 56.1%)] Loss: 0.029037 L1: 0.016581 Grad: 0.124292 Thermal: 0.000537 LR: 1.00e-05\n",
      "Epoch   1 [6050/10697 ( 56.6%)] Loss: 0.027478 L1: 0.016020 Grad: 0.114329 Thermal: 0.000514 LR: 1.00e-05\n",
      "Epoch   1 [6050/10697 ( 56.6%)] Loss: 0.027478 L1: 0.016020 Grad: 0.114329 Thermal: 0.000514 LR: 1.00e-05\n",
      "Epoch   1 [6100/10697 ( 57.0%)] Loss: 0.025662 L1: 0.015061 Grad: 0.105792 Thermal: 0.000422 LR: 1.00e-05\n",
      "Epoch   1 [6100/10697 ( 57.0%)] Loss: 0.025662 L1: 0.015061 Grad: 0.105792 Thermal: 0.000422 LR: 1.00e-05\n",
      "Epoch   1 [6150/10697 ( 57.5%)] Loss: 0.026040 L1: 0.015155 Grad: 0.108645 Thermal: 0.000396 LR: 1.00e-05\n",
      "Epoch   1 [6150/10697 ( 57.5%)] Loss: 0.026040 L1: 0.015155 Grad: 0.108645 Thermal: 0.000396 LR: 1.00e-05\n",
      "Epoch   1 [6200/10697 ( 58.0%)] Loss: 0.020934 L1: 0.012032 Grad: 0.088883 Thermal: 0.000276 LR: 1.00e-05\n",
      "Epoch   1 [6200/10697 ( 58.0%)] Loss: 0.020934 L1: 0.012032 Grad: 0.088883 Thermal: 0.000276 LR: 1.00e-05\n",
      "Epoch   1 [6250/10697 ( 58.4%)] Loss: 0.027569 L1: 0.016002 Grad: 0.115436 Thermal: 0.000467 LR: 1.00e-05\n",
      "Epoch   1 [6250/10697 ( 58.4%)] Loss: 0.027569 L1: 0.016002 Grad: 0.115436 Thermal: 0.000467 LR: 1.00e-05\n",
      "Epoch   1 [6300/10697 ( 58.9%)] Loss: 0.030177 L1: 0.017933 Grad: 0.122149 Thermal: 0.000572 LR: 1.00e-05\n",
      "Epoch   1 [6300/10697 ( 58.9%)] Loss: 0.030177 L1: 0.017933 Grad: 0.122149 Thermal: 0.000572 LR: 1.00e-05\n",
      "Epoch   1 [6350/10697 ( 59.4%)] Loss: 0.028456 L1: 0.016727 Grad: 0.117054 Thermal: 0.000473 LR: 1.00e-05\n",
      "Epoch   1 [6350/10697 ( 59.4%)] Loss: 0.028456 L1: 0.016727 Grad: 0.117054 Thermal: 0.000473 LR: 1.00e-05\n",
      "Epoch   1 [6400/10697 ( 59.8%)] Loss: 0.031618 L1: 0.017795 Grad: 0.137943 Thermal: 0.000583 LR: 1.00e-05\n",
      "Epoch   1 [6400/10697 ( 59.8%)] Loss: 0.031618 L1: 0.017795 Grad: 0.137943 Thermal: 0.000583 LR: 1.00e-05\n",
      "Epoch   1 [6450/10697 ( 60.3%)] Loss: 0.027356 L1: 0.015862 Grad: 0.114673 Thermal: 0.000519 LR: 1.00e-05\n",
      "Epoch   1 [6450/10697 ( 60.3%)] Loss: 0.027356 L1: 0.015862 Grad: 0.114673 Thermal: 0.000519 LR: 1.00e-05\n",
      "Epoch   1 [6500/10697 ( 60.8%)] Loss: 0.036472 L1: 0.020976 Grad: 0.154526 Thermal: 0.000877 LR: 1.00e-05\n",
      "Epoch   1 [6500/10697 ( 60.8%)] Loss: 0.036472 L1: 0.020976 Grad: 0.154526 Thermal: 0.000877 LR: 1.00e-05\n",
      "Epoch   1 [6550/10697 ( 61.2%)] Loss: 0.028149 L1: 0.016352 Grad: 0.117710 Thermal: 0.000513 LR: 1.00e-05\n",
      "Epoch   1 [6550/10697 ( 61.2%)] Loss: 0.028149 L1: 0.016352 Grad: 0.117710 Thermal: 0.000513 LR: 1.00e-05\n",
      "Epoch   1 [6600/10697 ( 61.7%)] Loss: 0.029332 L1: 0.016756 Grad: 0.125481 Thermal: 0.000551 LR: 1.00e-05\n",
      "Epoch   1 [6600/10697 ( 61.7%)] Loss: 0.029332 L1: 0.016756 Grad: 0.125481 Thermal: 0.000551 LR: 1.00e-05\n",
      "Epoch   1 [6650/10697 ( 62.2%)] Loss: 0.027575 L1: 0.015759 Grad: 0.117910 Thermal: 0.000488 LR: 1.00e-05\n",
      "Epoch   1 [6650/10697 ( 62.2%)] Loss: 0.027575 L1: 0.015759 Grad: 0.117910 Thermal: 0.000488 LR: 1.00e-05\n",
      "Epoch   1 [6700/10697 ( 62.6%)] Loss: 0.034697 L1: 0.020054 Grad: 0.146073 Thermal: 0.000705 LR: 1.00e-05\n",
      "Epoch   1 [6700/10697 ( 62.6%)] Loss: 0.034697 L1: 0.020054 Grad: 0.146073 Thermal: 0.000705 LR: 1.00e-05\n",
      "Epoch   1 [6750/10697 ( 63.1%)] Loss: 0.030835 L1: 0.018109 Grad: 0.126980 Thermal: 0.000559 LR: 1.00e-05\n",
      "Epoch   1 [6750/10697 ( 63.1%)] Loss: 0.030835 L1: 0.018109 Grad: 0.126980 Thermal: 0.000559 LR: 1.00e-05\n",
      "Epoch   1 [6800/10697 ( 63.6%)] Loss: 0.032236 L1: 0.018615 Grad: 0.135890 Thermal: 0.000642 LR: 1.00e-05\n",
      "Epoch   1 [6800/10697 ( 63.6%)] Loss: 0.032236 L1: 0.018615 Grad: 0.135890 Thermal: 0.000642 LR: 1.00e-05\n",
      "Epoch   1 [6850/10697 ( 64.0%)] Loss: 0.027527 L1: 0.015911 Grad: 0.115946 Thermal: 0.000446 LR: 1.00e-05\n",
      "Epoch   1 [6850/10697 ( 64.0%)] Loss: 0.027527 L1: 0.015911 Grad: 0.115946 Thermal: 0.000446 LR: 1.00e-05\n",
      "Epoch   1 [6900/10697 ( 64.5%)] Loss: 0.033158 L1: 0.019262 Grad: 0.138640 Thermal: 0.000639 LR: 1.00e-05\n",
      "Epoch   1 [6900/10697 ( 64.5%)] Loss: 0.033158 L1: 0.019262 Grad: 0.138640 Thermal: 0.000639 LR: 1.00e-05\n",
      "Epoch   1 [6950/10697 ( 65.0%)] Loss: 0.033657 L1: 0.019271 Grad: 0.143538 Thermal: 0.000656 LR: 1.00e-05\n",
      "Epoch   1 [6950/10697 ( 65.0%)] Loss: 0.033657 L1: 0.019271 Grad: 0.143538 Thermal: 0.000656 LR: 1.00e-05\n",
      "Epoch   1 [7000/10697 ( 65.4%)] Loss: 0.031822 L1: 0.017874 Grad: 0.139176 Thermal: 0.000593 LR: 1.00e-05\n",
      "Epoch   1 [7000/10697 ( 65.4%)] Loss: 0.031822 L1: 0.017874 Grad: 0.139176 Thermal: 0.000593 LR: 1.00e-05\n",
      "Epoch   1 [7050/10697 ( 65.9%)] Loss: 0.026857 L1: 0.015725 Grad: 0.111075 Thermal: 0.000473 LR: 1.00e-05\n",
      "Epoch   1 [7050/10697 ( 65.9%)] Loss: 0.026857 L1: 0.015725 Grad: 0.111075 Thermal: 0.000473 LR: 1.00e-05\n",
      "Epoch   1 [7100/10697 ( 66.4%)] Loss: 0.023303 L1: 0.013640 Grad: 0.096459 Thermal: 0.000343 LR: 1.00e-05\n",
      "Epoch   1 [7100/10697 ( 66.4%)] Loss: 0.023303 L1: 0.013640 Grad: 0.096459 Thermal: 0.000343 LR: 1.00e-05\n",
      "Epoch   1 [7150/10697 ( 66.8%)] Loss: 0.026068 L1: 0.014948 Grad: 0.110984 Thermal: 0.000436 LR: 1.00e-05\n",
      "Epoch   1 [7150/10697 ( 66.8%)] Loss: 0.026068 L1: 0.014948 Grad: 0.110984 Thermal: 0.000436 LR: 1.00e-05\n",
      "Epoch   1 [7200/10697 ( 67.3%)] Loss: 0.030605 L1: 0.017437 Grad: 0.131401 Thermal: 0.000561 LR: 1.00e-05\n",
      "Epoch   1 [7200/10697 ( 67.3%)] Loss: 0.030605 L1: 0.017437 Grad: 0.131401 Thermal: 0.000561 LR: 1.00e-05\n",
      "Epoch   1 [7250/10697 ( 67.8%)] Loss: 0.022001 L1: 0.012357 Grad: 0.096297 Thermal: 0.000278 LR: 1.00e-05\n",
      "Epoch   1 [7250/10697 ( 67.8%)] Loss: 0.022001 L1: 0.012357 Grad: 0.096297 Thermal: 0.000278 LR: 1.00e-05\n",
      "Epoch   1 [7300/10697 ( 68.2%)] Loss: 0.019090 L1: 0.010707 Grad: 0.083702 Thermal: 0.000248 LR: 1.00e-05\n",
      "Epoch   1 [7300/10697 ( 68.2%)] Loss: 0.019090 L1: 0.010707 Grad: 0.083702 Thermal: 0.000248 LR: 1.00e-05\n",
      "Epoch   1 [7350/10697 ( 68.7%)] Loss: 0.021707 L1: 0.012647 Grad: 0.090445 Thermal: 0.000319 LR: 1.00e-05\n",
      "Epoch   1 [7350/10697 ( 68.7%)] Loss: 0.021707 L1: 0.012647 Grad: 0.090445 Thermal: 0.000319 LR: 1.00e-05\n",
      "Epoch   1 [7400/10697 ( 69.2%)] Loss: 0.028131 L1: 0.016393 Grad: 0.117134 Thermal: 0.000495 LR: 1.00e-05\n",
      "Epoch   1 [7400/10697 ( 69.2%)] Loss: 0.028131 L1: 0.016393 Grad: 0.117134 Thermal: 0.000495 LR: 1.00e-05\n",
      "Epoch   1 [7450/10697 ( 69.6%)] Loss: 0.029525 L1: 0.017375 Grad: 0.121221 Thermal: 0.000553 LR: 1.00e-05\n",
      "Epoch   1 [7450/10697 ( 69.6%)] Loss: 0.029525 L1: 0.017375 Grad: 0.121221 Thermal: 0.000553 LR: 1.00e-05\n",
      "Epoch   1 [7500/10697 ( 70.1%)] Loss: 0.026156 L1: 0.015568 Grad: 0.105660 Thermal: 0.000445 LR: 1.00e-05\n",
      "Epoch   1 [7500/10697 ( 70.1%)] Loss: 0.026156 L1: 0.015568 Grad: 0.105660 Thermal: 0.000445 LR: 1.00e-05\n",
      "Epoch   1 [7550/10697 ( 70.6%)] Loss: 0.033033 L1: 0.018934 Grad: 0.140658 Thermal: 0.000671 LR: 1.00e-05\n",
      "Epoch   1 [7550/10697 ( 70.6%)] Loss: 0.033033 L1: 0.018934 Grad: 0.140658 Thermal: 0.000671 LR: 1.00e-05\n",
      "Epoch   1 [7600/10697 ( 71.0%)] Loss: 0.029648 L1: 0.017694 Grad: 0.119254 Thermal: 0.000571 LR: 1.00e-05\n",
      "Epoch   1 [7600/10697 ( 71.0%)] Loss: 0.029648 L1: 0.017694 Grad: 0.119254 Thermal: 0.000571 LR: 1.00e-05\n",
      "Epoch   1 [7650/10697 ( 71.5%)] Loss: 0.029027 L1: 0.017189 Grad: 0.118121 Thermal: 0.000508 LR: 1.00e-05\n",
      "Epoch   1 [7650/10697 ( 71.5%)] Loss: 0.029027 L1: 0.017189 Grad: 0.118121 Thermal: 0.000508 LR: 1.00e-05\n",
      "Epoch   1 [7700/10697 ( 72.0%)] Loss: 0.020639 L1: 0.011677 Grad: 0.089476 Thermal: 0.000286 LR: 1.00e-05\n",
      "Epoch   1 [7700/10697 ( 72.0%)] Loss: 0.020639 L1: 0.011677 Grad: 0.089476 Thermal: 0.000286 LR: 1.00e-05\n",
      "Epoch   1 [7750/10697 ( 72.5%)] Loss: 0.030566 L1: 0.017938 Grad: 0.125992 Thermal: 0.000564 LR: 1.00e-05\n",
      "Epoch   1 [7750/10697 ( 72.5%)] Loss: 0.030566 L1: 0.017938 Grad: 0.125992 Thermal: 0.000564 LR: 1.00e-05\n",
      "Epoch   1 [7800/10697 ( 72.9%)] Loss: 0.023175 L1: 0.013632 Grad: 0.095239 Thermal: 0.000379 LR: 1.00e-05\n",
      "Epoch   1 [7800/10697 ( 72.9%)] Loss: 0.023175 L1: 0.013632 Grad: 0.095239 Thermal: 0.000379 LR: 1.00e-05\n",
      "Epoch   1 [7850/10697 ( 73.4%)] Loss: 0.021571 L1: 0.012087 Grad: 0.094697 Thermal: 0.000290 LR: 1.00e-05\n",
      "Epoch   1 [7850/10697 ( 73.4%)] Loss: 0.021571 L1: 0.012087 Grad: 0.094697 Thermal: 0.000290 LR: 1.00e-05\n",
      "Epoch   1 [7900/10697 ( 73.9%)] Loss: 0.029637 L1: 0.017132 Grad: 0.124803 Thermal: 0.000485 LR: 1.00e-05\n",
      "Epoch   1 [7900/10697 ( 73.9%)] Loss: 0.029637 L1: 0.017132 Grad: 0.124803 Thermal: 0.000485 LR: 1.00e-05\n",
      "Epoch   1 [7950/10697 ( 74.3%)] Loss: 0.022583 L1: 0.013215 Grad: 0.093489 Thermal: 0.000381 LR: 1.00e-05\n",
      "Epoch   1 [7950/10697 ( 74.3%)] Loss: 0.022583 L1: 0.013215 Grad: 0.093489 Thermal: 0.000381 LR: 1.00e-05\n",
      "Epoch   1 [8000/10697 ( 74.8%)] Loss: 0.027567 L1: 0.016062 Grad: 0.114817 Thermal: 0.000474 LR: 1.00e-05\n",
      "Epoch   1 [8000/10697 ( 74.8%)] Loss: 0.027567 L1: 0.016062 Grad: 0.114817 Thermal: 0.000474 LR: 1.00e-05\n",
      "Epoch   1 [8050/10697 ( 75.3%)] Loss: 0.028414 L1: 0.016452 Grad: 0.119376 Thermal: 0.000483 LR: 1.00e-05\n",
      "Epoch   1 [8050/10697 ( 75.3%)] Loss: 0.028414 L1: 0.016452 Grad: 0.119376 Thermal: 0.000483 LR: 1.00e-05\n",
      "Epoch   1 [8100/10697 ( 75.7%)] Loss: 0.028146 L1: 0.016719 Grad: 0.114023 Thermal: 0.000496 LR: 1.00e-05\n",
      "Epoch   1 [8100/10697 ( 75.7%)] Loss: 0.028146 L1: 0.016719 Grad: 0.114023 Thermal: 0.000496 LR: 1.00e-05\n",
      "Epoch   1 [8150/10697 ( 76.2%)] Loss: 0.028878 L1: 0.017017 Grad: 0.118356 Thermal: 0.000512 LR: 1.00e-05\n",
      "Epoch   1 [8150/10697 ( 76.2%)] Loss: 0.028878 L1: 0.017017 Grad: 0.118356 Thermal: 0.000512 LR: 1.00e-05\n",
      "Epoch   1 [8200/10697 ( 76.7%)] Loss: 0.028003 L1: 0.016295 Grad: 0.116852 Thermal: 0.000463 LR: 1.00e-05\n",
      "Epoch   1 [8200/10697 ( 76.7%)] Loss: 0.028003 L1: 0.016295 Grad: 0.116852 Thermal: 0.000463 LR: 1.00e-05\n",
      "Epoch   1 [8250/10697 ( 77.1%)] Loss: 0.028555 L1: 0.016624 Grad: 0.119063 Thermal: 0.000481 LR: 1.00e-05\n",
      "Epoch   1 [8250/10697 ( 77.1%)] Loss: 0.028555 L1: 0.016624 Grad: 0.119063 Thermal: 0.000481 LR: 1.00e-05\n",
      "Epoch   1 [8300/10697 ( 77.6%)] Loss: 0.025295 L1: 0.014150 Grad: 0.111253 Thermal: 0.000386 LR: 1.00e-05\n",
      "Epoch   1 [8300/10697 ( 77.6%)] Loss: 0.025295 L1: 0.014150 Grad: 0.111253 Thermal: 0.000386 LR: 1.00e-05\n",
      "Epoch   1 [8350/10697 ( 78.1%)] Loss: 0.022983 L1: 0.013393 Grad: 0.095717 Thermal: 0.000351 LR: 1.00e-05\n",
      "Epoch   1 [8350/10697 ( 78.1%)] Loss: 0.022983 L1: 0.013393 Grad: 0.095717 Thermal: 0.000351 LR: 1.00e-05\n",
      "Epoch   1 [8400/10697 ( 78.5%)] Loss: 0.029546 L1: 0.017264 Grad: 0.122571 Thermal: 0.000515 LR: 1.00e-05\n",
      "Epoch   1 [8400/10697 ( 78.5%)] Loss: 0.029546 L1: 0.017264 Grad: 0.122571 Thermal: 0.000515 LR: 1.00e-05\n",
      "Epoch   1 [8450/10697 ( 79.0%)] Loss: 0.035380 L1: 0.020301 Grad: 0.150425 Thermal: 0.000735 LR: 1.00e-05\n",
      "Epoch   1 [8450/10697 ( 79.0%)] Loss: 0.035380 L1: 0.020301 Grad: 0.150425 Thermal: 0.000735 LR: 1.00e-05\n",
      "Epoch   1 [8500/10697 ( 79.5%)] Loss: 0.033938 L1: 0.018983 Grad: 0.149212 Thermal: 0.000676 LR: 1.00e-05\n",
      "Epoch   1 [8500/10697 ( 79.5%)] Loss: 0.033938 L1: 0.018983 Grad: 0.149212 Thermal: 0.000676 LR: 1.00e-05\n",
      "Epoch   1 [8550/10697 ( 79.9%)] Loss: 0.022258 L1: 0.013300 Grad: 0.089396 Thermal: 0.000362 LR: 1.00e-05\n",
      "Epoch   1 [8550/10697 ( 79.9%)] Loss: 0.022258 L1: 0.013300 Grad: 0.089396 Thermal: 0.000362 LR: 1.00e-05\n",
      "Epoch   1 [8600/10697 ( 80.4%)] Loss: 0.032868 L1: 0.018908 Grad: 0.139287 Thermal: 0.000629 LR: 1.00e-05\n",
      "Epoch   1 [8600/10697 ( 80.4%)] Loss: 0.032868 L1: 0.018908 Grad: 0.139287 Thermal: 0.000629 LR: 1.00e-05\n",
      "Epoch   1 [8650/10697 ( 80.9%)] Loss: 0.031526 L1: 0.018493 Grad: 0.130030 Thermal: 0.000593 LR: 1.00e-05\n",
      "Epoch   1 [8650/10697 ( 80.9%)] Loss: 0.031526 L1: 0.018493 Grad: 0.130030 Thermal: 0.000593 LR: 1.00e-05\n",
      "Epoch   1 [8700/10697 ( 81.3%)] Loss: 0.023610 L1: 0.013564 Grad: 0.100258 Thermal: 0.000399 LR: 1.00e-05\n",
      "Epoch   1 [8700/10697 ( 81.3%)] Loss: 0.023610 L1: 0.013564 Grad: 0.100258 Thermal: 0.000399 LR: 1.00e-05\n",
      "Epoch   1 [8750/10697 ( 81.8%)] Loss: 0.026732 L1: 0.015325 Grad: 0.113861 Thermal: 0.000409 LR: 1.00e-05\n",
      "Epoch   1 [8750/10697 ( 81.8%)] Loss: 0.026732 L1: 0.015325 Grad: 0.113861 Thermal: 0.000409 LR: 1.00e-05\n",
      "Epoch   1 [8800/10697 ( 82.3%)] Loss: 0.027344 L1: 0.015651 Grad: 0.116727 Thermal: 0.000410 LR: 1.00e-05\n",
      "Epoch   1 [8800/10697 ( 82.3%)] Loss: 0.027344 L1: 0.015651 Grad: 0.116727 Thermal: 0.000410 LR: 1.00e-05\n",
      "Epoch   1 [8850/10697 ( 82.7%)] Loss: 0.038077 L1: 0.021632 Grad: 0.164036 Thermal: 0.000844 LR: 1.00e-05\n",
      "Epoch   1 [8850/10697 ( 82.7%)] Loss: 0.038077 L1: 0.021632 Grad: 0.164036 Thermal: 0.000844 LR: 1.00e-05\n",
      "Epoch   1 [8900/10697 ( 83.2%)] Loss: 0.023593 L1: 0.013789 Grad: 0.097859 Thermal: 0.000380 LR: 1.00e-05\n",
      "Epoch   1 [8900/10697 ( 83.2%)] Loss: 0.023593 L1: 0.013789 Grad: 0.097859 Thermal: 0.000380 LR: 1.00e-05\n",
      "Epoch   1 [8950/10697 ( 83.7%)] Loss: 0.027858 L1: 0.016299 Grad: 0.115342 Thermal: 0.000488 LR: 1.00e-05\n",
      "Epoch   1 [8950/10697 ( 83.7%)] Loss: 0.027858 L1: 0.016299 Grad: 0.115342 Thermal: 0.000488 LR: 1.00e-05\n",
      "Epoch   1 [9000/10697 ( 84.1%)] Loss: 0.025854 L1: 0.015405 Grad: 0.104269 Thermal: 0.000448 LR: 1.00e-05\n",
      "Epoch   1 [9000/10697 ( 84.1%)] Loss: 0.025854 L1: 0.015405 Grad: 0.104269 Thermal: 0.000448 LR: 1.00e-05\n",
      "Epoch   1 [9050/10697 ( 84.6%)] Loss: 0.028647 L1: 0.016954 Grad: 0.116682 Thermal: 0.000494 LR: 1.00e-05\n",
      "Epoch   1 [9050/10697 ( 84.6%)] Loss: 0.028647 L1: 0.016954 Grad: 0.116682 Thermal: 0.000494 LR: 1.00e-05\n",
      "Epoch   1 [9100/10697 ( 85.1%)] Loss: 0.025434 L1: 0.014356 Grad: 0.110575 Thermal: 0.000397 LR: 1.00e-05\n",
      "Epoch   1 [9100/10697 ( 85.1%)] Loss: 0.025434 L1: 0.014356 Grad: 0.110575 Thermal: 0.000397 LR: 1.00e-05\n",
      "Epoch   1 [9150/10697 ( 85.5%)] Loss: 0.029336 L1: 0.016800 Grad: 0.125097 Thermal: 0.000524 LR: 1.00e-05\n",
      "Epoch   1 [9150/10697 ( 85.5%)] Loss: 0.029336 L1: 0.016800 Grad: 0.125097 Thermal: 0.000524 LR: 1.00e-05\n",
      "Epoch   1 [9200/10697 ( 86.0%)] Loss: 0.034632 L1: 0.020011 Grad: 0.145867 Thermal: 0.000686 LR: 1.00e-05\n",
      "Epoch   1 [9200/10697 ( 86.0%)] Loss: 0.034632 L1: 0.020011 Grad: 0.145867 Thermal: 0.000686 LR: 1.00e-05\n",
      "Epoch   1 [9250/10697 ( 86.5%)] Loss: 0.028712 L1: 0.017318 Grad: 0.113688 Thermal: 0.000521 LR: 1.00e-05\n",
      "Epoch   1 [9250/10697 ( 86.5%)] Loss: 0.028712 L1: 0.017318 Grad: 0.113688 Thermal: 0.000521 LR: 1.00e-05\n",
      "Epoch   1 [9300/10697 ( 86.9%)] Loss: 0.026990 L1: 0.015704 Grad: 0.112639 Thermal: 0.000451 LR: 1.00e-05\n",
      "Epoch   1 [9300/10697 ( 86.9%)] Loss: 0.026990 L1: 0.015704 Grad: 0.112639 Thermal: 0.000451 LR: 1.00e-05\n",
      "Epoch   1 [9350/10697 ( 87.4%)] Loss: 0.027765 L1: 0.016172 Grad: 0.115705 Thermal: 0.000456 LR: 1.00e-05\n",
      "Epoch   1 [9350/10697 ( 87.4%)] Loss: 0.027765 L1: 0.016172 Grad: 0.115705 Thermal: 0.000456 LR: 1.00e-05\n",
      "Epoch   1 [9400/10697 ( 87.9%)] Loss: 0.028441 L1: 0.016542 Grad: 0.118756 Thermal: 0.000457 LR: 1.00e-05\n",
      "Epoch   1 [9400/10697 ( 87.9%)] Loss: 0.028441 L1: 0.016542 Grad: 0.118756 Thermal: 0.000457 LR: 1.00e-05\n",
      "Epoch   1 [9450/10697 ( 88.3%)] Loss: 0.027988 L1: 0.015636 Grad: 0.123263 Thermal: 0.000513 LR: 1.00e-05\n",
      "Epoch   1 [9450/10697 ( 88.3%)] Loss: 0.027988 L1: 0.015636 Grad: 0.123263 Thermal: 0.000513 LR: 1.00e-05\n",
      "Epoch   1 [9500/10697 ( 88.8%)] Loss: 0.026235 L1: 0.015287 Grad: 0.109276 Thermal: 0.000404 LR: 1.00e-05\n",
      "Epoch   1 [9500/10697 ( 88.8%)] Loss: 0.026235 L1: 0.015287 Grad: 0.109276 Thermal: 0.000404 LR: 1.00e-05\n",
      "Epoch   1 [9550/10697 ( 89.3%)] Loss: 0.023933 L1: 0.014127 Grad: 0.097869 Thermal: 0.000367 LR: 1.00e-05\n",
      "Epoch   1 [9550/10697 ( 89.3%)] Loss: 0.023933 L1: 0.014127 Grad: 0.097869 Thermal: 0.000367 LR: 1.00e-05\n",
      "Epoch   1 [9600/10697 ( 89.7%)] Loss: 0.030648 L1: 0.017216 Grad: 0.134052 Thermal: 0.000522 LR: 1.00e-05\n",
      "Epoch   1 [9600/10697 ( 89.7%)] Loss: 0.030648 L1: 0.017216 Grad: 0.134052 Thermal: 0.000522 LR: 1.00e-05\n",
      "Epoch   1 [9650/10697 ( 90.2%)] Loss: 0.026332 L1: 0.015371 Grad: 0.109385 Thermal: 0.000453 LR: 1.00e-05\n",
      "Epoch   1 [9650/10697 ( 90.2%)] Loss: 0.026332 L1: 0.015371 Grad: 0.109385 Thermal: 0.000453 LR: 1.00e-05\n",
      "Epoch   1 [9700/10697 ( 90.7%)] Loss: 0.025746 L1: 0.014348 Grad: 0.113777 Thermal: 0.000401 LR: 1.00e-05\n",
      "Epoch   1 [9700/10697 ( 90.7%)] Loss: 0.025746 L1: 0.014348 Grad: 0.113777 Thermal: 0.000401 LR: 1.00e-05\n",
      "Epoch   1 [9750/10697 ( 91.1%)] Loss: 0.028268 L1: 0.016490 Grad: 0.117532 Thermal: 0.000483 LR: 1.00e-05\n",
      "Epoch   1 [9750/10697 ( 91.1%)] Loss: 0.028268 L1: 0.016490 Grad: 0.117532 Thermal: 0.000483 LR: 1.00e-05\n",
      "Epoch   1 [9800/10697 ( 91.6%)] Loss: 0.027671 L1: 0.015928 Grad: 0.117183 Thermal: 0.000483 LR: 1.00e-05\n",
      "Epoch   1 [9800/10697 ( 91.6%)] Loss: 0.027671 L1: 0.015928 Grad: 0.117183 Thermal: 0.000483 LR: 1.00e-05\n",
      "Epoch   1 [9850/10697 ( 92.1%)] Loss: 0.024607 L1: 0.014488 Grad: 0.101003 Thermal: 0.000373 LR: 1.00e-05\n",
      "Epoch   1 [9850/10697 ( 92.1%)] Loss: 0.024607 L1: 0.014488 Grad: 0.101003 Thermal: 0.000373 LR: 1.00e-05\n",
      "Epoch   1 [9900/10697 ( 92.5%)] Loss: 0.020366 L1: 0.011619 Grad: 0.087338 Thermal: 0.000259 LR: 1.00e-05\n",
      "Epoch   1 [9900/10697 ( 92.5%)] Loss: 0.020366 L1: 0.011619 Grad: 0.087338 Thermal: 0.000259 LR: 1.00e-05\n",
      "Epoch   1 [9950/10697 ( 93.0%)] Loss: 0.029137 L1: 0.017309 Grad: 0.118027 Thermal: 0.000517 LR: 1.00e-05\n",
      "Epoch   1 [9950/10697 ( 93.0%)] Loss: 0.029137 L1: 0.017309 Grad: 0.118027 Thermal: 0.000517 LR: 1.00e-05\n",
      "Epoch   1 [10000/10697 ( 93.5%)] Loss: 0.031612 L1: 0.018458 Grad: 0.131239 Thermal: 0.000592 LR: 1.00e-05\n",
      "Epoch   1 [10000/10697 ( 93.5%)] Loss: 0.031612 L1: 0.018458 Grad: 0.131239 Thermal: 0.000592 LR: 1.00e-05\n",
      "Epoch   1 [10050/10697 ( 94.0%)] Loss: 0.024429 L1: 0.013892 Grad: 0.105181 Thermal: 0.000382 LR: 1.00e-05\n",
      "Epoch   1 [10050/10697 ( 94.0%)] Loss: 0.024429 L1: 0.013892 Grad: 0.105181 Thermal: 0.000382 LR: 1.00e-05\n",
      "Epoch   1 [10100/10697 ( 94.4%)] Loss: 0.025101 L1: 0.014824 Grad: 0.102539 Thermal: 0.000446 LR: 1.00e-05\n",
      "Epoch   1 [10100/10697 ( 94.4%)] Loss: 0.025101 L1: 0.014824 Grad: 0.102539 Thermal: 0.000446 LR: 1.00e-05\n",
      "Epoch   1 [10150/10697 ( 94.9%)] Loss: 0.024037 L1: 0.013541 Grad: 0.104785 Thermal: 0.000340 LR: 1.00e-05\n",
      "Epoch   1 [10150/10697 ( 94.9%)] Loss: 0.024037 L1: 0.013541 Grad: 0.104785 Thermal: 0.000340 LR: 1.00e-05\n",
      "Epoch   1 [10200/10697 ( 95.4%)] Loss: 0.031507 L1: 0.018591 Grad: 0.128866 Thermal: 0.000572 LR: 1.00e-05\n",
      "Epoch   1 [10200/10697 ( 95.4%)] Loss: 0.031507 L1: 0.018591 Grad: 0.128866 Thermal: 0.000572 LR: 1.00e-05\n",
      "Epoch   1 [10250/10697 ( 95.8%)] Loss: 0.022765 L1: 0.013268 Grad: 0.094793 Thermal: 0.000356 LR: 1.00e-05\n",
      "Epoch   1 [10250/10697 ( 95.8%)] Loss: 0.022765 L1: 0.013268 Grad: 0.094793 Thermal: 0.000356 LR: 1.00e-05\n",
      "Epoch   1 [10300/10697 ( 96.3%)] Loss: 0.022838 L1: 0.013370 Grad: 0.094510 Thermal: 0.000352 LR: 1.00e-05\n",
      "Epoch   1 [10300/10697 ( 96.3%)] Loss: 0.022838 L1: 0.013370 Grad: 0.094510 Thermal: 0.000352 LR: 1.00e-05\n",
      "Epoch   1 [10350/10697 ( 96.8%)] Loss: 0.027509 L1: 0.015847 Grad: 0.116381 Thermal: 0.000482 LR: 1.00e-05\n",
      "Epoch   1 [10350/10697 ( 96.8%)] Loss: 0.027509 L1: 0.015847 Grad: 0.116381 Thermal: 0.000482 LR: 1.00e-05\n",
      "Epoch   1 [10400/10697 ( 97.2%)] Loss: 0.028743 L1: 0.016955 Grad: 0.117643 Thermal: 0.000471 LR: 1.00e-05\n",
      "Epoch   1 [10400/10697 ( 97.2%)] Loss: 0.028743 L1: 0.016955 Grad: 0.117643 Thermal: 0.000471 LR: 1.00e-05\n",
      "Epoch   1 [10450/10697 ( 97.7%)] Loss: 0.023149 L1: 0.013606 Grad: 0.095229 Thermal: 0.000399 LR: 1.00e-05\n",
      "Epoch   1 [10450/10697 ( 97.7%)] Loss: 0.023149 L1: 0.013606 Grad: 0.095229 Thermal: 0.000399 LR: 1.00e-05\n",
      "Epoch   1 [10500/10697 ( 98.2%)] Loss: 0.027726 L1: 0.016077 Grad: 0.116258 Thermal: 0.000459 LR: 1.00e-05\n",
      "Epoch   1 [10500/10697 ( 98.2%)] Loss: 0.027726 L1: 0.016077 Grad: 0.116258 Thermal: 0.000459 LR: 1.00e-05\n",
      "Epoch   1 [10550/10697 ( 98.6%)] Loss: 0.024655 L1: 0.013985 Grad: 0.106507 Thermal: 0.000390 LR: 1.00e-05\n",
      "Epoch   1 [10550/10697 ( 98.6%)] Loss: 0.024655 L1: 0.013985 Grad: 0.106507 Thermal: 0.000390 LR: 1.00e-05\n",
      "Epoch   1 [10600/10697 ( 99.1%)] Loss: 0.025634 L1: 0.014783 Grad: 0.108273 Thermal: 0.000474 LR: 1.00e-05\n",
      "Epoch   1 [10600/10697 ( 99.1%)] Loss: 0.025634 L1: 0.014783 Grad: 0.108273 Thermal: 0.000474 LR: 1.00e-05\n",
      "Epoch   1 [10650/10697 ( 99.6%)] Loss: 0.030994 L1: 0.018200 Grad: 0.127651 Thermal: 0.000562 LR: 1.00e-05\n",
      "Epoch   1 [10650/10697 ( 99.6%)] Loss: 0.030994 L1: 0.018200 Grad: 0.127651 Thermal: 0.000562 LR: 1.00e-05\n",
      "Epoch   1 Summary: Loss=0.028369 (L1:0.0164, Grad:0.1192, Thermal:0.0005) Val_PSNR=0.00dB Best=33.17dB Time=7.2min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch   1 Summary: Loss=0.028369 (L1:0.0164, Grad:0.1192, Thermal:0.0005) Val_PSNR=0.00dB Best=33.17dB Time=7.2min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch   2 [   0/10697 (  0.0%)] Loss: 0.027127 L1: 0.016224 Grad: 0.108796 Thermal: 0.000471 LR: 9.98e-06\n",
      "Epoch   2 [   0/10697 (  0.0%)] Loss: 0.027127 L1: 0.016224 Grad: 0.108796 Thermal: 0.000471 LR: 9.98e-06\n",
      "Epoch   2 [  50/10697 (  0.5%)] Loss: 0.029725 L1: 0.017481 Grad: 0.122165 Thermal: 0.000543 LR: 9.98e-06\n",
      "Epoch   2 [  50/10697 (  0.5%)] Loss: 0.029725 L1: 0.017481 Grad: 0.122165 Thermal: 0.000543 LR: 9.98e-06\n",
      "Epoch   2 [ 100/10697 (  0.9%)] Loss: 0.029713 L1: 0.017018 Grad: 0.126673 Thermal: 0.000548 LR: 9.98e-06\n",
      "Epoch   2 [ 100/10697 (  0.9%)] Loss: 0.029713 L1: 0.017018 Grad: 0.126673 Thermal: 0.000548 LR: 9.98e-06\n",
      "Epoch   2 [ 150/10697 (  1.4%)] Loss: 0.030359 L1: 0.017177 Grad: 0.131469 Thermal: 0.000701 LR: 9.98e-06\n",
      "Epoch   2 [ 150/10697 (  1.4%)] Loss: 0.030359 L1: 0.017177 Grad: 0.131469 Thermal: 0.000701 LR: 9.98e-06\n",
      "Epoch   2 [ 200/10697 (  1.9%)] Loss: 0.038629 L1: 0.021725 Grad: 0.168571 Thermal: 0.000932 LR: 9.98e-06\n",
      "Epoch   2 [ 200/10697 (  1.9%)] Loss: 0.038629 L1: 0.021725 Grad: 0.168571 Thermal: 0.000932 LR: 9.98e-06\n",
      "Epoch   2 [ 250/10697 (  2.3%)] Loss: 0.030560 L1: 0.017508 Grad: 0.130242 Thermal: 0.000556 LR: 9.98e-06\n",
      "Epoch   2 [ 250/10697 (  2.3%)] Loss: 0.030560 L1: 0.017508 Grad: 0.130242 Thermal: 0.000556 LR: 9.98e-06\n",
      "Epoch   2 [ 300/10697 (  2.8%)] Loss: 0.028723 L1: 0.017027 Grad: 0.116700 Thermal: 0.000515 LR: 9.98e-06\n",
      "Epoch   2 [ 300/10697 (  2.8%)] Loss: 0.028723 L1: 0.017027 Grad: 0.116700 Thermal: 0.000515 LR: 9.98e-06\n",
      "Epoch   2 [ 350/10697 (  3.3%)] Loss: 0.032389 L1: 0.018960 Grad: 0.133966 Thermal: 0.000648 LR: 9.98e-06\n",
      "Epoch   2 [ 350/10697 (  3.3%)] Loss: 0.032389 L1: 0.018960 Grad: 0.133966 Thermal: 0.000648 LR: 9.98e-06\n",
      "Epoch   2 [ 400/10697 (  3.7%)] Loss: 0.026794 L1: 0.015168 Grad: 0.116044 Thermal: 0.000439 LR: 9.98e-06\n",
      "Epoch   2 [ 400/10697 (  3.7%)] Loss: 0.026794 L1: 0.015168 Grad: 0.116044 Thermal: 0.000439 LR: 9.98e-06\n",
      "Epoch   2 [ 450/10697 (  4.2%)] Loss: 0.025033 L1: 0.014248 Grad: 0.107603 Thermal: 0.000489 LR: 9.98e-06\n",
      "Epoch   2 [ 450/10697 (  4.2%)] Loss: 0.025033 L1: 0.014248 Grad: 0.107603 Thermal: 0.000489 LR: 9.98e-06\n",
      "Epoch   2 [ 500/10697 (  4.7%)] Loss: 0.028099 L1: 0.016565 Grad: 0.115107 Thermal: 0.000471 LR: 9.98e-06\n",
      "Epoch   2 [ 500/10697 (  4.7%)] Loss: 0.028099 L1: 0.016565 Grad: 0.115107 Thermal: 0.000471 LR: 9.98e-06\n",
      "Epoch   2 [ 550/10697 (  5.1%)] Loss: 0.030993 L1: 0.017711 Grad: 0.132523 Thermal: 0.000595 LR: 9.98e-06\n",
      "Epoch   2 [ 550/10697 (  5.1%)] Loss: 0.030993 L1: 0.017711 Grad: 0.132523 Thermal: 0.000595 LR: 9.98e-06\n",
      "Epoch   2 [ 600/10697 (  5.6%)] Loss: 0.032386 L1: 0.018313 Grad: 0.140375 Thermal: 0.000716 LR: 9.98e-06\n",
      "Epoch   2 [ 600/10697 (  5.6%)] Loss: 0.032386 L1: 0.018313 Grad: 0.140375 Thermal: 0.000716 LR: 9.98e-06\n",
      "Epoch   2 [ 650/10697 (  6.1%)] Loss: 0.026875 L1: 0.015709 Grad: 0.111431 Thermal: 0.000471 LR: 9.98e-06\n",
      "Epoch   2 [ 650/10697 (  6.1%)] Loss: 0.026875 L1: 0.015709 Grad: 0.111431 Thermal: 0.000471 LR: 9.98e-06\n",
      "Epoch   2 [ 700/10697 (  6.5%)] Loss: 0.032845 L1: 0.018856 Grad: 0.139575 Thermal: 0.000611 LR: 9.98e-06\n",
      "Epoch   2 [ 700/10697 (  6.5%)] Loss: 0.032845 L1: 0.018856 Grad: 0.139575 Thermal: 0.000611 LR: 9.98e-06\n",
      "Epoch   2 [ 750/10697 (  7.0%)] Loss: 0.029825 L1: 0.017936 Grad: 0.118600 Thermal: 0.000582 LR: 9.98e-06\n",
      "Epoch   2 [ 750/10697 (  7.0%)] Loss: 0.029825 L1: 0.017936 Grad: 0.118600 Thermal: 0.000582 LR: 9.98e-06\n",
      "Epoch   2 [ 800/10697 (  7.5%)] Loss: 0.025264 L1: 0.014695 Grad: 0.105484 Thermal: 0.000410 LR: 9.98e-06\n",
      "Epoch   2 [ 800/10697 (  7.5%)] Loss: 0.025264 L1: 0.014695 Grad: 0.105484 Thermal: 0.000410 LR: 9.98e-06\n",
      "Epoch   2 [ 850/10697 (  7.9%)] Loss: 0.024467 L1: 0.014268 Grad: 0.101802 Thermal: 0.000385 LR: 9.98e-06\n",
      "Epoch   2 [ 850/10697 (  7.9%)] Loss: 0.024467 L1: 0.014268 Grad: 0.101802 Thermal: 0.000385 LR: 9.98e-06\n",
      "Epoch   2 [ 900/10697 (  8.4%)] Loss: 0.026875 L1: 0.015325 Grad: 0.115247 Thermal: 0.000493 LR: 9.98e-06\n",
      "Epoch   2 [ 900/10697 (  8.4%)] Loss: 0.026875 L1: 0.015325 Grad: 0.115247 Thermal: 0.000493 LR: 9.98e-06\n",
      "Epoch   2 [ 950/10697 (  8.9%)] Loss: 0.026086 L1: 0.015489 Grad: 0.105760 Thermal: 0.000422 LR: 9.98e-06\n",
      "Epoch   2 [ 950/10697 (  8.9%)] Loss: 0.026086 L1: 0.015489 Grad: 0.105760 Thermal: 0.000422 LR: 9.98e-06\n",
      "Epoch   2 [1000/10697 (  9.3%)] Loss: 0.024461 L1: 0.014059 Grad: 0.103824 Thermal: 0.000387 LR: 9.98e-06\n",
      "Epoch   2 [1000/10697 (  9.3%)] Loss: 0.024461 L1: 0.014059 Grad: 0.103824 Thermal: 0.000387 LR: 9.98e-06\n",
      "Epoch   2 [1050/10697 (  9.8%)] Loss: 0.028831 L1: 0.017014 Grad: 0.117912 Thermal: 0.000515 LR: 9.98e-06\n",
      "Epoch   2 [1050/10697 (  9.8%)] Loss: 0.028831 L1: 0.017014 Grad: 0.117912 Thermal: 0.000515 LR: 9.98e-06\n",
      "Epoch   2 [1100/10697 ( 10.3%)] Loss: 0.029741 L1: 0.017308 Grad: 0.124060 Thermal: 0.000530 LR: 9.98e-06\n",
      "Epoch   2 [1100/10697 ( 10.3%)] Loss: 0.029741 L1: 0.017308 Grad: 0.124060 Thermal: 0.000530 LR: 9.98e-06\n",
      "Epoch   2 [1150/10697 ( 10.8%)] Loss: 0.025099 L1: 0.014496 Grad: 0.105814 Thermal: 0.000436 LR: 9.98e-06\n",
      "Epoch   2 [1150/10697 ( 10.8%)] Loss: 0.025099 L1: 0.014496 Grad: 0.105814 Thermal: 0.000436 LR: 9.98e-06\n",
      "Epoch   2 [1200/10697 ( 11.2%)] Loss: 0.029109 L1: 0.016910 Grad: 0.121729 Thermal: 0.000520 LR: 9.98e-06\n",
      "Epoch   2 [1200/10697 ( 11.2%)] Loss: 0.029109 L1: 0.016910 Grad: 0.121729 Thermal: 0.000520 LR: 9.98e-06\n",
      "Epoch   2 [1250/10697 ( 11.7%)] Loss: 0.025620 L1: 0.014316 Grad: 0.112850 Thermal: 0.000373 LR: 9.98e-06\n",
      "Epoch   2 [1250/10697 ( 11.7%)] Loss: 0.025620 L1: 0.014316 Grad: 0.112850 Thermal: 0.000373 LR: 9.98e-06\n",
      "Epoch   2 [1300/10697 ( 12.2%)] Loss: 0.027648 L1: 0.015451 Grad: 0.121749 Thermal: 0.000428 LR: 9.98e-06\n",
      "Epoch   2 [1300/10697 ( 12.2%)] Loss: 0.027648 L1: 0.015451 Grad: 0.121749 Thermal: 0.000428 LR: 9.98e-06\n",
      "Epoch   2 [1350/10697 ( 12.6%)] Loss: 0.028670 L1: 0.017093 Grad: 0.115500 Thermal: 0.000525 LR: 9.98e-06\n",
      "Epoch   2 [1350/10697 ( 12.6%)] Loss: 0.028670 L1: 0.017093 Grad: 0.115500 Thermal: 0.000525 LR: 9.98e-06\n",
      "Epoch   2 [1400/10697 ( 13.1%)] Loss: 0.025132 L1: 0.014036 Grad: 0.110744 Thermal: 0.000428 LR: 9.98e-06\n",
      "Epoch   2 [1400/10697 ( 13.1%)] Loss: 0.025132 L1: 0.014036 Grad: 0.110744 Thermal: 0.000428 LR: 9.98e-06\n",
      "Epoch   2 [1450/10697 ( 13.6%)] Loss: 0.029491 L1: 0.017360 Grad: 0.121041 Thermal: 0.000523 LR: 9.98e-06\n",
      "Epoch   2 [1450/10697 ( 13.6%)] Loss: 0.029491 L1: 0.017360 Grad: 0.121041 Thermal: 0.000523 LR: 9.98e-06\n",
      "Epoch   2 [1500/10697 ( 14.0%)] Loss: 0.030452 L1: 0.017271 Grad: 0.131561 Thermal: 0.000494 LR: 9.98e-06\n",
      "Epoch   2 [1500/10697 ( 14.0%)] Loss: 0.030452 L1: 0.017271 Grad: 0.131561 Thermal: 0.000494 LR: 9.98e-06\n",
      "Epoch   2 [1550/10697 ( 14.5%)] Loss: 0.028002 L1: 0.016149 Grad: 0.118272 Thermal: 0.000510 LR: 9.98e-06\n",
      "Epoch   2 [1550/10697 ( 14.5%)] Loss: 0.028002 L1: 0.016149 Grad: 0.118272 Thermal: 0.000510 LR: 9.98e-06\n",
      "Epoch   2 [1600/10697 ( 15.0%)] Loss: 0.026525 L1: 0.015392 Grad: 0.111121 Thermal: 0.000427 LR: 9.98e-06\n",
      "Epoch   2 [1600/10697 ( 15.0%)] Loss: 0.026525 L1: 0.015392 Grad: 0.111121 Thermal: 0.000427 LR: 9.98e-06\n",
      "Epoch   2 [1650/10697 ( 15.4%)] Loss: 0.031093 L1: 0.018705 Grad: 0.123583 Thermal: 0.000601 LR: 9.98e-06\n",
      "Epoch   2 [1650/10697 ( 15.4%)] Loss: 0.031093 L1: 0.018705 Grad: 0.123583 Thermal: 0.000601 LR: 9.98e-06\n",
      "Epoch   2 [1700/10697 ( 15.9%)] Loss: 0.030911 L1: 0.018040 Grad: 0.128396 Thermal: 0.000626 LR: 9.98e-06\n",
      "Epoch   2 [1700/10697 ( 15.9%)] Loss: 0.030911 L1: 0.018040 Grad: 0.128396 Thermal: 0.000626 LR: 9.98e-06\n",
      "Epoch   2 [1750/10697 ( 16.4%)] Loss: 0.029466 L1: 0.016730 Grad: 0.127101 Thermal: 0.000520 LR: 9.98e-06\n",
      "Epoch   2 [1750/10697 ( 16.4%)] Loss: 0.029466 L1: 0.016730 Grad: 0.127101 Thermal: 0.000520 LR: 9.98e-06\n",
      "Epoch   2 [1800/10697 ( 16.8%)] Loss: 0.031411 L1: 0.018548 Grad: 0.128313 Thermal: 0.000621 LR: 9.98e-06\n",
      "Epoch   2 [1800/10697 ( 16.8%)] Loss: 0.031411 L1: 0.018548 Grad: 0.128313 Thermal: 0.000621 LR: 9.98e-06\n",
      "Epoch   2 [1850/10697 ( 17.3%)] Loss: 0.026937 L1: 0.015928 Grad: 0.109867 Thermal: 0.000452 LR: 9.98e-06\n",
      "Epoch   2 [1850/10697 ( 17.3%)] Loss: 0.026937 L1: 0.015928 Grad: 0.109867 Thermal: 0.000452 LR: 9.98e-06\n",
      "Epoch   2 [1900/10697 ( 17.8%)] Loss: 0.023694 L1: 0.013946 Grad: 0.097272 Thermal: 0.000410 LR: 9.98e-06\n",
      "Epoch   2 [1900/10697 ( 17.8%)] Loss: 0.023694 L1: 0.013946 Grad: 0.097272 Thermal: 0.000410 LR: 9.98e-06\n",
      "Epoch   2 [1950/10697 ( 18.2%)] Loss: 0.032033 L1: 0.018720 Grad: 0.132806 Thermal: 0.000645 LR: 9.98e-06\n",
      "Epoch   2 [1950/10697 ( 18.2%)] Loss: 0.032033 L1: 0.018720 Grad: 0.132806 Thermal: 0.000645 LR: 9.98e-06\n",
      "Epoch   2 [2000/10697 ( 18.7%)] Loss: 0.025845 L1: 0.014748 Grad: 0.110776 Thermal: 0.000391 LR: 9.98e-06\n",
      "Epoch   2 [2000/10697 ( 18.7%)] Loss: 0.025845 L1: 0.014748 Grad: 0.110776 Thermal: 0.000391 LR: 9.98e-06\n",
      "Epoch   2 [2050/10697 ( 19.2%)] Loss: 0.029817 L1: 0.017428 Grad: 0.123633 Thermal: 0.000517 LR: 9.98e-06\n",
      "Epoch   2 [2050/10697 ( 19.2%)] Loss: 0.029817 L1: 0.017428 Grad: 0.123633 Thermal: 0.000517 LR: 9.98e-06\n",
      "Epoch   2 [2100/10697 ( 19.6%)] Loss: 0.025820 L1: 0.014738 Grad: 0.110616 Thermal: 0.000414 LR: 9.98e-06\n",
      "Epoch   2 [2100/10697 ( 19.6%)] Loss: 0.025820 L1: 0.014738 Grad: 0.110616 Thermal: 0.000414 LR: 9.98e-06\n",
      "Epoch   2 [2150/10697 ( 20.1%)] Loss: 0.028478 L1: 0.016475 Grad: 0.119778 Thermal: 0.000502 LR: 9.98e-06\n",
      "Epoch   2 [2150/10697 ( 20.1%)] Loss: 0.028478 L1: 0.016475 Grad: 0.119778 Thermal: 0.000502 LR: 9.98e-06\n",
      "Epoch   2 [2200/10697 ( 20.6%)] Loss: 0.032415 L1: 0.019245 Grad: 0.131346 Thermal: 0.000692 LR: 9.98e-06\n",
      "Epoch   2 [2200/10697 ( 20.6%)] Loss: 0.032415 L1: 0.019245 Grad: 0.131346 Thermal: 0.000692 LR: 9.98e-06\n",
      "Epoch   2 [2250/10697 ( 21.0%)] Loss: 0.031248 L1: 0.018489 Grad: 0.127284 Thermal: 0.000607 LR: 9.98e-06\n",
      "Epoch   2 [2250/10697 ( 21.0%)] Loss: 0.031248 L1: 0.018489 Grad: 0.127284 Thermal: 0.000607 LR: 9.98e-06\n",
      "Epoch   2 [2300/10697 ( 21.5%)] Loss: 0.026557 L1: 0.015201 Grad: 0.113330 Thermal: 0.000447 LR: 9.98e-06\n",
      "Epoch   2 [2300/10697 ( 21.5%)] Loss: 0.026557 L1: 0.015201 Grad: 0.113330 Thermal: 0.000447 LR: 9.98e-06\n",
      "Epoch   2 [2350/10697 ( 22.0%)] Loss: 0.028917 L1: 0.016989 Grad: 0.119018 Thermal: 0.000529 LR: 9.98e-06\n",
      "Epoch   2 [2350/10697 ( 22.0%)] Loss: 0.028917 L1: 0.016989 Grad: 0.119018 Thermal: 0.000529 LR: 9.98e-06\n",
      "Epoch   2 [2400/10697 ( 22.4%)] Loss: 0.029268 L1: 0.017170 Grad: 0.120707 Thermal: 0.000539 LR: 9.98e-06\n",
      "Epoch   2 [2400/10697 ( 22.4%)] Loss: 0.029268 L1: 0.017170 Grad: 0.120707 Thermal: 0.000539 LR: 9.98e-06\n",
      "Epoch   2 [2450/10697 ( 22.9%)] Loss: 0.027994 L1: 0.016846 Grad: 0.111239 Thermal: 0.000489 LR: 9.98e-06\n",
      "Epoch   2 [2450/10697 ( 22.9%)] Loss: 0.027994 L1: 0.016846 Grad: 0.111239 Thermal: 0.000489 LR: 9.98e-06\n",
      "Epoch   2 [2500/10697 ( 23.4%)] Loss: 0.028997 L1: 0.016470 Grad: 0.125002 Thermal: 0.000540 LR: 9.98e-06\n",
      "Epoch   2 [2500/10697 ( 23.4%)] Loss: 0.028997 L1: 0.016470 Grad: 0.125002 Thermal: 0.000540 LR: 9.98e-06\n",
      "Epoch   2 [2550/10697 ( 23.8%)] Loss: 0.027472 L1: 0.015849 Grad: 0.116002 Thermal: 0.000455 LR: 9.98e-06\n",
      "Epoch   2 [2550/10697 ( 23.8%)] Loss: 0.027472 L1: 0.015849 Grad: 0.116002 Thermal: 0.000455 LR: 9.98e-06\n",
      "Epoch   2 [2600/10697 ( 24.3%)] Loss: 0.029757 L1: 0.017417 Grad: 0.123117 Thermal: 0.000559 LR: 9.98e-06\n",
      "Epoch   2 [2600/10697 ( 24.3%)] Loss: 0.029757 L1: 0.017417 Grad: 0.123117 Thermal: 0.000559 LR: 9.98e-06\n",
      "Epoch   2 [2650/10697 ( 24.8%)] Loss: 0.031121 L1: 0.018346 Grad: 0.127474 Thermal: 0.000563 LR: 9.98e-06\n",
      "Epoch   2 [2650/10697 ( 24.8%)] Loss: 0.031121 L1: 0.018346 Grad: 0.127474 Thermal: 0.000563 LR: 9.98e-06\n",
      "Epoch   2 [2700/10697 ( 25.2%)] Loss: 0.022798 L1: 0.013204 Grad: 0.095758 Thermal: 0.000360 LR: 9.98e-06\n",
      "Epoch   2 [2700/10697 ( 25.2%)] Loss: 0.022798 L1: 0.013204 Grad: 0.095758 Thermal: 0.000360 LR: 9.98e-06\n",
      "Epoch   2 [2750/10697 ( 25.7%)] Loss: 0.025064 L1: 0.014618 Grad: 0.104272 Thermal: 0.000381 LR: 9.98e-06\n",
      "Epoch   2 [2750/10697 ( 25.7%)] Loss: 0.025064 L1: 0.014618 Grad: 0.104272 Thermal: 0.000381 LR: 9.98e-06\n",
      "Epoch   2 [2800/10697 ( 26.2%)] Loss: 0.032082 L1: 0.018283 Grad: 0.137696 Thermal: 0.000589 LR: 9.98e-06\n",
      "Epoch   2 [2800/10697 ( 26.2%)] Loss: 0.032082 L1: 0.018283 Grad: 0.137696 Thermal: 0.000589 LR: 9.98e-06\n",
      "Epoch   2 [2850/10697 ( 26.6%)] Loss: 0.026549 L1: 0.015490 Grad: 0.110386 Thermal: 0.000419 LR: 9.98e-06\n",
      "Epoch   2 [2850/10697 ( 26.6%)] Loss: 0.026549 L1: 0.015490 Grad: 0.110386 Thermal: 0.000419 LR: 9.98e-06\n",
      "Epoch   2 [2900/10697 ( 27.1%)] Loss: 0.029632 L1: 0.017314 Grad: 0.122923 Thermal: 0.000514 LR: 9.98e-06\n",
      "Epoch   2 [2900/10697 ( 27.1%)] Loss: 0.029632 L1: 0.017314 Grad: 0.122923 Thermal: 0.000514 LR: 9.98e-06\n",
      "Epoch   2 [2950/10697 ( 27.6%)] Loss: 0.023415 L1: 0.013539 Grad: 0.098570 Thermal: 0.000379 LR: 9.98e-06\n",
      "Epoch   2 [2950/10697 ( 27.6%)] Loss: 0.023415 L1: 0.013539 Grad: 0.098570 Thermal: 0.000379 LR: 9.98e-06\n",
      "Epoch   2 [3000/10697 ( 28.0%)] Loss: 0.027221 L1: 0.015734 Grad: 0.114650 Thermal: 0.000443 LR: 9.98e-06\n",
      "Epoch   2 [3000/10697 ( 28.0%)] Loss: 0.027221 L1: 0.015734 Grad: 0.114650 Thermal: 0.000443 LR: 9.98e-06\n",
      "Epoch   2 [3050/10697 ( 28.5%)] Loss: 0.028723 L1: 0.016813 Grad: 0.118837 Thermal: 0.000535 LR: 9.98e-06\n",
      "Epoch   2 [3050/10697 ( 28.5%)] Loss: 0.028723 L1: 0.016813 Grad: 0.118837 Thermal: 0.000535 LR: 9.98e-06\n",
      "Epoch   2 [3100/10697 ( 29.0%)] Loss: 0.027463 L1: 0.016213 Grad: 0.112277 Thermal: 0.000454 LR: 9.98e-06\n",
      "Epoch   2 [3100/10697 ( 29.0%)] Loss: 0.027463 L1: 0.016213 Grad: 0.112277 Thermal: 0.000454 LR: 9.98e-06\n",
      "Epoch   2 [3150/10697 ( 29.4%)] Loss: 0.031087 L1: 0.017937 Grad: 0.131218 Thermal: 0.000578 LR: 9.98e-06\n",
      "Epoch   2 [3150/10697 ( 29.4%)] Loss: 0.031087 L1: 0.017937 Grad: 0.131218 Thermal: 0.000578 LR: 9.98e-06\n",
      "Epoch   2 [3200/10697 ( 29.9%)] Loss: 0.030747 L1: 0.017100 Grad: 0.136150 Thermal: 0.000643 LR: 9.98e-06\n",
      "Epoch   2 [3200/10697 ( 29.9%)] Loss: 0.030747 L1: 0.017100 Grad: 0.136150 Thermal: 0.000643 LR: 9.98e-06\n",
      "Epoch   2 [3250/10697 ( 30.4%)] Loss: 0.023487 L1: 0.013335 Grad: 0.101353 Thermal: 0.000338 LR: 9.98e-06\n",
      "Epoch   2 [3250/10697 ( 30.4%)] Loss: 0.023487 L1: 0.013335 Grad: 0.101353 Thermal: 0.000338 LR: 9.98e-06\n",
      "Epoch   2 [3300/10697 ( 30.8%)] Loss: 0.036658 L1: 0.021161 Grad: 0.154536 Thermal: 0.000873 LR: 9.98e-06\n",
      "Epoch   2 [3300/10697 ( 30.8%)] Loss: 0.036658 L1: 0.021161 Grad: 0.154536 Thermal: 0.000873 LR: 9.98e-06\n",
      "Epoch   2 [3350/10697 ( 31.3%)] Loss: 0.023447 L1: 0.013253 Grad: 0.101747 Thermal: 0.000389 LR: 9.98e-06\n",
      "Epoch   2 [3350/10697 ( 31.3%)] Loss: 0.023447 L1: 0.013253 Grad: 0.101747 Thermal: 0.000389 LR: 9.98e-06\n",
      "Epoch   2 [3400/10697 ( 31.8%)] Loss: 0.025149 L1: 0.015101 Grad: 0.100273 Thermal: 0.000416 LR: 9.98e-06\n",
      "Epoch   2 [3400/10697 ( 31.8%)] Loss: 0.025149 L1: 0.015101 Grad: 0.100273 Thermal: 0.000416 LR: 9.98e-06\n",
      "Epoch   2 [3450/10697 ( 32.3%)] Loss: 0.030832 L1: 0.018150 Grad: 0.126531 Thermal: 0.000579 LR: 9.98e-06\n",
      "Epoch   2 [3450/10697 ( 32.3%)] Loss: 0.030832 L1: 0.018150 Grad: 0.126531 Thermal: 0.000579 LR: 9.98e-06\n",
      "Epoch   2 [3500/10697 ( 32.7%)] Loss: 0.028599 L1: 0.016726 Grad: 0.118479 Thermal: 0.000494 LR: 9.98e-06\n",
      "Epoch   2 [3500/10697 ( 32.7%)] Loss: 0.028599 L1: 0.016726 Grad: 0.118479 Thermal: 0.000494 LR: 9.98e-06\n",
      "Epoch   2 [3550/10697 ( 33.2%)] Loss: 0.018296 L1: 0.010537 Grad: 0.077461 Thermal: 0.000250 LR: 9.98e-06\n",
      "Epoch   2 [3550/10697 ( 33.2%)] Loss: 0.018296 L1: 0.010537 Grad: 0.077461 Thermal: 0.000250 LR: 9.98e-06\n",
      "Epoch   2 [3600/10697 ( 33.7%)] Loss: 0.016882 L1: 0.009367 Grad: 0.075054 Thermal: 0.000193 LR: 9.98e-06\n",
      "Epoch   2 [3600/10697 ( 33.7%)] Loss: 0.016882 L1: 0.009367 Grad: 0.075054 Thermal: 0.000193 LR: 9.98e-06\n",
      "Epoch   2 [3650/10697 ( 34.1%)] Loss: 0.027396 L1: 0.015925 Grad: 0.114505 Thermal: 0.000416 LR: 9.98e-06\n",
      "Epoch   2 [3650/10697 ( 34.1%)] Loss: 0.027396 L1: 0.015925 Grad: 0.114505 Thermal: 0.000416 LR: 9.98e-06\n",
      "Epoch   2 [3700/10697 ( 34.6%)] Loss: 0.035834 L1: 0.020693 Grad: 0.151031 Thermal: 0.000776 LR: 9.98e-06\n",
      "Epoch   2 [3700/10697 ( 34.6%)] Loss: 0.035834 L1: 0.020693 Grad: 0.151031 Thermal: 0.000776 LR: 9.98e-06\n",
      "Epoch   2 [3750/10697 ( 35.1%)] Loss: 0.029993 L1: 0.017670 Grad: 0.122970 Thermal: 0.000524 LR: 9.98e-06\n",
      "Epoch   2 [3750/10697 ( 35.1%)] Loss: 0.029993 L1: 0.017670 Grad: 0.122970 Thermal: 0.000524 LR: 9.98e-06\n",
      "Epoch   2 [3800/10697 ( 35.5%)] Loss: 0.022257 L1: 0.013080 Grad: 0.091615 Thermal: 0.000316 LR: 9.98e-06\n",
      "Epoch   2 [3800/10697 ( 35.5%)] Loss: 0.022257 L1: 0.013080 Grad: 0.091615 Thermal: 0.000316 LR: 9.98e-06\n",
      "Epoch   2 [3850/10697 ( 36.0%)] Loss: 0.031538 L1: 0.017775 Grad: 0.137343 Thermal: 0.000573 LR: 9.98e-06\n",
      "Epoch   2 [3850/10697 ( 36.0%)] Loss: 0.031538 L1: 0.017775 Grad: 0.137343 Thermal: 0.000573 LR: 9.98e-06\n",
      "Epoch   2 [3900/10697 ( 36.5%)] Loss: 0.027154 L1: 0.015965 Grad: 0.111664 Thermal: 0.000445 LR: 9.98e-06\n",
      "Epoch   2 [3900/10697 ( 36.5%)] Loss: 0.027154 L1: 0.015965 Grad: 0.111664 Thermal: 0.000445 LR: 9.98e-06\n",
      "Epoch   2 [3950/10697 ( 36.9%)] Loss: 0.028169 L1: 0.015839 Grad: 0.123083 Thermal: 0.000444 LR: 9.98e-06\n",
      "Epoch   2 [3950/10697 ( 36.9%)] Loss: 0.028169 L1: 0.015839 Grad: 0.123083 Thermal: 0.000444 LR: 9.98e-06\n",
      "Epoch   2 [4000/10697 ( 37.4%)] Loss: 0.035026 L1: 0.020279 Grad: 0.147097 Thermal: 0.000737 LR: 9.98e-06\n",
      "Epoch   2 [4000/10697 ( 37.4%)] Loss: 0.035026 L1: 0.020279 Grad: 0.147097 Thermal: 0.000737 LR: 9.98e-06\n",
      "Epoch   2 [4050/10697 ( 37.9%)] Loss: 0.029685 L1: 0.017017 Grad: 0.126420 Thermal: 0.000515 LR: 9.98e-06\n",
      "Epoch   2 [4050/10697 ( 37.9%)] Loss: 0.029685 L1: 0.017017 Grad: 0.126420 Thermal: 0.000515 LR: 9.98e-06\n",
      "Epoch   2 [4100/10697 ( 38.3%)] Loss: 0.033081 L1: 0.019035 Grad: 0.140084 Thermal: 0.000749 LR: 9.98e-06\n",
      "Epoch   2 [4100/10697 ( 38.3%)] Loss: 0.033081 L1: 0.019035 Grad: 0.140084 Thermal: 0.000749 LR: 9.98e-06\n",
      "Epoch   2 [4150/10697 ( 38.8%)] Loss: 0.026322 L1: 0.015090 Grad: 0.112110 Thermal: 0.000423 LR: 9.98e-06\n",
      "Epoch   2 [4150/10697 ( 38.8%)] Loss: 0.026322 L1: 0.015090 Grad: 0.112110 Thermal: 0.000423 LR: 9.98e-06\n",
      "Epoch   2 [4200/10697 ( 39.3%)] Loss: 0.029763 L1: 0.017113 Grad: 0.126233 Thermal: 0.000526 LR: 9.98e-06\n",
      "Epoch   2 [4200/10697 ( 39.3%)] Loss: 0.029763 L1: 0.017113 Grad: 0.126233 Thermal: 0.000526 LR: 9.98e-06\n",
      "Epoch   2 [4250/10697 ( 39.7%)] Loss: 0.029133 L1: 0.016973 Grad: 0.121358 Thermal: 0.000473 LR: 9.98e-06\n",
      "Epoch   2 [4250/10697 ( 39.7%)] Loss: 0.029133 L1: 0.016973 Grad: 0.121358 Thermal: 0.000473 LR: 9.98e-06\n",
      "Epoch   2 [4300/10697 ( 40.2%)] Loss: 0.027388 L1: 0.015649 Grad: 0.117201 Thermal: 0.000388 LR: 9.98e-06\n",
      "Epoch   2 [4300/10697 ( 40.2%)] Loss: 0.027388 L1: 0.015649 Grad: 0.117201 Thermal: 0.000388 LR: 9.98e-06\n",
      "Epoch   2 [4350/10697 ( 40.7%)] Loss: 0.034381 L1: 0.019869 Grad: 0.144759 Thermal: 0.000719 LR: 9.98e-06\n",
      "Epoch   2 [4350/10697 ( 40.7%)] Loss: 0.034381 L1: 0.019869 Grad: 0.144759 Thermal: 0.000719 LR: 9.98e-06\n",
      "Epoch   2 [4400/10697 ( 41.1%)] Loss: 0.042300 L1: 0.023995 Grad: 0.182545 Thermal: 0.001025 LR: 9.98e-06\n",
      "Epoch   2 [4400/10697 ( 41.1%)] Loss: 0.042300 L1: 0.023995 Grad: 0.182545 Thermal: 0.001025 LR: 9.98e-06\n",
      "Epoch   2 [4450/10697 ( 41.6%)] Loss: 0.024810 L1: 0.014196 Grad: 0.105938 Thermal: 0.000395 LR: 9.98e-06\n",
      "Epoch   2 [4450/10697 ( 41.6%)] Loss: 0.024810 L1: 0.014196 Grad: 0.105938 Thermal: 0.000395 LR: 9.98e-06\n",
      "Epoch   2 [4500/10697 ( 42.1%)] Loss: 0.023658 L1: 0.013613 Grad: 0.100267 Thermal: 0.000366 LR: 9.98e-06\n",
      "Epoch   2 [4500/10697 ( 42.1%)] Loss: 0.023658 L1: 0.013613 Grad: 0.100267 Thermal: 0.000366 LR: 9.98e-06\n",
      "Epoch   2 [4550/10697 ( 42.5%)] Loss: 0.022704 L1: 0.013064 Grad: 0.096228 Thermal: 0.000331 LR: 9.98e-06\n",
      "Epoch   2 [4550/10697 ( 42.5%)] Loss: 0.022704 L1: 0.013064 Grad: 0.096228 Thermal: 0.000331 LR: 9.98e-06\n",
      "Epoch   2 [4600/10697 ( 43.0%)] Loss: 0.019748 L1: 0.011468 Grad: 0.082632 Thermal: 0.000326 LR: 9.98e-06\n",
      "Epoch   2 [4600/10697 ( 43.0%)] Loss: 0.019748 L1: 0.011468 Grad: 0.082632 Thermal: 0.000326 LR: 9.98e-06\n",
      "Epoch   2 [4650/10697 ( 43.5%)] Loss: 0.025980 L1: 0.015179 Grad: 0.107799 Thermal: 0.000427 LR: 9.98e-06\n",
      "Epoch   2 [4650/10697 ( 43.5%)] Loss: 0.025980 L1: 0.015179 Grad: 0.107799 Thermal: 0.000427 LR: 9.98e-06\n",
      "Epoch   2 [4700/10697 ( 43.9%)] Loss: 0.030234 L1: 0.018023 Grad: 0.121804 Thermal: 0.000597 LR: 9.98e-06\n",
      "Epoch   2 [4700/10697 ( 43.9%)] Loss: 0.030234 L1: 0.018023 Grad: 0.121804 Thermal: 0.000597 LR: 9.98e-06\n",
      "Epoch   2 [4750/10697 ( 44.4%)] Loss: 0.029676 L1: 0.017311 Grad: 0.123387 Thermal: 0.000541 LR: 9.98e-06\n",
      "Epoch   2 [4750/10697 ( 44.4%)] Loss: 0.029676 L1: 0.017311 Grad: 0.123387 Thermal: 0.000541 LR: 9.98e-06\n",
      "Epoch   2 [4800/10697 ( 44.9%)] Loss: 0.030344 L1: 0.017436 Grad: 0.128797 Thermal: 0.000552 LR: 9.98e-06\n",
      "Epoch   2 [4800/10697 ( 44.9%)] Loss: 0.030344 L1: 0.017436 Grad: 0.128797 Thermal: 0.000552 LR: 9.98e-06\n",
      "Epoch   2 [4850/10697 ( 45.3%)] Loss: 0.022818 L1: 0.013533 Grad: 0.092673 Thermal: 0.000360 LR: 9.98e-06\n",
      "Epoch   2 [4850/10697 ( 45.3%)] Loss: 0.022818 L1: 0.013533 Grad: 0.092673 Thermal: 0.000360 LR: 9.98e-06\n",
      "Epoch   2 [4900/10697 ( 45.8%)] Loss: 0.024336 L1: 0.014143 Grad: 0.101745 Thermal: 0.000379 LR: 9.98e-06\n",
      "Epoch   2 [4900/10697 ( 45.8%)] Loss: 0.024336 L1: 0.014143 Grad: 0.101745 Thermal: 0.000379 LR: 9.98e-06\n",
      "Epoch   2 [4950/10697 ( 46.3%)] Loss: 0.026017 L1: 0.015140 Grad: 0.108547 Thermal: 0.000445 LR: 9.98e-06\n",
      "Epoch   2 [4950/10697 ( 46.3%)] Loss: 0.026017 L1: 0.015140 Grad: 0.108547 Thermal: 0.000445 LR: 9.98e-06\n",
      "Epoch   2 [5000/10697 ( 46.7%)] Loss: 0.031393 L1: 0.018024 Grad: 0.133387 Thermal: 0.000615 LR: 9.98e-06\n",
      "Epoch   2 [5000/10697 ( 46.7%)] Loss: 0.031393 L1: 0.018024 Grad: 0.133387 Thermal: 0.000615 LR: 9.98e-06\n",
      "Epoch   2 [5050/10697 ( 47.2%)] Loss: 0.026983 L1: 0.015540 Grad: 0.114177 Thermal: 0.000506 LR: 9.98e-06\n",
      "Epoch   2 [5050/10697 ( 47.2%)] Loss: 0.026983 L1: 0.015540 Grad: 0.114177 Thermal: 0.000506 LR: 9.98e-06\n",
      "Epoch   2 [5100/10697 ( 47.7%)] Loss: 0.029086 L1: 0.016417 Grad: 0.126463 Thermal: 0.000454 LR: 9.98e-06\n",
      "Epoch   2 [5100/10697 ( 47.7%)] Loss: 0.029086 L1: 0.016417 Grad: 0.126463 Thermal: 0.000454 LR: 9.98e-06\n",
      "Epoch   2 [5150/10697 ( 48.1%)] Loss: 0.029464 L1: 0.017065 Grad: 0.123697 Thermal: 0.000598 LR: 9.98e-06\n",
      "Epoch   2 [5150/10697 ( 48.1%)] Loss: 0.029464 L1: 0.017065 Grad: 0.123697 Thermal: 0.000598 LR: 9.98e-06\n",
      "Epoch   2 [5200/10697 ( 48.6%)] Loss: 0.027982 L1: 0.016367 Grad: 0.115898 Thermal: 0.000506 LR: 9.98e-06\n",
      "Epoch   2 [5200/10697 ( 48.6%)] Loss: 0.027982 L1: 0.016367 Grad: 0.115898 Thermal: 0.000506 LR: 9.98e-06\n",
      "Epoch   2 [5250/10697 ( 49.1%)] Loss: 0.026298 L1: 0.015280 Grad: 0.109959 Thermal: 0.000436 LR: 9.98e-06\n",
      "Epoch   2 [5250/10697 ( 49.1%)] Loss: 0.026298 L1: 0.015280 Grad: 0.109959 Thermal: 0.000436 LR: 9.98e-06\n",
      "Epoch   2 [5300/10697 ( 49.5%)] Loss: 0.027485 L1: 0.016414 Grad: 0.110480 Thermal: 0.000468 LR: 9.98e-06\n",
      "Epoch   2 [5300/10697 ( 49.5%)] Loss: 0.027485 L1: 0.016414 Grad: 0.110480 Thermal: 0.000468 LR: 9.98e-06\n",
      "Epoch   2 [5350/10697 ( 50.0%)] Loss: 0.027961 L1: 0.015988 Grad: 0.119465 Thermal: 0.000526 LR: 9.98e-06\n",
      "Epoch   2 [5350/10697 ( 50.0%)] Loss: 0.027961 L1: 0.015988 Grad: 0.119465 Thermal: 0.000526 LR: 9.98e-06\n",
      "Epoch   2 [5400/10697 ( 50.5%)] Loss: 0.025835 L1: 0.014977 Grad: 0.108367 Thermal: 0.000416 LR: 9.98e-06\n",
      "Epoch   2 [5400/10697 ( 50.5%)] Loss: 0.025835 L1: 0.014977 Grad: 0.108367 Thermal: 0.000416 LR: 9.98e-06\n",
      "Epoch   2 [5450/10697 ( 50.9%)] Loss: 0.029259 L1: 0.017000 Grad: 0.122329 Thermal: 0.000516 LR: 9.98e-06\n",
      "Epoch   2 [5450/10697 ( 50.9%)] Loss: 0.029259 L1: 0.017000 Grad: 0.122329 Thermal: 0.000516 LR: 9.98e-06\n",
      "Epoch   2 [5500/10697 ( 51.4%)] Loss: 0.025088 L1: 0.015012 Grad: 0.100555 Thermal: 0.000402 LR: 9.98e-06\n",
      "Epoch   2 [5500/10697 ( 51.4%)] Loss: 0.025088 L1: 0.015012 Grad: 0.100555 Thermal: 0.000402 LR: 9.98e-06\n",
      "Epoch   2 [5550/10697 ( 51.9%)] Loss: 0.028084 L1: 0.016509 Grad: 0.115470 Thermal: 0.000546 LR: 9.98e-06\n",
      "Epoch   2 [5550/10697 ( 51.9%)] Loss: 0.028084 L1: 0.016509 Grad: 0.115470 Thermal: 0.000546 LR: 9.98e-06\n",
      "Epoch   2 [5600/10697 ( 52.4%)] Loss: 0.038101 L1: 0.022085 Grad: 0.159754 Thermal: 0.000813 LR: 9.98e-06\n",
      "Epoch   2 [5600/10697 ( 52.4%)] Loss: 0.038101 L1: 0.022085 Grad: 0.159754 Thermal: 0.000813 LR: 9.98e-06\n",
      "Epoch   2 [5650/10697 ( 52.8%)] Loss: 0.029255 L1: 0.017025 Grad: 0.122048 Thermal: 0.000507 LR: 9.98e-06\n",
      "Epoch   2 [5650/10697 ( 52.8%)] Loss: 0.029255 L1: 0.017025 Grad: 0.122048 Thermal: 0.000507 LR: 9.98e-06\n",
      "Epoch   2 [5700/10697 ( 53.3%)] Loss: 0.029809 L1: 0.017088 Grad: 0.126923 Thermal: 0.000580 LR: 9.98e-06\n",
      "Epoch   2 [5700/10697 ( 53.3%)] Loss: 0.029809 L1: 0.017088 Grad: 0.126923 Thermal: 0.000580 LR: 9.98e-06\n",
      "Epoch   2 [5750/10697 ( 53.8%)] Loss: 0.034683 L1: 0.020146 Grad: 0.145033 Thermal: 0.000674 LR: 9.98e-06\n",
      "Epoch   2 [5750/10697 ( 53.8%)] Loss: 0.034683 L1: 0.020146 Grad: 0.145033 Thermal: 0.000674 LR: 9.98e-06\n",
      "Epoch   2 [5800/10697 ( 54.2%)] Loss: 0.028309 L1: 0.016340 Grad: 0.119413 Thermal: 0.000536 LR: 9.98e-06\n",
      "Epoch   2 [5800/10697 ( 54.2%)] Loss: 0.028309 L1: 0.016340 Grad: 0.119413 Thermal: 0.000536 LR: 9.98e-06\n",
      "Epoch   2 [5850/10697 ( 54.7%)] Loss: 0.026997 L1: 0.015427 Grad: 0.115471 Thermal: 0.000452 LR: 9.98e-06\n",
      "Epoch   2 [5850/10697 ( 54.7%)] Loss: 0.026997 L1: 0.015427 Grad: 0.115471 Thermal: 0.000452 LR: 9.98e-06\n",
      "Epoch   2 [5900/10697 ( 55.2%)] Loss: 0.028679 L1: 0.016644 Grad: 0.120112 Thermal: 0.000479 LR: 9.98e-06\n",
      "Epoch   2 [5900/10697 ( 55.2%)] Loss: 0.028679 L1: 0.016644 Grad: 0.120112 Thermal: 0.000479 LR: 9.98e-06\n",
      "Epoch   2 [5950/10697 ( 55.6%)] Loss: 0.024041 L1: 0.014156 Grad: 0.098653 Thermal: 0.000378 LR: 9.98e-06\n",
      "Epoch   2 [5950/10697 ( 55.6%)] Loss: 0.024041 L1: 0.014156 Grad: 0.098653 Thermal: 0.000378 LR: 9.98e-06\n",
      "Epoch   2 [6000/10697 ( 56.1%)] Loss: 0.024623 L1: 0.014192 Grad: 0.104104 Thermal: 0.000416 LR: 9.98e-06\n",
      "Epoch   2 [6000/10697 ( 56.1%)] Loss: 0.024623 L1: 0.014192 Grad: 0.104104 Thermal: 0.000416 LR: 9.98e-06\n",
      "Epoch   2 [6050/10697 ( 56.6%)] Loss: 0.029029 L1: 0.016508 Grad: 0.124961 Thermal: 0.000502 LR: 9.98e-06\n",
      "Epoch   2 [6050/10697 ( 56.6%)] Loss: 0.029029 L1: 0.016508 Grad: 0.124961 Thermal: 0.000502 LR: 9.98e-06\n",
      "Epoch   2 [6100/10697 ( 57.0%)] Loss: 0.027232 L1: 0.016197 Grad: 0.110112 Thermal: 0.000470 LR: 9.98e-06\n",
      "Epoch   2 [6100/10697 ( 57.0%)] Loss: 0.027232 L1: 0.016197 Grad: 0.110112 Thermal: 0.000470 LR: 9.98e-06\n",
      "Epoch   2 [6150/10697 ( 57.5%)] Loss: 0.023840 L1: 0.012969 Grad: 0.108561 Thermal: 0.000295 LR: 9.98e-06\n",
      "Epoch   2 [6150/10697 ( 57.5%)] Loss: 0.023840 L1: 0.012969 Grad: 0.108561 Thermal: 0.000295 LR: 9.98e-06\n",
      "Epoch   2 [6200/10697 ( 58.0%)] Loss: 0.027809 L1: 0.015990 Grad: 0.117944 Thermal: 0.000501 LR: 9.98e-06\n",
      "Epoch   2 [6200/10697 ( 58.0%)] Loss: 0.027809 L1: 0.015990 Grad: 0.117944 Thermal: 0.000501 LR: 9.98e-06\n",
      "Epoch   2 [6250/10697 ( 58.4%)] Loss: 0.027162 L1: 0.016253 Grad: 0.108851 Thermal: 0.000467 LR: 9.98e-06\n",
      "Epoch   2 [6250/10697 ( 58.4%)] Loss: 0.027162 L1: 0.016253 Grad: 0.108851 Thermal: 0.000467 LR: 9.98e-06\n",
      "Epoch   2 [6300/10697 ( 58.9%)] Loss: 0.029417 L1: 0.017215 Grad: 0.121753 Thermal: 0.000535 LR: 9.98e-06\n",
      "Epoch   2 [6300/10697 ( 58.9%)] Loss: 0.029417 L1: 0.017215 Grad: 0.121753 Thermal: 0.000535 LR: 9.98e-06\n",
      "Epoch   2 [6350/10697 ( 59.4%)] Loss: 0.031590 L1: 0.018473 Grad: 0.130879 Thermal: 0.000583 LR: 9.98e-06\n",
      "Epoch   2 [6350/10697 ( 59.4%)] Loss: 0.031590 L1: 0.018473 Grad: 0.130879 Thermal: 0.000583 LR: 9.98e-06\n",
      "Epoch   2 [6400/10697 ( 59.8%)] Loss: 0.031031 L1: 0.017858 Grad: 0.131447 Thermal: 0.000571 LR: 9.98e-06\n",
      "Epoch   2 [6400/10697 ( 59.8%)] Loss: 0.031031 L1: 0.017858 Grad: 0.131447 Thermal: 0.000571 LR: 9.98e-06\n",
      "Epoch   2 [6450/10697 ( 60.3%)] Loss: 0.026964 L1: 0.015302 Grad: 0.116398 Thermal: 0.000436 LR: 9.98e-06\n",
      "Epoch   2 [6450/10697 ( 60.3%)] Loss: 0.026964 L1: 0.015302 Grad: 0.116398 Thermal: 0.000436 LR: 9.98e-06\n",
      "Epoch   2 [6500/10697 ( 60.8%)] Loss: 0.020982 L1: 0.012237 Grad: 0.087308 Thermal: 0.000289 LR: 9.98e-06\n",
      "Epoch   2 [6500/10697 ( 60.8%)] Loss: 0.020982 L1: 0.012237 Grad: 0.087308 Thermal: 0.000289 LR: 9.98e-06\n",
      "Epoch   2 [6550/10697 ( 61.2%)] Loss: 0.035995 L1: 0.021010 Grad: 0.149456 Thermal: 0.000792 LR: 9.98e-06\n",
      "Epoch   2 [6550/10697 ( 61.2%)] Loss: 0.035995 L1: 0.021010 Grad: 0.149456 Thermal: 0.000792 LR: 9.98e-06\n",
      "Epoch   2 [6600/10697 ( 61.7%)] Loss: 0.028160 L1: 0.016398 Grad: 0.117365 Thermal: 0.000517 LR: 9.98e-06\n",
      "Epoch   2 [6600/10697 ( 61.7%)] Loss: 0.028160 L1: 0.016398 Grad: 0.117365 Thermal: 0.000517 LR: 9.98e-06\n",
      "Epoch   2 [6650/10697 ( 62.2%)] Loss: 0.031706 L1: 0.018681 Grad: 0.129951 Thermal: 0.000596 LR: 9.98e-06\n",
      "Epoch   2 [6650/10697 ( 62.2%)] Loss: 0.031706 L1: 0.018681 Grad: 0.129951 Thermal: 0.000596 LR: 9.98e-06\n",
      "Epoch   2 [6700/10697 ( 62.6%)] Loss: 0.028101 L1: 0.016530 Grad: 0.115472 Thermal: 0.000473 LR: 9.98e-06\n",
      "Epoch   2 [6700/10697 ( 62.6%)] Loss: 0.028101 L1: 0.016530 Grad: 0.115472 Thermal: 0.000473 LR: 9.98e-06\n",
      "Epoch   2 [6750/10697 ( 63.1%)] Loss: 0.029111 L1: 0.016854 Grad: 0.122324 Thermal: 0.000497 LR: 9.98e-06\n",
      "Epoch   2 [6750/10697 ( 63.1%)] Loss: 0.029111 L1: 0.016854 Grad: 0.122324 Thermal: 0.000497 LR: 9.98e-06\n",
      "Epoch   2 [6800/10697 ( 63.6%)] Loss: 0.025828 L1: 0.015059 Grad: 0.107462 Thermal: 0.000453 LR: 9.98e-06\n",
      "Epoch   2 [6800/10697 ( 63.6%)] Loss: 0.025828 L1: 0.015059 Grad: 0.107462 Thermal: 0.000453 LR: 9.98e-06\n",
      "Epoch   2 [6850/10697 ( 64.0%)] Loss: 0.027080 L1: 0.015747 Grad: 0.113093 Thermal: 0.000458 LR: 9.98e-06\n",
      "Epoch   2 [6850/10697 ( 64.0%)] Loss: 0.027080 L1: 0.015747 Grad: 0.113093 Thermal: 0.000458 LR: 9.98e-06\n",
      "Epoch   2 [6900/10697 ( 64.5%)] Loss: 0.026484 L1: 0.015401 Grad: 0.110561 Thermal: 0.000535 LR: 9.98e-06\n",
      "Epoch   2 [6900/10697 ( 64.5%)] Loss: 0.026484 L1: 0.015401 Grad: 0.110561 Thermal: 0.000535 LR: 9.98e-06\n",
      "Epoch   2 [6950/10697 ( 65.0%)] Loss: 0.028167 L1: 0.016120 Grad: 0.120232 Thermal: 0.000485 LR: 9.98e-06\n",
      "Epoch   2 [6950/10697 ( 65.0%)] Loss: 0.028167 L1: 0.016120 Grad: 0.120232 Thermal: 0.000485 LR: 9.98e-06\n",
      "Epoch   2 [7000/10697 ( 65.4%)] Loss: 0.025268 L1: 0.014992 Grad: 0.102540 Thermal: 0.000422 LR: 9.98e-06\n",
      "Epoch   2 [7000/10697 ( 65.4%)] Loss: 0.025268 L1: 0.014992 Grad: 0.102540 Thermal: 0.000422 LR: 9.98e-06\n",
      "Epoch   2 [7050/10697 ( 65.9%)] Loss: 0.025886 L1: 0.014994 Grad: 0.108730 Thermal: 0.000376 LR: 9.98e-06\n",
      "Epoch   2 [7050/10697 ( 65.9%)] Loss: 0.025886 L1: 0.014994 Grad: 0.108730 Thermal: 0.000376 LR: 9.98e-06\n",
      "Epoch   2 [7100/10697 ( 66.4%)] Loss: 0.028487 L1: 0.016170 Grad: 0.122943 Thermal: 0.000458 LR: 9.98e-06\n",
      "Epoch   2 [7100/10697 ( 66.4%)] Loss: 0.028487 L1: 0.016170 Grad: 0.122943 Thermal: 0.000458 LR: 9.98e-06\n",
      "Epoch   2 [7150/10697 ( 66.8%)] Loss: 0.028285 L1: 0.016442 Grad: 0.118189 Thermal: 0.000481 LR: 9.98e-06\n",
      "Epoch   2 [7150/10697 ( 66.8%)] Loss: 0.028285 L1: 0.016442 Grad: 0.118189 Thermal: 0.000481 LR: 9.98e-06\n",
      "Epoch   2 [7200/10697 ( 67.3%)] Loss: 0.027739 L1: 0.016115 Grad: 0.116022 Thermal: 0.000439 LR: 9.98e-06\n",
      "Epoch   2 [7200/10697 ( 67.3%)] Loss: 0.027739 L1: 0.016115 Grad: 0.116022 Thermal: 0.000439 LR: 9.98e-06\n",
      "Epoch   2 [7250/10697 ( 67.8%)] Loss: 0.023443 L1: 0.013746 Grad: 0.096781 Thermal: 0.000372 LR: 9.98e-06\n",
      "Epoch   2 [7250/10697 ( 67.8%)] Loss: 0.023443 L1: 0.013746 Grad: 0.096781 Thermal: 0.000372 LR: 9.98e-06\n",
      "Epoch   2 [7300/10697 ( 68.2%)] Loss: 0.028760 L1: 0.016688 Grad: 0.120453 Thermal: 0.000546 LR: 9.98e-06\n",
      "Epoch   2 [7300/10697 ( 68.2%)] Loss: 0.028760 L1: 0.016688 Grad: 0.120453 Thermal: 0.000546 LR: 9.98e-06\n",
      "Epoch   2 [7350/10697 ( 68.7%)] Loss: 0.023929 L1: 0.013873 Grad: 0.100375 Thermal: 0.000378 LR: 9.98e-06\n",
      "Epoch   2 [7350/10697 ( 68.7%)] Loss: 0.023929 L1: 0.013873 Grad: 0.100375 Thermal: 0.000378 LR: 9.98e-06\n",
      "Epoch   2 [7400/10697 ( 69.2%)] Loss: 0.022931 L1: 0.013496 Grad: 0.094165 Thermal: 0.000364 LR: 9.98e-06\n",
      "Epoch   2 [7400/10697 ( 69.2%)] Loss: 0.022931 L1: 0.013496 Grad: 0.094165 Thermal: 0.000364 LR: 9.98e-06\n",
      "Epoch   2 [7450/10697 ( 69.6%)] Loss: 0.027525 L1: 0.016455 Grad: 0.110463 Thermal: 0.000477 LR: 9.98e-06\n",
      "Epoch   2 [7450/10697 ( 69.6%)] Loss: 0.027525 L1: 0.016455 Grad: 0.110463 Thermal: 0.000477 LR: 9.98e-06\n",
      "Epoch   2 [7500/10697 ( 70.1%)] Loss: 0.029543 L1: 0.017077 Grad: 0.124415 Thermal: 0.000498 LR: 9.98e-06\n",
      "Epoch   2 [7500/10697 ( 70.1%)] Loss: 0.029543 L1: 0.017077 Grad: 0.124415 Thermal: 0.000498 LR: 9.98e-06\n",
      "Epoch   2 [7550/10697 ( 70.6%)] Loss: 0.026073 L1: 0.015221 Grad: 0.108280 Thermal: 0.000479 LR: 9.98e-06\n",
      "Epoch   2 [7550/10697 ( 70.6%)] Loss: 0.026073 L1: 0.015221 Grad: 0.108280 Thermal: 0.000479 LR: 9.98e-06\n",
      "Epoch   2 [7600/10697 ( 71.0%)] Loss: 0.025523 L1: 0.014889 Grad: 0.106152 Thermal: 0.000394 LR: 9.98e-06\n",
      "Epoch   2 [7600/10697 ( 71.0%)] Loss: 0.025523 L1: 0.014889 Grad: 0.106152 Thermal: 0.000394 LR: 9.98e-06\n",
      "Epoch   2 [7650/10697 ( 71.5%)] Loss: 0.031253 L1: 0.017943 Grad: 0.132814 Thermal: 0.000578 LR: 9.98e-06\n",
      "Epoch   2 [7650/10697 ( 71.5%)] Loss: 0.031253 L1: 0.017943 Grad: 0.132814 Thermal: 0.000578 LR: 9.98e-06\n",
      "Epoch   2 [7700/10697 ( 72.0%)] Loss: 0.031237 L1: 0.018008 Grad: 0.132000 Thermal: 0.000581 LR: 9.98e-06\n",
      "Epoch   2 [7700/10697 ( 72.0%)] Loss: 0.031237 L1: 0.018008 Grad: 0.132000 Thermal: 0.000581 LR: 9.98e-06\n",
      "Epoch   2 [7750/10697 ( 72.5%)] Loss: 0.023380 L1: 0.013856 Grad: 0.095061 Thermal: 0.000363 LR: 9.98e-06\n",
      "Epoch   2 [7750/10697 ( 72.5%)] Loss: 0.023380 L1: 0.013856 Grad: 0.095061 Thermal: 0.000363 LR: 9.98e-06\n",
      "Epoch   2 [7800/10697 ( 72.9%)] Loss: 0.020121 L1: 0.011649 Grad: 0.084594 Thermal: 0.000251 LR: 9.98e-06\n",
      "Epoch   2 [7800/10697 ( 72.9%)] Loss: 0.020121 L1: 0.011649 Grad: 0.084594 Thermal: 0.000251 LR: 9.98e-06\n",
      "Epoch   2 [7850/10697 ( 73.4%)] Loss: 0.029435 L1: 0.016873 Grad: 0.125368 Thermal: 0.000511 LR: 9.98e-06\n",
      "Epoch   2 [7850/10697 ( 73.4%)] Loss: 0.029435 L1: 0.016873 Grad: 0.125368 Thermal: 0.000511 LR: 9.98e-06\n",
      "Epoch   2 [7900/10697 ( 73.9%)] Loss: 0.023143 L1: 0.013369 Grad: 0.097555 Thermal: 0.000361 LR: 9.98e-06\n",
      "Epoch   2 [7900/10697 ( 73.9%)] Loss: 0.023143 L1: 0.013369 Grad: 0.097555 Thermal: 0.000361 LR: 9.98e-06\n",
      "Epoch   2 [7950/10697 ( 74.3%)] Loss: 0.032808 L1: 0.018997 Grad: 0.137768 Thermal: 0.000687 LR: 9.98e-06\n",
      "Epoch   2 [7950/10697 ( 74.3%)] Loss: 0.032808 L1: 0.018997 Grad: 0.137768 Thermal: 0.000687 LR: 9.98e-06\n",
      "Epoch   2 [8000/10697 ( 74.8%)] Loss: 0.025619 L1: 0.014961 Grad: 0.106370 Thermal: 0.000419 LR: 9.98e-06\n",
      "Epoch   2 [8000/10697 ( 74.8%)] Loss: 0.025619 L1: 0.014961 Grad: 0.106370 Thermal: 0.000419 LR: 9.98e-06\n",
      "Epoch   2 [8050/10697 ( 75.3%)] Loss: 0.032170 L1: 0.018536 Grad: 0.136018 Thermal: 0.000634 LR: 9.98e-06\n",
      "Epoch   2 [8050/10697 ( 75.3%)] Loss: 0.032170 L1: 0.018536 Grad: 0.136018 Thermal: 0.000634 LR: 9.98e-06\n",
      "Epoch   2 [8100/10697 ( 75.7%)] Loss: 0.028627 L1: 0.016842 Grad: 0.117594 Thermal: 0.000510 LR: 9.98e-06\n",
      "Epoch   2 [8100/10697 ( 75.7%)] Loss: 0.028627 L1: 0.016842 Grad: 0.117594 Thermal: 0.000510 LR: 9.98e-06\n",
      "Epoch   2 [8150/10697 ( 76.2%)] Loss: 0.021307 L1: 0.012545 Grad: 0.087446 Thermal: 0.000337 LR: 9.98e-06\n",
      "Epoch   2 [8150/10697 ( 76.2%)] Loss: 0.021307 L1: 0.012545 Grad: 0.087446 Thermal: 0.000337 LR: 9.98e-06\n",
      "Epoch   2 [8200/10697 ( 76.7%)] Loss: 0.026609 L1: 0.015315 Grad: 0.112717 Thermal: 0.000452 LR: 9.98e-06\n",
      "Epoch   2 [8200/10697 ( 76.7%)] Loss: 0.026609 L1: 0.015315 Grad: 0.112717 Thermal: 0.000452 LR: 9.98e-06\n",
      "Epoch   2 [8250/10697 ( 77.1%)] Loss: 0.028893 L1: 0.016691 Grad: 0.121783 Thermal: 0.000483 LR: 9.98e-06\n",
      "Epoch   2 [8250/10697 ( 77.1%)] Loss: 0.028893 L1: 0.016691 Grad: 0.121783 Thermal: 0.000483 LR: 9.98e-06\n",
      "Epoch   2 [8300/10697 ( 77.6%)] Loss: 0.030662 L1: 0.018116 Grad: 0.125177 Thermal: 0.000574 LR: 9.98e-06\n",
      "Epoch   2 [8300/10697 ( 77.6%)] Loss: 0.030662 L1: 0.018116 Grad: 0.125177 Thermal: 0.000574 LR: 9.98e-06\n",
      "Epoch   2 [8350/10697 ( 78.1%)] Loss: 0.030474 L1: 0.017655 Grad: 0.127915 Thermal: 0.000542 LR: 9.98e-06\n",
      "Epoch   2 [8350/10697 ( 78.1%)] Loss: 0.030474 L1: 0.017655 Grad: 0.127915 Thermal: 0.000542 LR: 9.98e-06\n",
      "Epoch   2 [8400/10697 ( 78.5%)] Loss: 0.023656 L1: 0.013720 Grad: 0.099183 Thermal: 0.000347 LR: 9.98e-06\n",
      "Epoch   2 [8400/10697 ( 78.5%)] Loss: 0.023656 L1: 0.013720 Grad: 0.099183 Thermal: 0.000347 LR: 9.98e-06\n",
      "Epoch   2 [8450/10697 ( 79.0%)] Loss: 0.024518 L1: 0.014438 Grad: 0.100597 Thermal: 0.000392 LR: 9.98e-06\n",
      "Epoch   2 [8450/10697 ( 79.0%)] Loss: 0.024518 L1: 0.014438 Grad: 0.100597 Thermal: 0.000392 LR: 9.98e-06\n",
      "Epoch   2 [8500/10697 ( 79.5%)] Loss: 0.027524 L1: 0.016191 Grad: 0.113114 Thermal: 0.000432 LR: 9.98e-06\n",
      "Epoch   2 [8500/10697 ( 79.5%)] Loss: 0.027524 L1: 0.016191 Grad: 0.113114 Thermal: 0.000432 LR: 9.98e-06\n",
      "Epoch   2 [8550/10697 ( 79.9%)] Loss: 0.031372 L1: 0.018013 Grad: 0.133260 Thermal: 0.000665 LR: 9.98e-06\n",
      "Epoch   2 [8550/10697 ( 79.9%)] Loss: 0.031372 L1: 0.018013 Grad: 0.133260 Thermal: 0.000665 LR: 9.98e-06\n",
      "Epoch   2 [8600/10697 ( 80.4%)] Loss: 0.025715 L1: 0.015144 Grad: 0.105500 Thermal: 0.000421 LR: 9.98e-06\n",
      "Epoch   2 [8600/10697 ( 80.4%)] Loss: 0.025715 L1: 0.015144 Grad: 0.105500 Thermal: 0.000421 LR: 9.98e-06\n",
      "Epoch   2 [8650/10697 ( 80.9%)] Loss: 0.025314 L1: 0.014729 Grad: 0.105638 Thermal: 0.000419 LR: 9.98e-06\n",
      "Epoch   2 [8650/10697 ( 80.9%)] Loss: 0.025314 L1: 0.014729 Grad: 0.105638 Thermal: 0.000419 LR: 9.98e-06\n",
      "Epoch   2 [8700/10697 ( 81.3%)] Loss: 0.030217 L1: 0.017777 Grad: 0.124130 Thermal: 0.000547 LR: 9.98e-06\n",
      "Epoch   2 [8700/10697 ( 81.3%)] Loss: 0.030217 L1: 0.017777 Grad: 0.124130 Thermal: 0.000547 LR: 9.98e-06\n",
      "Epoch   2 [8750/10697 ( 81.8%)] Loss: 0.029171 L1: 0.016800 Grad: 0.123425 Thermal: 0.000555 LR: 9.98e-06\n",
      "Epoch   2 [8750/10697 ( 81.8%)] Loss: 0.029171 L1: 0.016800 Grad: 0.123425 Thermal: 0.000555 LR: 9.98e-06\n",
      "Epoch   2 [8800/10697 ( 82.3%)] Loss: 0.029478 L1: 0.017339 Grad: 0.121103 Thermal: 0.000571 LR: 9.98e-06\n",
      "Epoch   2 [8800/10697 ( 82.3%)] Loss: 0.029478 L1: 0.017339 Grad: 0.121103 Thermal: 0.000571 LR: 9.98e-06\n",
      "Epoch   2 [8850/10697 ( 82.7%)] Loss: 0.026591 L1: 0.015448 Grad: 0.111192 Thermal: 0.000489 LR: 9.98e-06\n",
      "Epoch   2 [8850/10697 ( 82.7%)] Loss: 0.026591 L1: 0.015448 Grad: 0.111192 Thermal: 0.000489 LR: 9.98e-06\n",
      "Epoch   2 [8900/10697 ( 83.2%)] Loss: 0.029416 L1: 0.017361 Grad: 0.120269 Thermal: 0.000561 LR: 9.98e-06\n",
      "Epoch   2 [8900/10697 ( 83.2%)] Loss: 0.029416 L1: 0.017361 Grad: 0.120269 Thermal: 0.000561 LR: 9.98e-06\n",
      "Epoch   2 [8950/10697 ( 83.7%)] Loss: 0.025290 L1: 0.014673 Grad: 0.105971 Thermal: 0.000408 LR: 9.98e-06\n",
      "Epoch   2 [8950/10697 ( 83.7%)] Loss: 0.025290 L1: 0.014673 Grad: 0.105971 Thermal: 0.000408 LR: 9.98e-06\n",
      "Epoch   2 [9000/10697 ( 84.1%)] Loss: 0.025563 L1: 0.014805 Grad: 0.107368 Thermal: 0.000418 LR: 9.98e-06\n",
      "Epoch   2 [9000/10697 ( 84.1%)] Loss: 0.025563 L1: 0.014805 Grad: 0.107368 Thermal: 0.000418 LR: 9.98e-06\n",
      "Epoch   2 [9050/10697 ( 84.6%)] Loss: 0.026135 L1: 0.014894 Grad: 0.112185 Thermal: 0.000446 LR: 9.98e-06\n",
      "Epoch   2 [9050/10697 ( 84.6%)] Loss: 0.026135 L1: 0.014894 Grad: 0.112185 Thermal: 0.000446 LR: 9.98e-06\n",
      "Epoch   2 [9100/10697 ( 85.1%)] Loss: 0.029160 L1: 0.016894 Grad: 0.122380 Thermal: 0.000567 LR: 9.98e-06\n",
      "Epoch   2 [9100/10697 ( 85.1%)] Loss: 0.029160 L1: 0.016894 Grad: 0.122380 Thermal: 0.000567 LR: 9.98e-06\n",
      "Epoch   2 [9150/10697 ( 85.5%)] Loss: 0.029704 L1: 0.016957 Grad: 0.127179 Thermal: 0.000584 LR: 9.98e-06\n",
      "Epoch   2 [9150/10697 ( 85.5%)] Loss: 0.029704 L1: 0.016957 Grad: 0.127179 Thermal: 0.000584 LR: 9.98e-06\n",
      "Epoch   2 [9200/10697 ( 86.0%)] Loss: 0.027359 L1: 0.015656 Grad: 0.116795 Thermal: 0.000485 LR: 9.98e-06\n",
      "Epoch   2 [9200/10697 ( 86.0%)] Loss: 0.027359 L1: 0.015656 Grad: 0.116795 Thermal: 0.000485 LR: 9.98e-06\n",
      "Epoch   2 [9250/10697 ( 86.5%)] Loss: 0.027286 L1: 0.015827 Grad: 0.114367 Thermal: 0.000449 LR: 9.98e-06\n",
      "Epoch   2 [9250/10697 ( 86.5%)] Loss: 0.027286 L1: 0.015827 Grad: 0.114367 Thermal: 0.000449 LR: 9.98e-06\n",
      "Epoch   2 [9300/10697 ( 86.9%)] Loss: 0.024201 L1: 0.014384 Grad: 0.097987 Thermal: 0.000377 LR: 9.98e-06\n",
      "Epoch   2 [9300/10697 ( 86.9%)] Loss: 0.024201 L1: 0.014384 Grad: 0.097987 Thermal: 0.000377 LR: 9.98e-06\n",
      "Epoch   2 [9350/10697 ( 87.4%)] Loss: 0.028362 L1: 0.016836 Grad: 0.114997 Thermal: 0.000529 LR: 9.98e-06\n",
      "Epoch   2 [9350/10697 ( 87.4%)] Loss: 0.028362 L1: 0.016836 Grad: 0.114997 Thermal: 0.000529 LR: 9.98e-06\n",
      "Epoch   2 [9400/10697 ( 87.9%)] Loss: 0.028311 L1: 0.016973 Grad: 0.113130 Thermal: 0.000506 LR: 9.98e-06\n",
      "Epoch   2 [9400/10697 ( 87.9%)] Loss: 0.028311 L1: 0.016973 Grad: 0.113130 Thermal: 0.000506 LR: 9.98e-06\n",
      "Epoch   2 [9450/10697 ( 88.3%)] Loss: 0.032799 L1: 0.018397 Grad: 0.143700 Thermal: 0.000624 LR: 9.98e-06\n",
      "Epoch   2 [9450/10697 ( 88.3%)] Loss: 0.032799 L1: 0.018397 Grad: 0.143700 Thermal: 0.000624 LR: 9.98e-06\n",
      "Epoch   2 [9500/10697 ( 88.8%)] Loss: 0.025891 L1: 0.015256 Grad: 0.106119 Thermal: 0.000465 LR: 9.98e-06\n",
      "Epoch   2 [9500/10697 ( 88.8%)] Loss: 0.025891 L1: 0.015256 Grad: 0.106119 Thermal: 0.000465 LR: 9.98e-06\n",
      "Epoch   2 [9550/10697 ( 89.3%)] Loss: 0.033060 L1: 0.019043 Grad: 0.139831 Thermal: 0.000685 LR: 9.98e-06\n",
      "Epoch   2 [9550/10697 ( 89.3%)] Loss: 0.033060 L1: 0.019043 Grad: 0.139831 Thermal: 0.000685 LR: 9.98e-06\n",
      "Epoch   2 [9600/10697 ( 89.7%)] Loss: 0.027994 L1: 0.016042 Grad: 0.119296 Thermal: 0.000455 LR: 9.98e-06\n",
      "Epoch   2 [9600/10697 ( 89.7%)] Loss: 0.027994 L1: 0.016042 Grad: 0.119296 Thermal: 0.000455 LR: 9.98e-06\n",
      "Epoch   2 [9650/10697 ( 90.2%)] Loss: 0.027409 L1: 0.015810 Grad: 0.115772 Thermal: 0.000428 LR: 9.98e-06\n",
      "Epoch   2 [9650/10697 ( 90.2%)] Loss: 0.027409 L1: 0.015810 Grad: 0.115772 Thermal: 0.000428 LR: 9.98e-06\n",
      "Epoch   2 [9700/10697 ( 90.7%)] Loss: 0.026974 L1: 0.015765 Grad: 0.111858 Thermal: 0.000465 LR: 9.98e-06\n",
      "Epoch   2 [9700/10697 ( 90.7%)] Loss: 0.026974 L1: 0.015765 Grad: 0.111858 Thermal: 0.000465 LR: 9.98e-06\n",
      "Epoch   2 [9750/10697 ( 91.1%)] Loss: 0.024969 L1: 0.014733 Grad: 0.102155 Thermal: 0.000400 LR: 9.98e-06\n",
      "Epoch   2 [9750/10697 ( 91.1%)] Loss: 0.024969 L1: 0.014733 Grad: 0.102155 Thermal: 0.000400 LR: 9.98e-06\n",
      "Epoch   2 [9800/10697 ( 91.6%)] Loss: 0.023176 L1: 0.013474 Grad: 0.096828 Thermal: 0.000374 LR: 9.98e-06\n",
      "Epoch   2 [9800/10697 ( 91.6%)] Loss: 0.023176 L1: 0.013474 Grad: 0.096828 Thermal: 0.000374 LR: 9.98e-06\n",
      "Epoch   2 [9850/10697 ( 92.1%)] Loss: 0.028802 L1: 0.017058 Grad: 0.117185 Thermal: 0.000499 LR: 9.98e-06\n",
      "Epoch   2 [9850/10697 ( 92.1%)] Loss: 0.028802 L1: 0.017058 Grad: 0.117185 Thermal: 0.000499 LR: 9.98e-06\n",
      "Epoch   2 [9900/10697 ( 92.5%)] Loss: 0.025003 L1: 0.014442 Grad: 0.105386 Thermal: 0.000443 LR: 9.98e-06\n",
      "Epoch   2 [9900/10697 ( 92.5%)] Loss: 0.025003 L1: 0.014442 Grad: 0.105386 Thermal: 0.000443 LR: 9.98e-06\n",
      "Epoch   2 [9950/10697 ( 93.0%)] Loss: 0.023662 L1: 0.013891 Grad: 0.097506 Thermal: 0.000396 LR: 9.98e-06\n",
      "Epoch   2 [9950/10697 ( 93.0%)] Loss: 0.023662 L1: 0.013891 Grad: 0.097506 Thermal: 0.000396 LR: 9.98e-06\n",
      "Epoch   2 [10000/10697 ( 93.5%)] Loss: 0.020244 L1: 0.011404 Grad: 0.088274 Thermal: 0.000264 LR: 9.98e-06\n",
      "Epoch   2 [10000/10697 ( 93.5%)] Loss: 0.020244 L1: 0.011404 Grad: 0.088274 Thermal: 0.000264 LR: 9.98e-06\n",
      "Epoch   2 [10050/10697 ( 94.0%)] Loss: 0.025119 L1: 0.014278 Grad: 0.108220 Thermal: 0.000378 LR: 9.98e-06\n",
      "Epoch   2 [10050/10697 ( 94.0%)] Loss: 0.025119 L1: 0.014278 Grad: 0.108220 Thermal: 0.000378 LR: 9.98e-06\n",
      "Epoch   2 [10100/10697 ( 94.4%)] Loss: 0.030907 L1: 0.017797 Grad: 0.130801 Thermal: 0.000579 LR: 9.98e-06\n",
      "Epoch   2 [10100/10697 ( 94.4%)] Loss: 0.030907 L1: 0.017797 Grad: 0.130801 Thermal: 0.000579 LR: 9.98e-06\n",
      "Epoch   2 [10150/10697 ( 94.9%)] Loss: 0.027795 L1: 0.016129 Grad: 0.116434 Thermal: 0.000450 LR: 9.98e-06\n",
      "Epoch   2 [10150/10697 ( 94.9%)] Loss: 0.027795 L1: 0.016129 Grad: 0.116434 Thermal: 0.000450 LR: 9.98e-06\n",
      "Epoch   2 [10200/10697 ( 95.4%)] Loss: 0.025364 L1: 0.014483 Grad: 0.108574 Thermal: 0.000458 LR: 9.98e-06\n",
      "Epoch   2 [10200/10697 ( 95.4%)] Loss: 0.025364 L1: 0.014483 Grad: 0.108574 Thermal: 0.000458 LR: 9.98e-06\n",
      "Epoch   2 [10250/10697 ( 95.8%)] Loss: 0.022557 L1: 0.013140 Grad: 0.094001 Thermal: 0.000339 LR: 9.98e-06\n",
      "Epoch   2 [10250/10697 ( 95.8%)] Loss: 0.022557 L1: 0.013140 Grad: 0.094001 Thermal: 0.000339 LR: 9.98e-06\n",
      "Epoch   2 [10300/10697 ( 96.3%)] Loss: 0.030833 L1: 0.018020 Grad: 0.127804 Thermal: 0.000636 LR: 9.98e-06\n",
      "Epoch   2 [10300/10697 ( 96.3%)] Loss: 0.030833 L1: 0.018020 Grad: 0.127804 Thermal: 0.000636 LR: 9.98e-06\n",
      "Epoch   2 [10350/10697 ( 96.8%)] Loss: 0.024815 L1: 0.014334 Grad: 0.104614 Thermal: 0.000395 LR: 9.98e-06\n",
      "Epoch   2 [10350/10697 ( 96.8%)] Loss: 0.024815 L1: 0.014334 Grad: 0.104614 Thermal: 0.000395 LR: 9.98e-06\n",
      "Epoch   2 [10400/10697 ( 97.2%)] Loss: 0.030549 L1: 0.017298 Grad: 0.132194 Thermal: 0.000632 LR: 9.98e-06\n",
      "Epoch   2 [10400/10697 ( 97.2%)] Loss: 0.030549 L1: 0.017298 Grad: 0.132194 Thermal: 0.000632 LR: 9.98e-06\n",
      "Epoch   2 [10450/10697 ( 97.7%)] Loss: 0.028429 L1: 0.016061 Grad: 0.123397 Thermal: 0.000564 LR: 9.98e-06\n",
      "Epoch   2 [10450/10697 ( 97.7%)] Loss: 0.028429 L1: 0.016061 Grad: 0.123397 Thermal: 0.000564 LR: 9.98e-06\n",
      "Epoch   2 [10500/10697 ( 98.2%)] Loss: 0.027806 L1: 0.016316 Grad: 0.114664 Thermal: 0.000474 LR: 9.98e-06\n",
      "Epoch   2 [10500/10697 ( 98.2%)] Loss: 0.027806 L1: 0.016316 Grad: 0.114664 Thermal: 0.000474 LR: 9.98e-06\n",
      "Epoch   2 [10550/10697 ( 98.6%)] Loss: 0.031050 L1: 0.017771 Grad: 0.132479 Thermal: 0.000625 LR: 9.98e-06\n",
      "Epoch   2 [10550/10697 ( 98.6%)] Loss: 0.031050 L1: 0.017771 Grad: 0.132479 Thermal: 0.000625 LR: 9.98e-06\n",
      "Epoch   2 [10600/10697 ( 99.1%)] Loss: 0.030538 L1: 0.017450 Grad: 0.130574 Thermal: 0.000592 LR: 9.98e-06\n",
      "Epoch   2 [10600/10697 ( 99.1%)] Loss: 0.030538 L1: 0.017450 Grad: 0.130574 Thermal: 0.000592 LR: 9.98e-06\n",
      "Epoch   2 [10650/10697 ( 99.6%)] Loss: 0.022334 L1: 0.013142 Grad: 0.091742 Thermal: 0.000368 LR: 9.98e-06\n",
      "Epoch   2 [10650/10697 ( 99.6%)] Loss: 0.022334 L1: 0.013142 Grad: 0.091742 Thermal: 0.000368 LR: 9.98e-06\n",
      "Epoch   2 Summary: Loss=0.027687 (L1:0.0161, Grad:0.1160, Thermal:0.0005) Val_PSNR=0.00dB Best=33.17dB Time=10.8min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch   2 Summary: Loss=0.027687 (L1:0.0161, Grad:0.1160, Thermal:0.0005) Val_PSNR=0.00dB Best=33.17dB Time=10.8min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch   3 [   0/10697 (  0.0%)] Loss: 0.025394 L1: 0.014908 Grad: 0.104658 Thermal: 0.000412 LR: 9.97e-06\n",
      "Epoch   3 [   0/10697 (  0.0%)] Loss: 0.025394 L1: 0.014908 Grad: 0.104658 Thermal: 0.000412 LR: 9.97e-06\n",
      "Epoch   3 [  50/10697 (  0.5%)] Loss: 0.021746 L1: 0.012754 Grad: 0.089761 Thermal: 0.000312 LR: 9.97e-06\n",
      "Epoch   3 [  50/10697 (  0.5%)] Loss: 0.021746 L1: 0.012754 Grad: 0.089761 Thermal: 0.000312 LR: 9.97e-06\n",
      "Epoch   3 [ 100/10697 (  0.9%)] Loss: 0.026536 L1: 0.015515 Grad: 0.109990 Thermal: 0.000440 LR: 9.97e-06\n",
      "Epoch   3 [ 100/10697 (  0.9%)] Loss: 0.026536 L1: 0.015515 Grad: 0.109990 Thermal: 0.000440 LR: 9.97e-06\n",
      "Epoch   3 [ 150/10697 (  1.4%)] Loss: 0.021221 L1: 0.012044 Grad: 0.091622 Thermal: 0.000294 LR: 9.97e-06\n",
      "Epoch   3 [ 150/10697 (  1.4%)] Loss: 0.021221 L1: 0.012044 Grad: 0.091622 Thermal: 0.000294 LR: 9.97e-06\n",
      "Epoch   3 [ 200/10697 (  1.9%)] Loss: 0.027817 L1: 0.016349 Grad: 0.114438 Thermal: 0.000483 LR: 9.97e-06\n",
      "Epoch   3 [ 200/10697 (  1.9%)] Loss: 0.027817 L1: 0.016349 Grad: 0.114438 Thermal: 0.000483 LR: 9.97e-06\n",
      "Epoch   3 [ 250/10697 (  2.3%)] Loss: 0.030423 L1: 0.017300 Grad: 0.130952 Thermal: 0.000565 LR: 9.97e-06\n",
      "Epoch   3 [ 250/10697 (  2.3%)] Loss: 0.030423 L1: 0.017300 Grad: 0.130952 Thermal: 0.000565 LR: 9.97e-06\n",
      "Epoch   3 [ 300/10697 (  2.8%)] Loss: 0.027317 L1: 0.015992 Grad: 0.113016 Thermal: 0.000484 LR: 9.97e-06\n",
      "Epoch   3 [ 300/10697 (  2.8%)] Loss: 0.027317 L1: 0.015992 Grad: 0.113016 Thermal: 0.000484 LR: 9.97e-06\n",
      "Epoch   3 [ 350/10697 (  3.3%)] Loss: 0.029212 L1: 0.017027 Grad: 0.121582 Thermal: 0.000532 LR: 9.97e-06\n",
      "Epoch   3 [ 350/10697 (  3.3%)] Loss: 0.029212 L1: 0.017027 Grad: 0.121582 Thermal: 0.000532 LR: 9.97e-06\n",
      "Epoch   3 [ 400/10697 (  3.7%)] Loss: 0.024388 L1: 0.014259 Grad: 0.101081 Thermal: 0.000424 LR: 9.97e-06\n",
      "Epoch   3 [ 400/10697 (  3.7%)] Loss: 0.024388 L1: 0.014259 Grad: 0.101081 Thermal: 0.000424 LR: 9.97e-06\n",
      "Epoch   3 [ 450/10697 (  4.2%)] Loss: 0.030803 L1: 0.018091 Grad: 0.126827 Thermal: 0.000589 LR: 9.97e-06\n",
      "Epoch   3 [ 450/10697 (  4.2%)] Loss: 0.030803 L1: 0.018091 Grad: 0.126827 Thermal: 0.000589 LR: 9.97e-06\n",
      "Epoch   3 [ 500/10697 (  4.7%)] Loss: 0.022104 L1: 0.012774 Grad: 0.093131 Thermal: 0.000341 LR: 9.97e-06\n",
      "Epoch   3 [ 500/10697 (  4.7%)] Loss: 0.022104 L1: 0.012774 Grad: 0.093131 Thermal: 0.000341 LR: 9.97e-06\n",
      "Epoch   3 [ 550/10697 (  5.1%)] Loss: 0.025780 L1: 0.015110 Grad: 0.106496 Thermal: 0.000399 LR: 9.97e-06\n",
      "Epoch   3 [ 550/10697 (  5.1%)] Loss: 0.025780 L1: 0.015110 Grad: 0.106496 Thermal: 0.000399 LR: 9.97e-06\n",
      "Epoch   3 [ 600/10697 (  5.6%)] Loss: 0.023852 L1: 0.014368 Grad: 0.094647 Thermal: 0.000399 LR: 9.97e-06\n",
      "Epoch   3 [ 600/10697 (  5.6%)] Loss: 0.023852 L1: 0.014368 Grad: 0.094647 Thermal: 0.000399 LR: 9.97e-06\n",
      "Epoch   3 [ 650/10697 (  6.1%)] Loss: 0.030097 L1: 0.018277 Grad: 0.117903 Thermal: 0.000580 LR: 9.97e-06\n",
      "Epoch   3 [ 650/10697 (  6.1%)] Loss: 0.030097 L1: 0.018277 Grad: 0.117903 Thermal: 0.000580 LR: 9.97e-06\n",
      "Epoch   3 [ 700/10697 (  6.5%)] Loss: 0.019819 L1: 0.011218 Grad: 0.085880 Thermal: 0.000248 LR: 9.97e-06\n",
      "Epoch   3 [ 700/10697 (  6.5%)] Loss: 0.019819 L1: 0.011218 Grad: 0.085880 Thermal: 0.000248 LR: 9.97e-06\n",
      "Epoch   3 [ 750/10697 (  7.0%)] Loss: 0.030206 L1: 0.017326 Grad: 0.128530 Thermal: 0.000540 LR: 9.97e-06\n",
      "Epoch   3 [ 750/10697 (  7.0%)] Loss: 0.030206 L1: 0.017326 Grad: 0.128530 Thermal: 0.000540 LR: 9.97e-06\n",
      "Epoch   3 [ 800/10697 (  7.5%)] Loss: 0.019450 L1: 0.011428 Grad: 0.080065 Thermal: 0.000297 LR: 9.97e-06\n",
      "Epoch   3 [ 800/10697 (  7.5%)] Loss: 0.019450 L1: 0.011428 Grad: 0.080065 Thermal: 0.000297 LR: 9.97e-06\n",
      "Epoch   3 [ 850/10697 (  7.9%)] Loss: 0.027812 L1: 0.015917 Grad: 0.118702 Thermal: 0.000483 LR: 9.97e-06\n",
      "Epoch   3 [ 850/10697 (  7.9%)] Loss: 0.027812 L1: 0.015917 Grad: 0.118702 Thermal: 0.000483 LR: 9.97e-06\n",
      "Epoch   3 [ 900/10697 (  8.4%)] Loss: 0.027617 L1: 0.016042 Grad: 0.115520 Thermal: 0.000457 LR: 9.97e-06\n",
      "Epoch   3 [ 900/10697 (  8.4%)] Loss: 0.027617 L1: 0.016042 Grad: 0.115520 Thermal: 0.000457 LR: 9.97e-06\n",
      "Epoch   3 [ 950/10697 (  8.9%)] Loss: 0.030433 L1: 0.017305 Grad: 0.130966 Thermal: 0.000613 LR: 9.97e-06\n",
      "Epoch   3 [ 950/10697 (  8.9%)] Loss: 0.030433 L1: 0.017305 Grad: 0.130966 Thermal: 0.000613 LR: 9.97e-06\n",
      "Epoch   3 [1000/10697 (  9.3%)] Loss: 0.028303 L1: 0.016386 Grad: 0.118948 Thermal: 0.000442 LR: 9.97e-06\n",
      "Epoch   3 [1000/10697 (  9.3%)] Loss: 0.028303 L1: 0.016386 Grad: 0.118948 Thermal: 0.000442 LR: 9.97e-06\n",
      "Epoch   3 [1050/10697 (  9.8%)] Loss: 0.028001 L1: 0.016097 Grad: 0.118762 Thermal: 0.000553 LR: 9.97e-06\n",
      "Epoch   3 [1050/10697 (  9.8%)] Loss: 0.028001 L1: 0.016097 Grad: 0.118762 Thermal: 0.000553 LR: 9.97e-06\n",
      "Epoch   3 [1100/10697 ( 10.3%)] Loss: 0.029517 L1: 0.017178 Grad: 0.123132 Thermal: 0.000531 LR: 9.97e-06\n",
      "Epoch   3 [1100/10697 ( 10.3%)] Loss: 0.029517 L1: 0.017178 Grad: 0.123132 Thermal: 0.000531 LR: 9.97e-06\n",
      "Epoch   3 [1150/10697 ( 10.8%)] Loss: 0.029418 L1: 0.017061 Grad: 0.123302 Thermal: 0.000540 LR: 9.97e-06\n",
      "Epoch   3 [1150/10697 ( 10.8%)] Loss: 0.029418 L1: 0.017061 Grad: 0.123302 Thermal: 0.000540 LR: 9.97e-06\n",
      "Epoch   3 [1200/10697 ( 11.2%)] Loss: 0.028464 L1: 0.016359 Grad: 0.120806 Thermal: 0.000491 LR: 9.97e-06\n",
      "Epoch   3 [1200/10697 ( 11.2%)] Loss: 0.028464 L1: 0.016359 Grad: 0.120806 Thermal: 0.000491 LR: 9.97e-06\n",
      "Epoch   3 [1250/10697 ( 11.7%)] Loss: 0.026257 L1: 0.015482 Grad: 0.107537 Thermal: 0.000441 LR: 9.97e-06\n",
      "Epoch   3 [1250/10697 ( 11.7%)] Loss: 0.026257 L1: 0.015482 Grad: 0.107537 Thermal: 0.000441 LR: 9.97e-06\n",
      "Epoch   3 [1300/10697 ( 12.2%)] Loss: 0.026886 L1: 0.016056 Grad: 0.108062 Thermal: 0.000488 LR: 9.97e-06\n",
      "Epoch   3 [1300/10697 ( 12.2%)] Loss: 0.026886 L1: 0.016056 Grad: 0.108062 Thermal: 0.000488 LR: 9.97e-06\n",
      "Epoch   3 [1350/10697 ( 12.6%)] Loss: 0.028414 L1: 0.016309 Grad: 0.120809 Thermal: 0.000487 LR: 9.97e-06\n",
      "Epoch   3 [1350/10697 ( 12.6%)] Loss: 0.028414 L1: 0.016309 Grad: 0.120809 Thermal: 0.000487 LR: 9.97e-06\n",
      "Epoch   3 [1400/10697 ( 13.1%)] Loss: 0.022483 L1: 0.013080 Grad: 0.093866 Thermal: 0.000341 LR: 9.97e-06\n",
      "Epoch   3 [1400/10697 ( 13.1%)] Loss: 0.022483 L1: 0.013080 Grad: 0.093866 Thermal: 0.000341 LR: 9.97e-06\n",
      "Epoch   3 [1450/10697 ( 13.6%)] Loss: 0.044590 L1: 0.025723 Grad: 0.188021 Thermal: 0.001310 LR: 9.97e-06\n",
      "Epoch   3 [1450/10697 ( 13.6%)] Loss: 0.044590 L1: 0.025723 Grad: 0.188021 Thermal: 0.001310 LR: 9.97e-06\n",
      "Epoch   3 [1500/10697 ( 14.0%)] Loss: 0.030230 L1: 0.017524 Grad: 0.126759 Thermal: 0.000593 LR: 9.97e-06\n",
      "Epoch   3 [1500/10697 ( 14.0%)] Loss: 0.030230 L1: 0.017524 Grad: 0.126759 Thermal: 0.000593 LR: 9.97e-06\n",
      "Epoch   3 [1550/10697 ( 14.5%)] Loss: 0.024640 L1: 0.014534 Grad: 0.100854 Thermal: 0.000399 LR: 9.97e-06\n",
      "Epoch   3 [1550/10697 ( 14.5%)] Loss: 0.024640 L1: 0.014534 Grad: 0.100854 Thermal: 0.000399 LR: 9.97e-06\n",
      "Epoch   3 [1600/10697 ( 15.0%)] Loss: 0.027689 L1: 0.016025 Grad: 0.116390 Thermal: 0.000512 LR: 9.97e-06\n",
      "Epoch   3 [1600/10697 ( 15.0%)] Loss: 0.027689 L1: 0.016025 Grad: 0.116390 Thermal: 0.000512 LR: 9.97e-06\n",
      "Epoch   3 [1650/10697 ( 15.4%)] Loss: 0.027533 L1: 0.016385 Grad: 0.111237 Thermal: 0.000486 LR: 9.97e-06\n",
      "Epoch   3 [1650/10697 ( 15.4%)] Loss: 0.027533 L1: 0.016385 Grad: 0.111237 Thermal: 0.000486 LR: 9.97e-06\n",
      "Epoch   3 [1700/10697 ( 15.9%)] Loss: 0.033164 L1: 0.018899 Grad: 0.142274 Thermal: 0.000750 LR: 9.97e-06\n",
      "Epoch   3 [1700/10697 ( 15.9%)] Loss: 0.033164 L1: 0.018899 Grad: 0.142274 Thermal: 0.000750 LR: 9.97e-06\n",
      "Epoch   3 [1750/10697 ( 16.4%)] Loss: 0.030021 L1: 0.016850 Grad: 0.131411 Thermal: 0.000609 LR: 9.97e-06\n",
      "Epoch   3 [1750/10697 ( 16.4%)] Loss: 0.030021 L1: 0.016850 Grad: 0.131411 Thermal: 0.000609 LR: 9.97e-06\n",
      "Epoch   3 [1800/10697 ( 16.8%)] Loss: 0.030064 L1: 0.017081 Grad: 0.129560 Thermal: 0.000539 LR: 9.97e-06\n",
      "Epoch   3 [1800/10697 ( 16.8%)] Loss: 0.030064 L1: 0.017081 Grad: 0.129560 Thermal: 0.000539 LR: 9.97e-06\n",
      "Epoch   3 [1850/10697 ( 17.3%)] Loss: 0.026903 L1: 0.015642 Grad: 0.112384 Thermal: 0.000451 LR: 9.97e-06\n",
      "Epoch   3 [1850/10697 ( 17.3%)] Loss: 0.026903 L1: 0.015642 Grad: 0.112384 Thermal: 0.000451 LR: 9.97e-06\n",
      "Epoch   3 [1900/10697 ( 17.8%)] Loss: 0.029495 L1: 0.017338 Grad: 0.121313 Thermal: 0.000517 LR: 9.97e-06\n",
      "Epoch   3 [1900/10697 ( 17.8%)] Loss: 0.029495 L1: 0.017338 Grad: 0.121313 Thermal: 0.000517 LR: 9.97e-06\n",
      "Epoch   3 [1950/10697 ( 18.2%)] Loss: 0.025679 L1: 0.014714 Grad: 0.109437 Thermal: 0.000437 LR: 9.97e-06\n",
      "Epoch   3 [1950/10697 ( 18.2%)] Loss: 0.025679 L1: 0.014714 Grad: 0.109437 Thermal: 0.000437 LR: 9.97e-06\n",
      "Epoch   3 [2000/10697 ( 18.7%)] Loss: 0.026711 L1: 0.015991 Grad: 0.106984 Thermal: 0.000446 LR: 9.97e-06\n",
      "Epoch   3 [2000/10697 ( 18.7%)] Loss: 0.026711 L1: 0.015991 Grad: 0.106984 Thermal: 0.000446 LR: 9.97e-06\n",
      "Epoch   3 [2050/10697 ( 19.2%)] Loss: 0.022775 L1: 0.013564 Grad: 0.091930 Thermal: 0.000359 LR: 9.97e-06\n",
      "Epoch   3 [2050/10697 ( 19.2%)] Loss: 0.022775 L1: 0.013564 Grad: 0.091930 Thermal: 0.000359 LR: 9.97e-06\n",
      "Epoch   3 [2100/10697 ( 19.6%)] Loss: 0.026493 L1: 0.015181 Grad: 0.112899 Thermal: 0.000436 LR: 9.97e-06\n",
      "Epoch   3 [2100/10697 ( 19.6%)] Loss: 0.026493 L1: 0.015181 Grad: 0.112899 Thermal: 0.000436 LR: 9.97e-06\n",
      "Epoch   3 [2150/10697 ( 20.1%)] Loss: 0.027696 L1: 0.015729 Grad: 0.119438 Thermal: 0.000452 LR: 9.97e-06\n",
      "Epoch   3 [2150/10697 ( 20.1%)] Loss: 0.027696 L1: 0.015729 Grad: 0.119438 Thermal: 0.000452 LR: 9.97e-06\n",
      "Epoch   3 [2200/10697 ( 20.6%)] Loss: 0.027703 L1: 0.016303 Grad: 0.113748 Thermal: 0.000516 LR: 9.97e-06\n",
      "Epoch   3 [2200/10697 ( 20.6%)] Loss: 0.027703 L1: 0.016303 Grad: 0.113748 Thermal: 0.000516 LR: 9.97e-06\n",
      "Epoch   3 [2250/10697 ( 21.0%)] Loss: 0.029777 L1: 0.017097 Grad: 0.126520 Thermal: 0.000557 LR: 9.97e-06\n",
      "Epoch   3 [2250/10697 ( 21.0%)] Loss: 0.029777 L1: 0.017097 Grad: 0.126520 Thermal: 0.000557 LR: 9.97e-06\n",
      "Epoch   3 [2300/10697 ( 21.5%)] Loss: 0.023041 L1: 0.013614 Grad: 0.094074 Thermal: 0.000384 LR: 9.97e-06\n",
      "Epoch   3 [2300/10697 ( 21.5%)] Loss: 0.023041 L1: 0.013614 Grad: 0.094074 Thermal: 0.000384 LR: 9.97e-06\n",
      "Epoch   3 [2350/10697 ( 22.0%)] Loss: 0.034572 L1: 0.019635 Grad: 0.149026 Thermal: 0.000702 LR: 9.97e-06\n",
      "Epoch   3 [2350/10697 ( 22.0%)] Loss: 0.034572 L1: 0.019635 Grad: 0.149026 Thermal: 0.000702 LR: 9.97e-06\n",
      "Epoch   3 [2400/10697 ( 22.4%)] Loss: 0.028534 L1: 0.016982 Grad: 0.115265 Thermal: 0.000503 LR: 9.97e-06\n",
      "Epoch   3 [2400/10697 ( 22.4%)] Loss: 0.028534 L1: 0.016982 Grad: 0.115265 Thermal: 0.000503 LR: 9.97e-06\n",
      "Epoch   3 [2450/10697 ( 22.9%)] Loss: 0.029133 L1: 0.017324 Grad: 0.117796 Thermal: 0.000592 LR: 9.97e-06\n",
      "Epoch   3 [2450/10697 ( 22.9%)] Loss: 0.029133 L1: 0.017324 Grad: 0.117796 Thermal: 0.000592 LR: 9.97e-06\n",
      "Epoch   3 [2500/10697 ( 23.4%)] Loss: 0.022675 L1: 0.013062 Grad: 0.095963 Thermal: 0.000338 LR: 9.97e-06\n",
      "Epoch   3 [2500/10697 ( 23.4%)] Loss: 0.022675 L1: 0.013062 Grad: 0.095963 Thermal: 0.000338 LR: 9.97e-06\n",
      "Epoch   3 [2550/10697 ( 23.8%)] Loss: 0.026404 L1: 0.014844 Grad: 0.115384 Thermal: 0.000442 LR: 9.97e-06\n",
      "Epoch   3 [2550/10697 ( 23.8%)] Loss: 0.026404 L1: 0.014844 Grad: 0.115384 Thermal: 0.000442 LR: 9.97e-06\n",
      "Epoch   3 [2600/10697 ( 24.3%)] Loss: 0.024632 L1: 0.014347 Grad: 0.102653 Thermal: 0.000396 LR: 9.97e-06\n",
      "Epoch   3 [2600/10697 ( 24.3%)] Loss: 0.024632 L1: 0.014347 Grad: 0.102653 Thermal: 0.000396 LR: 9.97e-06\n",
      "Epoch   3 [2650/10697 ( 24.8%)] Loss: 0.027980 L1: 0.016633 Grad: 0.113219 Thermal: 0.000510 LR: 9.97e-06\n",
      "Epoch   3 [2650/10697 ( 24.8%)] Loss: 0.027980 L1: 0.016633 Grad: 0.113219 Thermal: 0.000510 LR: 9.97e-06\n",
      "Epoch   3 [2700/10697 ( 25.2%)] Loss: 0.020853 L1: 0.011967 Grad: 0.088703 Thermal: 0.000324 LR: 9.97e-06\n",
      "Epoch   3 [2700/10697 ( 25.2%)] Loss: 0.020853 L1: 0.011967 Grad: 0.088703 Thermal: 0.000324 LR: 9.97e-06\n",
      "Epoch   3 [2750/10697 ( 25.7%)] Loss: 0.021939 L1: 0.012690 Grad: 0.092327 Thermal: 0.000316 LR: 9.97e-06\n",
      "Epoch   3 [2750/10697 ( 25.7%)] Loss: 0.021939 L1: 0.012690 Grad: 0.092327 Thermal: 0.000316 LR: 9.97e-06\n",
      "Epoch   3 [2800/10697 ( 26.2%)] Loss: 0.036227 L1: 0.020905 Grad: 0.152784 Thermal: 0.000865 LR: 9.97e-06\n",
      "Epoch   3 [2800/10697 ( 26.2%)] Loss: 0.036227 L1: 0.020905 Grad: 0.152784 Thermal: 0.000865 LR: 9.97e-06\n",
      "Epoch   3 [2850/10697 ( 26.6%)] Loss: 0.029691 L1: 0.017442 Grad: 0.122219 Thermal: 0.000530 LR: 9.97e-06\n",
      "Epoch   3 [2850/10697 ( 26.6%)] Loss: 0.029691 L1: 0.017442 Grad: 0.122219 Thermal: 0.000530 LR: 9.97e-06\n",
      "Epoch   3 [2900/10697 ( 27.1%)] Loss: 0.029289 L1: 0.017293 Grad: 0.119704 Thermal: 0.000508 LR: 9.97e-06\n",
      "Epoch   3 [2900/10697 ( 27.1%)] Loss: 0.029289 L1: 0.017293 Grad: 0.119704 Thermal: 0.000508 LR: 9.97e-06\n",
      "Epoch   3 [2950/10697 ( 27.6%)] Loss: 0.024701 L1: 0.014273 Grad: 0.104067 Thermal: 0.000422 LR: 9.97e-06\n",
      "Epoch   3 [2950/10697 ( 27.6%)] Loss: 0.024701 L1: 0.014273 Grad: 0.104067 Thermal: 0.000422 LR: 9.97e-06\n",
      "Epoch   3 [3000/10697 ( 28.0%)] Loss: 0.022728 L1: 0.013521 Grad: 0.091878 Thermal: 0.000366 LR: 9.97e-06\n",
      "Epoch   3 [3000/10697 ( 28.0%)] Loss: 0.022728 L1: 0.013521 Grad: 0.091878 Thermal: 0.000366 LR: 9.97e-06\n",
      "Epoch   3 [3050/10697 ( 28.5%)] Loss: 0.023349 L1: 0.013291 Grad: 0.100413 Thermal: 0.000326 LR: 9.97e-06\n",
      "Epoch   3 [3050/10697 ( 28.5%)] Loss: 0.023349 L1: 0.013291 Grad: 0.100413 Thermal: 0.000326 LR: 9.97e-06\n",
      "Epoch   3 [3100/10697 ( 29.0%)] Loss: 0.029963 L1: 0.017610 Grad: 0.123245 Thermal: 0.000563 LR: 9.97e-06\n",
      "Epoch   3 [3100/10697 ( 29.0%)] Loss: 0.029963 L1: 0.017610 Grad: 0.123245 Thermal: 0.000563 LR: 9.97e-06\n",
      "Epoch   3 [3150/10697 ( 29.4%)] Loss: 0.025353 L1: 0.014847 Grad: 0.104848 Thermal: 0.000406 LR: 9.97e-06\n",
      "Epoch   3 [3150/10697 ( 29.4%)] Loss: 0.025353 L1: 0.014847 Grad: 0.104848 Thermal: 0.000406 LR: 9.97e-06\n",
      "Epoch   3 [3200/10697 ( 29.9%)] Loss: 0.027986 L1: 0.016379 Grad: 0.115851 Thermal: 0.000446 LR: 9.97e-06\n",
      "Epoch   3 [3200/10697 ( 29.9%)] Loss: 0.027986 L1: 0.016379 Grad: 0.115851 Thermal: 0.000446 LR: 9.97e-06\n",
      "Epoch   3 [3250/10697 ( 30.4%)] Loss: 0.021546 L1: 0.012483 Grad: 0.090462 Thermal: 0.000331 LR: 9.97e-06\n",
      "Epoch   3 [3250/10697 ( 30.4%)] Loss: 0.021546 L1: 0.012483 Grad: 0.090462 Thermal: 0.000331 LR: 9.97e-06\n",
      "Epoch   3 [3300/10697 ( 30.8%)] Loss: 0.025600 L1: 0.014354 Grad: 0.112253 Thermal: 0.000404 LR: 9.97e-06\n",
      "Epoch   3 [3300/10697 ( 30.8%)] Loss: 0.025600 L1: 0.014354 Grad: 0.112253 Thermal: 0.000404 LR: 9.97e-06\n",
      "Epoch   3 [3350/10697 ( 31.3%)] Loss: 0.034094 L1: 0.019354 Grad: 0.147048 Thermal: 0.000695 LR: 9.97e-06\n",
      "Epoch   3 [3350/10697 ( 31.3%)] Loss: 0.034094 L1: 0.019354 Grad: 0.147048 Thermal: 0.000695 LR: 9.97e-06\n",
      "Epoch   3 [3400/10697 ( 31.8%)] Loss: 0.022778 L1: 0.013108 Grad: 0.096526 Thermal: 0.000348 LR: 9.97e-06\n",
      "Epoch   3 [3400/10697 ( 31.8%)] Loss: 0.022778 L1: 0.013108 Grad: 0.096526 Thermal: 0.000348 LR: 9.97e-06\n",
      "Epoch   3 [3450/10697 ( 32.3%)] Loss: 0.029574 L1: 0.017276 Grad: 0.122713 Thermal: 0.000520 LR: 9.97e-06\n",
      "Epoch   3 [3450/10697 ( 32.3%)] Loss: 0.029574 L1: 0.017276 Grad: 0.122713 Thermal: 0.000520 LR: 9.97e-06\n",
      "Epoch   3 [3500/10697 ( 32.7%)] Loss: 0.037498 L1: 0.021446 Grad: 0.160099 Thermal: 0.000842 LR: 9.97e-06\n",
      "Epoch   3 [3500/10697 ( 32.7%)] Loss: 0.037498 L1: 0.021446 Grad: 0.160099 Thermal: 0.000842 LR: 9.97e-06\n",
      "Epoch   3 [3550/10697 ( 33.2%)] Loss: 0.024256 L1: 0.014134 Grad: 0.101015 Thermal: 0.000393 LR: 9.97e-06\n",
      "Epoch   3 [3550/10697 ( 33.2%)] Loss: 0.024256 L1: 0.014134 Grad: 0.101015 Thermal: 0.000393 LR: 9.97e-06\n",
      "Epoch   3 [3600/10697 ( 33.7%)] Loss: 0.023295 L1: 0.013185 Grad: 0.100939 Thermal: 0.000322 LR: 9.97e-06\n",
      "Epoch   3 [3600/10697 ( 33.7%)] Loss: 0.023295 L1: 0.013185 Grad: 0.100939 Thermal: 0.000322 LR: 9.97e-06\n",
      "Epoch   3 [3650/10697 ( 34.1%)] Loss: 0.026171 L1: 0.014901 Grad: 0.112462 Thermal: 0.000481 LR: 9.97e-06\n",
      "Epoch   3 [3650/10697 ( 34.1%)] Loss: 0.026171 L1: 0.014901 Grad: 0.112462 Thermal: 0.000481 LR: 9.97e-06\n",
      "Epoch   3 [3700/10697 ( 34.6%)] Loss: 0.024809 L1: 0.014650 Grad: 0.101379 Thermal: 0.000410 LR: 9.97e-06\n",
      "Epoch   3 [3700/10697 ( 34.6%)] Loss: 0.024809 L1: 0.014650 Grad: 0.101379 Thermal: 0.000410 LR: 9.97e-06\n",
      "Epoch   3 [3750/10697 ( 35.1%)] Loss: 0.023493 L1: 0.013851 Grad: 0.096217 Thermal: 0.000407 LR: 9.97e-06\n",
      "Epoch   3 [3750/10697 ( 35.1%)] Loss: 0.023493 L1: 0.013851 Grad: 0.096217 Thermal: 0.000407 LR: 9.97e-06\n",
      "Epoch   3 [3800/10697 ( 35.5%)] Loss: 0.026909 L1: 0.015318 Grad: 0.115686 Thermal: 0.000438 LR: 9.97e-06\n",
      "Epoch   3 [3800/10697 ( 35.5%)] Loss: 0.026909 L1: 0.015318 Grad: 0.115686 Thermal: 0.000438 LR: 9.97e-06\n",
      "Epoch   3 [3850/10697 ( 36.0%)] Loss: 0.031434 L1: 0.018019 Grad: 0.133849 Thermal: 0.000602 LR: 9.97e-06\n",
      "Epoch   3 [3850/10697 ( 36.0%)] Loss: 0.031434 L1: 0.018019 Grad: 0.133849 Thermal: 0.000602 LR: 9.97e-06\n",
      "Epoch   3 [3900/10697 ( 36.5%)] Loss: 0.024767 L1: 0.014451 Grad: 0.102961 Thermal: 0.000406 LR: 9.97e-06\n",
      "Epoch   3 [3900/10697 ( 36.5%)] Loss: 0.024767 L1: 0.014451 Grad: 0.102961 Thermal: 0.000406 LR: 9.97e-06\n",
      "Epoch   3 [3950/10697 ( 36.9%)] Loss: 0.028122 L1: 0.016018 Grad: 0.120801 Thermal: 0.000484 LR: 9.97e-06\n",
      "Epoch   3 [3950/10697 ( 36.9%)] Loss: 0.028122 L1: 0.016018 Grad: 0.120801 Thermal: 0.000484 LR: 9.97e-06\n",
      "Epoch   3 [4000/10697 ( 37.4%)] Loss: 0.025584 L1: 0.014849 Grad: 0.107125 Thermal: 0.000466 LR: 9.97e-06\n",
      "Epoch   3 [4000/10697 ( 37.4%)] Loss: 0.025584 L1: 0.014849 Grad: 0.107125 Thermal: 0.000466 LR: 9.97e-06\n",
      "Epoch   3 [4050/10697 ( 37.9%)] Loss: 0.019171 L1: 0.011096 Grad: 0.080619 Thermal: 0.000268 LR: 9.97e-06\n",
      "Epoch   3 [4050/10697 ( 37.9%)] Loss: 0.019171 L1: 0.011096 Grad: 0.080619 Thermal: 0.000268 LR: 9.97e-06\n",
      "Epoch   3 [4100/10697 ( 38.3%)] Loss: 0.026750 L1: 0.015190 Grad: 0.115409 Thermal: 0.000399 LR: 9.97e-06\n",
      "Epoch   3 [4100/10697 ( 38.3%)] Loss: 0.026750 L1: 0.015190 Grad: 0.115409 Thermal: 0.000399 LR: 9.97e-06\n",
      "Epoch   3 [4150/10697 ( 38.8%)] Loss: 0.028897 L1: 0.016463 Grad: 0.124098 Thermal: 0.000486 LR: 9.97e-06\n",
      "Epoch   3 [4150/10697 ( 38.8%)] Loss: 0.028897 L1: 0.016463 Grad: 0.124098 Thermal: 0.000486 LR: 9.97e-06\n",
      "Epoch   3 [4200/10697 ( 39.3%)] Loss: 0.022399 L1: 0.013094 Grad: 0.092880 Thermal: 0.000348 LR: 9.97e-06\n",
      "Epoch   3 [4200/10697 ( 39.3%)] Loss: 0.022399 L1: 0.013094 Grad: 0.092880 Thermal: 0.000348 LR: 9.97e-06\n",
      "Epoch   3 [4250/10697 ( 39.7%)] Loss: 0.028246 L1: 0.016237 Grad: 0.119825 Thermal: 0.000522 LR: 9.97e-06\n",
      "Epoch   3 [4250/10697 ( 39.7%)] Loss: 0.028246 L1: 0.016237 Grad: 0.119825 Thermal: 0.000522 LR: 9.97e-06\n",
      "Epoch   3 [4300/10697 ( 40.2%)] Loss: 0.025000 L1: 0.014562 Grad: 0.104189 Thermal: 0.000395 LR: 9.97e-06\n",
      "Epoch   3 [4300/10697 ( 40.2%)] Loss: 0.025000 L1: 0.014562 Grad: 0.104189 Thermal: 0.000395 LR: 9.97e-06\n",
      "Epoch   3 [4350/10697 ( 40.7%)] Loss: 0.024464 L1: 0.013847 Grad: 0.105976 Thermal: 0.000386 LR: 9.97e-06\n",
      "Epoch   3 [4350/10697 ( 40.7%)] Loss: 0.024464 L1: 0.013847 Grad: 0.105976 Thermal: 0.000386 LR: 9.97e-06\n",
      "Epoch   3 [4400/10697 ( 41.1%)] Loss: 0.032820 L1: 0.018649 Grad: 0.141369 Thermal: 0.000681 LR: 9.97e-06\n",
      "Epoch   3 [4400/10697 ( 41.1%)] Loss: 0.032820 L1: 0.018649 Grad: 0.141369 Thermal: 0.000681 LR: 9.97e-06\n",
      "Epoch   3 [4450/10697 ( 41.6%)] Loss: 0.031279 L1: 0.018099 Grad: 0.131484 Thermal: 0.000632 LR: 9.97e-06\n",
      "Epoch   3 [4450/10697 ( 41.6%)] Loss: 0.031279 L1: 0.018099 Grad: 0.131484 Thermal: 0.000632 LR: 9.97e-06\n",
      "Epoch   3 [4500/10697 ( 42.1%)] Loss: 0.027933 L1: 0.016159 Grad: 0.117530 Thermal: 0.000424 LR: 9.97e-06\n",
      "Epoch   3 [4500/10697 ( 42.1%)] Loss: 0.027933 L1: 0.016159 Grad: 0.117530 Thermal: 0.000424 LR: 9.97e-06\n",
      "Epoch   3 [4550/10697 ( 42.5%)] Loss: 0.030606 L1: 0.017914 Grad: 0.126626 Thermal: 0.000580 LR: 9.97e-06\n",
      "Epoch   3 [4550/10697 ( 42.5%)] Loss: 0.030606 L1: 0.017914 Grad: 0.126626 Thermal: 0.000580 LR: 9.97e-06\n",
      "Epoch   3 [4600/10697 ( 43.0%)] Loss: 0.025755 L1: 0.014991 Grad: 0.107444 Thermal: 0.000400 LR: 9.97e-06\n",
      "Epoch   3 [4600/10697 ( 43.0%)] Loss: 0.025755 L1: 0.014991 Grad: 0.107444 Thermal: 0.000400 LR: 9.97e-06\n",
      "Epoch   3 [4650/10697 ( 43.5%)] Loss: 0.027606 L1: 0.016236 Grad: 0.113457 Thermal: 0.000498 LR: 9.97e-06\n",
      "Epoch   3 [4650/10697 ( 43.5%)] Loss: 0.027606 L1: 0.016236 Grad: 0.113457 Thermal: 0.000498 LR: 9.97e-06\n",
      "Epoch   3 [4700/10697 ( 43.9%)] Loss: 0.024207 L1: 0.013813 Grad: 0.103761 Thermal: 0.000358 LR: 9.97e-06\n",
      "Epoch   3 [4700/10697 ( 43.9%)] Loss: 0.024207 L1: 0.013813 Grad: 0.103761 Thermal: 0.000358 LR: 9.97e-06\n",
      "Epoch   3 [4750/10697 ( 44.4%)] Loss: 0.026479 L1: 0.015737 Grad: 0.107204 Thermal: 0.000436 LR: 9.97e-06\n",
      "Epoch   3 [4750/10697 ( 44.4%)] Loss: 0.026479 L1: 0.015737 Grad: 0.107204 Thermal: 0.000436 LR: 9.97e-06\n",
      "Epoch   3 [4800/10697 ( 44.9%)] Loss: 0.031852 L1: 0.018141 Grad: 0.136809 Thermal: 0.000602 LR: 9.97e-06\n",
      "Epoch   3 [4800/10697 ( 44.9%)] Loss: 0.031852 L1: 0.018141 Grad: 0.136809 Thermal: 0.000602 LR: 9.97e-06\n",
      "Epoch   3 [4850/10697 ( 45.3%)] Loss: 0.032754 L1: 0.018260 Grad: 0.144660 Thermal: 0.000576 LR: 9.97e-06\n",
      "Epoch   3 [4850/10697 ( 45.3%)] Loss: 0.032754 L1: 0.018260 Grad: 0.144660 Thermal: 0.000576 LR: 9.97e-06\n",
      "Epoch   3 [4900/10697 ( 45.8%)] Loss: 0.030184 L1: 0.017618 Grad: 0.125402 Thermal: 0.000531 LR: 9.97e-06\n",
      "Epoch   3 [4900/10697 ( 45.8%)] Loss: 0.030184 L1: 0.017618 Grad: 0.125402 Thermal: 0.000531 LR: 9.97e-06\n",
      "Epoch   3 [4950/10697 ( 46.3%)] Loss: 0.024291 L1: 0.014348 Grad: 0.099236 Thermal: 0.000384 LR: 9.97e-06\n",
      "Epoch   3 [4950/10697 ( 46.3%)] Loss: 0.024291 L1: 0.014348 Grad: 0.099236 Thermal: 0.000384 LR: 9.97e-06\n",
      "Epoch   3 [5000/10697 ( 46.7%)] Loss: 0.031281 L1: 0.018084 Grad: 0.131671 Thermal: 0.000595 LR: 9.97e-06\n",
      "Epoch   3 [5000/10697 ( 46.7%)] Loss: 0.031281 L1: 0.018084 Grad: 0.131671 Thermal: 0.000595 LR: 9.97e-06\n",
      "Epoch   3 [5050/10697 ( 47.2%)] Loss: 0.028259 L1: 0.016676 Grad: 0.115581 Thermal: 0.000485 LR: 9.97e-06\n",
      "Epoch   3 [5050/10697 ( 47.2%)] Loss: 0.028259 L1: 0.016676 Grad: 0.115581 Thermal: 0.000485 LR: 9.97e-06\n",
      "Epoch   3 [5100/10697 ( 47.7%)] Loss: 0.031904 L1: 0.018533 Grad: 0.133377 Thermal: 0.000658 LR: 9.97e-06\n",
      "Epoch   3 [5100/10697 ( 47.7%)] Loss: 0.031904 L1: 0.018533 Grad: 0.133377 Thermal: 0.000658 LR: 9.97e-06\n",
      "Epoch   3 [5150/10697 ( 48.1%)] Loss: 0.030517 L1: 0.017676 Grad: 0.128137 Thermal: 0.000540 LR: 9.97e-06\n",
      "Epoch   3 [5150/10697 ( 48.1%)] Loss: 0.030517 L1: 0.017676 Grad: 0.128137 Thermal: 0.000540 LR: 9.97e-06\n",
      "Epoch   3 [5200/10697 ( 48.6%)] Loss: 0.033689 L1: 0.019395 Grad: 0.142593 Thermal: 0.000691 LR: 9.97e-06\n",
      "Epoch   3 [5200/10697 ( 48.6%)] Loss: 0.033689 L1: 0.019395 Grad: 0.142593 Thermal: 0.000691 LR: 9.97e-06\n",
      "Epoch   3 [5250/10697 ( 49.1%)] Loss: 0.020828 L1: 0.012187 Grad: 0.086265 Thermal: 0.000291 LR: 9.97e-06\n",
      "Epoch   3 [5250/10697 ( 49.1%)] Loss: 0.020828 L1: 0.012187 Grad: 0.086265 Thermal: 0.000291 LR: 9.97e-06\n",
      "Epoch   3 [5300/10697 ( 49.5%)] Loss: 0.024919 L1: 0.014568 Grad: 0.103301 Thermal: 0.000414 LR: 9.97e-06\n",
      "Epoch   3 [5300/10697 ( 49.5%)] Loss: 0.024919 L1: 0.014568 Grad: 0.103301 Thermal: 0.000414 LR: 9.97e-06\n",
      "Epoch   3 [5350/10697 ( 50.0%)] Loss: 0.026837 L1: 0.014990 Grad: 0.118239 Thermal: 0.000470 LR: 9.97e-06\n",
      "Epoch   3 [5350/10697 ( 50.0%)] Loss: 0.026837 L1: 0.014990 Grad: 0.118239 Thermal: 0.000470 LR: 9.97e-06\n",
      "Epoch   3 [5400/10697 ( 50.5%)] Loss: 0.024549 L1: 0.014503 Grad: 0.100267 Thermal: 0.000398 LR: 9.97e-06\n",
      "Epoch   3 [5400/10697 ( 50.5%)] Loss: 0.024549 L1: 0.014503 Grad: 0.100267 Thermal: 0.000398 LR: 9.97e-06\n",
      "Epoch   3 [5450/10697 ( 50.9%)] Loss: 0.023157 L1: 0.013303 Grad: 0.098369 Thermal: 0.000330 LR: 9.97e-06\n",
      "Epoch   3 [5450/10697 ( 50.9%)] Loss: 0.023157 L1: 0.013303 Grad: 0.098369 Thermal: 0.000330 LR: 9.97e-06\n",
      "Epoch   3 [5500/10697 ( 51.4%)] Loss: 0.025464 L1: 0.014748 Grad: 0.106912 Thermal: 0.000494 LR: 9.97e-06\n",
      "Epoch   3 [5500/10697 ( 51.4%)] Loss: 0.025464 L1: 0.014748 Grad: 0.106912 Thermal: 0.000494 LR: 9.97e-06\n",
      "Epoch   3 [5550/10697 ( 51.9%)] Loss: 0.023939 L1: 0.013942 Grad: 0.099792 Thermal: 0.000369 LR: 9.97e-06\n",
      "Epoch   3 [5550/10697 ( 51.9%)] Loss: 0.023939 L1: 0.013942 Grad: 0.099792 Thermal: 0.000369 LR: 9.97e-06\n",
      "Epoch   3 [5600/10697 ( 52.4%)] Loss: 0.030878 L1: 0.017336 Grad: 0.135134 Thermal: 0.000558 LR: 9.97e-06\n",
      "Epoch   3 [5600/10697 ( 52.4%)] Loss: 0.030878 L1: 0.017336 Grad: 0.135134 Thermal: 0.000558 LR: 9.97e-06\n",
      "Epoch   3 [5650/10697 ( 52.8%)] Loss: 0.026190 L1: 0.015199 Grad: 0.109681 Thermal: 0.000470 LR: 9.97e-06\n",
      "Epoch   3 [5650/10697 ( 52.8%)] Loss: 0.026190 L1: 0.015199 Grad: 0.109681 Thermal: 0.000470 LR: 9.97e-06\n",
      "Epoch   3 [5700/10697 ( 53.3%)] Loss: 0.027792 L1: 0.015548 Grad: 0.122187 Thermal: 0.000509 LR: 9.97e-06\n",
      "Epoch   3 [5700/10697 ( 53.3%)] Loss: 0.027792 L1: 0.015548 Grad: 0.122187 Thermal: 0.000509 LR: 9.97e-06\n",
      "Epoch   3 [5750/10697 ( 53.8%)] Loss: 0.028825 L1: 0.016772 Grad: 0.120268 Thermal: 0.000508 LR: 9.97e-06\n",
      "Epoch   3 [5750/10697 ( 53.8%)] Loss: 0.028825 L1: 0.016772 Grad: 0.120268 Thermal: 0.000508 LR: 9.97e-06\n",
      "Epoch   3 [5800/10697 ( 54.2%)] Loss: 0.026143 L1: 0.015123 Grad: 0.109985 Thermal: 0.000436 LR: 9.97e-06\n",
      "Epoch   3 [5800/10697 ( 54.2%)] Loss: 0.026143 L1: 0.015123 Grad: 0.109985 Thermal: 0.000436 LR: 9.97e-06\n",
      "Epoch   3 [5850/10697 ( 54.7%)] Loss: 0.030455 L1: 0.018122 Grad: 0.123036 Thermal: 0.000591 LR: 9.97e-06\n",
      "Epoch   3 [5850/10697 ( 54.7%)] Loss: 0.030455 L1: 0.018122 Grad: 0.123036 Thermal: 0.000591 LR: 9.97e-06\n",
      "Epoch   3 [5900/10697 ( 55.2%)] Loss: 0.025225 L1: 0.014685 Grad: 0.105215 Thermal: 0.000386 LR: 9.97e-06\n",
      "Epoch   3 [5900/10697 ( 55.2%)] Loss: 0.025225 L1: 0.014685 Grad: 0.105215 Thermal: 0.000386 LR: 9.97e-06\n",
      "Epoch   3 [5950/10697 ( 55.6%)] Loss: 0.024897 L1: 0.013970 Grad: 0.109070 Thermal: 0.000392 LR: 9.97e-06\n",
      "Epoch   3 [5950/10697 ( 55.6%)] Loss: 0.024897 L1: 0.013970 Grad: 0.109070 Thermal: 0.000392 LR: 9.97e-06\n",
      "Epoch   3 [6000/10697 ( 56.1%)] Loss: 0.021430 L1: 0.012349 Grad: 0.090641 Thermal: 0.000321 LR: 9.97e-06\n",
      "Epoch   3 [6000/10697 ( 56.1%)] Loss: 0.021430 L1: 0.012349 Grad: 0.090641 Thermal: 0.000321 LR: 9.97e-06\n",
      "Epoch   3 [6050/10697 ( 56.6%)] Loss: 0.027491 L1: 0.015982 Grad: 0.114848 Thermal: 0.000482 LR: 9.97e-06\n",
      "Epoch   3 [6050/10697 ( 56.6%)] Loss: 0.027491 L1: 0.015982 Grad: 0.114848 Thermal: 0.000482 LR: 9.97e-06\n",
      "Epoch   3 [6100/10697 ( 57.0%)] Loss: 0.026553 L1: 0.015259 Grad: 0.112726 Thermal: 0.000444 LR: 9.97e-06\n",
      "Epoch   3 [6100/10697 ( 57.0%)] Loss: 0.026553 L1: 0.015259 Grad: 0.112726 Thermal: 0.000444 LR: 9.97e-06\n",
      "Epoch   3 [6150/10697 ( 57.5%)] Loss: 0.031961 L1: 0.018280 Grad: 0.136523 Thermal: 0.000586 LR: 9.97e-06\n",
      "Epoch   3 [6150/10697 ( 57.5%)] Loss: 0.031961 L1: 0.018280 Grad: 0.136523 Thermal: 0.000586 LR: 9.97e-06\n",
      "Epoch   3 [6200/10697 ( 58.0%)] Loss: 0.027647 L1: 0.016711 Grad: 0.109100 Thermal: 0.000511 LR: 9.97e-06\n",
      "Epoch   3 [6200/10697 ( 58.0%)] Loss: 0.027647 L1: 0.016711 Grad: 0.109100 Thermal: 0.000511 LR: 9.97e-06\n",
      "Epoch   3 [6250/10697 ( 58.4%)] Loss: 0.025122 L1: 0.013915 Grad: 0.111887 Thermal: 0.000356 LR: 9.97e-06\n",
      "Epoch   3 [6250/10697 ( 58.4%)] Loss: 0.025122 L1: 0.013915 Grad: 0.111887 Thermal: 0.000356 LR: 9.97e-06\n",
      "Epoch   3 [6300/10697 ( 58.9%)] Loss: 0.024215 L1: 0.014396 Grad: 0.097998 Thermal: 0.000382 LR: 9.97e-06\n",
      "Epoch   3 [6300/10697 ( 58.9%)] Loss: 0.024215 L1: 0.014396 Grad: 0.097998 Thermal: 0.000382 LR: 9.97e-06\n",
      "Epoch   3 [6350/10697 ( 59.4%)] Loss: 0.028359 L1: 0.016716 Grad: 0.116193 Thermal: 0.000485 LR: 9.97e-06\n",
      "Epoch   3 [6350/10697 ( 59.4%)] Loss: 0.028359 L1: 0.016716 Grad: 0.116193 Thermal: 0.000485 LR: 9.97e-06\n",
      "Epoch   3 [6400/10697 ( 59.8%)] Loss: 0.027496 L1: 0.016065 Grad: 0.114074 Thermal: 0.000471 LR: 9.97e-06\n",
      "Epoch   3 [6400/10697 ( 59.8%)] Loss: 0.027496 L1: 0.016065 Grad: 0.114074 Thermal: 0.000471 LR: 9.97e-06\n",
      "Epoch   3 [6450/10697 ( 60.3%)] Loss: 0.020499 L1: 0.012263 Grad: 0.082205 Thermal: 0.000307 LR: 9.97e-06\n",
      "Epoch   3 [6450/10697 ( 60.3%)] Loss: 0.020499 L1: 0.012263 Grad: 0.082205 Thermal: 0.000307 LR: 9.97e-06\n",
      "Epoch   3 [6500/10697 ( 60.8%)] Loss: 0.028034 L1: 0.016635 Grad: 0.113743 Thermal: 0.000494 LR: 9.97e-06\n",
      "Epoch   3 [6500/10697 ( 60.8%)] Loss: 0.028034 L1: 0.016635 Grad: 0.113743 Thermal: 0.000494 LR: 9.97e-06\n",
      "Epoch   3 [6550/10697 ( 61.2%)] Loss: 0.024087 L1: 0.013974 Grad: 0.100959 Thermal: 0.000358 LR: 9.97e-06\n",
      "Epoch   3 [6550/10697 ( 61.2%)] Loss: 0.024087 L1: 0.013974 Grad: 0.100959 Thermal: 0.000358 LR: 9.97e-06\n",
      "Epoch   3 [6600/10697 ( 61.7%)] Loss: 0.032468 L1: 0.019154 Grad: 0.132832 Thermal: 0.000608 LR: 9.97e-06\n",
      "Epoch   3 [6600/10697 ( 61.7%)] Loss: 0.032468 L1: 0.019154 Grad: 0.132832 Thermal: 0.000608 LR: 9.97e-06\n",
      "Epoch   3 [6650/10697 ( 62.2%)] Loss: 0.029159 L1: 0.016819 Grad: 0.123158 Thermal: 0.000486 LR: 9.97e-06\n",
      "Epoch   3 [6650/10697 ( 62.2%)] Loss: 0.029159 L1: 0.016819 Grad: 0.123158 Thermal: 0.000486 LR: 9.97e-06\n",
      "Epoch   3 [6700/10697 ( 62.6%)] Loss: 0.022153 L1: 0.012897 Grad: 0.092399 Thermal: 0.000337 LR: 9.97e-06\n",
      "Epoch   3 [6700/10697 ( 62.6%)] Loss: 0.022153 L1: 0.012897 Grad: 0.092399 Thermal: 0.000337 LR: 9.97e-06\n",
      "Epoch   3 [6750/10697 ( 63.1%)] Loss: 0.031721 L1: 0.019015 Grad: 0.126746 Thermal: 0.000634 LR: 9.97e-06\n",
      "Epoch   3 [6750/10697 ( 63.1%)] Loss: 0.031721 L1: 0.019015 Grad: 0.126746 Thermal: 0.000634 LR: 9.97e-06\n",
      "Epoch   3 [6800/10697 ( 63.6%)] Loss: 0.029489 L1: 0.017182 Grad: 0.122798 Thermal: 0.000549 LR: 9.97e-06\n",
      "Epoch   3 [6800/10697 ( 63.6%)] Loss: 0.029489 L1: 0.017182 Grad: 0.122798 Thermal: 0.000549 LR: 9.97e-06\n",
      "Epoch   3 [6850/10697 ( 64.0%)] Loss: 0.031956 L1: 0.018617 Grad: 0.133005 Thermal: 0.000757 LR: 9.97e-06\n",
      "Epoch   3 [6850/10697 ( 64.0%)] Loss: 0.031956 L1: 0.018617 Grad: 0.133005 Thermal: 0.000757 LR: 9.97e-06\n",
      "Epoch   3 [6900/10697 ( 64.5%)] Loss: 0.027689 L1: 0.016161 Grad: 0.115051 Thermal: 0.000457 LR: 9.97e-06\n",
      "Epoch   3 [6900/10697 ( 64.5%)] Loss: 0.027689 L1: 0.016161 Grad: 0.115051 Thermal: 0.000457 LR: 9.97e-06\n",
      "Epoch   3 [6950/10697 ( 65.0%)] Loss: 0.031374 L1: 0.018656 Grad: 0.126865 Thermal: 0.000619 LR: 9.97e-06\n",
      "Epoch   3 [6950/10697 ( 65.0%)] Loss: 0.031374 L1: 0.018656 Grad: 0.126865 Thermal: 0.000619 LR: 9.97e-06\n",
      "Epoch   3 [7000/10697 ( 65.4%)] Loss: 0.028644 L1: 0.017003 Grad: 0.116158 Thermal: 0.000516 LR: 9.97e-06\n",
      "Epoch   3 [7000/10697 ( 65.4%)] Loss: 0.028644 L1: 0.017003 Grad: 0.116158 Thermal: 0.000516 LR: 9.97e-06\n",
      "Epoch   3 [7050/10697 ( 65.9%)] Loss: 0.031641 L1: 0.018643 Grad: 0.129657 Thermal: 0.000642 LR: 9.97e-06\n",
      "Epoch   3 [7050/10697 ( 65.9%)] Loss: 0.031641 L1: 0.018643 Grad: 0.129657 Thermal: 0.000642 LR: 9.97e-06\n",
      "Epoch   3 [7100/10697 ( 66.4%)] Loss: 0.026868 L1: 0.015669 Grad: 0.111761 Thermal: 0.000472 LR: 9.97e-06\n",
      "Epoch   3 [7100/10697 ( 66.4%)] Loss: 0.026868 L1: 0.015669 Grad: 0.111761 Thermal: 0.000472 LR: 9.97e-06\n",
      "Epoch   3 [7150/10697 ( 66.8%)] Loss: 0.036624 L1: 0.021073 Grad: 0.155091 Thermal: 0.000824 LR: 9.97e-06\n",
      "Epoch   3 [7150/10697 ( 66.8%)] Loss: 0.036624 L1: 0.021073 Grad: 0.155091 Thermal: 0.000824 LR: 9.97e-06\n",
      "Epoch   3 [7200/10697 ( 67.3%)] Loss: 0.024437 L1: 0.014156 Grad: 0.102599 Thermal: 0.000406 LR: 9.97e-06\n",
      "Epoch   3 [7200/10697 ( 67.3%)] Loss: 0.024437 L1: 0.014156 Grad: 0.102599 Thermal: 0.000406 LR: 9.97e-06\n",
      "Epoch   3 [7250/10697 ( 67.8%)] Loss: 0.022450 L1: 0.013172 Grad: 0.092608 Thermal: 0.000346 LR: 9.97e-06\n",
      "Epoch   3 [7250/10697 ( 67.8%)] Loss: 0.022450 L1: 0.013172 Grad: 0.092608 Thermal: 0.000346 LR: 9.97e-06\n",
      "Epoch   3 [7300/10697 ( 68.2%)] Loss: 0.026938 L1: 0.015924 Grad: 0.109892 Thermal: 0.000482 LR: 9.97e-06\n",
      "Epoch   3 [7300/10697 ( 68.2%)] Loss: 0.026938 L1: 0.015924 Grad: 0.109892 Thermal: 0.000482 LR: 9.97e-06\n",
      "Epoch   3 [7350/10697 ( 68.7%)] Loss: 0.029319 L1: 0.016760 Grad: 0.125318 Thermal: 0.000532 LR: 9.97e-06\n",
      "Epoch   3 [7350/10697 ( 68.7%)] Loss: 0.029319 L1: 0.016760 Grad: 0.125318 Thermal: 0.000532 LR: 9.97e-06\n",
      "Epoch   3 [7400/10697 ( 69.2%)] Loss: 0.023861 L1: 0.013708 Grad: 0.101341 Thermal: 0.000377 LR: 9.97e-06\n",
      "Epoch   3 [7400/10697 ( 69.2%)] Loss: 0.023861 L1: 0.013708 Grad: 0.101341 Thermal: 0.000377 LR: 9.97e-06\n",
      "Epoch   3 [7450/10697 ( 69.6%)] Loss: 0.020517 L1: 0.011565 Grad: 0.089383 Thermal: 0.000278 LR: 9.97e-06\n",
      "Epoch   3 [7450/10697 ( 69.6%)] Loss: 0.020517 L1: 0.011565 Grad: 0.089383 Thermal: 0.000278 LR: 9.97e-06\n",
      "Epoch   3 [7500/10697 ( 70.1%)] Loss: 0.026950 L1: 0.015489 Grad: 0.114392 Thermal: 0.000435 LR: 9.97e-06\n",
      "Epoch   3 [7500/10697 ( 70.1%)] Loss: 0.026950 L1: 0.015489 Grad: 0.114392 Thermal: 0.000435 LR: 9.97e-06\n",
      "Epoch   3 [7550/10697 ( 70.6%)] Loss: 0.023863 L1: 0.014074 Grad: 0.097697 Thermal: 0.000370 LR: 9.97e-06\n",
      "Epoch   3 [7550/10697 ( 70.6%)] Loss: 0.023863 L1: 0.014074 Grad: 0.097697 Thermal: 0.000370 LR: 9.97e-06\n",
      "Epoch   3 [7600/10697 ( 71.0%)] Loss: 0.028672 L1: 0.016202 Grad: 0.124472 Thermal: 0.000467 LR: 9.97e-06\n",
      "Epoch   3 [7600/10697 ( 71.0%)] Loss: 0.028672 L1: 0.016202 Grad: 0.124472 Thermal: 0.000467 LR: 9.97e-06\n",
      "Epoch   3 [7650/10697 ( 71.5%)] Loss: 0.022741 L1: 0.012923 Grad: 0.097992 Thermal: 0.000382 LR: 9.97e-06\n",
      "Epoch   3 [7650/10697 ( 71.5%)] Loss: 0.022741 L1: 0.012923 Grad: 0.097992 Thermal: 0.000382 LR: 9.97e-06\n",
      "Epoch   3 [7700/10697 ( 72.0%)] Loss: 0.026586 L1: 0.015177 Grad: 0.113870 Thermal: 0.000448 LR: 9.97e-06\n",
      "Epoch   3 [7700/10697 ( 72.0%)] Loss: 0.026586 L1: 0.015177 Grad: 0.113870 Thermal: 0.000448 LR: 9.97e-06\n",
      "Epoch   3 [7750/10697 ( 72.5%)] Loss: 0.027644 L1: 0.016076 Grad: 0.115439 Thermal: 0.000484 LR: 9.97e-06\n",
      "Epoch   3 [7750/10697 ( 72.5%)] Loss: 0.027644 L1: 0.016076 Grad: 0.115439 Thermal: 0.000484 LR: 9.97e-06\n",
      "Epoch   3 [7800/10697 ( 72.9%)] Loss: 0.023632 L1: 0.013815 Grad: 0.097969 Thermal: 0.000390 LR: 9.97e-06\n",
      "Epoch   3 [7800/10697 ( 72.9%)] Loss: 0.023632 L1: 0.013815 Grad: 0.097969 Thermal: 0.000390 LR: 9.97e-06\n",
      "Epoch   3 [7850/10697 ( 73.4%)] Loss: 0.026962 L1: 0.015615 Grad: 0.113240 Thermal: 0.000447 LR: 9.97e-06\n",
      "Epoch   3 [7850/10697 ( 73.4%)] Loss: 0.026962 L1: 0.015615 Grad: 0.113240 Thermal: 0.000447 LR: 9.97e-06\n",
      "Epoch   3 [7900/10697 ( 73.9%)] Loss: 0.028718 L1: 0.016910 Grad: 0.117803 Thermal: 0.000547 LR: 9.97e-06\n",
      "Epoch   3 [7900/10697 ( 73.9%)] Loss: 0.028718 L1: 0.016910 Grad: 0.117803 Thermal: 0.000547 LR: 9.97e-06\n",
      "Epoch   3 [7950/10697 ( 74.3%)] Loss: 0.027017 L1: 0.015434 Grad: 0.115615 Thermal: 0.000422 LR: 9.97e-06\n",
      "Epoch   3 [7950/10697 ( 74.3%)] Loss: 0.027017 L1: 0.015434 Grad: 0.115615 Thermal: 0.000422 LR: 9.97e-06\n",
      "Epoch   3 [8000/10697 ( 74.8%)] Loss: 0.028631 L1: 0.016604 Grad: 0.120005 Thermal: 0.000541 LR: 9.97e-06\n",
      "Epoch   3 [8000/10697 ( 74.8%)] Loss: 0.028631 L1: 0.016604 Grad: 0.120005 Thermal: 0.000541 LR: 9.97e-06\n",
      "Epoch   3 [8050/10697 ( 75.3%)] Loss: 0.029226 L1: 0.017310 Grad: 0.118891 Thermal: 0.000535 LR: 9.97e-06\n",
      "Epoch   3 [8050/10697 ( 75.3%)] Loss: 0.029226 L1: 0.017310 Grad: 0.118891 Thermal: 0.000535 LR: 9.97e-06\n",
      "Epoch   3 [8100/10697 ( 75.7%)] Loss: 0.026257 L1: 0.015314 Grad: 0.109209 Thermal: 0.000443 LR: 9.97e-06\n",
      "Epoch   3 [8100/10697 ( 75.7%)] Loss: 0.026257 L1: 0.015314 Grad: 0.109209 Thermal: 0.000443 LR: 9.97e-06\n",
      "Epoch   3 [8150/10697 ( 76.2%)] Loss: 0.034062 L1: 0.019371 Grad: 0.146540 Thermal: 0.000736 LR: 9.97e-06\n",
      "Epoch   3 [8150/10697 ( 76.2%)] Loss: 0.034062 L1: 0.019371 Grad: 0.146540 Thermal: 0.000736 LR: 9.97e-06\n",
      "Epoch   3 [8200/10697 ( 76.7%)] Loss: 0.028047 L1: 0.016565 Grad: 0.114576 Thermal: 0.000481 LR: 9.97e-06\n",
      "Epoch   3 [8200/10697 ( 76.7%)] Loss: 0.028047 L1: 0.016565 Grad: 0.114576 Thermal: 0.000481 LR: 9.97e-06\n",
      "Epoch   3 [8250/10697 ( 77.1%)] Loss: 0.024211 L1: 0.014116 Grad: 0.100749 Thermal: 0.000408 LR: 9.97e-06\n",
      "Epoch   3 [8250/10697 ( 77.1%)] Loss: 0.024211 L1: 0.014116 Grad: 0.100749 Thermal: 0.000408 LR: 9.97e-06\n",
      "Epoch   3 [8300/10697 ( 77.6%)] Loss: 0.026732 L1: 0.015636 Grad: 0.110720 Thermal: 0.000474 LR: 9.97e-06\n",
      "Epoch   3 [8300/10697 ( 77.6%)] Loss: 0.026732 L1: 0.015636 Grad: 0.110720 Thermal: 0.000474 LR: 9.97e-06\n",
      "Epoch   3 [8350/10697 ( 78.1%)] Loss: 0.028722 L1: 0.016356 Grad: 0.123435 Thermal: 0.000450 LR: 9.97e-06\n",
      "Epoch   3 [8350/10697 ( 78.1%)] Loss: 0.028722 L1: 0.016356 Grad: 0.123435 Thermal: 0.000450 LR: 9.97e-06\n",
      "Epoch   3 [8400/10697 ( 78.5%)] Loss: 0.022552 L1: 0.012541 Grad: 0.099935 Thermal: 0.000355 LR: 9.97e-06\n",
      "Epoch   3 [8400/10697 ( 78.5%)] Loss: 0.022552 L1: 0.012541 Grad: 0.099935 Thermal: 0.000355 LR: 9.97e-06\n",
      "Epoch   3 [8450/10697 ( 79.0%)] Loss: 0.028349 L1: 0.016464 Grad: 0.118582 Thermal: 0.000522 LR: 9.97e-06\n",
      "Epoch   3 [8450/10697 ( 79.0%)] Loss: 0.028349 L1: 0.016464 Grad: 0.118582 Thermal: 0.000522 LR: 9.97e-06\n",
      "Epoch   3 [8500/10697 ( 79.5%)] Loss: 0.039325 L1: 0.022936 Grad: 0.163313 Thermal: 0.001150 LR: 9.97e-06\n",
      "Epoch   3 [8500/10697 ( 79.5%)] Loss: 0.039325 L1: 0.022936 Grad: 0.163313 Thermal: 0.001150 LR: 9.97e-06\n",
      "Epoch   3 [8550/10697 ( 79.9%)] Loss: 0.027262 L1: 0.015890 Grad: 0.113502 Thermal: 0.000445 LR: 9.97e-06\n",
      "Epoch   3 [8550/10697 ( 79.9%)] Loss: 0.027262 L1: 0.015890 Grad: 0.113502 Thermal: 0.000445 LR: 9.97e-06\n",
      "Epoch   3 [8600/10697 ( 80.4%)] Loss: 0.025152 L1: 0.015121 Grad: 0.100111 Thermal: 0.000391 LR: 9.97e-06\n",
      "Epoch   3 [8600/10697 ( 80.4%)] Loss: 0.025152 L1: 0.015121 Grad: 0.100111 Thermal: 0.000391 LR: 9.97e-06\n",
      "Epoch   3 [8650/10697 ( 80.9%)] Loss: 0.026057 L1: 0.015179 Grad: 0.108563 Thermal: 0.000443 LR: 9.97e-06\n",
      "Epoch   3 [8650/10697 ( 80.9%)] Loss: 0.026057 L1: 0.015179 Grad: 0.108563 Thermal: 0.000443 LR: 9.97e-06\n",
      "Epoch   3 [8700/10697 ( 81.3%)] Loss: 0.028336 L1: 0.016554 Grad: 0.117574 Thermal: 0.000499 LR: 9.97e-06\n",
      "Epoch   3 [8700/10697 ( 81.3%)] Loss: 0.028336 L1: 0.016554 Grad: 0.117574 Thermal: 0.000499 LR: 9.97e-06\n",
      "Epoch   3 [8750/10697 ( 81.8%)] Loss: 0.029887 L1: 0.016777 Grad: 0.130820 Thermal: 0.000569 LR: 9.97e-06\n",
      "Epoch   3 [8750/10697 ( 81.8%)] Loss: 0.029887 L1: 0.016777 Grad: 0.130820 Thermal: 0.000569 LR: 9.97e-06\n",
      "Epoch   3 [8800/10697 ( 82.3%)] Loss: 0.016769 L1: 0.009373 Grad: 0.073852 Thermal: 0.000213 LR: 9.97e-06\n",
      "Epoch   3 [8800/10697 ( 82.3%)] Loss: 0.016769 L1: 0.009373 Grad: 0.073852 Thermal: 0.000213 LR: 9.97e-06\n",
      "Epoch   3 [8850/10697 ( 82.7%)] Loss: 0.029200 L1: 0.017177 Grad: 0.119866 Thermal: 0.000728 LR: 9.97e-06\n",
      "Epoch   3 [8850/10697 ( 82.7%)] Loss: 0.029200 L1: 0.017177 Grad: 0.119866 Thermal: 0.000728 LR: 9.97e-06\n",
      "Epoch   3 [8900/10697 ( 83.2%)] Loss: 0.027064 L1: 0.016090 Grad: 0.109492 Thermal: 0.000503 LR: 9.97e-06\n",
      "Epoch   3 [8900/10697 ( 83.2%)] Loss: 0.027064 L1: 0.016090 Grad: 0.109492 Thermal: 0.000503 LR: 9.97e-06\n",
      "Epoch   3 [8950/10697 ( 83.7%)] Loss: 0.028593 L1: 0.016262 Grad: 0.123065 Thermal: 0.000486 LR: 9.97e-06\n",
      "Epoch   3 [8950/10697 ( 83.7%)] Loss: 0.028593 L1: 0.016262 Grad: 0.123065 Thermal: 0.000486 LR: 9.97e-06\n",
      "Epoch   3 [9000/10697 ( 84.1%)] Loss: 0.030016 L1: 0.017447 Grad: 0.125378 Thermal: 0.000619 LR: 9.97e-06\n",
      "Epoch   3 [9000/10697 ( 84.1%)] Loss: 0.030016 L1: 0.017447 Grad: 0.125378 Thermal: 0.000619 LR: 9.97e-06\n",
      "Epoch   3 [9050/10697 ( 84.6%)] Loss: 0.026587 L1: 0.015615 Grad: 0.109489 Thermal: 0.000462 LR: 9.97e-06\n",
      "Epoch   3 [9050/10697 ( 84.6%)] Loss: 0.026587 L1: 0.015615 Grad: 0.109489 Thermal: 0.000462 LR: 9.97e-06\n",
      "Epoch   3 [9100/10697 ( 85.1%)] Loss: 0.027603 L1: 0.015992 Grad: 0.115862 Thermal: 0.000485 LR: 9.97e-06\n",
      "Epoch   3 [9100/10697 ( 85.1%)] Loss: 0.027603 L1: 0.015992 Grad: 0.115862 Thermal: 0.000485 LR: 9.97e-06\n",
      "Epoch   3 [9150/10697 ( 85.5%)] Loss: 0.025784 L1: 0.015330 Grad: 0.104327 Thermal: 0.000427 LR: 9.97e-06\n",
      "Epoch   3 [9150/10697 ( 85.5%)] Loss: 0.025784 L1: 0.015330 Grad: 0.104327 Thermal: 0.000427 LR: 9.97e-06\n",
      "Epoch   3 [9200/10697 ( 86.0%)] Loss: 0.025667 L1: 0.014832 Grad: 0.108124 Thermal: 0.000453 LR: 9.97e-06\n",
      "Epoch   3 [9200/10697 ( 86.0%)] Loss: 0.025667 L1: 0.014832 Grad: 0.108124 Thermal: 0.000453 LR: 9.97e-06\n",
      "Epoch   3 [9250/10697 ( 86.5%)] Loss: 0.024574 L1: 0.014470 Grad: 0.100849 Thermal: 0.000385 LR: 9.97e-06\n",
      "Epoch   3 [9250/10697 ( 86.5%)] Loss: 0.024574 L1: 0.014470 Grad: 0.100849 Thermal: 0.000385 LR: 9.97e-06\n",
      "Epoch   3 [9300/10697 ( 86.9%)] Loss: 0.033320 L1: 0.018916 Grad: 0.143655 Thermal: 0.000770 LR: 9.97e-06\n",
      "Epoch   3 [9300/10697 ( 86.9%)] Loss: 0.033320 L1: 0.018916 Grad: 0.143655 Thermal: 0.000770 LR: 9.97e-06\n",
      "Epoch   3 [9350/10697 ( 87.4%)] Loss: 0.022611 L1: 0.013454 Grad: 0.091396 Thermal: 0.000352 LR: 9.97e-06\n",
      "Epoch   3 [9350/10697 ( 87.4%)] Loss: 0.022611 L1: 0.013454 Grad: 0.091396 Thermal: 0.000352 LR: 9.97e-06\n",
      "Epoch   3 [9400/10697 ( 87.9%)] Loss: 0.025543 L1: 0.014917 Grad: 0.106030 Thermal: 0.000461 LR: 9.97e-06\n",
      "Epoch   3 [9400/10697 ( 87.9%)] Loss: 0.025543 L1: 0.014917 Grad: 0.106030 Thermal: 0.000461 LR: 9.97e-06\n",
      "Epoch   3 [9450/10697 ( 88.3%)] Loss: 0.027415 L1: 0.016073 Grad: 0.113169 Thermal: 0.000492 LR: 9.97e-06\n",
      "Epoch   3 [9450/10697 ( 88.3%)] Loss: 0.027415 L1: 0.016073 Grad: 0.113169 Thermal: 0.000492 LR: 9.97e-06\n",
      "Epoch   3 [9500/10697 ( 88.8%)] Loss: 0.026743 L1: 0.015977 Grad: 0.107427 Thermal: 0.000469 LR: 9.97e-06\n",
      "Epoch   3 [9500/10697 ( 88.8%)] Loss: 0.026743 L1: 0.015977 Grad: 0.107427 Thermal: 0.000469 LR: 9.97e-06\n",
      "Epoch   3 [9550/10697 ( 89.3%)] Loss: 0.017749 L1: 0.009893 Grad: 0.078451 Thermal: 0.000213 LR: 9.97e-06\n",
      "Epoch   3 [9550/10697 ( 89.3%)] Loss: 0.017749 L1: 0.009893 Grad: 0.078451 Thermal: 0.000213 LR: 9.97e-06\n",
      "Epoch   3 [9600/10697 ( 89.7%)] Loss: 0.026822 L1: 0.015523 Grad: 0.112759 Thermal: 0.000449 LR: 9.97e-06\n",
      "Epoch   3 [9600/10697 ( 89.7%)] Loss: 0.026822 L1: 0.015523 Grad: 0.112759 Thermal: 0.000449 LR: 9.97e-06\n",
      "Epoch   3 [9650/10697 ( 90.2%)] Loss: 0.022118 L1: 0.013073 Grad: 0.090274 Thermal: 0.000372 LR: 9.97e-06\n",
      "Epoch   3 [9650/10697 ( 90.2%)] Loss: 0.022118 L1: 0.013073 Grad: 0.090274 Thermal: 0.000372 LR: 9.97e-06\n",
      "Epoch   3 [9700/10697 ( 90.7%)] Loss: 0.021404 L1: 0.012454 Grad: 0.089326 Thermal: 0.000352 LR: 9.97e-06\n",
      "Epoch   3 [9700/10697 ( 90.7%)] Loss: 0.021404 L1: 0.012454 Grad: 0.089326 Thermal: 0.000352 LR: 9.97e-06\n",
      "Epoch   3 [9750/10697 ( 91.1%)] Loss: 0.025979 L1: 0.015393 Grad: 0.105645 Thermal: 0.000438 LR: 9.97e-06\n",
      "Epoch   3 [9750/10697 ( 91.1%)] Loss: 0.025979 L1: 0.015393 Grad: 0.105645 Thermal: 0.000438 LR: 9.97e-06\n",
      "Epoch   3 [9800/10697 ( 91.6%)] Loss: 0.025115 L1: 0.014700 Grad: 0.103950 Thermal: 0.000394 LR: 9.97e-06\n",
      "Epoch   3 [9800/10697 ( 91.6%)] Loss: 0.025115 L1: 0.014700 Grad: 0.103950 Thermal: 0.000394 LR: 9.97e-06\n",
      "Epoch   3 [9850/10697 ( 92.1%)] Loss: 0.025350 L1: 0.014642 Grad: 0.106887 Thermal: 0.000397 LR: 9.97e-06\n",
      "Epoch   3 [9850/10697 ( 92.1%)] Loss: 0.025350 L1: 0.014642 Grad: 0.106887 Thermal: 0.000397 LR: 9.97e-06\n",
      "Epoch   3 [9900/10697 ( 92.5%)] Loss: 0.026450 L1: 0.015171 Grad: 0.112563 Thermal: 0.000453 LR: 9.97e-06\n",
      "Epoch   3 [9900/10697 ( 92.5%)] Loss: 0.026450 L1: 0.015171 Grad: 0.112563 Thermal: 0.000453 LR: 9.97e-06\n",
      "Epoch   3 [9950/10697 ( 93.0%)] Loss: 0.026471 L1: 0.015429 Grad: 0.110212 Thermal: 0.000418 LR: 9.97e-06\n",
      "Epoch   3 [9950/10697 ( 93.0%)] Loss: 0.026471 L1: 0.015429 Grad: 0.110212 Thermal: 0.000418 LR: 9.97e-06\n",
      "Epoch   3 [10000/10697 ( 93.5%)] Loss: 0.029622 L1: 0.016887 Grad: 0.127103 Thermal: 0.000495 LR: 9.97e-06\n",
      "Epoch   3 [10000/10697 ( 93.5%)] Loss: 0.029622 L1: 0.016887 Grad: 0.127103 Thermal: 0.000495 LR: 9.97e-06\n",
      "Epoch   3 [10050/10697 ( 94.0%)] Loss: 0.026350 L1: 0.015048 Grad: 0.112791 Thermal: 0.000457 LR: 9.97e-06\n",
      "Epoch   3 [10050/10697 ( 94.0%)] Loss: 0.026350 L1: 0.015048 Grad: 0.112791 Thermal: 0.000457 LR: 9.97e-06\n",
      "Epoch   3 [10100/10697 ( 94.4%)] Loss: 0.031859 L1: 0.018475 Grad: 0.133545 Thermal: 0.000605 LR: 9.97e-06\n",
      "Epoch   3 [10100/10697 ( 94.4%)] Loss: 0.031859 L1: 0.018475 Grad: 0.133545 Thermal: 0.000605 LR: 9.97e-06\n",
      "Epoch   3 [10150/10697 ( 94.9%)] Loss: 0.021653 L1: 0.012515 Grad: 0.091203 Thermal: 0.000365 LR: 9.97e-06\n",
      "Epoch   3 [10150/10697 ( 94.9%)] Loss: 0.021653 L1: 0.012515 Grad: 0.091203 Thermal: 0.000365 LR: 9.97e-06\n",
      "Epoch   3 [10200/10697 ( 95.4%)] Loss: 0.013681 L1: 0.007504 Grad: 0.061702 Thermal: 0.000145 LR: 9.97e-06\n",
      "Epoch   3 [10200/10697 ( 95.4%)] Loss: 0.013681 L1: 0.007504 Grad: 0.061702 Thermal: 0.000145 LR: 9.97e-06\n",
      "Epoch   3 [10250/10697 ( 95.8%)] Loss: 0.029302 L1: 0.016833 Grad: 0.124418 Thermal: 0.000556 LR: 9.97e-06\n",
      "Epoch   3 [10250/10697 ( 95.8%)] Loss: 0.029302 L1: 0.016833 Grad: 0.124418 Thermal: 0.000556 LR: 9.97e-06\n",
      "Epoch   3 [10300/10697 ( 96.3%)] Loss: 0.029226 L1: 0.017604 Grad: 0.115950 Thermal: 0.000534 LR: 9.97e-06\n",
      "Epoch   3 [10300/10697 ( 96.3%)] Loss: 0.029226 L1: 0.017604 Grad: 0.115950 Thermal: 0.000534 LR: 9.97e-06\n",
      "Epoch   3 [10350/10697 ( 96.8%)] Loss: 0.027735 L1: 0.016732 Grad: 0.109794 Thermal: 0.000480 LR: 9.97e-06\n",
      "Epoch   3 [10350/10697 ( 96.8%)] Loss: 0.027735 L1: 0.016732 Grad: 0.109794 Thermal: 0.000480 LR: 9.97e-06\n",
      "Epoch   3 [10400/10697 ( 97.2%)] Loss: 0.024504 L1: 0.014009 Grad: 0.104763 Thermal: 0.000379 LR: 9.97e-06\n",
      "Epoch   3 [10400/10697 ( 97.2%)] Loss: 0.024504 L1: 0.014009 Grad: 0.104763 Thermal: 0.000379 LR: 9.97e-06\n",
      "Epoch   3 [10450/10697 ( 97.7%)] Loss: 0.029576 L1: 0.017078 Grad: 0.124696 Thermal: 0.000575 LR: 9.97e-06\n",
      "Epoch   3 [10450/10697 ( 97.7%)] Loss: 0.029576 L1: 0.017078 Grad: 0.124696 Thermal: 0.000575 LR: 9.97e-06\n",
      "Epoch   3 [10500/10697 ( 98.2%)] Loss: 0.028633 L1: 0.016368 Grad: 0.122373 Thermal: 0.000538 LR: 9.97e-06\n",
      "Epoch   3 [10500/10697 ( 98.2%)] Loss: 0.028633 L1: 0.016368 Grad: 0.122373 Thermal: 0.000538 LR: 9.97e-06\n",
      "Epoch   3 [10550/10697 ( 98.6%)] Loss: 0.028169 L1: 0.016745 Grad: 0.113972 Thermal: 0.000526 LR: 9.97e-06\n",
      "Epoch   3 [10550/10697 ( 98.6%)] Loss: 0.028169 L1: 0.016745 Grad: 0.113972 Thermal: 0.000526 LR: 9.97e-06\n",
      "Epoch   3 [10600/10697 ( 99.1%)] Loss: 0.028161 L1: 0.016201 Grad: 0.119359 Thermal: 0.000483 LR: 9.97e-06\n",
      "Epoch   3 [10600/10697 ( 99.1%)] Loss: 0.028161 L1: 0.016201 Grad: 0.119359 Thermal: 0.000483 LR: 9.97e-06\n",
      "Epoch   3 [10650/10697 ( 99.6%)] Loss: 0.025438 L1: 0.014766 Grad: 0.106512 Thermal: 0.000409 LR: 9.97e-06\n",
      "Epoch   3 [10650/10697 ( 99.6%)] Loss: 0.025438 L1: 0.014766 Grad: 0.106512 Thermal: 0.000409 LR: 9.97e-06\n",
      "Epoch   3 Summary: Loss=0.027320 (L1:0.0159, Grad:0.1142, Thermal:0.0005) Val_PSNR=0.00dB Best=33.17dB Time=14.4min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch   3 Summary: Loss=0.027320 (L1:0.0159, Grad:0.1142, Thermal:0.0005) Val_PSNR=0.00dB Best=33.17dB Time=14.4min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch   4 [   0/10697 (  0.0%)] Loss: 0.025171 L1: 0.014468 Grad: 0.106828 Thermal: 0.000387 LR: 9.94e-06\n",
      "Epoch   4 [   0/10697 (  0.0%)] Loss: 0.025171 L1: 0.014468 Grad: 0.106828 Thermal: 0.000387 LR: 9.94e-06\n",
      "Epoch   4 [  50/10697 (  0.5%)] Loss: 0.023581 L1: 0.013545 Grad: 0.100176 Thermal: 0.000356 LR: 9.94e-06\n",
      "Epoch   4 [  50/10697 (  0.5%)] Loss: 0.023581 L1: 0.013545 Grad: 0.100176 Thermal: 0.000356 LR: 9.94e-06\n",
      "Epoch   4 [ 100/10697 (  0.9%)] Loss: 0.025739 L1: 0.015129 Grad: 0.105882 Thermal: 0.000436 LR: 9.94e-06\n",
      "Epoch   4 [ 100/10697 (  0.9%)] Loss: 0.025739 L1: 0.015129 Grad: 0.105882 Thermal: 0.000436 LR: 9.94e-06\n",
      "Epoch   4 [ 150/10697 (  1.4%)] Loss: 0.030411 L1: 0.017517 Grad: 0.128638 Thermal: 0.000601 LR: 9.94e-06\n",
      "Epoch   4 [ 150/10697 (  1.4%)] Loss: 0.030411 L1: 0.017517 Grad: 0.128638 Thermal: 0.000601 LR: 9.94e-06\n",
      "Epoch   4 [ 200/10697 (  1.9%)] Loss: 0.023203 L1: 0.013686 Grad: 0.094982 Thermal: 0.000374 LR: 9.94e-06\n",
      "Epoch   4 [ 200/10697 (  1.9%)] Loss: 0.023203 L1: 0.013686 Grad: 0.094982 Thermal: 0.000374 LR: 9.94e-06\n",
      "Epoch   4 [ 250/10697 (  2.3%)] Loss: 0.040324 L1: 0.022919 Grad: 0.173559 Thermal: 0.000984 LR: 9.94e-06\n",
      "Epoch   4 [ 250/10697 (  2.3%)] Loss: 0.040324 L1: 0.022919 Grad: 0.173559 Thermal: 0.000984 LR: 9.94e-06\n",
      "Epoch   4 [ 300/10697 (  2.8%)] Loss: 0.028658 L1: 0.016321 Grad: 0.123112 Thermal: 0.000523 LR: 9.94e-06\n",
      "Epoch   4 [ 300/10697 (  2.8%)] Loss: 0.028658 L1: 0.016321 Grad: 0.123112 Thermal: 0.000523 LR: 9.94e-06\n",
      "Epoch   4 [ 350/10697 (  3.3%)] Loss: 0.024618 L1: 0.014403 Grad: 0.101956 Thermal: 0.000391 LR: 9.94e-06\n",
      "Epoch   4 [ 350/10697 (  3.3%)] Loss: 0.024618 L1: 0.014403 Grad: 0.101956 Thermal: 0.000391 LR: 9.94e-06\n",
      "Epoch   4 [ 400/10697 (  3.7%)] Loss: 0.026071 L1: 0.015133 Grad: 0.109168 Thermal: 0.000434 LR: 9.94e-06\n",
      "Epoch   4 [ 400/10697 (  3.7%)] Loss: 0.026071 L1: 0.015133 Grad: 0.109168 Thermal: 0.000434 LR: 9.94e-06\n",
      "Epoch   4 [ 450/10697 (  4.2%)] Loss: 0.027132 L1: 0.015770 Grad: 0.113392 Thermal: 0.000457 LR: 9.94e-06\n",
      "Epoch   4 [ 450/10697 (  4.2%)] Loss: 0.027132 L1: 0.015770 Grad: 0.113392 Thermal: 0.000457 LR: 9.94e-06\n",
      "Epoch   4 [ 500/10697 (  4.7%)] Loss: 0.021231 L1: 0.012152 Grad: 0.090636 Thermal: 0.000316 LR: 9.94e-06\n",
      "Epoch   4 [ 500/10697 (  4.7%)] Loss: 0.021231 L1: 0.012152 Grad: 0.090636 Thermal: 0.000316 LR: 9.94e-06\n",
      "Epoch   4 [ 550/10697 (  5.1%)] Loss: 0.019738 L1: 0.010849 Grad: 0.088753 Thermal: 0.000273 LR: 9.94e-06\n",
      "Epoch   4 [ 550/10697 (  5.1%)] Loss: 0.019738 L1: 0.010849 Grad: 0.088753 Thermal: 0.000273 LR: 9.94e-06\n",
      "Epoch   4 [ 600/10697 (  5.6%)] Loss: 0.027563 L1: 0.016258 Grad: 0.112808 Thermal: 0.000484 LR: 9.94e-06\n",
      "Epoch   4 [ 600/10697 (  5.6%)] Loss: 0.027563 L1: 0.016258 Grad: 0.112808 Thermal: 0.000484 LR: 9.94e-06\n",
      "Epoch   4 [ 650/10697 (  6.1%)] Loss: 0.032356 L1: 0.018429 Grad: 0.138973 Thermal: 0.000598 LR: 9.94e-06\n",
      "Epoch   4 [ 650/10697 (  6.1%)] Loss: 0.032356 L1: 0.018429 Grad: 0.138973 Thermal: 0.000598 LR: 9.94e-06\n",
      "Epoch   4 [ 700/10697 (  6.5%)] Loss: 0.032655 L1: 0.018194 Grad: 0.144299 Thermal: 0.000611 LR: 9.94e-06\n",
      "Epoch   4 [ 700/10697 (  6.5%)] Loss: 0.032655 L1: 0.018194 Grad: 0.144299 Thermal: 0.000611 LR: 9.94e-06\n",
      "Epoch   4 [ 750/10697 (  7.0%)] Loss: 0.030585 L1: 0.017982 Grad: 0.125742 Thermal: 0.000560 LR: 9.94e-06\n",
      "Epoch   4 [ 750/10697 (  7.0%)] Loss: 0.030585 L1: 0.017982 Grad: 0.125742 Thermal: 0.000560 LR: 9.94e-06\n",
      "Epoch   4 [ 800/10697 (  7.5%)] Loss: 0.020195 L1: 0.011543 Grad: 0.086387 Thermal: 0.000257 LR: 9.94e-06\n",
      "Epoch   4 [ 800/10697 (  7.5%)] Loss: 0.020195 L1: 0.011543 Grad: 0.086387 Thermal: 0.000257 LR: 9.94e-06\n",
      "Epoch   4 [ 850/10697 (  7.9%)] Loss: 0.033839 L1: 0.019546 Grad: 0.142575 Thermal: 0.000704 LR: 9.94e-06\n",
      "Epoch   4 [ 850/10697 (  7.9%)] Loss: 0.033839 L1: 0.019546 Grad: 0.142575 Thermal: 0.000704 LR: 9.94e-06\n",
      "Epoch   4 [ 900/10697 (  8.4%)] Loss: 0.023610 L1: 0.013817 Grad: 0.097738 Thermal: 0.000374 LR: 9.94e-06\n",
      "Epoch   4 [ 900/10697 (  8.4%)] Loss: 0.023610 L1: 0.013817 Grad: 0.097738 Thermal: 0.000374 LR: 9.94e-06\n",
      "Epoch   4 [ 950/10697 (  8.9%)] Loss: 0.025657 L1: 0.014517 Grad: 0.111172 Thermal: 0.000444 LR: 9.94e-06\n",
      "Epoch   4 [ 950/10697 (  8.9%)] Loss: 0.025657 L1: 0.014517 Grad: 0.111172 Thermal: 0.000444 LR: 9.94e-06\n",
      "Epoch   4 [1000/10697 (  9.3%)] Loss: 0.029848 L1: 0.017121 Grad: 0.126961 Thermal: 0.000608 LR: 9.94e-06\n",
      "Epoch   4 [1000/10697 (  9.3%)] Loss: 0.029848 L1: 0.017121 Grad: 0.126961 Thermal: 0.000608 LR: 9.94e-06\n",
      "Epoch   4 [1050/10697 (  9.8%)] Loss: 0.029520 L1: 0.017450 Grad: 0.120429 Thermal: 0.000542 LR: 9.94e-06\n",
      "Epoch   4 [1050/10697 (  9.8%)] Loss: 0.029520 L1: 0.017450 Grad: 0.120429 Thermal: 0.000542 LR: 9.94e-06\n",
      "Epoch   4 [1100/10697 ( 10.3%)] Loss: 0.027358 L1: 0.016197 Grad: 0.111360 Thermal: 0.000516 LR: 9.94e-06\n",
      "Epoch   4 [1100/10697 ( 10.3%)] Loss: 0.027358 L1: 0.016197 Grad: 0.111360 Thermal: 0.000516 LR: 9.94e-06\n",
      "Epoch   4 [1150/10697 ( 10.8%)] Loss: 0.023882 L1: 0.013674 Grad: 0.101902 Thermal: 0.000350 LR: 9.94e-06\n",
      "Epoch   4 [1150/10697 ( 10.8%)] Loss: 0.023882 L1: 0.013674 Grad: 0.101902 Thermal: 0.000350 LR: 9.94e-06\n",
      "Epoch   4 [1200/10697 ( 11.2%)] Loss: 0.026964 L1: 0.015573 Grad: 0.113679 Thermal: 0.000470 LR: 9.94e-06\n",
      "Epoch   4 [1200/10697 ( 11.2%)] Loss: 0.026964 L1: 0.015573 Grad: 0.113679 Thermal: 0.000470 LR: 9.94e-06\n",
      "Epoch   4 [1250/10697 ( 11.7%)] Loss: 0.026912 L1: 0.015731 Grad: 0.111575 Thermal: 0.000468 LR: 9.94e-06\n",
      "Epoch   4 [1250/10697 ( 11.7%)] Loss: 0.026912 L1: 0.015731 Grad: 0.111575 Thermal: 0.000468 LR: 9.94e-06\n",
      "Epoch   4 [1300/10697 ( 12.2%)] Loss: 0.025700 L1: 0.014805 Grad: 0.108732 Thermal: 0.000430 LR: 9.94e-06\n",
      "Epoch   4 [1300/10697 ( 12.2%)] Loss: 0.025700 L1: 0.014805 Grad: 0.108732 Thermal: 0.000430 LR: 9.94e-06\n",
      "Epoch   4 [1350/10697 ( 12.6%)] Loss: 0.020942 L1: 0.012441 Grad: 0.084837 Thermal: 0.000339 LR: 9.94e-06\n",
      "Epoch   4 [1350/10697 ( 12.6%)] Loss: 0.020942 L1: 0.012441 Grad: 0.084837 Thermal: 0.000339 LR: 9.94e-06\n",
      "Epoch   4 [1400/10697 ( 13.1%)] Loss: 0.027214 L1: 0.016476 Grad: 0.107130 Thermal: 0.000493 LR: 9.94e-06\n",
      "Epoch   4 [1400/10697 ( 13.1%)] Loss: 0.027214 L1: 0.016476 Grad: 0.107130 Thermal: 0.000493 LR: 9.94e-06\n",
      "Epoch   4 [1450/10697 ( 13.6%)] Loss: 0.025258 L1: 0.014554 Grad: 0.106828 Thermal: 0.000426 LR: 9.94e-06\n",
      "Epoch   4 [1450/10697 ( 13.6%)] Loss: 0.025258 L1: 0.014554 Grad: 0.106828 Thermal: 0.000426 LR: 9.94e-06\n",
      "Epoch   4 [1500/10697 ( 14.0%)] Loss: 0.024128 L1: 0.014184 Grad: 0.099238 Thermal: 0.000393 LR: 9.94e-06\n",
      "Epoch   4 [1500/10697 ( 14.0%)] Loss: 0.024128 L1: 0.014184 Grad: 0.099238 Thermal: 0.000393 LR: 9.94e-06\n",
      "Epoch   4 [1550/10697 ( 14.5%)] Loss: 0.020208 L1: 0.011685 Grad: 0.085081 Thermal: 0.000299 LR: 9.94e-06\n",
      "Epoch   4 [1550/10697 ( 14.5%)] Loss: 0.020208 L1: 0.011685 Grad: 0.085081 Thermal: 0.000299 LR: 9.94e-06\n",
      "Epoch   4 [1600/10697 ( 15.0%)] Loss: 0.026425 L1: 0.015601 Grad: 0.108010 Thermal: 0.000452 LR: 9.94e-06\n",
      "Epoch   4 [1600/10697 ( 15.0%)] Loss: 0.026425 L1: 0.015601 Grad: 0.108010 Thermal: 0.000452 LR: 9.94e-06\n",
      "Epoch   4 [1650/10697 ( 15.4%)] Loss: 0.028956 L1: 0.017217 Grad: 0.117113 Thermal: 0.000541 LR: 9.94e-06\n",
      "Epoch   4 [1650/10697 ( 15.4%)] Loss: 0.028956 L1: 0.017217 Grad: 0.117113 Thermal: 0.000541 LR: 9.94e-06\n",
      "Epoch   4 [1700/10697 ( 15.9%)] Loss: 0.029445 L1: 0.017107 Grad: 0.123123 Thermal: 0.000515 LR: 9.94e-06\n",
      "Epoch   4 [1700/10697 ( 15.9%)] Loss: 0.029445 L1: 0.017107 Grad: 0.123123 Thermal: 0.000515 LR: 9.94e-06\n",
      "Epoch   4 [1750/10697 ( 16.4%)] Loss: 0.025838 L1: 0.015084 Grad: 0.107333 Thermal: 0.000404 LR: 9.94e-06\n",
      "Epoch   4 [1750/10697 ( 16.4%)] Loss: 0.025838 L1: 0.015084 Grad: 0.107333 Thermal: 0.000404 LR: 9.94e-06\n",
      "Epoch   4 [1800/10697 ( 16.8%)] Loss: 0.020943 L1: 0.012207 Grad: 0.087214 Thermal: 0.000299 LR: 9.94e-06\n",
      "Epoch   4 [1800/10697 ( 16.8%)] Loss: 0.020943 L1: 0.012207 Grad: 0.087214 Thermal: 0.000299 LR: 9.94e-06\n",
      "Epoch   4 [1850/10697 ( 17.3%)] Loss: 0.022287 L1: 0.012672 Grad: 0.095974 Thermal: 0.000343 LR: 9.94e-06\n",
      "Epoch   4 [1850/10697 ( 17.3%)] Loss: 0.022287 L1: 0.012672 Grad: 0.095974 Thermal: 0.000343 LR: 9.94e-06\n",
      "Epoch   4 [1900/10697 ( 17.8%)] Loss: 0.026596 L1: 0.015799 Grad: 0.107726 Thermal: 0.000489 LR: 9.94e-06\n",
      "Epoch   4 [1900/10697 ( 17.8%)] Loss: 0.026596 L1: 0.015799 Grad: 0.107726 Thermal: 0.000489 LR: 9.94e-06\n",
      "Epoch   4 [1950/10697 ( 18.2%)] Loss: 0.029854 L1: 0.017286 Grad: 0.125422 Thermal: 0.000530 LR: 9.94e-06\n",
      "Epoch   4 [1950/10697 ( 18.2%)] Loss: 0.029854 L1: 0.017286 Grad: 0.125422 Thermal: 0.000530 LR: 9.94e-06\n",
      "Epoch   4 [2000/10697 ( 18.7%)] Loss: 0.027647 L1: 0.015985 Grad: 0.116361 Thermal: 0.000516 LR: 9.94e-06\n",
      "Epoch   4 [2000/10697 ( 18.7%)] Loss: 0.027647 L1: 0.015985 Grad: 0.116361 Thermal: 0.000516 LR: 9.94e-06\n",
      "Epoch   4 [2050/10697 ( 19.2%)] Loss: 0.028828 L1: 0.016816 Grad: 0.119889 Thermal: 0.000475 LR: 9.94e-06\n",
      "Epoch   4 [2050/10697 ( 19.2%)] Loss: 0.028828 L1: 0.016816 Grad: 0.119889 Thermal: 0.000475 LR: 9.94e-06\n",
      "Epoch   4 [2100/10697 ( 19.6%)] Loss: 0.025080 L1: 0.014921 Grad: 0.101376 Thermal: 0.000427 LR: 9.94e-06\n",
      "Epoch   4 [2100/10697 ( 19.6%)] Loss: 0.025080 L1: 0.014921 Grad: 0.101376 Thermal: 0.000427 LR: 9.94e-06\n",
      "Epoch   4 [2150/10697 ( 20.1%)] Loss: 0.031878 L1: 0.018719 Grad: 0.131270 Thermal: 0.000627 LR: 9.94e-06\n",
      "Epoch   4 [2150/10697 ( 20.1%)] Loss: 0.031878 L1: 0.018719 Grad: 0.131270 Thermal: 0.000627 LR: 9.94e-06\n",
      "Epoch   4 [2200/10697 ( 20.6%)] Loss: 0.026480 L1: 0.015402 Grad: 0.110529 Thermal: 0.000511 LR: 9.94e-06\n",
      "Epoch   4 [2200/10697 ( 20.6%)] Loss: 0.026480 L1: 0.015402 Grad: 0.110529 Thermal: 0.000511 LR: 9.94e-06\n",
      "Epoch   4 [2250/10697 ( 21.0%)] Loss: 0.022380 L1: 0.012947 Grad: 0.094169 Thermal: 0.000334 LR: 9.94e-06\n",
      "Epoch   4 [2250/10697 ( 21.0%)] Loss: 0.022380 L1: 0.012947 Grad: 0.094169 Thermal: 0.000334 LR: 9.94e-06\n",
      "Epoch   4 [2300/10697 ( 21.5%)] Loss: 0.025563 L1: 0.014556 Grad: 0.109845 Thermal: 0.000450 LR: 9.94e-06\n",
      "Epoch   4 [2300/10697 ( 21.5%)] Loss: 0.025563 L1: 0.014556 Grad: 0.109845 Thermal: 0.000450 LR: 9.94e-06\n",
      "Epoch   4 [2350/10697 ( 22.0%)] Loss: 0.021940 L1: 0.012546 Grad: 0.093763 Thermal: 0.000360 LR: 9.94e-06\n",
      "Epoch   4 [2350/10697 ( 22.0%)] Loss: 0.021940 L1: 0.012546 Grad: 0.093763 Thermal: 0.000360 LR: 9.94e-06\n",
      "Epoch   4 [2400/10697 ( 22.4%)] Loss: 0.024079 L1: 0.014374 Grad: 0.096852 Thermal: 0.000397 LR: 9.94e-06\n",
      "Epoch   4 [2400/10697 ( 22.4%)] Loss: 0.024079 L1: 0.014374 Grad: 0.096852 Thermal: 0.000397 LR: 9.94e-06\n",
      "Epoch   4 [2450/10697 ( 22.9%)] Loss: 0.030892 L1: 0.018012 Grad: 0.128496 Thermal: 0.000604 LR: 9.94e-06\n",
      "Epoch   4 [2450/10697 ( 22.9%)] Loss: 0.030892 L1: 0.018012 Grad: 0.128496 Thermal: 0.000604 LR: 9.94e-06\n",
      "Epoch   4 [2500/10697 ( 23.4%)] Loss: 0.026376 L1: 0.015300 Grad: 0.110549 Thermal: 0.000419 LR: 9.94e-06\n",
      "Epoch   4 [2500/10697 ( 23.4%)] Loss: 0.026376 L1: 0.015300 Grad: 0.110549 Thermal: 0.000419 LR: 9.94e-06\n",
      "Epoch   4 [2550/10697 ( 23.8%)] Loss: 0.027091 L1: 0.015583 Grad: 0.114824 Thermal: 0.000520 LR: 9.94e-06\n",
      "Epoch   4 [2550/10697 ( 23.8%)] Loss: 0.027091 L1: 0.015583 Grad: 0.114824 Thermal: 0.000520 LR: 9.94e-06\n",
      "Epoch   4 [2600/10697 ( 24.3%)] Loss: 0.024460 L1: 0.014348 Grad: 0.100922 Thermal: 0.000393 LR: 9.94e-06\n",
      "Epoch   4 [2600/10697 ( 24.3%)] Loss: 0.024460 L1: 0.014348 Grad: 0.100922 Thermal: 0.000393 LR: 9.94e-06\n",
      "Epoch   4 [2650/10697 ( 24.8%)] Loss: 0.028639 L1: 0.016705 Grad: 0.119065 Thermal: 0.000554 LR: 9.94e-06\n",
      "Epoch   4 [2650/10697 ( 24.8%)] Loss: 0.028639 L1: 0.016705 Grad: 0.119065 Thermal: 0.000554 LR: 9.94e-06\n",
      "Epoch   4 [2700/10697 ( 25.2%)] Loss: 0.027540 L1: 0.016004 Grad: 0.115102 Thermal: 0.000526 LR: 9.94e-06\n",
      "Epoch   4 [2700/10697 ( 25.2%)] Loss: 0.027540 L1: 0.016004 Grad: 0.115102 Thermal: 0.000526 LR: 9.94e-06\n",
      "Epoch   4 [2750/10697 ( 25.7%)] Loss: 0.029863 L1: 0.017263 Grad: 0.125715 Thermal: 0.000566 LR: 9.94e-06\n",
      "Epoch   4 [2750/10697 ( 25.7%)] Loss: 0.029863 L1: 0.017263 Grad: 0.125715 Thermal: 0.000566 LR: 9.94e-06\n",
      "Epoch   4 [2800/10697 ( 26.2%)] Loss: 0.026837 L1: 0.015359 Grad: 0.114534 Thermal: 0.000484 LR: 9.94e-06\n",
      "Epoch   4 [2800/10697 ( 26.2%)] Loss: 0.026837 L1: 0.015359 Grad: 0.114534 Thermal: 0.000484 LR: 9.94e-06\n",
      "Epoch   4 [2850/10697 ( 26.6%)] Loss: 0.022976 L1: 0.013463 Grad: 0.094965 Thermal: 0.000339 LR: 9.94e-06\n",
      "Epoch   4 [2850/10697 ( 26.6%)] Loss: 0.022976 L1: 0.013463 Grad: 0.094965 Thermal: 0.000339 LR: 9.94e-06\n",
      "Epoch   4 [2900/10697 ( 27.1%)] Loss: 0.023528 L1: 0.013994 Grad: 0.095160 Thermal: 0.000370 LR: 9.94e-06\n",
      "Epoch   4 [2900/10697 ( 27.1%)] Loss: 0.023528 L1: 0.013994 Grad: 0.095160 Thermal: 0.000370 LR: 9.94e-06\n",
      "Epoch   4 [2950/10697 ( 27.6%)] Loss: 0.026779 L1: 0.016105 Grad: 0.106513 Thermal: 0.000466 LR: 9.94e-06\n",
      "Epoch   4 [2950/10697 ( 27.6%)] Loss: 0.026779 L1: 0.016105 Grad: 0.106513 Thermal: 0.000466 LR: 9.94e-06\n",
      "Epoch   4 [3000/10697 ( 28.0%)] Loss: 0.030168 L1: 0.017470 Grad: 0.126719 Thermal: 0.000540 LR: 9.94e-06\n",
      "Epoch   4 [3000/10697 ( 28.0%)] Loss: 0.030168 L1: 0.017470 Grad: 0.126719 Thermal: 0.000540 LR: 9.94e-06\n",
      "Epoch   4 [3050/10697 ( 28.5%)] Loss: 0.029391 L1: 0.017050 Grad: 0.123148 Thermal: 0.000527 LR: 9.94e-06\n",
      "Epoch   4 [3050/10697 ( 28.5%)] Loss: 0.029391 L1: 0.017050 Grad: 0.123148 Thermal: 0.000527 LR: 9.94e-06\n",
      "Epoch   4 [3100/10697 ( 29.0%)] Loss: 0.027818 L1: 0.016242 Grad: 0.115501 Thermal: 0.000521 LR: 9.94e-06\n",
      "Epoch   4 [3100/10697 ( 29.0%)] Loss: 0.027818 L1: 0.016242 Grad: 0.115501 Thermal: 0.000521 LR: 9.94e-06\n",
      "Epoch   4 [3150/10697 ( 29.4%)] Loss: 0.022355 L1: 0.012587 Grad: 0.097506 Thermal: 0.000352 LR: 9.94e-06\n",
      "Epoch   4 [3150/10697 ( 29.4%)] Loss: 0.022355 L1: 0.012587 Grad: 0.097506 Thermal: 0.000352 LR: 9.94e-06\n",
      "Epoch   4 [3200/10697 ( 29.9%)] Loss: 0.025967 L1: 0.015446 Grad: 0.104985 Thermal: 0.000458 LR: 9.94e-06\n",
      "Epoch   4 [3200/10697 ( 29.9%)] Loss: 0.025967 L1: 0.015446 Grad: 0.104985 Thermal: 0.000458 LR: 9.94e-06\n",
      "Epoch   4 [3250/10697 ( 30.4%)] Loss: 0.026479 L1: 0.015670 Grad: 0.107859 Thermal: 0.000456 LR: 9.94e-06\n",
      "Epoch   4 [3250/10697 ( 30.4%)] Loss: 0.026479 L1: 0.015670 Grad: 0.107859 Thermal: 0.000456 LR: 9.94e-06\n",
      "Epoch   4 [3300/10697 ( 30.8%)] Loss: 0.028110 L1: 0.016055 Grad: 0.120317 Thermal: 0.000480 LR: 9.94e-06\n",
      "Epoch   4 [3300/10697 ( 30.8%)] Loss: 0.028110 L1: 0.016055 Grad: 0.120317 Thermal: 0.000480 LR: 9.94e-06\n",
      "Epoch   4 [3350/10697 ( 31.3%)] Loss: 0.025446 L1: 0.014845 Grad: 0.105801 Thermal: 0.000430 LR: 9.94e-06\n",
      "Epoch   4 [3350/10697 ( 31.3%)] Loss: 0.025446 L1: 0.014845 Grad: 0.105801 Thermal: 0.000430 LR: 9.94e-06\n",
      "Epoch   4 [3400/10697 ( 31.8%)] Loss: 0.025361 L1: 0.014544 Grad: 0.107969 Thermal: 0.000404 LR: 9.94e-06\n",
      "Epoch   4 [3400/10697 ( 31.8%)] Loss: 0.025361 L1: 0.014544 Grad: 0.107969 Thermal: 0.000404 LR: 9.94e-06\n",
      "Epoch   4 [3450/10697 ( 32.3%)] Loss: 0.031508 L1: 0.018179 Grad: 0.132944 Thermal: 0.000682 LR: 9.94e-06\n",
      "Epoch   4 [3450/10697 ( 32.3%)] Loss: 0.031508 L1: 0.018179 Grad: 0.132944 Thermal: 0.000682 LR: 9.94e-06\n",
      "Epoch   4 [3500/10697 ( 32.7%)] Loss: 0.022313 L1: 0.013208 Grad: 0.090878 Thermal: 0.000343 LR: 9.94e-06\n",
      "Epoch   4 [3500/10697 ( 32.7%)] Loss: 0.022313 L1: 0.013208 Grad: 0.090878 Thermal: 0.000343 LR: 9.94e-06\n",
      "Epoch   4 [3550/10697 ( 33.2%)] Loss: 0.025404 L1: 0.014890 Grad: 0.104933 Thermal: 0.000420 LR: 9.94e-06\n",
      "Epoch   4 [3550/10697 ( 33.2%)] Loss: 0.025404 L1: 0.014890 Grad: 0.104933 Thermal: 0.000420 LR: 9.94e-06\n",
      "Epoch   4 [3600/10697 ( 33.7%)] Loss: 0.021829 L1: 0.013004 Grad: 0.088080 Thermal: 0.000334 LR: 9.94e-06\n",
      "Epoch   4 [3600/10697 ( 33.7%)] Loss: 0.021829 L1: 0.013004 Grad: 0.088080 Thermal: 0.000334 LR: 9.94e-06\n",
      "Epoch   4 [3650/10697 ( 34.1%)] Loss: 0.026592 L1: 0.015981 Grad: 0.105868 Thermal: 0.000494 LR: 9.94e-06\n",
      "Epoch   4 [3650/10697 ( 34.1%)] Loss: 0.026592 L1: 0.015981 Grad: 0.105868 Thermal: 0.000494 LR: 9.94e-06\n",
      "Epoch   4 [3700/10697 ( 34.6%)] Loss: 0.023335 L1: 0.013522 Grad: 0.097941 Thermal: 0.000372 LR: 9.94e-06\n",
      "Epoch   4 [3700/10697 ( 34.6%)] Loss: 0.023335 L1: 0.013522 Grad: 0.097941 Thermal: 0.000372 LR: 9.94e-06\n",
      "Epoch   4 [3750/10697 ( 35.1%)] Loss: 0.026809 L1: 0.015710 Grad: 0.110755 Thermal: 0.000458 LR: 9.94e-06\n",
      "Epoch   4 [3750/10697 ( 35.1%)] Loss: 0.026809 L1: 0.015710 Grad: 0.110755 Thermal: 0.000458 LR: 9.94e-06\n",
      "Epoch   4 [3800/10697 ( 35.5%)] Loss: 0.022592 L1: 0.013345 Grad: 0.092294 Thermal: 0.000356 LR: 9.94e-06\n",
      "Epoch   4 [3800/10697 ( 35.5%)] Loss: 0.022592 L1: 0.013345 Grad: 0.092294 Thermal: 0.000356 LR: 9.94e-06\n",
      "Epoch   4 [3850/10697 ( 36.0%)] Loss: 0.030292 L1: 0.017624 Grad: 0.126404 Thermal: 0.000540 LR: 9.94e-06\n",
      "Epoch   4 [3850/10697 ( 36.0%)] Loss: 0.030292 L1: 0.017624 Grad: 0.126404 Thermal: 0.000540 LR: 9.94e-06\n",
      "Epoch   4 [3900/10697 ( 36.5%)] Loss: 0.028200 L1: 0.016342 Grad: 0.118326 Thermal: 0.000519 LR: 9.94e-06\n",
      "Epoch   4 [3900/10697 ( 36.5%)] Loss: 0.028200 L1: 0.016342 Grad: 0.118326 Thermal: 0.000519 LR: 9.94e-06\n",
      "Epoch   4 [3950/10697 ( 36.9%)] Loss: 0.023952 L1: 0.013943 Grad: 0.099889 Thermal: 0.000395 LR: 9.94e-06\n",
      "Epoch   4 [3950/10697 ( 36.9%)] Loss: 0.023952 L1: 0.013943 Grad: 0.099889 Thermal: 0.000395 LR: 9.94e-06\n",
      "Epoch   4 [4000/10697 ( 37.4%)] Loss: 0.028881 L1: 0.016648 Grad: 0.122065 Thermal: 0.000534 LR: 9.94e-06\n",
      "Epoch   4 [4000/10697 ( 37.4%)] Loss: 0.028881 L1: 0.016648 Grad: 0.122065 Thermal: 0.000534 LR: 9.94e-06\n",
      "Epoch   4 [4050/10697 ( 37.9%)] Loss: 0.027482 L1: 0.015784 Grad: 0.116716 Thermal: 0.000521 LR: 9.94e-06\n",
      "Epoch   4 [4050/10697 ( 37.9%)] Loss: 0.027482 L1: 0.015784 Grad: 0.116716 Thermal: 0.000521 LR: 9.94e-06\n",
      "Epoch   4 [4100/10697 ( 38.3%)] Loss: 0.028146 L1: 0.015896 Grad: 0.122259 Thermal: 0.000490 LR: 9.94e-06\n",
      "Epoch   4 [4100/10697 ( 38.3%)] Loss: 0.028146 L1: 0.015896 Grad: 0.122259 Thermal: 0.000490 LR: 9.94e-06\n",
      "Epoch   4 [4150/10697 ( 38.8%)] Loss: 0.026380 L1: 0.015424 Grad: 0.109324 Thermal: 0.000463 LR: 9.94e-06\n",
      "Epoch   4 [4150/10697 ( 38.8%)] Loss: 0.026380 L1: 0.015424 Grad: 0.109324 Thermal: 0.000463 LR: 9.94e-06\n",
      "Epoch   4 [4200/10697 ( 39.3%)] Loss: 0.029020 L1: 0.017202 Grad: 0.117901 Thermal: 0.000549 LR: 9.94e-06\n",
      "Epoch   4 [4200/10697 ( 39.3%)] Loss: 0.029020 L1: 0.017202 Grad: 0.117901 Thermal: 0.000549 LR: 9.94e-06\n",
      "Epoch   4 [4250/10697 ( 39.7%)] Loss: 0.028255 L1: 0.016116 Grad: 0.121139 Thermal: 0.000517 LR: 9.94e-06\n",
      "Epoch   4 [4250/10697 ( 39.7%)] Loss: 0.028255 L1: 0.016116 Grad: 0.121139 Thermal: 0.000517 LR: 9.94e-06\n",
      "Epoch   4 [4300/10697 ( 40.2%)] Loss: 0.024369 L1: 0.014744 Grad: 0.096027 Thermal: 0.000451 LR: 9.94e-06\n",
      "Epoch   4 [4300/10697 ( 40.2%)] Loss: 0.024369 L1: 0.014744 Grad: 0.096027 Thermal: 0.000451 LR: 9.94e-06\n",
      "Epoch   4 [4350/10697 ( 40.7%)] Loss: 0.028203 L1: 0.016201 Grad: 0.119764 Thermal: 0.000513 LR: 9.94e-06\n",
      "Epoch   4 [4350/10697 ( 40.7%)] Loss: 0.028203 L1: 0.016201 Grad: 0.119764 Thermal: 0.000513 LR: 9.94e-06\n",
      "Epoch   4 [4400/10697 ( 41.1%)] Loss: 0.027087 L1: 0.015959 Grad: 0.111053 Thermal: 0.000453 LR: 9.94e-06\n",
      "Epoch   4 [4400/10697 ( 41.1%)] Loss: 0.027087 L1: 0.015959 Grad: 0.111053 Thermal: 0.000453 LR: 9.94e-06\n",
      "Epoch   4 [4450/10697 ( 41.6%)] Loss: 0.027329 L1: 0.016371 Grad: 0.109336 Thermal: 0.000493 LR: 9.94e-06\n",
      "Epoch   4 [4450/10697 ( 41.6%)] Loss: 0.027329 L1: 0.016371 Grad: 0.109336 Thermal: 0.000493 LR: 9.94e-06\n",
      "Epoch   4 [4500/10697 ( 42.1%)] Loss: 0.022072 L1: 0.012718 Grad: 0.093381 Thermal: 0.000321 LR: 9.94e-06\n",
      "Epoch   4 [4500/10697 ( 42.1%)] Loss: 0.022072 L1: 0.012718 Grad: 0.093381 Thermal: 0.000321 LR: 9.94e-06\n",
      "Epoch   4 [4550/10697 ( 42.5%)] Loss: 0.024512 L1: 0.013858 Grad: 0.106345 Thermal: 0.000381 LR: 9.94e-06\n",
      "Epoch   4 [4550/10697 ( 42.5%)] Loss: 0.024512 L1: 0.013858 Grad: 0.106345 Thermal: 0.000381 LR: 9.94e-06\n",
      "Epoch   4 [4600/10697 ( 43.0%)] Loss: 0.028003 L1: 0.016403 Grad: 0.115762 Thermal: 0.000486 LR: 9.94e-06\n",
      "Epoch   4 [4600/10697 ( 43.0%)] Loss: 0.028003 L1: 0.016403 Grad: 0.115762 Thermal: 0.000486 LR: 9.94e-06\n",
      "Epoch   4 [4650/10697 ( 43.5%)] Loss: 0.031984 L1: 0.018539 Grad: 0.134140 Thermal: 0.000615 LR: 9.94e-06\n",
      "Epoch   4 [4650/10697 ( 43.5%)] Loss: 0.031984 L1: 0.018539 Grad: 0.134140 Thermal: 0.000615 LR: 9.94e-06\n",
      "Epoch   4 [4700/10697 ( 43.9%)] Loss: 0.018139 L1: 0.010599 Grad: 0.075263 Thermal: 0.000270 LR: 9.94e-06\n",
      "Epoch   4 [4700/10697 ( 43.9%)] Loss: 0.018139 L1: 0.010599 Grad: 0.075263 Thermal: 0.000270 LR: 9.94e-06\n",
      "Epoch   4 [4750/10697 ( 44.4%)] Loss: 0.025380 L1: 0.014550 Grad: 0.108088 Thermal: 0.000413 LR: 9.94e-06\n",
      "Epoch   4 [4750/10697 ( 44.4%)] Loss: 0.025380 L1: 0.014550 Grad: 0.108088 Thermal: 0.000413 LR: 9.94e-06\n",
      "Epoch   4 [4800/10697 ( 44.9%)] Loss: 0.028337 L1: 0.016808 Grad: 0.115037 Thermal: 0.000504 LR: 9.94e-06\n",
      "Epoch   4 [4800/10697 ( 44.9%)] Loss: 0.028337 L1: 0.016808 Grad: 0.115037 Thermal: 0.000504 LR: 9.94e-06\n",
      "Epoch   4 [4850/10697 ( 45.3%)] Loss: 0.032576 L1: 0.018587 Grad: 0.139585 Thermal: 0.000604 LR: 9.94e-06\n",
      "Epoch   4 [4850/10697 ( 45.3%)] Loss: 0.032576 L1: 0.018587 Grad: 0.139585 Thermal: 0.000604 LR: 9.94e-06\n",
      "Epoch   4 [4900/10697 ( 45.8%)] Loss: 0.025084 L1: 0.014982 Grad: 0.100798 Thermal: 0.000434 LR: 9.94e-06\n",
      "Epoch   4 [4900/10697 ( 45.8%)] Loss: 0.025084 L1: 0.014982 Grad: 0.100798 Thermal: 0.000434 LR: 9.94e-06\n",
      "Epoch   4 [4950/10697 ( 46.3%)] Loss: 0.025113 L1: 0.014570 Grad: 0.105225 Thermal: 0.000420 LR: 9.94e-06\n",
      "Epoch   4 [4950/10697 ( 46.3%)] Loss: 0.025113 L1: 0.014570 Grad: 0.105225 Thermal: 0.000420 LR: 9.94e-06\n",
      "Epoch   4 [5000/10697 ( 46.7%)] Loss: 0.024141 L1: 0.014005 Grad: 0.101184 Thermal: 0.000364 LR: 9.94e-06\n",
      "Epoch   4 [5000/10697 ( 46.7%)] Loss: 0.024141 L1: 0.014005 Grad: 0.101184 Thermal: 0.000364 LR: 9.94e-06\n",
      "Epoch   4 [5050/10697 ( 47.2%)] Loss: 0.029643 L1: 0.017240 Grad: 0.123775 Thermal: 0.000496 LR: 9.94e-06\n",
      "Epoch   4 [5050/10697 ( 47.2%)] Loss: 0.029643 L1: 0.017240 Grad: 0.123775 Thermal: 0.000496 LR: 9.94e-06\n",
      "Epoch   4 [5100/10697 ( 47.7%)] Loss: 0.029544 L1: 0.016913 Grad: 0.126040 Thermal: 0.000528 LR: 9.94e-06\n",
      "Epoch   4 [5100/10697 ( 47.7%)] Loss: 0.029544 L1: 0.016913 Grad: 0.126040 Thermal: 0.000528 LR: 9.94e-06\n",
      "Epoch   4 [5150/10697 ( 48.1%)] Loss: 0.030768 L1: 0.017798 Grad: 0.129425 Thermal: 0.000556 LR: 9.94e-06\n",
      "Epoch   4 [5150/10697 ( 48.1%)] Loss: 0.030768 L1: 0.017798 Grad: 0.129425 Thermal: 0.000556 LR: 9.94e-06\n",
      "Epoch   4 [5200/10697 ( 48.6%)] Loss: 0.024526 L1: 0.014356 Grad: 0.101493 Thermal: 0.000411 LR: 9.94e-06\n",
      "Epoch   4 [5200/10697 ( 48.6%)] Loss: 0.024526 L1: 0.014356 Grad: 0.101493 Thermal: 0.000411 LR: 9.94e-06\n",
      "Epoch   4 [5250/10697 ( 49.1%)] Loss: 0.028598 L1: 0.017045 Grad: 0.115278 Thermal: 0.000511 LR: 9.94e-06\n",
      "Epoch   4 [5250/10697 ( 49.1%)] Loss: 0.028598 L1: 0.017045 Grad: 0.115278 Thermal: 0.000511 LR: 9.94e-06\n",
      "Epoch   4 [5300/10697 ( 49.5%)] Loss: 0.030353 L1: 0.017988 Grad: 0.123363 Thermal: 0.000567 LR: 9.94e-06\n",
      "Epoch   4 [5300/10697 ( 49.5%)] Loss: 0.030353 L1: 0.017988 Grad: 0.123363 Thermal: 0.000567 LR: 9.94e-06\n",
      "Epoch   4 [5350/10697 ( 50.0%)] Loss: 0.026788 L1: 0.015953 Grad: 0.108106 Thermal: 0.000479 LR: 9.94e-06\n",
      "Epoch   4 [5350/10697 ( 50.0%)] Loss: 0.026788 L1: 0.015953 Grad: 0.108106 Thermal: 0.000479 LR: 9.94e-06\n",
      "Epoch   4 [5400/10697 ( 50.5%)] Loss: 0.026620 L1: 0.015835 Grad: 0.107613 Thermal: 0.000485 LR: 9.94e-06\n",
      "Epoch   4 [5400/10697 ( 50.5%)] Loss: 0.026620 L1: 0.015835 Grad: 0.107613 Thermal: 0.000485 LR: 9.94e-06\n",
      "Epoch   4 [5450/10697 ( 50.9%)] Loss: 0.026649 L1: 0.015334 Grad: 0.112932 Thermal: 0.000436 LR: 9.94e-06\n",
      "Epoch   4 [5450/10697 ( 50.9%)] Loss: 0.026649 L1: 0.015334 Grad: 0.112932 Thermal: 0.000436 LR: 9.94e-06\n",
      "Epoch   4 [5500/10697 ( 51.4%)] Loss: 0.025067 L1: 0.014896 Grad: 0.101497 Thermal: 0.000426 LR: 9.94e-06\n",
      "Epoch   4 [5500/10697 ( 51.4%)] Loss: 0.025067 L1: 0.014896 Grad: 0.101497 Thermal: 0.000426 LR: 9.94e-06\n",
      "Epoch   4 [5550/10697 ( 51.9%)] Loss: 0.022677 L1: 0.013301 Grad: 0.093589 Thermal: 0.000345 LR: 9.94e-06\n",
      "Epoch   4 [5550/10697 ( 51.9%)] Loss: 0.022677 L1: 0.013301 Grad: 0.093589 Thermal: 0.000345 LR: 9.94e-06\n",
      "Epoch   4 [5600/10697 ( 52.4%)] Loss: 0.022407 L1: 0.013060 Grad: 0.093301 Thermal: 0.000329 LR: 9.94e-06\n",
      "Epoch   4 [5600/10697 ( 52.4%)] Loss: 0.022407 L1: 0.013060 Grad: 0.093301 Thermal: 0.000329 LR: 9.94e-06\n",
      "Epoch   4 [5650/10697 ( 52.8%)] Loss: 0.033593 L1: 0.019228 Grad: 0.143330 Thermal: 0.000655 LR: 9.94e-06\n",
      "Epoch   4 [5650/10697 ( 52.8%)] Loss: 0.033593 L1: 0.019228 Grad: 0.143330 Thermal: 0.000655 LR: 9.94e-06\n",
      "Epoch   4 [5700/10697 ( 53.3%)] Loss: 0.027750 L1: 0.015943 Grad: 0.117821 Thermal: 0.000504 LR: 9.94e-06\n",
      "Epoch   4 [5700/10697 ( 53.3%)] Loss: 0.027750 L1: 0.015943 Grad: 0.117821 Thermal: 0.000504 LR: 9.94e-06\n",
      "Epoch   4 [5750/10697 ( 53.8%)] Loss: 0.023739 L1: 0.013927 Grad: 0.097932 Thermal: 0.000382 LR: 9.94e-06\n",
      "Epoch   4 [5750/10697 ( 53.8%)] Loss: 0.023739 L1: 0.013927 Grad: 0.097932 Thermal: 0.000382 LR: 9.94e-06\n",
      "Epoch   4 [5800/10697 ( 54.2%)] Loss: 0.028871 L1: 0.017001 Grad: 0.118422 Thermal: 0.000550 LR: 9.94e-06\n",
      "Epoch   4 [5800/10697 ( 54.2%)] Loss: 0.028871 L1: 0.017001 Grad: 0.118422 Thermal: 0.000550 LR: 9.94e-06\n",
      "Epoch   4 [5850/10697 ( 54.7%)] Loss: 0.032706 L1: 0.018875 Grad: 0.137957 Thermal: 0.000707 LR: 9.94e-06\n",
      "Epoch   4 [5850/10697 ( 54.7%)] Loss: 0.032706 L1: 0.018875 Grad: 0.137957 Thermal: 0.000707 LR: 9.94e-06\n",
      "Epoch   4 [5900/10697 ( 55.2%)] Loss: 0.024770 L1: 0.013987 Grad: 0.107645 Thermal: 0.000368 LR: 9.94e-06\n",
      "Epoch   4 [5900/10697 ( 55.2%)] Loss: 0.024770 L1: 0.013987 Grad: 0.107645 Thermal: 0.000368 LR: 9.94e-06\n",
      "Epoch   4 [5950/10697 ( 55.6%)] Loss: 0.028513 L1: 0.016432 Grad: 0.120536 Thermal: 0.000550 LR: 9.94e-06\n",
      "Epoch   4 [5950/10697 ( 55.6%)] Loss: 0.028513 L1: 0.016432 Grad: 0.120536 Thermal: 0.000550 LR: 9.94e-06\n",
      "Epoch   4 [6000/10697 ( 56.1%)] Loss: 0.018614 L1: 0.010593 Grad: 0.080076 Thermal: 0.000272 LR: 9.94e-06\n",
      "Epoch   4 [6000/10697 ( 56.1%)] Loss: 0.018614 L1: 0.010593 Grad: 0.080076 Thermal: 0.000272 LR: 9.94e-06\n",
      "Epoch   4 [6050/10697 ( 56.6%)] Loss: 0.026159 L1: 0.015077 Grad: 0.110580 Thermal: 0.000488 LR: 9.94e-06\n",
      "Epoch   4 [6050/10697 ( 56.6%)] Loss: 0.026159 L1: 0.015077 Grad: 0.110580 Thermal: 0.000488 LR: 9.94e-06\n",
      "Epoch   4 [6100/10697 ( 57.0%)] Loss: 0.030484 L1: 0.017835 Grad: 0.126194 Thermal: 0.000597 LR: 9.94e-06\n",
      "Epoch   4 [6100/10697 ( 57.0%)] Loss: 0.030484 L1: 0.017835 Grad: 0.126194 Thermal: 0.000597 LR: 9.94e-06\n",
      "Epoch   4 [6150/10697 ( 57.5%)] Loss: 0.025872 L1: 0.015626 Grad: 0.102223 Thermal: 0.000471 LR: 9.94e-06\n",
      "Epoch   4 [6150/10697 ( 57.5%)] Loss: 0.025872 L1: 0.015626 Grad: 0.102223 Thermal: 0.000471 LR: 9.94e-06\n",
      "Epoch   4 [6200/10697 ( 58.0%)] Loss: 0.027373 L1: 0.015905 Grad: 0.114441 Thermal: 0.000477 LR: 9.94e-06\n",
      "Epoch   4 [6200/10697 ( 58.0%)] Loss: 0.027373 L1: 0.015905 Grad: 0.114441 Thermal: 0.000477 LR: 9.94e-06\n",
      "Epoch   4 [6250/10697 ( 58.4%)] Loss: 0.024449 L1: 0.013714 Grad: 0.107152 Thermal: 0.000392 LR: 9.94e-06\n",
      "Epoch   4 [6250/10697 ( 58.4%)] Loss: 0.024449 L1: 0.013714 Grad: 0.107152 Thermal: 0.000392 LR: 9.94e-06\n",
      "Epoch   4 [6300/10697 ( 58.9%)] Loss: 0.027411 L1: 0.015622 Grad: 0.117660 Thermal: 0.000453 LR: 9.94e-06\n",
      "Epoch   4 [6300/10697 ( 58.9%)] Loss: 0.027411 L1: 0.015622 Grad: 0.117660 Thermal: 0.000453 LR: 9.94e-06\n",
      "Epoch   4 [6350/10697 ( 59.4%)] Loss: 0.028898 L1: 0.016746 Grad: 0.121264 Thermal: 0.000525 LR: 9.94e-06\n",
      "Epoch   4 [6350/10697 ( 59.4%)] Loss: 0.028898 L1: 0.016746 Grad: 0.121264 Thermal: 0.000525 LR: 9.94e-06\n",
      "Epoch   4 [6400/10697 ( 59.8%)] Loss: 0.023719 L1: 0.013323 Grad: 0.103780 Thermal: 0.000351 LR: 9.94e-06\n",
      "Epoch   4 [6400/10697 ( 59.8%)] Loss: 0.023719 L1: 0.013323 Grad: 0.103780 Thermal: 0.000351 LR: 9.94e-06\n",
      "Epoch   4 [6450/10697 ( 60.3%)] Loss: 0.025766 L1: 0.014896 Grad: 0.108500 Thermal: 0.000400 LR: 9.94e-06\n",
      "Epoch   4 [6450/10697 ( 60.3%)] Loss: 0.025766 L1: 0.014896 Grad: 0.108500 Thermal: 0.000400 LR: 9.94e-06\n",
      "Epoch   4 [6500/10697 ( 60.8%)] Loss: 0.026926 L1: 0.015452 Grad: 0.114512 Thermal: 0.000450 LR: 9.94e-06\n",
      "Epoch   4 [6500/10697 ( 60.8%)] Loss: 0.026926 L1: 0.015452 Grad: 0.114512 Thermal: 0.000450 LR: 9.94e-06\n",
      "Epoch   4 [6550/10697 ( 61.2%)] Loss: 0.035711 L1: 0.020546 Grad: 0.151264 Thermal: 0.000774 LR: 9.94e-06\n",
      "Epoch   4 [6550/10697 ( 61.2%)] Loss: 0.035711 L1: 0.020546 Grad: 0.151264 Thermal: 0.000774 LR: 9.94e-06\n",
      "Epoch   4 [6600/10697 ( 61.7%)] Loss: 0.022509 L1: 0.012867 Grad: 0.096270 Thermal: 0.000312 LR: 9.94e-06\n",
      "Epoch   4 [6600/10697 ( 61.7%)] Loss: 0.022509 L1: 0.012867 Grad: 0.096270 Thermal: 0.000312 LR: 9.94e-06\n",
      "Epoch   4 [6650/10697 ( 62.2%)] Loss: 0.027890 L1: 0.016196 Grad: 0.116710 Thermal: 0.000465 LR: 9.94e-06\n",
      "Epoch   4 [6650/10697 ( 62.2%)] Loss: 0.027890 L1: 0.016196 Grad: 0.116710 Thermal: 0.000465 LR: 9.94e-06\n",
      "Epoch   4 [6700/10697 ( 62.6%)] Loss: 0.029488 L1: 0.017278 Grad: 0.121848 Thermal: 0.000505 LR: 9.94e-06\n",
      "Epoch   4 [6700/10697 ( 62.6%)] Loss: 0.029488 L1: 0.017278 Grad: 0.121848 Thermal: 0.000505 LR: 9.94e-06\n",
      "Epoch   4 [6750/10697 ( 63.1%)] Loss: 0.027471 L1: 0.015972 Grad: 0.114730 Thermal: 0.000508 LR: 9.94e-06\n",
      "Epoch   4 [6750/10697 ( 63.1%)] Loss: 0.027471 L1: 0.015972 Grad: 0.114730 Thermal: 0.000508 LR: 9.94e-06\n",
      "Epoch   4 [6800/10697 ( 63.6%)] Loss: 0.023471 L1: 0.013241 Grad: 0.102122 Thermal: 0.000362 LR: 9.94e-06\n",
      "Epoch   4 [6800/10697 ( 63.6%)] Loss: 0.023471 L1: 0.013241 Grad: 0.102122 Thermal: 0.000362 LR: 9.94e-06\n",
      "Epoch   4 [6850/10697 ( 64.0%)] Loss: 0.030516 L1: 0.017866 Grad: 0.126204 Thermal: 0.000582 LR: 9.94e-06\n",
      "Epoch   4 [6850/10697 ( 64.0%)] Loss: 0.030516 L1: 0.017866 Grad: 0.126204 Thermal: 0.000582 LR: 9.94e-06\n",
      "Epoch   4 [6900/10697 ( 64.5%)] Loss: 0.027816 L1: 0.016584 Grad: 0.112079 Thermal: 0.000482 LR: 9.94e-06\n",
      "Epoch   4 [6900/10697 ( 64.5%)] Loss: 0.027816 L1: 0.016584 Grad: 0.112079 Thermal: 0.000482 LR: 9.94e-06\n",
      "Epoch   4 [6950/10697 ( 65.0%)] Loss: 0.024254 L1: 0.014213 Grad: 0.100224 Thermal: 0.000379 LR: 9.94e-06\n",
      "Epoch   4 [6950/10697 ( 65.0%)] Loss: 0.024254 L1: 0.014213 Grad: 0.100224 Thermal: 0.000379 LR: 9.94e-06\n",
      "Epoch   4 [7000/10697 ( 65.4%)] Loss: 0.029860 L1: 0.017053 Grad: 0.127799 Thermal: 0.000556 LR: 9.94e-06\n",
      "Epoch   4 [7000/10697 ( 65.4%)] Loss: 0.029860 L1: 0.017053 Grad: 0.127799 Thermal: 0.000556 LR: 9.94e-06\n",
      "Epoch   4 [7050/10697 ( 65.9%)] Loss: 0.023467 L1: 0.013738 Grad: 0.097102 Thermal: 0.000365 LR: 9.94e-06\n",
      "Epoch   4 [7050/10697 ( 65.9%)] Loss: 0.023467 L1: 0.013738 Grad: 0.097102 Thermal: 0.000365 LR: 9.94e-06\n",
      "Epoch   4 [7100/10697 ( 66.4%)] Loss: 0.033904 L1: 0.019166 Grad: 0.147031 Thermal: 0.000702 LR: 9.94e-06\n",
      "Epoch   4 [7100/10697 ( 66.4%)] Loss: 0.033904 L1: 0.019166 Grad: 0.147031 Thermal: 0.000702 LR: 9.94e-06\n",
      "Epoch   4 [7150/10697 ( 66.8%)] Loss: 0.028900 L1: 0.016426 Grad: 0.124480 Thermal: 0.000513 LR: 9.94e-06\n",
      "Epoch   4 [7150/10697 ( 66.8%)] Loss: 0.028900 L1: 0.016426 Grad: 0.124480 Thermal: 0.000513 LR: 9.94e-06\n",
      "Epoch   4 [7200/10697 ( 67.3%)] Loss: 0.026217 L1: 0.014628 Grad: 0.115660 Thermal: 0.000459 LR: 9.94e-06\n",
      "Epoch   4 [7200/10697 ( 67.3%)] Loss: 0.026217 L1: 0.014628 Grad: 0.115660 Thermal: 0.000459 LR: 9.94e-06\n",
      "Epoch   4 [7250/10697 ( 67.8%)] Loss: 0.029175 L1: 0.016831 Grad: 0.123179 Thermal: 0.000523 LR: 9.94e-06\n",
      "Epoch   4 [7250/10697 ( 67.8%)] Loss: 0.029175 L1: 0.016831 Grad: 0.123179 Thermal: 0.000523 LR: 9.94e-06\n",
      "Epoch   4 [7300/10697 ( 68.2%)] Loss: 0.029014 L1: 0.016615 Grad: 0.123753 Thermal: 0.000485 LR: 9.94e-06\n",
      "Epoch   4 [7300/10697 ( 68.2%)] Loss: 0.029014 L1: 0.016615 Grad: 0.123753 Thermal: 0.000485 LR: 9.94e-06\n",
      "Epoch   4 [7350/10697 ( 68.7%)] Loss: 0.029534 L1: 0.017249 Grad: 0.122561 Thermal: 0.000574 LR: 9.94e-06\n",
      "Epoch   4 [7350/10697 ( 68.7%)] Loss: 0.029534 L1: 0.017249 Grad: 0.122561 Thermal: 0.000574 LR: 9.94e-06\n",
      "Epoch   4 [7400/10697 ( 69.2%)] Loss: 0.027169 L1: 0.015783 Grad: 0.113618 Thermal: 0.000486 LR: 9.94e-06\n",
      "Epoch   4 [7400/10697 ( 69.2%)] Loss: 0.027169 L1: 0.015783 Grad: 0.113618 Thermal: 0.000486 LR: 9.94e-06\n",
      "Epoch   4 [7450/10697 ( 69.6%)] Loss: 0.026238 L1: 0.015472 Grad: 0.107435 Thermal: 0.000449 LR: 9.94e-06\n",
      "Epoch   4 [7450/10697 ( 69.6%)] Loss: 0.026238 L1: 0.015472 Grad: 0.107435 Thermal: 0.000449 LR: 9.94e-06\n",
      "Epoch   4 [7500/10697 ( 70.1%)] Loss: 0.026833 L1: 0.015539 Grad: 0.112701 Thermal: 0.000479 LR: 9.94e-06\n",
      "Epoch   4 [7500/10697 ( 70.1%)] Loss: 0.026833 L1: 0.015539 Grad: 0.112701 Thermal: 0.000479 LR: 9.94e-06\n",
      "Epoch   4 [7550/10697 ( 70.6%)] Loss: 0.028550 L1: 0.016839 Grad: 0.116844 Thermal: 0.000534 LR: 9.94e-06\n",
      "Epoch   4 [7550/10697 ( 70.6%)] Loss: 0.028550 L1: 0.016839 Grad: 0.116844 Thermal: 0.000534 LR: 9.94e-06\n",
      "Epoch   4 [7600/10697 ( 71.0%)] Loss: 0.027438 L1: 0.016267 Grad: 0.111477 Thermal: 0.000467 LR: 9.94e-06\n",
      "Epoch   4 [7600/10697 ( 71.0%)] Loss: 0.027438 L1: 0.016267 Grad: 0.111477 Thermal: 0.000467 LR: 9.94e-06\n",
      "Epoch   4 [7650/10697 ( 71.5%)] Loss: 0.027805 L1: 0.016391 Grad: 0.113915 Thermal: 0.000454 LR: 9.94e-06\n",
      "Epoch   4 [7650/10697 ( 71.5%)] Loss: 0.027805 L1: 0.016391 Grad: 0.113915 Thermal: 0.000454 LR: 9.94e-06\n",
      "Epoch   4 [7700/10697 ( 72.0%)] Loss: 0.031610 L1: 0.018249 Grad: 0.133227 Thermal: 0.000758 LR: 9.94e-06\n",
      "Epoch   4 [7700/10697 ( 72.0%)] Loss: 0.031610 L1: 0.018249 Grad: 0.133227 Thermal: 0.000758 LR: 9.94e-06\n",
      "Epoch   4 [7750/10697 ( 72.5%)] Loss: 0.026214 L1: 0.015314 Grad: 0.108780 Thermal: 0.000441 LR: 9.94e-06\n",
      "Epoch   4 [7750/10697 ( 72.5%)] Loss: 0.026214 L1: 0.015314 Grad: 0.108780 Thermal: 0.000441 LR: 9.94e-06\n",
      "Epoch   4 [7800/10697 ( 72.9%)] Loss: 0.030733 L1: 0.017533 Grad: 0.131696 Thermal: 0.000593 LR: 9.94e-06\n",
      "Epoch   4 [7800/10697 ( 72.9%)] Loss: 0.030733 L1: 0.017533 Grad: 0.131696 Thermal: 0.000593 LR: 9.94e-06\n",
      "Epoch   4 [7850/10697 ( 73.4%)] Loss: 0.027904 L1: 0.016654 Grad: 0.112265 Thermal: 0.000467 LR: 9.94e-06\n",
      "Epoch   4 [7850/10697 ( 73.4%)] Loss: 0.027904 L1: 0.016654 Grad: 0.112265 Thermal: 0.000467 LR: 9.94e-06\n",
      "Epoch   4 [7900/10697 ( 73.9%)] Loss: 0.033002 L1: 0.018866 Grad: 0.141032 Thermal: 0.000649 LR: 9.94e-06\n",
      "Epoch   4 [7900/10697 ( 73.9%)] Loss: 0.033002 L1: 0.018866 Grad: 0.141032 Thermal: 0.000649 LR: 9.94e-06\n",
      "Epoch   4 [7950/10697 ( 74.3%)] Loss: 0.022822 L1: 0.013139 Grad: 0.096668 Thermal: 0.000331 LR: 9.94e-06\n",
      "Epoch   4 [7950/10697 ( 74.3%)] Loss: 0.022822 L1: 0.013139 Grad: 0.096668 Thermal: 0.000331 LR: 9.94e-06\n",
      "Epoch   4 [8000/10697 ( 74.8%)] Loss: 0.022539 L1: 0.012973 Grad: 0.095496 Thermal: 0.000326 LR: 9.94e-06\n",
      "Epoch   4 [8000/10697 ( 74.8%)] Loss: 0.022539 L1: 0.012973 Grad: 0.095496 Thermal: 0.000326 LR: 9.94e-06\n",
      "Epoch   4 [8050/10697 ( 75.3%)] Loss: 0.029523 L1: 0.017042 Grad: 0.124561 Thermal: 0.000484 LR: 9.94e-06\n",
      "Epoch   4 [8050/10697 ( 75.3%)] Loss: 0.029523 L1: 0.017042 Grad: 0.124561 Thermal: 0.000484 LR: 9.94e-06\n",
      "Epoch   4 [8100/10697 ( 75.7%)] Loss: 0.028117 L1: 0.017007 Grad: 0.110838 Thermal: 0.000539 LR: 9.94e-06\n",
      "Epoch   4 [8100/10697 ( 75.7%)] Loss: 0.028117 L1: 0.017007 Grad: 0.110838 Thermal: 0.000539 LR: 9.94e-06\n",
      "Epoch   4 [8150/10697 ( 76.2%)] Loss: 0.020015 L1: 0.011269 Grad: 0.087295 Thermal: 0.000321 LR: 9.94e-06\n",
      "Epoch   4 [8150/10697 ( 76.2%)] Loss: 0.020015 L1: 0.011269 Grad: 0.087295 Thermal: 0.000321 LR: 9.94e-06\n",
      "Epoch   4 [8200/10697 ( 76.7%)] Loss: 0.030089 L1: 0.017364 Grad: 0.126956 Thermal: 0.000594 LR: 9.94e-06\n",
      "Epoch   4 [8200/10697 ( 76.7%)] Loss: 0.030089 L1: 0.017364 Grad: 0.126956 Thermal: 0.000594 LR: 9.94e-06\n",
      "Epoch   4 [8250/10697 ( 77.1%)] Loss: 0.030991 L1: 0.018323 Grad: 0.126377 Thermal: 0.000609 LR: 9.94e-06\n",
      "Epoch   4 [8250/10697 ( 77.1%)] Loss: 0.030991 L1: 0.018323 Grad: 0.126377 Thermal: 0.000609 LR: 9.94e-06\n",
      "Epoch   4 [8300/10697 ( 77.6%)] Loss: 0.026826 L1: 0.015571 Grad: 0.112316 Thermal: 0.000478 LR: 9.94e-06\n",
      "Epoch   4 [8300/10697 ( 77.6%)] Loss: 0.026826 L1: 0.015571 Grad: 0.112316 Thermal: 0.000478 LR: 9.94e-06\n",
      "Epoch   4 [8350/10697 ( 78.1%)] Loss: 0.031785 L1: 0.018117 Grad: 0.136389 Thermal: 0.000569 LR: 9.94e-06\n",
      "Epoch   4 [8350/10697 ( 78.1%)] Loss: 0.031785 L1: 0.018117 Grad: 0.136389 Thermal: 0.000569 LR: 9.94e-06\n",
      "Epoch   4 [8400/10697 ( 78.5%)] Loss: 0.031943 L1: 0.018710 Grad: 0.131967 Thermal: 0.000722 LR: 9.94e-06\n",
      "Epoch   4 [8400/10697 ( 78.5%)] Loss: 0.031943 L1: 0.018710 Grad: 0.131967 Thermal: 0.000722 LR: 9.94e-06\n",
      "Epoch   4 [8450/10697 ( 79.0%)] Loss: 0.031876 L1: 0.018095 Grad: 0.137483 Thermal: 0.000658 LR: 9.94e-06\n",
      "Epoch   4 [8450/10697 ( 79.0%)] Loss: 0.031876 L1: 0.018095 Grad: 0.137483 Thermal: 0.000658 LR: 9.94e-06\n",
      "Epoch   4 [8500/10697 ( 79.5%)] Loss: 0.031875 L1: 0.018548 Grad: 0.132960 Thermal: 0.000619 LR: 9.94e-06\n",
      "Epoch   4 [8500/10697 ( 79.5%)] Loss: 0.031875 L1: 0.018548 Grad: 0.132960 Thermal: 0.000619 LR: 9.94e-06\n",
      "Epoch   4 [8550/10697 ( 79.9%)] Loss: 0.025478 L1: 0.014671 Grad: 0.107870 Thermal: 0.000411 LR: 9.94e-06\n",
      "Epoch   4 [8550/10697 ( 79.9%)] Loss: 0.025478 L1: 0.014671 Grad: 0.107870 Thermal: 0.000411 LR: 9.94e-06\n",
      "Epoch   4 [8600/10697 ( 80.4%)] Loss: 0.033144 L1: 0.019429 Grad: 0.136806 Thermal: 0.000689 LR: 9.94e-06\n",
      "Epoch   4 [8600/10697 ( 80.4%)] Loss: 0.033144 L1: 0.019429 Grad: 0.136806 Thermal: 0.000689 LR: 9.94e-06\n",
      "Epoch   4 [8650/10697 ( 80.9%)] Loss: 0.023457 L1: 0.013402 Grad: 0.100362 Thermal: 0.000376 LR: 9.94e-06\n",
      "Epoch   4 [8650/10697 ( 80.9%)] Loss: 0.023457 L1: 0.013402 Grad: 0.100362 Thermal: 0.000376 LR: 9.94e-06\n",
      "Epoch   4 [8700/10697 ( 81.3%)] Loss: 0.026904 L1: 0.015441 Grad: 0.114411 Thermal: 0.000446 LR: 9.94e-06\n",
      "Epoch   4 [8700/10697 ( 81.3%)] Loss: 0.026904 L1: 0.015441 Grad: 0.114411 Thermal: 0.000446 LR: 9.94e-06\n",
      "Epoch   4 [8750/10697 ( 81.8%)] Loss: 0.030281 L1: 0.017858 Grad: 0.123926 Thermal: 0.000626 LR: 9.94e-06\n",
      "Epoch   4 [8750/10697 ( 81.8%)] Loss: 0.030281 L1: 0.017858 Grad: 0.123926 Thermal: 0.000626 LR: 9.94e-06\n",
      "Epoch   4 [8800/10697 ( 82.3%)] Loss: 0.025389 L1: 0.014538 Grad: 0.108309 Thermal: 0.000400 LR: 9.94e-06\n",
      "Epoch   4 [8800/10697 ( 82.3%)] Loss: 0.025389 L1: 0.014538 Grad: 0.108309 Thermal: 0.000400 LR: 9.94e-06\n",
      "Epoch   4 [8850/10697 ( 82.7%)] Loss: 0.025747 L1: 0.015079 Grad: 0.106459 Thermal: 0.000443 LR: 9.94e-06\n",
      "Epoch   4 [8850/10697 ( 82.7%)] Loss: 0.025747 L1: 0.015079 Grad: 0.106459 Thermal: 0.000443 LR: 9.94e-06\n",
      "Epoch   4 [8900/10697 ( 83.2%)] Loss: 0.024384 L1: 0.014236 Grad: 0.101302 Thermal: 0.000362 LR: 9.94e-06\n",
      "Epoch   4 [8900/10697 ( 83.2%)] Loss: 0.024384 L1: 0.014236 Grad: 0.101302 Thermal: 0.000362 LR: 9.94e-06\n",
      "Epoch   4 [8950/10697 ( 83.7%)] Loss: 0.017620 L1: 0.010344 Grad: 0.072633 Thermal: 0.000249 LR: 9.94e-06\n",
      "Epoch   4 [8950/10697 ( 83.7%)] Loss: 0.017620 L1: 0.010344 Grad: 0.072633 Thermal: 0.000249 LR: 9.94e-06\n",
      "Epoch   4 [9000/10697 ( 84.1%)] Loss: 0.023989 L1: 0.013876 Grad: 0.100922 Thermal: 0.000406 LR: 9.94e-06\n",
      "Epoch   4 [9000/10697 ( 84.1%)] Loss: 0.023989 L1: 0.013876 Grad: 0.100922 Thermal: 0.000406 LR: 9.94e-06\n",
      "Epoch   4 [9050/10697 ( 84.6%)] Loss: 0.025633 L1: 0.015132 Grad: 0.104815 Thermal: 0.000398 LR: 9.94e-06\n",
      "Epoch   4 [9050/10697 ( 84.6%)] Loss: 0.025633 L1: 0.015132 Grad: 0.104815 Thermal: 0.000398 LR: 9.94e-06\n",
      "Epoch   4 [9100/10697 ( 85.1%)] Loss: 0.029900 L1: 0.017358 Grad: 0.125132 Thermal: 0.000588 LR: 9.94e-06\n",
      "Epoch   4 [9100/10697 ( 85.1%)] Loss: 0.029900 L1: 0.017358 Grad: 0.125132 Thermal: 0.000588 LR: 9.94e-06\n",
      "Epoch   4 [9150/10697 ( 85.5%)] Loss: 0.021235 L1: 0.012626 Grad: 0.085919 Thermal: 0.000332 LR: 9.94e-06\n",
      "Epoch   4 [9150/10697 ( 85.5%)] Loss: 0.021235 L1: 0.012626 Grad: 0.085919 Thermal: 0.000332 LR: 9.94e-06\n",
      "Epoch   4 [9200/10697 ( 86.0%)] Loss: 0.025849 L1: 0.015120 Grad: 0.107083 Thermal: 0.000421 LR: 9.94e-06\n",
      "Epoch   4 [9200/10697 ( 86.0%)] Loss: 0.025849 L1: 0.015120 Grad: 0.107083 Thermal: 0.000421 LR: 9.94e-06\n",
      "Epoch   4 [9250/10697 ( 86.5%)] Loss: 0.026153 L1: 0.014843 Grad: 0.112893 Thermal: 0.000411 LR: 9.94e-06\n",
      "Epoch   4 [9250/10697 ( 86.5%)] Loss: 0.026153 L1: 0.014843 Grad: 0.112893 Thermal: 0.000411 LR: 9.94e-06\n",
      "Epoch   4 [9300/10697 ( 86.9%)] Loss: 0.026837 L1: 0.015839 Grad: 0.109757 Thermal: 0.000455 LR: 9.94e-06\n",
      "Epoch   4 [9300/10697 ( 86.9%)] Loss: 0.026837 L1: 0.015839 Grad: 0.109757 Thermal: 0.000455 LR: 9.94e-06\n",
      "Epoch   4 [9350/10697 ( 87.4%)] Loss: 0.029233 L1: 0.017310 Grad: 0.118940 Thermal: 0.000579 LR: 9.94e-06\n",
      "Epoch   4 [9350/10697 ( 87.4%)] Loss: 0.029233 L1: 0.017310 Grad: 0.118940 Thermal: 0.000579 LR: 9.94e-06\n",
      "Epoch   4 [9400/10697 ( 87.9%)] Loss: 0.029118 L1: 0.017078 Grad: 0.120149 Thermal: 0.000517 LR: 9.94e-06\n",
      "Epoch   4 [9400/10697 ( 87.9%)] Loss: 0.029118 L1: 0.017078 Grad: 0.120149 Thermal: 0.000517 LR: 9.94e-06\n",
      "Epoch   4 [9450/10697 ( 88.3%)] Loss: 0.030207 L1: 0.017577 Grad: 0.126021 Thermal: 0.000564 LR: 9.94e-06\n",
      "Epoch   4 [9450/10697 ( 88.3%)] Loss: 0.030207 L1: 0.017577 Grad: 0.126021 Thermal: 0.000564 LR: 9.94e-06\n",
      "Epoch   4 [9500/10697 ( 88.8%)] Loss: 0.033346 L1: 0.019115 Grad: 0.142011 Thermal: 0.000597 LR: 9.94e-06\n",
      "Epoch   4 [9500/10697 ( 88.8%)] Loss: 0.033346 L1: 0.019115 Grad: 0.142011 Thermal: 0.000597 LR: 9.94e-06\n",
      "Epoch   4 [9550/10697 ( 89.3%)] Loss: 0.030671 L1: 0.017960 Grad: 0.126821 Thermal: 0.000583 LR: 9.94e-06\n",
      "Epoch   4 [9550/10697 ( 89.3%)] Loss: 0.030671 L1: 0.017960 Grad: 0.126821 Thermal: 0.000583 LR: 9.94e-06\n",
      "Epoch   4 [9600/10697 ( 89.7%)] Loss: 0.030945 L1: 0.017813 Grad: 0.131044 Thermal: 0.000545 LR: 9.94e-06\n",
      "Epoch   4 [9600/10697 ( 89.7%)] Loss: 0.030945 L1: 0.017813 Grad: 0.131044 Thermal: 0.000545 LR: 9.94e-06\n",
      "Epoch   4 [9650/10697 ( 90.2%)] Loss: 0.024990 L1: 0.014827 Grad: 0.101427 Thermal: 0.000393 LR: 9.94e-06\n",
      "Epoch   4 [9650/10697 ( 90.2%)] Loss: 0.024990 L1: 0.014827 Grad: 0.101427 Thermal: 0.000393 LR: 9.94e-06\n",
      "Epoch   4 [9700/10697 ( 90.7%)] Loss: 0.034516 L1: 0.019923 Grad: 0.145557 Thermal: 0.000743 LR: 9.94e-06\n",
      "Epoch   4 [9700/10697 ( 90.7%)] Loss: 0.034516 L1: 0.019923 Grad: 0.145557 Thermal: 0.000743 LR: 9.94e-06\n",
      "Epoch   4 [9750/10697 ( 91.1%)] Loss: 0.025580 L1: 0.014800 Grad: 0.107593 Thermal: 0.000428 LR: 9.94e-06\n",
      "Epoch   4 [9750/10697 ( 91.1%)] Loss: 0.025580 L1: 0.014800 Grad: 0.107593 Thermal: 0.000428 LR: 9.94e-06\n",
      "Epoch   4 [9800/10697 ( 91.6%)] Loss: 0.026358 L1: 0.015780 Grad: 0.105564 Thermal: 0.000443 LR: 9.94e-06\n",
      "Epoch   4 [9800/10697 ( 91.6%)] Loss: 0.026358 L1: 0.015780 Grad: 0.105564 Thermal: 0.000443 LR: 9.94e-06\n",
      "Epoch   4 [9850/10697 ( 92.1%)] Loss: 0.021017 L1: 0.012036 Grad: 0.089668 Thermal: 0.000289 LR: 9.94e-06\n",
      "Epoch   4 [9850/10697 ( 92.1%)] Loss: 0.021017 L1: 0.012036 Grad: 0.089668 Thermal: 0.000289 LR: 9.94e-06\n",
      "Epoch   4 [9900/10697 ( 92.5%)] Loss: 0.029501 L1: 0.017545 Grad: 0.119294 Thermal: 0.000544 LR: 9.94e-06\n",
      "Epoch   4 [9900/10697 ( 92.5%)] Loss: 0.029501 L1: 0.017545 Grad: 0.119294 Thermal: 0.000544 LR: 9.94e-06\n",
      "Epoch   4 [9950/10697 ( 93.0%)] Loss: 0.026298 L1: 0.015034 Grad: 0.112446 Thermal: 0.000398 LR: 9.94e-06\n",
      "Epoch   4 [9950/10697 ( 93.0%)] Loss: 0.026298 L1: 0.015034 Grad: 0.112446 Thermal: 0.000398 LR: 9.94e-06\n",
      "Epoch   4 [10000/10697 ( 93.5%)] Loss: 0.027532 L1: 0.015721 Grad: 0.117877 Thermal: 0.000467 LR: 9.94e-06\n",
      "Epoch   4 [10000/10697 ( 93.5%)] Loss: 0.027532 L1: 0.015721 Grad: 0.117877 Thermal: 0.000467 LR: 9.94e-06\n",
      "Epoch   4 [10050/10697 ( 94.0%)] Loss: 0.032572 L1: 0.018956 Grad: 0.135868 Thermal: 0.000594 LR: 9.94e-06\n",
      "Epoch   4 [10050/10697 ( 94.0%)] Loss: 0.032572 L1: 0.018956 Grad: 0.135868 Thermal: 0.000594 LR: 9.94e-06\n",
      "Epoch   4 [10100/10697 ( 94.4%)] Loss: 0.031332 L1: 0.017969 Grad: 0.133353 Thermal: 0.000552 LR: 9.94e-06\n",
      "Epoch   4 [10100/10697 ( 94.4%)] Loss: 0.031332 L1: 0.017969 Grad: 0.133353 Thermal: 0.000552 LR: 9.94e-06\n",
      "Epoch   4 [10150/10697 ( 94.9%)] Loss: 0.030325 L1: 0.017282 Grad: 0.130161 Thermal: 0.000528 LR: 9.94e-06\n",
      "Epoch   4 [10150/10697 ( 94.9%)] Loss: 0.030325 L1: 0.017282 Grad: 0.130161 Thermal: 0.000528 LR: 9.94e-06\n",
      "Epoch   4 [10200/10697 ( 95.4%)] Loss: 0.031751 L1: 0.018150 Grad: 0.135686 Thermal: 0.000641 LR: 9.94e-06\n",
      "Epoch   4 [10200/10697 ( 95.4%)] Loss: 0.031751 L1: 0.018150 Grad: 0.135686 Thermal: 0.000641 LR: 9.94e-06\n",
      "Epoch   4 [10250/10697 ( 95.8%)] Loss: 0.031301 L1: 0.017799 Grad: 0.134716 Thermal: 0.000599 LR: 9.94e-06\n",
      "Epoch   4 [10250/10697 ( 95.8%)] Loss: 0.031301 L1: 0.017799 Grad: 0.134716 Thermal: 0.000599 LR: 9.94e-06\n",
      "Epoch   4 [10300/10697 ( 96.3%)] Loss: 0.034218 L1: 0.019771 Grad: 0.144112 Thermal: 0.000710 LR: 9.94e-06\n",
      "Epoch   4 [10300/10697 ( 96.3%)] Loss: 0.034218 L1: 0.019771 Grad: 0.144112 Thermal: 0.000710 LR: 9.94e-06\n",
      "Epoch   4 [10350/10697 ( 96.8%)] Loss: 0.036691 L1: 0.021125 Grad: 0.155266 Thermal: 0.000776 LR: 9.94e-06\n",
      "Epoch   4 [10350/10697 ( 96.8%)] Loss: 0.036691 L1: 0.021125 Grad: 0.155266 Thermal: 0.000776 LR: 9.94e-06\n",
      "Epoch   4 [10400/10697 ( 97.2%)] Loss: 0.031224 L1: 0.018135 Grad: 0.130568 Thermal: 0.000652 LR: 9.94e-06\n",
      "Epoch   4 [10400/10697 ( 97.2%)] Loss: 0.031224 L1: 0.018135 Grad: 0.130568 Thermal: 0.000652 LR: 9.94e-06\n",
      "Epoch   4 [10450/10697 ( 97.7%)] Loss: 0.030457 L1: 0.017632 Grad: 0.127955 Thermal: 0.000589 LR: 9.94e-06\n",
      "Epoch   4 [10450/10697 ( 97.7%)] Loss: 0.030457 L1: 0.017632 Grad: 0.127955 Thermal: 0.000589 LR: 9.94e-06\n",
      "Epoch   4 [10500/10697 ( 98.2%)] Loss: 0.025009 L1: 0.014479 Grad: 0.105105 Thermal: 0.000398 LR: 9.94e-06\n",
      "Epoch   4 [10500/10697 ( 98.2%)] Loss: 0.025009 L1: 0.014479 Grad: 0.105105 Thermal: 0.000398 LR: 9.94e-06\n",
      "Epoch   4 [10550/10697 ( 98.6%)] Loss: 0.027227 L1: 0.015668 Grad: 0.115363 Thermal: 0.000463 LR: 9.94e-06\n",
      "Epoch   4 [10550/10697 ( 98.6%)] Loss: 0.027227 L1: 0.015668 Grad: 0.115363 Thermal: 0.000463 LR: 9.94e-06\n",
      "Epoch   4 [10600/10697 ( 99.1%)] Loss: 0.027818 L1: 0.016172 Grad: 0.116208 Thermal: 0.000493 LR: 9.94e-06\n",
      "Epoch   4 [10600/10697 ( 99.1%)] Loss: 0.027818 L1: 0.016172 Grad: 0.116208 Thermal: 0.000493 LR: 9.94e-06\n",
      "Epoch   4 [10650/10697 ( 99.6%)] Loss: 0.021424 L1: 0.012672 Grad: 0.087366 Thermal: 0.000325 LR: 9.94e-06\n",
      "Epoch   4 [10650/10697 ( 99.6%)] Loss: 0.021424 L1: 0.012672 Grad: 0.087366 Thermal: 0.000325 LR: 9.94e-06\n",
      "Epoch   4 Summary: Loss=0.027122 (L1:0.0158, Grad:0.1132, Thermal:0.0005) Val_PSNR=0.00dB Best=33.17dB Time=17.9min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch   4 Summary: Loss=0.027122 (L1:0.0158, Grad:0.1132, Thermal:0.0005) Val_PSNR=0.00dB Best=33.17dB Time=17.9min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch   5 [   0/10697 (  0.0%)] Loss: 0.027136 L1: 0.016042 Grad: 0.110711 Thermal: 0.000462 LR: 9.90e-06\n",
      "Epoch   5 [   0/10697 (  0.0%)] Loss: 0.027136 L1: 0.016042 Grad: 0.110711 Thermal: 0.000462 LR: 9.90e-06\n",
      "Epoch   5 [  50/10697 (  0.5%)] Loss: 0.026693 L1: 0.015402 Grad: 0.112691 Thermal: 0.000419 LR: 9.90e-06\n",
      "Epoch   5 [  50/10697 (  0.5%)] Loss: 0.026693 L1: 0.015402 Grad: 0.112691 Thermal: 0.000419 LR: 9.90e-06\n",
      "Epoch   5 [ 100/10697 (  0.9%)] Loss: 0.028361 L1: 0.015864 Grad: 0.124758 Thermal: 0.000425 LR: 9.90e-06\n",
      "Epoch   5 [ 100/10697 (  0.9%)] Loss: 0.028361 L1: 0.015864 Grad: 0.124758 Thermal: 0.000425 LR: 9.90e-06\n",
      "Epoch   5 [ 150/10697 (  1.4%)] Loss: 0.027728 L1: 0.016141 Grad: 0.115606 Thermal: 0.000522 LR: 9.90e-06\n",
      "Epoch   5 [ 150/10697 (  1.4%)] Loss: 0.027728 L1: 0.016141 Grad: 0.115606 Thermal: 0.000522 LR: 9.90e-06\n",
      "Epoch   5 [ 200/10697 (  1.9%)] Loss: 0.029897 L1: 0.017578 Grad: 0.122916 Thermal: 0.000557 LR: 9.90e-06\n",
      "Epoch   5 [ 200/10697 (  1.9%)] Loss: 0.029897 L1: 0.017578 Grad: 0.122916 Thermal: 0.000557 LR: 9.90e-06\n",
      "Epoch   5 [ 250/10697 (  2.3%)] Loss: 0.018708 L1: 0.010827 Grad: 0.078677 Thermal: 0.000263 LR: 9.90e-06\n",
      "Epoch   5 [ 250/10697 (  2.3%)] Loss: 0.018708 L1: 0.010827 Grad: 0.078677 Thermal: 0.000263 LR: 9.90e-06\n",
      "Epoch   5 [ 300/10697 (  2.8%)] Loss: 0.025009 L1: 0.014609 Grad: 0.103797 Thermal: 0.000408 LR: 9.90e-06\n",
      "Epoch   5 [ 300/10697 (  2.8%)] Loss: 0.025009 L1: 0.014609 Grad: 0.103797 Thermal: 0.000408 LR: 9.90e-06\n",
      "Epoch   5 [ 350/10697 (  3.3%)] Loss: 0.027266 L1: 0.016003 Grad: 0.112376 Thermal: 0.000507 LR: 9.90e-06\n",
      "Epoch   5 [ 350/10697 (  3.3%)] Loss: 0.027266 L1: 0.016003 Grad: 0.112376 Thermal: 0.000507 LR: 9.90e-06\n",
      "Epoch   5 [ 400/10697 (  3.7%)] Loss: 0.025345 L1: 0.014833 Grad: 0.104912 Thermal: 0.000418 LR: 9.90e-06\n",
      "Epoch   5 [ 400/10697 (  3.7%)] Loss: 0.025345 L1: 0.014833 Grad: 0.104912 Thermal: 0.000418 LR: 9.90e-06\n",
      "Epoch   5 [ 450/10697 (  4.2%)] Loss: 0.025053 L1: 0.014637 Grad: 0.103952 Thermal: 0.000424 LR: 9.90e-06\n",
      "Epoch   5 [ 450/10697 (  4.2%)] Loss: 0.025053 L1: 0.014637 Grad: 0.103952 Thermal: 0.000424 LR: 9.90e-06\n",
      "Epoch   5 [ 500/10697 (  4.7%)] Loss: 0.022685 L1: 0.013531 Grad: 0.091365 Thermal: 0.000347 LR: 9.90e-06\n",
      "Epoch   5 [ 500/10697 (  4.7%)] Loss: 0.022685 L1: 0.013531 Grad: 0.091365 Thermal: 0.000347 LR: 9.90e-06\n",
      "Epoch   5 [ 550/10697 (  5.1%)] Loss: 0.028785 L1: 0.016522 Grad: 0.122396 Thermal: 0.000469 LR: 9.90e-06\n",
      "Epoch   5 [ 550/10697 (  5.1%)] Loss: 0.028785 L1: 0.016522 Grad: 0.122396 Thermal: 0.000469 LR: 9.90e-06\n",
      "Epoch   5 [ 600/10697 (  5.6%)] Loss: 0.027341 L1: 0.015985 Grad: 0.113321 Thermal: 0.000489 LR: 9.90e-06\n",
      "Epoch   5 [ 600/10697 (  5.6%)] Loss: 0.027341 L1: 0.015985 Grad: 0.113321 Thermal: 0.000489 LR: 9.90e-06\n",
      "Epoch   5 [ 650/10697 (  6.1%)] Loss: 0.028774 L1: 0.016373 Grad: 0.123781 Thermal: 0.000449 LR: 9.90e-06\n",
      "Epoch   5 [ 650/10697 (  6.1%)] Loss: 0.028774 L1: 0.016373 Grad: 0.123781 Thermal: 0.000449 LR: 9.90e-06\n",
      "Epoch   5 [ 700/10697 (  6.5%)] Loss: 0.032664 L1: 0.019159 Grad: 0.134738 Thermal: 0.000635 LR: 9.90e-06\n",
      "Epoch   5 [ 700/10697 (  6.5%)] Loss: 0.032664 L1: 0.019159 Grad: 0.134738 Thermal: 0.000635 LR: 9.90e-06\n",
      "Epoch   5 [ 750/10697 (  7.0%)] Loss: 0.022004 L1: 0.012626 Grad: 0.093592 Thermal: 0.000371 LR: 9.90e-06\n",
      "Epoch   5 [ 750/10697 (  7.0%)] Loss: 0.022004 L1: 0.012626 Grad: 0.093592 Thermal: 0.000371 LR: 9.90e-06\n",
      "Epoch   5 [ 800/10697 (  7.5%)] Loss: 0.023951 L1: 0.014166 Grad: 0.097645 Thermal: 0.000407 LR: 9.90e-06\n",
      "Epoch   5 [ 800/10697 (  7.5%)] Loss: 0.023951 L1: 0.014166 Grad: 0.097645 Thermal: 0.000407 LR: 9.90e-06\n",
      "Epoch   5 [ 850/10697 (  7.9%)] Loss: 0.019112 L1: 0.011082 Grad: 0.080158 Thermal: 0.000281 LR: 9.90e-06\n",
      "Epoch   5 [ 850/10697 (  7.9%)] Loss: 0.019112 L1: 0.011082 Grad: 0.080158 Thermal: 0.000281 LR: 9.90e-06\n",
      "Epoch   5 [ 900/10697 (  8.4%)] Loss: 0.027058 L1: 0.015906 Grad: 0.111264 Thermal: 0.000502 LR: 9.90e-06\n",
      "Epoch   5 [ 900/10697 (  8.4%)] Loss: 0.027058 L1: 0.015906 Grad: 0.111264 Thermal: 0.000502 LR: 9.90e-06\n",
      "Epoch   5 [ 950/10697 (  8.9%)] Loss: 0.032161 L1: 0.018524 Grad: 0.136039 Thermal: 0.000660 LR: 9.90e-06\n",
      "Epoch   5 [ 950/10697 (  8.9%)] Loss: 0.032161 L1: 0.018524 Grad: 0.136039 Thermal: 0.000660 LR: 9.90e-06\n",
      "Epoch   5 [1000/10697 (  9.3%)] Loss: 0.029894 L1: 0.017425 Grad: 0.124408 Thermal: 0.000560 LR: 9.90e-06\n",
      "Epoch   5 [1000/10697 (  9.3%)] Loss: 0.029894 L1: 0.017425 Grad: 0.124408 Thermal: 0.000560 LR: 9.90e-06\n",
      "Epoch   5 [1050/10697 (  9.8%)] Loss: 0.038491 L1: 0.022378 Grad: 0.160613 Thermal: 0.001022 LR: 9.90e-06\n",
      "Epoch   5 [1050/10697 (  9.8%)] Loss: 0.038491 L1: 0.022378 Grad: 0.160613 Thermal: 0.001022 LR: 9.90e-06\n",
      "Epoch   5 [1100/10697 ( 10.3%)] Loss: 0.027097 L1: 0.015550 Grad: 0.115245 Thermal: 0.000443 LR: 9.90e-06\n",
      "Epoch   5 [1100/10697 ( 10.3%)] Loss: 0.027097 L1: 0.015550 Grad: 0.115245 Thermal: 0.000443 LR: 9.90e-06\n",
      "Epoch   5 [1150/10697 ( 10.8%)] Loss: 0.032422 L1: 0.018866 Grad: 0.135211 Thermal: 0.000686 LR: 9.90e-06\n",
      "Epoch   5 [1150/10697 ( 10.8%)] Loss: 0.032422 L1: 0.018866 Grad: 0.135211 Thermal: 0.000686 LR: 9.90e-06\n",
      "Epoch   5 [1200/10697 ( 11.2%)] Loss: 0.030269 L1: 0.017631 Grad: 0.126093 Thermal: 0.000570 LR: 9.90e-06\n",
      "Epoch   5 [1200/10697 ( 11.2%)] Loss: 0.030269 L1: 0.017631 Grad: 0.126093 Thermal: 0.000570 LR: 9.90e-06\n",
      "Epoch   5 [1250/10697 ( 11.7%)] Loss: 0.022762 L1: 0.013500 Grad: 0.092450 Thermal: 0.000352 LR: 9.90e-06\n",
      "Epoch   5 [1250/10697 ( 11.7%)] Loss: 0.022762 L1: 0.013500 Grad: 0.092450 Thermal: 0.000352 LR: 9.90e-06\n",
      "Epoch   5 [1300/10697 ( 12.2%)] Loss: 0.024434 L1: 0.014703 Grad: 0.097107 Thermal: 0.000408 LR: 9.90e-06\n",
      "Epoch   5 [1300/10697 ( 12.2%)] Loss: 0.024434 L1: 0.014703 Grad: 0.097107 Thermal: 0.000408 LR: 9.90e-06\n",
      "Epoch   5 [1350/10697 ( 12.6%)] Loss: 0.026289 L1: 0.015065 Grad: 0.112028 Thermal: 0.000419 LR: 9.90e-06\n",
      "Epoch   5 [1350/10697 ( 12.6%)] Loss: 0.026289 L1: 0.015065 Grad: 0.112028 Thermal: 0.000419 LR: 9.90e-06\n",
      "Epoch   5 [1400/10697 ( 13.1%)] Loss: 0.023883 L1: 0.013935 Grad: 0.099277 Thermal: 0.000399 LR: 9.90e-06\n",
      "Epoch   5 [1400/10697 ( 13.1%)] Loss: 0.023883 L1: 0.013935 Grad: 0.099277 Thermal: 0.000399 LR: 9.90e-06\n",
      "Epoch   5 [1450/10697 ( 13.6%)] Loss: 0.022737 L1: 0.013257 Grad: 0.094632 Thermal: 0.000327 LR: 9.90e-06\n",
      "Epoch   5 [1450/10697 ( 13.6%)] Loss: 0.022737 L1: 0.013257 Grad: 0.094632 Thermal: 0.000327 LR: 9.90e-06\n",
      "Epoch   5 [1500/10697 ( 14.0%)] Loss: 0.024936 L1: 0.014854 Grad: 0.100619 Thermal: 0.000405 LR: 9.90e-06\n",
      "Epoch   5 [1500/10697 ( 14.0%)] Loss: 0.024936 L1: 0.014854 Grad: 0.100619 Thermal: 0.000405 LR: 9.90e-06\n",
      "Epoch   5 [1550/10697 ( 14.5%)] Loss: 0.023718 L1: 0.014125 Grad: 0.095727 Thermal: 0.000414 LR: 9.90e-06\n",
      "Epoch   5 [1550/10697 ( 14.5%)] Loss: 0.023718 L1: 0.014125 Grad: 0.095727 Thermal: 0.000414 LR: 9.90e-06\n",
      "Epoch   5 [1600/10697 ( 15.0%)] Loss: 0.031260 L1: 0.017868 Grad: 0.133601 Thermal: 0.000630 LR: 9.90e-06\n",
      "Epoch   5 [1600/10697 ( 15.0%)] Loss: 0.031260 L1: 0.017868 Grad: 0.133601 Thermal: 0.000630 LR: 9.90e-06\n",
      "Epoch   5 [1650/10697 ( 15.4%)] Loss: 0.029721 L1: 0.017109 Grad: 0.125864 Thermal: 0.000514 LR: 9.90e-06\n",
      "Epoch   5 [1650/10697 ( 15.4%)] Loss: 0.029721 L1: 0.017109 Grad: 0.125864 Thermal: 0.000514 LR: 9.90e-06\n",
      "Epoch   5 [1700/10697 ( 15.9%)] Loss: 0.020192 L1: 0.011640 Grad: 0.085371 Thermal: 0.000287 LR: 9.90e-06\n",
      "Epoch   5 [1700/10697 ( 15.9%)] Loss: 0.020192 L1: 0.011640 Grad: 0.085371 Thermal: 0.000287 LR: 9.90e-06\n",
      "Epoch   5 [1750/10697 ( 16.4%)] Loss: 0.028503 L1: 0.017050 Grad: 0.114280 Thermal: 0.000502 LR: 9.90e-06\n",
      "Epoch   5 [1750/10697 ( 16.4%)] Loss: 0.028503 L1: 0.017050 Grad: 0.114280 Thermal: 0.000502 LR: 9.90e-06\n",
      "Epoch   5 [1800/10697 ( 16.8%)] Loss: 0.022995 L1: 0.013640 Grad: 0.093343 Thermal: 0.000405 LR: 9.90e-06\n",
      "Epoch   5 [1800/10697 ( 16.8%)] Loss: 0.022995 L1: 0.013640 Grad: 0.093343 Thermal: 0.000405 LR: 9.90e-06\n",
      "Epoch   5 [1850/10697 ( 17.3%)] Loss: 0.030218 L1: 0.017442 Grad: 0.127494 Thermal: 0.000527 LR: 9.90e-06\n",
      "Epoch   5 [1850/10697 ( 17.3%)] Loss: 0.030218 L1: 0.017442 Grad: 0.127494 Thermal: 0.000527 LR: 9.90e-06\n",
      "Epoch   5 [1900/10697 ( 17.8%)] Loss: 0.029733 L1: 0.017476 Grad: 0.122287 Thermal: 0.000562 LR: 9.90e-06\n",
      "Epoch   5 [1900/10697 ( 17.8%)] Loss: 0.029733 L1: 0.017476 Grad: 0.122287 Thermal: 0.000562 LR: 9.90e-06\n",
      "Epoch   5 [1950/10697 ( 18.2%)] Loss: 0.025429 L1: 0.015361 Grad: 0.100461 Thermal: 0.000433 LR: 9.90e-06\n",
      "Epoch   5 [1950/10697 ( 18.2%)] Loss: 0.025429 L1: 0.015361 Grad: 0.100461 Thermal: 0.000433 LR: 9.90e-06\n",
      "Epoch   5 [2000/10697 ( 18.7%)] Loss: 0.024186 L1: 0.013747 Grad: 0.104203 Thermal: 0.000364 LR: 9.90e-06\n",
      "Epoch   5 [2000/10697 ( 18.7%)] Loss: 0.024186 L1: 0.013747 Grad: 0.104203 Thermal: 0.000364 LR: 9.90e-06\n",
      "Epoch   5 [2050/10697 ( 19.2%)] Loss: 0.020255 L1: 0.011594 Grad: 0.086477 Thermal: 0.000250 LR: 9.90e-06\n",
      "Epoch   5 [2050/10697 ( 19.2%)] Loss: 0.020255 L1: 0.011594 Grad: 0.086477 Thermal: 0.000250 LR: 9.90e-06\n",
      "Epoch   5 [2100/10697 ( 19.6%)] Loss: 0.030998 L1: 0.018007 Grad: 0.129605 Thermal: 0.000609 LR: 9.90e-06\n",
      "Epoch   5 [2100/10697 ( 19.6%)] Loss: 0.030998 L1: 0.018007 Grad: 0.129605 Thermal: 0.000609 LR: 9.90e-06\n",
      "Epoch   5 [2150/10697 ( 20.1%)] Loss: 0.034418 L1: 0.020249 Grad: 0.141290 Thermal: 0.000812 LR: 9.90e-06\n",
      "Epoch   5 [2150/10697 ( 20.1%)] Loss: 0.034418 L1: 0.020249 Grad: 0.141290 Thermal: 0.000812 LR: 9.90e-06\n",
      "Epoch   5 [2200/10697 ( 20.6%)] Loss: 0.033295 L1: 0.019019 Grad: 0.142382 Thermal: 0.000749 LR: 9.90e-06\n",
      "Epoch   5 [2200/10697 ( 20.6%)] Loss: 0.033295 L1: 0.019019 Grad: 0.142382 Thermal: 0.000749 LR: 9.90e-06\n",
      "Epoch   5 [2250/10697 ( 21.0%)] Loss: 0.028261 L1: 0.016537 Grad: 0.116980 Thermal: 0.000511 LR: 9.90e-06\n",
      "Epoch   5 [2250/10697 ( 21.0%)] Loss: 0.028261 L1: 0.016537 Grad: 0.116980 Thermal: 0.000511 LR: 9.90e-06\n",
      "Epoch   5 [2300/10697 ( 21.5%)] Loss: 0.023933 L1: 0.013560 Grad: 0.103497 Thermal: 0.000476 LR: 9.90e-06\n",
      "Epoch   5 [2300/10697 ( 21.5%)] Loss: 0.023933 L1: 0.013560 Grad: 0.103497 Thermal: 0.000476 LR: 9.90e-06\n",
      "Epoch   5 [2350/10697 ( 22.0%)] Loss: 0.027545 L1: 0.016024 Grad: 0.114967 Thermal: 0.000471 LR: 9.90e-06\n",
      "Epoch   5 [2350/10697 ( 22.0%)] Loss: 0.027545 L1: 0.016024 Grad: 0.114967 Thermal: 0.000471 LR: 9.90e-06\n",
      "Epoch   5 [2400/10697 ( 22.4%)] Loss: 0.025189 L1: 0.014676 Grad: 0.104933 Thermal: 0.000397 LR: 9.90e-06\n",
      "Epoch   5 [2400/10697 ( 22.4%)] Loss: 0.025189 L1: 0.014676 Grad: 0.104933 Thermal: 0.000397 LR: 9.90e-06\n",
      "Epoch   5 [2450/10697 ( 22.9%)] Loss: 0.031570 L1: 0.018497 Grad: 0.130405 Thermal: 0.000657 LR: 9.90e-06\n",
      "Epoch   5 [2450/10697 ( 22.9%)] Loss: 0.031570 L1: 0.018497 Grad: 0.130405 Thermal: 0.000657 LR: 9.90e-06\n",
      "Epoch   5 [2500/10697 ( 23.4%)] Loss: 0.020551 L1: 0.011907 Grad: 0.086302 Thermal: 0.000272 LR: 9.90e-06\n",
      "Epoch   5 [2500/10697 ( 23.4%)] Loss: 0.020551 L1: 0.011907 Grad: 0.086302 Thermal: 0.000272 LR: 9.90e-06\n",
      "Epoch   5 [2550/10697 ( 23.8%)] Loss: 0.034190 L1: 0.019910 Grad: 0.142427 Thermal: 0.000752 LR: 9.90e-06\n",
      "Epoch   5 [2550/10697 ( 23.8%)] Loss: 0.034190 L1: 0.019910 Grad: 0.142427 Thermal: 0.000752 LR: 9.90e-06\n",
      "Epoch   5 [2600/10697 ( 24.3%)] Loss: 0.030857 L1: 0.017907 Grad: 0.129199 Thermal: 0.000614 LR: 9.90e-06\n",
      "Epoch   5 [2600/10697 ( 24.3%)] Loss: 0.030857 L1: 0.017907 Grad: 0.129199 Thermal: 0.000614 LR: 9.90e-06\n",
      "Epoch   5 [2650/10697 ( 24.8%)] Loss: 0.042481 L1: 0.024373 Grad: 0.180530 Thermal: 0.001116 LR: 9.90e-06\n",
      "Epoch   5 [2650/10697 ( 24.8%)] Loss: 0.042481 L1: 0.024373 Grad: 0.180530 Thermal: 0.001116 LR: 9.90e-06\n",
      "Epoch   5 [2700/10697 ( 25.2%)] Loss: 0.025405 L1: 0.015029 Grad: 0.103561 Thermal: 0.000405 LR: 9.90e-06\n",
      "Epoch   5 [2700/10697 ( 25.2%)] Loss: 0.025405 L1: 0.015029 Grad: 0.103561 Thermal: 0.000405 LR: 9.90e-06\n",
      "Epoch   5 [2750/10697 ( 25.7%)] Loss: 0.025126 L1: 0.015052 Grad: 0.100528 Thermal: 0.000424 LR: 9.90e-06\n",
      "Epoch   5 [2750/10697 ( 25.7%)] Loss: 0.025126 L1: 0.015052 Grad: 0.100528 Thermal: 0.000424 LR: 9.90e-06\n",
      "Epoch   5 [2800/10697 ( 26.2%)] Loss: 0.022263 L1: 0.012535 Grad: 0.097121 Thermal: 0.000309 LR: 9.90e-06\n",
      "Epoch   5 [2800/10697 ( 26.2%)] Loss: 0.022263 L1: 0.012535 Grad: 0.097121 Thermal: 0.000309 LR: 9.90e-06\n",
      "Epoch   5 [2850/10697 ( 26.6%)] Loss: 0.028634 L1: 0.016511 Grad: 0.120989 Thermal: 0.000495 LR: 9.90e-06\n",
      "Epoch   5 [2850/10697 ( 26.6%)] Loss: 0.028634 L1: 0.016511 Grad: 0.120989 Thermal: 0.000495 LR: 9.90e-06\n",
      "Epoch   5 [2900/10697 ( 27.1%)] Loss: 0.034113 L1: 0.019076 Grad: 0.150023 Thermal: 0.000710 LR: 9.90e-06\n",
      "Epoch   5 [2900/10697 ( 27.1%)] Loss: 0.034113 L1: 0.019076 Grad: 0.150023 Thermal: 0.000710 LR: 9.90e-06\n",
      "Epoch   5 [2950/10697 ( 27.6%)] Loss: 0.026919 L1: 0.016019 Grad: 0.108767 Thermal: 0.000479 LR: 9.90e-06\n",
      "Epoch   5 [2950/10697 ( 27.6%)] Loss: 0.026919 L1: 0.016019 Grad: 0.108767 Thermal: 0.000479 LR: 9.90e-06\n",
      "Epoch   5 [3000/10697 ( 28.0%)] Loss: 0.029253 L1: 0.016783 Grad: 0.124442 Thermal: 0.000501 LR: 9.90e-06\n",
      "Epoch   5 [3000/10697 ( 28.0%)] Loss: 0.029253 L1: 0.016783 Grad: 0.124442 Thermal: 0.000501 LR: 9.90e-06\n",
      "Epoch   5 [3050/10697 ( 28.5%)] Loss: 0.031910 L1: 0.018883 Grad: 0.129953 Thermal: 0.000625 LR: 9.90e-06\n",
      "Epoch   5 [3050/10697 ( 28.5%)] Loss: 0.031910 L1: 0.018883 Grad: 0.129953 Thermal: 0.000625 LR: 9.90e-06\n",
      "Epoch   5 [3100/10697 ( 29.0%)] Loss: 0.021615 L1: 0.012529 Grad: 0.090688 Thermal: 0.000325 LR: 9.90e-06\n",
      "Epoch   5 [3100/10697 ( 29.0%)] Loss: 0.021615 L1: 0.012529 Grad: 0.090688 Thermal: 0.000325 LR: 9.90e-06\n",
      "Epoch   5 [3150/10697 ( 29.4%)] Loss: 0.030606 L1: 0.017775 Grad: 0.128041 Thermal: 0.000538 LR: 9.90e-06\n",
      "Epoch   5 [3150/10697 ( 29.4%)] Loss: 0.030606 L1: 0.017775 Grad: 0.128041 Thermal: 0.000538 LR: 9.90e-06\n",
      "Epoch   5 [3200/10697 ( 29.9%)] Loss: 0.023281 L1: 0.013764 Grad: 0.094995 Thermal: 0.000350 LR: 9.90e-06\n",
      "Epoch   5 [3200/10697 ( 29.9%)] Loss: 0.023281 L1: 0.013764 Grad: 0.094995 Thermal: 0.000350 LR: 9.90e-06\n",
      "Epoch   5 [3250/10697 ( 30.4%)] Loss: 0.030215 L1: 0.017043 Grad: 0.131448 Thermal: 0.000540 LR: 9.90e-06\n",
      "Epoch   5 [3250/10697 ( 30.4%)] Loss: 0.030215 L1: 0.017043 Grad: 0.131448 Thermal: 0.000540 LR: 9.90e-06\n",
      "Epoch   5 [3300/10697 ( 30.8%)] Loss: 0.028390 L1: 0.016474 Grad: 0.118893 Thermal: 0.000521 LR: 9.90e-06\n",
      "Epoch   5 [3300/10697 ( 30.8%)] Loss: 0.028390 L1: 0.016474 Grad: 0.118893 Thermal: 0.000521 LR: 9.90e-06\n",
      "Epoch   5 [3350/10697 ( 31.3%)] Loss: 0.031057 L1: 0.017891 Grad: 0.131369 Thermal: 0.000581 LR: 9.90e-06\n",
      "Epoch   5 [3350/10697 ( 31.3%)] Loss: 0.031057 L1: 0.017891 Grad: 0.131369 Thermal: 0.000581 LR: 9.90e-06\n",
      "Epoch   5 [3400/10697 ( 31.8%)] Loss: 0.027839 L1: 0.016422 Grad: 0.113887 Thermal: 0.000567 LR: 9.90e-06\n",
      "Epoch   5 [3400/10697 ( 31.8%)] Loss: 0.027839 L1: 0.016422 Grad: 0.113887 Thermal: 0.000567 LR: 9.90e-06\n",
      "Epoch   5 [3450/10697 ( 32.3%)] Loss: 0.026368 L1: 0.015057 Grad: 0.112903 Thermal: 0.000404 LR: 9.90e-06\n",
      "Epoch   5 [3450/10697 ( 32.3%)] Loss: 0.026368 L1: 0.015057 Grad: 0.112903 Thermal: 0.000404 LR: 9.90e-06\n",
      "Epoch   5 [3500/10697 ( 32.7%)] Loss: 0.031184 L1: 0.018339 Grad: 0.128139 Thermal: 0.000618 LR: 9.90e-06\n",
      "Epoch   5 [3500/10697 ( 32.7%)] Loss: 0.031184 L1: 0.018339 Grad: 0.128139 Thermal: 0.000618 LR: 9.90e-06\n",
      "Epoch   5 [3550/10697 ( 33.2%)] Loss: 0.023664 L1: 0.013640 Grad: 0.100059 Thermal: 0.000350 LR: 9.90e-06\n",
      "Epoch   5 [3550/10697 ( 33.2%)] Loss: 0.023664 L1: 0.013640 Grad: 0.100059 Thermal: 0.000350 LR: 9.90e-06\n",
      "Epoch   5 [3600/10697 ( 33.7%)] Loss: 0.029212 L1: 0.017224 Grad: 0.119623 Thermal: 0.000510 LR: 9.90e-06\n",
      "Epoch   5 [3600/10697 ( 33.7%)] Loss: 0.029212 L1: 0.017224 Grad: 0.119623 Thermal: 0.000510 LR: 9.90e-06\n",
      "Epoch   5 [3650/10697 ( 34.1%)] Loss: 0.029196 L1: 0.016958 Grad: 0.122099 Thermal: 0.000565 LR: 9.90e-06\n",
      "Epoch   5 [3650/10697 ( 34.1%)] Loss: 0.029196 L1: 0.016958 Grad: 0.122099 Thermal: 0.000565 LR: 9.90e-06\n",
      "Epoch   5 [3700/10697 ( 34.6%)] Loss: 0.026415 L1: 0.015321 Grad: 0.110718 Thermal: 0.000455 LR: 9.90e-06\n",
      "Epoch   5 [3700/10697 ( 34.6%)] Loss: 0.026415 L1: 0.015321 Grad: 0.110718 Thermal: 0.000455 LR: 9.90e-06\n",
      "Epoch   5 [3750/10697 ( 35.1%)] Loss: 0.024881 L1: 0.014489 Grad: 0.103684 Thermal: 0.000476 LR: 9.90e-06\n",
      "Epoch   5 [3750/10697 ( 35.1%)] Loss: 0.024881 L1: 0.014489 Grad: 0.103684 Thermal: 0.000476 LR: 9.90e-06\n",
      "Epoch   5 [3800/10697 ( 35.5%)] Loss: 0.028599 L1: 0.016643 Grad: 0.119290 Thermal: 0.000541 LR: 9.90e-06\n",
      "Epoch   5 [3800/10697 ( 35.5%)] Loss: 0.028599 L1: 0.016643 Grad: 0.119290 Thermal: 0.000541 LR: 9.90e-06\n",
      "Epoch   5 [3850/10697 ( 36.0%)] Loss: 0.027804 L1: 0.016449 Grad: 0.113309 Thermal: 0.000482 LR: 9.90e-06\n",
      "Epoch   5 [3850/10697 ( 36.0%)] Loss: 0.027804 L1: 0.016449 Grad: 0.113309 Thermal: 0.000482 LR: 9.90e-06\n",
      "Epoch   5 [3900/10697 ( 36.5%)] Loss: 0.027050 L1: 0.015758 Grad: 0.112688 Thermal: 0.000454 LR: 9.90e-06\n",
      "Epoch   5 [3900/10697 ( 36.5%)] Loss: 0.027050 L1: 0.015758 Grad: 0.112688 Thermal: 0.000454 LR: 9.90e-06\n",
      "Epoch   5 [3950/10697 ( 36.9%)] Loss: 0.022878 L1: 0.013372 Grad: 0.094886 Thermal: 0.000352 LR: 9.90e-06\n",
      "Epoch   5 [3950/10697 ( 36.9%)] Loss: 0.022878 L1: 0.013372 Grad: 0.094886 Thermal: 0.000352 LR: 9.90e-06\n",
      "Epoch   5 [4000/10697 ( 37.4%)] Loss: 0.030834 L1: 0.017939 Grad: 0.128678 Thermal: 0.000564 LR: 9.90e-06\n",
      "Epoch   5 [4000/10697 ( 37.4%)] Loss: 0.030834 L1: 0.017939 Grad: 0.128678 Thermal: 0.000564 LR: 9.90e-06\n",
      "Epoch   5 [4050/10697 ( 37.9%)] Loss: 0.023312 L1: 0.013442 Grad: 0.098501 Thermal: 0.000386 LR: 9.90e-06\n",
      "Epoch   5 [4050/10697 ( 37.9%)] Loss: 0.023312 L1: 0.013442 Grad: 0.098501 Thermal: 0.000386 LR: 9.90e-06\n",
      "Epoch   5 [4100/10697 ( 38.3%)] Loss: 0.025598 L1: 0.015099 Grad: 0.104788 Thermal: 0.000402 LR: 9.90e-06\n",
      "Epoch   5 [4100/10697 ( 38.3%)] Loss: 0.025598 L1: 0.015099 Grad: 0.104788 Thermal: 0.000402 LR: 9.90e-06\n",
      "Epoch   5 [4150/10697 ( 38.8%)] Loss: 0.019411 L1: 0.010968 Grad: 0.084291 Thermal: 0.000273 LR: 9.90e-06\n",
      "Epoch   5 [4150/10697 ( 38.8%)] Loss: 0.019411 L1: 0.010968 Grad: 0.084291 Thermal: 0.000273 LR: 9.90e-06\n",
      "Epoch   5 [4200/10697 ( 39.3%)] Loss: 0.026340 L1: 0.014902 Grad: 0.114161 Thermal: 0.000421 LR: 9.90e-06\n",
      "Epoch   5 [4200/10697 ( 39.3%)] Loss: 0.026340 L1: 0.014902 Grad: 0.114161 Thermal: 0.000421 LR: 9.90e-06\n",
      "Epoch   5 [4250/10697 ( 39.7%)] Loss: 0.031921 L1: 0.018549 Grad: 0.133401 Thermal: 0.000620 LR: 9.90e-06\n",
      "Epoch   5 [4250/10697 ( 39.7%)] Loss: 0.031921 L1: 0.018549 Grad: 0.133401 Thermal: 0.000620 LR: 9.90e-06\n",
      "Epoch   5 [4300/10697 ( 40.2%)] Loss: 0.024687 L1: 0.014482 Grad: 0.101840 Thermal: 0.000422 LR: 9.90e-06\n",
      "Epoch   5 [4300/10697 ( 40.2%)] Loss: 0.024687 L1: 0.014482 Grad: 0.101840 Thermal: 0.000422 LR: 9.90e-06\n",
      "Epoch   5 [4350/10697 ( 40.7%)] Loss: 0.026702 L1: 0.015726 Grad: 0.109549 Thermal: 0.000425 LR: 9.90e-06\n",
      "Epoch   5 [4350/10697 ( 40.7%)] Loss: 0.026702 L1: 0.015726 Grad: 0.109549 Thermal: 0.000425 LR: 9.90e-06\n",
      "Epoch   5 [4400/10697 ( 41.1%)] Loss: 0.027180 L1: 0.015734 Grad: 0.114214 Thermal: 0.000490 LR: 9.90e-06\n",
      "Epoch   5 [4400/10697 ( 41.1%)] Loss: 0.027180 L1: 0.015734 Grad: 0.114214 Thermal: 0.000490 LR: 9.90e-06\n",
      "Epoch   5 [4450/10697 ( 41.6%)] Loss: 0.024317 L1: 0.014090 Grad: 0.102081 Thermal: 0.000363 LR: 9.90e-06\n",
      "Epoch   5 [4450/10697 ( 41.6%)] Loss: 0.024317 L1: 0.014090 Grad: 0.102081 Thermal: 0.000363 LR: 9.90e-06\n",
      "Epoch   5 [4500/10697 ( 42.1%)] Loss: 0.030018 L1: 0.017382 Grad: 0.126061 Thermal: 0.000598 LR: 9.90e-06\n",
      "Epoch   5 [4500/10697 ( 42.1%)] Loss: 0.030018 L1: 0.017382 Grad: 0.126061 Thermal: 0.000598 LR: 9.90e-06\n",
      "Epoch   5 [4550/10697 ( 42.5%)] Loss: 0.026682 L1: 0.015520 Grad: 0.111414 Thermal: 0.000418 LR: 9.90e-06\n",
      "Epoch   5 [4550/10697 ( 42.5%)] Loss: 0.026682 L1: 0.015520 Grad: 0.111414 Thermal: 0.000418 LR: 9.90e-06\n",
      "Epoch   5 [4600/10697 ( 43.0%)] Loss: 0.027399 L1: 0.015923 Grad: 0.114517 Thermal: 0.000475 LR: 9.90e-06\n",
      "Epoch   5 [4600/10697 ( 43.0%)] Loss: 0.027399 L1: 0.015923 Grad: 0.114517 Thermal: 0.000475 LR: 9.90e-06\n",
      "Epoch   5 [4650/10697 ( 43.5%)] Loss: 0.029357 L1: 0.017281 Grad: 0.120500 Thermal: 0.000531 LR: 9.90e-06\n",
      "Epoch   5 [4650/10697 ( 43.5%)] Loss: 0.029357 L1: 0.017281 Grad: 0.120500 Thermal: 0.000531 LR: 9.90e-06\n",
      "Epoch   5 [4700/10697 ( 43.9%)] Loss: 0.025928 L1: 0.015341 Grad: 0.105658 Thermal: 0.000433 LR: 9.90e-06\n",
      "Epoch   5 [4700/10697 ( 43.9%)] Loss: 0.025928 L1: 0.015341 Grad: 0.105658 Thermal: 0.000433 LR: 9.90e-06\n",
      "Epoch   5 [4750/10697 ( 44.4%)] Loss: 0.027450 L1: 0.015729 Grad: 0.116983 Thermal: 0.000444 LR: 9.90e-06\n",
      "Epoch   5 [4750/10697 ( 44.4%)] Loss: 0.027450 L1: 0.015729 Grad: 0.116983 Thermal: 0.000444 LR: 9.90e-06\n",
      "Epoch   5 [4800/10697 ( 44.9%)] Loss: 0.027740 L1: 0.016535 Grad: 0.111802 Thermal: 0.000484 LR: 9.90e-06\n",
      "Epoch   5 [4800/10697 ( 44.9%)] Loss: 0.027740 L1: 0.016535 Grad: 0.111802 Thermal: 0.000484 LR: 9.90e-06\n",
      "Epoch   5 [4850/10697 ( 45.3%)] Loss: 0.028407 L1: 0.016312 Grad: 0.120705 Thermal: 0.000499 LR: 9.90e-06\n",
      "Epoch   5 [4850/10697 ( 45.3%)] Loss: 0.028407 L1: 0.016312 Grad: 0.120705 Thermal: 0.000499 LR: 9.90e-06\n",
      "Epoch   5 [4900/10697 ( 45.8%)] Loss: 0.028490 L1: 0.016334 Grad: 0.121268 Thermal: 0.000598 LR: 9.90e-06\n",
      "Epoch   5 [4900/10697 ( 45.8%)] Loss: 0.028490 L1: 0.016334 Grad: 0.121268 Thermal: 0.000598 LR: 9.90e-06\n",
      "Epoch   5 [4950/10697 ( 46.3%)] Loss: 0.027527 L1: 0.016082 Grad: 0.114220 Thermal: 0.000458 LR: 9.90e-06\n",
      "Epoch   5 [4950/10697 ( 46.3%)] Loss: 0.027527 L1: 0.016082 Grad: 0.114220 Thermal: 0.000458 LR: 9.90e-06\n",
      "Epoch   5 [5000/10697 ( 46.7%)] Loss: 0.029693 L1: 0.017440 Grad: 0.122258 Thermal: 0.000538 LR: 9.90e-06\n",
      "Epoch   5 [5000/10697 ( 46.7%)] Loss: 0.029693 L1: 0.017440 Grad: 0.122258 Thermal: 0.000538 LR: 9.90e-06\n",
      "Epoch   5 [5050/10697 ( 47.2%)] Loss: 0.025843 L1: 0.014941 Grad: 0.108805 Thermal: 0.000430 LR: 9.90e-06\n",
      "Epoch   5 [5050/10697 ( 47.2%)] Loss: 0.025843 L1: 0.014941 Grad: 0.108805 Thermal: 0.000430 LR: 9.90e-06\n",
      "Epoch   5 [5100/10697 ( 47.7%)] Loss: 0.025117 L1: 0.014121 Grad: 0.109775 Thermal: 0.000382 LR: 9.90e-06\n",
      "Epoch   5 [5100/10697 ( 47.7%)] Loss: 0.025117 L1: 0.014121 Grad: 0.109775 Thermal: 0.000382 LR: 9.90e-06\n",
      "Epoch   5 [5150/10697 ( 48.1%)] Loss: 0.026008 L1: 0.015508 Grad: 0.104781 Thermal: 0.000443 LR: 9.90e-06\n",
      "Epoch   5 [5150/10697 ( 48.1%)] Loss: 0.026008 L1: 0.015508 Grad: 0.104781 Thermal: 0.000443 LR: 9.90e-06\n",
      "Epoch   5 [5200/10697 ( 48.6%)] Loss: 0.024089 L1: 0.013706 Grad: 0.103624 Thermal: 0.000412 LR: 9.90e-06\n",
      "Epoch   5 [5200/10697 ( 48.6%)] Loss: 0.024089 L1: 0.013706 Grad: 0.103624 Thermal: 0.000412 LR: 9.90e-06\n",
      "Epoch   5 [5250/10697 ( 49.1%)] Loss: 0.030903 L1: 0.017925 Grad: 0.129500 Thermal: 0.000556 LR: 9.90e-06\n",
      "Epoch   5 [5250/10697 ( 49.1%)] Loss: 0.030903 L1: 0.017925 Grad: 0.129500 Thermal: 0.000556 LR: 9.90e-06\n",
      "Epoch   5 [5300/10697 ( 49.5%)] Loss: 0.029542 L1: 0.017120 Grad: 0.123923 Thermal: 0.000601 LR: 9.90e-06\n",
      "Epoch   5 [5300/10697 ( 49.5%)] Loss: 0.029542 L1: 0.017120 Grad: 0.123923 Thermal: 0.000601 LR: 9.90e-06\n",
      "Epoch   5 [5350/10697 ( 50.0%)] Loss: 0.025183 L1: 0.014789 Grad: 0.103739 Thermal: 0.000409 LR: 9.90e-06\n",
      "Epoch   5 [5350/10697 ( 50.0%)] Loss: 0.025183 L1: 0.014789 Grad: 0.103739 Thermal: 0.000409 LR: 9.90e-06\n",
      "Epoch   5 [5400/10697 ( 50.5%)] Loss: 0.027312 L1: 0.016096 Grad: 0.111928 Thermal: 0.000461 LR: 9.90e-06\n",
      "Epoch   5 [5400/10697 ( 50.5%)] Loss: 0.027312 L1: 0.016096 Grad: 0.111928 Thermal: 0.000461 LR: 9.90e-06\n",
      "Epoch   5 [5450/10697 ( 50.9%)] Loss: 0.022555 L1: 0.013133 Grad: 0.094045 Thermal: 0.000346 LR: 9.90e-06\n",
      "Epoch   5 [5450/10697 ( 50.9%)] Loss: 0.022555 L1: 0.013133 Grad: 0.094045 Thermal: 0.000346 LR: 9.90e-06\n",
      "Epoch   5 [5500/10697 ( 51.4%)] Loss: 0.028362 L1: 0.016500 Grad: 0.118373 Thermal: 0.000499 LR: 9.90e-06\n",
      "Epoch   5 [5500/10697 ( 51.4%)] Loss: 0.028362 L1: 0.016500 Grad: 0.118373 Thermal: 0.000499 LR: 9.90e-06\n",
      "Epoch   5 [5550/10697 ( 51.9%)] Loss: 0.029909 L1: 0.017485 Grad: 0.123972 Thermal: 0.000540 LR: 9.90e-06\n",
      "Epoch   5 [5550/10697 ( 51.9%)] Loss: 0.029909 L1: 0.017485 Grad: 0.123972 Thermal: 0.000540 LR: 9.90e-06\n",
      "Epoch   5 [5600/10697 ( 52.4%)] Loss: 0.025743 L1: 0.014884 Grad: 0.108368 Thermal: 0.000438 LR: 9.90e-06\n",
      "Epoch   5 [5600/10697 ( 52.4%)] Loss: 0.025743 L1: 0.014884 Grad: 0.108368 Thermal: 0.000438 LR: 9.90e-06\n",
      "Epoch   5 [5650/10697 ( 52.8%)] Loss: 0.023024 L1: 0.013175 Grad: 0.098311 Thermal: 0.000345 LR: 9.90e-06\n",
      "Epoch   5 [5650/10697 ( 52.8%)] Loss: 0.023024 L1: 0.013175 Grad: 0.098311 Thermal: 0.000345 LR: 9.90e-06\n",
      "Epoch   5 [5700/10697 ( 53.3%)] Loss: 0.027334 L1: 0.016433 Grad: 0.108773 Thermal: 0.000480 LR: 9.90e-06\n",
      "Epoch   5 [5700/10697 ( 53.3%)] Loss: 0.027334 L1: 0.016433 Grad: 0.108773 Thermal: 0.000480 LR: 9.90e-06\n",
      "Epoch   5 [5750/10697 ( 53.8%)] Loss: 0.030588 L1: 0.017813 Grad: 0.127436 Thermal: 0.000645 LR: 9.90e-06\n",
      "Epoch   5 [5750/10697 ( 53.8%)] Loss: 0.030588 L1: 0.017813 Grad: 0.127436 Thermal: 0.000645 LR: 9.90e-06\n",
      "Epoch   5 [5800/10697 ( 54.2%)] Loss: 0.022737 L1: 0.012937 Grad: 0.097843 Thermal: 0.000300 LR: 9.90e-06\n",
      "Epoch   5 [5800/10697 ( 54.2%)] Loss: 0.022737 L1: 0.012937 Grad: 0.097843 Thermal: 0.000300 LR: 9.90e-06\n",
      "Epoch   5 [5850/10697 ( 54.7%)] Loss: 0.026187 L1: 0.015459 Grad: 0.107055 Thermal: 0.000448 LR: 9.90e-06\n",
      "Epoch   5 [5850/10697 ( 54.7%)] Loss: 0.026187 L1: 0.015459 Grad: 0.107055 Thermal: 0.000448 LR: 9.90e-06\n",
      "Epoch   5 [5900/10697 ( 55.2%)] Loss: 0.022344 L1: 0.012695 Grad: 0.096325 Thermal: 0.000340 LR: 9.90e-06\n",
      "Epoch   5 [5900/10697 ( 55.2%)] Loss: 0.022344 L1: 0.012695 Grad: 0.096325 Thermal: 0.000340 LR: 9.90e-06\n",
      "Epoch   5 [5950/10697 ( 55.6%)] Loss: 0.027424 L1: 0.016233 Grad: 0.111662 Thermal: 0.000487 LR: 9.90e-06\n",
      "Epoch   5 [5950/10697 ( 55.6%)] Loss: 0.027424 L1: 0.016233 Grad: 0.111662 Thermal: 0.000487 LR: 9.90e-06\n",
      "Epoch   5 [6000/10697 ( 56.1%)] Loss: 0.027374 L1: 0.015993 Grad: 0.113574 Thermal: 0.000462 LR: 9.90e-06\n",
      "Epoch   5 [6000/10697 ( 56.1%)] Loss: 0.027374 L1: 0.015993 Grad: 0.113574 Thermal: 0.000462 LR: 9.90e-06\n",
      "Epoch   5 [6050/10697 ( 56.6%)] Loss: 0.029721 L1: 0.017390 Grad: 0.123039 Thermal: 0.000546 LR: 9.90e-06\n",
      "Epoch   5 [6050/10697 ( 56.6%)] Loss: 0.029721 L1: 0.017390 Grad: 0.123039 Thermal: 0.000546 LR: 9.90e-06\n",
      "Epoch   5 [6100/10697 ( 57.0%)] Loss: 0.028604 L1: 0.016981 Grad: 0.115976 Thermal: 0.000506 LR: 9.90e-06\n",
      "Epoch   5 [6100/10697 ( 57.0%)] Loss: 0.028604 L1: 0.016981 Grad: 0.115976 Thermal: 0.000506 LR: 9.90e-06\n",
      "Epoch   5 [6150/10697 ( 57.5%)] Loss: 0.026091 L1: 0.015325 Grad: 0.107448 Thermal: 0.000431 LR: 9.90e-06\n",
      "Epoch   5 [6150/10697 ( 57.5%)] Loss: 0.026091 L1: 0.015325 Grad: 0.107448 Thermal: 0.000431 LR: 9.90e-06\n",
      "Epoch   5 [6200/10697 ( 58.0%)] Loss: 0.026402 L1: 0.015214 Grad: 0.111652 Thermal: 0.000459 LR: 9.90e-06\n",
      "Epoch   5 [6200/10697 ( 58.0%)] Loss: 0.026402 L1: 0.015214 Grad: 0.111652 Thermal: 0.000459 LR: 9.90e-06\n",
      "Epoch   5 [6250/10697 ( 58.4%)] Loss: 0.027244 L1: 0.015454 Grad: 0.117647 Thermal: 0.000505 LR: 9.90e-06\n",
      "Epoch   5 [6250/10697 ( 58.4%)] Loss: 0.027244 L1: 0.015454 Grad: 0.117647 Thermal: 0.000505 LR: 9.90e-06\n",
      "Epoch   5 [6300/10697 ( 58.9%)] Loss: 0.029559 L1: 0.017197 Grad: 0.123326 Thermal: 0.000579 LR: 9.90e-06\n",
      "Epoch   5 [6300/10697 ( 58.9%)] Loss: 0.029559 L1: 0.017197 Grad: 0.123326 Thermal: 0.000579 LR: 9.90e-06\n",
      "Epoch   5 [6350/10697 ( 59.4%)] Loss: 0.027842 L1: 0.016584 Grad: 0.112325 Thermal: 0.000494 LR: 9.90e-06\n",
      "Epoch   5 [6350/10697 ( 59.4%)] Loss: 0.027842 L1: 0.016584 Grad: 0.112325 Thermal: 0.000494 LR: 9.90e-06\n",
      "Epoch   5 [6400/10697 ( 59.8%)] Loss: 0.022341 L1: 0.013263 Grad: 0.090608 Thermal: 0.000354 LR: 9.90e-06\n",
      "Epoch   5 [6400/10697 ( 59.8%)] Loss: 0.022341 L1: 0.013263 Grad: 0.090608 Thermal: 0.000354 LR: 9.90e-06\n",
      "Epoch   5 [6450/10697 ( 60.3%)] Loss: 0.029139 L1: 0.017251 Grad: 0.118620 Thermal: 0.000516 LR: 9.90e-06\n",
      "Epoch   5 [6450/10697 ( 60.3%)] Loss: 0.029139 L1: 0.017251 Grad: 0.118620 Thermal: 0.000516 LR: 9.90e-06\n",
      "Epoch   5 [6500/10697 ( 60.8%)] Loss: 0.026795 L1: 0.015775 Grad: 0.109951 Thermal: 0.000496 LR: 9.90e-06\n",
      "Epoch   5 [6500/10697 ( 60.8%)] Loss: 0.026795 L1: 0.015775 Grad: 0.109951 Thermal: 0.000496 LR: 9.90e-06\n",
      "Epoch   5 [6550/10697 ( 61.2%)] Loss: 0.024784 L1: 0.014678 Grad: 0.100855 Thermal: 0.000411 LR: 9.90e-06\n",
      "Epoch   5 [6550/10697 ( 61.2%)] Loss: 0.024784 L1: 0.014678 Grad: 0.100855 Thermal: 0.000411 LR: 9.90e-06\n",
      "Epoch   5 [6600/10697 ( 61.7%)] Loss: 0.027365 L1: 0.015854 Grad: 0.114872 Thermal: 0.000485 LR: 9.90e-06\n",
      "Epoch   5 [6600/10697 ( 61.7%)] Loss: 0.027365 L1: 0.015854 Grad: 0.114872 Thermal: 0.000485 LR: 9.90e-06\n",
      "Epoch   5 [6650/10697 ( 62.2%)] Loss: 0.027200 L1: 0.015513 Grad: 0.116651 Thermal: 0.000448 LR: 9.90e-06\n",
      "Epoch   5 [6650/10697 ( 62.2%)] Loss: 0.027200 L1: 0.015513 Grad: 0.116651 Thermal: 0.000448 LR: 9.90e-06\n",
      "Epoch   5 [6700/10697 ( 62.6%)] Loss: 0.033782 L1: 0.020014 Grad: 0.137343 Thermal: 0.000673 LR: 9.90e-06\n",
      "Epoch   5 [6700/10697 ( 62.6%)] Loss: 0.033782 L1: 0.020014 Grad: 0.137343 Thermal: 0.000673 LR: 9.90e-06\n",
      "Epoch   5 [6750/10697 ( 63.1%)] Loss: 0.030677 L1: 0.018164 Grad: 0.124837 Thermal: 0.000572 LR: 9.90e-06\n",
      "Epoch   5 [6750/10697 ( 63.1%)] Loss: 0.030677 L1: 0.018164 Grad: 0.124837 Thermal: 0.000572 LR: 9.90e-06\n",
      "Epoch   5 [6800/10697 ( 63.6%)] Loss: 0.025993 L1: 0.015141 Grad: 0.108313 Thermal: 0.000424 LR: 9.90e-06\n",
      "Epoch   5 [6800/10697 ( 63.6%)] Loss: 0.025993 L1: 0.015141 Grad: 0.108313 Thermal: 0.000424 LR: 9.90e-06\n",
      "Epoch   5 [6850/10697 ( 64.0%)] Loss: 0.029544 L1: 0.017215 Grad: 0.123029 Thermal: 0.000522 LR: 9.90e-06\n",
      "Epoch   5 [6850/10697 ( 64.0%)] Loss: 0.029544 L1: 0.017215 Grad: 0.123029 Thermal: 0.000522 LR: 9.90e-06\n",
      "Epoch   5 [6900/10697 ( 64.5%)] Loss: 0.025322 L1: 0.014714 Grad: 0.105870 Thermal: 0.000417 LR: 9.90e-06\n",
      "Epoch   5 [6900/10697 ( 64.5%)] Loss: 0.025322 L1: 0.014714 Grad: 0.105870 Thermal: 0.000417 LR: 9.90e-06\n",
      "Epoch   5 [6950/10697 ( 65.0%)] Loss: 0.030560 L1: 0.017903 Grad: 0.126253 Thermal: 0.000638 LR: 9.90e-06\n",
      "Epoch   5 [6950/10697 ( 65.0%)] Loss: 0.030560 L1: 0.017903 Grad: 0.126253 Thermal: 0.000638 LR: 9.90e-06\n",
      "Epoch   5 [7000/10697 ( 65.4%)] Loss: 0.018317 L1: 0.010700 Grad: 0.076038 Thermal: 0.000258 LR: 9.90e-06\n",
      "Epoch   5 [7000/10697 ( 65.4%)] Loss: 0.018317 L1: 0.010700 Grad: 0.076038 Thermal: 0.000258 LR: 9.90e-06\n",
      "Epoch   5 [7050/10697 ( 65.9%)] Loss: 0.028964 L1: 0.016937 Grad: 0.120031 Thermal: 0.000490 LR: 9.90e-06\n",
      "Epoch   5 [7050/10697 ( 65.9%)] Loss: 0.028964 L1: 0.016937 Grad: 0.120031 Thermal: 0.000490 LR: 9.90e-06\n",
      "Epoch   5 [7100/10697 ( 66.4%)] Loss: 0.026587 L1: 0.015530 Grad: 0.110345 Thermal: 0.000444 LR: 9.90e-06\n",
      "Epoch   5 [7100/10697 ( 66.4%)] Loss: 0.026587 L1: 0.015530 Grad: 0.110345 Thermal: 0.000444 LR: 9.90e-06\n",
      "Epoch   5 [7150/10697 ( 66.8%)] Loss: 0.034041 L1: 0.019557 Grad: 0.144458 Thermal: 0.000766 LR: 9.90e-06\n",
      "Epoch   5 [7150/10697 ( 66.8%)] Loss: 0.034041 L1: 0.019557 Grad: 0.144458 Thermal: 0.000766 LR: 9.90e-06\n",
      "Epoch   5 [7200/10697 ( 67.3%)] Loss: 0.026152 L1: 0.015393 Grad: 0.107380 Thermal: 0.000434 LR: 9.90e-06\n",
      "Epoch   5 [7200/10697 ( 67.3%)] Loss: 0.026152 L1: 0.015393 Grad: 0.107380 Thermal: 0.000434 LR: 9.90e-06\n",
      "Epoch   5 [7250/10697 ( 67.8%)] Loss: 0.027795 L1: 0.016013 Grad: 0.117597 Thermal: 0.000435 LR: 9.90e-06\n",
      "Epoch   5 [7250/10697 ( 67.8%)] Loss: 0.027795 L1: 0.016013 Grad: 0.117597 Thermal: 0.000435 LR: 9.90e-06\n",
      "Epoch   5 [7300/10697 ( 68.2%)] Loss: 0.025045 L1: 0.014944 Grad: 0.100815 Thermal: 0.000401 LR: 9.90e-06\n",
      "Epoch   5 [7300/10697 ( 68.2%)] Loss: 0.025045 L1: 0.014944 Grad: 0.100815 Thermal: 0.000401 LR: 9.90e-06\n",
      "Epoch   5 [7350/10697 ( 68.7%)] Loss: 0.027470 L1: 0.015892 Grad: 0.115549 Thermal: 0.000466 LR: 9.90e-06\n",
      "Epoch   5 [7350/10697 ( 68.7%)] Loss: 0.027470 L1: 0.015892 Grad: 0.115549 Thermal: 0.000466 LR: 9.90e-06\n",
      "Epoch   5 [7400/10697 ( 69.2%)] Loss: 0.023365 L1: 0.013335 Grad: 0.100136 Thermal: 0.000327 LR: 9.90e-06\n",
      "Epoch   5 [7400/10697 ( 69.2%)] Loss: 0.023365 L1: 0.013335 Grad: 0.100136 Thermal: 0.000327 LR: 9.90e-06\n",
      "Epoch   5 [7450/10697 ( 69.6%)] Loss: 0.026140 L1: 0.015316 Grad: 0.107971 Thermal: 0.000541 LR: 9.90e-06\n",
      "Epoch   5 [7450/10697 ( 69.6%)] Loss: 0.026140 L1: 0.015316 Grad: 0.107971 Thermal: 0.000541 LR: 9.90e-06\n",
      "Epoch   5 [7500/10697 ( 70.1%)] Loss: 0.029821 L1: 0.017245 Grad: 0.125491 Thermal: 0.000536 LR: 9.90e-06\n",
      "Epoch   5 [7500/10697 ( 70.1%)] Loss: 0.029821 L1: 0.017245 Grad: 0.125491 Thermal: 0.000536 LR: 9.90e-06\n",
      "Epoch   5 [7550/10697 ( 70.6%)] Loss: 0.028560 L1: 0.016450 Grad: 0.120806 Thermal: 0.000592 LR: 9.90e-06\n",
      "Epoch   5 [7550/10697 ( 70.6%)] Loss: 0.028560 L1: 0.016450 Grad: 0.120806 Thermal: 0.000592 LR: 9.90e-06\n",
      "Epoch   5 [7600/10697 ( 71.0%)] Loss: 0.022848 L1: 0.013346 Grad: 0.094844 Thermal: 0.000352 LR: 9.90e-06\n",
      "Epoch   5 [7600/10697 ( 71.0%)] Loss: 0.022848 L1: 0.013346 Grad: 0.094844 Thermal: 0.000352 LR: 9.90e-06\n",
      "Epoch   5 [7650/10697 ( 71.5%)] Loss: 0.025327 L1: 0.014873 Grad: 0.104339 Thermal: 0.000408 LR: 9.90e-06\n",
      "Epoch   5 [7650/10697 ( 71.5%)] Loss: 0.025327 L1: 0.014873 Grad: 0.104339 Thermal: 0.000408 LR: 9.90e-06\n",
      "Epoch   5 [7700/10697 ( 72.0%)] Loss: 0.027154 L1: 0.015676 Grad: 0.114549 Thermal: 0.000453 LR: 9.90e-06\n",
      "Epoch   5 [7700/10697 ( 72.0%)] Loss: 0.027154 L1: 0.015676 Grad: 0.114549 Thermal: 0.000453 LR: 9.90e-06\n",
      "Epoch   5 [7750/10697 ( 72.5%)] Loss: 0.026220 L1: 0.015388 Grad: 0.108103 Thermal: 0.000426 LR: 9.90e-06\n",
      "Epoch   5 [7750/10697 ( 72.5%)] Loss: 0.026220 L1: 0.015388 Grad: 0.108103 Thermal: 0.000426 LR: 9.90e-06\n",
      "Epoch   5 [7800/10697 ( 72.9%)] Loss: 0.025042 L1: 0.014624 Grad: 0.103960 Thermal: 0.000437 LR: 9.90e-06\n",
      "Epoch   5 [7800/10697 ( 72.9%)] Loss: 0.025042 L1: 0.014624 Grad: 0.103960 Thermal: 0.000437 LR: 9.90e-06\n",
      "Epoch   5 [7850/10697 ( 73.4%)] Loss: 0.028868 L1: 0.016992 Grad: 0.118493 Thermal: 0.000538 LR: 9.90e-06\n",
      "Epoch   5 [7850/10697 ( 73.4%)] Loss: 0.028868 L1: 0.016992 Grad: 0.118493 Thermal: 0.000538 LR: 9.90e-06\n",
      "Epoch   5 [7900/10697 ( 73.9%)] Loss: 0.034765 L1: 0.020296 Grad: 0.144328 Thermal: 0.000736 LR: 9.90e-06\n",
      "Epoch   5 [7900/10697 ( 73.9%)] Loss: 0.034765 L1: 0.020296 Grad: 0.144328 Thermal: 0.000736 LR: 9.90e-06\n",
      "Epoch   5 [7950/10697 ( 74.3%)] Loss: 0.028039 L1: 0.016836 Grad: 0.111776 Thermal: 0.000499 LR: 9.90e-06\n",
      "Epoch   5 [7950/10697 ( 74.3%)] Loss: 0.028039 L1: 0.016836 Grad: 0.111776 Thermal: 0.000499 LR: 9.90e-06\n",
      "Epoch   5 [8000/10697 ( 74.8%)] Loss: 0.022012 L1: 0.012673 Grad: 0.093193 Thermal: 0.000383 LR: 9.90e-06\n",
      "Epoch   5 [8000/10697 ( 74.8%)] Loss: 0.022012 L1: 0.012673 Grad: 0.093193 Thermal: 0.000383 LR: 9.90e-06\n",
      "Epoch   5 [8050/10697 ( 75.3%)] Loss: 0.033954 L1: 0.019230 Grad: 0.146864 Thermal: 0.000763 LR: 9.90e-06\n",
      "Epoch   5 [8050/10697 ( 75.3%)] Loss: 0.033954 L1: 0.019230 Grad: 0.146864 Thermal: 0.000763 LR: 9.90e-06\n",
      "Epoch   5 [8100/10697 ( 75.7%)] Loss: 0.021561 L1: 0.012451 Grad: 0.090889 Thermal: 0.000425 LR: 9.90e-06\n",
      "Epoch   5 [8100/10697 ( 75.7%)] Loss: 0.021561 L1: 0.012451 Grad: 0.090889 Thermal: 0.000425 LR: 9.90e-06\n",
      "Epoch   5 [8150/10697 ( 76.2%)] Loss: 0.025262 L1: 0.015091 Grad: 0.101486 Thermal: 0.000451 LR: 9.90e-06\n",
      "Epoch   5 [8150/10697 ( 76.2%)] Loss: 0.025262 L1: 0.015091 Grad: 0.101486 Thermal: 0.000451 LR: 9.90e-06\n",
      "Epoch   5 [8200/10697 ( 76.7%)] Loss: 0.024315 L1: 0.013806 Grad: 0.104909 Thermal: 0.000374 LR: 9.90e-06\n",
      "Epoch   5 [8200/10697 ( 76.7%)] Loss: 0.024315 L1: 0.013806 Grad: 0.104909 Thermal: 0.000374 LR: 9.90e-06\n",
      "Epoch   5 [8250/10697 ( 77.1%)] Loss: 0.020111 L1: 0.011428 Grad: 0.086697 Thermal: 0.000272 LR: 9.90e-06\n",
      "Epoch   5 [8250/10697 ( 77.1%)] Loss: 0.020111 L1: 0.011428 Grad: 0.086697 Thermal: 0.000272 LR: 9.90e-06\n",
      "Epoch   5 [8300/10697 ( 77.6%)] Loss: 0.025779 L1: 0.014891 Grad: 0.108660 Thermal: 0.000452 LR: 9.90e-06\n",
      "Epoch   5 [8300/10697 ( 77.6%)] Loss: 0.025779 L1: 0.014891 Grad: 0.108660 Thermal: 0.000452 LR: 9.90e-06\n",
      "Epoch   5 [8350/10697 ( 78.1%)] Loss: 0.019988 L1: 0.011370 Grad: 0.086042 Thermal: 0.000265 LR: 9.90e-06\n",
      "Epoch   5 [8350/10697 ( 78.1%)] Loss: 0.019988 L1: 0.011370 Grad: 0.086042 Thermal: 0.000265 LR: 9.90e-06\n",
      "Epoch   5 [8400/10697 ( 78.5%)] Loss: 0.029856 L1: 0.017653 Grad: 0.121752 Thermal: 0.000567 LR: 9.90e-06\n",
      "Epoch   5 [8400/10697 ( 78.5%)] Loss: 0.029856 L1: 0.017653 Grad: 0.121752 Thermal: 0.000567 LR: 9.90e-06\n",
      "Epoch   5 [8450/10697 ( 79.0%)] Loss: 0.030291 L1: 0.017539 Grad: 0.127250 Thermal: 0.000535 LR: 9.90e-06\n",
      "Epoch   5 [8450/10697 ( 79.0%)] Loss: 0.030291 L1: 0.017539 Grad: 0.127250 Thermal: 0.000535 LR: 9.90e-06\n",
      "Epoch   5 [8500/10697 ( 79.5%)] Loss: 0.026946 L1: 0.015841 Grad: 0.110821 Thermal: 0.000460 LR: 9.90e-06\n",
      "Epoch   5 [8500/10697 ( 79.5%)] Loss: 0.026946 L1: 0.015841 Grad: 0.110821 Thermal: 0.000460 LR: 9.90e-06\n",
      "Epoch   5 [8550/10697 ( 79.9%)] Loss: 0.031858 L1: 0.018686 Grad: 0.131399 Thermal: 0.000635 LR: 9.90e-06\n",
      "Epoch   5 [8550/10697 ( 79.9%)] Loss: 0.031858 L1: 0.018686 Grad: 0.131399 Thermal: 0.000635 LR: 9.90e-06\n",
      "Epoch   5 [8600/10697 ( 80.4%)] Loss: 0.027307 L1: 0.016330 Grad: 0.109521 Thermal: 0.000496 LR: 9.90e-06\n",
      "Epoch   5 [8600/10697 ( 80.4%)] Loss: 0.027307 L1: 0.016330 Grad: 0.109521 Thermal: 0.000496 LR: 9.90e-06\n",
      "Epoch   5 [8650/10697 ( 80.9%)] Loss: 0.030535 L1: 0.017741 Grad: 0.127648 Thermal: 0.000582 LR: 9.90e-06\n",
      "Epoch   5 [8650/10697 ( 80.9%)] Loss: 0.030535 L1: 0.017741 Grad: 0.127648 Thermal: 0.000582 LR: 9.90e-06\n",
      "Epoch   5 [8700/10697 ( 81.3%)] Loss: 0.025586 L1: 0.015447 Grad: 0.101167 Thermal: 0.000448 LR: 9.90e-06\n",
      "Epoch   5 [8700/10697 ( 81.3%)] Loss: 0.025586 L1: 0.015447 Grad: 0.101167 Thermal: 0.000448 LR: 9.90e-06\n",
      "Epoch   5 [8750/10697 ( 81.8%)] Loss: 0.025893 L1: 0.015100 Grad: 0.107698 Thermal: 0.000464 LR: 9.90e-06\n",
      "Epoch   5 [8750/10697 ( 81.8%)] Loss: 0.025893 L1: 0.015100 Grad: 0.107698 Thermal: 0.000464 LR: 9.90e-06\n",
      "Epoch   5 [8800/10697 ( 82.3%)] Loss: 0.023539 L1: 0.013822 Grad: 0.096972 Thermal: 0.000396 LR: 9.90e-06\n",
      "Epoch   5 [8800/10697 ( 82.3%)] Loss: 0.023539 L1: 0.013822 Grad: 0.096972 Thermal: 0.000396 LR: 9.90e-06\n",
      "Epoch   5 [8850/10697 ( 82.7%)] Loss: 0.023041 L1: 0.013420 Grad: 0.096009 Thermal: 0.000386 LR: 9.90e-06\n",
      "Epoch   5 [8850/10697 ( 82.7%)] Loss: 0.023041 L1: 0.013420 Grad: 0.096009 Thermal: 0.000386 LR: 9.90e-06\n",
      "Epoch   5 [8900/10697 ( 83.2%)] Loss: 0.028008 L1: 0.016142 Grad: 0.118422 Thermal: 0.000471 LR: 9.90e-06\n",
      "Epoch   5 [8900/10697 ( 83.2%)] Loss: 0.028008 L1: 0.016142 Grad: 0.118422 Thermal: 0.000471 LR: 9.90e-06\n",
      "Epoch   5 [8950/10697 ( 83.7%)] Loss: 0.019823 L1: 0.011550 Grad: 0.082582 Thermal: 0.000297 LR: 9.90e-06\n",
      "Epoch   5 [8950/10697 ( 83.7%)] Loss: 0.019823 L1: 0.011550 Grad: 0.082582 Thermal: 0.000297 LR: 9.90e-06\n",
      "Epoch   5 [9000/10697 ( 84.1%)] Loss: 0.021754 L1: 0.012765 Grad: 0.089727 Thermal: 0.000320 LR: 9.90e-06\n",
      "Epoch   5 [9000/10697 ( 84.1%)] Loss: 0.021754 L1: 0.012765 Grad: 0.089727 Thermal: 0.000320 LR: 9.90e-06\n",
      "Epoch   5 [9050/10697 ( 84.6%)] Loss: 0.028318 L1: 0.016522 Grad: 0.117721 Thermal: 0.000483 LR: 9.90e-06\n",
      "Epoch   5 [9050/10697 ( 84.6%)] Loss: 0.028318 L1: 0.016522 Grad: 0.117721 Thermal: 0.000483 LR: 9.90e-06\n",
      "Epoch   5 [9100/10697 ( 85.1%)] Loss: 0.023141 L1: 0.013432 Grad: 0.096900 Thermal: 0.000366 LR: 9.90e-06\n",
      "Epoch   5 [9100/10697 ( 85.1%)] Loss: 0.023141 L1: 0.013432 Grad: 0.096900 Thermal: 0.000366 LR: 9.90e-06\n",
      "Epoch   5 [9150/10697 ( 85.5%)] Loss: 0.030219 L1: 0.017518 Grad: 0.126727 Thermal: 0.000550 LR: 9.90e-06\n",
      "Epoch   5 [9150/10697 ( 85.5%)] Loss: 0.030219 L1: 0.017518 Grad: 0.126727 Thermal: 0.000550 LR: 9.90e-06\n",
      "Epoch   5 [9200/10697 ( 86.0%)] Loss: 0.036420 L1: 0.021140 Grad: 0.152411 Thermal: 0.000784 LR: 9.90e-06\n",
      "Epoch   5 [9200/10697 ( 86.0%)] Loss: 0.036420 L1: 0.021140 Grad: 0.152411 Thermal: 0.000784 LR: 9.90e-06\n",
      "Epoch   5 [9250/10697 ( 86.5%)] Loss: 0.024000 L1: 0.014019 Grad: 0.099619 Thermal: 0.000390 LR: 9.90e-06\n",
      "Epoch   5 [9250/10697 ( 86.5%)] Loss: 0.024000 L1: 0.014019 Grad: 0.099619 Thermal: 0.000390 LR: 9.90e-06\n",
      "Epoch   5 [9300/10697 ( 86.9%)] Loss: 0.024683 L1: 0.014146 Grad: 0.105172 Thermal: 0.000382 LR: 9.90e-06\n",
      "Epoch   5 [9300/10697 ( 86.9%)] Loss: 0.024683 L1: 0.014146 Grad: 0.105172 Thermal: 0.000382 LR: 9.90e-06\n",
      "Epoch   5 [9350/10697 ( 87.4%)] Loss: 0.028801 L1: 0.016791 Grad: 0.119846 Thermal: 0.000514 LR: 9.90e-06\n",
      "Epoch   5 [9350/10697 ( 87.4%)] Loss: 0.028801 L1: 0.016791 Grad: 0.119846 Thermal: 0.000514 LR: 9.90e-06\n",
      "Epoch   5 [9400/10697 ( 87.9%)] Loss: 0.031247 L1: 0.018110 Grad: 0.131046 Thermal: 0.000637 LR: 9.90e-06\n",
      "Epoch   5 [9400/10697 ( 87.9%)] Loss: 0.031247 L1: 0.018110 Grad: 0.131046 Thermal: 0.000637 LR: 9.90e-06\n",
      "Epoch   5 [9450/10697 ( 88.3%)] Loss: 0.031234 L1: 0.018208 Grad: 0.129942 Thermal: 0.000643 LR: 9.90e-06\n",
      "Epoch   5 [9450/10697 ( 88.3%)] Loss: 0.031234 L1: 0.018208 Grad: 0.129942 Thermal: 0.000643 LR: 9.90e-06\n",
      "Epoch   5 [9500/10697 ( 88.8%)] Loss: 0.026992 L1: 0.015733 Grad: 0.112371 Thermal: 0.000434 LR: 9.90e-06\n",
      "Epoch   5 [9500/10697 ( 88.8%)] Loss: 0.026992 L1: 0.015733 Grad: 0.112371 Thermal: 0.000434 LR: 9.90e-06\n",
      "Epoch   5 [9550/10697 ( 89.3%)] Loss: 0.024553 L1: 0.014663 Grad: 0.098693 Thermal: 0.000410 LR: 9.90e-06\n",
      "Epoch   5 [9550/10697 ( 89.3%)] Loss: 0.024553 L1: 0.014663 Grad: 0.098693 Thermal: 0.000410 LR: 9.90e-06\n",
      "Epoch   5 [9600/10697 ( 89.7%)] Loss: 0.033080 L1: 0.019426 Grad: 0.136209 Thermal: 0.000661 LR: 9.90e-06\n",
      "Epoch   5 [9600/10697 ( 89.7%)] Loss: 0.033080 L1: 0.019426 Grad: 0.136209 Thermal: 0.000661 LR: 9.90e-06\n",
      "Epoch   5 [9650/10697 ( 90.2%)] Loss: 0.023872 L1: 0.013905 Grad: 0.099473 Thermal: 0.000409 LR: 9.90e-06\n",
      "Epoch   5 [9650/10697 ( 90.2%)] Loss: 0.023872 L1: 0.013905 Grad: 0.099473 Thermal: 0.000409 LR: 9.90e-06\n",
      "Epoch   5 [9700/10697 ( 90.7%)] Loss: 0.028229 L1: 0.016541 Grad: 0.116648 Thermal: 0.000465 LR: 9.90e-06\n",
      "Epoch   5 [9700/10697 ( 90.7%)] Loss: 0.028229 L1: 0.016541 Grad: 0.116648 Thermal: 0.000465 LR: 9.90e-06\n",
      "Epoch   5 [9750/10697 ( 91.1%)] Loss: 0.027728 L1: 0.015522 Grad: 0.121830 Thermal: 0.000445 LR: 9.90e-06\n",
      "Epoch   5 [9750/10697 ( 91.1%)] Loss: 0.027728 L1: 0.015522 Grad: 0.121830 Thermal: 0.000445 LR: 9.90e-06\n",
      "Epoch   5 [9800/10697 ( 91.6%)] Loss: 0.024290 L1: 0.014602 Grad: 0.096680 Thermal: 0.000395 LR: 9.90e-06\n",
      "Epoch   5 [9800/10697 ( 91.6%)] Loss: 0.024290 L1: 0.014602 Grad: 0.096680 Thermal: 0.000395 LR: 9.90e-06\n",
      "Epoch   5 [9850/10697 ( 92.1%)] Loss: 0.032035 L1: 0.018420 Grad: 0.135831 Thermal: 0.000637 LR: 9.90e-06\n",
      "Epoch   5 [9850/10697 ( 92.1%)] Loss: 0.032035 L1: 0.018420 Grad: 0.135831 Thermal: 0.000637 LR: 9.90e-06\n",
      "Epoch   5 [9900/10697 ( 92.5%)] Loss: 0.026778 L1: 0.015875 Grad: 0.108788 Thermal: 0.000482 LR: 9.90e-06\n",
      "Epoch   5 [9900/10697 ( 92.5%)] Loss: 0.026778 L1: 0.015875 Grad: 0.108788 Thermal: 0.000482 LR: 9.90e-06\n",
      "Epoch   5 [9950/10697 ( 93.0%)] Loss: 0.026765 L1: 0.016115 Grad: 0.106259 Thermal: 0.000480 LR: 9.90e-06\n",
      "Epoch   5 [9950/10697 ( 93.0%)] Loss: 0.026765 L1: 0.016115 Grad: 0.106259 Thermal: 0.000480 LR: 9.90e-06\n",
      "Epoch   5 [10000/10697 ( 93.5%)] Loss: 0.024724 L1: 0.014255 Grad: 0.104474 Thermal: 0.000422 LR: 9.90e-06\n",
      "Epoch   5 [10000/10697 ( 93.5%)] Loss: 0.024724 L1: 0.014255 Grad: 0.104474 Thermal: 0.000422 LR: 9.90e-06\n",
      "Epoch   5 [10050/10697 ( 94.0%)] Loss: 0.027884 L1: 0.016342 Grad: 0.115160 Thermal: 0.000517 LR: 9.90e-06\n",
      "Epoch   5 [10050/10697 ( 94.0%)] Loss: 0.027884 L1: 0.016342 Grad: 0.115160 Thermal: 0.000517 LR: 9.90e-06\n",
      "Epoch   5 [10100/10697 ( 94.4%)] Loss: 0.024249 L1: 0.014447 Grad: 0.097826 Thermal: 0.000385 LR: 9.90e-06\n",
      "Epoch   5 [10100/10697 ( 94.4%)] Loss: 0.024249 L1: 0.014447 Grad: 0.097826 Thermal: 0.000385 LR: 9.90e-06\n",
      "Epoch   5 [10150/10697 ( 94.9%)] Loss: 0.028001 L1: 0.016235 Grad: 0.117375 Thermal: 0.000559 LR: 9.90e-06\n",
      "Epoch   5 [10150/10697 ( 94.9%)] Loss: 0.028001 L1: 0.016235 Grad: 0.117375 Thermal: 0.000559 LR: 9.90e-06\n",
      "Epoch   5 [10200/10697 ( 95.4%)] Loss: 0.028535 L1: 0.016098 Grad: 0.124111 Thermal: 0.000510 LR: 9.90e-06\n",
      "Epoch   5 [10200/10697 ( 95.4%)] Loss: 0.028535 L1: 0.016098 Grad: 0.124111 Thermal: 0.000510 LR: 9.90e-06\n",
      "Epoch   5 [10250/10697 ( 95.8%)] Loss: 0.026181 L1: 0.015378 Grad: 0.107768 Thermal: 0.000528 LR: 9.90e-06\n",
      "Epoch   5 [10250/10697 ( 95.8%)] Loss: 0.026181 L1: 0.015378 Grad: 0.107768 Thermal: 0.000528 LR: 9.90e-06\n",
      "Epoch   5 [10300/10697 ( 96.3%)] Loss: 0.028406 L1: 0.016762 Grad: 0.116197 Thermal: 0.000493 LR: 9.90e-06\n",
      "Epoch   5 [10300/10697 ( 96.3%)] Loss: 0.028406 L1: 0.016762 Grad: 0.116197 Thermal: 0.000493 LR: 9.90e-06\n",
      "Epoch   5 [10350/10697 ( 96.8%)] Loss: 0.019766 L1: 0.011179 Grad: 0.085748 Thermal: 0.000240 LR: 9.90e-06\n",
      "Epoch   5 [10350/10697 ( 96.8%)] Loss: 0.019766 L1: 0.011179 Grad: 0.085748 Thermal: 0.000240 LR: 9.90e-06\n",
      "Epoch   5 [10400/10697 ( 97.2%)] Loss: 0.027844 L1: 0.016675 Grad: 0.111438 Thermal: 0.000491 LR: 9.90e-06\n",
      "Epoch   5 [10400/10697 ( 97.2%)] Loss: 0.027844 L1: 0.016675 Grad: 0.111438 Thermal: 0.000491 LR: 9.90e-06\n",
      "Epoch   5 [10450/10697 ( 97.7%)] Loss: 0.033550 L1: 0.019019 Grad: 0.144952 Thermal: 0.000722 LR: 9.90e-06\n",
      "Epoch   5 [10450/10697 ( 97.7%)] Loss: 0.033550 L1: 0.019019 Grad: 0.144952 Thermal: 0.000722 LR: 9.90e-06\n",
      "Epoch   5 [10500/10697 ( 98.2%)] Loss: 0.028153 L1: 0.016446 Grad: 0.116834 Thermal: 0.000474 LR: 9.90e-06\n",
      "Epoch   5 [10500/10697 ( 98.2%)] Loss: 0.028153 L1: 0.016446 Grad: 0.116834 Thermal: 0.000474 LR: 9.90e-06\n",
      "Epoch   5 [10550/10697 ( 98.6%)] Loss: 0.024457 L1: 0.014309 Grad: 0.101279 Thermal: 0.000399 LR: 9.90e-06\n",
      "Epoch   5 [10550/10697 ( 98.6%)] Loss: 0.024457 L1: 0.014309 Grad: 0.101279 Thermal: 0.000399 LR: 9.90e-06\n",
      "Epoch   5 [10600/10697 ( 99.1%)] Loss: 0.028153 L1: 0.016731 Grad: 0.113951 Thermal: 0.000540 LR: 9.90e-06\n",
      "Epoch   5 [10600/10697 ( 99.1%)] Loss: 0.028153 L1: 0.016731 Grad: 0.113951 Thermal: 0.000540 LR: 9.90e-06\n",
      "Epoch   5 [10650/10697 ( 99.6%)] Loss: 0.027578 L1: 0.016362 Grad: 0.111916 Thermal: 0.000480 LR: 9.90e-06\n",
      "Epoch   5 [10650/10697 ( 99.6%)] Loss: 0.027578 L1: 0.016362 Grad: 0.111916 Thermal: 0.000480 LR: 9.90e-06\n",
      "üí´ New best model saved! PSNR: 33.75\n",
      "Epoch   5 Summary: Loss=0.026983 (L1:0.0157, Grad:0.1126, Thermal:0.0005) Val_PSNR=33.75dB Best=33.75dB Time=21.6min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "üí´ New best model saved! PSNR: 33.75\n",
      "Epoch   5 Summary: Loss=0.026983 (L1:0.0157, Grad:0.1126, Thermal:0.0005) Val_PSNR=33.75dB Best=33.75dB Time=21.6min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch   6 [   0/10697 (  0.0%)] Loss: 0.027297 L1: 0.015798 Grad: 0.114754 Thermal: 0.000455 LR: 9.86e-06\n",
      "Epoch   6 [   0/10697 (  0.0%)] Loss: 0.027297 L1: 0.015798 Grad: 0.114754 Thermal: 0.000455 LR: 9.86e-06\n",
      "Epoch   6 [  50/10697 (  0.5%)] Loss: 0.029805 L1: 0.017643 Grad: 0.121347 Thermal: 0.000559 LR: 9.86e-06\n",
      "Epoch   6 [  50/10697 (  0.5%)] Loss: 0.029805 L1: 0.017643 Grad: 0.121347 Thermal: 0.000559 LR: 9.86e-06\n",
      "Epoch   6 [ 100/10697 (  0.9%)] Loss: 0.026103 L1: 0.015423 Grad: 0.106592 Thermal: 0.000422 LR: 9.86e-06\n",
      "Epoch   6 [ 100/10697 (  0.9%)] Loss: 0.026103 L1: 0.015423 Grad: 0.106592 Thermal: 0.000422 LR: 9.86e-06\n",
      "Epoch   6 [ 150/10697 (  1.4%)] Loss: 0.020780 L1: 0.012151 Grad: 0.086144 Thermal: 0.000290 LR: 9.86e-06\n",
      "Epoch   6 [ 150/10697 (  1.4%)] Loss: 0.020780 L1: 0.012151 Grad: 0.086144 Thermal: 0.000290 LR: 9.86e-06\n",
      "Epoch   6 [ 200/10697 (  1.9%)] Loss: 0.029413 L1: 0.017040 Grad: 0.123447 Thermal: 0.000573 LR: 9.86e-06\n",
      "Epoch   6 [ 200/10697 (  1.9%)] Loss: 0.029413 L1: 0.017040 Grad: 0.123447 Thermal: 0.000573 LR: 9.86e-06\n",
      "Epoch   6 [ 250/10697 (  2.3%)] Loss: 0.028258 L1: 0.016817 Grad: 0.114150 Thermal: 0.000519 LR: 9.86e-06\n",
      "Epoch   6 [ 250/10697 (  2.3%)] Loss: 0.028258 L1: 0.016817 Grad: 0.114150 Thermal: 0.000519 LR: 9.86e-06\n",
      "Epoch   6 [ 300/10697 (  2.8%)] Loss: 0.023217 L1: 0.013763 Grad: 0.094345 Thermal: 0.000380 LR: 9.86e-06\n",
      "Epoch   6 [ 300/10697 (  2.8%)] Loss: 0.023217 L1: 0.013763 Grad: 0.094345 Thermal: 0.000380 LR: 9.86e-06\n",
      "Epoch   6 [ 350/10697 (  3.3%)] Loss: 0.027559 L1: 0.015707 Grad: 0.118241 Thermal: 0.000547 LR: 9.86e-06\n",
      "Epoch   6 [ 350/10697 (  3.3%)] Loss: 0.027559 L1: 0.015707 Grad: 0.118241 Thermal: 0.000547 LR: 9.86e-06\n",
      "Epoch   6 [ 400/10697 (  3.7%)] Loss: 0.026611 L1: 0.015407 Grad: 0.111812 Thermal: 0.000462 LR: 9.86e-06\n",
      "Epoch   6 [ 400/10697 (  3.7%)] Loss: 0.026611 L1: 0.015407 Grad: 0.111812 Thermal: 0.000462 LR: 9.86e-06\n",
      "Epoch   6 [ 450/10697 (  4.2%)] Loss: 0.027094 L1: 0.015414 Grad: 0.116570 Thermal: 0.000452 LR: 9.86e-06\n",
      "Epoch   6 [ 450/10697 (  4.2%)] Loss: 0.027094 L1: 0.015414 Grad: 0.116570 Thermal: 0.000452 LR: 9.86e-06\n",
      "Epoch   6 [ 500/10697 (  4.7%)] Loss: 0.024135 L1: 0.013977 Grad: 0.101400 Thermal: 0.000360 LR: 9.86e-06\n",
      "Epoch   6 [ 500/10697 (  4.7%)] Loss: 0.024135 L1: 0.013977 Grad: 0.101400 Thermal: 0.000360 LR: 9.86e-06\n",
      "Epoch   6 [ 550/10697 (  5.1%)] Loss: 0.029085 L1: 0.016993 Grad: 0.120670 Thermal: 0.000498 LR: 9.86e-06\n",
      "Epoch   6 [ 550/10697 (  5.1%)] Loss: 0.029085 L1: 0.016993 Grad: 0.120670 Thermal: 0.000498 LR: 9.86e-06\n",
      "Epoch   6 [ 600/10697 (  5.6%)] Loss: 0.026775 L1: 0.015727 Grad: 0.110253 Thermal: 0.000447 LR: 9.86e-06\n",
      "Epoch   6 [ 600/10697 (  5.6%)] Loss: 0.026775 L1: 0.015727 Grad: 0.110253 Thermal: 0.000447 LR: 9.86e-06\n",
      "Epoch   6 [ 650/10697 (  6.1%)] Loss: 0.028726 L1: 0.016730 Grad: 0.119693 Thermal: 0.000544 LR: 9.86e-06\n",
      "Epoch   6 [ 650/10697 (  6.1%)] Loss: 0.028726 L1: 0.016730 Grad: 0.119693 Thermal: 0.000544 LR: 9.86e-06\n",
      "Epoch   6 [ 700/10697 (  6.5%)] Loss: 0.026016 L1: 0.015471 Grad: 0.105191 Thermal: 0.000510 LR: 9.86e-06\n",
      "Epoch   6 [ 700/10697 (  6.5%)] Loss: 0.026016 L1: 0.015471 Grad: 0.105191 Thermal: 0.000510 LR: 9.86e-06\n",
      "Epoch   6 [ 750/10697 (  7.0%)] Loss: 0.033154 L1: 0.019120 Grad: 0.139996 Thermal: 0.000687 LR: 9.86e-06\n",
      "Epoch   6 [ 750/10697 (  7.0%)] Loss: 0.033154 L1: 0.019120 Grad: 0.139996 Thermal: 0.000687 LR: 9.86e-06\n",
      "Epoch   6 [ 800/10697 (  7.5%)] Loss: 0.027706 L1: 0.016363 Grad: 0.113197 Thermal: 0.000473 LR: 9.86e-06\n",
      "Epoch   6 [ 800/10697 (  7.5%)] Loss: 0.027706 L1: 0.016363 Grad: 0.113197 Thermal: 0.000473 LR: 9.86e-06\n",
      "Epoch   6 [ 850/10697 (  7.9%)] Loss: 0.020938 L1: 0.012167 Grad: 0.087537 Thermal: 0.000327 LR: 9.86e-06\n",
      "Epoch   6 [ 850/10697 (  7.9%)] Loss: 0.020938 L1: 0.012167 Grad: 0.087537 Thermal: 0.000327 LR: 9.86e-06\n",
      "Epoch   6 [ 900/10697 (  8.4%)] Loss: 0.028770 L1: 0.016772 Grad: 0.119711 Thermal: 0.000529 LR: 9.86e-06\n",
      "Epoch   6 [ 900/10697 (  8.4%)] Loss: 0.028770 L1: 0.016772 Grad: 0.119711 Thermal: 0.000529 LR: 9.86e-06\n",
      "Epoch   6 [ 950/10697 (  8.9%)] Loss: 0.024253 L1: 0.014184 Grad: 0.100492 Thermal: 0.000390 LR: 9.86e-06\n",
      "Epoch   6 [ 950/10697 (  8.9%)] Loss: 0.024253 L1: 0.014184 Grad: 0.100492 Thermal: 0.000390 LR: 9.86e-06\n",
      "Epoch   6 [1000/10697 (  9.3%)] Loss: 0.036468 L1: 0.020831 Grad: 0.155889 Thermal: 0.000976 LR: 9.86e-06\n",
      "Epoch   6 [1000/10697 (  9.3%)] Loss: 0.036468 L1: 0.020831 Grad: 0.155889 Thermal: 0.000976 LR: 9.86e-06\n",
      "Epoch   6 [1050/10697 (  9.8%)] Loss: 0.027953 L1: 0.016118 Grad: 0.118095 Thermal: 0.000494 LR: 9.86e-06\n",
      "Epoch   6 [1050/10697 (  9.8%)] Loss: 0.027953 L1: 0.016118 Grad: 0.118095 Thermal: 0.000494 LR: 9.86e-06\n",
      "Epoch   6 [1100/10697 ( 10.3%)] Loss: 0.023684 L1: 0.013584 Grad: 0.100829 Thermal: 0.000340 LR: 9.86e-06\n",
      "Epoch   6 [1100/10697 ( 10.3%)] Loss: 0.023684 L1: 0.013584 Grad: 0.100829 Thermal: 0.000340 LR: 9.86e-06\n",
      "Epoch   6 [1150/10697 ( 10.8%)] Loss: 0.019238 L1: 0.010934 Grad: 0.082879 Thermal: 0.000324 LR: 9.86e-06\n",
      "Epoch   6 [1150/10697 ( 10.8%)] Loss: 0.019238 L1: 0.010934 Grad: 0.082879 Thermal: 0.000324 LR: 9.86e-06\n",
      "Epoch   6 [1200/10697 ( 11.2%)] Loss: 0.028167 L1: 0.016357 Grad: 0.117848 Thermal: 0.000511 LR: 9.86e-06\n",
      "Epoch   6 [1200/10697 ( 11.2%)] Loss: 0.028167 L1: 0.016357 Grad: 0.117848 Thermal: 0.000511 LR: 9.86e-06\n",
      "Epoch   6 [1250/10697 ( 11.7%)] Loss: 0.033094 L1: 0.019044 Grad: 0.140180 Thermal: 0.000633 LR: 9.86e-06\n",
      "Epoch   6 [1250/10697 ( 11.7%)] Loss: 0.033094 L1: 0.019044 Grad: 0.140180 Thermal: 0.000633 LR: 9.86e-06\n",
      "Epoch   6 [1300/10697 ( 12.2%)] Loss: 0.035795 L1: 0.020553 Grad: 0.152048 Thermal: 0.000744 LR: 9.86e-06\n",
      "Epoch   6 [1300/10697 ( 12.2%)] Loss: 0.035795 L1: 0.020553 Grad: 0.152048 Thermal: 0.000744 LR: 9.86e-06\n",
      "Epoch   6 [1350/10697 ( 12.6%)] Loss: 0.031239 L1: 0.018300 Grad: 0.129082 Thermal: 0.000608 LR: 9.86e-06\n",
      "Epoch   6 [1350/10697 ( 12.6%)] Loss: 0.031239 L1: 0.018300 Grad: 0.129082 Thermal: 0.000608 LR: 9.86e-06\n",
      "Epoch   6 [1400/10697 ( 13.1%)] Loss: 0.025222 L1: 0.015037 Grad: 0.101636 Thermal: 0.000414 LR: 9.86e-06\n",
      "Epoch   6 [1400/10697 ( 13.1%)] Loss: 0.025222 L1: 0.015037 Grad: 0.101636 Thermal: 0.000414 LR: 9.86e-06\n",
      "Epoch   6 [1450/10697 ( 13.6%)] Loss: 0.026747 L1: 0.015904 Grad: 0.108195 Thermal: 0.000459 LR: 9.86e-06\n",
      "Epoch   6 [1450/10697 ( 13.6%)] Loss: 0.026747 L1: 0.015904 Grad: 0.108195 Thermal: 0.000459 LR: 9.86e-06\n",
      "Epoch   6 [1500/10697 ( 14.0%)] Loss: 0.020987 L1: 0.012160 Grad: 0.088119 Thermal: 0.000319 LR: 9.86e-06\n",
      "Epoch   6 [1500/10697 ( 14.0%)] Loss: 0.020987 L1: 0.012160 Grad: 0.088119 Thermal: 0.000319 LR: 9.86e-06\n",
      "Epoch   6 [1550/10697 ( 14.5%)] Loss: 0.030485 L1: 0.017926 Grad: 0.125280 Thermal: 0.000623 LR: 9.86e-06\n",
      "Epoch   6 [1550/10697 ( 14.5%)] Loss: 0.030485 L1: 0.017926 Grad: 0.125280 Thermal: 0.000623 LR: 9.86e-06\n",
      "Epoch   6 [1600/10697 ( 15.0%)] Loss: 0.022471 L1: 0.013314 Grad: 0.091387 Thermal: 0.000362 LR: 9.86e-06\n",
      "Epoch   6 [1600/10697 ( 15.0%)] Loss: 0.022471 L1: 0.013314 Grad: 0.091387 Thermal: 0.000362 LR: 9.86e-06\n",
      "Epoch   6 [1650/10697 ( 15.4%)] Loss: 0.025143 L1: 0.015000 Grad: 0.101216 Thermal: 0.000429 LR: 9.86e-06\n",
      "Epoch   6 [1650/10697 ( 15.4%)] Loss: 0.025143 L1: 0.015000 Grad: 0.101216 Thermal: 0.000429 LR: 9.86e-06\n",
      "Epoch   6 [1700/10697 ( 15.9%)] Loss: 0.023204 L1: 0.013439 Grad: 0.097465 Thermal: 0.000362 LR: 9.86e-06\n",
      "Epoch   6 [1700/10697 ( 15.9%)] Loss: 0.023204 L1: 0.013439 Grad: 0.097465 Thermal: 0.000362 LR: 9.86e-06\n",
      "Epoch   6 [1750/10697 ( 16.4%)] Loss: 0.019632 L1: 0.011349 Grad: 0.082693 Thermal: 0.000275 LR: 9.86e-06\n",
      "Epoch   6 [1750/10697 ( 16.4%)] Loss: 0.019632 L1: 0.011349 Grad: 0.082693 Thermal: 0.000275 LR: 9.86e-06\n",
      "Epoch   6 [1800/10697 ( 16.8%)] Loss: 0.023293 L1: 0.013518 Grad: 0.097571 Thermal: 0.000352 LR: 9.86e-06\n",
      "Epoch   6 [1800/10697 ( 16.8%)] Loss: 0.023293 L1: 0.013518 Grad: 0.097571 Thermal: 0.000352 LR: 9.86e-06\n",
      "Epoch   6 [1850/10697 ( 17.3%)] Loss: 0.033889 L1: 0.019506 Grad: 0.143500 Thermal: 0.000669 LR: 9.86e-06\n",
      "Epoch   6 [1850/10697 ( 17.3%)] Loss: 0.033889 L1: 0.019506 Grad: 0.143500 Thermal: 0.000669 LR: 9.86e-06\n",
      "Epoch   6 [1900/10697 ( 17.8%)] Loss: 0.034273 L1: 0.019685 Grad: 0.145519 Thermal: 0.000725 LR: 9.86e-06\n",
      "Epoch   6 [1900/10697 ( 17.8%)] Loss: 0.034273 L1: 0.019685 Grad: 0.145519 Thermal: 0.000725 LR: 9.86e-06\n",
      "Epoch   6 [1950/10697 ( 18.2%)] Loss: 0.033751 L1: 0.019973 Grad: 0.137421 Thermal: 0.000710 LR: 9.86e-06\n",
      "Epoch   6 [1950/10697 ( 18.2%)] Loss: 0.033751 L1: 0.019973 Grad: 0.137421 Thermal: 0.000710 LR: 9.86e-06\n",
      "Epoch   6 [2000/10697 ( 18.7%)] Loss: 0.029091 L1: 0.017271 Grad: 0.117933 Thermal: 0.000525 LR: 9.86e-06\n",
      "Epoch   6 [2000/10697 ( 18.7%)] Loss: 0.029091 L1: 0.017271 Grad: 0.117933 Thermal: 0.000525 LR: 9.86e-06\n",
      "Epoch   6 [2050/10697 ( 19.2%)] Loss: 0.022813 L1: 0.013203 Grad: 0.095923 Thermal: 0.000355 LR: 9.86e-06\n",
      "Epoch   6 [2050/10697 ( 19.2%)] Loss: 0.022813 L1: 0.013203 Grad: 0.095923 Thermal: 0.000355 LR: 9.86e-06\n",
      "Epoch   6 [2100/10697 ( 19.6%)] Loss: 0.031311 L1: 0.018062 Grad: 0.132171 Thermal: 0.000642 LR: 9.86e-06\n",
      "Epoch   6 [2100/10697 ( 19.6%)] Loss: 0.031311 L1: 0.018062 Grad: 0.132171 Thermal: 0.000642 LR: 9.86e-06\n",
      "Epoch   6 [2150/10697 ( 20.1%)] Loss: 0.031568 L1: 0.018178 Grad: 0.133595 Thermal: 0.000604 LR: 9.86e-06\n",
      "Epoch   6 [2150/10697 ( 20.1%)] Loss: 0.031568 L1: 0.018178 Grad: 0.133595 Thermal: 0.000604 LR: 9.86e-06\n",
      "Epoch   6 [2200/10697 ( 20.6%)] Loss: 0.031989 L1: 0.018691 Grad: 0.132685 Thermal: 0.000594 LR: 9.86e-06\n",
      "Epoch   6 [2200/10697 ( 20.6%)] Loss: 0.031989 L1: 0.018691 Grad: 0.132685 Thermal: 0.000594 LR: 9.86e-06\n",
      "Epoch   6 [2250/10697 ( 21.0%)] Loss: 0.029003 L1: 0.016519 Grad: 0.124606 Thermal: 0.000460 LR: 9.86e-06\n",
      "Epoch   6 [2250/10697 ( 21.0%)] Loss: 0.029003 L1: 0.016519 Grad: 0.124606 Thermal: 0.000460 LR: 9.86e-06\n",
      "Epoch   6 [2300/10697 ( 21.5%)] Loss: 0.024940 L1: 0.014726 Grad: 0.101924 Thermal: 0.000447 LR: 9.86e-06\n",
      "Epoch   6 [2300/10697 ( 21.5%)] Loss: 0.024940 L1: 0.014726 Grad: 0.101924 Thermal: 0.000447 LR: 9.86e-06\n",
      "Epoch   6 [2350/10697 ( 22.0%)] Loss: 0.023393 L1: 0.013577 Grad: 0.097993 Thermal: 0.000321 LR: 9.86e-06\n",
      "Epoch   6 [2350/10697 ( 22.0%)] Loss: 0.023393 L1: 0.013577 Grad: 0.097993 Thermal: 0.000321 LR: 9.86e-06\n",
      "Epoch   6 [2400/10697 ( 22.4%)] Loss: 0.029398 L1: 0.017357 Grad: 0.120139 Thermal: 0.000546 LR: 9.86e-06\n",
      "Epoch   6 [2400/10697 ( 22.4%)] Loss: 0.029398 L1: 0.017357 Grad: 0.120139 Thermal: 0.000546 LR: 9.86e-06\n",
      "Epoch   6 [2450/10697 ( 22.9%)] Loss: 0.027523 L1: 0.016083 Grad: 0.114129 Thermal: 0.000534 LR: 9.86e-06\n",
      "Epoch   6 [2450/10697 ( 22.9%)] Loss: 0.027523 L1: 0.016083 Grad: 0.114129 Thermal: 0.000534 LR: 9.86e-06\n",
      "Epoch   6 [2500/10697 ( 23.4%)] Loss: 0.024822 L1: 0.014379 Grad: 0.104228 Thermal: 0.000398 LR: 9.86e-06\n",
      "Epoch   6 [2500/10697 ( 23.4%)] Loss: 0.024822 L1: 0.014379 Grad: 0.104228 Thermal: 0.000398 LR: 9.86e-06\n",
      "Epoch   6 [2550/10697 ( 23.8%)] Loss: 0.028075 L1: 0.016234 Grad: 0.118157 Thermal: 0.000512 LR: 9.86e-06\n",
      "Epoch   6 [2550/10697 ( 23.8%)] Loss: 0.028075 L1: 0.016234 Grad: 0.118157 Thermal: 0.000512 LR: 9.86e-06\n",
      "Epoch   6 [2600/10697 ( 24.3%)] Loss: 0.029382 L1: 0.017183 Grad: 0.121712 Thermal: 0.000567 LR: 9.86e-06\n",
      "Epoch   6 [2600/10697 ( 24.3%)] Loss: 0.029382 L1: 0.017183 Grad: 0.121712 Thermal: 0.000567 LR: 9.86e-06\n",
      "Epoch   6 [2650/10697 ( 24.8%)] Loss: 0.025854 L1: 0.014784 Grad: 0.110497 Thermal: 0.000406 LR: 9.86e-06\n",
      "Epoch   6 [2650/10697 ( 24.8%)] Loss: 0.025854 L1: 0.014784 Grad: 0.110497 Thermal: 0.000406 LR: 9.86e-06\n",
      "Epoch   6 [2700/10697 ( 25.2%)] Loss: 0.024934 L1: 0.014771 Grad: 0.101430 Thermal: 0.000398 LR: 9.86e-06\n",
      "Epoch   6 [2700/10697 ( 25.2%)] Loss: 0.024934 L1: 0.014771 Grad: 0.101430 Thermal: 0.000398 LR: 9.86e-06\n",
      "Epoch   6 [2750/10697 ( 25.7%)] Loss: 0.026162 L1: 0.014964 Grad: 0.111768 Thermal: 0.000425 LR: 9.86e-06\n",
      "Epoch   6 [2750/10697 ( 25.7%)] Loss: 0.026162 L1: 0.014964 Grad: 0.111768 Thermal: 0.000425 LR: 9.86e-06\n",
      "Epoch   6 [2800/10697 ( 26.2%)] Loss: 0.024847 L1: 0.014180 Grad: 0.106465 Thermal: 0.000403 LR: 9.86e-06\n",
      "Epoch   6 [2800/10697 ( 26.2%)] Loss: 0.024847 L1: 0.014180 Grad: 0.106465 Thermal: 0.000403 LR: 9.86e-06\n",
      "Epoch   6 [2850/10697 ( 26.6%)] Loss: 0.028224 L1: 0.016659 Grad: 0.115374 Thermal: 0.000549 LR: 9.86e-06\n",
      "Epoch   6 [2850/10697 ( 26.6%)] Loss: 0.028224 L1: 0.016659 Grad: 0.115374 Thermal: 0.000549 LR: 9.86e-06\n",
      "Epoch   6 [2900/10697 ( 27.1%)] Loss: 0.033416 L1: 0.019420 Grad: 0.139610 Thermal: 0.000702 LR: 9.86e-06\n",
      "Epoch   6 [2900/10697 ( 27.1%)] Loss: 0.033416 L1: 0.019420 Grad: 0.139610 Thermal: 0.000702 LR: 9.86e-06\n",
      "Epoch   6 [2950/10697 ( 27.6%)] Loss: 0.033525 L1: 0.019760 Grad: 0.137293 Thermal: 0.000710 LR: 9.86e-06\n",
      "Epoch   6 [2950/10697 ( 27.6%)] Loss: 0.033525 L1: 0.019760 Grad: 0.137293 Thermal: 0.000710 LR: 9.86e-06\n",
      "Epoch   6 [3000/10697 ( 28.0%)] Loss: 0.027639 L1: 0.016347 Grad: 0.112661 Thermal: 0.000504 LR: 9.86e-06\n",
      "Epoch   6 [3000/10697 ( 28.0%)] Loss: 0.027639 L1: 0.016347 Grad: 0.112661 Thermal: 0.000504 LR: 9.86e-06\n",
      "Epoch   6 [3050/10697 ( 28.5%)] Loss: 0.032372 L1: 0.018842 Grad: 0.134989 Thermal: 0.000629 LR: 9.86e-06\n",
      "Epoch   6 [3050/10697 ( 28.5%)] Loss: 0.032372 L1: 0.018842 Grad: 0.134989 Thermal: 0.000629 LR: 9.86e-06\n",
      "Epoch   6 [3100/10697 ( 29.0%)] Loss: 0.023341 L1: 0.013374 Grad: 0.099494 Thermal: 0.000354 LR: 9.86e-06\n",
      "Epoch   6 [3100/10697 ( 29.0%)] Loss: 0.023341 L1: 0.013374 Grad: 0.099494 Thermal: 0.000354 LR: 9.86e-06\n",
      "Epoch   6 [3150/10697 ( 29.4%)] Loss: 0.021137 L1: 0.012126 Grad: 0.089962 Thermal: 0.000308 LR: 9.86e-06\n",
      "Epoch   6 [3150/10697 ( 29.4%)] Loss: 0.021137 L1: 0.012126 Grad: 0.089962 Thermal: 0.000308 LR: 9.86e-06\n",
      "Epoch   6 [3200/10697 ( 29.9%)] Loss: 0.027328 L1: 0.015686 Grad: 0.116155 Thermal: 0.000528 LR: 9.86e-06\n",
      "Epoch   6 [3200/10697 ( 29.9%)] Loss: 0.027328 L1: 0.015686 Grad: 0.116155 Thermal: 0.000528 LR: 9.86e-06\n",
      "Epoch   6 [3250/10697 ( 30.4%)] Loss: 0.026104 L1: 0.015171 Grad: 0.109126 Thermal: 0.000415 LR: 9.86e-06\n",
      "Epoch   6 [3250/10697 ( 30.4%)] Loss: 0.026104 L1: 0.015171 Grad: 0.109126 Thermal: 0.000415 LR: 9.86e-06\n",
      "Epoch   6 [3300/10697 ( 30.8%)] Loss: 0.023718 L1: 0.014204 Grad: 0.094942 Thermal: 0.000399 LR: 9.86e-06\n",
      "Epoch   6 [3300/10697 ( 30.8%)] Loss: 0.023718 L1: 0.014204 Grad: 0.094942 Thermal: 0.000399 LR: 9.86e-06\n",
      "Epoch   6 [3350/10697 ( 31.3%)] Loss: 0.021194 L1: 0.012133 Grad: 0.090458 Thermal: 0.000299 LR: 9.86e-06\n",
      "Epoch   6 [3350/10697 ( 31.3%)] Loss: 0.021194 L1: 0.012133 Grad: 0.090458 Thermal: 0.000299 LR: 9.86e-06\n",
      "Epoch   6 [3400/10697 ( 31.8%)] Loss: 0.032139 L1: 0.018408 Grad: 0.136987 Thermal: 0.000651 LR: 9.86e-06\n",
      "Epoch   6 [3400/10697 ( 31.8%)] Loss: 0.032139 L1: 0.018408 Grad: 0.136987 Thermal: 0.000651 LR: 9.86e-06\n",
      "Epoch   6 [3450/10697 ( 32.3%)] Loss: 0.026702 L1: 0.015221 Grad: 0.114527 Thermal: 0.000564 LR: 9.86e-06\n",
      "Epoch   6 [3450/10697 ( 32.3%)] Loss: 0.026702 L1: 0.015221 Grad: 0.114527 Thermal: 0.000564 LR: 9.86e-06\n",
      "Epoch   6 [3500/10697 ( 32.7%)] Loss: 0.026140 L1: 0.014903 Grad: 0.112124 Thermal: 0.000496 LR: 9.86e-06\n",
      "Epoch   6 [3500/10697 ( 32.7%)] Loss: 0.026140 L1: 0.014903 Grad: 0.112124 Thermal: 0.000496 LR: 9.86e-06\n",
      "Epoch   6 [3550/10697 ( 33.2%)] Loss: 0.026632 L1: 0.015197 Grad: 0.114126 Thermal: 0.000447 LR: 9.86e-06\n",
      "Epoch   6 [3550/10697 ( 33.2%)] Loss: 0.026632 L1: 0.015197 Grad: 0.114126 Thermal: 0.000447 LR: 9.86e-06\n",
      "Epoch   6 [3600/10697 ( 33.7%)] Loss: 0.018032 L1: 0.010436 Grad: 0.075851 Thermal: 0.000221 LR: 9.86e-06\n",
      "Epoch   6 [3600/10697 ( 33.7%)] Loss: 0.018032 L1: 0.010436 Grad: 0.075851 Thermal: 0.000221 LR: 9.86e-06\n",
      "Epoch   6 [3650/10697 ( 34.1%)] Loss: 0.026691 L1: 0.015553 Grad: 0.111165 Thermal: 0.000437 LR: 9.86e-06\n",
      "Epoch   6 [3650/10697 ( 34.1%)] Loss: 0.026691 L1: 0.015553 Grad: 0.111165 Thermal: 0.000437 LR: 9.86e-06\n",
      "Epoch   6 [3700/10697 ( 34.6%)] Loss: 0.026073 L1: 0.014994 Grad: 0.110582 Thermal: 0.000413 LR: 9.86e-06\n",
      "Epoch   6 [3700/10697 ( 34.6%)] Loss: 0.026073 L1: 0.014994 Grad: 0.110582 Thermal: 0.000413 LR: 9.86e-06\n",
      "Epoch   6 [3750/10697 ( 35.1%)] Loss: 0.020590 L1: 0.011778 Grad: 0.087957 Thermal: 0.000316 LR: 9.86e-06\n",
      "Epoch   6 [3750/10697 ( 35.1%)] Loss: 0.020590 L1: 0.011778 Grad: 0.087957 Thermal: 0.000316 LR: 9.86e-06\n",
      "Epoch   6 [3800/10697 ( 35.5%)] Loss: 0.027063 L1: 0.015823 Grad: 0.112162 Thermal: 0.000474 LR: 9.86e-06\n",
      "Epoch   6 [3800/10697 ( 35.5%)] Loss: 0.027063 L1: 0.015823 Grad: 0.112162 Thermal: 0.000474 LR: 9.86e-06\n",
      "Epoch   6 [3850/10697 ( 36.0%)] Loss: 0.032837 L1: 0.018652 Grad: 0.141538 Thermal: 0.000623 LR: 9.86e-06\n",
      "Epoch   6 [3850/10697 ( 36.0%)] Loss: 0.032837 L1: 0.018652 Grad: 0.141538 Thermal: 0.000623 LR: 9.86e-06\n",
      "Epoch   6 [3900/10697 ( 36.5%)] Loss: 0.019599 L1: 0.011279 Grad: 0.083069 Thermal: 0.000263 LR: 9.86e-06\n",
      "Epoch   6 [3900/10697 ( 36.5%)] Loss: 0.019599 L1: 0.011279 Grad: 0.083069 Thermal: 0.000263 LR: 9.86e-06\n",
      "Epoch   6 [3950/10697 ( 36.9%)] Loss: 0.027121 L1: 0.015620 Grad: 0.114776 Thermal: 0.000456 LR: 9.86e-06\n",
      "Epoch   6 [3950/10697 ( 36.9%)] Loss: 0.027121 L1: 0.015620 Grad: 0.114776 Thermal: 0.000456 LR: 9.86e-06\n",
      "Epoch   6 [4000/10697 ( 37.4%)] Loss: 0.026538 L1: 0.015983 Grad: 0.105331 Thermal: 0.000444 LR: 9.86e-06\n",
      "Epoch   6 [4000/10697 ( 37.4%)] Loss: 0.026538 L1: 0.015983 Grad: 0.105331 Thermal: 0.000444 LR: 9.86e-06\n",
      "Epoch   6 [4050/10697 ( 37.9%)] Loss: 0.024732 L1: 0.014509 Grad: 0.102030 Thermal: 0.000406 LR: 9.86e-06\n",
      "Epoch   6 [4050/10697 ( 37.9%)] Loss: 0.024732 L1: 0.014509 Grad: 0.102030 Thermal: 0.000406 LR: 9.86e-06\n",
      "Epoch   6 [4100/10697 ( 38.3%)] Loss: 0.028929 L1: 0.017081 Grad: 0.118226 Thermal: 0.000500 LR: 9.86e-06\n",
      "Epoch   6 [4100/10697 ( 38.3%)] Loss: 0.028929 L1: 0.017081 Grad: 0.118226 Thermal: 0.000500 LR: 9.86e-06\n",
      "Epoch   6 [4150/10697 ( 38.8%)] Loss: 0.027326 L1: 0.016243 Grad: 0.110595 Thermal: 0.000477 LR: 9.86e-06\n",
      "Epoch   6 [4150/10697 ( 38.8%)] Loss: 0.027326 L1: 0.016243 Grad: 0.110595 Thermal: 0.000477 LR: 9.86e-06\n",
      "Epoch   6 [4200/10697 ( 39.3%)] Loss: 0.028182 L1: 0.016212 Grad: 0.119443 Thermal: 0.000517 LR: 9.86e-06\n",
      "Epoch   6 [4200/10697 ( 39.3%)] Loss: 0.028182 L1: 0.016212 Grad: 0.119443 Thermal: 0.000517 LR: 9.86e-06\n",
      "Epoch   6 [4250/10697 ( 39.7%)] Loss: 0.025424 L1: 0.014928 Grad: 0.104760 Thermal: 0.000392 LR: 9.86e-06\n",
      "Epoch   6 [4250/10697 ( 39.7%)] Loss: 0.025424 L1: 0.014928 Grad: 0.104760 Thermal: 0.000392 LR: 9.86e-06\n",
      "Epoch   6 [4300/10697 ( 40.2%)] Loss: 0.027466 L1: 0.016076 Grad: 0.113660 Thermal: 0.000473 LR: 9.86e-06\n",
      "Epoch   6 [4300/10697 ( 40.2%)] Loss: 0.027466 L1: 0.016076 Grad: 0.113660 Thermal: 0.000473 LR: 9.86e-06\n",
      "Epoch   6 [4350/10697 ( 40.7%)] Loss: 0.032460 L1: 0.018663 Grad: 0.137672 Thermal: 0.000589 LR: 9.86e-06\n",
      "Epoch   6 [4350/10697 ( 40.7%)] Loss: 0.032460 L1: 0.018663 Grad: 0.137672 Thermal: 0.000589 LR: 9.86e-06\n",
      "Epoch   6 [4400/10697 ( 41.1%)] Loss: 0.024882 L1: 0.014659 Grad: 0.102029 Thermal: 0.000403 LR: 9.86e-06\n",
      "Epoch   6 [4400/10697 ( 41.1%)] Loss: 0.024882 L1: 0.014659 Grad: 0.102029 Thermal: 0.000403 LR: 9.86e-06\n",
      "Epoch   6 [4450/10697 ( 41.6%)] Loss: 0.025960 L1: 0.015358 Grad: 0.105794 Thermal: 0.000455 LR: 9.86e-06\n",
      "Epoch   6 [4450/10697 ( 41.6%)] Loss: 0.025960 L1: 0.015358 Grad: 0.105794 Thermal: 0.000455 LR: 9.86e-06\n",
      "Epoch   6 [4500/10697 ( 42.1%)] Loss: 0.031003 L1: 0.017756 Grad: 0.132174 Thermal: 0.000598 LR: 9.86e-06\n",
      "Epoch   6 [4500/10697 ( 42.1%)] Loss: 0.031003 L1: 0.017756 Grad: 0.132174 Thermal: 0.000598 LR: 9.86e-06\n",
      "Epoch   6 [4550/10697 ( 42.5%)] Loss: 0.030842 L1: 0.018137 Grad: 0.126768 Thermal: 0.000570 LR: 9.86e-06\n",
      "Epoch   6 [4550/10697 ( 42.5%)] Loss: 0.030842 L1: 0.018137 Grad: 0.126768 Thermal: 0.000570 LR: 9.86e-06\n",
      "Epoch   6 [4600/10697 ( 43.0%)] Loss: 0.027044 L1: 0.015650 Grad: 0.113702 Thermal: 0.000493 LR: 9.86e-06\n",
      "Epoch   6 [4600/10697 ( 43.0%)] Loss: 0.027044 L1: 0.015650 Grad: 0.113702 Thermal: 0.000493 LR: 9.86e-06\n",
      "Epoch   6 [4650/10697 ( 43.5%)] Loss: 0.023791 L1: 0.013376 Grad: 0.103970 Thermal: 0.000355 LR: 9.86e-06\n",
      "Epoch   6 [4650/10697 ( 43.5%)] Loss: 0.023791 L1: 0.013376 Grad: 0.103970 Thermal: 0.000355 LR: 9.86e-06\n",
      "Epoch   6 [4700/10697 ( 43.9%)] Loss: 0.028887 L1: 0.016749 Grad: 0.121130 Thermal: 0.000497 LR: 9.86e-06\n",
      "Epoch   6 [4700/10697 ( 43.9%)] Loss: 0.028887 L1: 0.016749 Grad: 0.121130 Thermal: 0.000497 LR: 9.86e-06\n",
      "Epoch   6 [4750/10697 ( 44.4%)] Loss: 0.023333 L1: 0.013515 Grad: 0.097997 Thermal: 0.000362 LR: 9.86e-06\n",
      "Epoch   6 [4750/10697 ( 44.4%)] Loss: 0.023333 L1: 0.013515 Grad: 0.097997 Thermal: 0.000362 LR: 9.86e-06\n",
      "Epoch   6 [4800/10697 ( 44.9%)] Loss: 0.027015 L1: 0.016192 Grad: 0.107989 Thermal: 0.000472 LR: 9.86e-06\n",
      "Epoch   6 [4800/10697 ( 44.9%)] Loss: 0.027015 L1: 0.016192 Grad: 0.107989 Thermal: 0.000472 LR: 9.86e-06\n",
      "Epoch   6 [4850/10697 ( 45.3%)] Loss: 0.030653 L1: 0.017652 Grad: 0.129744 Thermal: 0.000529 LR: 9.86e-06\n",
      "Epoch   6 [4850/10697 ( 45.3%)] Loss: 0.030653 L1: 0.017652 Grad: 0.129744 Thermal: 0.000529 LR: 9.86e-06\n",
      "Epoch   6 [4900/10697 ( 45.8%)] Loss: 0.030014 L1: 0.017414 Grad: 0.125727 Thermal: 0.000550 LR: 9.86e-06\n",
      "Epoch   6 [4900/10697 ( 45.8%)] Loss: 0.030014 L1: 0.017414 Grad: 0.125727 Thermal: 0.000550 LR: 9.86e-06\n",
      "Epoch   6 [4950/10697 ( 46.3%)] Loss: 0.032631 L1: 0.019174 Grad: 0.134239 Thermal: 0.000657 LR: 9.86e-06\n",
      "Epoch   6 [4950/10697 ( 46.3%)] Loss: 0.032631 L1: 0.019174 Grad: 0.134239 Thermal: 0.000657 LR: 9.86e-06\n",
      "Epoch   6 [5000/10697 ( 46.7%)] Loss: 0.021587 L1: 0.012797 Grad: 0.087735 Thermal: 0.000342 LR: 9.86e-06\n",
      "Epoch   6 [5000/10697 ( 46.7%)] Loss: 0.021587 L1: 0.012797 Grad: 0.087735 Thermal: 0.000342 LR: 9.86e-06\n",
      "Epoch   6 [5050/10697 ( 47.2%)] Loss: 0.032690 L1: 0.019045 Grad: 0.136122 Thermal: 0.000662 LR: 9.86e-06\n",
      "Epoch   6 [5050/10697 ( 47.2%)] Loss: 0.032690 L1: 0.019045 Grad: 0.136122 Thermal: 0.000662 LR: 9.86e-06\n",
      "Epoch   6 [5100/10697 ( 47.7%)] Loss: 0.034950 L1: 0.020141 Grad: 0.147713 Thermal: 0.000752 LR: 9.86e-06\n",
      "Epoch   6 [5100/10697 ( 47.7%)] Loss: 0.034950 L1: 0.020141 Grad: 0.147713 Thermal: 0.000752 LR: 9.86e-06\n",
      "Epoch   6 [5150/10697 ( 48.1%)] Loss: 0.029857 L1: 0.017157 Grad: 0.126703 Thermal: 0.000584 LR: 9.86e-06\n",
      "Epoch   6 [5150/10697 ( 48.1%)] Loss: 0.029857 L1: 0.017157 Grad: 0.126703 Thermal: 0.000584 LR: 9.86e-06\n",
      "Epoch   6 [5200/10697 ( 48.6%)] Loss: 0.029011 L1: 0.016578 Grad: 0.124067 Thermal: 0.000527 LR: 9.86e-06\n",
      "Epoch   6 [5200/10697 ( 48.6%)] Loss: 0.029011 L1: 0.016578 Grad: 0.124067 Thermal: 0.000527 LR: 9.86e-06\n",
      "Epoch   6 [5250/10697 ( 49.1%)] Loss: 0.031444 L1: 0.018193 Grad: 0.132190 Thermal: 0.000630 LR: 9.86e-06\n",
      "Epoch   6 [5250/10697 ( 49.1%)] Loss: 0.031444 L1: 0.018193 Grad: 0.132190 Thermal: 0.000630 LR: 9.86e-06\n",
      "Epoch   6 [5300/10697 ( 49.5%)] Loss: 0.034849 L1: 0.020197 Grad: 0.146154 Thermal: 0.000750 LR: 9.86e-06\n",
      "Epoch   6 [5300/10697 ( 49.5%)] Loss: 0.034849 L1: 0.020197 Grad: 0.146154 Thermal: 0.000750 LR: 9.86e-06\n",
      "Epoch   6 [5350/10697 ( 50.0%)] Loss: 0.025894 L1: 0.015173 Grad: 0.106981 Thermal: 0.000452 LR: 9.86e-06\n",
      "Epoch   6 [5350/10697 ( 50.0%)] Loss: 0.025894 L1: 0.015173 Grad: 0.106981 Thermal: 0.000452 LR: 9.86e-06\n",
      "Epoch   6 [5400/10697 ( 50.5%)] Loss: 0.023932 L1: 0.013828 Grad: 0.100838 Thermal: 0.000402 LR: 9.86e-06\n",
      "Epoch   6 [5400/10697 ( 50.5%)] Loss: 0.023932 L1: 0.013828 Grad: 0.100838 Thermal: 0.000402 LR: 9.86e-06\n",
      "Epoch   6 [5450/10697 ( 50.9%)] Loss: 0.018176 L1: 0.010459 Grad: 0.077059 Thermal: 0.000227 LR: 9.86e-06\n",
      "Epoch   6 [5450/10697 ( 50.9%)] Loss: 0.018176 L1: 0.010459 Grad: 0.077059 Thermal: 0.000227 LR: 9.86e-06\n",
      "Epoch   6 [5500/10697 ( 51.4%)] Loss: 0.028302 L1: 0.016226 Grad: 0.120529 Thermal: 0.000447 LR: 9.86e-06\n",
      "Epoch   6 [5500/10697 ( 51.4%)] Loss: 0.028302 L1: 0.016226 Grad: 0.120529 Thermal: 0.000447 LR: 9.86e-06\n",
      "Epoch   6 [5550/10697 ( 51.9%)] Loss: 0.032064 L1: 0.018911 Grad: 0.131212 Thermal: 0.000641 LR: 9.86e-06\n",
      "Epoch   6 [5550/10697 ( 51.9%)] Loss: 0.032064 L1: 0.018911 Grad: 0.131212 Thermal: 0.000641 LR: 9.86e-06\n",
      "Epoch   6 [5600/10697 ( 52.4%)] Loss: 0.031602 L1: 0.018174 Grad: 0.133940 Thermal: 0.000690 LR: 9.86e-06\n",
      "Epoch   6 [5600/10697 ( 52.4%)] Loss: 0.031602 L1: 0.018174 Grad: 0.133940 Thermal: 0.000690 LR: 9.86e-06\n",
      "Epoch   6 [5650/10697 ( 52.8%)] Loss: 0.032850 L1: 0.018978 Grad: 0.138388 Thermal: 0.000660 LR: 9.86e-06\n",
      "Epoch   6 [5650/10697 ( 52.8%)] Loss: 0.032850 L1: 0.018978 Grad: 0.138388 Thermal: 0.000660 LR: 9.86e-06\n",
      "Epoch   6 [5700/10697 ( 53.3%)] Loss: 0.030769 L1: 0.017601 Grad: 0.131401 Thermal: 0.000552 LR: 9.86e-06\n",
      "Epoch   6 [5700/10697 ( 53.3%)] Loss: 0.030769 L1: 0.017601 Grad: 0.131401 Thermal: 0.000552 LR: 9.86e-06\n",
      "Epoch   6 [5750/10697 ( 53.8%)] Loss: 0.028915 L1: 0.016739 Grad: 0.121455 Thermal: 0.000621 LR: 9.86e-06\n",
      "Epoch   6 [5750/10697 ( 53.8%)] Loss: 0.028915 L1: 0.016739 Grad: 0.121455 Thermal: 0.000621 LR: 9.86e-06\n",
      "Epoch   6 [5800/10697 ( 54.2%)] Loss: 0.018469 L1: 0.010488 Grad: 0.079685 Thermal: 0.000244 LR: 9.86e-06\n",
      "Epoch   6 [5800/10697 ( 54.2%)] Loss: 0.018469 L1: 0.010488 Grad: 0.079685 Thermal: 0.000244 LR: 9.86e-06\n",
      "Epoch   6 [5850/10697 ( 54.7%)] Loss: 0.024686 L1: 0.014468 Grad: 0.101968 Thermal: 0.000421 LR: 9.86e-06\n",
      "Epoch   6 [5850/10697 ( 54.7%)] Loss: 0.024686 L1: 0.014468 Grad: 0.101968 Thermal: 0.000421 LR: 9.86e-06\n",
      "Epoch   6 [5900/10697 ( 55.2%)] Loss: 0.040593 L1: 0.023074 Grad: 0.174709 Thermal: 0.000972 LR: 9.86e-06\n",
      "Epoch   6 [5900/10697 ( 55.2%)] Loss: 0.040593 L1: 0.023074 Grad: 0.174709 Thermal: 0.000972 LR: 9.86e-06\n",
      "Epoch   6 [5950/10697 ( 55.6%)] Loss: 0.023691 L1: 0.014109 Grad: 0.095608 Thermal: 0.000421 LR: 9.86e-06\n",
      "Epoch   6 [5950/10697 ( 55.6%)] Loss: 0.023691 L1: 0.014109 Grad: 0.095608 Thermal: 0.000421 LR: 9.86e-06\n",
      "Epoch   6 [6000/10697 ( 56.1%)] Loss: 0.025976 L1: 0.015143 Grad: 0.108127 Thermal: 0.000416 LR: 9.86e-06\n",
      "Epoch   6 [6000/10697 ( 56.1%)] Loss: 0.025976 L1: 0.015143 Grad: 0.108127 Thermal: 0.000416 LR: 9.86e-06\n",
      "Epoch   6 [6050/10697 ( 56.6%)] Loss: 0.024675 L1: 0.014432 Grad: 0.102237 Thermal: 0.000379 LR: 9.86e-06\n",
      "Epoch   6 [6050/10697 ( 56.6%)] Loss: 0.024675 L1: 0.014432 Grad: 0.102237 Thermal: 0.000379 LR: 9.86e-06\n",
      "Epoch   6 [6100/10697 ( 57.0%)] Loss: 0.026284 L1: 0.015504 Grad: 0.107554 Thermal: 0.000494 LR: 9.86e-06\n",
      "Epoch   6 [6100/10697 ( 57.0%)] Loss: 0.026284 L1: 0.015504 Grad: 0.107554 Thermal: 0.000494 LR: 9.86e-06\n",
      "Epoch   6 [6150/10697 ( 57.5%)] Loss: 0.018170 L1: 0.010719 Grad: 0.074391 Thermal: 0.000251 LR: 9.86e-06\n",
      "Epoch   6 [6150/10697 ( 57.5%)] Loss: 0.018170 L1: 0.010719 Grad: 0.074391 Thermal: 0.000251 LR: 9.86e-06\n",
      "Epoch   6 [6200/10697 ( 58.0%)] Loss: 0.024111 L1: 0.014301 Grad: 0.097903 Thermal: 0.000401 LR: 9.86e-06\n",
      "Epoch   6 [6200/10697 ( 58.0%)] Loss: 0.024111 L1: 0.014301 Grad: 0.097903 Thermal: 0.000401 LR: 9.86e-06\n",
      "Epoch   6 [6250/10697 ( 58.4%)] Loss: 0.026185 L1: 0.015822 Grad: 0.103403 Thermal: 0.000444 LR: 9.86e-06\n",
      "Epoch   6 [6250/10697 ( 58.4%)] Loss: 0.026185 L1: 0.015822 Grad: 0.103403 Thermal: 0.000444 LR: 9.86e-06\n",
      "Epoch   6 [6300/10697 ( 58.9%)] Loss: 0.021829 L1: 0.012516 Grad: 0.092949 Thermal: 0.000357 LR: 9.86e-06\n",
      "Epoch   6 [6300/10697 ( 58.9%)] Loss: 0.021829 L1: 0.012516 Grad: 0.092949 Thermal: 0.000357 LR: 9.86e-06\n",
      "Epoch   6 [6350/10697 ( 59.4%)] Loss: 0.025486 L1: 0.015368 Grad: 0.100960 Thermal: 0.000434 LR: 9.86e-06\n",
      "Epoch   6 [6350/10697 ( 59.4%)] Loss: 0.025486 L1: 0.015368 Grad: 0.100960 Thermal: 0.000434 LR: 9.86e-06\n",
      "Epoch   6 [6400/10697 ( 59.8%)] Loss: 0.025751 L1: 0.014425 Grad: 0.113048 Thermal: 0.000428 LR: 9.86e-06\n",
      "Epoch   6 [6400/10697 ( 59.8%)] Loss: 0.025751 L1: 0.014425 Grad: 0.113048 Thermal: 0.000428 LR: 9.86e-06\n",
      "Epoch   6 [6450/10697 ( 60.3%)] Loss: 0.028080 L1: 0.016866 Grad: 0.111885 Thermal: 0.000515 LR: 9.86e-06\n",
      "Epoch   6 [6450/10697 ( 60.3%)] Loss: 0.028080 L1: 0.016866 Grad: 0.111885 Thermal: 0.000515 LR: 9.86e-06\n",
      "Epoch   6 [6500/10697 ( 60.8%)] Loss: 0.023494 L1: 0.013688 Grad: 0.097863 Thermal: 0.000394 LR: 9.86e-06\n",
      "Epoch   6 [6500/10697 ( 60.8%)] Loss: 0.023494 L1: 0.013688 Grad: 0.097863 Thermal: 0.000394 LR: 9.86e-06\n",
      "Epoch   6 [6550/10697 ( 61.2%)] Loss: 0.029278 L1: 0.017610 Grad: 0.116405 Thermal: 0.000542 LR: 9.86e-06\n",
      "Epoch   6 [6550/10697 ( 61.2%)] Loss: 0.029278 L1: 0.017610 Grad: 0.116405 Thermal: 0.000542 LR: 9.86e-06\n",
      "Epoch   6 [6600/10697 ( 61.7%)] Loss: 0.023461 L1: 0.013490 Grad: 0.099494 Thermal: 0.000426 LR: 9.86e-06\n",
      "Epoch   6 [6600/10697 ( 61.7%)] Loss: 0.023461 L1: 0.013490 Grad: 0.099494 Thermal: 0.000426 LR: 9.86e-06\n",
      "Epoch   6 [6650/10697 ( 62.2%)] Loss: 0.028539 L1: 0.016834 Grad: 0.116792 Thermal: 0.000513 LR: 9.86e-06\n",
      "Epoch   6 [6650/10697 ( 62.2%)] Loss: 0.028539 L1: 0.016834 Grad: 0.116792 Thermal: 0.000513 LR: 9.86e-06\n",
      "Epoch   6 [6700/10697 ( 62.6%)] Loss: 0.023949 L1: 0.014028 Grad: 0.099024 Thermal: 0.000373 LR: 9.86e-06\n",
      "Epoch   6 [6700/10697 ( 62.6%)] Loss: 0.023949 L1: 0.014028 Grad: 0.099024 Thermal: 0.000373 LR: 9.86e-06\n",
      "Epoch   6 [6750/10697 ( 63.1%)] Loss: 0.021598 L1: 0.012446 Grad: 0.091358 Thermal: 0.000326 LR: 9.86e-06\n",
      "Epoch   6 [6750/10697 ( 63.1%)] Loss: 0.021598 L1: 0.012446 Grad: 0.091358 Thermal: 0.000326 LR: 9.86e-06\n",
      "Epoch   6 [6800/10697 ( 63.6%)] Loss: 0.036915 L1: 0.020782 Grad: 0.160943 Thermal: 0.000773 LR: 9.86e-06\n",
      "Epoch   6 [6800/10697 ( 63.6%)] Loss: 0.036915 L1: 0.020782 Grad: 0.160943 Thermal: 0.000773 LR: 9.86e-06\n",
      "Epoch   6 [6850/10697 ( 64.0%)] Loss: 0.026897 L1: 0.015212 Grad: 0.116640 Thermal: 0.000420 LR: 9.86e-06\n",
      "Epoch   6 [6850/10697 ( 64.0%)] Loss: 0.026897 L1: 0.015212 Grad: 0.116640 Thermal: 0.000420 LR: 9.86e-06\n",
      "Epoch   6 [6900/10697 ( 64.5%)] Loss: 0.026816 L1: 0.015547 Grad: 0.112456 Thermal: 0.000487 LR: 9.86e-06\n",
      "Epoch   6 [6900/10697 ( 64.5%)] Loss: 0.026816 L1: 0.015547 Grad: 0.112456 Thermal: 0.000487 LR: 9.86e-06\n",
      "Epoch   6 [6950/10697 ( 65.0%)] Loss: 0.023132 L1: 0.013061 Grad: 0.100537 Thermal: 0.000349 LR: 9.86e-06\n",
      "Epoch   6 [6950/10697 ( 65.0%)] Loss: 0.023132 L1: 0.013061 Grad: 0.100537 Thermal: 0.000349 LR: 9.86e-06\n",
      "Epoch   6 [7000/10697 ( 65.4%)] Loss: 0.021963 L1: 0.012981 Grad: 0.089648 Thermal: 0.000331 LR: 9.86e-06\n",
      "Epoch   6 [7000/10697 ( 65.4%)] Loss: 0.021963 L1: 0.012981 Grad: 0.089648 Thermal: 0.000331 LR: 9.86e-06\n",
      "Epoch   6 [7050/10697 ( 65.9%)] Loss: 0.025370 L1: 0.014600 Grad: 0.107509 Thermal: 0.000393 LR: 9.86e-06\n",
      "Epoch   6 [7050/10697 ( 65.9%)] Loss: 0.025370 L1: 0.014600 Grad: 0.107509 Thermal: 0.000393 LR: 9.86e-06\n",
      "Epoch   6 [7100/10697 ( 66.4%)] Loss: 0.032982 L1: 0.019227 Grad: 0.137210 Thermal: 0.000685 LR: 9.86e-06\n",
      "Epoch   6 [7100/10697 ( 66.4%)] Loss: 0.032982 L1: 0.019227 Grad: 0.137210 Thermal: 0.000685 LR: 9.86e-06\n",
      "Epoch   6 [7150/10697 ( 66.8%)] Loss: 0.025480 L1: 0.014995 Grad: 0.104641 Thermal: 0.000414 LR: 9.86e-06\n",
      "Epoch   6 [7150/10697 ( 66.8%)] Loss: 0.025480 L1: 0.014995 Grad: 0.104641 Thermal: 0.000414 LR: 9.86e-06\n",
      "Epoch   6 [7200/10697 ( 67.3%)] Loss: 0.029134 L1: 0.016800 Grad: 0.123092 Thermal: 0.000491 LR: 9.86e-06\n",
      "Epoch   6 [7200/10697 ( 67.3%)] Loss: 0.029134 L1: 0.016800 Grad: 0.123092 Thermal: 0.000491 LR: 9.86e-06\n",
      "Epoch   6 [7250/10697 ( 67.8%)] Loss: 0.027790 L1: 0.016105 Grad: 0.116595 Thermal: 0.000504 LR: 9.86e-06\n",
      "Epoch   6 [7250/10697 ( 67.8%)] Loss: 0.027790 L1: 0.016105 Grad: 0.116595 Thermal: 0.000504 LR: 9.86e-06\n",
      "Epoch   6 [7300/10697 ( 68.2%)] Loss: 0.024845 L1: 0.014078 Grad: 0.107487 Thermal: 0.000383 LR: 9.86e-06\n",
      "Epoch   6 [7300/10697 ( 68.2%)] Loss: 0.024845 L1: 0.014078 Grad: 0.107487 Thermal: 0.000383 LR: 9.86e-06\n",
      "Epoch   6 [7350/10697 ( 68.7%)] Loss: 0.026679 L1: 0.015664 Grad: 0.109915 Thermal: 0.000471 LR: 9.86e-06\n",
      "Epoch   6 [7350/10697 ( 68.7%)] Loss: 0.026679 L1: 0.015664 Grad: 0.109915 Thermal: 0.000471 LR: 9.86e-06\n",
      "Epoch   6 [7400/10697 ( 69.2%)] Loss: 0.033512 L1: 0.019714 Grad: 0.137623 Thermal: 0.000731 LR: 9.86e-06\n",
      "Epoch   6 [7400/10697 ( 69.2%)] Loss: 0.033512 L1: 0.019714 Grad: 0.137623 Thermal: 0.000731 LR: 9.86e-06\n",
      "Epoch   6 [7450/10697 ( 69.6%)] Loss: 0.019852 L1: 0.011668 Grad: 0.081703 Thermal: 0.000271 LR: 9.86e-06\n",
      "Epoch   6 [7450/10697 ( 69.6%)] Loss: 0.019852 L1: 0.011668 Grad: 0.081703 Thermal: 0.000271 LR: 9.86e-06\n",
      "Epoch   6 [7500/10697 ( 70.1%)] Loss: 0.023810 L1: 0.013745 Grad: 0.100459 Thermal: 0.000394 LR: 9.86e-06\n",
      "Epoch   6 [7500/10697 ( 70.1%)] Loss: 0.023810 L1: 0.013745 Grad: 0.100459 Thermal: 0.000394 LR: 9.86e-06\n",
      "Epoch   6 [7550/10697 ( 70.6%)] Loss: 0.022232 L1: 0.012905 Grad: 0.093109 Thermal: 0.000320 LR: 9.86e-06\n",
      "Epoch   6 [7550/10697 ( 70.6%)] Loss: 0.022232 L1: 0.012905 Grad: 0.093109 Thermal: 0.000320 LR: 9.86e-06\n",
      "Epoch   6 [7600/10697 ( 71.0%)] Loss: 0.023994 L1: 0.014010 Grad: 0.099643 Thermal: 0.000388 LR: 9.86e-06\n",
      "Epoch   6 [7600/10697 ( 71.0%)] Loss: 0.023994 L1: 0.014010 Grad: 0.099643 Thermal: 0.000388 LR: 9.86e-06\n",
      "Epoch   6 [7650/10697 ( 71.5%)] Loss: 0.026500 L1: 0.015822 Grad: 0.106558 Thermal: 0.000439 LR: 9.86e-06\n",
      "Epoch   6 [7650/10697 ( 71.5%)] Loss: 0.026500 L1: 0.015822 Grad: 0.106558 Thermal: 0.000439 LR: 9.86e-06\n",
      "Epoch   6 [7700/10697 ( 72.0%)] Loss: 0.019997 L1: 0.011573 Grad: 0.084091 Thermal: 0.000289 LR: 9.86e-06\n",
      "Epoch   6 [7700/10697 ( 72.0%)] Loss: 0.019997 L1: 0.011573 Grad: 0.084091 Thermal: 0.000289 LR: 9.86e-06\n",
      "Epoch   6 [7750/10697 ( 72.5%)] Loss: 0.031973 L1: 0.018664 Grad: 0.132791 Thermal: 0.000608 LR: 9.86e-06\n",
      "Epoch   6 [7750/10697 ( 72.5%)] Loss: 0.031973 L1: 0.018664 Grad: 0.132791 Thermal: 0.000608 LR: 9.86e-06\n",
      "Epoch   6 [7800/10697 ( 72.9%)] Loss: 0.025912 L1: 0.015209 Grad: 0.106839 Thermal: 0.000382 LR: 9.86e-06\n",
      "Epoch   6 [7800/10697 ( 72.9%)] Loss: 0.025912 L1: 0.015209 Grad: 0.106839 Thermal: 0.000382 LR: 9.86e-06\n",
      "Epoch   6 [7850/10697 ( 73.4%)] Loss: 0.026352 L1: 0.015161 Grad: 0.111682 Thermal: 0.000446 LR: 9.86e-06\n",
      "Epoch   6 [7850/10697 ( 73.4%)] Loss: 0.026352 L1: 0.015161 Grad: 0.111682 Thermal: 0.000446 LR: 9.86e-06\n",
      "Epoch   6 [7900/10697 ( 73.9%)] Loss: 0.027452 L1: 0.016499 Grad: 0.109283 Thermal: 0.000490 LR: 9.86e-06\n",
      "Epoch   6 [7900/10697 ( 73.9%)] Loss: 0.027452 L1: 0.016499 Grad: 0.109283 Thermal: 0.000490 LR: 9.86e-06\n",
      "Epoch   6 [7950/10697 ( 74.3%)] Loss: 0.024408 L1: 0.014093 Grad: 0.102917 Thermal: 0.000455 LR: 9.86e-06\n",
      "Epoch   6 [7950/10697 ( 74.3%)] Loss: 0.024408 L1: 0.014093 Grad: 0.102917 Thermal: 0.000455 LR: 9.86e-06\n",
      "Epoch   6 [8000/10697 ( 74.8%)] Loss: 0.027478 L1: 0.015881 Grad: 0.115747 Thermal: 0.000449 LR: 9.86e-06\n",
      "Epoch   6 [8000/10697 ( 74.8%)] Loss: 0.027478 L1: 0.015881 Grad: 0.115747 Thermal: 0.000449 LR: 9.86e-06\n",
      "Epoch   6 [8050/10697 ( 75.3%)] Loss: 0.028703 L1: 0.017178 Grad: 0.114990 Thermal: 0.000510 LR: 9.86e-06\n",
      "Epoch   6 [8050/10697 ( 75.3%)] Loss: 0.028703 L1: 0.017178 Grad: 0.114990 Thermal: 0.000510 LR: 9.86e-06\n",
      "Epoch   6 [8100/10697 ( 75.7%)] Loss: 0.024978 L1: 0.014856 Grad: 0.101018 Thermal: 0.000416 LR: 9.86e-06\n",
      "Epoch   6 [8100/10697 ( 75.7%)] Loss: 0.024978 L1: 0.014856 Grad: 0.101018 Thermal: 0.000416 LR: 9.86e-06\n",
      "Epoch   6 [8150/10697 ( 76.2%)] Loss: 0.027498 L1: 0.015633 Grad: 0.118420 Thermal: 0.000465 LR: 9.86e-06\n",
      "Epoch   6 [8150/10697 ( 76.2%)] Loss: 0.027498 L1: 0.015633 Grad: 0.118420 Thermal: 0.000465 LR: 9.86e-06\n",
      "Epoch   6 [8200/10697 ( 76.7%)] Loss: 0.030142 L1: 0.017707 Grad: 0.124086 Thermal: 0.000541 LR: 9.86e-06\n",
      "Epoch   6 [8200/10697 ( 76.7%)] Loss: 0.030142 L1: 0.017707 Grad: 0.124086 Thermal: 0.000541 LR: 9.86e-06\n",
      "Epoch   6 [8250/10697 ( 77.1%)] Loss: 0.028025 L1: 0.016269 Grad: 0.117330 Thermal: 0.000467 LR: 9.86e-06\n",
      "Epoch   6 [8250/10697 ( 77.1%)] Loss: 0.028025 L1: 0.016269 Grad: 0.117330 Thermal: 0.000467 LR: 9.86e-06\n",
      "Epoch   6 [8300/10697 ( 77.6%)] Loss: 0.026320 L1: 0.015522 Grad: 0.107768 Thermal: 0.000438 LR: 9.86e-06\n",
      "Epoch   6 [8300/10697 ( 77.6%)] Loss: 0.026320 L1: 0.015522 Grad: 0.107768 Thermal: 0.000438 LR: 9.86e-06\n",
      "Epoch   6 [8350/10697 ( 78.1%)] Loss: 0.030455 L1: 0.017117 Grad: 0.133053 Thermal: 0.000653 LR: 9.86e-06\n",
      "Epoch   6 [8350/10697 ( 78.1%)] Loss: 0.030455 L1: 0.017117 Grad: 0.133053 Thermal: 0.000653 LR: 9.86e-06\n",
      "Epoch   6 [8400/10697 ( 78.5%)] Loss: 0.033295 L1: 0.019594 Grad: 0.136606 Thermal: 0.000800 LR: 9.86e-06\n",
      "Epoch   6 [8400/10697 ( 78.5%)] Loss: 0.033295 L1: 0.019594 Grad: 0.136606 Thermal: 0.000800 LR: 9.86e-06\n",
      "Epoch   6 [8450/10697 ( 79.0%)] Loss: 0.025537 L1: 0.014604 Grad: 0.109124 Thermal: 0.000411 LR: 9.86e-06\n",
      "Epoch   6 [8450/10697 ( 79.0%)] Loss: 0.025537 L1: 0.014604 Grad: 0.109124 Thermal: 0.000411 LR: 9.86e-06\n",
      "Epoch   6 [8500/10697 ( 79.5%)] Loss: 0.027154 L1: 0.015492 Grad: 0.116369 Thermal: 0.000500 LR: 9.86e-06\n",
      "Epoch   6 [8500/10697 ( 79.5%)] Loss: 0.027154 L1: 0.015492 Grad: 0.116369 Thermal: 0.000500 LR: 9.86e-06\n",
      "Epoch   6 [8550/10697 ( 79.9%)] Loss: 0.021889 L1: 0.012712 Grad: 0.091571 Thermal: 0.000398 LR: 9.86e-06\n",
      "Epoch   6 [8550/10697 ( 79.9%)] Loss: 0.021889 L1: 0.012712 Grad: 0.091571 Thermal: 0.000398 LR: 9.86e-06\n",
      "Epoch   6 [8600/10697 ( 80.4%)] Loss: 0.026848 L1: 0.015896 Grad: 0.109290 Thermal: 0.000464 LR: 9.86e-06\n",
      "Epoch   6 [8600/10697 ( 80.4%)] Loss: 0.026848 L1: 0.015896 Grad: 0.109290 Thermal: 0.000464 LR: 9.86e-06\n",
      "Epoch   6 [8650/10697 ( 80.9%)] Loss: 0.027499 L1: 0.016050 Grad: 0.114232 Thermal: 0.000520 LR: 9.86e-06\n",
      "Epoch   6 [8650/10697 ( 80.9%)] Loss: 0.027499 L1: 0.016050 Grad: 0.114232 Thermal: 0.000520 LR: 9.86e-06\n",
      "Epoch   6 [8700/10697 ( 81.3%)] Loss: 0.022634 L1: 0.013087 Grad: 0.095295 Thermal: 0.000343 LR: 9.86e-06\n",
      "Epoch   6 [8700/10697 ( 81.3%)] Loss: 0.022634 L1: 0.013087 Grad: 0.095295 Thermal: 0.000343 LR: 9.86e-06\n",
      "Epoch   6 [8750/10697 ( 81.8%)] Loss: 0.024373 L1: 0.014406 Grad: 0.099459 Thermal: 0.000427 LR: 9.86e-06\n",
      "Epoch   6 [8750/10697 ( 81.8%)] Loss: 0.024373 L1: 0.014406 Grad: 0.099459 Thermal: 0.000427 LR: 9.86e-06\n",
      "Epoch   6 [8800/10697 ( 82.3%)] Loss: 0.032296 L1: 0.018360 Grad: 0.139038 Thermal: 0.000659 LR: 9.86e-06\n",
      "Epoch   6 [8800/10697 ( 82.3%)] Loss: 0.032296 L1: 0.018360 Grad: 0.139038 Thermal: 0.000659 LR: 9.86e-06\n",
      "Epoch   6 [8850/10697 ( 82.7%)] Loss: 0.024828 L1: 0.014337 Grad: 0.104711 Thermal: 0.000402 LR: 9.86e-06\n",
      "Epoch   6 [8850/10697 ( 82.7%)] Loss: 0.024828 L1: 0.014337 Grad: 0.104711 Thermal: 0.000402 LR: 9.86e-06\n",
      "Epoch   6 [8900/10697 ( 83.2%)] Loss: 0.026797 L1: 0.015511 Grad: 0.112619 Thermal: 0.000481 LR: 9.86e-06\n",
      "Epoch   6 [8900/10697 ( 83.2%)] Loss: 0.026797 L1: 0.015511 Grad: 0.112619 Thermal: 0.000481 LR: 9.86e-06\n",
      "Epoch   6 [8950/10697 ( 83.7%)] Loss: 0.027584 L1: 0.016140 Grad: 0.114197 Thermal: 0.000485 LR: 9.86e-06\n",
      "Epoch   6 [8950/10697 ( 83.7%)] Loss: 0.027584 L1: 0.016140 Grad: 0.114197 Thermal: 0.000485 LR: 9.86e-06\n",
      "Epoch   6 [9000/10697 ( 84.1%)] Loss: 0.025857 L1: 0.014821 Grad: 0.110164 Thermal: 0.000387 LR: 9.86e-06\n",
      "Epoch   6 [9000/10697 ( 84.1%)] Loss: 0.025857 L1: 0.014821 Grad: 0.110164 Thermal: 0.000387 LR: 9.86e-06\n",
      "Epoch   6 [9050/10697 ( 84.6%)] Loss: 0.022129 L1: 0.012733 Grad: 0.093795 Thermal: 0.000344 LR: 9.86e-06\n",
      "Epoch   6 [9050/10697 ( 84.6%)] Loss: 0.022129 L1: 0.012733 Grad: 0.093795 Thermal: 0.000344 LR: 9.86e-06\n",
      "Epoch   6 [9100/10697 ( 85.1%)] Loss: 0.023874 L1: 0.014004 Grad: 0.098516 Thermal: 0.000369 LR: 9.86e-06\n",
      "Epoch   6 [9100/10697 ( 85.1%)] Loss: 0.023874 L1: 0.014004 Grad: 0.098516 Thermal: 0.000369 LR: 9.86e-06\n",
      "Epoch   6 [9150/10697 ( 85.5%)] Loss: 0.031366 L1: 0.018305 Grad: 0.130282 Thermal: 0.000661 LR: 9.86e-06\n",
      "Epoch   6 [9150/10697 ( 85.5%)] Loss: 0.031366 L1: 0.018305 Grad: 0.130282 Thermal: 0.000661 LR: 9.86e-06\n",
      "Epoch   6 [9200/10697 ( 86.0%)] Loss: 0.027472 L1: 0.016382 Grad: 0.110650 Thermal: 0.000494 LR: 9.86e-06\n",
      "Epoch   6 [9200/10697 ( 86.0%)] Loss: 0.027472 L1: 0.016382 Grad: 0.110650 Thermal: 0.000494 LR: 9.86e-06\n",
      "Epoch   6 [9250/10697 ( 86.5%)] Loss: 0.027799 L1: 0.016133 Grad: 0.116430 Thermal: 0.000468 LR: 9.86e-06\n",
      "Epoch   6 [9250/10697 ( 86.5%)] Loss: 0.027799 L1: 0.016133 Grad: 0.116430 Thermal: 0.000468 LR: 9.86e-06\n",
      "Epoch   6 [9300/10697 ( 86.9%)] Loss: 0.027622 L1: 0.016504 Grad: 0.110948 Thermal: 0.000458 LR: 9.86e-06\n",
      "Epoch   6 [9300/10697 ( 86.9%)] Loss: 0.027622 L1: 0.016504 Grad: 0.110948 Thermal: 0.000458 LR: 9.86e-06\n",
      "Epoch   6 [9350/10697 ( 87.4%)] Loss: 0.022291 L1: 0.013130 Grad: 0.091437 Thermal: 0.000349 LR: 9.86e-06\n",
      "Epoch   6 [9350/10697 ( 87.4%)] Loss: 0.022291 L1: 0.013130 Grad: 0.091437 Thermal: 0.000349 LR: 9.86e-06\n",
      "Epoch   6 [9400/10697 ( 87.9%)] Loss: 0.027503 L1: 0.015996 Grad: 0.114839 Thermal: 0.000475 LR: 9.86e-06\n",
      "Epoch   6 [9400/10697 ( 87.9%)] Loss: 0.027503 L1: 0.015996 Grad: 0.114839 Thermal: 0.000475 LR: 9.86e-06\n",
      "Epoch   6 [9450/10697 ( 88.3%)] Loss: 0.013171 L1: 0.007485 Grad: 0.056785 Thermal: 0.000157 LR: 9.86e-06\n",
      "Epoch   6 [9450/10697 ( 88.3%)] Loss: 0.013171 L1: 0.007485 Grad: 0.056785 Thermal: 0.000157 LR: 9.86e-06\n",
      "Epoch   6 [9500/10697 ( 88.8%)] Loss: 0.028250 L1: 0.016496 Grad: 0.117311 Thermal: 0.000472 LR: 9.86e-06\n",
      "Epoch   6 [9500/10697 ( 88.8%)] Loss: 0.028250 L1: 0.016496 Grad: 0.117311 Thermal: 0.000472 LR: 9.86e-06\n",
      "Epoch   6 [9550/10697 ( 89.3%)] Loss: 0.025344 L1: 0.014705 Grad: 0.106145 Thermal: 0.000479 LR: 9.86e-06\n",
      "Epoch   6 [9550/10697 ( 89.3%)] Loss: 0.025344 L1: 0.014705 Grad: 0.106145 Thermal: 0.000479 LR: 9.86e-06\n",
      "Epoch   6 [9600/10697 ( 89.7%)] Loss: 0.026978 L1: 0.016019 Grad: 0.109344 Thermal: 0.000490 LR: 9.86e-06\n",
      "Epoch   6 [9600/10697 ( 89.7%)] Loss: 0.026978 L1: 0.016019 Grad: 0.109344 Thermal: 0.000490 LR: 9.86e-06\n",
      "Epoch   6 [9650/10697 ( 90.2%)] Loss: 0.026554 L1: 0.015098 Grad: 0.114323 Thermal: 0.000469 LR: 9.86e-06\n",
      "Epoch   6 [9650/10697 ( 90.2%)] Loss: 0.026554 L1: 0.015098 Grad: 0.114323 Thermal: 0.000469 LR: 9.86e-06\n",
      "Epoch   6 [9700/10697 ( 90.7%)] Loss: 0.025891 L1: 0.015124 Grad: 0.107457 Thermal: 0.000426 LR: 9.86e-06\n",
      "Epoch   6 [9700/10697 ( 90.7%)] Loss: 0.025891 L1: 0.015124 Grad: 0.107457 Thermal: 0.000426 LR: 9.86e-06\n",
      "Epoch   6 [9750/10697 ( 91.1%)] Loss: 0.022554 L1: 0.012537 Grad: 0.100008 Thermal: 0.000333 LR: 9.86e-06\n",
      "Epoch   6 [9750/10697 ( 91.1%)] Loss: 0.022554 L1: 0.012537 Grad: 0.100008 Thermal: 0.000333 LR: 9.86e-06\n",
      "Epoch   6 [9800/10697 ( 91.6%)] Loss: 0.026877 L1: 0.015825 Grad: 0.110290 Thermal: 0.000462 LR: 9.86e-06\n",
      "Epoch   6 [9800/10697 ( 91.6%)] Loss: 0.026877 L1: 0.015825 Grad: 0.110290 Thermal: 0.000462 LR: 9.86e-06\n",
      "Epoch   6 [9850/10697 ( 92.1%)] Loss: 0.026721 L1: 0.015583 Grad: 0.111164 Thermal: 0.000434 LR: 9.86e-06\n",
      "Epoch   6 [9850/10697 ( 92.1%)] Loss: 0.026721 L1: 0.015583 Grad: 0.111164 Thermal: 0.000434 LR: 9.86e-06\n",
      "Epoch   6 [9900/10697 ( 92.5%)] Loss: 0.025766 L1: 0.015074 Grad: 0.106703 Thermal: 0.000433 LR: 9.86e-06\n",
      "Epoch   6 [9900/10697 ( 92.5%)] Loss: 0.025766 L1: 0.015074 Grad: 0.106703 Thermal: 0.000433 LR: 9.86e-06\n",
      "Epoch   6 [9950/10697 ( 93.0%)] Loss: 0.031526 L1: 0.018132 Grad: 0.133650 Thermal: 0.000594 LR: 9.86e-06\n",
      "Epoch   6 [9950/10697 ( 93.0%)] Loss: 0.031526 L1: 0.018132 Grad: 0.133650 Thermal: 0.000594 LR: 9.86e-06\n",
      "Epoch   6 [10000/10697 ( 93.5%)] Loss: 0.029089 L1: 0.017091 Grad: 0.119722 Thermal: 0.000507 LR: 9.86e-06\n",
      "Epoch   6 [10000/10697 ( 93.5%)] Loss: 0.029089 L1: 0.017091 Grad: 0.119722 Thermal: 0.000507 LR: 9.86e-06\n",
      "Epoch   6 [10050/10697 ( 94.0%)] Loss: 0.023980 L1: 0.014007 Grad: 0.099531 Thermal: 0.000393 LR: 9.86e-06\n",
      "Epoch   6 [10050/10697 ( 94.0%)] Loss: 0.023980 L1: 0.014007 Grad: 0.099531 Thermal: 0.000393 LR: 9.86e-06\n",
      "Epoch   6 [10100/10697 ( 94.4%)] Loss: 0.023113 L1: 0.013017 Grad: 0.100750 Thermal: 0.000401 LR: 9.86e-06\n",
      "Epoch   6 [10100/10697 ( 94.4%)] Loss: 0.023113 L1: 0.013017 Grad: 0.100750 Thermal: 0.000401 LR: 9.86e-06\n",
      "Epoch   6 [10150/10697 ( 94.9%)] Loss: 0.025234 L1: 0.014841 Grad: 0.103726 Thermal: 0.000405 LR: 9.86e-06\n",
      "Epoch   6 [10150/10697 ( 94.9%)] Loss: 0.025234 L1: 0.014841 Grad: 0.103726 Thermal: 0.000405 LR: 9.86e-06\n",
      "Epoch   6 [10200/10697 ( 95.4%)] Loss: 0.022112 L1: 0.012495 Grad: 0.095996 Thermal: 0.000339 LR: 9.86e-06\n",
      "Epoch   6 [10200/10697 ( 95.4%)] Loss: 0.022112 L1: 0.012495 Grad: 0.095996 Thermal: 0.000339 LR: 9.86e-06\n",
      "Epoch   6 [10250/10697 ( 95.8%)] Loss: 0.027278 L1: 0.015969 Grad: 0.112859 Thermal: 0.000472 LR: 9.86e-06\n",
      "Epoch   6 [10250/10697 ( 95.8%)] Loss: 0.027278 L1: 0.015969 Grad: 0.112859 Thermal: 0.000472 LR: 9.86e-06\n",
      "Epoch   6 [10300/10697 ( 96.3%)] Loss: 0.026483 L1: 0.014989 Grad: 0.114723 Thermal: 0.000449 LR: 9.86e-06\n",
      "Epoch   6 [10300/10697 ( 96.3%)] Loss: 0.026483 L1: 0.014989 Grad: 0.114723 Thermal: 0.000449 LR: 9.86e-06\n",
      "Epoch   6 [10350/10697 ( 96.8%)] Loss: 0.024665 L1: 0.014585 Grad: 0.100595 Thermal: 0.000398 LR: 9.86e-06\n",
      "Epoch   6 [10350/10697 ( 96.8%)] Loss: 0.024665 L1: 0.014585 Grad: 0.100595 Thermal: 0.000398 LR: 9.86e-06\n",
      "Epoch   6 [10400/10697 ( 97.2%)] Loss: 0.027451 L1: 0.015784 Grad: 0.116432 Thermal: 0.000477 LR: 9.86e-06\n",
      "Epoch   6 [10400/10697 ( 97.2%)] Loss: 0.027451 L1: 0.015784 Grad: 0.116432 Thermal: 0.000477 LR: 9.86e-06\n",
      "Epoch   6 [10450/10697 ( 97.7%)] Loss: 0.023064 L1: 0.013694 Grad: 0.093508 Thermal: 0.000388 LR: 9.86e-06\n",
      "Epoch   6 [10450/10697 ( 97.7%)] Loss: 0.023064 L1: 0.013694 Grad: 0.093508 Thermal: 0.000388 LR: 9.86e-06\n",
      "Epoch   6 [10500/10697 ( 98.2%)] Loss: 0.028073 L1: 0.016574 Grad: 0.114737 Thermal: 0.000508 LR: 9.86e-06\n",
      "Epoch   6 [10500/10697 ( 98.2%)] Loss: 0.028073 L1: 0.016574 Grad: 0.114737 Thermal: 0.000508 LR: 9.86e-06\n",
      "Epoch   6 [10550/10697 ( 98.6%)] Loss: 0.029735 L1: 0.017554 Grad: 0.121541 Thermal: 0.000539 LR: 9.86e-06\n",
      "Epoch   6 [10550/10697 ( 98.6%)] Loss: 0.029735 L1: 0.017554 Grad: 0.121541 Thermal: 0.000539 LR: 9.86e-06\n",
      "Epoch   6 [10600/10697 ( 99.1%)] Loss: 0.025564 L1: 0.014817 Grad: 0.107281 Thermal: 0.000385 LR: 9.86e-06\n",
      "Epoch   6 [10600/10697 ( 99.1%)] Loss: 0.025564 L1: 0.014817 Grad: 0.107281 Thermal: 0.000385 LR: 9.86e-06\n",
      "Epoch   6 [10650/10697 ( 99.6%)] Loss: 0.034993 L1: 0.020262 Grad: 0.146919 Thermal: 0.000770 LR: 9.86e-06\n",
      "Epoch   6 [10650/10697 ( 99.6%)] Loss: 0.034993 L1: 0.020262 Grad: 0.146919 Thermal: 0.000770 LR: 9.86e-06\n",
      "Epoch   6 Summary: Loss=0.026906 (L1:0.0157, Grad:0.1122, Thermal:0.0005) Val_PSNR=0.00dB Best=33.75dB Time=25.1min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch   6 Summary: Loss=0.026906 (L1:0.0157, Grad:0.1122, Thermal:0.0005) Val_PSNR=0.00dB Best=33.75dB Time=25.1min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch   7 [   0/10697 (  0.0%)] Loss: 0.028658 L1: 0.016878 Grad: 0.117548 Thermal: 0.000493 LR: 9.81e-06\n",
      "Epoch   7 [   0/10697 (  0.0%)] Loss: 0.028658 L1: 0.016878 Grad: 0.117548 Thermal: 0.000493 LR: 9.81e-06\n",
      "Epoch   7 [  50/10697 (  0.5%)] Loss: 0.026146 L1: 0.015398 Grad: 0.107276 Thermal: 0.000424 LR: 9.81e-06\n",
      "Epoch   7 [  50/10697 (  0.5%)] Loss: 0.026146 L1: 0.015398 Grad: 0.107276 Thermal: 0.000424 LR: 9.81e-06\n",
      "Epoch   7 [ 100/10697 (  0.9%)] Loss: 0.022337 L1: 0.013183 Grad: 0.091371 Thermal: 0.000344 LR: 9.81e-06\n",
      "Epoch   7 [ 100/10697 (  0.9%)] Loss: 0.022337 L1: 0.013183 Grad: 0.091371 Thermal: 0.000344 LR: 9.81e-06\n",
      "Epoch   7 [ 150/10697 (  1.4%)] Loss: 0.034311 L1: 0.020036 Grad: 0.142355 Thermal: 0.000773 LR: 9.81e-06\n",
      "Epoch   7 [ 150/10697 (  1.4%)] Loss: 0.034311 L1: 0.020036 Grad: 0.142355 Thermal: 0.000773 LR: 9.81e-06\n",
      "Epoch   7 [ 200/10697 (  1.9%)] Loss: 0.031248 L1: 0.017732 Grad: 0.134871 Thermal: 0.000560 LR: 9.81e-06\n",
      "Epoch   7 [ 200/10697 (  1.9%)] Loss: 0.031248 L1: 0.017732 Grad: 0.134871 Thermal: 0.000560 LR: 9.81e-06\n",
      "Epoch   7 [ 250/10697 (  2.3%)] Loss: 0.030373 L1: 0.017423 Grad: 0.129209 Thermal: 0.000578 LR: 9.81e-06\n",
      "Epoch   7 [ 250/10697 (  2.3%)] Loss: 0.030373 L1: 0.017423 Grad: 0.129209 Thermal: 0.000578 LR: 9.81e-06\n",
      "Epoch   7 [ 300/10697 (  2.8%)] Loss: 0.023231 L1: 0.013866 Grad: 0.093468 Thermal: 0.000369 LR: 9.81e-06\n",
      "Epoch   7 [ 300/10697 (  2.8%)] Loss: 0.023231 L1: 0.013866 Grad: 0.093468 Thermal: 0.000369 LR: 9.81e-06\n",
      "Epoch   7 [ 350/10697 (  3.3%)] Loss: 0.032451 L1: 0.018943 Grad: 0.134700 Thermal: 0.000749 LR: 9.81e-06\n",
      "Epoch   7 [ 350/10697 (  3.3%)] Loss: 0.032451 L1: 0.018943 Grad: 0.134700 Thermal: 0.000749 LR: 9.81e-06\n",
      "Epoch   7 [ 400/10697 (  3.7%)] Loss: 0.028183 L1: 0.015964 Grad: 0.121977 Thermal: 0.000432 LR: 9.81e-06\n",
      "Epoch   7 [ 400/10697 (  3.7%)] Loss: 0.028183 L1: 0.015964 Grad: 0.121977 Thermal: 0.000432 LR: 9.81e-06\n",
      "Epoch   7 [ 450/10697 (  4.2%)] Loss: 0.026478 L1: 0.015456 Grad: 0.110008 Thermal: 0.000418 LR: 9.81e-06\n",
      "Epoch   7 [ 450/10697 (  4.2%)] Loss: 0.026478 L1: 0.015456 Grad: 0.110008 Thermal: 0.000418 LR: 9.81e-06\n",
      "Epoch   7 [ 500/10697 (  4.7%)] Loss: 0.029502 L1: 0.017019 Grad: 0.124566 Thermal: 0.000535 LR: 9.81e-06\n",
      "Epoch   7 [ 500/10697 (  4.7%)] Loss: 0.029502 L1: 0.017019 Grad: 0.124566 Thermal: 0.000535 LR: 9.81e-06\n",
      "Epoch   7 [ 550/10697 (  5.1%)] Loss: 0.023608 L1: 0.013566 Grad: 0.100198 Thermal: 0.000433 LR: 9.81e-06\n",
      "Epoch   7 [ 550/10697 (  5.1%)] Loss: 0.023608 L1: 0.013566 Grad: 0.100198 Thermal: 0.000433 LR: 9.81e-06\n",
      "Epoch   7 [ 600/10697 (  5.6%)] Loss: 0.029437 L1: 0.016936 Grad: 0.124743 Thermal: 0.000551 LR: 9.81e-06\n",
      "Epoch   7 [ 600/10697 (  5.6%)] Loss: 0.029437 L1: 0.016936 Grad: 0.124743 Thermal: 0.000551 LR: 9.81e-06\n",
      "Epoch   7 [ 650/10697 (  6.1%)] Loss: 0.026456 L1: 0.015308 Grad: 0.111266 Thermal: 0.000427 LR: 9.81e-06\n",
      "Epoch   7 [ 650/10697 (  6.1%)] Loss: 0.026456 L1: 0.015308 Grad: 0.111266 Thermal: 0.000427 LR: 9.81e-06\n",
      "Epoch   7 [ 700/10697 (  6.5%)] Loss: 0.027343 L1: 0.016187 Grad: 0.111319 Thermal: 0.000470 LR: 9.81e-06\n",
      "Epoch   7 [ 700/10697 (  6.5%)] Loss: 0.027343 L1: 0.016187 Grad: 0.111319 Thermal: 0.000470 LR: 9.81e-06\n",
      "Epoch   7 [ 750/10697 (  7.0%)] Loss: 0.028927 L1: 0.017223 Grad: 0.116783 Thermal: 0.000499 LR: 9.81e-06\n",
      "Epoch   7 [ 750/10697 (  7.0%)] Loss: 0.028927 L1: 0.017223 Grad: 0.116783 Thermal: 0.000499 LR: 9.81e-06\n",
      "Epoch   7 [ 800/10697 (  7.5%)] Loss: 0.027383 L1: 0.016270 Grad: 0.110888 Thermal: 0.000501 LR: 9.81e-06\n",
      "Epoch   7 [ 800/10697 (  7.5%)] Loss: 0.027383 L1: 0.016270 Grad: 0.110888 Thermal: 0.000501 LR: 9.81e-06\n",
      "Epoch   7 [ 850/10697 (  7.9%)] Loss: 0.017520 L1: 0.010009 Grad: 0.075004 Thermal: 0.000217 LR: 9.81e-06\n",
      "Epoch   7 [ 850/10697 (  7.9%)] Loss: 0.017520 L1: 0.010009 Grad: 0.075004 Thermal: 0.000217 LR: 9.81e-06\n",
      "Epoch   7 [ 900/10697 (  8.4%)] Loss: 0.018213 L1: 0.010614 Grad: 0.075866 Thermal: 0.000249 LR: 9.81e-06\n",
      "Epoch   7 [ 900/10697 (  8.4%)] Loss: 0.018213 L1: 0.010614 Grad: 0.075866 Thermal: 0.000249 LR: 9.81e-06\n",
      "Epoch   7 [ 950/10697 (  8.9%)] Loss: 0.023754 L1: 0.013669 Grad: 0.100664 Thermal: 0.000365 LR: 9.81e-06\n",
      "Epoch   7 [ 950/10697 (  8.9%)] Loss: 0.023754 L1: 0.013669 Grad: 0.100664 Thermal: 0.000365 LR: 9.81e-06\n",
      "Epoch   7 [1000/10697 (  9.3%)] Loss: 0.028425 L1: 0.016081 Grad: 0.123172 Thermal: 0.000544 LR: 9.81e-06\n",
      "Epoch   7 [1000/10697 (  9.3%)] Loss: 0.028425 L1: 0.016081 Grad: 0.123172 Thermal: 0.000544 LR: 9.81e-06\n",
      "Epoch   7 [1050/10697 (  9.8%)] Loss: 0.023319 L1: 0.013703 Grad: 0.095967 Thermal: 0.000391 LR: 9.81e-06\n",
      "Epoch   7 [1050/10697 (  9.8%)] Loss: 0.023319 L1: 0.013703 Grad: 0.095967 Thermal: 0.000391 LR: 9.81e-06\n",
      "Epoch   7 [1100/10697 ( 10.3%)] Loss: 0.024181 L1: 0.014201 Grad: 0.099616 Thermal: 0.000383 LR: 9.81e-06\n",
      "Epoch   7 [1100/10697 ( 10.3%)] Loss: 0.024181 L1: 0.014201 Grad: 0.099616 Thermal: 0.000383 LR: 9.81e-06\n",
      "Epoch   7 [1150/10697 ( 10.8%)] Loss: 0.026920 L1: 0.015395 Grad: 0.115025 Thermal: 0.000434 LR: 9.81e-06\n",
      "Epoch   7 [1150/10697 ( 10.8%)] Loss: 0.026920 L1: 0.015395 Grad: 0.115025 Thermal: 0.000434 LR: 9.81e-06\n",
      "Epoch   7 [1200/10697 ( 11.2%)] Loss: 0.026507 L1: 0.015636 Grad: 0.108487 Thermal: 0.000444 LR: 9.81e-06\n",
      "Epoch   7 [1200/10697 ( 11.2%)] Loss: 0.026507 L1: 0.015636 Grad: 0.108487 Thermal: 0.000444 LR: 9.81e-06\n",
      "Epoch   7 [1250/10697 ( 11.7%)] Loss: 0.025557 L1: 0.014475 Grad: 0.110619 Thermal: 0.000406 LR: 9.81e-06\n",
      "Epoch   7 [1250/10697 ( 11.7%)] Loss: 0.025557 L1: 0.014475 Grad: 0.110619 Thermal: 0.000406 LR: 9.81e-06\n",
      "Epoch   7 [1300/10697 ( 12.2%)] Loss: 0.030930 L1: 0.018118 Grad: 0.127829 Thermal: 0.000593 LR: 9.81e-06\n",
      "Epoch   7 [1300/10697 ( 12.2%)] Loss: 0.030930 L1: 0.018118 Grad: 0.127829 Thermal: 0.000593 LR: 9.81e-06\n",
      "Epoch   7 [1350/10697 ( 12.6%)] Loss: 0.031417 L1: 0.018210 Grad: 0.131778 Thermal: 0.000591 LR: 9.81e-06\n",
      "Epoch   7 [1350/10697 ( 12.6%)] Loss: 0.031417 L1: 0.018210 Grad: 0.131778 Thermal: 0.000591 LR: 9.81e-06\n",
      "Epoch   7 [1400/10697 ( 13.1%)] Loss: 0.024318 L1: 0.014335 Grad: 0.099629 Thermal: 0.000398 LR: 9.81e-06\n",
      "Epoch   7 [1400/10697 ( 13.1%)] Loss: 0.024318 L1: 0.014335 Grad: 0.099629 Thermal: 0.000398 LR: 9.81e-06\n",
      "Epoch   7 [1450/10697 ( 13.6%)] Loss: 0.022982 L1: 0.013063 Grad: 0.099011 Thermal: 0.000375 LR: 9.81e-06\n",
      "Epoch   7 [1450/10697 ( 13.6%)] Loss: 0.022982 L1: 0.013063 Grad: 0.099011 Thermal: 0.000375 LR: 9.81e-06\n",
      "Epoch   7 [1500/10697 ( 14.0%)] Loss: 0.022375 L1: 0.013044 Grad: 0.093161 Thermal: 0.000308 LR: 9.81e-06\n",
      "Epoch   7 [1500/10697 ( 14.0%)] Loss: 0.022375 L1: 0.013044 Grad: 0.093161 Thermal: 0.000308 LR: 9.81e-06\n",
      "Epoch   7 [1550/10697 ( 14.5%)] Loss: 0.024204 L1: 0.013950 Grad: 0.102354 Thermal: 0.000386 LR: 9.81e-06\n",
      "Epoch   7 [1550/10697 ( 14.5%)] Loss: 0.024204 L1: 0.013950 Grad: 0.102354 Thermal: 0.000386 LR: 9.81e-06\n",
      "Epoch   7 [1600/10697 ( 15.0%)] Loss: 0.026195 L1: 0.015263 Grad: 0.109102 Thermal: 0.000441 LR: 9.81e-06\n",
      "Epoch   7 [1600/10697 ( 15.0%)] Loss: 0.026195 L1: 0.015263 Grad: 0.109102 Thermal: 0.000441 LR: 9.81e-06\n",
      "Epoch   7 [1650/10697 ( 15.4%)] Loss: 0.026072 L1: 0.015501 Grad: 0.105466 Thermal: 0.000484 LR: 9.81e-06\n",
      "Epoch   7 [1650/10697 ( 15.4%)] Loss: 0.026072 L1: 0.015501 Grad: 0.105466 Thermal: 0.000484 LR: 9.81e-06\n",
      "Epoch   7 [1700/10697 ( 15.9%)] Loss: 0.027353 L1: 0.015909 Grad: 0.114202 Thermal: 0.000470 LR: 9.81e-06\n",
      "Epoch   7 [1700/10697 ( 15.9%)] Loss: 0.027353 L1: 0.015909 Grad: 0.114202 Thermal: 0.000470 LR: 9.81e-06\n",
      "Epoch   7 [1750/10697 ( 16.4%)] Loss: 0.026142 L1: 0.015269 Grad: 0.108488 Thermal: 0.000471 LR: 9.81e-06\n",
      "Epoch   7 [1750/10697 ( 16.4%)] Loss: 0.026142 L1: 0.015269 Grad: 0.108488 Thermal: 0.000471 LR: 9.81e-06\n",
      "Epoch   7 [1800/10697 ( 16.8%)] Loss: 0.035762 L1: 0.020365 Grad: 0.153553 Thermal: 0.000834 LR: 9.81e-06\n",
      "Epoch   7 [1800/10697 ( 16.8%)] Loss: 0.035762 L1: 0.020365 Grad: 0.153553 Thermal: 0.000834 LR: 9.81e-06\n",
      "Epoch   7 [1850/10697 ( 17.3%)] Loss: 0.022088 L1: 0.012799 Grad: 0.092715 Thermal: 0.000354 LR: 9.81e-06\n",
      "Epoch   7 [1850/10697 ( 17.3%)] Loss: 0.022088 L1: 0.012799 Grad: 0.092715 Thermal: 0.000354 LR: 9.81e-06\n",
      "Epoch   7 [1900/10697 ( 17.8%)] Loss: 0.024137 L1: 0.013576 Grad: 0.105405 Thermal: 0.000397 LR: 9.81e-06\n",
      "Epoch   7 [1900/10697 ( 17.8%)] Loss: 0.024137 L1: 0.013576 Grad: 0.105405 Thermal: 0.000397 LR: 9.81e-06\n",
      "Epoch   7 [1950/10697 ( 18.2%)] Loss: 0.023603 L1: 0.013667 Grad: 0.099193 Thermal: 0.000327 LR: 9.81e-06\n",
      "Epoch   7 [1950/10697 ( 18.2%)] Loss: 0.023603 L1: 0.013667 Grad: 0.099193 Thermal: 0.000327 LR: 9.81e-06\n",
      "Epoch   7 [2000/10697 ( 18.7%)] Loss: 0.029701 L1: 0.017634 Grad: 0.120369 Thermal: 0.000591 LR: 9.81e-06\n",
      "Epoch   7 [2000/10697 ( 18.7%)] Loss: 0.029701 L1: 0.017634 Grad: 0.120369 Thermal: 0.000591 LR: 9.81e-06\n",
      "Epoch   7 [2050/10697 ( 19.2%)] Loss: 0.021790 L1: 0.012701 Grad: 0.090723 Thermal: 0.000316 LR: 9.81e-06\n",
      "Epoch   7 [2050/10697 ( 19.2%)] Loss: 0.021790 L1: 0.012701 Grad: 0.090723 Thermal: 0.000316 LR: 9.81e-06\n",
      "Epoch   7 [2100/10697 ( 19.6%)] Loss: 0.028986 L1: 0.016647 Grad: 0.123122 Thermal: 0.000540 LR: 9.81e-06\n",
      "Epoch   7 [2100/10697 ( 19.6%)] Loss: 0.028986 L1: 0.016647 Grad: 0.123122 Thermal: 0.000540 LR: 9.81e-06\n",
      "Epoch   7 [2150/10697 ( 20.1%)] Loss: 0.030310 L1: 0.017632 Grad: 0.126504 Thermal: 0.000546 LR: 9.81e-06\n",
      "Epoch   7 [2150/10697 ( 20.1%)] Loss: 0.030310 L1: 0.017632 Grad: 0.126504 Thermal: 0.000546 LR: 9.81e-06\n",
      "Epoch   7 [2200/10697 ( 20.6%)] Loss: 0.024835 L1: 0.014276 Grad: 0.105390 Thermal: 0.000414 LR: 9.81e-06\n",
      "Epoch   7 [2200/10697 ( 20.6%)] Loss: 0.024835 L1: 0.014276 Grad: 0.105390 Thermal: 0.000414 LR: 9.81e-06\n",
      "Epoch   7 [2250/10697 ( 21.0%)] Loss: 0.029775 L1: 0.016988 Grad: 0.127580 Thermal: 0.000567 LR: 9.81e-06\n",
      "Epoch   7 [2250/10697 ( 21.0%)] Loss: 0.029775 L1: 0.016988 Grad: 0.127580 Thermal: 0.000567 LR: 9.81e-06\n",
      "Epoch   7 [2300/10697 ( 21.5%)] Loss: 0.026124 L1: 0.015749 Grad: 0.103530 Thermal: 0.000441 LR: 9.81e-06\n",
      "Epoch   7 [2300/10697 ( 21.5%)] Loss: 0.026124 L1: 0.015749 Grad: 0.103530 Thermal: 0.000441 LR: 9.81e-06\n",
      "Epoch   7 [2350/10697 ( 22.0%)] Loss: 0.023537 L1: 0.013227 Grad: 0.102949 Thermal: 0.000314 LR: 9.81e-06\n",
      "Epoch   7 [2350/10697 ( 22.0%)] Loss: 0.023537 L1: 0.013227 Grad: 0.102949 Thermal: 0.000314 LR: 9.81e-06\n",
      "Epoch   7 [2400/10697 ( 22.4%)] Loss: 0.030400 L1: 0.017484 Grad: 0.128885 Thermal: 0.000547 LR: 9.81e-06\n",
      "Epoch   7 [2400/10697 ( 22.4%)] Loss: 0.030400 L1: 0.017484 Grad: 0.128885 Thermal: 0.000547 LR: 9.81e-06\n",
      "Epoch   7 [2450/10697 ( 22.9%)] Loss: 0.022434 L1: 0.012692 Grad: 0.097256 Thermal: 0.000320 LR: 9.81e-06\n",
      "Epoch   7 [2450/10697 ( 22.9%)] Loss: 0.022434 L1: 0.012692 Grad: 0.097256 Thermal: 0.000320 LR: 9.81e-06\n",
      "Epoch   7 [2500/10697 ( 23.4%)] Loss: 0.016522 L1: 0.009096 Grad: 0.074163 Thermal: 0.000184 LR: 9.81e-06\n",
      "Epoch   7 [2500/10697 ( 23.4%)] Loss: 0.016522 L1: 0.009096 Grad: 0.074163 Thermal: 0.000184 LR: 9.81e-06\n",
      "Epoch   7 [2550/10697 ( 23.8%)] Loss: 0.026879 L1: 0.015632 Grad: 0.112241 Thermal: 0.000457 LR: 9.81e-06\n",
      "Epoch   7 [2550/10697 ( 23.8%)] Loss: 0.026879 L1: 0.015632 Grad: 0.112241 Thermal: 0.000457 LR: 9.81e-06\n",
      "Epoch   7 [2600/10697 ( 24.3%)] Loss: 0.027169 L1: 0.016293 Grad: 0.108528 Thermal: 0.000474 LR: 9.81e-06\n",
      "Epoch   7 [2600/10697 ( 24.3%)] Loss: 0.027169 L1: 0.016293 Grad: 0.108528 Thermal: 0.000474 LR: 9.81e-06\n",
      "Epoch   7 [2650/10697 ( 24.8%)] Loss: 0.020565 L1: 0.011871 Grad: 0.086799 Thermal: 0.000270 LR: 9.81e-06\n",
      "Epoch   7 [2650/10697 ( 24.8%)] Loss: 0.020565 L1: 0.011871 Grad: 0.086799 Thermal: 0.000270 LR: 9.81e-06\n",
      "Epoch   7 [2700/10697 ( 25.2%)] Loss: 0.027996 L1: 0.016118 Grad: 0.118526 Thermal: 0.000502 LR: 9.81e-06\n",
      "Epoch   7 [2700/10697 ( 25.2%)] Loss: 0.027996 L1: 0.016118 Grad: 0.118526 Thermal: 0.000502 LR: 9.81e-06\n",
      "Epoch   7 [2750/10697 ( 25.7%)] Loss: 0.031044 L1: 0.018477 Grad: 0.125356 Thermal: 0.000625 LR: 9.81e-06\n",
      "Epoch   7 [2750/10697 ( 25.7%)] Loss: 0.031044 L1: 0.018477 Grad: 0.125356 Thermal: 0.000625 LR: 9.81e-06\n",
      "Epoch   7 [2800/10697 ( 26.2%)] Loss: 0.029353 L1: 0.017472 Grad: 0.118529 Thermal: 0.000551 LR: 9.81e-06\n",
      "Epoch   7 [2800/10697 ( 26.2%)] Loss: 0.029353 L1: 0.017472 Grad: 0.118529 Thermal: 0.000551 LR: 9.81e-06\n",
      "Epoch   7 [2850/10697 ( 26.6%)] Loss: 0.025415 L1: 0.014685 Grad: 0.107108 Thermal: 0.000391 LR: 9.81e-06\n",
      "Epoch   7 [2850/10697 ( 26.6%)] Loss: 0.025415 L1: 0.014685 Grad: 0.107108 Thermal: 0.000391 LR: 9.81e-06\n",
      "Epoch   7 [2900/10697 ( 27.1%)] Loss: 0.028501 L1: 0.016630 Grad: 0.118463 Thermal: 0.000507 LR: 9.81e-06\n",
      "Epoch   7 [2900/10697 ( 27.1%)] Loss: 0.028501 L1: 0.016630 Grad: 0.118463 Thermal: 0.000507 LR: 9.81e-06\n",
      "Epoch   7 [2950/10697 ( 27.6%)] Loss: 0.021862 L1: 0.012435 Grad: 0.094088 Thermal: 0.000367 LR: 9.81e-06\n",
      "Epoch   7 [2950/10697 ( 27.6%)] Loss: 0.021862 L1: 0.012435 Grad: 0.094088 Thermal: 0.000367 LR: 9.81e-06\n",
      "Epoch   7 [3000/10697 ( 28.0%)] Loss: 0.023938 L1: 0.014272 Grad: 0.096463 Thermal: 0.000394 LR: 9.81e-06\n",
      "Epoch   7 [3000/10697 ( 28.0%)] Loss: 0.023938 L1: 0.014272 Grad: 0.096463 Thermal: 0.000394 LR: 9.81e-06\n",
      "Epoch   7 [3050/10697 ( 28.5%)] Loss: 0.027805 L1: 0.016391 Grad: 0.113896 Thermal: 0.000489 LR: 9.81e-06\n",
      "Epoch   7 [3050/10697 ( 28.5%)] Loss: 0.027805 L1: 0.016391 Grad: 0.113896 Thermal: 0.000489 LR: 9.81e-06\n",
      "Epoch   7 [3100/10697 ( 29.0%)] Loss: 0.026590 L1: 0.015481 Grad: 0.110848 Thermal: 0.000467 LR: 9.81e-06\n",
      "Epoch   7 [3100/10697 ( 29.0%)] Loss: 0.026590 L1: 0.015481 Grad: 0.110848 Thermal: 0.000467 LR: 9.81e-06\n",
      "Epoch   7 [3150/10697 ( 29.4%)] Loss: 0.026264 L1: 0.015086 Grad: 0.111580 Thermal: 0.000408 LR: 9.81e-06\n",
      "Epoch   7 [3150/10697 ( 29.4%)] Loss: 0.026264 L1: 0.015086 Grad: 0.111580 Thermal: 0.000408 LR: 9.81e-06\n",
      "Epoch   7 [3200/10697 ( 29.9%)] Loss: 0.029830 L1: 0.017462 Grad: 0.123403 Thermal: 0.000560 LR: 9.81e-06\n",
      "Epoch   7 [3200/10697 ( 29.9%)] Loss: 0.029830 L1: 0.017462 Grad: 0.123403 Thermal: 0.000560 LR: 9.81e-06\n",
      "Epoch   7 [3250/10697 ( 30.4%)] Loss: 0.026228 L1: 0.015136 Grad: 0.110699 Thermal: 0.000434 LR: 9.81e-06\n",
      "Epoch   7 [3250/10697 ( 30.4%)] Loss: 0.026228 L1: 0.015136 Grad: 0.110699 Thermal: 0.000434 LR: 9.81e-06\n",
      "Epoch   7 [3300/10697 ( 30.8%)] Loss: 0.025365 L1: 0.014847 Grad: 0.104968 Thermal: 0.000414 LR: 9.81e-06\n",
      "Epoch   7 [3300/10697 ( 30.8%)] Loss: 0.025365 L1: 0.014847 Grad: 0.104968 Thermal: 0.000414 LR: 9.81e-06\n",
      "Epoch   7 [3350/10697 ( 31.3%)] Loss: 0.025654 L1: 0.015034 Grad: 0.105996 Thermal: 0.000414 LR: 9.81e-06\n",
      "Epoch   7 [3350/10697 ( 31.3%)] Loss: 0.025654 L1: 0.015034 Grad: 0.105996 Thermal: 0.000414 LR: 9.81e-06\n",
      "Epoch   7 [3400/10697 ( 31.8%)] Loss: 0.020709 L1: 0.011732 Grad: 0.089597 Thermal: 0.000342 LR: 9.81e-06\n",
      "Epoch   7 [3400/10697 ( 31.8%)] Loss: 0.020709 L1: 0.011732 Grad: 0.089597 Thermal: 0.000342 LR: 9.81e-06\n",
      "Epoch   7 [3450/10697 ( 32.3%)] Loss: 0.024719 L1: 0.014673 Grad: 0.100252 Thermal: 0.000430 LR: 9.81e-06\n",
      "Epoch   7 [3450/10697 ( 32.3%)] Loss: 0.024719 L1: 0.014673 Grad: 0.100252 Thermal: 0.000430 LR: 9.81e-06\n",
      "Epoch   7 [3500/10697 ( 32.7%)] Loss: 0.030337 L1: 0.018056 Grad: 0.122524 Thermal: 0.000579 LR: 9.81e-06\n",
      "Epoch   7 [3500/10697 ( 32.7%)] Loss: 0.030337 L1: 0.018056 Grad: 0.122524 Thermal: 0.000579 LR: 9.81e-06\n",
      "Epoch   7 [3550/10697 ( 33.2%)] Loss: 0.030003 L1: 0.017599 Grad: 0.123776 Thermal: 0.000523 LR: 9.81e-06\n",
      "Epoch   7 [3550/10697 ( 33.2%)] Loss: 0.030003 L1: 0.017599 Grad: 0.123776 Thermal: 0.000523 LR: 9.81e-06\n",
      "Epoch   7 [3600/10697 ( 33.7%)] Loss: 0.025424 L1: 0.014712 Grad: 0.106908 Thermal: 0.000410 LR: 9.81e-06\n",
      "Epoch   7 [3600/10697 ( 33.7%)] Loss: 0.025424 L1: 0.014712 Grad: 0.106908 Thermal: 0.000410 LR: 9.81e-06\n",
      "Epoch   7 [3650/10697 ( 34.1%)] Loss: 0.026658 L1: 0.015734 Grad: 0.108991 Thermal: 0.000491 LR: 9.81e-06\n",
      "Epoch   7 [3650/10697 ( 34.1%)] Loss: 0.026658 L1: 0.015734 Grad: 0.108991 Thermal: 0.000491 LR: 9.81e-06\n",
      "Epoch   7 [3700/10697 ( 34.6%)] Loss: 0.025332 L1: 0.014834 Grad: 0.104771 Thermal: 0.000411 LR: 9.81e-06\n",
      "Epoch   7 [3700/10697 ( 34.6%)] Loss: 0.025332 L1: 0.014834 Grad: 0.104771 Thermal: 0.000411 LR: 9.81e-06\n",
      "Epoch   7 [3750/10697 ( 35.1%)] Loss: 0.031281 L1: 0.017981 Grad: 0.132721 Thermal: 0.000562 LR: 9.81e-06\n",
      "Epoch   7 [3750/10697 ( 35.1%)] Loss: 0.031281 L1: 0.017981 Grad: 0.132721 Thermal: 0.000562 LR: 9.81e-06\n",
      "Epoch   7 [3800/10697 ( 35.5%)] Loss: 0.027468 L1: 0.016449 Grad: 0.109940 Thermal: 0.000496 LR: 9.81e-06\n",
      "Epoch   7 [3800/10697 ( 35.5%)] Loss: 0.027468 L1: 0.016449 Grad: 0.109940 Thermal: 0.000496 LR: 9.81e-06\n",
      "Epoch   7 [3850/10697 ( 36.0%)] Loss: 0.020304 L1: 0.011869 Grad: 0.084184 Thermal: 0.000320 LR: 9.81e-06\n",
      "Epoch   7 [3850/10697 ( 36.0%)] Loss: 0.020304 L1: 0.011869 Grad: 0.084184 Thermal: 0.000320 LR: 9.81e-06\n",
      "Epoch   7 [3900/10697 ( 36.5%)] Loss: 0.027355 L1: 0.015817 Grad: 0.115129 Thermal: 0.000492 LR: 9.81e-06\n",
      "Epoch   7 [3900/10697 ( 36.5%)] Loss: 0.027355 L1: 0.015817 Grad: 0.115129 Thermal: 0.000492 LR: 9.81e-06\n",
      "Epoch   7 [3950/10697 ( 36.9%)] Loss: 0.030274 L1: 0.017753 Grad: 0.124928 Thermal: 0.000565 LR: 9.81e-06\n",
      "Epoch   7 [3950/10697 ( 36.9%)] Loss: 0.030274 L1: 0.017753 Grad: 0.124928 Thermal: 0.000565 LR: 9.81e-06\n",
      "Epoch   7 [4000/10697 ( 37.4%)] Loss: 0.026755 L1: 0.015521 Grad: 0.112142 Thermal: 0.000409 LR: 9.81e-06\n",
      "Epoch   7 [4000/10697 ( 37.4%)] Loss: 0.026755 L1: 0.015521 Grad: 0.112142 Thermal: 0.000409 LR: 9.81e-06\n",
      "Epoch   7 [4050/10697 ( 37.9%)] Loss: 0.029039 L1: 0.017149 Grad: 0.118632 Thermal: 0.000529 LR: 9.81e-06\n",
      "Epoch   7 [4050/10697 ( 37.9%)] Loss: 0.029039 L1: 0.017149 Grad: 0.118632 Thermal: 0.000529 LR: 9.81e-06\n",
      "Epoch   7 [4100/10697 ( 38.3%)] Loss: 0.025900 L1: 0.015082 Grad: 0.107974 Thermal: 0.000410 LR: 9.81e-06\n",
      "Epoch   7 [4100/10697 ( 38.3%)] Loss: 0.025900 L1: 0.015082 Grad: 0.107974 Thermal: 0.000410 LR: 9.81e-06\n",
      "Epoch   7 [4150/10697 ( 38.8%)] Loss: 0.026955 L1: 0.015788 Grad: 0.111438 Thermal: 0.000455 LR: 9.81e-06\n",
      "Epoch   7 [4150/10697 ( 38.8%)] Loss: 0.026955 L1: 0.015788 Grad: 0.111438 Thermal: 0.000455 LR: 9.81e-06\n",
      "Epoch   7 [4200/10697 ( 39.3%)] Loss: 0.027013 L1: 0.016305 Grad: 0.106857 Thermal: 0.000459 LR: 9.81e-06\n",
      "Epoch   7 [4200/10697 ( 39.3%)] Loss: 0.027013 L1: 0.016305 Grad: 0.106857 Thermal: 0.000459 LR: 9.81e-06\n",
      "Epoch   7 [4250/10697 ( 39.7%)] Loss: 0.028568 L1: 0.016638 Grad: 0.119053 Thermal: 0.000493 LR: 9.81e-06\n",
      "Epoch   7 [4250/10697 ( 39.7%)] Loss: 0.028568 L1: 0.016638 Grad: 0.119053 Thermal: 0.000493 LR: 9.81e-06\n",
      "Epoch   7 [4300/10697 ( 40.2%)] Loss: 0.025448 L1: 0.014782 Grad: 0.106453 Thermal: 0.000423 LR: 9.81e-06\n",
      "Epoch   7 [4300/10697 ( 40.2%)] Loss: 0.025448 L1: 0.014782 Grad: 0.106453 Thermal: 0.000423 LR: 9.81e-06\n",
      "Epoch   7 [4350/10697 ( 40.7%)] Loss: 0.027014 L1: 0.015853 Grad: 0.111368 Thermal: 0.000481 LR: 9.81e-06\n",
      "Epoch   7 [4350/10697 ( 40.7%)] Loss: 0.027014 L1: 0.015853 Grad: 0.111368 Thermal: 0.000481 LR: 9.81e-06\n",
      "Epoch   7 [4400/10697 ( 41.1%)] Loss: 0.027367 L1: 0.016473 Grad: 0.108706 Thermal: 0.000475 LR: 9.81e-06\n",
      "Epoch   7 [4400/10697 ( 41.1%)] Loss: 0.027367 L1: 0.016473 Grad: 0.108706 Thermal: 0.000475 LR: 9.81e-06\n",
      "Epoch   7 [4450/10697 ( 41.6%)] Loss: 0.029035 L1: 0.016408 Grad: 0.125965 Thermal: 0.000608 LR: 9.81e-06\n",
      "Epoch   7 [4450/10697 ( 41.6%)] Loss: 0.029035 L1: 0.016408 Grad: 0.125965 Thermal: 0.000608 LR: 9.81e-06\n",
      "Epoch   7 [4500/10697 ( 42.1%)] Loss: 0.028151 L1: 0.016417 Grad: 0.117105 Thermal: 0.000482 LR: 9.81e-06\n",
      "Epoch   7 [4500/10697 ( 42.1%)] Loss: 0.028151 L1: 0.016417 Grad: 0.117105 Thermal: 0.000482 LR: 9.81e-06\n",
      "Epoch   7 [4550/10697 ( 42.5%)] Loss: 0.031344 L1: 0.017939 Grad: 0.133762 Thermal: 0.000563 LR: 9.81e-06\n",
      "Epoch   7 [4550/10697 ( 42.5%)] Loss: 0.031344 L1: 0.017939 Grad: 0.133762 Thermal: 0.000563 LR: 9.81e-06\n",
      "Epoch   7 [4600/10697 ( 43.0%)] Loss: 0.028160 L1: 0.016112 Grad: 0.120246 Thermal: 0.000479 LR: 9.81e-06\n",
      "Epoch   7 [4600/10697 ( 43.0%)] Loss: 0.028160 L1: 0.016112 Grad: 0.120246 Thermal: 0.000479 LR: 9.81e-06\n",
      "Epoch   7 [4650/10697 ( 43.5%)] Loss: 0.026034 L1: 0.015634 Grad: 0.103784 Thermal: 0.000431 LR: 9.81e-06\n",
      "Epoch   7 [4650/10697 ( 43.5%)] Loss: 0.026034 L1: 0.015634 Grad: 0.103784 Thermal: 0.000431 LR: 9.81e-06\n",
      "Epoch   7 [4700/10697 ( 43.9%)] Loss: 0.026724 L1: 0.015789 Grad: 0.109121 Thermal: 0.000454 LR: 9.81e-06\n",
      "Epoch   7 [4700/10697 ( 43.9%)] Loss: 0.026724 L1: 0.015789 Grad: 0.109121 Thermal: 0.000454 LR: 9.81e-06\n",
      "Epoch   7 [4750/10697 ( 44.4%)] Loss: 0.029731 L1: 0.016932 Grad: 0.127743 Thermal: 0.000502 LR: 9.81e-06\n",
      "Epoch   7 [4750/10697 ( 44.4%)] Loss: 0.029731 L1: 0.016932 Grad: 0.127743 Thermal: 0.000502 LR: 9.81e-06\n",
      "Epoch   7 [4800/10697 ( 44.9%)] Loss: 0.020040 L1: 0.011878 Grad: 0.081460 Thermal: 0.000310 LR: 9.81e-06\n",
      "Epoch   7 [4800/10697 ( 44.9%)] Loss: 0.020040 L1: 0.011878 Grad: 0.081460 Thermal: 0.000310 LR: 9.81e-06\n",
      "Epoch   7 [4850/10697 ( 45.3%)] Loss: 0.027451 L1: 0.016406 Grad: 0.110214 Thermal: 0.000485 LR: 9.81e-06\n",
      "Epoch   7 [4850/10697 ( 45.3%)] Loss: 0.027451 L1: 0.016406 Grad: 0.110214 Thermal: 0.000485 LR: 9.81e-06\n",
      "Epoch   7 [4900/10697 ( 45.8%)] Loss: 0.022726 L1: 0.013074 Grad: 0.096353 Thermal: 0.000338 LR: 9.81e-06\n",
      "Epoch   7 [4900/10697 ( 45.8%)] Loss: 0.022726 L1: 0.013074 Grad: 0.096353 Thermal: 0.000338 LR: 9.81e-06\n",
      "Epoch   7 [4950/10697 ( 46.3%)] Loss: 0.029578 L1: 0.017733 Grad: 0.118165 Thermal: 0.000564 LR: 9.81e-06\n",
      "Epoch   7 [4950/10697 ( 46.3%)] Loss: 0.029578 L1: 0.017733 Grad: 0.118165 Thermal: 0.000564 LR: 9.81e-06\n",
      "Epoch   7 [5000/10697 ( 46.7%)] Loss: 0.023345 L1: 0.013411 Grad: 0.099152 Thermal: 0.000371 LR: 9.81e-06\n",
      "Epoch   7 [5000/10697 ( 46.7%)] Loss: 0.023345 L1: 0.013411 Grad: 0.099152 Thermal: 0.000371 LR: 9.81e-06\n",
      "Epoch   7 [5050/10697 ( 47.2%)] Loss: 0.025500 L1: 0.015334 Grad: 0.101451 Thermal: 0.000425 LR: 9.81e-06\n",
      "Epoch   7 [5050/10697 ( 47.2%)] Loss: 0.025500 L1: 0.015334 Grad: 0.101451 Thermal: 0.000425 LR: 9.81e-06\n",
      "Epoch   7 [5100/10697 ( 47.7%)] Loss: 0.021436 L1: 0.012411 Grad: 0.090093 Thermal: 0.000323 LR: 9.81e-06\n",
      "Epoch   7 [5100/10697 ( 47.7%)] Loss: 0.021436 L1: 0.012411 Grad: 0.090093 Thermal: 0.000323 LR: 9.81e-06\n",
      "Epoch   7 [5150/10697 ( 48.1%)] Loss: 0.026269 L1: 0.015542 Grad: 0.107043 Thermal: 0.000443 LR: 9.81e-06\n",
      "Epoch   7 [5150/10697 ( 48.1%)] Loss: 0.026269 L1: 0.015542 Grad: 0.107043 Thermal: 0.000443 LR: 9.81e-06\n",
      "Epoch   7 [5200/10697 ( 48.6%)] Loss: 0.030824 L1: 0.018016 Grad: 0.127801 Thermal: 0.000564 LR: 9.81e-06\n",
      "Epoch   7 [5200/10697 ( 48.6%)] Loss: 0.030824 L1: 0.018016 Grad: 0.127801 Thermal: 0.000564 LR: 9.81e-06\n",
      "Epoch   7 [5250/10697 ( 49.1%)] Loss: 0.022066 L1: 0.012811 Grad: 0.092372 Thermal: 0.000339 LR: 9.81e-06\n",
      "Epoch   7 [5250/10697 ( 49.1%)] Loss: 0.022066 L1: 0.012811 Grad: 0.092372 Thermal: 0.000339 LR: 9.81e-06\n",
      "Epoch   7 [5300/10697 ( 49.5%)] Loss: 0.023239 L1: 0.013505 Grad: 0.097168 Thermal: 0.000348 LR: 9.81e-06\n",
      "Epoch   7 [5300/10697 ( 49.5%)] Loss: 0.023239 L1: 0.013505 Grad: 0.097168 Thermal: 0.000348 LR: 9.81e-06\n",
      "Epoch   7 [5350/10697 ( 50.0%)] Loss: 0.024060 L1: 0.013522 Grad: 0.105179 Thermal: 0.000408 LR: 9.81e-06\n",
      "Epoch   7 [5350/10697 ( 50.0%)] Loss: 0.024060 L1: 0.013522 Grad: 0.105179 Thermal: 0.000408 LR: 9.81e-06\n",
      "Epoch   7 [5400/10697 ( 50.5%)] Loss: 0.027367 L1: 0.016180 Grad: 0.111657 Thermal: 0.000441 LR: 9.81e-06\n",
      "Epoch   7 [5400/10697 ( 50.5%)] Loss: 0.027367 L1: 0.016180 Grad: 0.111657 Thermal: 0.000441 LR: 9.81e-06\n",
      "Epoch   7 [5450/10697 ( 50.9%)] Loss: 0.029146 L1: 0.016998 Grad: 0.121228 Thermal: 0.000508 LR: 9.81e-06\n",
      "Epoch   7 [5450/10697 ( 50.9%)] Loss: 0.029146 L1: 0.016998 Grad: 0.121228 Thermal: 0.000508 LR: 9.81e-06\n",
      "Epoch   7 [5500/10697 ( 51.4%)] Loss: 0.030883 L1: 0.017852 Grad: 0.130033 Thermal: 0.000544 LR: 9.81e-06\n",
      "Epoch   7 [5500/10697 ( 51.4%)] Loss: 0.030883 L1: 0.017852 Grad: 0.130033 Thermal: 0.000544 LR: 9.81e-06\n",
      "Epoch   7 [5550/10697 ( 51.9%)] Loss: 0.031705 L1: 0.018513 Grad: 0.131630 Thermal: 0.000598 LR: 9.81e-06\n",
      "Epoch   7 [5550/10697 ( 51.9%)] Loss: 0.031705 L1: 0.018513 Grad: 0.131630 Thermal: 0.000598 LR: 9.81e-06\n",
      "Epoch   7 [5600/10697 ( 52.4%)] Loss: 0.030487 L1: 0.017848 Grad: 0.126103 Thermal: 0.000577 LR: 9.81e-06\n",
      "Epoch   7 [5600/10697 ( 52.4%)] Loss: 0.030487 L1: 0.017848 Grad: 0.126103 Thermal: 0.000577 LR: 9.81e-06\n",
      "Epoch   7 [5650/10697 ( 52.8%)] Loss: 0.021557 L1: 0.012654 Grad: 0.088866 Thermal: 0.000332 LR: 9.81e-06\n",
      "Epoch   7 [5650/10697 ( 52.8%)] Loss: 0.021557 L1: 0.012654 Grad: 0.088866 Thermal: 0.000332 LR: 9.81e-06\n",
      "Epoch   7 [5700/10697 ( 53.3%)] Loss: 0.023277 L1: 0.013782 Grad: 0.094740 Thermal: 0.000415 LR: 9.81e-06\n",
      "Epoch   7 [5700/10697 ( 53.3%)] Loss: 0.023277 L1: 0.013782 Grad: 0.094740 Thermal: 0.000415 LR: 9.81e-06\n",
      "Epoch   7 [5750/10697 ( 53.8%)] Loss: 0.032260 L1: 0.018720 Grad: 0.135064 Thermal: 0.000667 LR: 9.81e-06\n",
      "Epoch   7 [5750/10697 ( 53.8%)] Loss: 0.032260 L1: 0.018720 Grad: 0.135064 Thermal: 0.000667 LR: 9.81e-06\n",
      "Epoch   7 [5800/10697 ( 54.2%)] Loss: 0.025745 L1: 0.015353 Grad: 0.103683 Thermal: 0.000476 LR: 9.81e-06\n",
      "Epoch   7 [5800/10697 ( 54.2%)] Loss: 0.025745 L1: 0.015353 Grad: 0.103683 Thermal: 0.000476 LR: 9.81e-06\n",
      "Epoch   7 [5850/10697 ( 54.7%)] Loss: 0.033872 L1: 0.019787 Grad: 0.140493 Thermal: 0.000709 LR: 9.81e-06\n",
      "Epoch   7 [5850/10697 ( 54.7%)] Loss: 0.033872 L1: 0.019787 Grad: 0.140493 Thermal: 0.000709 LR: 9.81e-06\n",
      "Epoch   7 [5900/10697 ( 55.2%)] Loss: 0.025288 L1: 0.015245 Grad: 0.100213 Thermal: 0.000430 LR: 9.81e-06\n",
      "Epoch   7 [5900/10697 ( 55.2%)] Loss: 0.025288 L1: 0.015245 Grad: 0.100213 Thermal: 0.000430 LR: 9.81e-06\n",
      "Epoch   7 [5950/10697 ( 55.6%)] Loss: 0.027772 L1: 0.016022 Grad: 0.117253 Thermal: 0.000505 LR: 9.81e-06\n",
      "Epoch   7 [5950/10697 ( 55.6%)] Loss: 0.027772 L1: 0.016022 Grad: 0.117253 Thermal: 0.000505 LR: 9.81e-06\n",
      "Epoch   7 [6000/10697 ( 56.1%)] Loss: 0.031870 L1: 0.018306 Grad: 0.135338 Thermal: 0.000611 LR: 9.81e-06\n",
      "Epoch   7 [6000/10697 ( 56.1%)] Loss: 0.031870 L1: 0.018306 Grad: 0.135338 Thermal: 0.000611 LR: 9.81e-06\n",
      "Epoch   7 [6050/10697 ( 56.6%)] Loss: 0.030908 L1: 0.017950 Grad: 0.129268 Thermal: 0.000616 LR: 9.81e-06\n",
      "Epoch   7 [6050/10697 ( 56.6%)] Loss: 0.030908 L1: 0.017950 Grad: 0.129268 Thermal: 0.000616 LR: 9.81e-06\n",
      "Epoch   7 [6100/10697 ( 57.0%)] Loss: 0.028987 L1: 0.017038 Grad: 0.119174 Thermal: 0.000631 LR: 9.81e-06\n",
      "Epoch   7 [6100/10697 ( 57.0%)] Loss: 0.028987 L1: 0.017038 Grad: 0.119174 Thermal: 0.000631 LR: 9.81e-06\n",
      "Epoch   7 [6150/10697 ( 57.5%)] Loss: 0.027156 L1: 0.016127 Grad: 0.110066 Thermal: 0.000449 LR: 9.81e-06\n",
      "Epoch   7 [6150/10697 ( 57.5%)] Loss: 0.027156 L1: 0.016127 Grad: 0.110066 Thermal: 0.000449 LR: 9.81e-06\n",
      "Epoch   7 [6200/10697 ( 58.0%)] Loss: 0.018753 L1: 0.010649 Grad: 0.080912 Thermal: 0.000245 LR: 9.81e-06\n",
      "Epoch   7 [6200/10697 ( 58.0%)] Loss: 0.018753 L1: 0.010649 Grad: 0.080912 Thermal: 0.000245 LR: 9.81e-06\n",
      "Epoch   7 [6250/10697 ( 58.4%)] Loss: 0.024798 L1: 0.014318 Grad: 0.104614 Thermal: 0.000361 LR: 9.81e-06\n",
      "Epoch   7 [6250/10697 ( 58.4%)] Loss: 0.024798 L1: 0.014318 Grad: 0.104614 Thermal: 0.000361 LR: 9.81e-06\n",
      "Epoch   7 [6300/10697 ( 58.9%)] Loss: 0.025655 L1: 0.014825 Grad: 0.108081 Thermal: 0.000429 LR: 9.81e-06\n",
      "Epoch   7 [6300/10697 ( 58.9%)] Loss: 0.025655 L1: 0.014825 Grad: 0.108081 Thermal: 0.000429 LR: 9.81e-06\n",
      "Epoch   7 [6350/10697 ( 59.4%)] Loss: 0.023648 L1: 0.013866 Grad: 0.097616 Thermal: 0.000394 LR: 9.81e-06\n",
      "Epoch   7 [6350/10697 ( 59.4%)] Loss: 0.023648 L1: 0.013866 Grad: 0.097616 Thermal: 0.000394 LR: 9.81e-06\n",
      "Epoch   7 [6400/10697 ( 59.8%)] Loss: 0.029192 L1: 0.016919 Grad: 0.122461 Thermal: 0.000523 LR: 9.81e-06\n",
      "Epoch   7 [6400/10697 ( 59.8%)] Loss: 0.029192 L1: 0.016919 Grad: 0.122461 Thermal: 0.000523 LR: 9.81e-06\n",
      "Epoch   7 [6450/10697 ( 60.3%)] Loss: 0.028664 L1: 0.016678 Grad: 0.119615 Thermal: 0.000485 LR: 9.81e-06\n",
      "Epoch   7 [6450/10697 ( 60.3%)] Loss: 0.028664 L1: 0.016678 Grad: 0.119615 Thermal: 0.000485 LR: 9.81e-06\n",
      "Epoch   7 [6500/10697 ( 60.8%)] Loss: 0.027761 L1: 0.015929 Grad: 0.118086 Thermal: 0.000475 LR: 9.81e-06\n",
      "Epoch   7 [6500/10697 ( 60.8%)] Loss: 0.027761 L1: 0.015929 Grad: 0.118086 Thermal: 0.000475 LR: 9.81e-06\n",
      "Epoch   7 [6550/10697 ( 61.2%)] Loss: 0.024881 L1: 0.014563 Grad: 0.102968 Thermal: 0.000415 LR: 9.81e-06\n",
      "Epoch   7 [6550/10697 ( 61.2%)] Loss: 0.024881 L1: 0.014563 Grad: 0.102968 Thermal: 0.000415 LR: 9.81e-06\n",
      "Epoch   7 [6600/10697 ( 61.7%)] Loss: 0.025664 L1: 0.015186 Grad: 0.104527 Thermal: 0.000508 LR: 9.81e-06\n",
      "Epoch   7 [6600/10697 ( 61.7%)] Loss: 0.025664 L1: 0.015186 Grad: 0.104527 Thermal: 0.000508 LR: 9.81e-06\n",
      "Epoch   7 [6650/10697 ( 62.2%)] Loss: 0.026689 L1: 0.015856 Grad: 0.108111 Thermal: 0.000443 LR: 9.81e-06\n",
      "Epoch   7 [6650/10697 ( 62.2%)] Loss: 0.026689 L1: 0.015856 Grad: 0.108111 Thermal: 0.000443 LR: 9.81e-06\n",
      "Epoch   7 [6700/10697 ( 62.6%)] Loss: 0.029163 L1: 0.016827 Grad: 0.123093 Thermal: 0.000531 LR: 9.81e-06\n",
      "Epoch   7 [6700/10697 ( 62.6%)] Loss: 0.029163 L1: 0.016827 Grad: 0.123093 Thermal: 0.000531 LR: 9.81e-06\n",
      "Epoch   7 [6750/10697 ( 63.1%)] Loss: 0.028866 L1: 0.017010 Grad: 0.118314 Thermal: 0.000505 LR: 9.81e-06\n",
      "Epoch   7 [6750/10697 ( 63.1%)] Loss: 0.028866 L1: 0.017010 Grad: 0.118314 Thermal: 0.000505 LR: 9.81e-06\n",
      "Epoch   7 [6800/10697 ( 63.6%)] Loss: 0.030757 L1: 0.018312 Grad: 0.124153 Thermal: 0.000596 LR: 9.81e-06\n",
      "Epoch   7 [6800/10697 ( 63.6%)] Loss: 0.030757 L1: 0.018312 Grad: 0.124153 Thermal: 0.000596 LR: 9.81e-06\n",
      "Epoch   7 [6850/10697 ( 64.0%)] Loss: 0.026738 L1: 0.015614 Grad: 0.111023 Thermal: 0.000440 LR: 9.81e-06\n",
      "Epoch   7 [6850/10697 ( 64.0%)] Loss: 0.026738 L1: 0.015614 Grad: 0.111023 Thermal: 0.000440 LR: 9.81e-06\n",
      "Epoch   7 [6900/10697 ( 64.5%)] Loss: 0.028201 L1: 0.016435 Grad: 0.117412 Thermal: 0.000482 LR: 9.81e-06\n",
      "Epoch   7 [6900/10697 ( 64.5%)] Loss: 0.028201 L1: 0.016435 Grad: 0.117412 Thermal: 0.000482 LR: 9.81e-06\n",
      "Epoch   7 [6950/10697 ( 65.0%)] Loss: 0.024555 L1: 0.013920 Grad: 0.106176 Thermal: 0.000352 LR: 9.81e-06\n",
      "Epoch   7 [6950/10697 ( 65.0%)] Loss: 0.024555 L1: 0.013920 Grad: 0.106176 Thermal: 0.000352 LR: 9.81e-06\n",
      "Epoch   7 [7000/10697 ( 65.4%)] Loss: 0.027175 L1: 0.016023 Grad: 0.111272 Thermal: 0.000490 LR: 9.81e-06\n",
      "Epoch   7 [7000/10697 ( 65.4%)] Loss: 0.027175 L1: 0.016023 Grad: 0.111272 Thermal: 0.000490 LR: 9.81e-06\n",
      "Epoch   7 [7050/10697 ( 65.9%)] Loss: 0.028671 L1: 0.016642 Grad: 0.120026 Thermal: 0.000526 LR: 9.81e-06\n",
      "Epoch   7 [7050/10697 ( 65.9%)] Loss: 0.028671 L1: 0.016642 Grad: 0.120026 Thermal: 0.000526 LR: 9.81e-06\n",
      "Epoch   7 [7100/10697 ( 66.4%)] Loss: 0.026754 L1: 0.015512 Grad: 0.112201 Thermal: 0.000443 LR: 9.81e-06\n",
      "Epoch   7 [7100/10697 ( 66.4%)] Loss: 0.026754 L1: 0.015512 Grad: 0.112201 Thermal: 0.000443 LR: 9.81e-06\n",
      "Epoch   7 [7150/10697 ( 66.8%)] Loss: 0.025423 L1: 0.014682 Grad: 0.107193 Thermal: 0.000428 LR: 9.81e-06\n",
      "Epoch   7 [7150/10697 ( 66.8%)] Loss: 0.025423 L1: 0.014682 Grad: 0.107193 Thermal: 0.000428 LR: 9.81e-06\n",
      "Epoch   7 [7200/10697 ( 67.3%)] Loss: 0.028521 L1: 0.016513 Grad: 0.119820 Thermal: 0.000510 LR: 9.81e-06\n",
      "Epoch   7 [7200/10697 ( 67.3%)] Loss: 0.028521 L1: 0.016513 Grad: 0.119820 Thermal: 0.000510 LR: 9.81e-06\n",
      "Epoch   7 [7250/10697 ( 67.8%)] Loss: 0.028766 L1: 0.016727 Grad: 0.120093 Thermal: 0.000587 LR: 9.81e-06\n",
      "Epoch   7 [7250/10697 ( 67.8%)] Loss: 0.028766 L1: 0.016727 Grad: 0.120093 Thermal: 0.000587 LR: 9.81e-06\n",
      "Epoch   7 [7300/10697 ( 68.2%)] Loss: 0.026422 L1: 0.015383 Grad: 0.110184 Thermal: 0.000410 LR: 9.81e-06\n",
      "Epoch   7 [7300/10697 ( 68.2%)] Loss: 0.026422 L1: 0.015383 Grad: 0.110184 Thermal: 0.000410 LR: 9.81e-06\n",
      "Epoch   7 [7350/10697 ( 68.7%)] Loss: 0.026118 L1: 0.015123 Grad: 0.109692 Thermal: 0.000499 LR: 9.81e-06\n",
      "Epoch   7 [7350/10697 ( 68.7%)] Loss: 0.026118 L1: 0.015123 Grad: 0.109692 Thermal: 0.000499 LR: 9.81e-06\n",
      "Epoch   7 [7400/10697 ( 69.2%)] Loss: 0.016983 L1: 0.009578 Grad: 0.073946 Thermal: 0.000205 LR: 9.81e-06\n",
      "Epoch   7 [7400/10697 ( 69.2%)] Loss: 0.016983 L1: 0.009578 Grad: 0.073946 Thermal: 0.000205 LR: 9.81e-06\n",
      "Epoch   7 [7450/10697 ( 69.6%)] Loss: 0.027109 L1: 0.015563 Grad: 0.115225 Thermal: 0.000481 LR: 9.81e-06\n",
      "Epoch   7 [7450/10697 ( 69.6%)] Loss: 0.027109 L1: 0.015563 Grad: 0.115225 Thermal: 0.000481 LR: 9.81e-06\n",
      "Epoch   7 [7500/10697 ( 70.1%)] Loss: 0.025341 L1: 0.015193 Grad: 0.101274 Thermal: 0.000424 LR: 9.81e-06\n",
      "Epoch   7 [7500/10697 ( 70.1%)] Loss: 0.025341 L1: 0.015193 Grad: 0.101274 Thermal: 0.000424 LR: 9.81e-06\n",
      "Epoch   7 [7550/10697 ( 70.6%)] Loss: 0.028012 L1: 0.016472 Grad: 0.115152 Thermal: 0.000506 LR: 9.81e-06\n",
      "Epoch   7 [7550/10697 ( 70.6%)] Loss: 0.028012 L1: 0.016472 Grad: 0.115152 Thermal: 0.000506 LR: 9.81e-06\n",
      "Epoch   7 [7600/10697 ( 71.0%)] Loss: 0.029241 L1: 0.016511 Grad: 0.127036 Thermal: 0.000520 LR: 9.81e-06\n",
      "Epoch   7 [7600/10697 ( 71.0%)] Loss: 0.029241 L1: 0.016511 Grad: 0.127036 Thermal: 0.000520 LR: 9.81e-06\n",
      "Epoch   7 [7650/10697 ( 71.5%)] Loss: 0.028614 L1: 0.016669 Grad: 0.119205 Thermal: 0.000498 LR: 9.81e-06\n",
      "Epoch   7 [7650/10697 ( 71.5%)] Loss: 0.028614 L1: 0.016669 Grad: 0.119205 Thermal: 0.000498 LR: 9.81e-06\n",
      "Epoch   7 [7700/10697 ( 72.0%)] Loss: 0.028155 L1: 0.016839 Grad: 0.112861 Thermal: 0.000590 LR: 9.81e-06\n",
      "Epoch   7 [7700/10697 ( 72.0%)] Loss: 0.028155 L1: 0.016839 Grad: 0.112861 Thermal: 0.000590 LR: 9.81e-06\n",
      "Epoch   7 [7750/10697 ( 72.5%)] Loss: 0.027649 L1: 0.015960 Grad: 0.116638 Thermal: 0.000497 LR: 9.81e-06\n",
      "Epoch   7 [7750/10697 ( 72.5%)] Loss: 0.027649 L1: 0.015960 Grad: 0.116638 Thermal: 0.000497 LR: 9.81e-06\n",
      "Epoch   7 [7800/10697 ( 72.9%)] Loss: 0.028790 L1: 0.016834 Grad: 0.119292 Thermal: 0.000544 LR: 9.81e-06\n",
      "Epoch   7 [7800/10697 ( 72.9%)] Loss: 0.028790 L1: 0.016834 Grad: 0.119292 Thermal: 0.000544 LR: 9.81e-06\n",
      "Epoch   7 [7850/10697 ( 73.4%)] Loss: 0.025022 L1: 0.014991 Grad: 0.100098 Thermal: 0.000435 LR: 9.81e-06\n",
      "Epoch   7 [7850/10697 ( 73.4%)] Loss: 0.025022 L1: 0.014991 Grad: 0.100098 Thermal: 0.000435 LR: 9.81e-06\n",
      "Epoch   7 [7900/10697 ( 73.9%)] Loss: 0.022597 L1: 0.013193 Grad: 0.093843 Thermal: 0.000399 LR: 9.81e-06\n",
      "Epoch   7 [7900/10697 ( 73.9%)] Loss: 0.022597 L1: 0.013193 Grad: 0.093843 Thermal: 0.000399 LR: 9.81e-06\n",
      "Epoch   7 [7950/10697 ( 74.3%)] Loss: 0.027363 L1: 0.015729 Grad: 0.116087 Thermal: 0.000508 LR: 9.81e-06\n",
      "Epoch   7 [7950/10697 ( 74.3%)] Loss: 0.027363 L1: 0.015729 Grad: 0.116087 Thermal: 0.000508 LR: 9.81e-06\n",
      "Epoch   7 [8000/10697 ( 74.8%)] Loss: 0.022785 L1: 0.013460 Grad: 0.093062 Thermal: 0.000364 LR: 9.81e-06\n",
      "Epoch   7 [8000/10697 ( 74.8%)] Loss: 0.022785 L1: 0.013460 Grad: 0.093062 Thermal: 0.000364 LR: 9.81e-06\n",
      "Epoch   7 [8050/10697 ( 75.3%)] Loss: 0.029700 L1: 0.017886 Grad: 0.117869 Thermal: 0.000534 LR: 9.81e-06\n",
      "Epoch   7 [8050/10697 ( 75.3%)] Loss: 0.029700 L1: 0.017886 Grad: 0.117869 Thermal: 0.000534 LR: 9.81e-06\n",
      "Epoch   7 [8100/10697 ( 75.7%)] Loss: 0.027911 L1: 0.016390 Grad: 0.114962 Thermal: 0.000483 LR: 9.81e-06\n",
      "Epoch   7 [8100/10697 ( 75.7%)] Loss: 0.027911 L1: 0.016390 Grad: 0.114962 Thermal: 0.000483 LR: 9.81e-06\n",
      "Epoch   7 [8150/10697 ( 76.2%)] Loss: 0.021284 L1: 0.012226 Grad: 0.090426 Thermal: 0.000310 LR: 9.81e-06\n",
      "Epoch   7 [8150/10697 ( 76.2%)] Loss: 0.021284 L1: 0.012226 Grad: 0.090426 Thermal: 0.000310 LR: 9.81e-06\n",
      "Epoch   7 [8200/10697 ( 76.7%)] Loss: 0.027213 L1: 0.015895 Grad: 0.112953 Thermal: 0.000458 LR: 9.81e-06\n",
      "Epoch   7 [8200/10697 ( 76.7%)] Loss: 0.027213 L1: 0.015895 Grad: 0.112953 Thermal: 0.000458 LR: 9.81e-06\n",
      "Epoch   7 [8250/10697 ( 77.1%)] Loss: 0.028268 L1: 0.016678 Grad: 0.115645 Thermal: 0.000516 LR: 9.81e-06\n",
      "Epoch   7 [8250/10697 ( 77.1%)] Loss: 0.028268 L1: 0.016678 Grad: 0.115645 Thermal: 0.000516 LR: 9.81e-06\n",
      "Epoch   7 [8300/10697 ( 77.6%)] Loss: 0.024171 L1: 0.013825 Grad: 0.103268 Thermal: 0.000367 LR: 9.81e-06\n",
      "Epoch   7 [8300/10697 ( 77.6%)] Loss: 0.024171 L1: 0.013825 Grad: 0.103268 Thermal: 0.000367 LR: 9.81e-06\n",
      "Epoch   7 [8350/10697 ( 78.1%)] Loss: 0.022176 L1: 0.013263 Grad: 0.088942 Thermal: 0.000380 LR: 9.81e-06\n",
      "Epoch   7 [8350/10697 ( 78.1%)] Loss: 0.022176 L1: 0.013263 Grad: 0.088942 Thermal: 0.000380 LR: 9.81e-06\n",
      "Epoch   7 [8400/10697 ( 78.5%)] Loss: 0.022991 L1: 0.013817 Grad: 0.091545 Thermal: 0.000397 LR: 9.81e-06\n",
      "Epoch   7 [8400/10697 ( 78.5%)] Loss: 0.022991 L1: 0.013817 Grad: 0.091545 Thermal: 0.000397 LR: 9.81e-06\n",
      "Epoch   7 [8450/10697 ( 79.0%)] Loss: 0.021725 L1: 0.012500 Grad: 0.092103 Thermal: 0.000300 LR: 9.81e-06\n",
      "Epoch   7 [8450/10697 ( 79.0%)] Loss: 0.021725 L1: 0.012500 Grad: 0.092103 Thermal: 0.000300 LR: 9.81e-06\n",
      "Epoch   7 [8500/10697 ( 79.5%)] Loss: 0.028995 L1: 0.017155 Grad: 0.118122 Thermal: 0.000546 LR: 9.81e-06\n",
      "Epoch   7 [8500/10697 ( 79.5%)] Loss: 0.028995 L1: 0.017155 Grad: 0.118122 Thermal: 0.000546 LR: 9.81e-06\n",
      "Epoch   7 [8550/10697 ( 79.9%)] Loss: 0.029362 L1: 0.017558 Grad: 0.117767 Thermal: 0.000540 LR: 9.81e-06\n",
      "Epoch   7 [8550/10697 ( 79.9%)] Loss: 0.029362 L1: 0.017558 Grad: 0.117767 Thermal: 0.000540 LR: 9.81e-06\n",
      "Epoch   7 [8600/10697 ( 80.4%)] Loss: 0.023733 L1: 0.013964 Grad: 0.097493 Thermal: 0.000405 LR: 9.81e-06\n",
      "Epoch   7 [8600/10697 ( 80.4%)] Loss: 0.023733 L1: 0.013964 Grad: 0.097493 Thermal: 0.000405 LR: 9.81e-06\n",
      "Epoch   7 [8650/10697 ( 80.9%)] Loss: 0.028700 L1: 0.017039 Grad: 0.116351 Thermal: 0.000508 LR: 9.81e-06\n",
      "Epoch   7 [8650/10697 ( 80.9%)] Loss: 0.028700 L1: 0.017039 Grad: 0.116351 Thermal: 0.000508 LR: 9.81e-06\n",
      "Epoch   7 [8700/10697 ( 81.3%)] Loss: 0.028146 L1: 0.016390 Grad: 0.117290 Thermal: 0.000532 LR: 9.81e-06\n",
      "Epoch   7 [8700/10697 ( 81.3%)] Loss: 0.028146 L1: 0.016390 Grad: 0.117290 Thermal: 0.000532 LR: 9.81e-06\n",
      "Epoch   7 [8750/10697 ( 81.8%)] Loss: 0.025371 L1: 0.014654 Grad: 0.106953 Thermal: 0.000438 LR: 9.81e-06\n",
      "Epoch   7 [8750/10697 ( 81.8%)] Loss: 0.025371 L1: 0.014654 Grad: 0.106953 Thermal: 0.000438 LR: 9.81e-06\n",
      "Epoch   7 [8800/10697 ( 82.3%)] Loss: 0.027193 L1: 0.015365 Grad: 0.118048 Thermal: 0.000470 LR: 9.81e-06\n",
      "Epoch   7 [8800/10697 ( 82.3%)] Loss: 0.027193 L1: 0.015365 Grad: 0.118048 Thermal: 0.000470 LR: 9.81e-06\n",
      "Epoch   7 [8850/10697 ( 82.7%)] Loss: 0.037096 L1: 0.021284 Grad: 0.157657 Thermal: 0.000927 LR: 9.81e-06\n",
      "Epoch   7 [8850/10697 ( 82.7%)] Loss: 0.037096 L1: 0.021284 Grad: 0.157657 Thermal: 0.000927 LR: 9.81e-06\n",
      "Epoch   7 [8900/10697 ( 83.2%)] Loss: 0.026115 L1: 0.014970 Grad: 0.111234 Thermal: 0.000419 LR: 9.81e-06\n",
      "Epoch   7 [8900/10697 ( 83.2%)] Loss: 0.026115 L1: 0.014970 Grad: 0.111234 Thermal: 0.000419 LR: 9.81e-06\n",
      "Epoch   7 [8950/10697 ( 83.7%)] Loss: 0.022385 L1: 0.013018 Grad: 0.093485 Thermal: 0.000370 LR: 9.81e-06\n",
      "Epoch   7 [8950/10697 ( 83.7%)] Loss: 0.022385 L1: 0.013018 Grad: 0.093485 Thermal: 0.000370 LR: 9.81e-06\n",
      "Epoch   7 [9000/10697 ( 84.1%)] Loss: 0.029426 L1: 0.016508 Grad: 0.128904 Thermal: 0.000563 LR: 9.81e-06\n",
      "Epoch   7 [9000/10697 ( 84.1%)] Loss: 0.029426 L1: 0.016508 Grad: 0.128904 Thermal: 0.000563 LR: 9.81e-06\n",
      "Epoch   7 [9050/10697 ( 84.6%)] Loss: 0.025670 L1: 0.014937 Grad: 0.107094 Thermal: 0.000456 LR: 9.81e-06\n",
      "Epoch   7 [9050/10697 ( 84.6%)] Loss: 0.025670 L1: 0.014937 Grad: 0.107094 Thermal: 0.000456 LR: 9.81e-06\n",
      "Epoch   7 [9100/10697 ( 85.1%)] Loss: 0.019539 L1: 0.011232 Grad: 0.082941 Thermal: 0.000261 LR: 9.81e-06\n",
      "Epoch   7 [9100/10697 ( 85.1%)] Loss: 0.019539 L1: 0.011232 Grad: 0.082941 Thermal: 0.000261 LR: 9.81e-06\n",
      "Epoch   7 [9150/10697 ( 85.5%)] Loss: 0.026183 L1: 0.014962 Grad: 0.111972 Thermal: 0.000481 LR: 9.81e-06\n",
      "Epoch   7 [9150/10697 ( 85.5%)] Loss: 0.026183 L1: 0.014962 Grad: 0.111972 Thermal: 0.000481 LR: 9.81e-06\n",
      "Epoch   7 [9200/10697 ( 86.0%)] Loss: 0.025975 L1: 0.015101 Grad: 0.108510 Thermal: 0.000455 LR: 9.81e-06\n",
      "Epoch   7 [9200/10697 ( 86.0%)] Loss: 0.025975 L1: 0.015101 Grad: 0.108510 Thermal: 0.000455 LR: 9.81e-06\n",
      "Epoch   7 [9250/10697 ( 86.5%)] Loss: 0.023522 L1: 0.013555 Grad: 0.099482 Thermal: 0.000369 LR: 9.81e-06\n",
      "Epoch   7 [9250/10697 ( 86.5%)] Loss: 0.023522 L1: 0.013555 Grad: 0.099482 Thermal: 0.000369 LR: 9.81e-06\n",
      "Epoch   7 [9300/10697 ( 86.9%)] Loss: 0.021876 L1: 0.013045 Grad: 0.088152 Thermal: 0.000333 LR: 9.81e-06\n",
      "Epoch   7 [9300/10697 ( 86.9%)] Loss: 0.021876 L1: 0.013045 Grad: 0.088152 Thermal: 0.000333 LR: 9.81e-06\n",
      "Epoch   7 [9350/10697 ( 87.4%)] Loss: 0.028490 L1: 0.016054 Grad: 0.124099 Thermal: 0.000528 LR: 9.81e-06\n",
      "Epoch   7 [9350/10697 ( 87.4%)] Loss: 0.028490 L1: 0.016054 Grad: 0.124099 Thermal: 0.000528 LR: 9.81e-06\n",
      "Epoch   7 [9400/10697 ( 87.9%)] Loss: 0.026872 L1: 0.015610 Grad: 0.112412 Thermal: 0.000425 LR: 9.81e-06\n",
      "Epoch   7 [9400/10697 ( 87.9%)] Loss: 0.026872 L1: 0.015610 Grad: 0.112412 Thermal: 0.000425 LR: 9.81e-06\n",
      "Epoch   7 [9450/10697 ( 88.3%)] Loss: 0.026015 L1: 0.014619 Grad: 0.113758 Thermal: 0.000408 LR: 9.81e-06\n",
      "Epoch   7 [9450/10697 ( 88.3%)] Loss: 0.026015 L1: 0.014619 Grad: 0.113758 Thermal: 0.000408 LR: 9.81e-06\n",
      "Epoch   7 [9500/10697 ( 88.8%)] Loss: 0.027034 L1: 0.015977 Grad: 0.110328 Thermal: 0.000483 LR: 9.81e-06\n",
      "Epoch   7 [9500/10697 ( 88.8%)] Loss: 0.027034 L1: 0.015977 Grad: 0.110328 Thermal: 0.000483 LR: 9.81e-06\n",
      "Epoch   7 [9550/10697 ( 89.3%)] Loss: 0.027428 L1: 0.016031 Grad: 0.113717 Thermal: 0.000510 LR: 9.81e-06\n",
      "Epoch   7 [9550/10697 ( 89.3%)] Loss: 0.027428 L1: 0.016031 Grad: 0.113717 Thermal: 0.000510 LR: 9.81e-06\n",
      "Epoch   7 [9600/10697 ( 89.7%)] Loss: 0.029831 L1: 0.017298 Grad: 0.125044 Thermal: 0.000582 LR: 9.81e-06\n",
      "Epoch   7 [9600/10697 ( 89.7%)] Loss: 0.029831 L1: 0.017298 Grad: 0.125044 Thermal: 0.000582 LR: 9.81e-06\n",
      "Epoch   7 [9650/10697 ( 90.2%)] Loss: 0.026633 L1: 0.015684 Grad: 0.109263 Thermal: 0.000456 LR: 9.81e-06\n",
      "Epoch   7 [9650/10697 ( 90.2%)] Loss: 0.026633 L1: 0.015684 Grad: 0.109263 Thermal: 0.000456 LR: 9.81e-06\n",
      "Epoch   7 [9700/10697 ( 90.7%)] Loss: 0.023429 L1: 0.013616 Grad: 0.097958 Thermal: 0.000329 LR: 9.81e-06\n",
      "Epoch   7 [9700/10697 ( 90.7%)] Loss: 0.023429 L1: 0.013616 Grad: 0.097958 Thermal: 0.000329 LR: 9.81e-06\n",
      "Epoch   7 [9750/10697 ( 91.1%)] Loss: 0.024872 L1: 0.014702 Grad: 0.101488 Thermal: 0.000429 LR: 9.81e-06\n",
      "Epoch   7 [9750/10697 ( 91.1%)] Loss: 0.024872 L1: 0.014702 Grad: 0.101488 Thermal: 0.000429 LR: 9.81e-06\n",
      "Epoch   7 [9800/10697 ( 91.6%)] Loss: 0.025026 L1: 0.014630 Grad: 0.103750 Thermal: 0.000415 LR: 9.81e-06\n",
      "Epoch   7 [9800/10697 ( 91.6%)] Loss: 0.025026 L1: 0.014630 Grad: 0.103750 Thermal: 0.000415 LR: 9.81e-06\n",
      "Epoch   7 [9850/10697 ( 92.1%)] Loss: 0.037803 L1: 0.021083 Grad: 0.166813 Thermal: 0.000767 LR: 9.81e-06\n",
      "Epoch   7 [9850/10697 ( 92.1%)] Loss: 0.037803 L1: 0.021083 Grad: 0.166813 Thermal: 0.000767 LR: 9.81e-06\n",
      "Epoch   7 [9900/10697 ( 92.5%)] Loss: 0.031676 L1: 0.018363 Grad: 0.132802 Thermal: 0.000648 LR: 9.81e-06\n",
      "Epoch   7 [9900/10697 ( 92.5%)] Loss: 0.031676 L1: 0.018363 Grad: 0.132802 Thermal: 0.000648 LR: 9.81e-06\n",
      "Epoch   7 [9950/10697 ( 93.0%)] Loss: 0.030628 L1: 0.017541 Grad: 0.130612 Thermal: 0.000511 LR: 9.81e-06\n",
      "Epoch   7 [9950/10697 ( 93.0%)] Loss: 0.030628 L1: 0.017541 Grad: 0.130612 Thermal: 0.000511 LR: 9.81e-06\n",
      "Epoch   7 [10000/10697 ( 93.5%)] Loss: 0.027035 L1: 0.015378 Grad: 0.116324 Thermal: 0.000484 LR: 9.81e-06\n",
      "Epoch   7 [10000/10697 ( 93.5%)] Loss: 0.027035 L1: 0.015378 Grad: 0.116324 Thermal: 0.000484 LR: 9.81e-06\n",
      "Epoch   7 [10050/10697 ( 94.0%)] Loss: 0.025880 L1: 0.015300 Grad: 0.105589 Thermal: 0.000417 LR: 9.81e-06\n",
      "Epoch   7 [10050/10697 ( 94.0%)] Loss: 0.025880 L1: 0.015300 Grad: 0.105589 Thermal: 0.000417 LR: 9.81e-06\n",
      "Epoch   7 [10100/10697 ( 94.4%)] Loss: 0.030180 L1: 0.018070 Grad: 0.120777 Thermal: 0.000651 LR: 9.81e-06\n",
      "Epoch   7 [10100/10697 ( 94.4%)] Loss: 0.030180 L1: 0.018070 Grad: 0.120777 Thermal: 0.000651 LR: 9.81e-06\n",
      "Epoch   7 [10150/10697 ( 94.9%)] Loss: 0.038252 L1: 0.022217 Grad: 0.159842 Thermal: 0.001013 LR: 9.81e-06\n",
      "Epoch   7 [10150/10697 ( 94.9%)] Loss: 0.038252 L1: 0.022217 Grad: 0.159842 Thermal: 0.001013 LR: 9.81e-06\n",
      "Epoch   7 [10200/10697 ( 95.4%)] Loss: 0.028744 L1: 0.016309 Grad: 0.124050 Thermal: 0.000596 LR: 9.81e-06\n",
      "Epoch   7 [10200/10697 ( 95.4%)] Loss: 0.028744 L1: 0.016309 Grad: 0.124050 Thermal: 0.000596 LR: 9.81e-06\n",
      "Epoch   7 [10250/10697 ( 95.8%)] Loss: 0.023059 L1: 0.013318 Grad: 0.097234 Thermal: 0.000356 LR: 9.81e-06\n",
      "Epoch   7 [10250/10697 ( 95.8%)] Loss: 0.023059 L1: 0.013318 Grad: 0.097234 Thermal: 0.000356 LR: 9.81e-06\n",
      "Epoch   7 [10300/10697 ( 96.3%)] Loss: 0.037258 L1: 0.021066 Grad: 0.161431 Thermal: 0.000981 LR: 9.81e-06\n",
      "Epoch   7 [10300/10697 ( 96.3%)] Loss: 0.037258 L1: 0.021066 Grad: 0.161431 Thermal: 0.000981 LR: 9.81e-06\n",
      "Epoch   7 [10350/10697 ( 96.8%)] Loss: 0.025786 L1: 0.014660 Grad: 0.111054 Thermal: 0.000417 LR: 9.81e-06\n",
      "Epoch   7 [10350/10697 ( 96.8%)] Loss: 0.025786 L1: 0.014660 Grad: 0.111054 Thermal: 0.000417 LR: 9.81e-06\n",
      "Epoch   7 [10400/10697 ( 97.2%)] Loss: 0.027318 L1: 0.016065 Grad: 0.112296 Thermal: 0.000465 LR: 9.81e-06\n",
      "Epoch   7 [10400/10697 ( 97.2%)] Loss: 0.027318 L1: 0.016065 Grad: 0.112296 Thermal: 0.000465 LR: 9.81e-06\n",
      "Epoch   7 [10450/10697 ( 97.7%)] Loss: 0.027304 L1: 0.015972 Grad: 0.113083 Thermal: 0.000484 LR: 9.81e-06\n",
      "Epoch   7 [10450/10697 ( 97.7%)] Loss: 0.027304 L1: 0.015972 Grad: 0.113083 Thermal: 0.000484 LR: 9.81e-06\n",
      "Epoch   7 [10500/10697 ( 98.2%)] Loss: 0.024583 L1: 0.014057 Grad: 0.105062 Thermal: 0.000406 LR: 9.81e-06\n",
      "Epoch   7 [10500/10697 ( 98.2%)] Loss: 0.024583 L1: 0.014057 Grad: 0.105062 Thermal: 0.000406 LR: 9.81e-06\n",
      "Epoch   7 [10550/10697 ( 98.6%)] Loss: 0.030719 L1: 0.017779 Grad: 0.129113 Thermal: 0.000579 LR: 9.81e-06\n",
      "Epoch   7 [10550/10697 ( 98.6%)] Loss: 0.030719 L1: 0.017779 Grad: 0.129113 Thermal: 0.000579 LR: 9.81e-06\n",
      "Epoch   7 [10600/10697 ( 99.1%)] Loss: 0.029143 L1: 0.016893 Grad: 0.122201 Thermal: 0.000600 LR: 9.81e-06\n",
      "Epoch   7 [10600/10697 ( 99.1%)] Loss: 0.029143 L1: 0.016893 Grad: 0.122201 Thermal: 0.000600 LR: 9.81e-06\n",
      "Epoch   7 [10650/10697 ( 99.6%)] Loss: 0.024113 L1: 0.013683 Grad: 0.104094 Thermal: 0.000396 LR: 9.81e-06\n",
      "Epoch   7 [10650/10697 ( 99.6%)] Loss: 0.024113 L1: 0.013683 Grad: 0.104094 Thermal: 0.000396 LR: 9.81e-06\n",
      "Epoch   7 Summary: Loss=0.026815 (L1:0.0156, Grad:0.1118, Thermal:0.0005) Val_PSNR=0.00dB Best=33.75dB Time=28.7min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch   7 Summary: Loss=0.026815 (L1:0.0156, Grad:0.1118, Thermal:0.0005) Val_PSNR=0.00dB Best=33.75dB Time=28.7min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch   8 [   0/10697 (  0.0%)] Loss: 0.030587 L1: 0.017441 Grad: 0.131167 Thermal: 0.000595 LR: 9.76e-06\n",
      "Epoch   8 [   0/10697 (  0.0%)] Loss: 0.030587 L1: 0.017441 Grad: 0.131167 Thermal: 0.000595 LR: 9.76e-06\n",
      "Epoch   8 [  50/10697 (  0.5%)] Loss: 0.026905 L1: 0.016058 Grad: 0.108228 Thermal: 0.000471 LR: 9.76e-06\n",
      "Epoch   8 [  50/10697 (  0.5%)] Loss: 0.026905 L1: 0.016058 Grad: 0.108228 Thermal: 0.000471 LR: 9.76e-06\n",
      "Epoch   8 [ 100/10697 (  0.9%)] Loss: 0.026710 L1: 0.015954 Grad: 0.107331 Thermal: 0.000465 LR: 9.76e-06\n",
      "Epoch   8 [ 100/10697 (  0.9%)] Loss: 0.026710 L1: 0.015954 Grad: 0.107331 Thermal: 0.000465 LR: 9.76e-06\n",
      "Epoch   8 [ 150/10697 (  1.4%)] Loss: 0.028951 L1: 0.016496 Grad: 0.124277 Thermal: 0.000552 LR: 9.76e-06\n",
      "Epoch   8 [ 150/10697 (  1.4%)] Loss: 0.028951 L1: 0.016496 Grad: 0.124277 Thermal: 0.000552 LR: 9.76e-06\n",
      "Epoch   8 [ 200/10697 (  1.9%)] Loss: 0.028204 L1: 0.016088 Grad: 0.120873 Thermal: 0.000583 LR: 9.76e-06\n",
      "Epoch   8 [ 200/10697 (  1.9%)] Loss: 0.028204 L1: 0.016088 Grad: 0.120873 Thermal: 0.000583 LR: 9.76e-06\n",
      "Epoch   8 [ 250/10697 (  2.3%)] Loss: 0.023224 L1: 0.013293 Grad: 0.099119 Thermal: 0.000379 LR: 9.76e-06\n",
      "Epoch   8 [ 250/10697 (  2.3%)] Loss: 0.023224 L1: 0.013293 Grad: 0.099119 Thermal: 0.000379 LR: 9.76e-06\n",
      "Epoch   8 [ 300/10697 (  2.8%)] Loss: 0.033205 L1: 0.019010 Grad: 0.141566 Thermal: 0.000764 LR: 9.76e-06\n",
      "Epoch   8 [ 300/10697 (  2.8%)] Loss: 0.033205 L1: 0.019010 Grad: 0.141566 Thermal: 0.000764 LR: 9.76e-06\n",
      "Epoch   8 [ 350/10697 (  3.3%)] Loss: 0.033365 L1: 0.019275 Grad: 0.140530 Thermal: 0.000736 LR: 9.76e-06\n",
      "Epoch   8 [ 350/10697 (  3.3%)] Loss: 0.033365 L1: 0.019275 Grad: 0.140530 Thermal: 0.000736 LR: 9.76e-06\n",
      "Epoch   8 [ 400/10697 (  3.7%)] Loss: 0.033884 L1: 0.019641 Grad: 0.142078 Thermal: 0.000713 LR: 9.76e-06\n",
      "Epoch   8 [ 400/10697 (  3.7%)] Loss: 0.033884 L1: 0.019641 Grad: 0.142078 Thermal: 0.000713 LR: 9.76e-06\n",
      "Epoch   8 [ 450/10697 (  4.2%)] Loss: 0.029558 L1: 0.017307 Grad: 0.122224 Thermal: 0.000560 LR: 9.76e-06\n",
      "Epoch   8 [ 450/10697 (  4.2%)] Loss: 0.029558 L1: 0.017307 Grad: 0.122224 Thermal: 0.000560 LR: 9.76e-06\n",
      "Epoch   8 [ 500/10697 (  4.7%)] Loss: 0.031984 L1: 0.018394 Grad: 0.135579 Thermal: 0.000641 LR: 9.76e-06\n",
      "Epoch   8 [ 500/10697 (  4.7%)] Loss: 0.031984 L1: 0.018394 Grad: 0.135579 Thermal: 0.000641 LR: 9.76e-06\n",
      "Epoch   8 [ 550/10697 (  5.1%)] Loss: 0.027088 L1: 0.015506 Grad: 0.115592 Thermal: 0.000457 LR: 9.76e-06\n",
      "Epoch   8 [ 550/10697 (  5.1%)] Loss: 0.027088 L1: 0.015506 Grad: 0.115592 Thermal: 0.000457 LR: 9.76e-06\n",
      "Epoch   8 [ 600/10697 (  5.6%)] Loss: 0.028028 L1: 0.016957 Grad: 0.110442 Thermal: 0.000541 LR: 9.76e-06\n",
      "Epoch   8 [ 600/10697 (  5.6%)] Loss: 0.028028 L1: 0.016957 Grad: 0.110442 Thermal: 0.000541 LR: 9.76e-06\n",
      "Epoch   8 [ 650/10697 (  6.1%)] Loss: 0.027836 L1: 0.016769 Grad: 0.110418 Thermal: 0.000503 LR: 9.76e-06\n",
      "Epoch   8 [ 650/10697 (  6.1%)] Loss: 0.027836 L1: 0.016769 Grad: 0.110418 Thermal: 0.000503 LR: 9.76e-06\n",
      "Epoch   8 [ 700/10697 (  6.5%)] Loss: 0.024366 L1: 0.013929 Grad: 0.104166 Thermal: 0.000403 LR: 9.76e-06\n",
      "Epoch   8 [ 700/10697 (  6.5%)] Loss: 0.024366 L1: 0.013929 Grad: 0.104166 Thermal: 0.000403 LR: 9.76e-06\n",
      "Epoch   8 [ 750/10697 (  7.0%)] Loss: 0.026000 L1: 0.015323 Grad: 0.106534 Thermal: 0.000469 LR: 9.76e-06\n",
      "Epoch   8 [ 750/10697 (  7.0%)] Loss: 0.026000 L1: 0.015323 Grad: 0.106534 Thermal: 0.000469 LR: 9.76e-06\n",
      "Epoch   8 [ 800/10697 (  7.5%)] Loss: 0.025924 L1: 0.014756 Grad: 0.111465 Thermal: 0.000414 LR: 9.76e-06\n",
      "Epoch   8 [ 800/10697 (  7.5%)] Loss: 0.025924 L1: 0.014756 Grad: 0.111465 Thermal: 0.000414 LR: 9.76e-06\n",
      "Epoch   8 [ 850/10697 (  7.9%)] Loss: 0.026652 L1: 0.015836 Grad: 0.107924 Thermal: 0.000466 LR: 9.76e-06\n",
      "Epoch   8 [ 850/10697 (  7.9%)] Loss: 0.026652 L1: 0.015836 Grad: 0.107924 Thermal: 0.000466 LR: 9.76e-06\n",
      "Epoch   8 [ 900/10697 (  8.4%)] Loss: 0.019579 L1: 0.010894 Grad: 0.086713 Thermal: 0.000276 LR: 9.76e-06\n",
      "Epoch   8 [ 900/10697 (  8.4%)] Loss: 0.019579 L1: 0.010894 Grad: 0.086713 Thermal: 0.000276 LR: 9.76e-06\n",
      "Epoch   8 [ 950/10697 (  8.9%)] Loss: 0.027514 L1: 0.016296 Grad: 0.111949 Thermal: 0.000461 LR: 9.76e-06\n",
      "Epoch   8 [ 950/10697 (  8.9%)] Loss: 0.027514 L1: 0.016296 Grad: 0.111949 Thermal: 0.000461 LR: 9.76e-06\n",
      "Epoch   8 [1000/10697 (  9.3%)] Loss: 0.027106 L1: 0.015819 Grad: 0.112601 Thermal: 0.000553 LR: 9.76e-06\n",
      "Epoch   8 [1000/10697 (  9.3%)] Loss: 0.027106 L1: 0.015819 Grad: 0.112601 Thermal: 0.000553 LR: 9.76e-06\n",
      "Epoch   8 [1050/10697 (  9.8%)] Loss: 0.031472 L1: 0.018398 Grad: 0.130443 Thermal: 0.000590 LR: 9.76e-06\n",
      "Epoch   8 [1050/10697 (  9.8%)] Loss: 0.031472 L1: 0.018398 Grad: 0.130443 Thermal: 0.000590 LR: 9.76e-06\n",
      "Epoch   8 [1100/10697 ( 10.3%)] Loss: 0.022358 L1: 0.013077 Grad: 0.092629 Thermal: 0.000365 LR: 9.76e-06\n",
      "Epoch   8 [1100/10697 ( 10.3%)] Loss: 0.022358 L1: 0.013077 Grad: 0.092629 Thermal: 0.000365 LR: 9.76e-06\n",
      "Epoch   8 [1150/10697 ( 10.8%)] Loss: 0.024076 L1: 0.014285 Grad: 0.097712 Thermal: 0.000384 LR: 9.76e-06\n",
      "Epoch   8 [1150/10697 ( 10.8%)] Loss: 0.024076 L1: 0.014285 Grad: 0.097712 Thermal: 0.000384 LR: 9.76e-06\n",
      "Epoch   8 [1200/10697 ( 11.2%)] Loss: 0.026605 L1: 0.015532 Grad: 0.110491 Thermal: 0.000494 LR: 9.76e-06\n",
      "Epoch   8 [1200/10697 ( 11.2%)] Loss: 0.026605 L1: 0.015532 Grad: 0.110491 Thermal: 0.000494 LR: 9.76e-06\n",
      "Epoch   8 [1250/10697 ( 11.7%)] Loss: 0.025608 L1: 0.014886 Grad: 0.107008 Thermal: 0.000429 LR: 9.76e-06\n",
      "Epoch   8 [1250/10697 ( 11.7%)] Loss: 0.025608 L1: 0.014886 Grad: 0.107008 Thermal: 0.000429 LR: 9.76e-06\n",
      "Epoch   8 [1300/10697 ( 12.2%)] Loss: 0.031184 L1: 0.017360 Grad: 0.137929 Thermal: 0.000634 LR: 9.76e-06\n",
      "Epoch   8 [1300/10697 ( 12.2%)] Loss: 0.031184 L1: 0.017360 Grad: 0.137929 Thermal: 0.000634 LR: 9.76e-06\n",
      "Epoch   8 [1350/10697 ( 12.6%)] Loss: 0.032106 L1: 0.018664 Grad: 0.134090 Thermal: 0.000677 LR: 9.76e-06\n",
      "Epoch   8 [1350/10697 ( 12.6%)] Loss: 0.032106 L1: 0.018664 Grad: 0.134090 Thermal: 0.000677 LR: 9.76e-06\n",
      "Epoch   8 [1400/10697 ( 13.1%)] Loss: 0.030057 L1: 0.017760 Grad: 0.122690 Thermal: 0.000558 LR: 9.76e-06\n",
      "Epoch   8 [1400/10697 ( 13.1%)] Loss: 0.030057 L1: 0.017760 Grad: 0.122690 Thermal: 0.000558 LR: 9.76e-06\n",
      "Epoch   8 [1450/10697 ( 13.6%)] Loss: 0.028316 L1: 0.016521 Grad: 0.117687 Thermal: 0.000534 LR: 9.76e-06\n",
      "Epoch   8 [1450/10697 ( 13.6%)] Loss: 0.028316 L1: 0.016521 Grad: 0.117687 Thermal: 0.000534 LR: 9.76e-06\n",
      "Epoch   8 [1500/10697 ( 14.0%)] Loss: 0.025964 L1: 0.015215 Grad: 0.107248 Thermal: 0.000492 LR: 9.76e-06\n",
      "Epoch   8 [1500/10697 ( 14.0%)] Loss: 0.025964 L1: 0.015215 Grad: 0.107248 Thermal: 0.000492 LR: 9.76e-06\n",
      "Epoch   8 [1550/10697 ( 14.5%)] Loss: 0.022130 L1: 0.012966 Grad: 0.091467 Thermal: 0.000354 LR: 9.76e-06\n",
      "Epoch   8 [1550/10697 ( 14.5%)] Loss: 0.022130 L1: 0.012966 Grad: 0.091467 Thermal: 0.000354 LR: 9.76e-06\n",
      "Epoch   8 [1600/10697 ( 15.0%)] Loss: 0.022056 L1: 0.013125 Grad: 0.089135 Thermal: 0.000338 LR: 9.76e-06\n",
      "Epoch   8 [1600/10697 ( 15.0%)] Loss: 0.022056 L1: 0.013125 Grad: 0.089135 Thermal: 0.000338 LR: 9.76e-06\n",
      "Epoch   8 [1650/10697 ( 15.4%)] Loss: 0.024446 L1: 0.014551 Grad: 0.098762 Thermal: 0.000386 LR: 9.76e-06\n",
      "Epoch   8 [1650/10697 ( 15.4%)] Loss: 0.024446 L1: 0.014551 Grad: 0.098762 Thermal: 0.000386 LR: 9.76e-06\n",
      "Epoch   8 [1700/10697 ( 15.9%)] Loss: 0.027019 L1: 0.015714 Grad: 0.112808 Thermal: 0.000473 LR: 9.76e-06\n",
      "Epoch   8 [1700/10697 ( 15.9%)] Loss: 0.027019 L1: 0.015714 Grad: 0.112808 Thermal: 0.000473 LR: 9.76e-06\n",
      "Epoch   8 [1750/10697 ( 16.4%)] Loss: 0.025676 L1: 0.015025 Grad: 0.106309 Thermal: 0.000405 LR: 9.76e-06\n",
      "Epoch   8 [1750/10697 ( 16.4%)] Loss: 0.025676 L1: 0.015025 Grad: 0.106309 Thermal: 0.000405 LR: 9.76e-06\n",
      "Epoch   8 [1800/10697 ( 16.8%)] Loss: 0.024858 L1: 0.014724 Grad: 0.101135 Thermal: 0.000402 LR: 9.76e-06\n",
      "Epoch   8 [1800/10697 ( 16.8%)] Loss: 0.024858 L1: 0.014724 Grad: 0.101135 Thermal: 0.000402 LR: 9.76e-06\n",
      "Epoch   8 [1850/10697 ( 17.3%)] Loss: 0.023757 L1: 0.014087 Grad: 0.096499 Thermal: 0.000393 LR: 9.76e-06\n",
      "Epoch   8 [1850/10697 ( 17.3%)] Loss: 0.023757 L1: 0.014087 Grad: 0.096499 Thermal: 0.000393 LR: 9.76e-06\n",
      "Epoch   8 [1900/10697 ( 17.8%)] Loss: 0.027841 L1: 0.015971 Grad: 0.118452 Thermal: 0.000495 LR: 9.76e-06\n",
      "Epoch   8 [1900/10697 ( 17.8%)] Loss: 0.027841 L1: 0.015971 Grad: 0.118452 Thermal: 0.000495 LR: 9.76e-06\n",
      "Epoch   8 [1950/10697 ( 18.2%)] Loss: 0.022427 L1: 0.012829 Grad: 0.095816 Thermal: 0.000335 LR: 9.76e-06\n",
      "Epoch   8 [1950/10697 ( 18.2%)] Loss: 0.022427 L1: 0.012829 Grad: 0.095816 Thermal: 0.000335 LR: 9.76e-06\n",
      "Epoch   8 [2000/10697 ( 18.7%)] Loss: 0.031121 L1: 0.018127 Grad: 0.129638 Thermal: 0.000606 LR: 9.76e-06\n",
      "Epoch   8 [2000/10697 ( 18.7%)] Loss: 0.031121 L1: 0.018127 Grad: 0.129638 Thermal: 0.000606 LR: 9.76e-06\n",
      "Epoch   8 [2050/10697 ( 19.2%)] Loss: 0.025455 L1: 0.014620 Grad: 0.108137 Thermal: 0.000428 LR: 9.76e-06\n",
      "Epoch   8 [2050/10697 ( 19.2%)] Loss: 0.025455 L1: 0.014620 Grad: 0.108137 Thermal: 0.000428 LR: 9.76e-06\n",
      "Epoch   8 [2100/10697 ( 19.6%)] Loss: 0.029949 L1: 0.017875 Grad: 0.120413 Thermal: 0.000639 LR: 9.76e-06\n",
      "Epoch   8 [2100/10697 ( 19.6%)] Loss: 0.029949 L1: 0.017875 Grad: 0.120413 Thermal: 0.000639 LR: 9.76e-06\n",
      "Epoch   8 [2150/10697 ( 20.1%)] Loss: 0.029089 L1: 0.017129 Grad: 0.119344 Thermal: 0.000513 LR: 9.76e-06\n",
      "Epoch   8 [2150/10697 ( 20.1%)] Loss: 0.029089 L1: 0.017129 Grad: 0.119344 Thermal: 0.000513 LR: 9.76e-06\n",
      "Epoch   8 [2200/10697 ( 20.6%)] Loss: 0.028291 L1: 0.016200 Grad: 0.120602 Thermal: 0.000604 LR: 9.76e-06\n",
      "Epoch   8 [2200/10697 ( 20.6%)] Loss: 0.028291 L1: 0.016200 Grad: 0.120602 Thermal: 0.000604 LR: 9.76e-06\n",
      "Epoch   8 [2250/10697 ( 21.0%)] Loss: 0.029166 L1: 0.017489 Grad: 0.116489 Thermal: 0.000563 LR: 9.76e-06\n",
      "Epoch   8 [2250/10697 ( 21.0%)] Loss: 0.029166 L1: 0.017489 Grad: 0.116489 Thermal: 0.000563 LR: 9.76e-06\n",
      "Epoch   8 [2300/10697 ( 21.5%)] Loss: 0.028884 L1: 0.016794 Grad: 0.120647 Thermal: 0.000501 LR: 9.76e-06\n",
      "Epoch   8 [2300/10697 ( 21.5%)] Loss: 0.028884 L1: 0.016794 Grad: 0.120647 Thermal: 0.000501 LR: 9.76e-06\n",
      "Epoch   8 [2350/10697 ( 22.0%)] Loss: 0.028306 L1: 0.016717 Grad: 0.115631 Thermal: 0.000519 LR: 9.76e-06\n",
      "Epoch   8 [2350/10697 ( 22.0%)] Loss: 0.028306 L1: 0.016717 Grad: 0.115631 Thermal: 0.000519 LR: 9.76e-06\n",
      "Epoch   8 [2400/10697 ( 22.4%)] Loss: 0.028903 L1: 0.016590 Grad: 0.122867 Thermal: 0.000524 LR: 9.76e-06\n",
      "Epoch   8 [2400/10697 ( 22.4%)] Loss: 0.028903 L1: 0.016590 Grad: 0.122867 Thermal: 0.000524 LR: 9.76e-06\n",
      "Epoch   8 [2450/10697 ( 22.9%)] Loss: 0.027510 L1: 0.015874 Grad: 0.116114 Thermal: 0.000503 LR: 9.76e-06\n",
      "Epoch   8 [2450/10697 ( 22.9%)] Loss: 0.027510 L1: 0.015874 Grad: 0.116114 Thermal: 0.000503 LR: 9.76e-06\n",
      "Epoch   8 [2500/10697 ( 23.4%)] Loss: 0.027324 L1: 0.015710 Grad: 0.115923 Thermal: 0.000431 LR: 9.76e-06\n",
      "Epoch   8 [2500/10697 ( 23.4%)] Loss: 0.027324 L1: 0.015710 Grad: 0.115923 Thermal: 0.000431 LR: 9.76e-06\n",
      "Epoch   8 [2550/10697 ( 23.8%)] Loss: 0.025306 L1: 0.015159 Grad: 0.101260 Thermal: 0.000422 LR: 9.76e-06\n",
      "Epoch   8 [2550/10697 ( 23.8%)] Loss: 0.025306 L1: 0.015159 Grad: 0.101260 Thermal: 0.000422 LR: 9.76e-06\n",
      "Epoch   8 [2600/10697 ( 24.3%)] Loss: 0.025442 L1: 0.014395 Grad: 0.110270 Thermal: 0.000401 LR: 9.76e-06\n",
      "Epoch   8 [2600/10697 ( 24.3%)] Loss: 0.025442 L1: 0.014395 Grad: 0.110270 Thermal: 0.000401 LR: 9.76e-06\n",
      "Epoch   8 [2650/10697 ( 24.8%)] Loss: 0.023684 L1: 0.013568 Grad: 0.100982 Thermal: 0.000349 LR: 9.76e-06\n",
      "Epoch   8 [2650/10697 ( 24.8%)] Loss: 0.023684 L1: 0.013568 Grad: 0.100982 Thermal: 0.000349 LR: 9.76e-06\n",
      "Epoch   8 [2700/10697 ( 25.2%)] Loss: 0.025424 L1: 0.014550 Grad: 0.108541 Thermal: 0.000401 LR: 9.76e-06\n",
      "Epoch   8 [2700/10697 ( 25.2%)] Loss: 0.025424 L1: 0.014550 Grad: 0.108541 Thermal: 0.000401 LR: 9.76e-06\n",
      "Epoch   8 [2750/10697 ( 25.7%)] Loss: 0.027850 L1: 0.016366 Grad: 0.114610 Thermal: 0.000465 LR: 9.76e-06\n",
      "Epoch   8 [2750/10697 ( 25.7%)] Loss: 0.027850 L1: 0.016366 Grad: 0.114610 Thermal: 0.000465 LR: 9.76e-06\n",
      "Epoch   8 [2800/10697 ( 26.2%)] Loss: 0.025065 L1: 0.014591 Grad: 0.104539 Thermal: 0.000400 LR: 9.76e-06\n",
      "Epoch   8 [2800/10697 ( 26.2%)] Loss: 0.025065 L1: 0.014591 Grad: 0.104539 Thermal: 0.000400 LR: 9.76e-06\n",
      "Epoch   8 [2850/10697 ( 26.6%)] Loss: 0.022701 L1: 0.013365 Grad: 0.093176 Thermal: 0.000363 LR: 9.76e-06\n",
      "Epoch   8 [2850/10697 ( 26.6%)] Loss: 0.022701 L1: 0.013365 Grad: 0.093176 Thermal: 0.000363 LR: 9.76e-06\n",
      "Epoch   8 [2900/10697 ( 27.1%)] Loss: 0.023849 L1: 0.014088 Grad: 0.097423 Thermal: 0.000378 LR: 9.76e-06\n",
      "Epoch   8 [2900/10697 ( 27.1%)] Loss: 0.023849 L1: 0.014088 Grad: 0.097423 Thermal: 0.000378 LR: 9.76e-06\n",
      "Epoch   8 [2950/10697 ( 27.6%)] Loss: 0.027079 L1: 0.015823 Grad: 0.112338 Thermal: 0.000447 LR: 9.76e-06\n",
      "Epoch   8 [2950/10697 ( 27.6%)] Loss: 0.027079 L1: 0.015823 Grad: 0.112338 Thermal: 0.000447 LR: 9.76e-06\n",
      "Epoch   8 [3000/10697 ( 28.0%)] Loss: 0.024181 L1: 0.014147 Grad: 0.100142 Thermal: 0.000416 LR: 9.76e-06\n",
      "Epoch   8 [3000/10697 ( 28.0%)] Loss: 0.024181 L1: 0.014147 Grad: 0.100142 Thermal: 0.000416 LR: 9.76e-06\n",
      "Epoch   8 [3050/10697 ( 28.5%)] Loss: 0.027685 L1: 0.015673 Grad: 0.119899 Thermal: 0.000439 LR: 9.76e-06\n",
      "Epoch   8 [3050/10697 ( 28.5%)] Loss: 0.027685 L1: 0.015673 Grad: 0.119899 Thermal: 0.000439 LR: 9.76e-06\n",
      "Epoch   8 [3100/10697 ( 29.0%)] Loss: 0.024287 L1: 0.014237 Grad: 0.100306 Thermal: 0.000385 LR: 9.76e-06\n",
      "Epoch   8 [3100/10697 ( 29.0%)] Loss: 0.024287 L1: 0.014237 Grad: 0.100306 Thermal: 0.000385 LR: 9.76e-06\n",
      "Epoch   8 [3150/10697 ( 29.4%)] Loss: 0.030031 L1: 0.017470 Grad: 0.125317 Thermal: 0.000586 LR: 9.76e-06\n",
      "Epoch   8 [3150/10697 ( 29.4%)] Loss: 0.030031 L1: 0.017470 Grad: 0.125317 Thermal: 0.000586 LR: 9.76e-06\n",
      "Epoch   8 [3200/10697 ( 29.9%)] Loss: 0.028601 L1: 0.016357 Grad: 0.122186 Thermal: 0.000519 LR: 9.76e-06\n",
      "Epoch   8 [3200/10697 ( 29.9%)] Loss: 0.028601 L1: 0.016357 Grad: 0.122186 Thermal: 0.000519 LR: 9.76e-06\n",
      "Epoch   8 [3250/10697 ( 30.4%)] Loss: 0.028300 L1: 0.016851 Grad: 0.114239 Thermal: 0.000516 LR: 9.76e-06\n",
      "Epoch   8 [3250/10697 ( 30.4%)] Loss: 0.028300 L1: 0.016851 Grad: 0.114239 Thermal: 0.000516 LR: 9.76e-06\n",
      "Epoch   8 [3300/10697 ( 30.8%)] Loss: 0.042012 L1: 0.023770 Grad: 0.181953 Thermal: 0.000924 LR: 9.76e-06\n",
      "Epoch   8 [3300/10697 ( 30.8%)] Loss: 0.042012 L1: 0.023770 Grad: 0.181953 Thermal: 0.000924 LR: 9.76e-06\n",
      "Epoch   8 [3350/10697 ( 31.3%)] Loss: 0.029608 L1: 0.016696 Grad: 0.128863 Thermal: 0.000509 LR: 9.76e-06\n",
      "Epoch   8 [3350/10697 ( 31.3%)] Loss: 0.029608 L1: 0.016696 Grad: 0.128863 Thermal: 0.000509 LR: 9.76e-06\n",
      "Epoch   8 [3400/10697 ( 31.8%)] Loss: 0.027520 L1: 0.015760 Grad: 0.117364 Thermal: 0.000462 LR: 9.76e-06\n",
      "Epoch   8 [3400/10697 ( 31.8%)] Loss: 0.027520 L1: 0.015760 Grad: 0.117364 Thermal: 0.000462 LR: 9.76e-06\n",
      "Epoch   8 [3450/10697 ( 32.3%)] Loss: 0.023860 L1: 0.013856 Grad: 0.099854 Thermal: 0.000366 LR: 9.76e-06\n",
      "Epoch   8 [3450/10697 ( 32.3%)] Loss: 0.023860 L1: 0.013856 Grad: 0.099854 Thermal: 0.000366 LR: 9.76e-06\n",
      "Epoch   8 [3500/10697 ( 32.7%)] Loss: 0.025081 L1: 0.014974 Grad: 0.100866 Thermal: 0.000414 LR: 9.76e-06\n",
      "Epoch   8 [3500/10697 ( 32.7%)] Loss: 0.025081 L1: 0.014974 Grad: 0.100866 Thermal: 0.000414 LR: 9.76e-06\n",
      "Epoch   8 [3550/10697 ( 33.2%)] Loss: 0.026612 L1: 0.015286 Grad: 0.113021 Thermal: 0.000478 LR: 9.76e-06\n",
      "Epoch   8 [3550/10697 ( 33.2%)] Loss: 0.026612 L1: 0.015286 Grad: 0.113021 Thermal: 0.000478 LR: 9.76e-06\n",
      "Epoch   8 [3600/10697 ( 33.7%)] Loss: 0.019386 L1: 0.011170 Grad: 0.082038 Thermal: 0.000262 LR: 9.76e-06\n",
      "Epoch   8 [3600/10697 ( 33.7%)] Loss: 0.019386 L1: 0.011170 Grad: 0.082038 Thermal: 0.000262 LR: 9.76e-06\n",
      "Epoch   8 [3650/10697 ( 34.1%)] Loss: 0.027812 L1: 0.016273 Grad: 0.115149 Thermal: 0.000494 LR: 9.76e-06\n",
      "Epoch   8 [3650/10697 ( 34.1%)] Loss: 0.027812 L1: 0.016273 Grad: 0.115149 Thermal: 0.000494 LR: 9.76e-06\n",
      "Epoch   8 [3700/10697 ( 34.6%)] Loss: 0.029326 L1: 0.016718 Grad: 0.125819 Thermal: 0.000523 LR: 9.76e-06\n",
      "Epoch   8 [3700/10697 ( 34.6%)] Loss: 0.029326 L1: 0.016718 Grad: 0.125819 Thermal: 0.000523 LR: 9.76e-06\n",
      "Epoch   8 [3750/10697 ( 35.1%)] Loss: 0.038641 L1: 0.022090 Grad: 0.165011 Thermal: 0.001007 LR: 9.76e-06\n",
      "Epoch   8 [3750/10697 ( 35.1%)] Loss: 0.038641 L1: 0.022090 Grad: 0.165011 Thermal: 0.001007 LR: 9.76e-06\n",
      "Epoch   8 [3800/10697 ( 35.5%)] Loss: 0.029246 L1: 0.017771 Grad: 0.114455 Thermal: 0.000575 LR: 9.76e-06\n",
      "Epoch   8 [3800/10697 ( 35.5%)] Loss: 0.029246 L1: 0.017771 Grad: 0.114455 Thermal: 0.000575 LR: 9.76e-06\n",
      "Epoch   8 [3850/10697 ( 36.0%)] Loss: 0.028452 L1: 0.016705 Grad: 0.117226 Thermal: 0.000500 LR: 9.76e-06\n",
      "Epoch   8 [3850/10697 ( 36.0%)] Loss: 0.028452 L1: 0.016705 Grad: 0.117226 Thermal: 0.000500 LR: 9.76e-06\n",
      "Epoch   8 [3900/10697 ( 36.5%)] Loss: 0.024955 L1: 0.014779 Grad: 0.101560 Thermal: 0.000413 LR: 9.76e-06\n",
      "Epoch   8 [3900/10697 ( 36.5%)] Loss: 0.024955 L1: 0.014779 Grad: 0.101560 Thermal: 0.000413 LR: 9.76e-06\n",
      "Epoch   8 [3950/10697 ( 36.9%)] Loss: 0.023973 L1: 0.013845 Grad: 0.101092 Thermal: 0.000373 LR: 9.76e-06\n",
      "Epoch   8 [3950/10697 ( 36.9%)] Loss: 0.023973 L1: 0.013845 Grad: 0.101092 Thermal: 0.000373 LR: 9.76e-06\n",
      "Epoch   8 [4000/10697 ( 37.4%)] Loss: 0.022342 L1: 0.012635 Grad: 0.096916 Thermal: 0.000304 LR: 9.76e-06\n",
      "Epoch   8 [4000/10697 ( 37.4%)] Loss: 0.022342 L1: 0.012635 Grad: 0.096916 Thermal: 0.000304 LR: 9.76e-06\n",
      "Epoch   8 [4050/10697 ( 37.9%)] Loss: 0.027228 L1: 0.016278 Grad: 0.109273 Thermal: 0.000463 LR: 9.76e-06\n",
      "Epoch   8 [4050/10697 ( 37.9%)] Loss: 0.027228 L1: 0.016278 Grad: 0.109273 Thermal: 0.000463 LR: 9.76e-06\n",
      "Epoch   8 [4100/10697 ( 38.3%)] Loss: 0.024262 L1: 0.014062 Grad: 0.101810 Thermal: 0.000382 LR: 9.76e-06\n",
      "Epoch   8 [4100/10697 ( 38.3%)] Loss: 0.024262 L1: 0.014062 Grad: 0.101810 Thermal: 0.000382 LR: 9.76e-06\n",
      "Epoch   8 [4150/10697 ( 38.8%)] Loss: 0.026532 L1: 0.015380 Grad: 0.111292 Thermal: 0.000444 LR: 9.76e-06\n",
      "Epoch   8 [4150/10697 ( 38.8%)] Loss: 0.026532 L1: 0.015380 Grad: 0.111292 Thermal: 0.000444 LR: 9.76e-06\n",
      "Epoch   8 [4200/10697 ( 39.3%)] Loss: 0.027586 L1: 0.016724 Grad: 0.108368 Thermal: 0.000491 LR: 9.76e-06\n",
      "Epoch   8 [4200/10697 ( 39.3%)] Loss: 0.027586 L1: 0.016724 Grad: 0.108368 Thermal: 0.000491 LR: 9.76e-06\n",
      "Epoch   8 [4250/10697 ( 39.7%)] Loss: 0.026085 L1: 0.014983 Grad: 0.110787 Thermal: 0.000447 LR: 9.76e-06\n",
      "Epoch   8 [4250/10697 ( 39.7%)] Loss: 0.026085 L1: 0.014983 Grad: 0.110787 Thermal: 0.000447 LR: 9.76e-06\n",
      "Epoch   8 [4300/10697 ( 40.2%)] Loss: 0.020095 L1: 0.011812 Grad: 0.082688 Thermal: 0.000276 LR: 9.76e-06\n",
      "Epoch   8 [4300/10697 ( 40.2%)] Loss: 0.020095 L1: 0.011812 Grad: 0.082688 Thermal: 0.000276 LR: 9.76e-06\n",
      "Epoch   8 [4350/10697 ( 40.7%)] Loss: 0.027827 L1: 0.016592 Grad: 0.112091 Thermal: 0.000514 LR: 9.76e-06\n",
      "Epoch   8 [4350/10697 ( 40.7%)] Loss: 0.027827 L1: 0.016592 Grad: 0.112091 Thermal: 0.000514 LR: 9.76e-06\n",
      "Epoch   8 [4400/10697 ( 41.1%)] Loss: 0.024259 L1: 0.014433 Grad: 0.098067 Thermal: 0.000382 LR: 9.76e-06\n",
      "Epoch   8 [4400/10697 ( 41.1%)] Loss: 0.024259 L1: 0.014433 Grad: 0.098067 Thermal: 0.000382 LR: 9.76e-06\n",
      "Epoch   8 [4450/10697 ( 41.6%)] Loss: 0.028182 L1: 0.016137 Grad: 0.120185 Thermal: 0.000523 LR: 9.76e-06\n",
      "Epoch   8 [4450/10697 ( 41.6%)] Loss: 0.028182 L1: 0.016137 Grad: 0.120185 Thermal: 0.000523 LR: 9.76e-06\n",
      "Epoch   8 [4500/10697 ( 42.1%)] Loss: 0.032267 L1: 0.018704 Grad: 0.135299 Thermal: 0.000658 LR: 9.76e-06\n",
      "Epoch   8 [4500/10697 ( 42.1%)] Loss: 0.032267 L1: 0.018704 Grad: 0.135299 Thermal: 0.000658 LR: 9.76e-06\n",
      "Epoch   8 [4550/10697 ( 42.5%)] Loss: 0.019112 L1: 0.010989 Grad: 0.081083 Thermal: 0.000283 LR: 9.76e-06\n",
      "Epoch   8 [4550/10697 ( 42.5%)] Loss: 0.019112 L1: 0.010989 Grad: 0.081083 Thermal: 0.000283 LR: 9.76e-06\n",
      "Epoch   8 [4600/10697 ( 43.0%)] Loss: 0.031208 L1: 0.018792 Grad: 0.123825 Thermal: 0.000681 LR: 9.76e-06\n",
      "Epoch   8 [4600/10697 ( 43.0%)] Loss: 0.031208 L1: 0.018792 Grad: 0.123825 Thermal: 0.000681 LR: 9.76e-06\n",
      "Epoch   8 [4650/10697 ( 43.5%)] Loss: 0.030847 L1: 0.018502 Grad: 0.123127 Thermal: 0.000653 LR: 9.76e-06\n",
      "Epoch   8 [4650/10697 ( 43.5%)] Loss: 0.030847 L1: 0.018502 Grad: 0.123127 Thermal: 0.000653 LR: 9.76e-06\n",
      "Epoch   8 [4700/10697 ( 43.9%)] Loss: 0.029631 L1: 0.017364 Grad: 0.122356 Thermal: 0.000628 LR: 9.76e-06\n",
      "Epoch   8 [4700/10697 ( 43.9%)] Loss: 0.029631 L1: 0.017364 Grad: 0.122356 Thermal: 0.000628 LR: 9.76e-06\n",
      "Epoch   8 [4750/10697 ( 44.4%)] Loss: 0.032887 L1: 0.019104 Grad: 0.137508 Thermal: 0.000658 LR: 9.76e-06\n",
      "Epoch   8 [4750/10697 ( 44.4%)] Loss: 0.032887 L1: 0.019104 Grad: 0.137508 Thermal: 0.000658 LR: 9.76e-06\n",
      "Epoch   8 [4800/10697 ( 44.9%)] Loss: 0.018104 L1: 0.010304 Grad: 0.077887 Thermal: 0.000231 LR: 9.76e-06\n",
      "Epoch   8 [4800/10697 ( 44.9%)] Loss: 0.018104 L1: 0.010304 Grad: 0.077887 Thermal: 0.000231 LR: 9.76e-06\n",
      "Epoch   8 [4850/10697 ( 45.3%)] Loss: 0.030137 L1: 0.017021 Grad: 0.130862 Thermal: 0.000597 LR: 9.76e-06\n",
      "Epoch   8 [4850/10697 ( 45.3%)] Loss: 0.030137 L1: 0.017021 Grad: 0.130862 Thermal: 0.000597 LR: 9.76e-06\n",
      "Epoch   8 [4900/10697 ( 45.8%)] Loss: 0.025432 L1: 0.014907 Grad: 0.105043 Thermal: 0.000411 LR: 9.76e-06\n",
      "Epoch   8 [4900/10697 ( 45.8%)] Loss: 0.025432 L1: 0.014907 Grad: 0.105043 Thermal: 0.000411 LR: 9.76e-06\n",
      "Epoch   8 [4950/10697 ( 46.3%)] Loss: 0.028624 L1: 0.016895 Grad: 0.117035 Thermal: 0.000515 LR: 9.76e-06\n",
      "Epoch   8 [4950/10697 ( 46.3%)] Loss: 0.028624 L1: 0.016895 Grad: 0.117035 Thermal: 0.000515 LR: 9.76e-06\n",
      "Epoch   8 [5000/10697 ( 46.7%)] Loss: 0.025835 L1: 0.015128 Grad: 0.106840 Thermal: 0.000456 LR: 9.76e-06\n",
      "Epoch   8 [5000/10697 ( 46.7%)] Loss: 0.025835 L1: 0.015128 Grad: 0.106840 Thermal: 0.000456 LR: 9.76e-06\n",
      "Epoch   8 [5050/10697 ( 47.2%)] Loss: 0.017121 L1: 0.009804 Grad: 0.073069 Thermal: 0.000216 LR: 9.76e-06\n",
      "Epoch   8 [5050/10697 ( 47.2%)] Loss: 0.017121 L1: 0.009804 Grad: 0.073069 Thermal: 0.000216 LR: 9.76e-06\n",
      "Epoch   8 [5100/10697 ( 47.7%)] Loss: 0.026972 L1: 0.015605 Grad: 0.113425 Thermal: 0.000476 LR: 9.76e-06\n",
      "Epoch   8 [5100/10697 ( 47.7%)] Loss: 0.026972 L1: 0.015605 Grad: 0.113425 Thermal: 0.000476 LR: 9.76e-06\n",
      "Epoch   8 [5150/10697 ( 48.1%)] Loss: 0.024635 L1: 0.014049 Grad: 0.105666 Thermal: 0.000371 LR: 9.76e-06\n",
      "Epoch   8 [5150/10697 ( 48.1%)] Loss: 0.024635 L1: 0.014049 Grad: 0.105666 Thermal: 0.000371 LR: 9.76e-06\n",
      "Epoch   8 [5200/10697 ( 48.6%)] Loss: 0.028279 L1: 0.016356 Grad: 0.118999 Thermal: 0.000462 LR: 9.76e-06\n",
      "Epoch   8 [5200/10697 ( 48.6%)] Loss: 0.028279 L1: 0.016356 Grad: 0.118999 Thermal: 0.000462 LR: 9.76e-06\n",
      "Epoch   8 [5250/10697 ( 49.1%)] Loss: 0.024543 L1: 0.014483 Grad: 0.100402 Thermal: 0.000393 LR: 9.76e-06\n",
      "Epoch   8 [5250/10697 ( 49.1%)] Loss: 0.024543 L1: 0.014483 Grad: 0.100402 Thermal: 0.000393 LR: 9.76e-06\n",
      "Epoch   8 [5300/10697 ( 49.5%)] Loss: 0.026219 L1: 0.015344 Grad: 0.108542 Thermal: 0.000423 LR: 9.76e-06\n",
      "Epoch   8 [5300/10697 ( 49.5%)] Loss: 0.026219 L1: 0.015344 Grad: 0.108542 Thermal: 0.000423 LR: 9.76e-06\n",
      "Epoch   8 [5350/10697 ( 50.0%)] Loss: 0.027833 L1: 0.015799 Grad: 0.120088 Thermal: 0.000495 LR: 9.76e-06\n",
      "Epoch   8 [5350/10697 ( 50.0%)] Loss: 0.027833 L1: 0.015799 Grad: 0.120088 Thermal: 0.000495 LR: 9.76e-06\n",
      "Epoch   8 [5400/10697 ( 50.5%)] Loss: 0.025711 L1: 0.014934 Grad: 0.107560 Thermal: 0.000404 LR: 9.76e-06\n",
      "Epoch   8 [5400/10697 ( 50.5%)] Loss: 0.025711 L1: 0.014934 Grad: 0.107560 Thermal: 0.000404 LR: 9.76e-06\n",
      "Epoch   8 [5450/10697 ( 50.9%)] Loss: 0.032129 L1: 0.018531 Grad: 0.135679 Thermal: 0.000612 LR: 9.76e-06\n",
      "Epoch   8 [5450/10697 ( 50.9%)] Loss: 0.032129 L1: 0.018531 Grad: 0.135679 Thermal: 0.000612 LR: 9.76e-06\n",
      "Epoch   8 [5500/10697 ( 51.4%)] Loss: 0.032467 L1: 0.018825 Grad: 0.136074 Thermal: 0.000688 LR: 9.76e-06\n",
      "Epoch   8 [5500/10697 ( 51.4%)] Loss: 0.032467 L1: 0.018825 Grad: 0.136074 Thermal: 0.000688 LR: 9.76e-06\n",
      "Epoch   8 [5550/10697 ( 51.9%)] Loss: 0.024396 L1: 0.013499 Grad: 0.108799 Thermal: 0.000353 LR: 9.76e-06\n",
      "Epoch   8 [5550/10697 ( 51.9%)] Loss: 0.024396 L1: 0.013499 Grad: 0.108799 Thermal: 0.000353 LR: 9.76e-06\n",
      "Epoch   8 [5600/10697 ( 52.4%)] Loss: 0.024435 L1: 0.014310 Grad: 0.101044 Thermal: 0.000411 LR: 9.76e-06\n",
      "Epoch   8 [5600/10697 ( 52.4%)] Loss: 0.024435 L1: 0.014310 Grad: 0.101044 Thermal: 0.000411 LR: 9.76e-06\n",
      "Epoch   8 [5650/10697 ( 52.8%)] Loss: 0.033173 L1: 0.019579 Grad: 0.135591 Thermal: 0.000700 LR: 9.76e-06\n",
      "Epoch   8 [5650/10697 ( 52.8%)] Loss: 0.033173 L1: 0.019579 Grad: 0.135591 Thermal: 0.000700 LR: 9.76e-06\n",
      "Epoch   8 [5700/10697 ( 53.3%)] Loss: 0.023032 L1: 0.013413 Grad: 0.096010 Thermal: 0.000354 LR: 9.76e-06\n",
      "Epoch   8 [5700/10697 ( 53.3%)] Loss: 0.023032 L1: 0.013413 Grad: 0.096010 Thermal: 0.000354 LR: 9.76e-06\n",
      "Epoch   8 [5750/10697 ( 53.8%)] Loss: 0.023808 L1: 0.013896 Grad: 0.098915 Thermal: 0.000419 LR: 9.76e-06\n",
      "Epoch   8 [5750/10697 ( 53.8%)] Loss: 0.023808 L1: 0.013896 Grad: 0.098915 Thermal: 0.000419 LR: 9.76e-06\n",
      "Epoch   8 [5800/10697 ( 54.2%)] Loss: 0.024815 L1: 0.014645 Grad: 0.101485 Thermal: 0.000425 LR: 9.76e-06\n",
      "Epoch   8 [5800/10697 ( 54.2%)] Loss: 0.024815 L1: 0.014645 Grad: 0.101485 Thermal: 0.000425 LR: 9.76e-06\n",
      "Epoch   8 [5850/10697 ( 54.7%)] Loss: 0.038921 L1: 0.022483 Grad: 0.163895 Thermal: 0.000970 LR: 9.76e-06\n",
      "Epoch   8 [5850/10697 ( 54.7%)] Loss: 0.038921 L1: 0.022483 Grad: 0.163895 Thermal: 0.000970 LR: 9.76e-06\n",
      "Epoch   8 [5900/10697 ( 55.2%)] Loss: 0.026748 L1: 0.016003 Grad: 0.107208 Thermal: 0.000474 LR: 9.76e-06\n",
      "Epoch   8 [5900/10697 ( 55.2%)] Loss: 0.026748 L1: 0.016003 Grad: 0.107208 Thermal: 0.000474 LR: 9.76e-06\n",
      "Epoch   8 [5950/10697 ( 55.6%)] Loss: 0.026444 L1: 0.015413 Grad: 0.110097 Thermal: 0.000428 LR: 9.76e-06\n",
      "Epoch   8 [5950/10697 ( 55.6%)] Loss: 0.026444 L1: 0.015413 Grad: 0.110097 Thermal: 0.000428 LR: 9.76e-06\n",
      "Epoch   8 [6000/10697 ( 56.1%)] Loss: 0.027166 L1: 0.015703 Grad: 0.114412 Thermal: 0.000444 LR: 9.76e-06\n",
      "Epoch   8 [6000/10697 ( 56.1%)] Loss: 0.027166 L1: 0.015703 Grad: 0.114412 Thermal: 0.000444 LR: 9.76e-06\n",
      "Epoch   8 [6050/10697 ( 56.6%)] Loss: 0.023552 L1: 0.013334 Grad: 0.101977 Thermal: 0.000408 LR: 9.76e-06\n",
      "Epoch   8 [6050/10697 ( 56.6%)] Loss: 0.023552 L1: 0.013334 Grad: 0.101977 Thermal: 0.000408 LR: 9.76e-06\n",
      "Epoch   8 [6100/10697 ( 57.0%)] Loss: 0.029775 L1: 0.017590 Grad: 0.121582 Thermal: 0.000546 LR: 9.76e-06\n",
      "Epoch   8 [6100/10697 ( 57.0%)] Loss: 0.029775 L1: 0.017590 Grad: 0.121582 Thermal: 0.000546 LR: 9.76e-06\n",
      "Epoch   8 [6150/10697 ( 57.5%)] Loss: 0.024296 L1: 0.013505 Grad: 0.107731 Thermal: 0.000365 LR: 9.76e-06\n",
      "Epoch   8 [6150/10697 ( 57.5%)] Loss: 0.024296 L1: 0.013505 Grad: 0.107731 Thermal: 0.000365 LR: 9.76e-06\n",
      "Epoch   8 [6200/10697 ( 58.0%)] Loss: 0.029839 L1: 0.017460 Grad: 0.123527 Thermal: 0.000522 LR: 9.76e-06\n",
      "Epoch   8 [6200/10697 ( 58.0%)] Loss: 0.029839 L1: 0.017460 Grad: 0.123527 Thermal: 0.000522 LR: 9.76e-06\n",
      "Epoch   8 [6250/10697 ( 58.4%)] Loss: 0.020879 L1: 0.011994 Grad: 0.088710 Thermal: 0.000286 LR: 9.76e-06\n",
      "Epoch   8 [6250/10697 ( 58.4%)] Loss: 0.020879 L1: 0.011994 Grad: 0.088710 Thermal: 0.000286 LR: 9.76e-06\n",
      "Epoch   8 [6300/10697 ( 58.9%)] Loss: 0.022371 L1: 0.013225 Grad: 0.091284 Thermal: 0.000342 LR: 9.76e-06\n",
      "Epoch   8 [6300/10697 ( 58.9%)] Loss: 0.022371 L1: 0.013225 Grad: 0.091284 Thermal: 0.000342 LR: 9.76e-06\n",
      "Epoch   8 [6350/10697 ( 59.4%)] Loss: 0.025701 L1: 0.014920 Grad: 0.107581 Thermal: 0.000452 LR: 9.76e-06\n",
      "Epoch   8 [6350/10697 ( 59.4%)] Loss: 0.025701 L1: 0.014920 Grad: 0.107581 Thermal: 0.000452 LR: 9.76e-06\n",
      "Epoch   8 [6400/10697 ( 59.8%)] Loss: 0.025478 L1: 0.015059 Grad: 0.103986 Thermal: 0.000416 LR: 9.76e-06\n",
      "Epoch   8 [6400/10697 ( 59.8%)] Loss: 0.025478 L1: 0.015059 Grad: 0.103986 Thermal: 0.000416 LR: 9.76e-06\n",
      "Epoch   8 [6450/10697 ( 60.3%)] Loss: 0.024254 L1: 0.014043 Grad: 0.101917 Thermal: 0.000383 LR: 9.76e-06\n",
      "Epoch   8 [6450/10697 ( 60.3%)] Loss: 0.024254 L1: 0.014043 Grad: 0.101917 Thermal: 0.000383 LR: 9.76e-06\n",
      "Epoch   8 [6500/10697 ( 60.8%)] Loss: 0.029025 L1: 0.017133 Grad: 0.118637 Thermal: 0.000553 LR: 9.76e-06\n",
      "Epoch   8 [6500/10697 ( 60.8%)] Loss: 0.029025 L1: 0.017133 Grad: 0.118637 Thermal: 0.000553 LR: 9.76e-06\n",
      "Epoch   8 [6550/10697 ( 61.2%)] Loss: 0.023786 L1: 0.013713 Grad: 0.100518 Thermal: 0.000422 LR: 9.76e-06\n",
      "Epoch   8 [6550/10697 ( 61.2%)] Loss: 0.023786 L1: 0.013713 Grad: 0.100518 Thermal: 0.000422 LR: 9.76e-06\n",
      "Epoch   8 [6600/10697 ( 61.7%)] Loss: 0.024698 L1: 0.014365 Grad: 0.103129 Thermal: 0.000408 LR: 9.76e-06\n",
      "Epoch   8 [6600/10697 ( 61.7%)] Loss: 0.024698 L1: 0.014365 Grad: 0.103129 Thermal: 0.000408 LR: 9.76e-06\n",
      "Epoch   8 [6650/10697 ( 62.2%)] Loss: 0.019788 L1: 0.011604 Grad: 0.081695 Thermal: 0.000281 LR: 9.76e-06\n",
      "Epoch   8 [6650/10697 ( 62.2%)] Loss: 0.019788 L1: 0.011604 Grad: 0.081695 Thermal: 0.000281 LR: 9.76e-06\n",
      "Epoch   8 [6700/10697 ( 62.6%)] Loss: 0.024465 L1: 0.014478 Grad: 0.099677 Thermal: 0.000388 LR: 9.76e-06\n",
      "Epoch   8 [6700/10697 ( 62.6%)] Loss: 0.024465 L1: 0.014478 Grad: 0.099677 Thermal: 0.000388 LR: 9.76e-06\n",
      "Epoch   8 [6750/10697 ( 63.1%)] Loss: 0.025985 L1: 0.015164 Grad: 0.107996 Thermal: 0.000420 LR: 9.76e-06\n",
      "Epoch   8 [6750/10697 ( 63.1%)] Loss: 0.025985 L1: 0.015164 Grad: 0.107996 Thermal: 0.000420 LR: 9.76e-06\n",
      "Epoch   8 [6800/10697 ( 63.6%)] Loss: 0.026906 L1: 0.015433 Grad: 0.114504 Thermal: 0.000468 LR: 9.76e-06\n",
      "Epoch   8 [6800/10697 ( 63.6%)] Loss: 0.026906 L1: 0.015433 Grad: 0.114504 Thermal: 0.000468 LR: 9.76e-06\n",
      "Epoch   8 [6850/10697 ( 64.0%)] Loss: 0.027463 L1: 0.015946 Grad: 0.114951 Thermal: 0.000437 LR: 9.76e-06\n",
      "Epoch   8 [6850/10697 ( 64.0%)] Loss: 0.027463 L1: 0.015946 Grad: 0.114951 Thermal: 0.000437 LR: 9.76e-06\n",
      "Epoch   8 [6900/10697 ( 64.5%)] Loss: 0.023732 L1: 0.013572 Grad: 0.101418 Thermal: 0.000373 LR: 9.76e-06\n",
      "Epoch   8 [6900/10697 ( 64.5%)] Loss: 0.023732 L1: 0.013572 Grad: 0.101418 Thermal: 0.000373 LR: 9.76e-06\n",
      "Epoch   8 [6950/10697 ( 65.0%)] Loss: 0.027588 L1: 0.015788 Grad: 0.117725 Thermal: 0.000535 LR: 9.76e-06\n",
      "Epoch   8 [6950/10697 ( 65.0%)] Loss: 0.027588 L1: 0.015788 Grad: 0.117725 Thermal: 0.000535 LR: 9.76e-06\n",
      "Epoch   8 [7000/10697 ( 65.4%)] Loss: 0.029941 L1: 0.016891 Grad: 0.130230 Thermal: 0.000548 LR: 9.76e-06\n",
      "Epoch   8 [7000/10697 ( 65.4%)] Loss: 0.029941 L1: 0.016891 Grad: 0.130230 Thermal: 0.000548 LR: 9.76e-06\n",
      "Epoch   8 [7050/10697 ( 65.9%)] Loss: 0.028881 L1: 0.016813 Grad: 0.120421 Thermal: 0.000521 LR: 9.76e-06\n",
      "Epoch   8 [7050/10697 ( 65.9%)] Loss: 0.028881 L1: 0.016813 Grad: 0.120421 Thermal: 0.000521 LR: 9.76e-06\n",
      "Epoch   8 [7100/10697 ( 66.4%)] Loss: 0.030213 L1: 0.016716 Grad: 0.134714 Thermal: 0.000519 LR: 9.76e-06\n",
      "Epoch   8 [7100/10697 ( 66.4%)] Loss: 0.030213 L1: 0.016716 Grad: 0.134714 Thermal: 0.000519 LR: 9.76e-06\n",
      "Epoch   8 [7150/10697 ( 66.8%)] Loss: 0.022723 L1: 0.013153 Grad: 0.095513 Thermal: 0.000365 LR: 9.76e-06\n",
      "Epoch   8 [7150/10697 ( 66.8%)] Loss: 0.022723 L1: 0.013153 Grad: 0.095513 Thermal: 0.000365 LR: 9.76e-06\n",
      "Epoch   8 [7200/10697 ( 67.3%)] Loss: 0.025229 L1: 0.014569 Grad: 0.106391 Thermal: 0.000421 LR: 9.76e-06\n",
      "Epoch   8 [7200/10697 ( 67.3%)] Loss: 0.025229 L1: 0.014569 Grad: 0.106391 Thermal: 0.000421 LR: 9.76e-06\n",
      "Epoch   8 [7250/10697 ( 67.8%)] Loss: 0.023947 L1: 0.014099 Grad: 0.098285 Thermal: 0.000395 LR: 9.76e-06\n",
      "Epoch   8 [7250/10697 ( 67.8%)] Loss: 0.023947 L1: 0.014099 Grad: 0.098285 Thermal: 0.000395 LR: 9.76e-06\n",
      "Epoch   8 [7300/10697 ( 68.2%)] Loss: 0.029538 L1: 0.017387 Grad: 0.121229 Thermal: 0.000554 LR: 9.76e-06\n",
      "Epoch   8 [7300/10697 ( 68.2%)] Loss: 0.029538 L1: 0.017387 Grad: 0.121229 Thermal: 0.000554 LR: 9.76e-06\n",
      "Epoch   8 [7350/10697 ( 68.7%)] Loss: 0.027085 L1: 0.015712 Grad: 0.113510 Thermal: 0.000448 LR: 9.76e-06\n",
      "Epoch   8 [7350/10697 ( 68.7%)] Loss: 0.027085 L1: 0.015712 Grad: 0.113510 Thermal: 0.000448 LR: 9.76e-06\n",
      "Epoch   8 [7400/10697 ( 69.2%)] Loss: 0.029034 L1: 0.017057 Grad: 0.119519 Thermal: 0.000486 LR: 9.76e-06\n",
      "Epoch   8 [7400/10697 ( 69.2%)] Loss: 0.029034 L1: 0.017057 Grad: 0.119519 Thermal: 0.000486 LR: 9.76e-06\n",
      "Epoch   8 [7450/10697 ( 69.6%)] Loss: 0.029304 L1: 0.017050 Grad: 0.122268 Thermal: 0.000539 LR: 9.76e-06\n",
      "Epoch   8 [7450/10697 ( 69.6%)] Loss: 0.029304 L1: 0.017050 Grad: 0.122268 Thermal: 0.000539 LR: 9.76e-06\n",
      "Epoch   8 [7500/10697 ( 70.1%)] Loss: 0.028989 L1: 0.016992 Grad: 0.119724 Thermal: 0.000494 LR: 9.76e-06\n",
      "Epoch   8 [7500/10697 ( 70.1%)] Loss: 0.028989 L1: 0.016992 Grad: 0.119724 Thermal: 0.000494 LR: 9.76e-06\n",
      "Epoch   8 [7550/10697 ( 70.6%)] Loss: 0.025754 L1: 0.015408 Grad: 0.103244 Thermal: 0.000433 LR: 9.76e-06\n",
      "Epoch   8 [7550/10697 ( 70.6%)] Loss: 0.025754 L1: 0.015408 Grad: 0.103244 Thermal: 0.000433 LR: 9.76e-06\n",
      "Epoch   8 [7600/10697 ( 71.0%)] Loss: 0.025756 L1: 0.014909 Grad: 0.108261 Thermal: 0.000435 LR: 9.76e-06\n",
      "Epoch   8 [7600/10697 ( 71.0%)] Loss: 0.025756 L1: 0.014909 Grad: 0.108261 Thermal: 0.000435 LR: 9.76e-06\n",
      "Epoch   8 [7650/10697 ( 71.5%)] Loss: 0.031331 L1: 0.018409 Grad: 0.128918 Thermal: 0.000599 LR: 9.76e-06\n",
      "Epoch   8 [7650/10697 ( 71.5%)] Loss: 0.031331 L1: 0.018409 Grad: 0.128918 Thermal: 0.000599 LR: 9.76e-06\n",
      "Epoch   8 [7700/10697 ( 72.0%)] Loss: 0.027739 L1: 0.016474 Grad: 0.112418 Thermal: 0.000474 LR: 9.76e-06\n",
      "Epoch   8 [7700/10697 ( 72.0%)] Loss: 0.027739 L1: 0.016474 Grad: 0.112418 Thermal: 0.000474 LR: 9.76e-06\n",
      "Epoch   8 [7750/10697 ( 72.5%)] Loss: 0.023377 L1: 0.013524 Grad: 0.098347 Thermal: 0.000358 LR: 9.76e-06\n",
      "Epoch   8 [7750/10697 ( 72.5%)] Loss: 0.023377 L1: 0.013524 Grad: 0.098347 Thermal: 0.000358 LR: 9.76e-06\n",
      "Epoch   8 [7800/10697 ( 72.9%)] Loss: 0.029829 L1: 0.017167 Grad: 0.126307 Thermal: 0.000613 LR: 9.76e-06\n",
      "Epoch   8 [7800/10697 ( 72.9%)] Loss: 0.029829 L1: 0.017167 Grad: 0.126307 Thermal: 0.000613 LR: 9.76e-06\n",
      "Epoch   8 [7850/10697 ( 73.4%)] Loss: 0.028919 L1: 0.016646 Grad: 0.122449 Thermal: 0.000552 LR: 9.76e-06\n",
      "Epoch   8 [7850/10697 ( 73.4%)] Loss: 0.028919 L1: 0.016646 Grad: 0.122449 Thermal: 0.000552 LR: 9.76e-06\n",
      "Epoch   8 [7900/10697 ( 73.9%)] Loss: 0.024808 L1: 0.014766 Grad: 0.100197 Thermal: 0.000435 LR: 9.76e-06\n",
      "Epoch   8 [7900/10697 ( 73.9%)] Loss: 0.024808 L1: 0.014766 Grad: 0.100197 Thermal: 0.000435 LR: 9.76e-06\n",
      "Epoch   8 [7950/10697 ( 74.3%)] Loss: 0.025136 L1: 0.014440 Grad: 0.106768 Thermal: 0.000391 LR: 9.76e-06\n",
      "Epoch   8 [7950/10697 ( 74.3%)] Loss: 0.025136 L1: 0.014440 Grad: 0.106768 Thermal: 0.000391 LR: 9.76e-06\n",
      "Epoch   8 [8000/10697 ( 74.8%)] Loss: 0.020819 L1: 0.011916 Grad: 0.088889 Thermal: 0.000284 LR: 9.76e-06\n",
      "Epoch   8 [8000/10697 ( 74.8%)] Loss: 0.020819 L1: 0.011916 Grad: 0.088889 Thermal: 0.000284 LR: 9.76e-06\n",
      "Epoch   8 [8050/10697 ( 75.3%)] Loss: 0.020231 L1: 0.011551 Grad: 0.086668 Thermal: 0.000272 LR: 9.76e-06\n",
      "Epoch   8 [8050/10697 ( 75.3%)] Loss: 0.020231 L1: 0.011551 Grad: 0.086668 Thermal: 0.000272 LR: 9.76e-06\n",
      "Epoch   8 [8100/10697 ( 75.7%)] Loss: 0.027137 L1: 0.015478 Grad: 0.116363 Thermal: 0.000447 LR: 9.76e-06\n",
      "Epoch   8 [8100/10697 ( 75.7%)] Loss: 0.027137 L1: 0.015478 Grad: 0.116363 Thermal: 0.000447 LR: 9.76e-06\n",
      "Epoch   8 [8150/10697 ( 76.2%)] Loss: 0.030076 L1: 0.017315 Grad: 0.127337 Thermal: 0.000545 LR: 9.76e-06\n",
      "Epoch   8 [8150/10697 ( 76.2%)] Loss: 0.030076 L1: 0.017315 Grad: 0.127337 Thermal: 0.000545 LR: 9.76e-06\n",
      "Epoch   8 [8200/10697 ( 76.7%)] Loss: 0.023719 L1: 0.013836 Grad: 0.098642 Thermal: 0.000381 LR: 9.76e-06\n",
      "Epoch   8 [8200/10697 ( 76.7%)] Loss: 0.023719 L1: 0.013836 Grad: 0.098642 Thermal: 0.000381 LR: 9.76e-06\n",
      "Epoch   8 [8250/10697 ( 77.1%)] Loss: 0.031798 L1: 0.018789 Grad: 0.129774 Thermal: 0.000638 LR: 9.76e-06\n",
      "Epoch   8 [8250/10697 ( 77.1%)] Loss: 0.031798 L1: 0.018789 Grad: 0.129774 Thermal: 0.000638 LR: 9.76e-06\n",
      "Epoch   8 [8300/10697 ( 77.6%)] Loss: 0.025667 L1: 0.015544 Grad: 0.101017 Thermal: 0.000440 LR: 9.76e-06\n",
      "Epoch   8 [8300/10697 ( 77.6%)] Loss: 0.025667 L1: 0.015544 Grad: 0.101017 Thermal: 0.000440 LR: 9.76e-06\n",
      "Epoch   8 [8350/10697 ( 78.1%)] Loss: 0.023513 L1: 0.013432 Grad: 0.100647 Thermal: 0.000342 LR: 9.76e-06\n",
      "Epoch   8 [8350/10697 ( 78.1%)] Loss: 0.023513 L1: 0.013432 Grad: 0.100647 Thermal: 0.000342 LR: 9.76e-06\n",
      "Epoch   8 [8400/10697 ( 78.5%)] Loss: 0.031186 L1: 0.018070 Grad: 0.130855 Thermal: 0.000605 LR: 9.76e-06\n",
      "Epoch   8 [8400/10697 ( 78.5%)] Loss: 0.031186 L1: 0.018070 Grad: 0.130855 Thermal: 0.000605 LR: 9.76e-06\n",
      "Epoch   8 [8450/10697 ( 79.0%)] Loss: 0.031802 L1: 0.018492 Grad: 0.132741 Thermal: 0.000712 LR: 9.76e-06\n",
      "Epoch   8 [8450/10697 ( 79.0%)] Loss: 0.031802 L1: 0.018492 Grad: 0.132741 Thermal: 0.000712 LR: 9.76e-06\n",
      "Epoch   8 [8500/10697 ( 79.5%)] Loss: 0.026575 L1: 0.015442 Grad: 0.111105 Thermal: 0.000443 LR: 9.76e-06\n",
      "Epoch   8 [8500/10697 ( 79.5%)] Loss: 0.026575 L1: 0.015442 Grad: 0.111105 Thermal: 0.000443 LR: 9.76e-06\n",
      "Epoch   8 [8550/10697 ( 79.9%)] Loss: 0.028416 L1: 0.016904 Grad: 0.114863 Thermal: 0.000525 LR: 9.76e-06\n",
      "Epoch   8 [8550/10697 ( 79.9%)] Loss: 0.028416 L1: 0.016904 Grad: 0.114863 Thermal: 0.000525 LR: 9.76e-06\n",
      "Epoch   8 [8600/10697 ( 80.4%)] Loss: 0.030526 L1: 0.017161 Grad: 0.133384 Thermal: 0.000537 LR: 9.76e-06\n",
      "Epoch   8 [8600/10697 ( 80.4%)] Loss: 0.030526 L1: 0.017161 Grad: 0.133384 Thermal: 0.000537 LR: 9.76e-06\n",
      "Epoch   8 [8650/10697 ( 80.9%)] Loss: 0.030301 L1: 0.017149 Grad: 0.131233 Thermal: 0.000556 LR: 9.76e-06\n",
      "Epoch   8 [8650/10697 ( 80.9%)] Loss: 0.030301 L1: 0.017149 Grad: 0.131233 Thermal: 0.000556 LR: 9.76e-06\n",
      "Epoch   8 [8700/10697 ( 81.3%)] Loss: 0.034154 L1: 0.019502 Grad: 0.146179 Thermal: 0.000679 LR: 9.76e-06\n",
      "Epoch   8 [8700/10697 ( 81.3%)] Loss: 0.034154 L1: 0.019502 Grad: 0.146179 Thermal: 0.000679 LR: 9.76e-06\n",
      "Epoch   8 [8750/10697 ( 81.8%)] Loss: 0.026722 L1: 0.015911 Grad: 0.107871 Thermal: 0.000477 LR: 9.76e-06\n",
      "Epoch   8 [8750/10697 ( 81.8%)] Loss: 0.026722 L1: 0.015911 Grad: 0.107871 Thermal: 0.000477 LR: 9.76e-06\n",
      "Epoch   8 [8800/10697 ( 82.3%)] Loss: 0.028768 L1: 0.016908 Grad: 0.118331 Thermal: 0.000533 LR: 9.76e-06\n",
      "Epoch   8 [8800/10697 ( 82.3%)] Loss: 0.028768 L1: 0.016908 Grad: 0.118331 Thermal: 0.000533 LR: 9.76e-06\n",
      "Epoch   8 [8850/10697 ( 82.7%)] Loss: 0.026750 L1: 0.015695 Grad: 0.110318 Thermal: 0.000473 LR: 9.76e-06\n",
      "Epoch   8 [8850/10697 ( 82.7%)] Loss: 0.026750 L1: 0.015695 Grad: 0.110318 Thermal: 0.000473 LR: 9.76e-06\n",
      "Epoch   8 [8900/10697 ( 83.2%)] Loss: 0.026653 L1: 0.015918 Grad: 0.107117 Thermal: 0.000470 LR: 9.76e-06\n",
      "Epoch   8 [8900/10697 ( 83.2%)] Loss: 0.026653 L1: 0.015918 Grad: 0.107117 Thermal: 0.000470 LR: 9.76e-06\n",
      "Epoch   8 [8950/10697 ( 83.7%)] Loss: 0.022226 L1: 0.013083 Grad: 0.091266 Thermal: 0.000336 LR: 9.76e-06\n",
      "Epoch   8 [8950/10697 ( 83.7%)] Loss: 0.022226 L1: 0.013083 Grad: 0.091266 Thermal: 0.000336 LR: 9.76e-06\n",
      "Epoch   8 [9000/10697 ( 84.1%)] Loss: 0.035065 L1: 0.020658 Grad: 0.143686 Thermal: 0.000769 LR: 9.76e-06\n",
      "Epoch   8 [9000/10697 ( 84.1%)] Loss: 0.035065 L1: 0.020658 Grad: 0.143686 Thermal: 0.000769 LR: 9.76e-06\n",
      "Epoch   8 [9050/10697 ( 84.6%)] Loss: 0.025259 L1: 0.014805 Grad: 0.104340 Thermal: 0.000415 LR: 9.76e-06\n",
      "Epoch   8 [9050/10697 ( 84.6%)] Loss: 0.025259 L1: 0.014805 Grad: 0.104340 Thermal: 0.000415 LR: 9.76e-06\n",
      "Epoch   8 [9100/10697 ( 85.1%)] Loss: 0.026802 L1: 0.015600 Grad: 0.111806 Thermal: 0.000432 LR: 9.76e-06\n",
      "Epoch   8 [9100/10697 ( 85.1%)] Loss: 0.026802 L1: 0.015600 Grad: 0.111806 Thermal: 0.000432 LR: 9.76e-06\n",
      "Epoch   8 [9150/10697 ( 85.5%)] Loss: 0.020906 L1: 0.012150 Grad: 0.087402 Thermal: 0.000315 LR: 9.76e-06\n",
      "Epoch   8 [9150/10697 ( 85.5%)] Loss: 0.020906 L1: 0.012150 Grad: 0.087402 Thermal: 0.000315 LR: 9.76e-06\n",
      "Epoch   8 [9200/10697 ( 86.0%)] Loss: 0.025380 L1: 0.014769 Grad: 0.105903 Thermal: 0.000418 LR: 9.76e-06\n",
      "Epoch   8 [9200/10697 ( 86.0%)] Loss: 0.025380 L1: 0.014769 Grad: 0.105903 Thermal: 0.000418 LR: 9.76e-06\n",
      "Epoch   8 [9250/10697 ( 86.5%)] Loss: 0.025575 L1: 0.014805 Grad: 0.107490 Thermal: 0.000413 LR: 9.76e-06\n",
      "Epoch   8 [9250/10697 ( 86.5%)] Loss: 0.025575 L1: 0.014805 Grad: 0.107490 Thermal: 0.000413 LR: 9.76e-06\n",
      "Epoch   8 [9300/10697 ( 86.9%)] Loss: 0.021090 L1: 0.012673 Grad: 0.084009 Thermal: 0.000316 LR: 9.76e-06\n",
      "Epoch   8 [9300/10697 ( 86.9%)] Loss: 0.021090 L1: 0.012673 Grad: 0.084009 Thermal: 0.000316 LR: 9.76e-06\n",
      "Epoch   8 [9350/10697 ( 87.4%)] Loss: 0.033989 L1: 0.019833 Grad: 0.141150 Thermal: 0.000830 LR: 9.76e-06\n",
      "Epoch   8 [9350/10697 ( 87.4%)] Loss: 0.033989 L1: 0.019833 Grad: 0.141150 Thermal: 0.000830 LR: 9.76e-06\n",
      "Epoch   8 [9400/10697 ( 87.9%)] Loss: 0.029290 L1: 0.016562 Grad: 0.126994 Thermal: 0.000561 LR: 9.76e-06\n",
      "Epoch   8 [9400/10697 ( 87.9%)] Loss: 0.029290 L1: 0.016562 Grad: 0.126994 Thermal: 0.000561 LR: 9.76e-06\n",
      "Epoch   8 [9450/10697 ( 88.3%)] Loss: 0.031263 L1: 0.017823 Grad: 0.134100 Thermal: 0.000599 LR: 9.76e-06\n",
      "Epoch   8 [9450/10697 ( 88.3%)] Loss: 0.031263 L1: 0.017823 Grad: 0.134100 Thermal: 0.000599 LR: 9.76e-06\n",
      "Epoch   8 [9500/10697 ( 88.8%)] Loss: 0.024821 L1: 0.015025 Grad: 0.097743 Thermal: 0.000427 LR: 9.76e-06\n",
      "Epoch   8 [9500/10697 ( 88.8%)] Loss: 0.024821 L1: 0.015025 Grad: 0.097743 Thermal: 0.000427 LR: 9.76e-06\n",
      "Epoch   8 [9550/10697 ( 89.3%)] Loss: 0.023652 L1: 0.013519 Grad: 0.101161 Thermal: 0.000348 LR: 9.76e-06\n",
      "Epoch   8 [9550/10697 ( 89.3%)] Loss: 0.023652 L1: 0.013519 Grad: 0.101161 Thermal: 0.000348 LR: 9.76e-06\n",
      "Epoch   8 [9600/10697 ( 89.7%)] Loss: 0.022482 L1: 0.013153 Grad: 0.093121 Thermal: 0.000343 LR: 9.76e-06\n",
      "Epoch   8 [9600/10697 ( 89.7%)] Loss: 0.022482 L1: 0.013153 Grad: 0.093121 Thermal: 0.000343 LR: 9.76e-06\n",
      "Epoch   8 [9650/10697 ( 90.2%)] Loss: 0.025556 L1: 0.015137 Grad: 0.103978 Thermal: 0.000419 LR: 9.76e-06\n",
      "Epoch   8 [9650/10697 ( 90.2%)] Loss: 0.025556 L1: 0.015137 Grad: 0.103978 Thermal: 0.000419 LR: 9.76e-06\n",
      "Epoch   8 [9700/10697 ( 90.7%)] Loss: 0.020701 L1: 0.012092 Grad: 0.085937 Thermal: 0.000305 LR: 9.76e-06\n",
      "Epoch   8 [9700/10697 ( 90.7%)] Loss: 0.020701 L1: 0.012092 Grad: 0.085937 Thermal: 0.000305 LR: 9.76e-06\n",
      "Epoch   8 [9750/10697 ( 91.1%)] Loss: 0.029239 L1: 0.017165 Grad: 0.120455 Thermal: 0.000561 LR: 9.76e-06\n",
      "Epoch   8 [9750/10697 ( 91.1%)] Loss: 0.029239 L1: 0.017165 Grad: 0.120455 Thermal: 0.000561 LR: 9.76e-06\n",
      "Epoch   8 [9800/10697 ( 91.6%)] Loss: 0.024443 L1: 0.014028 Grad: 0.103961 Thermal: 0.000380 LR: 9.76e-06\n",
      "Epoch   8 [9800/10697 ( 91.6%)] Loss: 0.024443 L1: 0.014028 Grad: 0.103961 Thermal: 0.000380 LR: 9.76e-06\n",
      "Epoch   8 [9850/10697 ( 92.1%)] Loss: 0.026613 L1: 0.015614 Grad: 0.109693 Thermal: 0.000600 LR: 9.76e-06\n",
      "Epoch   8 [9850/10697 ( 92.1%)] Loss: 0.026613 L1: 0.015614 Grad: 0.109693 Thermal: 0.000600 LR: 9.76e-06\n",
      "Epoch   8 [9900/10697 ( 92.5%)] Loss: 0.025753 L1: 0.015084 Grad: 0.106485 Thermal: 0.000416 LR: 9.76e-06\n",
      "Epoch   8 [9900/10697 ( 92.5%)] Loss: 0.025753 L1: 0.015084 Grad: 0.106485 Thermal: 0.000416 LR: 9.76e-06\n",
      "Epoch   8 [9950/10697 ( 93.0%)] Loss: 0.027464 L1: 0.016057 Grad: 0.113839 Thermal: 0.000468 LR: 9.76e-06\n",
      "Epoch   8 [9950/10697 ( 93.0%)] Loss: 0.027464 L1: 0.016057 Grad: 0.113839 Thermal: 0.000468 LR: 9.76e-06\n",
      "Epoch   8 [10000/10697 ( 93.5%)] Loss: 0.024336 L1: 0.014261 Grad: 0.100560 Thermal: 0.000372 LR: 9.76e-06\n",
      "Epoch   8 [10000/10697 ( 93.5%)] Loss: 0.024336 L1: 0.014261 Grad: 0.100560 Thermal: 0.000372 LR: 9.76e-06\n",
      "Epoch   8 [10050/10697 ( 94.0%)] Loss: 0.029315 L1: 0.017421 Grad: 0.118675 Thermal: 0.000525 LR: 9.76e-06\n",
      "Epoch   8 [10050/10697 ( 94.0%)] Loss: 0.029315 L1: 0.017421 Grad: 0.118675 Thermal: 0.000525 LR: 9.76e-06\n",
      "Epoch   8 [10100/10697 ( 94.4%)] Loss: 0.025533 L1: 0.014919 Grad: 0.105927 Thermal: 0.000428 LR: 9.76e-06\n",
      "Epoch   8 [10100/10697 ( 94.4%)] Loss: 0.025533 L1: 0.014919 Grad: 0.105927 Thermal: 0.000428 LR: 9.76e-06\n",
      "Epoch   8 [10150/10697 ( 94.9%)] Loss: 0.028609 L1: 0.016673 Grad: 0.119103 Thermal: 0.000525 LR: 9.76e-06\n",
      "Epoch   8 [10150/10697 ( 94.9%)] Loss: 0.028609 L1: 0.016673 Grad: 0.119103 Thermal: 0.000525 LR: 9.76e-06\n",
      "Epoch   8 [10200/10697 ( 95.4%)] Loss: 0.025545 L1: 0.015196 Grad: 0.103266 Thermal: 0.000440 LR: 9.76e-06\n",
      "Epoch   8 [10200/10697 ( 95.4%)] Loss: 0.025545 L1: 0.015196 Grad: 0.103266 Thermal: 0.000440 LR: 9.76e-06\n",
      "Epoch   8 [10250/10697 ( 95.8%)] Loss: 0.024654 L1: 0.014423 Grad: 0.102122 Thermal: 0.000390 LR: 9.76e-06\n",
      "Epoch   8 [10250/10697 ( 95.8%)] Loss: 0.024654 L1: 0.014423 Grad: 0.102122 Thermal: 0.000390 LR: 9.76e-06\n",
      "Epoch   8 [10300/10697 ( 96.3%)] Loss: 0.025618 L1: 0.014483 Grad: 0.111142 Thermal: 0.000415 LR: 9.76e-06\n",
      "Epoch   8 [10300/10697 ( 96.3%)] Loss: 0.025618 L1: 0.014483 Grad: 0.111142 Thermal: 0.000415 LR: 9.76e-06\n",
      "Epoch   8 [10350/10697 ( 96.8%)] Loss: 0.027592 L1: 0.016192 Grad: 0.113768 Thermal: 0.000467 LR: 9.76e-06\n",
      "Epoch   8 [10350/10697 ( 96.8%)] Loss: 0.027592 L1: 0.016192 Grad: 0.113768 Thermal: 0.000467 LR: 9.76e-06\n",
      "Epoch   8 [10400/10697 ( 97.2%)] Loss: 0.024599 L1: 0.014466 Grad: 0.101137 Thermal: 0.000381 LR: 9.76e-06\n",
      "Epoch   8 [10400/10697 ( 97.2%)] Loss: 0.024599 L1: 0.014466 Grad: 0.101137 Thermal: 0.000381 LR: 9.76e-06\n",
      "Epoch   8 [10450/10697 ( 97.7%)] Loss: 0.031962 L1: 0.018472 Grad: 0.134563 Thermal: 0.000684 LR: 9.76e-06\n",
      "Epoch   8 [10450/10697 ( 97.7%)] Loss: 0.031962 L1: 0.018472 Grad: 0.134563 Thermal: 0.000684 LR: 9.76e-06\n",
      "Epoch   8 [10500/10697 ( 98.2%)] Loss: 0.030303 L1: 0.017378 Grad: 0.128930 Thermal: 0.000624 LR: 9.76e-06\n",
      "Epoch   8 [10500/10697 ( 98.2%)] Loss: 0.030303 L1: 0.017378 Grad: 0.128930 Thermal: 0.000624 LR: 9.76e-06\n",
      "Epoch   8 [10550/10697 ( 98.6%)] Loss: 0.028338 L1: 0.016003 Grad: 0.123070 Thermal: 0.000556 LR: 9.76e-06\n",
      "Epoch   8 [10550/10697 ( 98.6%)] Loss: 0.028338 L1: 0.016003 Grad: 0.123070 Thermal: 0.000556 LR: 9.76e-06\n",
      "Epoch   8 [10600/10697 ( 99.1%)] Loss: 0.024627 L1: 0.014613 Grad: 0.099930 Thermal: 0.000417 LR: 9.76e-06\n",
      "Epoch   8 [10600/10697 ( 99.1%)] Loss: 0.024627 L1: 0.014613 Grad: 0.099930 Thermal: 0.000417 LR: 9.76e-06\n",
      "Epoch   8 [10650/10697 ( 99.6%)] Loss: 0.021336 L1: 0.012575 Grad: 0.087458 Thermal: 0.000314 LR: 9.76e-06\n",
      "Epoch   8 [10650/10697 ( 99.6%)] Loss: 0.021336 L1: 0.012575 Grad: 0.087458 Thermal: 0.000314 LR: 9.76e-06\n",
      "Epoch   8 Summary: Loss=0.026810 (L1:0.0156, Grad:0.1118, Thermal:0.0005) Val_PSNR=0.00dB Best=33.75dB Time=32.3min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch   8 Summary: Loss=0.026810 (L1:0.0156, Grad:0.1118, Thermal:0.0005) Val_PSNR=0.00dB Best=33.75dB Time=32.3min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch   9 [   0/10697 (  0.0%)] Loss: 0.025279 L1: 0.014607 Grad: 0.106525 Thermal: 0.000388 LR: 9.69e-06\n",
      "Epoch   9 [   0/10697 (  0.0%)] Loss: 0.025279 L1: 0.014607 Grad: 0.106525 Thermal: 0.000388 LR: 9.69e-06\n",
      "Epoch   9 [  50/10697 (  0.5%)] Loss: 0.029997 L1: 0.017319 Grad: 0.126448 Thermal: 0.000658 LR: 9.69e-06\n",
      "Epoch   9 [  50/10697 (  0.5%)] Loss: 0.029997 L1: 0.017319 Grad: 0.126448 Thermal: 0.000658 LR: 9.69e-06\n",
      "Epoch   9 [ 100/10697 (  0.9%)] Loss: 0.026161 L1: 0.015422 Grad: 0.107172 Thermal: 0.000433 LR: 9.69e-06\n",
      "Epoch   9 [ 100/10697 (  0.9%)] Loss: 0.026161 L1: 0.015422 Grad: 0.107172 Thermal: 0.000433 LR: 9.69e-06\n",
      "Epoch   9 [ 150/10697 (  1.4%)] Loss: 0.021504 L1: 0.012227 Grad: 0.092594 Thermal: 0.000348 LR: 9.69e-06\n",
      "Epoch   9 [ 150/10697 (  1.4%)] Loss: 0.021504 L1: 0.012227 Grad: 0.092594 Thermal: 0.000348 LR: 9.69e-06\n",
      "Epoch   9 [ 200/10697 (  1.9%)] Loss: 0.034040 L1: 0.020191 Grad: 0.138104 Thermal: 0.000779 LR: 9.69e-06\n",
      "Epoch   9 [ 200/10697 (  1.9%)] Loss: 0.034040 L1: 0.020191 Grad: 0.138104 Thermal: 0.000779 LR: 9.69e-06\n",
      "Epoch   9 [ 250/10697 (  2.3%)] Loss: 0.024435 L1: 0.014541 Grad: 0.098731 Thermal: 0.000400 LR: 9.69e-06\n",
      "Epoch   9 [ 250/10697 (  2.3%)] Loss: 0.024435 L1: 0.014541 Grad: 0.098731 Thermal: 0.000400 LR: 9.69e-06\n",
      "Epoch   9 [ 300/10697 (  2.8%)] Loss: 0.028409 L1: 0.016350 Grad: 0.120362 Thermal: 0.000455 LR: 9.69e-06\n",
      "Epoch   9 [ 300/10697 (  2.8%)] Loss: 0.028409 L1: 0.016350 Grad: 0.120362 Thermal: 0.000455 LR: 9.69e-06\n",
      "Epoch   9 [ 350/10697 (  3.3%)] Loss: 0.022086 L1: 0.012677 Grad: 0.093906 Thermal: 0.000360 LR: 9.69e-06\n",
      "Epoch   9 [ 350/10697 (  3.3%)] Loss: 0.022086 L1: 0.012677 Grad: 0.093906 Thermal: 0.000360 LR: 9.69e-06\n",
      "Epoch   9 [ 400/10697 (  3.7%)] Loss: 0.024240 L1: 0.014309 Grad: 0.099103 Thermal: 0.000411 LR: 9.69e-06\n",
      "Epoch   9 [ 400/10697 (  3.7%)] Loss: 0.024240 L1: 0.014309 Grad: 0.099103 Thermal: 0.000411 LR: 9.69e-06\n",
      "Epoch   9 [ 450/10697 (  4.2%)] Loss: 0.026941 L1: 0.015935 Grad: 0.109822 Thermal: 0.000482 LR: 9.69e-06\n",
      "Epoch   9 [ 450/10697 (  4.2%)] Loss: 0.026941 L1: 0.015935 Grad: 0.109822 Thermal: 0.000482 LR: 9.69e-06\n",
      "Epoch   9 [ 500/10697 (  4.7%)] Loss: 0.029056 L1: 0.016943 Grad: 0.120849 Thermal: 0.000555 LR: 9.69e-06\n",
      "Epoch   9 [ 500/10697 (  4.7%)] Loss: 0.029056 L1: 0.016943 Grad: 0.120849 Thermal: 0.000555 LR: 9.69e-06\n",
      "Epoch   9 [ 550/10697 (  5.1%)] Loss: 0.032343 L1: 0.018685 Grad: 0.136242 Thermal: 0.000670 LR: 9.69e-06\n",
      "Epoch   9 [ 550/10697 (  5.1%)] Loss: 0.032343 L1: 0.018685 Grad: 0.136242 Thermal: 0.000670 LR: 9.69e-06\n",
      "Epoch   9 [ 600/10697 (  5.6%)] Loss: 0.029463 L1: 0.016928 Grad: 0.125045 Thermal: 0.000592 LR: 9.69e-06\n",
      "Epoch   9 [ 600/10697 (  5.6%)] Loss: 0.029463 L1: 0.016928 Grad: 0.125045 Thermal: 0.000592 LR: 9.69e-06\n",
      "Epoch   9 [ 650/10697 (  6.1%)] Loss: 0.023446 L1: 0.013768 Grad: 0.096598 Thermal: 0.000356 LR: 9.69e-06\n",
      "Epoch   9 [ 650/10697 (  6.1%)] Loss: 0.023446 L1: 0.013768 Grad: 0.096598 Thermal: 0.000356 LR: 9.69e-06\n",
      "Epoch   9 [ 700/10697 (  6.5%)] Loss: 0.025643 L1: 0.014800 Grad: 0.108210 Thermal: 0.000443 LR: 9.69e-06\n",
      "Epoch   9 [ 700/10697 (  6.5%)] Loss: 0.025643 L1: 0.014800 Grad: 0.108210 Thermal: 0.000443 LR: 9.69e-06\n",
      "Epoch   9 [ 750/10697 (  7.0%)] Loss: 0.022192 L1: 0.012878 Grad: 0.092977 Thermal: 0.000319 LR: 9.69e-06\n",
      "Epoch   9 [ 750/10697 (  7.0%)] Loss: 0.022192 L1: 0.012878 Grad: 0.092977 Thermal: 0.000319 LR: 9.69e-06\n",
      "Epoch   9 [ 800/10697 (  7.5%)] Loss: 0.023944 L1: 0.013682 Grad: 0.102432 Thermal: 0.000375 LR: 9.69e-06\n",
      "Epoch   9 [ 800/10697 (  7.5%)] Loss: 0.023944 L1: 0.013682 Grad: 0.102432 Thermal: 0.000375 LR: 9.69e-06\n",
      "Epoch   9 [ 850/10697 (  7.9%)] Loss: 0.024868 L1: 0.014318 Grad: 0.105295 Thermal: 0.000395 LR: 9.69e-06\n",
      "Epoch   9 [ 850/10697 (  7.9%)] Loss: 0.024868 L1: 0.014318 Grad: 0.105295 Thermal: 0.000395 LR: 9.69e-06\n",
      "Epoch   9 [ 900/10697 (  8.4%)] Loss: 0.026583 L1: 0.015244 Grad: 0.113128 Thermal: 0.000516 LR: 9.69e-06\n",
      "Epoch   9 [ 900/10697 (  8.4%)] Loss: 0.026583 L1: 0.015244 Grad: 0.113128 Thermal: 0.000516 LR: 9.69e-06\n",
      "Epoch   9 [ 950/10697 (  8.9%)] Loss: 0.028869 L1: 0.017163 Grad: 0.116793 Thermal: 0.000538 LR: 9.69e-06\n",
      "Epoch   9 [ 950/10697 (  8.9%)] Loss: 0.028869 L1: 0.017163 Grad: 0.116793 Thermal: 0.000538 LR: 9.69e-06\n",
      "Epoch   9 [1000/10697 (  9.3%)] Loss: 0.027496 L1: 0.016393 Grad: 0.110806 Thermal: 0.000462 LR: 9.69e-06\n",
      "Epoch   9 [1000/10697 (  9.3%)] Loss: 0.027496 L1: 0.016393 Grad: 0.110806 Thermal: 0.000462 LR: 9.69e-06\n",
      "Epoch   9 [1050/10697 (  9.8%)] Loss: 0.024099 L1: 0.014087 Grad: 0.099926 Thermal: 0.000382 LR: 9.69e-06\n",
      "Epoch   9 [1050/10697 (  9.8%)] Loss: 0.024099 L1: 0.014087 Grad: 0.099926 Thermal: 0.000382 LR: 9.69e-06\n",
      "Epoch   9 [1100/10697 ( 10.3%)] Loss: 0.028372 L1: 0.016187 Grad: 0.121618 Thermal: 0.000462 LR: 9.69e-06\n",
      "Epoch   9 [1100/10697 ( 10.3%)] Loss: 0.028372 L1: 0.016187 Grad: 0.121618 Thermal: 0.000462 LR: 9.69e-06\n",
      "Epoch   9 [1150/10697 ( 10.8%)] Loss: 0.024746 L1: 0.014676 Grad: 0.100503 Thermal: 0.000404 LR: 9.69e-06\n",
      "Epoch   9 [1150/10697 ( 10.8%)] Loss: 0.024746 L1: 0.014676 Grad: 0.100503 Thermal: 0.000404 LR: 9.69e-06\n",
      "Epoch   9 [1200/10697 ( 11.2%)] Loss: 0.021624 L1: 0.012614 Grad: 0.089920 Thermal: 0.000353 LR: 9.69e-06\n",
      "Epoch   9 [1200/10697 ( 11.2%)] Loss: 0.021624 L1: 0.012614 Grad: 0.089920 Thermal: 0.000353 LR: 9.69e-06\n",
      "Epoch   9 [1250/10697 ( 11.7%)] Loss: 0.022058 L1: 0.012737 Grad: 0.093033 Thermal: 0.000356 LR: 9.69e-06\n",
      "Epoch   9 [1250/10697 ( 11.7%)] Loss: 0.022058 L1: 0.012737 Grad: 0.093033 Thermal: 0.000356 LR: 9.69e-06\n",
      "Epoch   9 [1300/10697 ( 12.2%)] Loss: 0.022907 L1: 0.013438 Grad: 0.094486 Thermal: 0.000414 LR: 9.69e-06\n",
      "Epoch   9 [1300/10697 ( 12.2%)] Loss: 0.022907 L1: 0.013438 Grad: 0.094486 Thermal: 0.000414 LR: 9.69e-06\n",
      "Epoch   9 [1350/10697 ( 12.6%)] Loss: 0.026502 L1: 0.015351 Grad: 0.111301 Thermal: 0.000427 LR: 9.69e-06\n",
      "Epoch   9 [1350/10697 ( 12.6%)] Loss: 0.026502 L1: 0.015351 Grad: 0.111301 Thermal: 0.000427 LR: 9.69e-06\n",
      "Epoch   9 [1400/10697 ( 13.1%)] Loss: 0.026345 L1: 0.015808 Grad: 0.105136 Thermal: 0.000469 LR: 9.69e-06\n",
      "Epoch   9 [1400/10697 ( 13.1%)] Loss: 0.026345 L1: 0.015808 Grad: 0.105136 Thermal: 0.000469 LR: 9.69e-06\n",
      "Epoch   9 [1450/10697 ( 13.6%)] Loss: 0.025478 L1: 0.014895 Grad: 0.105606 Thermal: 0.000439 LR: 9.69e-06\n",
      "Epoch   9 [1450/10697 ( 13.6%)] Loss: 0.025478 L1: 0.014895 Grad: 0.105606 Thermal: 0.000439 LR: 9.69e-06\n",
      "Epoch   9 [1500/10697 ( 14.0%)] Loss: 0.028879 L1: 0.016428 Grad: 0.124250 Thermal: 0.000514 LR: 9.69e-06\n",
      "Epoch   9 [1500/10697 ( 14.0%)] Loss: 0.028879 L1: 0.016428 Grad: 0.124250 Thermal: 0.000514 LR: 9.69e-06\n",
      "Epoch   9 [1550/10697 ( 14.5%)] Loss: 0.028192 L1: 0.015866 Grad: 0.123025 Thermal: 0.000484 LR: 9.69e-06\n",
      "Epoch   9 [1550/10697 ( 14.5%)] Loss: 0.028192 L1: 0.015866 Grad: 0.123025 Thermal: 0.000484 LR: 9.69e-06\n",
      "Epoch   9 [1600/10697 ( 15.0%)] Loss: 0.022073 L1: 0.012225 Grad: 0.098321 Thermal: 0.000316 LR: 9.69e-06\n",
      "Epoch   9 [1600/10697 ( 15.0%)] Loss: 0.022073 L1: 0.012225 Grad: 0.098321 Thermal: 0.000316 LR: 9.69e-06\n",
      "Epoch   9 [1650/10697 ( 15.4%)] Loss: 0.029555 L1: 0.017552 Grad: 0.119769 Thermal: 0.000534 LR: 9.69e-06\n",
      "Epoch   9 [1650/10697 ( 15.4%)] Loss: 0.029555 L1: 0.017552 Grad: 0.119769 Thermal: 0.000534 LR: 9.69e-06\n",
      "Epoch   9 [1700/10697 ( 15.9%)] Loss: 0.024993 L1: 0.014740 Grad: 0.102318 Thermal: 0.000422 LR: 9.69e-06\n",
      "Epoch   9 [1700/10697 ( 15.9%)] Loss: 0.024993 L1: 0.014740 Grad: 0.102318 Thermal: 0.000422 LR: 9.69e-06\n",
      "Epoch   9 [1750/10697 ( 16.4%)] Loss: 0.029738 L1: 0.017197 Grad: 0.125107 Thermal: 0.000594 LR: 9.69e-06\n",
      "Epoch   9 [1750/10697 ( 16.4%)] Loss: 0.029738 L1: 0.017197 Grad: 0.125107 Thermal: 0.000594 LR: 9.69e-06\n",
      "Epoch   9 [1800/10697 ( 16.8%)] Loss: 0.022437 L1: 0.013231 Grad: 0.091886 Thermal: 0.000366 LR: 9.69e-06\n",
      "Epoch   9 [1800/10697 ( 16.8%)] Loss: 0.022437 L1: 0.013231 Grad: 0.091886 Thermal: 0.000366 LR: 9.69e-06\n",
      "Epoch   9 [1850/10697 ( 17.3%)] Loss: 0.021810 L1: 0.012666 Grad: 0.091289 Thermal: 0.000305 LR: 9.69e-06\n",
      "Epoch   9 [1850/10697 ( 17.3%)] Loss: 0.021810 L1: 0.012666 Grad: 0.091289 Thermal: 0.000305 LR: 9.69e-06\n",
      "Epoch   9 [1900/10697 ( 17.8%)] Loss: 0.023248 L1: 0.013332 Grad: 0.098991 Thermal: 0.000353 LR: 9.69e-06\n",
      "Epoch   9 [1900/10697 ( 17.8%)] Loss: 0.023248 L1: 0.013332 Grad: 0.098991 Thermal: 0.000353 LR: 9.69e-06\n",
      "Epoch   9 [1950/10697 ( 18.2%)] Loss: 0.025847 L1: 0.014626 Grad: 0.111974 Thermal: 0.000479 LR: 9.69e-06\n",
      "Epoch   9 [1950/10697 ( 18.2%)] Loss: 0.025847 L1: 0.014626 Grad: 0.111974 Thermal: 0.000479 LR: 9.69e-06\n",
      "Epoch   9 [2000/10697 ( 18.7%)] Loss: 0.023420 L1: 0.013555 Grad: 0.098487 Thermal: 0.000338 LR: 9.69e-06\n",
      "Epoch   9 [2000/10697 ( 18.7%)] Loss: 0.023420 L1: 0.013555 Grad: 0.098487 Thermal: 0.000338 LR: 9.69e-06\n",
      "Epoch   9 [2050/10697 ( 19.2%)] Loss: 0.025896 L1: 0.015087 Grad: 0.107869 Thermal: 0.000453 LR: 9.69e-06\n",
      "Epoch   9 [2050/10697 ( 19.2%)] Loss: 0.025896 L1: 0.015087 Grad: 0.107869 Thermal: 0.000453 LR: 9.69e-06\n",
      "Epoch   9 [2100/10697 ( 19.6%)] Loss: 0.023519 L1: 0.013856 Grad: 0.096441 Thermal: 0.000373 LR: 9.69e-06\n",
      "Epoch   9 [2100/10697 ( 19.6%)] Loss: 0.023519 L1: 0.013856 Grad: 0.096441 Thermal: 0.000373 LR: 9.69e-06\n",
      "Epoch   9 [2150/10697 ( 20.1%)] Loss: 0.028654 L1: 0.016382 Grad: 0.122465 Thermal: 0.000528 LR: 9.69e-06\n",
      "Epoch   9 [2150/10697 ( 20.1%)] Loss: 0.028654 L1: 0.016382 Grad: 0.122465 Thermal: 0.000528 LR: 9.69e-06\n",
      "Epoch   9 [2200/10697 ( 20.6%)] Loss: 0.025747 L1: 0.014994 Grad: 0.107320 Thermal: 0.000429 LR: 9.69e-06\n",
      "Epoch   9 [2200/10697 ( 20.6%)] Loss: 0.025747 L1: 0.014994 Grad: 0.107320 Thermal: 0.000429 LR: 9.69e-06\n",
      "Epoch   9 [2250/10697 ( 21.0%)] Loss: 0.027566 L1: 0.016305 Grad: 0.112383 Thermal: 0.000446 LR: 9.69e-06\n",
      "Epoch   9 [2250/10697 ( 21.0%)] Loss: 0.027566 L1: 0.016305 Grad: 0.112383 Thermal: 0.000446 LR: 9.69e-06\n",
      "Epoch   9 [2300/10697 ( 21.5%)] Loss: 0.023548 L1: 0.013674 Grad: 0.098560 Thermal: 0.000362 LR: 9.69e-06\n",
      "Epoch   9 [2300/10697 ( 21.5%)] Loss: 0.023548 L1: 0.013674 Grad: 0.098560 Thermal: 0.000362 LR: 9.69e-06\n",
      "Epoch   9 [2350/10697 ( 22.0%)] Loss: 0.026493 L1: 0.015145 Grad: 0.113245 Thermal: 0.000457 LR: 9.69e-06\n",
      "Epoch   9 [2350/10697 ( 22.0%)] Loss: 0.026493 L1: 0.015145 Grad: 0.113245 Thermal: 0.000457 LR: 9.69e-06\n",
      "Epoch   9 [2400/10697 ( 22.4%)] Loss: 0.024706 L1: 0.014526 Grad: 0.101607 Thermal: 0.000398 LR: 9.69e-06\n",
      "Epoch   9 [2400/10697 ( 22.4%)] Loss: 0.024706 L1: 0.014526 Grad: 0.101607 Thermal: 0.000398 LR: 9.69e-06\n",
      "Epoch   9 [2450/10697 ( 22.9%)] Loss: 0.025709 L1: 0.014616 Grad: 0.110726 Thermal: 0.000407 LR: 9.69e-06\n",
      "Epoch   9 [2450/10697 ( 22.9%)] Loss: 0.025709 L1: 0.014616 Grad: 0.110726 Thermal: 0.000407 LR: 9.69e-06\n",
      "Epoch   9 [2500/10697 ( 23.4%)] Loss: 0.021899 L1: 0.012293 Grad: 0.095915 Thermal: 0.000290 LR: 9.69e-06\n",
      "Epoch   9 [2500/10697 ( 23.4%)] Loss: 0.021899 L1: 0.012293 Grad: 0.095915 Thermal: 0.000290 LR: 9.69e-06\n",
      "Epoch   9 [2550/10697 ( 23.8%)] Loss: 0.022298 L1: 0.013184 Grad: 0.090955 Thermal: 0.000363 LR: 9.69e-06\n",
      "Epoch   9 [2550/10697 ( 23.8%)] Loss: 0.022298 L1: 0.013184 Grad: 0.090955 Thermal: 0.000363 LR: 9.69e-06\n",
      "Epoch   9 [2600/10697 ( 24.3%)] Loss: 0.024584 L1: 0.014579 Grad: 0.099851 Thermal: 0.000396 LR: 9.69e-06\n",
      "Epoch   9 [2600/10697 ( 24.3%)] Loss: 0.024584 L1: 0.014579 Grad: 0.099851 Thermal: 0.000396 LR: 9.69e-06\n",
      "Epoch   9 [2650/10697 ( 24.8%)] Loss: 0.025133 L1: 0.014809 Grad: 0.103042 Thermal: 0.000397 LR: 9.69e-06\n",
      "Epoch   9 [2650/10697 ( 24.8%)] Loss: 0.025133 L1: 0.014809 Grad: 0.103042 Thermal: 0.000397 LR: 9.69e-06\n",
      "Epoch   9 [2700/10697 ( 25.2%)] Loss: 0.030543 L1: 0.017618 Grad: 0.128971 Thermal: 0.000555 LR: 9.69e-06\n",
      "Epoch   9 [2700/10697 ( 25.2%)] Loss: 0.030543 L1: 0.017618 Grad: 0.128971 Thermal: 0.000555 LR: 9.69e-06\n",
      "Epoch   9 [2750/10697 ( 25.7%)] Loss: 0.029358 L1: 0.016428 Grad: 0.129000 Thermal: 0.000607 LR: 9.69e-06\n",
      "Epoch   9 [2750/10697 ( 25.7%)] Loss: 0.029358 L1: 0.016428 Grad: 0.129000 Thermal: 0.000607 LR: 9.69e-06\n",
      "Epoch   9 [2800/10697 ( 26.2%)] Loss: 0.028577 L1: 0.016415 Grad: 0.121358 Thermal: 0.000527 LR: 9.69e-06\n",
      "Epoch   9 [2800/10697 ( 26.2%)] Loss: 0.028577 L1: 0.016415 Grad: 0.121358 Thermal: 0.000527 LR: 9.69e-06\n",
      "Epoch   9 [2850/10697 ( 26.6%)] Loss: 0.025286 L1: 0.014794 Grad: 0.104715 Thermal: 0.000402 LR: 9.69e-06\n",
      "Epoch   9 [2850/10697 ( 26.6%)] Loss: 0.025286 L1: 0.014794 Grad: 0.104715 Thermal: 0.000402 LR: 9.69e-06\n",
      "Epoch   9 [2900/10697 ( 27.1%)] Loss: 0.022806 L1: 0.012985 Grad: 0.098042 Thermal: 0.000333 LR: 9.69e-06\n",
      "Epoch   9 [2900/10697 ( 27.1%)] Loss: 0.022806 L1: 0.012985 Grad: 0.098042 Thermal: 0.000333 LR: 9.69e-06\n",
      "Epoch   9 [2950/10697 ( 27.6%)] Loss: 0.031647 L1: 0.018399 Grad: 0.132168 Thermal: 0.000638 LR: 9.69e-06\n",
      "Epoch   9 [2950/10697 ( 27.6%)] Loss: 0.031647 L1: 0.018399 Grad: 0.132168 Thermal: 0.000638 LR: 9.69e-06\n",
      "Epoch   9 [3000/10697 ( 28.0%)] Loss: 0.024585 L1: 0.013868 Grad: 0.106982 Thermal: 0.000387 LR: 9.69e-06\n",
      "Epoch   9 [3000/10697 ( 28.0%)] Loss: 0.024585 L1: 0.013868 Grad: 0.106982 Thermal: 0.000387 LR: 9.69e-06\n",
      "Epoch   9 [3050/10697 ( 28.5%)] Loss: 0.023730 L1: 0.014113 Grad: 0.095967 Thermal: 0.000390 LR: 9.69e-06\n",
      "Epoch   9 [3050/10697 ( 28.5%)] Loss: 0.023730 L1: 0.014113 Grad: 0.095967 Thermal: 0.000390 LR: 9.69e-06\n",
      "Epoch   9 [3100/10697 ( 29.0%)] Loss: 0.026290 L1: 0.015255 Grad: 0.110100 Thermal: 0.000504 LR: 9.69e-06\n",
      "Epoch   9 [3100/10697 ( 29.0%)] Loss: 0.026290 L1: 0.015255 Grad: 0.110100 Thermal: 0.000504 LR: 9.69e-06\n",
      "Epoch   9 [3150/10697 ( 29.4%)] Loss: 0.025985 L1: 0.015304 Grad: 0.106588 Thermal: 0.000436 LR: 9.69e-06\n",
      "Epoch   9 [3150/10697 ( 29.4%)] Loss: 0.025985 L1: 0.015304 Grad: 0.106588 Thermal: 0.000436 LR: 9.69e-06\n",
      "Epoch   9 [3200/10697 ( 29.9%)] Loss: 0.026749 L1: 0.015586 Grad: 0.111397 Thermal: 0.000465 LR: 9.69e-06\n",
      "Epoch   9 [3200/10697 ( 29.9%)] Loss: 0.026749 L1: 0.015586 Grad: 0.111397 Thermal: 0.000465 LR: 9.69e-06\n",
      "Epoch   9 [3250/10697 ( 30.4%)] Loss: 0.023714 L1: 0.013780 Grad: 0.099106 Thermal: 0.000479 LR: 9.69e-06\n",
      "Epoch   9 [3250/10697 ( 30.4%)] Loss: 0.023714 L1: 0.013780 Grad: 0.099106 Thermal: 0.000479 LR: 9.69e-06\n",
      "Epoch   9 [3300/10697 ( 30.8%)] Loss: 0.021734 L1: 0.012714 Grad: 0.090044 Thermal: 0.000319 LR: 9.69e-06\n",
      "Epoch   9 [3300/10697 ( 30.8%)] Loss: 0.021734 L1: 0.012714 Grad: 0.090044 Thermal: 0.000319 LR: 9.69e-06\n",
      "Epoch   9 [3350/10697 ( 31.3%)] Loss: 0.029301 L1: 0.017458 Grad: 0.118148 Thermal: 0.000563 LR: 9.69e-06\n",
      "Epoch   9 [3350/10697 ( 31.3%)] Loss: 0.029301 L1: 0.017458 Grad: 0.118148 Thermal: 0.000563 LR: 9.69e-06\n",
      "Epoch   9 [3400/10697 ( 31.8%)] Loss: 0.024645 L1: 0.014218 Grad: 0.104080 Thermal: 0.000370 LR: 9.69e-06\n",
      "Epoch   9 [3400/10697 ( 31.8%)] Loss: 0.024645 L1: 0.014218 Grad: 0.104080 Thermal: 0.000370 LR: 9.69e-06\n",
      "Epoch   9 [3450/10697 ( 32.3%)] Loss: 0.022622 L1: 0.013417 Grad: 0.091870 Thermal: 0.000363 LR: 9.69e-06\n",
      "Epoch   9 [3450/10697 ( 32.3%)] Loss: 0.022622 L1: 0.013417 Grad: 0.091870 Thermal: 0.000363 LR: 9.69e-06\n",
      "Epoch   9 [3500/10697 ( 32.7%)] Loss: 0.028397 L1: 0.016559 Grad: 0.118129 Thermal: 0.000503 LR: 9.69e-06\n",
      "Epoch   9 [3500/10697 ( 32.7%)] Loss: 0.028397 L1: 0.016559 Grad: 0.118129 Thermal: 0.000503 LR: 9.69e-06\n",
      "Epoch   9 [3550/10697 ( 33.2%)] Loss: 0.028255 L1: 0.016592 Grad: 0.116382 Thermal: 0.000480 LR: 9.69e-06\n",
      "Epoch   9 [3550/10697 ( 33.2%)] Loss: 0.028255 L1: 0.016592 Grad: 0.116382 Thermal: 0.000480 LR: 9.69e-06\n",
      "Epoch   9 [3600/10697 ( 33.7%)] Loss: 0.024379 L1: 0.013826 Grad: 0.105351 Thermal: 0.000360 LR: 9.69e-06\n",
      "Epoch   9 [3600/10697 ( 33.7%)] Loss: 0.024379 L1: 0.013826 Grad: 0.105351 Thermal: 0.000360 LR: 9.69e-06\n",
      "Epoch   9 [3650/10697 ( 34.1%)] Loss: 0.029123 L1: 0.016719 Grad: 0.123773 Thermal: 0.000530 LR: 9.69e-06\n",
      "Epoch   9 [3650/10697 ( 34.1%)] Loss: 0.029123 L1: 0.016719 Grad: 0.123773 Thermal: 0.000530 LR: 9.69e-06\n",
      "Epoch   9 [3700/10697 ( 34.6%)] Loss: 0.021322 L1: 0.012647 Grad: 0.086583 Thermal: 0.000317 LR: 9.69e-06\n",
      "Epoch   9 [3700/10697 ( 34.6%)] Loss: 0.021322 L1: 0.012647 Grad: 0.086583 Thermal: 0.000317 LR: 9.69e-06\n",
      "Epoch   9 [3750/10697 ( 35.1%)] Loss: 0.022560 L1: 0.012823 Grad: 0.097193 Thermal: 0.000352 LR: 9.69e-06\n",
      "Epoch   9 [3750/10697 ( 35.1%)] Loss: 0.022560 L1: 0.012823 Grad: 0.097193 Thermal: 0.000352 LR: 9.69e-06\n",
      "Epoch   9 [3800/10697 ( 35.5%)] Loss: 0.031560 L1: 0.018542 Grad: 0.129872 Thermal: 0.000630 LR: 9.69e-06\n",
      "Epoch   9 [3800/10697 ( 35.5%)] Loss: 0.031560 L1: 0.018542 Grad: 0.129872 Thermal: 0.000630 LR: 9.69e-06\n",
      "Epoch   9 [3850/10697 ( 36.0%)] Loss: 0.027524 L1: 0.015758 Grad: 0.117415 Thermal: 0.000498 LR: 9.69e-06\n",
      "Epoch   9 [3850/10697 ( 36.0%)] Loss: 0.027524 L1: 0.015758 Grad: 0.117415 Thermal: 0.000498 LR: 9.69e-06\n",
      "Epoch   9 [3900/10697 ( 36.5%)] Loss: 0.025632 L1: 0.015095 Grad: 0.105149 Thermal: 0.000450 LR: 9.69e-06\n",
      "Epoch   9 [3900/10697 ( 36.5%)] Loss: 0.025632 L1: 0.015095 Grad: 0.105149 Thermal: 0.000450 LR: 9.69e-06\n",
      "Epoch   9 [3950/10697 ( 36.9%)] Loss: 0.028290 L1: 0.016424 Grad: 0.118435 Thermal: 0.000468 LR: 9.69e-06\n",
      "Epoch   9 [3950/10697 ( 36.9%)] Loss: 0.028290 L1: 0.016424 Grad: 0.118435 Thermal: 0.000468 LR: 9.69e-06\n",
      "Epoch   9 [4000/10697 ( 37.4%)] Loss: 0.026600 L1: 0.015446 Grad: 0.111312 Thermal: 0.000453 LR: 9.69e-06\n",
      "Epoch   9 [4000/10697 ( 37.4%)] Loss: 0.026600 L1: 0.015446 Grad: 0.111312 Thermal: 0.000453 LR: 9.69e-06\n",
      "Epoch   9 [4050/10697 ( 37.9%)] Loss: 0.022727 L1: 0.012976 Grad: 0.097313 Thermal: 0.000399 LR: 9.69e-06\n",
      "Epoch   9 [4050/10697 ( 37.9%)] Loss: 0.022727 L1: 0.012976 Grad: 0.097313 Thermal: 0.000399 LR: 9.69e-06\n",
      "Epoch   9 [4100/10697 ( 38.3%)] Loss: 0.027170 L1: 0.015859 Grad: 0.112866 Thermal: 0.000489 LR: 9.69e-06\n",
      "Epoch   9 [4100/10697 ( 38.3%)] Loss: 0.027170 L1: 0.015859 Grad: 0.112866 Thermal: 0.000489 LR: 9.69e-06\n",
      "Epoch   9 [4150/10697 ( 38.8%)] Loss: 0.026277 L1: 0.015400 Grad: 0.108561 Thermal: 0.000429 LR: 9.69e-06\n",
      "Epoch   9 [4150/10697 ( 38.8%)] Loss: 0.026277 L1: 0.015400 Grad: 0.108561 Thermal: 0.000429 LR: 9.69e-06\n",
      "Epoch   9 [4200/10697 ( 39.3%)] Loss: 0.021582 L1: 0.012580 Grad: 0.089875 Thermal: 0.000300 LR: 9.69e-06\n",
      "Epoch   9 [4200/10697 ( 39.3%)] Loss: 0.021582 L1: 0.012580 Grad: 0.089875 Thermal: 0.000300 LR: 9.69e-06\n",
      "Epoch   9 [4250/10697 ( 39.7%)] Loss: 0.025630 L1: 0.014638 Grad: 0.109720 Thermal: 0.000412 LR: 9.69e-06\n",
      "Epoch   9 [4250/10697 ( 39.7%)] Loss: 0.025630 L1: 0.014638 Grad: 0.109720 Thermal: 0.000412 LR: 9.69e-06\n",
      "Epoch   9 [4300/10697 ( 40.2%)] Loss: 0.032432 L1: 0.018414 Grad: 0.139875 Thermal: 0.000603 LR: 9.69e-06\n",
      "Epoch   9 [4300/10697 ( 40.2%)] Loss: 0.032432 L1: 0.018414 Grad: 0.139875 Thermal: 0.000603 LR: 9.69e-06\n",
      "Epoch   9 [4350/10697 ( 40.7%)] Loss: 0.023722 L1: 0.013697 Grad: 0.100066 Thermal: 0.000367 LR: 9.69e-06\n",
      "Epoch   9 [4350/10697 ( 40.7%)] Loss: 0.023722 L1: 0.013697 Grad: 0.100066 Thermal: 0.000367 LR: 9.69e-06\n",
      "Epoch   9 [4400/10697 ( 41.1%)] Loss: 0.027731 L1: 0.016127 Grad: 0.115784 Thermal: 0.000505 LR: 9.69e-06\n",
      "Epoch   9 [4400/10697 ( 41.1%)] Loss: 0.027731 L1: 0.016127 Grad: 0.115784 Thermal: 0.000505 LR: 9.69e-06\n",
      "Epoch   9 [4450/10697 ( 41.6%)] Loss: 0.034298 L1: 0.019652 Grad: 0.146065 Thermal: 0.000787 LR: 9.69e-06\n",
      "Epoch   9 [4450/10697 ( 41.6%)] Loss: 0.034298 L1: 0.019652 Grad: 0.146065 Thermal: 0.000787 LR: 9.69e-06\n",
      "Epoch   9 [4500/10697 ( 42.1%)] Loss: 0.033753 L1: 0.019661 Grad: 0.140549 Thermal: 0.000747 LR: 9.69e-06\n",
      "Epoch   9 [4500/10697 ( 42.1%)] Loss: 0.033753 L1: 0.019661 Grad: 0.140549 Thermal: 0.000747 LR: 9.69e-06\n",
      "Epoch   9 [4550/10697 ( 42.5%)] Loss: 0.027780 L1: 0.016169 Grad: 0.115826 Thermal: 0.000573 LR: 9.69e-06\n",
      "Epoch   9 [4550/10697 ( 42.5%)] Loss: 0.027780 L1: 0.016169 Grad: 0.115826 Thermal: 0.000573 LR: 9.69e-06\n",
      "Epoch   9 [4600/10697 ( 43.0%)] Loss: 0.025858 L1: 0.014814 Grad: 0.110236 Thermal: 0.000408 LR: 9.69e-06\n",
      "Epoch   9 [4600/10697 ( 43.0%)] Loss: 0.025858 L1: 0.014814 Grad: 0.110236 Thermal: 0.000408 LR: 9.69e-06\n",
      "Epoch   9 [4650/10697 ( 43.5%)] Loss: 0.027074 L1: 0.015982 Grad: 0.110694 Thermal: 0.000448 LR: 9.69e-06\n",
      "Epoch   9 [4650/10697 ( 43.5%)] Loss: 0.027074 L1: 0.015982 Grad: 0.110694 Thermal: 0.000448 LR: 9.69e-06\n",
      "Epoch   9 [4700/10697 ( 43.9%)] Loss: 0.024629 L1: 0.014369 Grad: 0.102391 Thermal: 0.000408 LR: 9.69e-06\n",
      "Epoch   9 [4700/10697 ( 43.9%)] Loss: 0.024629 L1: 0.014369 Grad: 0.102391 Thermal: 0.000408 LR: 9.69e-06\n",
      "Epoch   9 [4750/10697 ( 44.4%)] Loss: 0.025393 L1: 0.014376 Grad: 0.109982 Thermal: 0.000383 LR: 9.69e-06\n",
      "Epoch   9 [4750/10697 ( 44.4%)] Loss: 0.025393 L1: 0.014376 Grad: 0.109982 Thermal: 0.000383 LR: 9.69e-06\n",
      "Epoch   9 [4800/10697 ( 44.9%)] Loss: 0.024245 L1: 0.014072 Grad: 0.101532 Thermal: 0.000385 LR: 9.69e-06\n",
      "Epoch   9 [4800/10697 ( 44.9%)] Loss: 0.024245 L1: 0.014072 Grad: 0.101532 Thermal: 0.000385 LR: 9.69e-06\n",
      "Epoch   9 [4850/10697 ( 45.3%)] Loss: 0.029616 L1: 0.017531 Grad: 0.120570 Thermal: 0.000543 LR: 9.69e-06\n",
      "Epoch   9 [4850/10697 ( 45.3%)] Loss: 0.029616 L1: 0.017531 Grad: 0.120570 Thermal: 0.000543 LR: 9.69e-06\n",
      "Epoch   9 [4900/10697 ( 45.8%)] Loss: 0.030490 L1: 0.017999 Grad: 0.124589 Thermal: 0.000649 LR: 9.69e-06\n",
      "Epoch   9 [4900/10697 ( 45.8%)] Loss: 0.030490 L1: 0.017999 Grad: 0.124589 Thermal: 0.000649 LR: 9.69e-06\n",
      "Epoch   9 [4950/10697 ( 46.3%)] Loss: 0.021838 L1: 0.012835 Grad: 0.089859 Thermal: 0.000340 LR: 9.69e-06\n",
      "Epoch   9 [4950/10697 ( 46.3%)] Loss: 0.021838 L1: 0.012835 Grad: 0.089859 Thermal: 0.000340 LR: 9.69e-06\n",
      "Epoch   9 [5000/10697 ( 46.7%)] Loss: 0.030752 L1: 0.017693 Grad: 0.130298 Thermal: 0.000584 LR: 9.69e-06\n",
      "Epoch   9 [5000/10697 ( 46.7%)] Loss: 0.030752 L1: 0.017693 Grad: 0.130298 Thermal: 0.000584 LR: 9.69e-06\n",
      "Epoch   9 [5050/10697 ( 47.2%)] Loss: 0.023474 L1: 0.013864 Grad: 0.095915 Thermal: 0.000361 LR: 9.69e-06\n",
      "Epoch   9 [5050/10697 ( 47.2%)] Loss: 0.023474 L1: 0.013864 Grad: 0.095915 Thermal: 0.000361 LR: 9.69e-06\n",
      "Epoch   9 [5100/10697 ( 47.7%)] Loss: 0.023466 L1: 0.013597 Grad: 0.098508 Thermal: 0.000361 LR: 9.69e-06\n",
      "Epoch   9 [5100/10697 ( 47.7%)] Loss: 0.023466 L1: 0.013597 Grad: 0.098508 Thermal: 0.000361 LR: 9.69e-06\n",
      "Epoch   9 [5150/10697 ( 48.1%)] Loss: 0.026054 L1: 0.015117 Grad: 0.109116 Thermal: 0.000509 LR: 9.69e-06\n",
      "Epoch   9 [5150/10697 ( 48.1%)] Loss: 0.026054 L1: 0.015117 Grad: 0.109116 Thermal: 0.000509 LR: 9.69e-06\n",
      "Epoch   9 [5200/10697 ( 48.6%)] Loss: 0.031062 L1: 0.018018 Grad: 0.130130 Thermal: 0.000629 LR: 9.69e-06\n",
      "Epoch   9 [5200/10697 ( 48.6%)] Loss: 0.031062 L1: 0.018018 Grad: 0.130130 Thermal: 0.000629 LR: 9.69e-06\n",
      "Epoch   9 [5250/10697 ( 49.1%)] Loss: 0.035477 L1: 0.020354 Grad: 0.150804 Thermal: 0.000848 LR: 9.69e-06\n",
      "Epoch   9 [5250/10697 ( 49.1%)] Loss: 0.035477 L1: 0.020354 Grad: 0.150804 Thermal: 0.000848 LR: 9.69e-06\n",
      "Epoch   9 [5300/10697 ( 49.5%)] Loss: 0.028912 L1: 0.016946 Grad: 0.119407 Thermal: 0.000508 LR: 9.69e-06\n",
      "Epoch   9 [5300/10697 ( 49.5%)] Loss: 0.028912 L1: 0.016946 Grad: 0.119407 Thermal: 0.000508 LR: 9.69e-06\n",
      "Epoch   9 [5350/10697 ( 50.0%)] Loss: 0.028706 L1: 0.016664 Grad: 0.120171 Thermal: 0.000503 LR: 9.69e-06\n",
      "Epoch   9 [5350/10697 ( 50.0%)] Loss: 0.028706 L1: 0.016664 Grad: 0.120171 Thermal: 0.000503 LR: 9.69e-06\n",
      "Epoch   9 [5400/10697 ( 50.5%)] Loss: 0.027159 L1: 0.015405 Grad: 0.117291 Thermal: 0.000513 LR: 9.69e-06\n",
      "Epoch   9 [5400/10697 ( 50.5%)] Loss: 0.027159 L1: 0.015405 Grad: 0.117291 Thermal: 0.000513 LR: 9.69e-06\n",
      "Epoch   9 [5450/10697 ( 50.9%)] Loss: 0.026394 L1: 0.014981 Grad: 0.113886 Thermal: 0.000486 LR: 9.69e-06\n",
      "Epoch   9 [5450/10697 ( 50.9%)] Loss: 0.026394 L1: 0.014981 Grad: 0.113886 Thermal: 0.000486 LR: 9.69e-06\n",
      "Epoch   9 [5500/10697 ( 51.4%)] Loss: 0.019599 L1: 0.011419 Grad: 0.081666 Thermal: 0.000285 LR: 9.69e-06\n",
      "Epoch   9 [5500/10697 ( 51.4%)] Loss: 0.019599 L1: 0.011419 Grad: 0.081666 Thermal: 0.000285 LR: 9.69e-06\n",
      "Epoch   9 [5550/10697 ( 51.9%)] Loss: 0.021406 L1: 0.012614 Grad: 0.087764 Thermal: 0.000311 LR: 9.69e-06\n",
      "Epoch   9 [5550/10697 ( 51.9%)] Loss: 0.021406 L1: 0.012614 Grad: 0.087764 Thermal: 0.000311 LR: 9.69e-06\n",
      "Epoch   9 [5600/10697 ( 52.4%)] Loss: 0.031531 L1: 0.018362 Grad: 0.131364 Thermal: 0.000635 LR: 9.69e-06\n",
      "Epoch   9 [5600/10697 ( 52.4%)] Loss: 0.031531 L1: 0.018362 Grad: 0.131364 Thermal: 0.000635 LR: 9.69e-06\n",
      "Epoch   9 [5650/10697 ( 52.8%)] Loss: 0.022401 L1: 0.013056 Grad: 0.093272 Thermal: 0.000349 LR: 9.69e-06\n",
      "Epoch   9 [5650/10697 ( 52.8%)] Loss: 0.022401 L1: 0.013056 Grad: 0.093272 Thermal: 0.000349 LR: 9.69e-06\n",
      "Epoch   9 [5700/10697 ( 53.3%)] Loss: 0.022566 L1: 0.013061 Grad: 0.094884 Thermal: 0.000335 LR: 9.69e-06\n",
      "Epoch   9 [5700/10697 ( 53.3%)] Loss: 0.022566 L1: 0.013061 Grad: 0.094884 Thermal: 0.000335 LR: 9.69e-06\n",
      "Epoch   9 [5750/10697 ( 53.8%)] Loss: 0.028332 L1: 0.016483 Grad: 0.118237 Thermal: 0.000505 LR: 9.69e-06\n",
      "Epoch   9 [5750/10697 ( 53.8%)] Loss: 0.028332 L1: 0.016483 Grad: 0.118237 Thermal: 0.000505 LR: 9.69e-06\n",
      "Epoch   9 [5800/10697 ( 54.2%)] Loss: 0.023668 L1: 0.013594 Grad: 0.100553 Thermal: 0.000374 LR: 9.69e-06\n",
      "Epoch   9 [5800/10697 ( 54.2%)] Loss: 0.023668 L1: 0.013594 Grad: 0.100553 Thermal: 0.000374 LR: 9.69e-06\n",
      "Epoch   9 [5850/10697 ( 54.7%)] Loss: 0.032232 L1: 0.018926 Grad: 0.132749 Thermal: 0.000630 LR: 9.69e-06\n",
      "Epoch   9 [5850/10697 ( 54.7%)] Loss: 0.032232 L1: 0.018926 Grad: 0.132749 Thermal: 0.000630 LR: 9.69e-06\n",
      "Epoch   9 [5900/10697 ( 55.2%)] Loss: 0.021987 L1: 0.012620 Grad: 0.093517 Thermal: 0.000313 LR: 9.69e-06\n",
      "Epoch   9 [5900/10697 ( 55.2%)] Loss: 0.021987 L1: 0.012620 Grad: 0.093517 Thermal: 0.000313 LR: 9.69e-06\n",
      "Epoch   9 [5950/10697 ( 55.6%)] Loss: 0.027063 L1: 0.016101 Grad: 0.109392 Thermal: 0.000463 LR: 9.69e-06\n",
      "Epoch   9 [5950/10697 ( 55.6%)] Loss: 0.027063 L1: 0.016101 Grad: 0.109392 Thermal: 0.000463 LR: 9.69e-06\n",
      "Epoch   9 [6000/10697 ( 56.1%)] Loss: 0.027359 L1: 0.015743 Grad: 0.115897 Thermal: 0.000516 LR: 9.69e-06\n",
      "Epoch   9 [6000/10697 ( 56.1%)] Loss: 0.027359 L1: 0.015743 Grad: 0.115897 Thermal: 0.000516 LR: 9.69e-06\n",
      "Epoch   9 [6050/10697 ( 56.6%)] Loss: 0.026763 L1: 0.016093 Grad: 0.106461 Thermal: 0.000469 LR: 9.69e-06\n",
      "Epoch   9 [6050/10697 ( 56.6%)] Loss: 0.026763 L1: 0.016093 Grad: 0.106461 Thermal: 0.000469 LR: 9.69e-06\n",
      "Epoch   9 [6100/10697 ( 57.0%)] Loss: 0.025122 L1: 0.014822 Grad: 0.102799 Thermal: 0.000390 LR: 9.69e-06\n",
      "Epoch   9 [6100/10697 ( 57.0%)] Loss: 0.025122 L1: 0.014822 Grad: 0.102799 Thermal: 0.000390 LR: 9.69e-06\n",
      "Epoch   9 [6150/10697 ( 57.5%)] Loss: 0.031195 L1: 0.017463 Grad: 0.137001 Thermal: 0.000632 LR: 9.69e-06\n",
      "Epoch   9 [6150/10697 ( 57.5%)] Loss: 0.031195 L1: 0.017463 Grad: 0.137001 Thermal: 0.000632 LR: 9.69e-06\n",
      "Epoch   9 [6200/10697 ( 58.0%)] Loss: 0.027172 L1: 0.016333 Grad: 0.108156 Thermal: 0.000463 LR: 9.69e-06\n",
      "Epoch   9 [6200/10697 ( 58.0%)] Loss: 0.027172 L1: 0.016333 Grad: 0.108156 Thermal: 0.000463 LR: 9.69e-06\n",
      "Epoch   9 [6250/10697 ( 58.4%)] Loss: 0.024485 L1: 0.014427 Grad: 0.100365 Thermal: 0.000440 LR: 9.69e-06\n",
      "Epoch   9 [6250/10697 ( 58.4%)] Loss: 0.024485 L1: 0.014427 Grad: 0.100365 Thermal: 0.000440 LR: 9.69e-06\n",
      "Epoch   9 [6300/10697 ( 58.9%)] Loss: 0.025141 L1: 0.014382 Grad: 0.107387 Thermal: 0.000409 LR: 9.69e-06\n",
      "Epoch   9 [6300/10697 ( 58.9%)] Loss: 0.025141 L1: 0.014382 Grad: 0.107387 Thermal: 0.000409 LR: 9.69e-06\n",
      "Epoch   9 [6350/10697 ( 59.4%)] Loss: 0.024235 L1: 0.013646 Grad: 0.105682 Thermal: 0.000411 LR: 9.69e-06\n",
      "Epoch   9 [6350/10697 ( 59.4%)] Loss: 0.024235 L1: 0.013646 Grad: 0.105682 Thermal: 0.000411 LR: 9.69e-06\n",
      "Epoch   9 [6400/10697 ( 59.8%)] Loss: 0.026410 L1: 0.015277 Grad: 0.111079 Thermal: 0.000497 LR: 9.69e-06\n",
      "Epoch   9 [6400/10697 ( 59.8%)] Loss: 0.026410 L1: 0.015277 Grad: 0.111079 Thermal: 0.000497 LR: 9.69e-06\n",
      "Epoch   9 [6450/10697 ( 60.3%)] Loss: 0.029561 L1: 0.017505 Grad: 0.120305 Thermal: 0.000524 LR: 9.69e-06\n",
      "Epoch   9 [6450/10697 ( 60.3%)] Loss: 0.029561 L1: 0.017505 Grad: 0.120305 Thermal: 0.000524 LR: 9.69e-06\n",
      "Epoch   9 [6500/10697 ( 60.8%)] Loss: 0.024968 L1: 0.014271 Grad: 0.106767 Thermal: 0.000407 LR: 9.69e-06\n",
      "Epoch   9 [6500/10697 ( 60.8%)] Loss: 0.024968 L1: 0.014271 Grad: 0.106767 Thermal: 0.000407 LR: 9.69e-06\n",
      "Epoch   9 [6550/10697 ( 61.2%)] Loss: 0.030411 L1: 0.017706 Grad: 0.126759 Thermal: 0.000579 LR: 9.69e-06\n",
      "Epoch   9 [6550/10697 ( 61.2%)] Loss: 0.030411 L1: 0.017706 Grad: 0.126759 Thermal: 0.000579 LR: 9.69e-06\n",
      "Epoch   9 [6600/10697 ( 61.7%)] Loss: 0.030135 L1: 0.017389 Grad: 0.127199 Thermal: 0.000535 LR: 9.69e-06\n",
      "Epoch   9 [6600/10697 ( 61.7%)] Loss: 0.030135 L1: 0.017389 Grad: 0.127199 Thermal: 0.000535 LR: 9.69e-06\n",
      "Epoch   9 [6650/10697 ( 62.2%)] Loss: 0.029729 L1: 0.017260 Grad: 0.124412 Thermal: 0.000543 LR: 9.69e-06\n",
      "Epoch   9 [6650/10697 ( 62.2%)] Loss: 0.029729 L1: 0.017260 Grad: 0.124412 Thermal: 0.000543 LR: 9.69e-06\n",
      "Epoch   9 [6700/10697 ( 62.6%)] Loss: 0.028459 L1: 0.016413 Grad: 0.120204 Thermal: 0.000514 LR: 9.69e-06\n",
      "Epoch   9 [6700/10697 ( 62.6%)] Loss: 0.028459 L1: 0.016413 Grad: 0.120204 Thermal: 0.000514 LR: 9.69e-06\n",
      "Epoch   9 [6750/10697 ( 63.1%)] Loss: 0.025122 L1: 0.014473 Grad: 0.106298 Thermal: 0.000392 LR: 9.69e-06\n",
      "Epoch   9 [6750/10697 ( 63.1%)] Loss: 0.025122 L1: 0.014473 Grad: 0.106298 Thermal: 0.000392 LR: 9.69e-06\n",
      "Epoch   9 [6800/10697 ( 63.6%)] Loss: 0.024475 L1: 0.014473 Grad: 0.099827 Thermal: 0.000396 LR: 9.69e-06\n",
      "Epoch   9 [6800/10697 ( 63.6%)] Loss: 0.024475 L1: 0.014473 Grad: 0.099827 Thermal: 0.000396 LR: 9.69e-06\n",
      "Epoch   9 [6850/10697 ( 64.0%)] Loss: 0.033366 L1: 0.019218 Grad: 0.141130 Thermal: 0.000697 LR: 9.69e-06\n",
      "Epoch   9 [6850/10697 ( 64.0%)] Loss: 0.033366 L1: 0.019218 Grad: 0.141130 Thermal: 0.000697 LR: 9.69e-06\n",
      "Epoch   9 [6900/10697 ( 64.5%)] Loss: 0.023100 L1: 0.013289 Grad: 0.097923 Thermal: 0.000369 LR: 9.69e-06\n",
      "Epoch   9 [6900/10697 ( 64.5%)] Loss: 0.023100 L1: 0.013289 Grad: 0.097923 Thermal: 0.000369 LR: 9.69e-06\n",
      "Epoch   9 [6950/10697 ( 65.0%)] Loss: 0.028189 L1: 0.016141 Grad: 0.120237 Thermal: 0.000487 LR: 9.69e-06\n",
      "Epoch   9 [6950/10697 ( 65.0%)] Loss: 0.028189 L1: 0.016141 Grad: 0.120237 Thermal: 0.000487 LR: 9.69e-06\n",
      "Epoch   9 [7000/10697 ( 65.4%)] Loss: 0.032502 L1: 0.018614 Grad: 0.138568 Thermal: 0.000626 LR: 9.69e-06\n",
      "Epoch   9 [7000/10697 ( 65.4%)] Loss: 0.032502 L1: 0.018614 Grad: 0.138568 Thermal: 0.000626 LR: 9.69e-06\n",
      "Epoch   9 [7050/10697 ( 65.9%)] Loss: 0.027206 L1: 0.015556 Grad: 0.116241 Thermal: 0.000521 LR: 9.69e-06\n",
      "Epoch   9 [7050/10697 ( 65.9%)] Loss: 0.027206 L1: 0.015556 Grad: 0.116241 Thermal: 0.000521 LR: 9.69e-06\n",
      "Epoch   9 [7100/10697 ( 66.4%)] Loss: 0.030524 L1: 0.017989 Grad: 0.125071 Thermal: 0.000567 LR: 9.69e-06\n",
      "Epoch   9 [7100/10697 ( 66.4%)] Loss: 0.030524 L1: 0.017989 Grad: 0.125071 Thermal: 0.000567 LR: 9.69e-06\n",
      "Epoch   9 [7150/10697 ( 66.8%)] Loss: 0.023287 L1: 0.013457 Grad: 0.098131 Thermal: 0.000337 LR: 9.69e-06\n",
      "Epoch   9 [7150/10697 ( 66.8%)] Loss: 0.023287 L1: 0.013457 Grad: 0.098131 Thermal: 0.000337 LR: 9.69e-06\n",
      "Epoch   9 [7200/10697 ( 67.3%)] Loss: 0.026542 L1: 0.015080 Grad: 0.114391 Thermal: 0.000464 LR: 9.69e-06\n",
      "Epoch   9 [7200/10697 ( 67.3%)] Loss: 0.026542 L1: 0.015080 Grad: 0.114391 Thermal: 0.000464 LR: 9.69e-06\n",
      "Epoch   9 [7250/10697 ( 67.8%)] Loss: 0.028575 L1: 0.016174 Grad: 0.123702 Thermal: 0.000602 LR: 9.69e-06\n",
      "Epoch   9 [7250/10697 ( 67.8%)] Loss: 0.028575 L1: 0.016174 Grad: 0.123702 Thermal: 0.000602 LR: 9.69e-06\n",
      "Epoch   9 [7300/10697 ( 68.2%)] Loss: 0.036029 L1: 0.021314 Grad: 0.146722 Thermal: 0.000847 LR: 9.69e-06\n",
      "Epoch   9 [7300/10697 ( 68.2%)] Loss: 0.036029 L1: 0.021314 Grad: 0.146722 Thermal: 0.000847 LR: 9.69e-06\n",
      "Epoch   9 [7350/10697 ( 68.7%)] Loss: 0.028649 L1: 0.016870 Grad: 0.117554 Thermal: 0.000486 LR: 9.69e-06\n",
      "Epoch   9 [7350/10697 ( 68.7%)] Loss: 0.028649 L1: 0.016870 Grad: 0.117554 Thermal: 0.000486 LR: 9.69e-06\n",
      "Epoch   9 [7400/10697 ( 69.2%)] Loss: 0.028469 L1: 0.016810 Grad: 0.116346 Thermal: 0.000505 LR: 9.69e-06\n",
      "Epoch   9 [7400/10697 ( 69.2%)] Loss: 0.028469 L1: 0.016810 Grad: 0.116346 Thermal: 0.000505 LR: 9.69e-06\n",
      "Epoch   9 [7450/10697 ( 69.6%)] Loss: 0.026800 L1: 0.015559 Grad: 0.112186 Thermal: 0.000445 LR: 9.69e-06\n",
      "Epoch   9 [7450/10697 ( 69.6%)] Loss: 0.026800 L1: 0.015559 Grad: 0.112186 Thermal: 0.000445 LR: 9.69e-06\n",
      "Epoch   9 [7500/10697 ( 70.1%)] Loss: 0.026008 L1: 0.015557 Grad: 0.104272 Thermal: 0.000481 LR: 9.69e-06\n",
      "Epoch   9 [7500/10697 ( 70.1%)] Loss: 0.026008 L1: 0.015557 Grad: 0.104272 Thermal: 0.000481 LR: 9.69e-06\n",
      "Epoch   9 [7550/10697 ( 70.6%)] Loss: 0.031017 L1: 0.018644 Grad: 0.123357 Thermal: 0.000749 LR: 9.69e-06\n",
      "Epoch   9 [7550/10697 ( 70.6%)] Loss: 0.031017 L1: 0.018644 Grad: 0.123357 Thermal: 0.000749 LR: 9.69e-06\n",
      "Epoch   9 [7600/10697 ( 71.0%)] Loss: 0.027434 L1: 0.016159 Grad: 0.112494 Thermal: 0.000509 LR: 9.69e-06\n",
      "Epoch   9 [7600/10697 ( 71.0%)] Loss: 0.027434 L1: 0.016159 Grad: 0.112494 Thermal: 0.000509 LR: 9.69e-06\n",
      "Epoch   9 [7650/10697 ( 71.5%)] Loss: 0.032611 L1: 0.018414 Grad: 0.141600 Thermal: 0.000741 LR: 9.69e-06\n",
      "Epoch   9 [7650/10697 ( 71.5%)] Loss: 0.032611 L1: 0.018414 Grad: 0.141600 Thermal: 0.000741 LR: 9.69e-06\n",
      "Epoch   9 [7700/10697 ( 72.0%)] Loss: 0.028112 L1: 0.016106 Grad: 0.119832 Thermal: 0.000447 LR: 9.69e-06\n",
      "Epoch   9 [7700/10697 ( 72.0%)] Loss: 0.028112 L1: 0.016106 Grad: 0.119832 Thermal: 0.000447 LR: 9.69e-06\n",
      "Epoch   9 [7750/10697 ( 72.5%)] Loss: 0.032495 L1: 0.018704 Grad: 0.137585 Thermal: 0.000642 LR: 9.69e-06\n",
      "Epoch   9 [7750/10697 ( 72.5%)] Loss: 0.032495 L1: 0.018704 Grad: 0.137585 Thermal: 0.000642 LR: 9.69e-06\n",
      "Epoch   9 [7800/10697 ( 72.9%)] Loss: 0.023563 L1: 0.014060 Grad: 0.094842 Thermal: 0.000365 LR: 9.69e-06\n",
      "Epoch   9 [7800/10697 ( 72.9%)] Loss: 0.023563 L1: 0.014060 Grad: 0.094842 Thermal: 0.000365 LR: 9.69e-06\n",
      "Epoch   9 [7850/10697 ( 73.4%)] Loss: 0.024127 L1: 0.013954 Grad: 0.101543 Thermal: 0.000381 LR: 9.69e-06\n",
      "Epoch   9 [7850/10697 ( 73.4%)] Loss: 0.024127 L1: 0.013954 Grad: 0.101543 Thermal: 0.000381 LR: 9.69e-06\n",
      "Epoch   9 [7900/10697 ( 73.9%)] Loss: 0.024617 L1: 0.013920 Grad: 0.106760 Thermal: 0.000418 LR: 9.69e-06\n",
      "Epoch   9 [7900/10697 ( 73.9%)] Loss: 0.024617 L1: 0.013920 Grad: 0.106760 Thermal: 0.000418 LR: 9.69e-06\n",
      "Epoch   9 [7950/10697 ( 74.3%)] Loss: 0.031285 L1: 0.018209 Grad: 0.130467 Thermal: 0.000597 LR: 9.69e-06\n",
      "Epoch   9 [7950/10697 ( 74.3%)] Loss: 0.031285 L1: 0.018209 Grad: 0.130467 Thermal: 0.000597 LR: 9.69e-06\n",
      "Epoch   9 [8000/10697 ( 74.8%)] Loss: 0.026754 L1: 0.015505 Grad: 0.112274 Thermal: 0.000435 LR: 9.69e-06\n",
      "Epoch   9 [8000/10697 ( 74.8%)] Loss: 0.026754 L1: 0.015505 Grad: 0.112274 Thermal: 0.000435 LR: 9.69e-06\n",
      "Epoch   9 [8050/10697 ( 75.3%)] Loss: 0.027185 L1: 0.016378 Grad: 0.107822 Thermal: 0.000498 LR: 9.69e-06\n",
      "Epoch   9 [8050/10697 ( 75.3%)] Loss: 0.027185 L1: 0.016378 Grad: 0.107822 Thermal: 0.000498 LR: 9.69e-06\n",
      "Epoch   9 [8100/10697 ( 75.7%)] Loss: 0.029785 L1: 0.017372 Grad: 0.123860 Thermal: 0.000551 LR: 9.69e-06\n",
      "Epoch   9 [8100/10697 ( 75.7%)] Loss: 0.029785 L1: 0.017372 Grad: 0.123860 Thermal: 0.000551 LR: 9.69e-06\n",
      "Epoch   9 [8150/10697 ( 76.2%)] Loss: 0.028968 L1: 0.016382 Grad: 0.125607 Thermal: 0.000508 LR: 9.69e-06\n",
      "Epoch   9 [8150/10697 ( 76.2%)] Loss: 0.028968 L1: 0.016382 Grad: 0.125607 Thermal: 0.000508 LR: 9.69e-06\n",
      "Epoch   9 [8200/10697 ( 76.7%)] Loss: 0.028536 L1: 0.016713 Grad: 0.117990 Thermal: 0.000489 LR: 9.69e-06\n",
      "Epoch   9 [8200/10697 ( 76.7%)] Loss: 0.028536 L1: 0.016713 Grad: 0.117990 Thermal: 0.000489 LR: 9.69e-06\n",
      "Epoch   9 [8250/10697 ( 77.1%)] Loss: 0.027594 L1: 0.015984 Grad: 0.115815 Thermal: 0.000568 LR: 9.69e-06\n",
      "Epoch   9 [8250/10697 ( 77.1%)] Loss: 0.027594 L1: 0.015984 Grad: 0.115815 Thermal: 0.000568 LR: 9.69e-06\n",
      "Epoch   9 [8300/10697 ( 77.6%)] Loss: 0.024932 L1: 0.014501 Grad: 0.104101 Thermal: 0.000406 LR: 9.69e-06\n",
      "Epoch   9 [8300/10697 ( 77.6%)] Loss: 0.024932 L1: 0.014501 Grad: 0.104101 Thermal: 0.000406 LR: 9.69e-06\n",
      "Epoch   9 [8350/10697 ( 78.1%)] Loss: 0.030585 L1: 0.017653 Grad: 0.129039 Thermal: 0.000565 LR: 9.69e-06\n",
      "Epoch   9 [8350/10697 ( 78.1%)] Loss: 0.030585 L1: 0.017653 Grad: 0.129039 Thermal: 0.000565 LR: 9.69e-06\n",
      "Epoch   9 [8400/10697 ( 78.5%)] Loss: 0.030245 L1: 0.017800 Grad: 0.124170 Thermal: 0.000560 LR: 9.69e-06\n",
      "Epoch   9 [8400/10697 ( 78.5%)] Loss: 0.030245 L1: 0.017800 Grad: 0.124170 Thermal: 0.000560 LR: 9.69e-06\n",
      "Epoch   9 [8450/10697 ( 79.0%)] Loss: 0.025811 L1: 0.015296 Grad: 0.104933 Thermal: 0.000423 LR: 9.69e-06\n",
      "Epoch   9 [8450/10697 ( 79.0%)] Loss: 0.025811 L1: 0.015296 Grad: 0.104933 Thermal: 0.000423 LR: 9.69e-06\n",
      "Epoch   9 [8500/10697 ( 79.5%)] Loss: 0.019396 L1: 0.011249 Grad: 0.081336 Thermal: 0.000268 LR: 9.69e-06\n",
      "Epoch   9 [8500/10697 ( 79.5%)] Loss: 0.019396 L1: 0.011249 Grad: 0.081336 Thermal: 0.000268 LR: 9.69e-06\n",
      "Epoch   9 [8550/10697 ( 79.9%)] Loss: 0.027186 L1: 0.015892 Grad: 0.112706 Thermal: 0.000463 LR: 9.69e-06\n",
      "Epoch   9 [8550/10697 ( 79.9%)] Loss: 0.027186 L1: 0.015892 Grad: 0.112706 Thermal: 0.000463 LR: 9.69e-06\n",
      "Epoch   9 [8600/10697 ( 80.4%)] Loss: 0.027614 L1: 0.016523 Grad: 0.110670 Thermal: 0.000470 LR: 9.69e-06\n",
      "Epoch   9 [8600/10697 ( 80.4%)] Loss: 0.027614 L1: 0.016523 Grad: 0.110670 Thermal: 0.000470 LR: 9.69e-06\n",
      "Epoch   9 [8650/10697 ( 80.9%)] Loss: 0.035481 L1: 0.020108 Grad: 0.153371 Thermal: 0.000725 LR: 9.69e-06\n",
      "Epoch   9 [8650/10697 ( 80.9%)] Loss: 0.035481 L1: 0.020108 Grad: 0.153371 Thermal: 0.000725 LR: 9.69e-06\n",
      "Epoch   9 [8700/10697 ( 81.3%)] Loss: 0.025179 L1: 0.014534 Grad: 0.106248 Thermal: 0.000405 LR: 9.69e-06\n",
      "Epoch   9 [8700/10697 ( 81.3%)] Loss: 0.025179 L1: 0.014534 Grad: 0.106248 Thermal: 0.000405 LR: 9.69e-06\n",
      "Epoch   9 [8750/10697 ( 81.8%)] Loss: 0.028171 L1: 0.016622 Grad: 0.115242 Thermal: 0.000485 LR: 9.69e-06\n",
      "Epoch   9 [8750/10697 ( 81.8%)] Loss: 0.028171 L1: 0.016622 Grad: 0.115242 Thermal: 0.000485 LR: 9.69e-06\n",
      "Epoch   9 [8800/10697 ( 82.3%)] Loss: 0.021899 L1: 0.012498 Grad: 0.093846 Thermal: 0.000342 LR: 9.69e-06\n",
      "Epoch   9 [8800/10697 ( 82.3%)] Loss: 0.021899 L1: 0.012498 Grad: 0.093846 Thermal: 0.000342 LR: 9.69e-06\n",
      "Epoch   9 [8850/10697 ( 82.7%)] Loss: 0.026315 L1: 0.014743 Grad: 0.115394 Thermal: 0.000653 LR: 9.69e-06\n",
      "Epoch   9 [8850/10697 ( 82.7%)] Loss: 0.026315 L1: 0.014743 Grad: 0.115394 Thermal: 0.000653 LR: 9.69e-06\n",
      "Epoch   9 [8900/10697 ( 83.2%)] Loss: 0.025873 L1: 0.014996 Grad: 0.108564 Thermal: 0.000418 LR: 9.69e-06\n",
      "Epoch   9 [8900/10697 ( 83.2%)] Loss: 0.025873 L1: 0.014996 Grad: 0.108564 Thermal: 0.000418 LR: 9.69e-06\n",
      "Epoch   9 [8950/10697 ( 83.7%)] Loss: 0.022622 L1: 0.013262 Grad: 0.093423 Thermal: 0.000364 LR: 9.69e-06\n",
      "Epoch   9 [8950/10697 ( 83.7%)] Loss: 0.022622 L1: 0.013262 Grad: 0.093423 Thermal: 0.000364 LR: 9.69e-06\n",
      "Epoch   9 [9000/10697 ( 84.1%)] Loss: 0.025006 L1: 0.014890 Grad: 0.100970 Thermal: 0.000383 LR: 9.69e-06\n",
      "Epoch   9 [9000/10697 ( 84.1%)] Loss: 0.025006 L1: 0.014890 Grad: 0.100970 Thermal: 0.000383 LR: 9.69e-06\n",
      "Epoch   9 [9050/10697 ( 84.6%)] Loss: 0.032200 L1: 0.018534 Grad: 0.136274 Thermal: 0.000784 LR: 9.69e-06\n",
      "Epoch   9 [9050/10697 ( 84.6%)] Loss: 0.032200 L1: 0.018534 Grad: 0.136274 Thermal: 0.000784 LR: 9.69e-06\n",
      "Epoch   9 [9100/10697 ( 85.1%)] Loss: 0.025465 L1: 0.014776 Grad: 0.106682 Thermal: 0.000405 LR: 9.69e-06\n",
      "Epoch   9 [9100/10697 ( 85.1%)] Loss: 0.025465 L1: 0.014776 Grad: 0.106682 Thermal: 0.000405 LR: 9.69e-06\n",
      "Epoch   9 [9150/10697 ( 85.5%)] Loss: 0.033233 L1: 0.019168 Grad: 0.140321 Thermal: 0.000672 LR: 9.69e-06\n",
      "Epoch   9 [9150/10697 ( 85.5%)] Loss: 0.033233 L1: 0.019168 Grad: 0.140321 Thermal: 0.000672 LR: 9.69e-06\n",
      "Epoch   9 [9200/10697 ( 86.0%)] Loss: 0.022414 L1: 0.013149 Grad: 0.092479 Thermal: 0.000332 LR: 9.69e-06\n",
      "Epoch   9 [9200/10697 ( 86.0%)] Loss: 0.022414 L1: 0.013149 Grad: 0.092479 Thermal: 0.000332 LR: 9.69e-06\n",
      "Epoch   9 [9250/10697 ( 86.5%)] Loss: 0.031873 L1: 0.018286 Grad: 0.135556 Thermal: 0.000622 LR: 9.69e-06\n",
      "Epoch   9 [9250/10697 ( 86.5%)] Loss: 0.031873 L1: 0.018286 Grad: 0.135556 Thermal: 0.000622 LR: 9.69e-06\n",
      "Epoch   9 [9300/10697 ( 86.9%)] Loss: 0.028658 L1: 0.016964 Grad: 0.116687 Thermal: 0.000516 LR: 9.69e-06\n",
      "Epoch   9 [9300/10697 ( 86.9%)] Loss: 0.028658 L1: 0.016964 Grad: 0.116687 Thermal: 0.000516 LR: 9.69e-06\n",
      "Epoch   9 [9350/10697 ( 87.4%)] Loss: 0.027270 L1: 0.016155 Grad: 0.110924 Thermal: 0.000460 LR: 9.69e-06\n",
      "Epoch   9 [9350/10697 ( 87.4%)] Loss: 0.027270 L1: 0.016155 Grad: 0.110924 Thermal: 0.000460 LR: 9.69e-06\n",
      "Epoch   9 [9400/10697 ( 87.9%)] Loss: 0.026138 L1: 0.015370 Grad: 0.107460 Thermal: 0.000443 LR: 9.69e-06\n",
      "Epoch   9 [9400/10697 ( 87.9%)] Loss: 0.026138 L1: 0.015370 Grad: 0.107460 Thermal: 0.000443 LR: 9.69e-06\n",
      "Epoch   9 [9450/10697 ( 88.3%)] Loss: 0.024618 L1: 0.013929 Grad: 0.106706 Thermal: 0.000366 LR: 9.69e-06\n",
      "Epoch   9 [9450/10697 ( 88.3%)] Loss: 0.024618 L1: 0.013929 Grad: 0.106706 Thermal: 0.000366 LR: 9.69e-06\n",
      "Epoch   9 [9500/10697 ( 88.8%)] Loss: 0.028638 L1: 0.016540 Grad: 0.120718 Thermal: 0.000536 LR: 9.69e-06\n",
      "Epoch   9 [9500/10697 ( 88.8%)] Loss: 0.028638 L1: 0.016540 Grad: 0.120718 Thermal: 0.000536 LR: 9.69e-06\n",
      "Epoch   9 [9550/10697 ( 89.3%)] Loss: 0.025364 L1: 0.014779 Grad: 0.105627 Thermal: 0.000445 LR: 9.69e-06\n",
      "Epoch   9 [9550/10697 ( 89.3%)] Loss: 0.025364 L1: 0.014779 Grad: 0.105627 Thermal: 0.000445 LR: 9.69e-06\n",
      "Epoch   9 [9600/10697 ( 89.7%)] Loss: 0.026272 L1: 0.015470 Grad: 0.107790 Thermal: 0.000467 LR: 9.69e-06\n",
      "Epoch   9 [9600/10697 ( 89.7%)] Loss: 0.026272 L1: 0.015470 Grad: 0.107790 Thermal: 0.000467 LR: 9.69e-06\n",
      "Epoch   9 [9650/10697 ( 90.2%)] Loss: 0.028391 L1: 0.016647 Grad: 0.117198 Thermal: 0.000482 LR: 9.69e-06\n",
      "Epoch   9 [9650/10697 ( 90.2%)] Loss: 0.028391 L1: 0.016647 Grad: 0.117198 Thermal: 0.000482 LR: 9.69e-06\n",
      "Epoch   9 [9700/10697 ( 90.7%)] Loss: 0.025085 L1: 0.014364 Grad: 0.107006 Thermal: 0.000391 LR: 9.69e-06\n",
      "Epoch   9 [9700/10697 ( 90.7%)] Loss: 0.025085 L1: 0.014364 Grad: 0.107006 Thermal: 0.000391 LR: 9.69e-06\n",
      "Epoch   9 [9750/10697 ( 91.1%)] Loss: 0.028755 L1: 0.016905 Grad: 0.118254 Thermal: 0.000508 LR: 9.69e-06\n",
      "Epoch   9 [9750/10697 ( 91.1%)] Loss: 0.028755 L1: 0.016905 Grad: 0.118254 Thermal: 0.000508 LR: 9.69e-06\n",
      "Epoch   9 [9800/10697 ( 91.6%)] Loss: 0.021924 L1: 0.012615 Grad: 0.092932 Thermal: 0.000330 LR: 9.69e-06\n",
      "Epoch   9 [9800/10697 ( 91.6%)] Loss: 0.021924 L1: 0.012615 Grad: 0.092932 Thermal: 0.000330 LR: 9.69e-06\n",
      "Epoch   9 [9850/10697 ( 92.1%)] Loss: 0.026773 L1: 0.015738 Grad: 0.110125 Thermal: 0.000453 LR: 9.69e-06\n",
      "Epoch   9 [9850/10697 ( 92.1%)] Loss: 0.026773 L1: 0.015738 Grad: 0.110125 Thermal: 0.000453 LR: 9.69e-06\n",
      "Epoch   9 [9900/10697 ( 92.5%)] Loss: 0.024859 L1: 0.014582 Grad: 0.102539 Thermal: 0.000476 LR: 9.69e-06\n",
      "Epoch   9 [9900/10697 ( 92.5%)] Loss: 0.024859 L1: 0.014582 Grad: 0.102539 Thermal: 0.000476 LR: 9.69e-06\n",
      "Epoch   9 [9950/10697 ( 93.0%)] Loss: 0.021616 L1: 0.012534 Grad: 0.090652 Thermal: 0.000337 LR: 9.69e-06\n",
      "Epoch   9 [9950/10697 ( 93.0%)] Loss: 0.021616 L1: 0.012534 Grad: 0.090652 Thermal: 0.000337 LR: 9.69e-06\n",
      "Epoch   9 [10000/10697 ( 93.5%)] Loss: 0.022702 L1: 0.013005 Grad: 0.096798 Thermal: 0.000355 LR: 9.69e-06\n",
      "Epoch   9 [10000/10697 ( 93.5%)] Loss: 0.022702 L1: 0.013005 Grad: 0.096798 Thermal: 0.000355 LR: 9.69e-06\n",
      "Epoch   9 [10050/10697 ( 94.0%)] Loss: 0.025161 L1: 0.014624 Grad: 0.105157 Thermal: 0.000437 LR: 9.69e-06\n",
      "Epoch   9 [10050/10697 ( 94.0%)] Loss: 0.025161 L1: 0.014624 Grad: 0.105157 Thermal: 0.000437 LR: 9.69e-06\n",
      "Epoch   9 [10100/10697 ( 94.4%)] Loss: 0.026005 L1: 0.015231 Grad: 0.107529 Thermal: 0.000435 LR: 9.69e-06\n",
      "Epoch   9 [10100/10697 ( 94.4%)] Loss: 0.026005 L1: 0.015231 Grad: 0.107529 Thermal: 0.000435 LR: 9.69e-06\n",
      "Epoch   9 [10150/10697 ( 94.9%)] Loss: 0.030104 L1: 0.017752 Grad: 0.123246 Thermal: 0.000545 LR: 9.69e-06\n",
      "Epoch   9 [10150/10697 ( 94.9%)] Loss: 0.030104 L1: 0.017752 Grad: 0.123246 Thermal: 0.000545 LR: 9.69e-06\n",
      "Epoch   9 [10200/10697 ( 95.4%)] Loss: 0.023993 L1: 0.014009 Grad: 0.099646 Thermal: 0.000390 LR: 9.69e-06\n",
      "Epoch   9 [10200/10697 ( 95.4%)] Loss: 0.023993 L1: 0.014009 Grad: 0.099646 Thermal: 0.000390 LR: 9.69e-06\n",
      "Epoch   9 [10250/10697 ( 95.8%)] Loss: 0.030362 L1: 0.017642 Grad: 0.126924 Thermal: 0.000559 LR: 9.69e-06\n",
      "Epoch   9 [10250/10697 ( 95.8%)] Loss: 0.030362 L1: 0.017642 Grad: 0.126924 Thermal: 0.000559 LR: 9.69e-06\n",
      "Epoch   9 [10300/10697 ( 96.3%)] Loss: 0.020339 L1: 0.011542 Grad: 0.087826 Thermal: 0.000287 LR: 9.69e-06\n",
      "Epoch   9 [10300/10697 ( 96.3%)] Loss: 0.020339 L1: 0.011542 Grad: 0.087826 Thermal: 0.000287 LR: 9.69e-06\n",
      "Epoch   9 [10350/10697 ( 96.8%)] Loss: 0.025322 L1: 0.014727 Grad: 0.105752 Thermal: 0.000404 LR: 9.69e-06\n",
      "Epoch   9 [10350/10697 ( 96.8%)] Loss: 0.025322 L1: 0.014727 Grad: 0.105752 Thermal: 0.000404 LR: 9.69e-06\n",
      "Epoch   9 [10400/10697 ( 97.2%)] Loss: 0.030053 L1: 0.017181 Grad: 0.128438 Thermal: 0.000559 LR: 9.69e-06\n",
      "Epoch   9 [10400/10697 ( 97.2%)] Loss: 0.030053 L1: 0.017181 Grad: 0.128438 Thermal: 0.000559 LR: 9.69e-06\n",
      "Epoch   9 [10450/10697 ( 97.7%)] Loss: 0.019503 L1: 0.011406 Grad: 0.080840 Thermal: 0.000269 LR: 9.69e-06\n",
      "Epoch   9 [10450/10697 ( 97.7%)] Loss: 0.019503 L1: 0.011406 Grad: 0.080840 Thermal: 0.000269 LR: 9.69e-06\n",
      "Epoch   9 [10500/10697 ( 98.2%)] Loss: 0.025660 L1: 0.015211 Grad: 0.104276 Thermal: 0.000438 LR: 9.69e-06\n",
      "Epoch   9 [10500/10697 ( 98.2%)] Loss: 0.025660 L1: 0.015211 Grad: 0.104276 Thermal: 0.000438 LR: 9.69e-06\n",
      "Epoch   9 [10550/10697 ( 98.6%)] Loss: 0.027672 L1: 0.016648 Grad: 0.109989 Thermal: 0.000506 LR: 9.69e-06\n",
      "Epoch   9 [10550/10697 ( 98.6%)] Loss: 0.027672 L1: 0.016648 Grad: 0.109989 Thermal: 0.000506 LR: 9.69e-06\n",
      "Epoch   9 [10600/10697 ( 99.1%)] Loss: 0.032073 L1: 0.018933 Grad: 0.131043 Thermal: 0.000724 LR: 9.69e-06\n",
      "Epoch   9 [10600/10697 ( 99.1%)] Loss: 0.032073 L1: 0.018933 Grad: 0.131043 Thermal: 0.000724 LR: 9.69e-06\n",
      "Epoch   9 [10650/10697 ( 99.6%)] Loss: 0.023805 L1: 0.014080 Grad: 0.097052 Thermal: 0.000394 LR: 9.69e-06\n",
      "Epoch   9 [10650/10697 ( 99.6%)] Loss: 0.023805 L1: 0.014080 Grad: 0.097052 Thermal: 0.000394 LR: 9.69e-06\n",
      "Epoch   9 Summary: Loss=0.026749 (L1:0.0156, Grad:0.1115, Thermal:0.0005) Val_PSNR=0.00dB Best=33.75dB Time=35.8min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch   9 Summary: Loss=0.026749 (L1:0.0156, Grad:0.1115, Thermal:0.0005) Val_PSNR=0.00dB Best=33.75dB Time=35.8min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  10 [   0/10697 (  0.0%)] Loss: 0.032502 L1: 0.018760 Grad: 0.137089 Thermal: 0.000666 LR: 9.62e-06\n",
      "Epoch  10 [   0/10697 (  0.0%)] Loss: 0.032502 L1: 0.018760 Grad: 0.137089 Thermal: 0.000666 LR: 9.62e-06\n",
      "Epoch  10 [  50/10697 (  0.5%)] Loss: 0.023088 L1: 0.013451 Grad: 0.096169 Thermal: 0.000386 LR: 9.62e-06\n",
      "Epoch  10 [  50/10697 (  0.5%)] Loss: 0.023088 L1: 0.013451 Grad: 0.096169 Thermal: 0.000386 LR: 9.62e-06\n",
      "Epoch  10 [ 100/10697 (  0.9%)] Loss: 0.029741 L1: 0.017655 Grad: 0.120582 Thermal: 0.000556 LR: 9.62e-06\n",
      "Epoch  10 [ 100/10697 (  0.9%)] Loss: 0.029741 L1: 0.017655 Grad: 0.120582 Thermal: 0.000556 LR: 9.62e-06\n",
      "Epoch  10 [ 150/10697 (  1.4%)] Loss: 0.025649 L1: 0.015197 Grad: 0.104255 Thermal: 0.000516 LR: 9.62e-06\n",
      "Epoch  10 [ 150/10697 (  1.4%)] Loss: 0.025649 L1: 0.015197 Grad: 0.104255 Thermal: 0.000516 LR: 9.62e-06\n",
      "Epoch  10 [ 200/10697 (  1.9%)] Loss: 0.026120 L1: 0.014967 Grad: 0.111329 Thermal: 0.000407 LR: 9.62e-06\n",
      "Epoch  10 [ 200/10697 (  1.9%)] Loss: 0.026120 L1: 0.014967 Grad: 0.111329 Thermal: 0.000407 LR: 9.62e-06\n",
      "Epoch  10 [ 250/10697 (  2.3%)] Loss: 0.026739 L1: 0.015945 Grad: 0.107723 Thermal: 0.000445 LR: 9.62e-06\n",
      "Epoch  10 [ 250/10697 (  2.3%)] Loss: 0.026739 L1: 0.015945 Grad: 0.107723 Thermal: 0.000445 LR: 9.62e-06\n",
      "Epoch  10 [ 300/10697 (  2.8%)] Loss: 0.033242 L1: 0.019202 Grad: 0.140055 Thermal: 0.000690 LR: 9.62e-06\n",
      "Epoch  10 [ 300/10697 (  2.8%)] Loss: 0.033242 L1: 0.019202 Grad: 0.140055 Thermal: 0.000690 LR: 9.62e-06\n",
      "Epoch  10 [ 350/10697 (  3.3%)] Loss: 0.027667 L1: 0.015961 Grad: 0.116807 Thermal: 0.000519 LR: 9.62e-06\n",
      "Epoch  10 [ 350/10697 (  3.3%)] Loss: 0.027667 L1: 0.015961 Grad: 0.116807 Thermal: 0.000519 LR: 9.62e-06\n",
      "Epoch  10 [ 400/10697 (  3.7%)] Loss: 0.021335 L1: 0.012132 Grad: 0.091894 Thermal: 0.000275 LR: 9.62e-06\n",
      "Epoch  10 [ 400/10697 (  3.7%)] Loss: 0.021335 L1: 0.012132 Grad: 0.091894 Thermal: 0.000275 LR: 9.62e-06\n",
      "Epoch  10 [ 450/10697 (  4.2%)] Loss: 0.020777 L1: 0.011684 Grad: 0.090791 Thermal: 0.000271 LR: 9.62e-06\n",
      "Epoch  10 [ 450/10697 (  4.2%)] Loss: 0.020777 L1: 0.011684 Grad: 0.090791 Thermal: 0.000271 LR: 9.62e-06\n",
      "Epoch  10 [ 500/10697 (  4.7%)] Loss: 0.027038 L1: 0.015840 Grad: 0.111734 Thermal: 0.000482 LR: 9.62e-06\n",
      "Epoch  10 [ 500/10697 (  4.7%)] Loss: 0.027038 L1: 0.015840 Grad: 0.111734 Thermal: 0.000482 LR: 9.62e-06\n",
      "Epoch  10 [ 550/10697 (  5.1%)] Loss: 0.035897 L1: 0.020551 Grad: 0.153047 Thermal: 0.000832 LR: 9.62e-06\n",
      "Epoch  10 [ 550/10697 (  5.1%)] Loss: 0.035897 L1: 0.020551 Grad: 0.153047 Thermal: 0.000832 LR: 9.62e-06\n",
      "Epoch  10 [ 600/10697 (  5.6%)] Loss: 0.022675 L1: 0.013215 Grad: 0.094428 Thermal: 0.000342 LR: 9.62e-06\n",
      "Epoch  10 [ 600/10697 (  5.6%)] Loss: 0.022675 L1: 0.013215 Grad: 0.094428 Thermal: 0.000342 LR: 9.62e-06\n",
      "Epoch  10 [ 650/10697 (  6.1%)] Loss: 0.027146 L1: 0.016119 Grad: 0.110024 Thermal: 0.000489 LR: 9.62e-06\n",
      "Epoch  10 [ 650/10697 (  6.1%)] Loss: 0.027146 L1: 0.016119 Grad: 0.110024 Thermal: 0.000489 LR: 9.62e-06\n",
      "Epoch  10 [ 700/10697 (  6.5%)] Loss: 0.023790 L1: 0.013769 Grad: 0.100020 Thermal: 0.000370 LR: 9.62e-06\n",
      "Epoch  10 [ 700/10697 (  6.5%)] Loss: 0.023790 L1: 0.013769 Grad: 0.100020 Thermal: 0.000370 LR: 9.62e-06\n",
      "Epoch  10 [ 750/10697 (  7.0%)] Loss: 0.027287 L1: 0.016042 Grad: 0.112183 Thermal: 0.000533 LR: 9.62e-06\n",
      "Epoch  10 [ 750/10697 (  7.0%)] Loss: 0.027287 L1: 0.016042 Grad: 0.112183 Thermal: 0.000533 LR: 9.62e-06\n",
      "Epoch  10 [ 800/10697 (  7.5%)] Loss: 0.029261 L1: 0.017329 Grad: 0.119040 Thermal: 0.000551 LR: 9.62e-06\n",
      "Epoch  10 [ 800/10697 (  7.5%)] Loss: 0.029261 L1: 0.017329 Grad: 0.119040 Thermal: 0.000551 LR: 9.62e-06\n",
      "Epoch  10 [ 850/10697 (  7.9%)] Loss: 0.018004 L1: 0.010129 Grad: 0.078623 Thermal: 0.000242 LR: 9.62e-06\n",
      "Epoch  10 [ 850/10697 (  7.9%)] Loss: 0.018004 L1: 0.010129 Grad: 0.078623 Thermal: 0.000242 LR: 9.62e-06\n",
      "Epoch  10 [ 900/10697 (  8.4%)] Loss: 0.024373 L1: 0.014364 Grad: 0.099891 Thermal: 0.000401 LR: 9.62e-06\n",
      "Epoch  10 [ 900/10697 (  8.4%)] Loss: 0.024373 L1: 0.014364 Grad: 0.099891 Thermal: 0.000401 LR: 9.62e-06\n",
      "Epoch  10 [ 950/10697 (  8.9%)] Loss: 0.031012 L1: 0.018142 Grad: 0.128421 Thermal: 0.000559 LR: 9.62e-06\n",
      "Epoch  10 [ 950/10697 (  8.9%)] Loss: 0.031012 L1: 0.018142 Grad: 0.128421 Thermal: 0.000559 LR: 9.62e-06\n",
      "Epoch  10 [1000/10697 (  9.3%)] Loss: 0.030960 L1: 0.017896 Grad: 0.130334 Thermal: 0.000592 LR: 9.62e-06\n",
      "Epoch  10 [1000/10697 (  9.3%)] Loss: 0.030960 L1: 0.017896 Grad: 0.130334 Thermal: 0.000592 LR: 9.62e-06\n",
      "Epoch  10 [1050/10697 (  9.8%)] Loss: 0.025558 L1: 0.015045 Grad: 0.104919 Thermal: 0.000437 LR: 9.62e-06\n",
      "Epoch  10 [1050/10697 (  9.8%)] Loss: 0.025558 L1: 0.015045 Grad: 0.104919 Thermal: 0.000437 LR: 9.62e-06\n",
      "Epoch  10 [1100/10697 ( 10.3%)] Loss: 0.029656 L1: 0.017337 Grad: 0.122880 Thermal: 0.000618 LR: 9.62e-06\n",
      "Epoch  10 [1100/10697 ( 10.3%)] Loss: 0.029656 L1: 0.017337 Grad: 0.122880 Thermal: 0.000618 LR: 9.62e-06\n",
      "Epoch  10 [1150/10697 ( 10.8%)] Loss: 0.024669 L1: 0.014519 Grad: 0.101307 Thermal: 0.000389 LR: 9.62e-06\n",
      "Epoch  10 [1150/10697 ( 10.8%)] Loss: 0.024669 L1: 0.014519 Grad: 0.101307 Thermal: 0.000389 LR: 9.62e-06\n",
      "Epoch  10 [1200/10697 ( 11.2%)] Loss: 0.023963 L1: 0.013972 Grad: 0.099716 Thermal: 0.000393 LR: 9.62e-06\n",
      "Epoch  10 [1200/10697 ( 11.2%)] Loss: 0.023963 L1: 0.013972 Grad: 0.099716 Thermal: 0.000393 LR: 9.62e-06\n",
      "Epoch  10 [1250/10697 ( 11.7%)] Loss: 0.027642 L1: 0.016292 Grad: 0.113278 Thermal: 0.000459 LR: 9.62e-06\n",
      "Epoch  10 [1250/10697 ( 11.7%)] Loss: 0.027642 L1: 0.016292 Grad: 0.113278 Thermal: 0.000459 LR: 9.62e-06\n",
      "Epoch  10 [1300/10697 ( 12.2%)] Loss: 0.027909 L1: 0.016387 Grad: 0.114961 Thermal: 0.000513 LR: 9.62e-06\n",
      "Epoch  10 [1300/10697 ( 12.2%)] Loss: 0.027909 L1: 0.016387 Grad: 0.114961 Thermal: 0.000513 LR: 9.62e-06\n",
      "Epoch  10 [1350/10697 ( 12.6%)] Loss: 0.026717 L1: 0.015394 Grad: 0.113006 Thermal: 0.000449 LR: 9.62e-06\n",
      "Epoch  10 [1350/10697 ( 12.6%)] Loss: 0.026717 L1: 0.015394 Grad: 0.113006 Thermal: 0.000449 LR: 9.62e-06\n",
      "Epoch  10 [1400/10697 ( 13.1%)] Loss: 0.031474 L1: 0.018306 Grad: 0.131373 Thermal: 0.000605 LR: 9.62e-06\n",
      "Epoch  10 [1400/10697 ( 13.1%)] Loss: 0.031474 L1: 0.018306 Grad: 0.131373 Thermal: 0.000605 LR: 9.62e-06\n",
      "Epoch  10 [1450/10697 ( 13.6%)] Loss: 0.023440 L1: 0.013263 Grad: 0.101579 Thermal: 0.000381 LR: 9.62e-06\n",
      "Epoch  10 [1450/10697 ( 13.6%)] Loss: 0.023440 L1: 0.013263 Grad: 0.101579 Thermal: 0.000381 LR: 9.62e-06\n",
      "Epoch  10 [1500/10697 ( 14.0%)] Loss: 0.026964 L1: 0.015210 Grad: 0.117317 Thermal: 0.000443 LR: 9.62e-06\n",
      "Epoch  10 [1500/10697 ( 14.0%)] Loss: 0.026964 L1: 0.015210 Grad: 0.117317 Thermal: 0.000443 LR: 9.62e-06\n",
      "Epoch  10 [1550/10697 ( 14.5%)] Loss: 0.029198 L1: 0.016959 Grad: 0.122129 Thermal: 0.000513 LR: 9.62e-06\n",
      "Epoch  10 [1550/10697 ( 14.5%)] Loss: 0.029198 L1: 0.016959 Grad: 0.122129 Thermal: 0.000513 LR: 9.62e-06\n",
      "Epoch  10 [1600/10697 ( 15.0%)] Loss: 0.025819 L1: 0.014735 Grad: 0.110644 Thermal: 0.000396 LR: 9.62e-06\n",
      "Epoch  10 [1600/10697 ( 15.0%)] Loss: 0.025819 L1: 0.014735 Grad: 0.110644 Thermal: 0.000396 LR: 9.62e-06\n",
      "Epoch  10 [1650/10697 ( 15.4%)] Loss: 0.029016 L1: 0.016936 Grad: 0.120549 Thermal: 0.000520 LR: 9.62e-06\n",
      "Epoch  10 [1650/10697 ( 15.4%)] Loss: 0.029016 L1: 0.016936 Grad: 0.120549 Thermal: 0.000520 LR: 9.62e-06\n",
      "Epoch  10 [1700/10697 ( 15.9%)] Loss: 0.020065 L1: 0.011681 Grad: 0.083696 Thermal: 0.000291 LR: 9.62e-06\n",
      "Epoch  10 [1700/10697 ( 15.9%)] Loss: 0.020065 L1: 0.011681 Grad: 0.083696 Thermal: 0.000291 LR: 9.62e-06\n",
      "Epoch  10 [1750/10697 ( 16.4%)] Loss: 0.029033 L1: 0.017391 Grad: 0.116158 Thermal: 0.000518 LR: 9.62e-06\n",
      "Epoch  10 [1750/10697 ( 16.4%)] Loss: 0.029033 L1: 0.017391 Grad: 0.116158 Thermal: 0.000518 LR: 9.62e-06\n",
      "Epoch  10 [1800/10697 ( 16.8%)] Loss: 0.028228 L1: 0.016570 Grad: 0.116327 Thermal: 0.000512 LR: 9.62e-06\n",
      "Epoch  10 [1800/10697 ( 16.8%)] Loss: 0.028228 L1: 0.016570 Grad: 0.116327 Thermal: 0.000512 LR: 9.62e-06\n",
      "Epoch  10 [1850/10697 ( 17.3%)] Loss: 0.023122 L1: 0.013443 Grad: 0.096577 Thermal: 0.000421 LR: 9.62e-06\n",
      "Epoch  10 [1850/10697 ( 17.3%)] Loss: 0.023122 L1: 0.013443 Grad: 0.096577 Thermal: 0.000421 LR: 9.62e-06\n",
      "Epoch  10 [1900/10697 ( 17.8%)] Loss: 0.025339 L1: 0.014676 Grad: 0.106397 Thermal: 0.000467 LR: 9.62e-06\n",
      "Epoch  10 [1900/10697 ( 17.8%)] Loss: 0.025339 L1: 0.014676 Grad: 0.106397 Thermal: 0.000467 LR: 9.62e-06\n",
      "Epoch  10 [1950/10697 ( 18.2%)] Loss: 0.031716 L1: 0.018069 Grad: 0.136115 Thermal: 0.000713 LR: 9.62e-06\n",
      "Epoch  10 [1950/10697 ( 18.2%)] Loss: 0.031716 L1: 0.018069 Grad: 0.136115 Thermal: 0.000713 LR: 9.62e-06\n",
      "Epoch  10 [2000/10697 ( 18.7%)] Loss: 0.028885 L1: 0.016587 Grad: 0.122706 Thermal: 0.000540 LR: 9.62e-06\n",
      "Epoch  10 [2000/10697 ( 18.7%)] Loss: 0.028885 L1: 0.016587 Grad: 0.122706 Thermal: 0.000540 LR: 9.62e-06\n",
      "Epoch  10 [2050/10697 ( 19.2%)] Loss: 0.031158 L1: 0.018164 Grad: 0.129620 Thermal: 0.000640 LR: 9.62e-06\n",
      "Epoch  10 [2050/10697 ( 19.2%)] Loss: 0.031158 L1: 0.018164 Grad: 0.129620 Thermal: 0.000640 LR: 9.62e-06\n",
      "Epoch  10 [2100/10697 ( 19.6%)] Loss: 0.023660 L1: 0.013588 Grad: 0.100514 Thermal: 0.000401 LR: 9.62e-06\n",
      "Epoch  10 [2100/10697 ( 19.6%)] Loss: 0.023660 L1: 0.013588 Grad: 0.100514 Thermal: 0.000401 LR: 9.62e-06\n",
      "Epoch  10 [2150/10697 ( 20.1%)] Loss: 0.031981 L1: 0.018339 Grad: 0.136118 Thermal: 0.000595 LR: 9.62e-06\n",
      "Epoch  10 [2150/10697 ( 20.1%)] Loss: 0.031981 L1: 0.018339 Grad: 0.136118 Thermal: 0.000595 LR: 9.62e-06\n",
      "Epoch  10 [2200/10697 ( 20.6%)] Loss: 0.027956 L1: 0.016044 Grad: 0.118887 Thermal: 0.000454 LR: 9.62e-06\n",
      "Epoch  10 [2200/10697 ( 20.6%)] Loss: 0.027956 L1: 0.016044 Grad: 0.118887 Thermal: 0.000454 LR: 9.62e-06\n",
      "Epoch  10 [2250/10697 ( 21.0%)] Loss: 0.026850 L1: 0.015624 Grad: 0.112015 Thermal: 0.000489 LR: 9.62e-06\n",
      "Epoch  10 [2250/10697 ( 21.0%)] Loss: 0.026850 L1: 0.015624 Grad: 0.112015 Thermal: 0.000489 LR: 9.62e-06\n",
      "Epoch  10 [2300/10697 ( 21.5%)] Loss: 0.028141 L1: 0.016440 Grad: 0.116757 Thermal: 0.000501 LR: 9.62e-06\n",
      "Epoch  10 [2300/10697 ( 21.5%)] Loss: 0.028141 L1: 0.016440 Grad: 0.116757 Thermal: 0.000501 LR: 9.62e-06\n",
      "Epoch  10 [2350/10697 ( 22.0%)] Loss: 0.026398 L1: 0.015501 Grad: 0.108750 Thermal: 0.000442 LR: 9.62e-06\n",
      "Epoch  10 [2350/10697 ( 22.0%)] Loss: 0.026398 L1: 0.015501 Grad: 0.108750 Thermal: 0.000442 LR: 9.62e-06\n",
      "Epoch  10 [2400/10697 ( 22.4%)] Loss: 0.016731 L1: 0.009435 Grad: 0.072865 Thermal: 0.000189 LR: 9.62e-06\n",
      "Epoch  10 [2400/10697 ( 22.4%)] Loss: 0.016731 L1: 0.009435 Grad: 0.072865 Thermal: 0.000189 LR: 9.62e-06\n",
      "Epoch  10 [2450/10697 ( 22.9%)] Loss: 0.030003 L1: 0.017586 Grad: 0.123891 Thermal: 0.000547 LR: 9.62e-06\n",
      "Epoch  10 [2450/10697 ( 22.9%)] Loss: 0.030003 L1: 0.017586 Grad: 0.123891 Thermal: 0.000547 LR: 9.62e-06\n",
      "Epoch  10 [2500/10697 ( 23.4%)] Loss: 0.026599 L1: 0.015480 Grad: 0.110981 Thermal: 0.000422 LR: 9.62e-06\n",
      "Epoch  10 [2500/10697 ( 23.4%)] Loss: 0.026599 L1: 0.015480 Grad: 0.110981 Thermal: 0.000422 LR: 9.62e-06\n",
      "Epoch  10 [2550/10697 ( 23.8%)] Loss: 0.030624 L1: 0.017209 Grad: 0.133860 Thermal: 0.000582 LR: 9.62e-06\n",
      "Epoch  10 [2550/10697 ( 23.8%)] Loss: 0.030624 L1: 0.017209 Grad: 0.133860 Thermal: 0.000582 LR: 9.62e-06\n",
      "Epoch  10 [2600/10697 ( 24.3%)] Loss: 0.023689 L1: 0.013519 Grad: 0.101528 Thermal: 0.000353 LR: 9.62e-06\n",
      "Epoch  10 [2600/10697 ( 24.3%)] Loss: 0.023689 L1: 0.013519 Grad: 0.101528 Thermal: 0.000353 LR: 9.62e-06\n",
      "Epoch  10 [2650/10697 ( 24.8%)] Loss: 0.036840 L1: 0.021163 Grad: 0.156331 Thermal: 0.000870 LR: 9.62e-06\n",
      "Epoch  10 [2650/10697 ( 24.8%)] Loss: 0.036840 L1: 0.021163 Grad: 0.156331 Thermal: 0.000870 LR: 9.62e-06\n",
      "Epoch  10 [2700/10697 ( 25.2%)] Loss: 0.029248 L1: 0.016726 Grad: 0.124925 Thermal: 0.000593 LR: 9.62e-06\n",
      "Epoch  10 [2700/10697 ( 25.2%)] Loss: 0.029248 L1: 0.016726 Grad: 0.124925 Thermal: 0.000593 LR: 9.62e-06\n",
      "Epoch  10 [2750/10697 ( 25.7%)] Loss: 0.023151 L1: 0.013694 Grad: 0.094387 Thermal: 0.000360 LR: 9.62e-06\n",
      "Epoch  10 [2750/10697 ( 25.7%)] Loss: 0.023151 L1: 0.013694 Grad: 0.094387 Thermal: 0.000360 LR: 9.62e-06\n",
      "Epoch  10 [2800/10697 ( 26.2%)] Loss: 0.024493 L1: 0.014430 Grad: 0.100444 Thermal: 0.000380 LR: 9.62e-06\n",
      "Epoch  10 [2800/10697 ( 26.2%)] Loss: 0.024493 L1: 0.014430 Grad: 0.100444 Thermal: 0.000380 LR: 9.62e-06\n",
      "Epoch  10 [2850/10697 ( 26.6%)] Loss: 0.025298 L1: 0.014435 Grad: 0.108415 Thermal: 0.000439 LR: 9.62e-06\n",
      "Epoch  10 [2850/10697 ( 26.6%)] Loss: 0.025298 L1: 0.014435 Grad: 0.108415 Thermal: 0.000439 LR: 9.62e-06\n",
      "Epoch  10 [2900/10697 ( 27.1%)] Loss: 0.027758 L1: 0.016134 Grad: 0.115982 Thermal: 0.000502 LR: 9.62e-06\n",
      "Epoch  10 [2900/10697 ( 27.1%)] Loss: 0.027758 L1: 0.016134 Grad: 0.115982 Thermal: 0.000502 LR: 9.62e-06\n",
      "Epoch  10 [2950/10697 ( 27.6%)] Loss: 0.020031 L1: 0.011476 Grad: 0.085415 Thermal: 0.000263 LR: 9.62e-06\n",
      "Epoch  10 [2950/10697 ( 27.6%)] Loss: 0.020031 L1: 0.011476 Grad: 0.085415 Thermal: 0.000263 LR: 9.62e-06\n",
      "Epoch  10 [3000/10697 ( 28.0%)] Loss: 0.027910 L1: 0.016669 Grad: 0.112155 Thermal: 0.000512 LR: 9.62e-06\n",
      "Epoch  10 [3000/10697 ( 28.0%)] Loss: 0.027910 L1: 0.016669 Grad: 0.112155 Thermal: 0.000512 LR: 9.62e-06\n",
      "Epoch  10 [3050/10697 ( 28.5%)] Loss: 0.026840 L1: 0.015377 Grad: 0.114365 Thermal: 0.000524 LR: 9.62e-06\n",
      "Epoch  10 [3050/10697 ( 28.5%)] Loss: 0.026840 L1: 0.015377 Grad: 0.114365 Thermal: 0.000524 LR: 9.62e-06\n",
      "Epoch  10 [3100/10697 ( 29.0%)] Loss: 0.028761 L1: 0.016948 Grad: 0.117869 Thermal: 0.000529 LR: 9.62e-06\n",
      "Epoch  10 [3100/10697 ( 29.0%)] Loss: 0.028761 L1: 0.016948 Grad: 0.117869 Thermal: 0.000529 LR: 9.62e-06\n",
      "Epoch  10 [3150/10697 ( 29.4%)] Loss: 0.024708 L1: 0.014619 Grad: 0.100702 Thermal: 0.000380 LR: 9.62e-06\n",
      "Epoch  10 [3150/10697 ( 29.4%)] Loss: 0.024708 L1: 0.014619 Grad: 0.100702 Thermal: 0.000380 LR: 9.62e-06\n",
      "Epoch  10 [3200/10697 ( 29.9%)] Loss: 0.021911 L1: 0.012997 Grad: 0.088935 Thermal: 0.000406 LR: 9.62e-06\n",
      "Epoch  10 [3200/10697 ( 29.9%)] Loss: 0.021911 L1: 0.012997 Grad: 0.088935 Thermal: 0.000406 LR: 9.62e-06\n",
      "Epoch  10 [3250/10697 ( 30.4%)] Loss: 0.024886 L1: 0.014796 Grad: 0.100693 Thermal: 0.000418 LR: 9.62e-06\n",
      "Epoch  10 [3250/10697 ( 30.4%)] Loss: 0.024886 L1: 0.014796 Grad: 0.100693 Thermal: 0.000418 LR: 9.62e-06\n",
      "Epoch  10 [3300/10697 ( 30.8%)] Loss: 0.021589 L1: 0.012527 Grad: 0.090468 Thermal: 0.000314 LR: 9.62e-06\n",
      "Epoch  10 [3300/10697 ( 30.8%)] Loss: 0.021589 L1: 0.012527 Grad: 0.090468 Thermal: 0.000314 LR: 9.62e-06\n",
      "Epoch  10 [3350/10697 ( 31.3%)] Loss: 0.024177 L1: 0.014345 Grad: 0.098119 Thermal: 0.000399 LR: 9.62e-06\n",
      "Epoch  10 [3350/10697 ( 31.3%)] Loss: 0.024177 L1: 0.014345 Grad: 0.098119 Thermal: 0.000399 LR: 9.62e-06\n",
      "Epoch  10 [3400/10697 ( 31.8%)] Loss: 0.027076 L1: 0.015696 Grad: 0.113554 Thermal: 0.000494 LR: 9.62e-06\n",
      "Epoch  10 [3400/10697 ( 31.8%)] Loss: 0.027076 L1: 0.015696 Grad: 0.113554 Thermal: 0.000494 LR: 9.62e-06\n",
      "Epoch  10 [3450/10697 ( 32.3%)] Loss: 0.024400 L1: 0.014396 Grad: 0.099842 Thermal: 0.000396 LR: 9.62e-06\n",
      "Epoch  10 [3450/10697 ( 32.3%)] Loss: 0.024400 L1: 0.014396 Grad: 0.099842 Thermal: 0.000396 LR: 9.62e-06\n",
      "Epoch  10 [3500/10697 ( 32.7%)] Loss: 0.026137 L1: 0.015482 Grad: 0.106327 Thermal: 0.000448 LR: 9.62e-06\n",
      "Epoch  10 [3500/10697 ( 32.7%)] Loss: 0.026137 L1: 0.015482 Grad: 0.106327 Thermal: 0.000448 LR: 9.62e-06\n",
      "Epoch  10 [3550/10697 ( 33.2%)] Loss: 0.027153 L1: 0.015625 Grad: 0.115028 Thermal: 0.000489 LR: 9.62e-06\n",
      "Epoch  10 [3550/10697 ( 33.2%)] Loss: 0.027153 L1: 0.015625 Grad: 0.115028 Thermal: 0.000489 LR: 9.62e-06\n",
      "Epoch  10 [3600/10697 ( 33.7%)] Loss: 0.021430 L1: 0.012509 Grad: 0.089042 Thermal: 0.000324 LR: 9.62e-06\n",
      "Epoch  10 [3600/10697 ( 33.7%)] Loss: 0.021430 L1: 0.012509 Grad: 0.089042 Thermal: 0.000324 LR: 9.62e-06\n",
      "Epoch  10 [3650/10697 ( 34.1%)] Loss: 0.028504 L1: 0.016757 Grad: 0.117193 Thermal: 0.000541 LR: 9.62e-06\n",
      "Epoch  10 [3650/10697 ( 34.1%)] Loss: 0.028504 L1: 0.016757 Grad: 0.117193 Thermal: 0.000541 LR: 9.62e-06\n",
      "Epoch  10 [3700/10697 ( 34.6%)] Loss: 0.024834 L1: 0.014571 Grad: 0.102414 Thermal: 0.000430 LR: 9.62e-06\n",
      "Epoch  10 [3700/10697 ( 34.6%)] Loss: 0.024834 L1: 0.014571 Grad: 0.102414 Thermal: 0.000430 LR: 9.62e-06\n",
      "Epoch  10 [3750/10697 ( 35.1%)] Loss: 0.025254 L1: 0.015071 Grad: 0.101598 Thermal: 0.000458 LR: 9.62e-06\n",
      "Epoch  10 [3750/10697 ( 35.1%)] Loss: 0.025254 L1: 0.015071 Grad: 0.101598 Thermal: 0.000458 LR: 9.62e-06\n",
      "Epoch  10 [3800/10697 ( 35.5%)] Loss: 0.024908 L1: 0.014528 Grad: 0.103611 Thermal: 0.000378 LR: 9.62e-06\n",
      "Epoch  10 [3800/10697 ( 35.5%)] Loss: 0.024908 L1: 0.014528 Grad: 0.103611 Thermal: 0.000378 LR: 9.62e-06\n",
      "Epoch  10 [3850/10697 ( 36.0%)] Loss: 0.024687 L1: 0.014793 Grad: 0.098730 Thermal: 0.000418 LR: 9.62e-06\n",
      "Epoch  10 [3850/10697 ( 36.0%)] Loss: 0.024687 L1: 0.014793 Grad: 0.098730 Thermal: 0.000418 LR: 9.62e-06\n",
      "Epoch  10 [3900/10697 ( 36.5%)] Loss: 0.025924 L1: 0.014875 Grad: 0.110228 Thermal: 0.000519 LR: 9.62e-06\n",
      "Epoch  10 [3900/10697 ( 36.5%)] Loss: 0.025924 L1: 0.014875 Grad: 0.110228 Thermal: 0.000519 LR: 9.62e-06\n",
      "Epoch  10 [3950/10697 ( 36.9%)] Loss: 0.027309 L1: 0.015839 Grad: 0.114445 Thermal: 0.000508 LR: 9.62e-06\n",
      "Epoch  10 [3950/10697 ( 36.9%)] Loss: 0.027309 L1: 0.015839 Grad: 0.114445 Thermal: 0.000508 LR: 9.62e-06\n",
      "Epoch  10 [4000/10697 ( 37.4%)] Loss: 0.026127 L1: 0.015122 Grad: 0.109825 Thermal: 0.000456 LR: 9.62e-06\n",
      "Epoch  10 [4000/10697 ( 37.4%)] Loss: 0.026127 L1: 0.015122 Grad: 0.109825 Thermal: 0.000456 LR: 9.62e-06\n",
      "Epoch  10 [4050/10697 ( 37.9%)] Loss: 0.028380 L1: 0.016589 Grad: 0.117649 Thermal: 0.000512 LR: 9.62e-06\n",
      "Epoch  10 [4050/10697 ( 37.9%)] Loss: 0.028380 L1: 0.016589 Grad: 0.117649 Thermal: 0.000512 LR: 9.62e-06\n",
      "Epoch  10 [4100/10697 ( 38.3%)] Loss: 0.021257 L1: 0.012294 Grad: 0.089483 Thermal: 0.000298 LR: 9.62e-06\n",
      "Epoch  10 [4100/10697 ( 38.3%)] Loss: 0.021257 L1: 0.012294 Grad: 0.089483 Thermal: 0.000298 LR: 9.62e-06\n",
      "Epoch  10 [4150/10697 ( 38.8%)] Loss: 0.028023 L1: 0.016265 Grad: 0.117339 Thermal: 0.000482 LR: 9.62e-06\n",
      "Epoch  10 [4150/10697 ( 38.8%)] Loss: 0.028023 L1: 0.016265 Grad: 0.117339 Thermal: 0.000482 LR: 9.62e-06\n",
      "Epoch  10 [4200/10697 ( 39.3%)] Loss: 0.023435 L1: 0.013765 Grad: 0.096485 Thermal: 0.000413 LR: 9.62e-06\n",
      "Epoch  10 [4200/10697 ( 39.3%)] Loss: 0.023435 L1: 0.013765 Grad: 0.096485 Thermal: 0.000413 LR: 9.62e-06\n",
      "Epoch  10 [4250/10697 ( 39.7%)] Loss: 0.025564 L1: 0.014844 Grad: 0.107004 Thermal: 0.000393 LR: 9.62e-06\n",
      "Epoch  10 [4250/10697 ( 39.7%)] Loss: 0.025564 L1: 0.014844 Grad: 0.107004 Thermal: 0.000393 LR: 9.62e-06\n",
      "Epoch  10 [4300/10697 ( 40.2%)] Loss: 0.026709 L1: 0.015585 Grad: 0.111009 Thermal: 0.000462 LR: 9.62e-06\n",
      "Epoch  10 [4300/10697 ( 40.2%)] Loss: 0.026709 L1: 0.015585 Grad: 0.111009 Thermal: 0.000462 LR: 9.62e-06\n",
      "Epoch  10 [4350/10697 ( 40.7%)] Loss: 0.030838 L1: 0.017445 Grad: 0.133629 Thermal: 0.000591 LR: 9.62e-06\n",
      "Epoch  10 [4350/10697 ( 40.7%)] Loss: 0.030838 L1: 0.017445 Grad: 0.133629 Thermal: 0.000591 LR: 9.62e-06\n",
      "Epoch  10 [4400/10697 ( 41.1%)] Loss: 0.025134 L1: 0.014162 Grad: 0.109516 Thermal: 0.000411 LR: 9.62e-06\n",
      "Epoch  10 [4400/10697 ( 41.1%)] Loss: 0.025134 L1: 0.014162 Grad: 0.109516 Thermal: 0.000411 LR: 9.62e-06\n",
      "Epoch  10 [4450/10697 ( 41.6%)] Loss: 0.022648 L1: 0.013189 Grad: 0.094415 Thermal: 0.000354 LR: 9.62e-06\n",
      "Epoch  10 [4450/10697 ( 41.6%)] Loss: 0.022648 L1: 0.013189 Grad: 0.094415 Thermal: 0.000354 LR: 9.62e-06\n",
      "Epoch  10 [4500/10697 ( 42.1%)] Loss: 0.024220 L1: 0.014261 Grad: 0.099413 Thermal: 0.000364 LR: 9.62e-06\n",
      "Epoch  10 [4500/10697 ( 42.1%)] Loss: 0.024220 L1: 0.014261 Grad: 0.099413 Thermal: 0.000364 LR: 9.62e-06\n",
      "Epoch  10 [4550/10697 ( 42.5%)] Loss: 0.023452 L1: 0.013692 Grad: 0.097405 Thermal: 0.000392 LR: 9.62e-06\n",
      "Epoch  10 [4550/10697 ( 42.5%)] Loss: 0.023452 L1: 0.013692 Grad: 0.097405 Thermal: 0.000392 LR: 9.62e-06\n",
      "Epoch  10 [4600/10697 ( 43.0%)] Loss: 0.030921 L1: 0.017884 Grad: 0.130064 Thermal: 0.000603 LR: 9.62e-06\n",
      "Epoch  10 [4600/10697 ( 43.0%)] Loss: 0.030921 L1: 0.017884 Grad: 0.130064 Thermal: 0.000603 LR: 9.62e-06\n",
      "Epoch  10 [4650/10697 ( 43.5%)] Loss: 0.027917 L1: 0.016080 Grad: 0.118133 Thermal: 0.000486 LR: 9.62e-06\n",
      "Epoch  10 [4650/10697 ( 43.5%)] Loss: 0.027917 L1: 0.016080 Grad: 0.118133 Thermal: 0.000486 LR: 9.62e-06\n",
      "Epoch  10 [4700/10697 ( 43.9%)] Loss: 0.026075 L1: 0.015718 Grad: 0.103344 Thermal: 0.000449 LR: 9.62e-06\n",
      "Epoch  10 [4700/10697 ( 43.9%)] Loss: 0.026075 L1: 0.015718 Grad: 0.103344 Thermal: 0.000449 LR: 9.62e-06\n",
      "Epoch  10 [4750/10697 ( 44.4%)] Loss: 0.020306 L1: 0.011822 Grad: 0.084697 Thermal: 0.000283 LR: 9.62e-06\n",
      "Epoch  10 [4750/10697 ( 44.4%)] Loss: 0.020306 L1: 0.011822 Grad: 0.084697 Thermal: 0.000283 LR: 9.62e-06\n",
      "Epoch  10 [4800/10697 ( 44.9%)] Loss: 0.025681 L1: 0.014935 Grad: 0.107233 Thermal: 0.000453 LR: 9.62e-06\n",
      "Epoch  10 [4800/10697 ( 44.9%)] Loss: 0.025681 L1: 0.014935 Grad: 0.107233 Thermal: 0.000453 LR: 9.62e-06\n",
      "Epoch  10 [4850/10697 ( 45.3%)] Loss: 0.027696 L1: 0.016419 Grad: 0.112526 Thermal: 0.000495 LR: 9.62e-06\n",
      "Epoch  10 [4850/10697 ( 45.3%)] Loss: 0.027696 L1: 0.016419 Grad: 0.112526 Thermal: 0.000495 LR: 9.62e-06\n",
      "Epoch  10 [4900/10697 ( 45.8%)] Loss: 0.025686 L1: 0.014581 Grad: 0.110853 Thermal: 0.000404 LR: 9.62e-06\n",
      "Epoch  10 [4900/10697 ( 45.8%)] Loss: 0.025686 L1: 0.014581 Grad: 0.110853 Thermal: 0.000404 LR: 9.62e-06\n",
      "Epoch  10 [4950/10697 ( 46.3%)] Loss: 0.021282 L1: 0.012401 Grad: 0.088668 Thermal: 0.000288 LR: 9.62e-06\n",
      "Epoch  10 [4950/10697 ( 46.3%)] Loss: 0.021282 L1: 0.012401 Grad: 0.088668 Thermal: 0.000288 LR: 9.62e-06\n",
      "Epoch  10 [5000/10697 ( 46.7%)] Loss: 0.027821 L1: 0.015870 Grad: 0.119284 Thermal: 0.000442 LR: 9.62e-06\n",
      "Epoch  10 [5000/10697 ( 46.7%)] Loss: 0.027821 L1: 0.015870 Grad: 0.119284 Thermal: 0.000442 LR: 9.62e-06\n",
      "Epoch  10 [5050/10697 ( 47.2%)] Loss: 0.027966 L1: 0.016401 Grad: 0.115403 Thermal: 0.000490 LR: 9.62e-06\n",
      "Epoch  10 [5050/10697 ( 47.2%)] Loss: 0.027966 L1: 0.016401 Grad: 0.115403 Thermal: 0.000490 LR: 9.62e-06\n",
      "Epoch  10 [5100/10697 ( 47.7%)] Loss: 0.034826 L1: 0.019554 Grad: 0.152323 Thermal: 0.000787 LR: 9.62e-06\n",
      "Epoch  10 [5100/10697 ( 47.7%)] Loss: 0.034826 L1: 0.019554 Grad: 0.152323 Thermal: 0.000787 LR: 9.62e-06\n",
      "Epoch  10 [5150/10697 ( 48.1%)] Loss: 0.031018 L1: 0.017890 Grad: 0.131002 Thermal: 0.000554 LR: 9.62e-06\n",
      "Epoch  10 [5150/10697 ( 48.1%)] Loss: 0.031018 L1: 0.017890 Grad: 0.131002 Thermal: 0.000554 LR: 9.62e-06\n",
      "Epoch  10 [5200/10697 ( 48.6%)] Loss: 0.028985 L1: 0.017515 Grad: 0.114422 Thermal: 0.000568 LR: 9.62e-06\n",
      "Epoch  10 [5200/10697 ( 48.6%)] Loss: 0.028985 L1: 0.017515 Grad: 0.114422 Thermal: 0.000568 LR: 9.62e-06\n",
      "Epoch  10 [5250/10697 ( 49.1%)] Loss: 0.025745 L1: 0.015142 Grad: 0.105815 Thermal: 0.000422 LR: 9.62e-06\n",
      "Epoch  10 [5250/10697 ( 49.1%)] Loss: 0.025745 L1: 0.015142 Grad: 0.105815 Thermal: 0.000422 LR: 9.62e-06\n",
      "Epoch  10 [5300/10697 ( 49.5%)] Loss: 0.027492 L1: 0.016076 Grad: 0.113932 Thermal: 0.000459 LR: 9.62e-06\n",
      "Epoch  10 [5300/10697 ( 49.5%)] Loss: 0.027492 L1: 0.016076 Grad: 0.113932 Thermal: 0.000459 LR: 9.62e-06\n",
      "Epoch  10 [5350/10697 ( 50.0%)] Loss: 0.026830 L1: 0.016270 Grad: 0.105367 Thermal: 0.000470 LR: 9.62e-06\n",
      "Epoch  10 [5350/10697 ( 50.0%)] Loss: 0.026830 L1: 0.016270 Grad: 0.105367 Thermal: 0.000470 LR: 9.62e-06\n",
      "Epoch  10 [5400/10697 ( 50.5%)] Loss: 0.033052 L1: 0.018801 Grad: 0.142221 Thermal: 0.000581 LR: 9.62e-06\n",
      "Epoch  10 [5400/10697 ( 50.5%)] Loss: 0.033052 L1: 0.018801 Grad: 0.142221 Thermal: 0.000581 LR: 9.62e-06\n",
      "Epoch  10 [5450/10697 ( 50.9%)] Loss: 0.024222 L1: 0.013668 Grad: 0.105324 Thermal: 0.000424 LR: 9.62e-06\n",
      "Epoch  10 [5450/10697 ( 50.9%)] Loss: 0.024222 L1: 0.013668 Grad: 0.105324 Thermal: 0.000424 LR: 9.62e-06\n",
      "Epoch  10 [5500/10697 ( 51.4%)] Loss: 0.026021 L1: 0.015740 Grad: 0.102582 Thermal: 0.000462 LR: 9.62e-06\n",
      "Epoch  10 [5500/10697 ( 51.4%)] Loss: 0.026021 L1: 0.015740 Grad: 0.102582 Thermal: 0.000462 LR: 9.62e-06\n",
      "Epoch  10 [5550/10697 ( 51.9%)] Loss: 0.032659 L1: 0.018949 Grad: 0.136759 Thermal: 0.000681 LR: 9.62e-06\n",
      "Epoch  10 [5550/10697 ( 51.9%)] Loss: 0.032659 L1: 0.018949 Grad: 0.136759 Thermal: 0.000681 LR: 9.62e-06\n",
      "Epoch  10 [5600/10697 ( 52.4%)] Loss: 0.024095 L1: 0.014075 Grad: 0.099966 Thermal: 0.000457 LR: 9.62e-06\n",
      "Epoch  10 [5600/10697 ( 52.4%)] Loss: 0.024095 L1: 0.014075 Grad: 0.099966 Thermal: 0.000457 LR: 9.62e-06\n",
      "Epoch  10 [5650/10697 ( 52.8%)] Loss: 0.025138 L1: 0.014650 Grad: 0.104673 Thermal: 0.000407 LR: 9.62e-06\n",
      "Epoch  10 [5650/10697 ( 52.8%)] Loss: 0.025138 L1: 0.014650 Grad: 0.104673 Thermal: 0.000407 LR: 9.62e-06\n",
      "Epoch  10 [5700/10697 ( 53.3%)] Loss: 0.028513 L1: 0.016727 Grad: 0.117608 Thermal: 0.000508 LR: 9.62e-06\n",
      "Epoch  10 [5700/10697 ( 53.3%)] Loss: 0.028513 L1: 0.016727 Grad: 0.117608 Thermal: 0.000508 LR: 9.62e-06\n",
      "Epoch  10 [5750/10697 ( 53.8%)] Loss: 0.028413 L1: 0.016887 Grad: 0.115002 Thermal: 0.000503 LR: 9.62e-06\n",
      "Epoch  10 [5750/10697 ( 53.8%)] Loss: 0.028413 L1: 0.016887 Grad: 0.115002 Thermal: 0.000503 LR: 9.62e-06\n",
      "Epoch  10 [5800/10697 ( 54.2%)] Loss: 0.029437 L1: 0.016968 Grad: 0.124439 Thermal: 0.000514 LR: 9.62e-06\n",
      "Epoch  10 [5800/10697 ( 54.2%)] Loss: 0.029437 L1: 0.016968 Grad: 0.124439 Thermal: 0.000514 LR: 9.62e-06\n",
      "Epoch  10 [5850/10697 ( 54.7%)] Loss: 0.025443 L1: 0.014608 Grad: 0.108111 Thermal: 0.000466 LR: 9.62e-06\n",
      "Epoch  10 [5850/10697 ( 54.7%)] Loss: 0.025443 L1: 0.014608 Grad: 0.108111 Thermal: 0.000466 LR: 9.62e-06\n",
      "Epoch  10 [5900/10697 ( 55.2%)] Loss: 0.023281 L1: 0.013606 Grad: 0.096529 Thermal: 0.000441 LR: 9.62e-06\n",
      "Epoch  10 [5900/10697 ( 55.2%)] Loss: 0.023281 L1: 0.013606 Grad: 0.096529 Thermal: 0.000441 LR: 9.62e-06\n",
      "Epoch  10 [5950/10697 ( 55.6%)] Loss: 0.031256 L1: 0.018259 Grad: 0.129635 Thermal: 0.000674 LR: 9.62e-06\n",
      "Epoch  10 [5950/10697 ( 55.6%)] Loss: 0.031256 L1: 0.018259 Grad: 0.129635 Thermal: 0.000674 LR: 9.62e-06\n",
      "Epoch  10 [6000/10697 ( 56.1%)] Loss: 0.030933 L1: 0.018222 Grad: 0.126813 Thermal: 0.000589 LR: 9.62e-06\n",
      "Epoch  10 [6000/10697 ( 56.1%)] Loss: 0.030933 L1: 0.018222 Grad: 0.126813 Thermal: 0.000589 LR: 9.62e-06\n",
      "Epoch  10 [6050/10697 ( 56.6%)] Loss: 0.034839 L1: 0.020225 Grad: 0.145666 Thermal: 0.000956 LR: 9.62e-06\n",
      "Epoch  10 [6050/10697 ( 56.6%)] Loss: 0.034839 L1: 0.020225 Grad: 0.145666 Thermal: 0.000956 LR: 9.62e-06\n",
      "Epoch  10 [6100/10697 ( 57.0%)] Loss: 0.030759 L1: 0.018123 Grad: 0.126060 Thermal: 0.000589 LR: 9.62e-06\n",
      "Epoch  10 [6100/10697 ( 57.0%)] Loss: 0.030759 L1: 0.018123 Grad: 0.126060 Thermal: 0.000589 LR: 9.62e-06\n",
      "Epoch  10 [6150/10697 ( 57.5%)] Loss: 0.024028 L1: 0.014175 Grad: 0.098346 Thermal: 0.000384 LR: 9.62e-06\n",
      "Epoch  10 [6150/10697 ( 57.5%)] Loss: 0.024028 L1: 0.014175 Grad: 0.098346 Thermal: 0.000384 LR: 9.62e-06\n",
      "Epoch  10 [6200/10697 ( 58.0%)] Loss: 0.029896 L1: 0.017171 Grad: 0.126951 Thermal: 0.000594 LR: 9.62e-06\n",
      "Epoch  10 [6200/10697 ( 58.0%)] Loss: 0.029896 L1: 0.017171 Grad: 0.126951 Thermal: 0.000594 LR: 9.62e-06\n",
      "Epoch  10 [6250/10697 ( 58.4%)] Loss: 0.022652 L1: 0.013271 Grad: 0.093603 Thermal: 0.000398 LR: 9.62e-06\n",
      "Epoch  10 [6250/10697 ( 58.4%)] Loss: 0.022652 L1: 0.013271 Grad: 0.093603 Thermal: 0.000398 LR: 9.62e-06\n",
      "Epoch  10 [6300/10697 ( 58.9%)] Loss: 0.026789 L1: 0.015565 Grad: 0.112003 Thermal: 0.000472 LR: 9.62e-06\n",
      "Epoch  10 [6300/10697 ( 58.9%)] Loss: 0.026789 L1: 0.015565 Grad: 0.112003 Thermal: 0.000472 LR: 9.62e-06\n",
      "Epoch  10 [6350/10697 ( 59.4%)] Loss: 0.031141 L1: 0.018140 Grad: 0.129721 Thermal: 0.000574 LR: 9.62e-06\n",
      "Epoch  10 [6350/10697 ( 59.4%)] Loss: 0.031141 L1: 0.018140 Grad: 0.129721 Thermal: 0.000574 LR: 9.62e-06\n",
      "Epoch  10 [6400/10697 ( 59.8%)] Loss: 0.026894 L1: 0.015730 Grad: 0.111423 Thermal: 0.000434 LR: 9.62e-06\n",
      "Epoch  10 [6400/10697 ( 59.8%)] Loss: 0.026894 L1: 0.015730 Grad: 0.111423 Thermal: 0.000434 LR: 9.62e-06\n",
      "Epoch  10 [6450/10697 ( 60.3%)] Loss: 0.025237 L1: 0.014583 Grad: 0.106327 Thermal: 0.000428 LR: 9.62e-06\n",
      "Epoch  10 [6450/10697 ( 60.3%)] Loss: 0.025237 L1: 0.014583 Grad: 0.106327 Thermal: 0.000428 LR: 9.62e-06\n",
      "Epoch  10 [6500/10697 ( 60.8%)] Loss: 0.021428 L1: 0.012449 Grad: 0.089632 Thermal: 0.000310 LR: 9.62e-06\n",
      "Epoch  10 [6500/10697 ( 60.8%)] Loss: 0.021428 L1: 0.012449 Grad: 0.089632 Thermal: 0.000310 LR: 9.62e-06\n",
      "Epoch  10 [6550/10697 ( 61.2%)] Loss: 0.026090 L1: 0.015164 Grad: 0.109043 Thermal: 0.000419 LR: 9.62e-06\n",
      "Epoch  10 [6550/10697 ( 61.2%)] Loss: 0.026090 L1: 0.015164 Grad: 0.109043 Thermal: 0.000419 LR: 9.62e-06\n",
      "Epoch  10 [6600/10697 ( 61.7%)] Loss: 0.018563 L1: 0.010550 Grad: 0.079994 Thermal: 0.000277 LR: 9.62e-06\n",
      "Epoch  10 [6600/10697 ( 61.7%)] Loss: 0.018563 L1: 0.010550 Grad: 0.079994 Thermal: 0.000277 LR: 9.62e-06\n",
      "Epoch  10 [6650/10697 ( 62.2%)] Loss: 0.025341 L1: 0.014571 Grad: 0.107487 Thermal: 0.000416 LR: 9.62e-06\n",
      "Epoch  10 [6650/10697 ( 62.2%)] Loss: 0.025341 L1: 0.014571 Grad: 0.107487 Thermal: 0.000416 LR: 9.62e-06\n",
      "Epoch  10 [6700/10697 ( 62.6%)] Loss: 0.026144 L1: 0.015544 Grad: 0.105771 Thermal: 0.000448 LR: 9.62e-06\n",
      "Epoch  10 [6700/10697 ( 62.6%)] Loss: 0.026144 L1: 0.015544 Grad: 0.105771 Thermal: 0.000448 LR: 9.62e-06\n",
      "Epoch  10 [6750/10697 ( 63.1%)] Loss: 0.026031 L1: 0.015450 Grad: 0.105594 Thermal: 0.000431 LR: 9.62e-06\n",
      "Epoch  10 [6750/10697 ( 63.1%)] Loss: 0.026031 L1: 0.015450 Grad: 0.105594 Thermal: 0.000431 LR: 9.62e-06\n",
      "Epoch  10 [6800/10697 ( 63.6%)] Loss: 0.027510 L1: 0.016361 Grad: 0.111241 Thermal: 0.000509 LR: 9.62e-06\n",
      "Epoch  10 [6800/10697 ( 63.6%)] Loss: 0.027510 L1: 0.016361 Grad: 0.111241 Thermal: 0.000509 LR: 9.62e-06\n",
      "Epoch  10 [6850/10697 ( 64.0%)] Loss: 0.024588 L1: 0.014215 Grad: 0.103530 Thermal: 0.000397 LR: 9.62e-06\n",
      "Epoch  10 [6850/10697 ( 64.0%)] Loss: 0.024588 L1: 0.014215 Grad: 0.103530 Thermal: 0.000397 LR: 9.62e-06\n",
      "Epoch  10 [6900/10697 ( 64.5%)] Loss: 0.027624 L1: 0.015757 Grad: 0.118424 Thermal: 0.000488 LR: 9.62e-06\n",
      "Epoch  10 [6900/10697 ( 64.5%)] Loss: 0.027624 L1: 0.015757 Grad: 0.118424 Thermal: 0.000488 LR: 9.62e-06\n",
      "Epoch  10 [6950/10697 ( 65.0%)] Loss: 0.027391 L1: 0.015664 Grad: 0.117021 Thermal: 0.000496 LR: 9.62e-06\n",
      "Epoch  10 [6950/10697 ( 65.0%)] Loss: 0.027391 L1: 0.015664 Grad: 0.117021 Thermal: 0.000496 LR: 9.62e-06\n",
      "Epoch  10 [7000/10697 ( 65.4%)] Loss: 0.025061 L1: 0.014956 Grad: 0.100840 Thermal: 0.000428 LR: 9.62e-06\n",
      "Epoch  10 [7000/10697 ( 65.4%)] Loss: 0.025061 L1: 0.014956 Grad: 0.100840 Thermal: 0.000428 LR: 9.62e-06\n",
      "Epoch  10 [7050/10697 ( 65.9%)] Loss: 0.030744 L1: 0.018240 Grad: 0.124746 Thermal: 0.000588 LR: 9.62e-06\n",
      "Epoch  10 [7050/10697 ( 65.9%)] Loss: 0.030744 L1: 0.018240 Grad: 0.124746 Thermal: 0.000588 LR: 9.62e-06\n",
      "Epoch  10 [7100/10697 ( 66.4%)] Loss: 0.029733 L1: 0.017117 Grad: 0.125886 Thermal: 0.000547 LR: 9.62e-06\n",
      "Epoch  10 [7100/10697 ( 66.4%)] Loss: 0.029733 L1: 0.017117 Grad: 0.125886 Thermal: 0.000547 LR: 9.62e-06\n",
      "Epoch  10 [7150/10697 ( 66.8%)] Loss: 0.028497 L1: 0.016436 Grad: 0.120371 Thermal: 0.000481 LR: 9.62e-06\n",
      "Epoch  10 [7150/10697 ( 66.8%)] Loss: 0.028497 L1: 0.016436 Grad: 0.120371 Thermal: 0.000481 LR: 9.62e-06\n",
      "Epoch  10 [7200/10697 ( 67.3%)] Loss: 0.029770 L1: 0.017102 Grad: 0.126384 Thermal: 0.000591 LR: 9.62e-06\n",
      "Epoch  10 [7200/10697 ( 67.3%)] Loss: 0.029770 L1: 0.017102 Grad: 0.126384 Thermal: 0.000591 LR: 9.62e-06\n",
      "Epoch  10 [7250/10697 ( 67.8%)] Loss: 0.032172 L1: 0.018599 Grad: 0.135405 Thermal: 0.000659 LR: 9.62e-06\n",
      "Epoch  10 [7250/10697 ( 67.8%)] Loss: 0.032172 L1: 0.018599 Grad: 0.135405 Thermal: 0.000659 LR: 9.62e-06\n",
      "Epoch  10 [7300/10697 ( 68.2%)] Loss: 0.026984 L1: 0.015890 Grad: 0.110713 Thermal: 0.000456 LR: 9.62e-06\n",
      "Epoch  10 [7300/10697 ( 68.2%)] Loss: 0.026984 L1: 0.015890 Grad: 0.110713 Thermal: 0.000456 LR: 9.62e-06\n",
      "Epoch  10 [7350/10697 ( 68.7%)] Loss: 0.027688 L1: 0.016040 Grad: 0.116236 Thermal: 0.000502 LR: 9.62e-06\n",
      "Epoch  10 [7350/10697 ( 68.7%)] Loss: 0.027688 L1: 0.016040 Grad: 0.116236 Thermal: 0.000502 LR: 9.62e-06\n",
      "Epoch  10 [7400/10697 ( 69.2%)] Loss: 0.028130 L1: 0.016025 Grad: 0.120803 Thermal: 0.000496 LR: 9.62e-06\n",
      "Epoch  10 [7400/10697 ( 69.2%)] Loss: 0.028130 L1: 0.016025 Grad: 0.120803 Thermal: 0.000496 LR: 9.62e-06\n",
      "Epoch  10 [7450/10697 ( 69.6%)] Loss: 0.028772 L1: 0.016934 Grad: 0.118122 Thermal: 0.000521 LR: 9.62e-06\n",
      "Epoch  10 [7450/10697 ( 69.6%)] Loss: 0.028772 L1: 0.016934 Grad: 0.118122 Thermal: 0.000521 LR: 9.62e-06\n",
      "Epoch  10 [7500/10697 ( 70.1%)] Loss: 0.024312 L1: 0.014137 Grad: 0.101548 Thermal: 0.000399 LR: 9.62e-06\n",
      "Epoch  10 [7500/10697 ( 70.1%)] Loss: 0.024312 L1: 0.014137 Grad: 0.101548 Thermal: 0.000399 LR: 9.62e-06\n",
      "Epoch  10 [7550/10697 ( 70.6%)] Loss: 0.028335 L1: 0.016788 Grad: 0.115222 Thermal: 0.000488 LR: 9.62e-06\n",
      "Epoch  10 [7550/10697 ( 70.6%)] Loss: 0.028335 L1: 0.016788 Grad: 0.115222 Thermal: 0.000488 LR: 9.62e-06\n",
      "Epoch  10 [7600/10697 ( 71.0%)] Loss: 0.023106 L1: 0.013301 Grad: 0.097880 Thermal: 0.000332 LR: 9.62e-06\n",
      "Epoch  10 [7600/10697 ( 71.0%)] Loss: 0.023106 L1: 0.013301 Grad: 0.097880 Thermal: 0.000332 LR: 9.62e-06\n",
      "Epoch  10 [7650/10697 ( 71.5%)] Loss: 0.025905 L1: 0.015387 Grad: 0.104961 Thermal: 0.000448 LR: 9.62e-06\n",
      "Epoch  10 [7650/10697 ( 71.5%)] Loss: 0.025905 L1: 0.015387 Grad: 0.104961 Thermal: 0.000448 LR: 9.62e-06\n",
      "Epoch  10 [7700/10697 ( 72.0%)] Loss: 0.026912 L1: 0.015221 Grad: 0.116682 Thermal: 0.000464 LR: 9.62e-06\n",
      "Epoch  10 [7700/10697 ( 72.0%)] Loss: 0.026912 L1: 0.015221 Grad: 0.116682 Thermal: 0.000464 LR: 9.62e-06\n",
      "Epoch  10 [7750/10697 ( 72.5%)] Loss: 0.023317 L1: 0.013403 Grad: 0.098953 Thermal: 0.000365 LR: 9.62e-06\n",
      "Epoch  10 [7750/10697 ( 72.5%)] Loss: 0.023317 L1: 0.013403 Grad: 0.098953 Thermal: 0.000365 LR: 9.62e-06\n",
      "Epoch  10 [7800/10697 ( 72.9%)] Loss: 0.023882 L1: 0.014173 Grad: 0.096889 Thermal: 0.000401 LR: 9.62e-06\n",
      "Epoch  10 [7800/10697 ( 72.9%)] Loss: 0.023882 L1: 0.014173 Grad: 0.096889 Thermal: 0.000401 LR: 9.62e-06\n",
      "Epoch  10 [7850/10697 ( 73.4%)] Loss: 0.029186 L1: 0.017318 Grad: 0.118403 Thermal: 0.000560 LR: 9.62e-06\n",
      "Epoch  10 [7850/10697 ( 73.4%)] Loss: 0.029186 L1: 0.017318 Grad: 0.118403 Thermal: 0.000560 LR: 9.62e-06\n",
      "Epoch  10 [7900/10697 ( 73.9%)] Loss: 0.024801 L1: 0.014629 Grad: 0.101526 Thermal: 0.000389 LR: 9.62e-06\n",
      "Epoch  10 [7900/10697 ( 73.9%)] Loss: 0.024801 L1: 0.014629 Grad: 0.101526 Thermal: 0.000389 LR: 9.62e-06\n",
      "Epoch  10 [7950/10697 ( 74.3%)] Loss: 0.025124 L1: 0.014790 Grad: 0.103138 Thermal: 0.000406 LR: 9.62e-06\n",
      "Epoch  10 [7950/10697 ( 74.3%)] Loss: 0.025124 L1: 0.014790 Grad: 0.103138 Thermal: 0.000406 LR: 9.62e-06\n",
      "Epoch  10 [8000/10697 ( 74.8%)] Loss: 0.024913 L1: 0.014326 Grad: 0.105672 Thermal: 0.000382 LR: 9.62e-06\n",
      "Epoch  10 [8000/10697 ( 74.8%)] Loss: 0.024913 L1: 0.014326 Grad: 0.105672 Thermal: 0.000382 LR: 9.62e-06\n",
      "Epoch  10 [8050/10697 ( 75.3%)] Loss: 0.024538 L1: 0.014663 Grad: 0.098545 Thermal: 0.000415 LR: 9.62e-06\n",
      "Epoch  10 [8050/10697 ( 75.3%)] Loss: 0.024538 L1: 0.014663 Grad: 0.098545 Thermal: 0.000415 LR: 9.62e-06\n",
      "Epoch  10 [8100/10697 ( 75.7%)] Loss: 0.025016 L1: 0.014508 Grad: 0.104889 Thermal: 0.000399 LR: 9.62e-06\n",
      "Epoch  10 [8100/10697 ( 75.7%)] Loss: 0.025016 L1: 0.014508 Grad: 0.104889 Thermal: 0.000399 LR: 9.62e-06\n",
      "Epoch  10 [8150/10697 ( 76.2%)] Loss: 0.022530 L1: 0.013229 Grad: 0.092837 Thermal: 0.000342 LR: 9.62e-06\n",
      "Epoch  10 [8150/10697 ( 76.2%)] Loss: 0.022530 L1: 0.013229 Grad: 0.092837 Thermal: 0.000342 LR: 9.62e-06\n",
      "Epoch  10 [8200/10697 ( 76.7%)] Loss: 0.024029 L1: 0.014223 Grad: 0.097879 Thermal: 0.000369 LR: 9.62e-06\n",
      "Epoch  10 [8200/10697 ( 76.7%)] Loss: 0.024029 L1: 0.014223 Grad: 0.097879 Thermal: 0.000369 LR: 9.62e-06\n",
      "Epoch  10 [8250/10697 ( 77.1%)] Loss: 0.027711 L1: 0.016227 Grad: 0.114600 Thermal: 0.000487 LR: 9.62e-06\n",
      "Epoch  10 [8250/10697 ( 77.1%)] Loss: 0.027711 L1: 0.016227 Grad: 0.114600 Thermal: 0.000487 LR: 9.62e-06\n",
      "Epoch  10 [8300/10697 ( 77.6%)] Loss: 0.020500 L1: 0.011821 Grad: 0.086639 Thermal: 0.000289 LR: 9.62e-06\n",
      "Epoch  10 [8300/10697 ( 77.6%)] Loss: 0.020500 L1: 0.011821 Grad: 0.086639 Thermal: 0.000289 LR: 9.62e-06\n",
      "Epoch  10 [8350/10697 ( 78.1%)] Loss: 0.026916 L1: 0.015975 Grad: 0.109172 Thermal: 0.000460 LR: 9.62e-06\n",
      "Epoch  10 [8350/10697 ( 78.1%)] Loss: 0.026916 L1: 0.015975 Grad: 0.109172 Thermal: 0.000460 LR: 9.62e-06\n",
      "Epoch  10 [8400/10697 ( 78.5%)] Loss: 0.023094 L1: 0.013737 Grad: 0.093396 Thermal: 0.000350 LR: 9.62e-06\n",
      "Epoch  10 [8400/10697 ( 78.5%)] Loss: 0.023094 L1: 0.013737 Grad: 0.093396 Thermal: 0.000350 LR: 9.62e-06\n",
      "Epoch  10 [8450/10697 ( 79.0%)] Loss: 0.019951 L1: 0.011799 Grad: 0.081364 Thermal: 0.000317 LR: 9.62e-06\n",
      "Epoch  10 [8450/10697 ( 79.0%)] Loss: 0.019951 L1: 0.011799 Grad: 0.081364 Thermal: 0.000317 LR: 9.62e-06\n",
      "Epoch  10 [8500/10697 ( 79.5%)] Loss: 0.033795 L1: 0.019694 Grad: 0.140694 Thermal: 0.000632 LR: 9.62e-06\n",
      "Epoch  10 [8500/10697 ( 79.5%)] Loss: 0.033795 L1: 0.019694 Grad: 0.140694 Thermal: 0.000632 LR: 9.62e-06\n",
      "Epoch  10 [8550/10697 ( 79.9%)] Loss: 0.027553 L1: 0.015985 Grad: 0.115433 Thermal: 0.000487 LR: 9.62e-06\n",
      "Epoch  10 [8550/10697 ( 79.9%)] Loss: 0.027553 L1: 0.015985 Grad: 0.115433 Thermal: 0.000487 LR: 9.62e-06\n",
      "Epoch  10 [8600/10697 ( 80.4%)] Loss: 0.025898 L1: 0.015326 Grad: 0.105506 Thermal: 0.000430 LR: 9.62e-06\n",
      "Epoch  10 [8600/10697 ( 80.4%)] Loss: 0.025898 L1: 0.015326 Grad: 0.105506 Thermal: 0.000430 LR: 9.62e-06\n",
      "Epoch  10 [8650/10697 ( 80.9%)] Loss: 0.030771 L1: 0.018291 Grad: 0.124486 Thermal: 0.000634 LR: 9.62e-06\n",
      "Epoch  10 [8650/10697 ( 80.9%)] Loss: 0.030771 L1: 0.018291 Grad: 0.124486 Thermal: 0.000634 LR: 9.62e-06\n",
      "Epoch  10 [8700/10697 ( 81.3%)] Loss: 0.028103 L1: 0.016261 Grad: 0.118190 Thermal: 0.000469 LR: 9.62e-06\n",
      "Epoch  10 [8700/10697 ( 81.3%)] Loss: 0.028103 L1: 0.016261 Grad: 0.118190 Thermal: 0.000469 LR: 9.62e-06\n",
      "Epoch  10 [8750/10697 ( 81.8%)] Loss: 0.028493 L1: 0.016768 Grad: 0.116998 Thermal: 0.000517 LR: 9.62e-06\n",
      "Epoch  10 [8750/10697 ( 81.8%)] Loss: 0.028493 L1: 0.016768 Grad: 0.116998 Thermal: 0.000517 LR: 9.62e-06\n",
      "Epoch  10 [8800/10697 ( 82.3%)] Loss: 0.030947 L1: 0.017977 Grad: 0.129411 Thermal: 0.000580 LR: 9.62e-06\n",
      "Epoch  10 [8800/10697 ( 82.3%)] Loss: 0.030947 L1: 0.017977 Grad: 0.129411 Thermal: 0.000580 LR: 9.62e-06\n",
      "Epoch  10 [8850/10697 ( 82.7%)] Loss: 0.020505 L1: 0.011970 Grad: 0.085198 Thermal: 0.000313 LR: 9.62e-06\n",
      "Epoch  10 [8850/10697 ( 82.7%)] Loss: 0.020505 L1: 0.011970 Grad: 0.085198 Thermal: 0.000313 LR: 9.62e-06\n",
      "Epoch  10 [8900/10697 ( 83.2%)] Loss: 0.028722 L1: 0.016547 Grad: 0.121476 Thermal: 0.000553 LR: 9.62e-06\n",
      "Epoch  10 [8900/10697 ( 83.2%)] Loss: 0.028722 L1: 0.016547 Grad: 0.121476 Thermal: 0.000553 LR: 9.62e-06\n",
      "Epoch  10 [8950/10697 ( 83.7%)] Loss: 0.018916 L1: 0.010921 Grad: 0.079825 Thermal: 0.000257 LR: 9.62e-06\n",
      "Epoch  10 [8950/10697 ( 83.7%)] Loss: 0.018916 L1: 0.010921 Grad: 0.079825 Thermal: 0.000257 LR: 9.62e-06\n",
      "Epoch  10 [9000/10697 ( 84.1%)] Loss: 0.023919 L1: 0.013924 Grad: 0.099726 Thermal: 0.000446 LR: 9.62e-06\n",
      "Epoch  10 [9000/10697 ( 84.1%)] Loss: 0.023919 L1: 0.013924 Grad: 0.099726 Thermal: 0.000446 LR: 9.62e-06\n",
      "Epoch  10 [9050/10697 ( 84.6%)] Loss: 0.028286 L1: 0.016410 Grad: 0.118499 Thermal: 0.000540 LR: 9.62e-06\n",
      "Epoch  10 [9050/10697 ( 84.6%)] Loss: 0.028286 L1: 0.016410 Grad: 0.118499 Thermal: 0.000540 LR: 9.62e-06\n",
      "Epoch  10 [9100/10697 ( 85.1%)] Loss: 0.023492 L1: 0.013653 Grad: 0.098199 Thermal: 0.000381 LR: 9.62e-06\n",
      "Epoch  10 [9100/10697 ( 85.1%)] Loss: 0.023492 L1: 0.013653 Grad: 0.098199 Thermal: 0.000381 LR: 9.62e-06\n",
      "Epoch  10 [9150/10697 ( 85.5%)] Loss: 0.027333 L1: 0.015939 Grad: 0.113709 Thermal: 0.000456 LR: 9.62e-06\n",
      "Epoch  10 [9150/10697 ( 85.5%)] Loss: 0.027333 L1: 0.015939 Grad: 0.113709 Thermal: 0.000456 LR: 9.62e-06\n",
      "Epoch  10 [9200/10697 ( 86.0%)] Loss: 0.028731 L1: 0.016866 Grad: 0.118364 Thermal: 0.000564 LR: 9.62e-06\n",
      "Epoch  10 [9200/10697 ( 86.0%)] Loss: 0.028731 L1: 0.016866 Grad: 0.118364 Thermal: 0.000564 LR: 9.62e-06\n",
      "Epoch  10 [9250/10697 ( 86.5%)] Loss: 0.014712 L1: 0.008387 Grad: 0.063149 Thermal: 0.000195 LR: 9.62e-06\n",
      "Epoch  10 [9250/10697 ( 86.5%)] Loss: 0.014712 L1: 0.008387 Grad: 0.063149 Thermal: 0.000195 LR: 9.62e-06\n",
      "Epoch  10 [9300/10697 ( 86.9%)] Loss: 0.025755 L1: 0.014967 Grad: 0.107683 Thermal: 0.000413 LR: 9.62e-06\n",
      "Epoch  10 [9300/10697 ( 86.9%)] Loss: 0.025755 L1: 0.014967 Grad: 0.107683 Thermal: 0.000413 LR: 9.62e-06\n",
      "Epoch  10 [9350/10697 ( 87.4%)] Loss: 0.025447 L1: 0.014345 Grad: 0.110813 Thermal: 0.000411 LR: 9.62e-06\n",
      "Epoch  10 [9350/10697 ( 87.4%)] Loss: 0.025447 L1: 0.014345 Grad: 0.110813 Thermal: 0.000411 LR: 9.62e-06\n",
      "Epoch  10 [9400/10697 ( 87.9%)] Loss: 0.026143 L1: 0.015446 Grad: 0.106754 Thermal: 0.000440 LR: 9.62e-06\n",
      "Epoch  10 [9400/10697 ( 87.9%)] Loss: 0.026143 L1: 0.015446 Grad: 0.106754 Thermal: 0.000440 LR: 9.62e-06\n",
      "Epoch  10 [9450/10697 ( 88.3%)] Loss: 0.029660 L1: 0.017185 Grad: 0.124488 Thermal: 0.000523 LR: 9.62e-06\n",
      "Epoch  10 [9450/10697 ( 88.3%)] Loss: 0.029660 L1: 0.017185 Grad: 0.124488 Thermal: 0.000523 LR: 9.62e-06\n",
      "Epoch  10 [9500/10697 ( 88.8%)] Loss: 0.027310 L1: 0.016000 Grad: 0.112836 Thermal: 0.000533 LR: 9.62e-06\n",
      "Epoch  10 [9500/10697 ( 88.8%)] Loss: 0.027310 L1: 0.016000 Grad: 0.112836 Thermal: 0.000533 LR: 9.62e-06\n",
      "Epoch  10 [9550/10697 ( 89.3%)] Loss: 0.036242 L1: 0.021000 Grad: 0.152012 Thermal: 0.000805 LR: 9.62e-06\n",
      "Epoch  10 [9550/10697 ( 89.3%)] Loss: 0.036242 L1: 0.021000 Grad: 0.152012 Thermal: 0.000805 LR: 9.62e-06\n",
      "Epoch  10 [9600/10697 ( 89.7%)] Loss: 0.027174 L1: 0.016184 Grad: 0.109653 Thermal: 0.000486 LR: 9.62e-06\n",
      "Epoch  10 [9600/10697 ( 89.7%)] Loss: 0.027174 L1: 0.016184 Grad: 0.109653 Thermal: 0.000486 LR: 9.62e-06\n",
      "Epoch  10 [9650/10697 ( 90.2%)] Loss: 0.030054 L1: 0.017081 Grad: 0.129415 Thermal: 0.000632 LR: 9.62e-06\n",
      "Epoch  10 [9650/10697 ( 90.2%)] Loss: 0.030054 L1: 0.017081 Grad: 0.129415 Thermal: 0.000632 LR: 9.62e-06\n",
      "Epoch  10 [9700/10697 ( 90.7%)] Loss: 0.023025 L1: 0.013563 Grad: 0.094444 Thermal: 0.000344 LR: 9.62e-06\n",
      "Epoch  10 [9700/10697 ( 90.7%)] Loss: 0.023025 L1: 0.013563 Grad: 0.094444 Thermal: 0.000344 LR: 9.62e-06\n",
      "Epoch  10 [9750/10697 ( 91.1%)] Loss: 0.026392 L1: 0.015313 Grad: 0.110546 Thermal: 0.000479 LR: 9.62e-06\n",
      "Epoch  10 [9750/10697 ( 91.1%)] Loss: 0.026392 L1: 0.015313 Grad: 0.110546 Thermal: 0.000479 LR: 9.62e-06\n",
      "Epoch  10 [9800/10697 ( 91.6%)] Loss: 0.017938 L1: 0.010632 Grad: 0.072924 Thermal: 0.000272 LR: 9.62e-06\n",
      "Epoch  10 [9800/10697 ( 91.6%)] Loss: 0.017938 L1: 0.010632 Grad: 0.072924 Thermal: 0.000272 LR: 9.62e-06\n",
      "Epoch  10 [9850/10697 ( 92.1%)] Loss: 0.021989 L1: 0.012573 Grad: 0.094015 Thermal: 0.000294 LR: 9.62e-06\n",
      "Epoch  10 [9850/10697 ( 92.1%)] Loss: 0.021989 L1: 0.012573 Grad: 0.094015 Thermal: 0.000294 LR: 9.62e-06\n",
      "Epoch  10 [9900/10697 ( 92.5%)] Loss: 0.026180 L1: 0.015132 Grad: 0.110245 Thermal: 0.000458 LR: 9.62e-06\n",
      "Epoch  10 [9900/10697 ( 92.5%)] Loss: 0.026180 L1: 0.015132 Grad: 0.110245 Thermal: 0.000458 LR: 9.62e-06\n",
      "Epoch  10 [9950/10697 ( 93.0%)] Loss: 0.026270 L1: 0.015217 Grad: 0.110319 Thermal: 0.000427 LR: 9.62e-06\n",
      "Epoch  10 [9950/10697 ( 93.0%)] Loss: 0.026270 L1: 0.015217 Grad: 0.110319 Thermal: 0.000427 LR: 9.62e-06\n",
      "Epoch  10 [10000/10697 ( 93.5%)] Loss: 0.024399 L1: 0.013793 Grad: 0.105850 Thermal: 0.000413 LR: 9.62e-06\n",
      "Epoch  10 [10000/10697 ( 93.5%)] Loss: 0.024399 L1: 0.013793 Grad: 0.105850 Thermal: 0.000413 LR: 9.62e-06\n",
      "Epoch  10 [10050/10697 ( 94.0%)] Loss: 0.028562 L1: 0.017061 Grad: 0.114750 Thermal: 0.000509 LR: 9.62e-06\n",
      "Epoch  10 [10050/10697 ( 94.0%)] Loss: 0.028562 L1: 0.017061 Grad: 0.114750 Thermal: 0.000509 LR: 9.62e-06\n",
      "Epoch  10 [10100/10697 ( 94.4%)] Loss: 0.022762 L1: 0.013311 Grad: 0.094334 Thermal: 0.000362 LR: 9.62e-06\n",
      "Epoch  10 [10100/10697 ( 94.4%)] Loss: 0.022762 L1: 0.013311 Grad: 0.094334 Thermal: 0.000362 LR: 9.62e-06\n",
      "Epoch  10 [10150/10697 ( 94.9%)] Loss: 0.027805 L1: 0.016396 Grad: 0.113817 Thermal: 0.000538 LR: 9.62e-06\n",
      "Epoch  10 [10150/10697 ( 94.9%)] Loss: 0.027805 L1: 0.016396 Grad: 0.113817 Thermal: 0.000538 LR: 9.62e-06\n",
      "Epoch  10 [10200/10697 ( 95.4%)] Loss: 0.022030 L1: 0.012871 Grad: 0.091424 Thermal: 0.000342 LR: 9.62e-06\n",
      "Epoch  10 [10200/10697 ( 95.4%)] Loss: 0.022030 L1: 0.012871 Grad: 0.091424 Thermal: 0.000342 LR: 9.62e-06\n",
      "Epoch  10 [10250/10697 ( 95.8%)] Loss: 0.024553 L1: 0.014748 Grad: 0.097850 Thermal: 0.000403 LR: 9.62e-06\n",
      "Epoch  10 [10250/10697 ( 95.8%)] Loss: 0.024553 L1: 0.014748 Grad: 0.097850 Thermal: 0.000403 LR: 9.62e-06\n",
      "Epoch  10 [10300/10697 ( 96.3%)] Loss: 0.023880 L1: 0.013635 Grad: 0.102250 Thermal: 0.000383 LR: 9.62e-06\n",
      "Epoch  10 [10300/10697 ( 96.3%)] Loss: 0.023880 L1: 0.013635 Grad: 0.102250 Thermal: 0.000383 LR: 9.62e-06\n",
      "Epoch  10 [10350/10697 ( 96.8%)] Loss: 0.031411 L1: 0.018193 Grad: 0.131875 Thermal: 0.000603 LR: 9.62e-06\n",
      "Epoch  10 [10350/10697 ( 96.8%)] Loss: 0.031411 L1: 0.018193 Grad: 0.131875 Thermal: 0.000603 LR: 9.62e-06\n",
      "Epoch  10 [10400/10697 ( 97.2%)] Loss: 0.024877 L1: 0.014268 Grad: 0.105896 Thermal: 0.000381 LR: 9.62e-06\n",
      "Epoch  10 [10400/10697 ( 97.2%)] Loss: 0.024877 L1: 0.014268 Grad: 0.105896 Thermal: 0.000381 LR: 9.62e-06\n",
      "Epoch  10 [10450/10697 ( 97.7%)] Loss: 0.026527 L1: 0.014824 Grad: 0.116817 Thermal: 0.000434 LR: 9.62e-06\n",
      "Epoch  10 [10450/10697 ( 97.7%)] Loss: 0.026527 L1: 0.014824 Grad: 0.116817 Thermal: 0.000434 LR: 9.62e-06\n",
      "Epoch  10 [10500/10697 ( 98.2%)] Loss: 0.028021 L1: 0.016042 Grad: 0.119512 Thermal: 0.000563 LR: 9.62e-06\n",
      "Epoch  10 [10500/10697 ( 98.2%)] Loss: 0.028021 L1: 0.016042 Grad: 0.119512 Thermal: 0.000563 LR: 9.62e-06\n",
      "Epoch  10 [10550/10697 ( 98.6%)] Loss: 0.032903 L1: 0.019124 Grad: 0.137469 Thermal: 0.000656 LR: 9.62e-06\n",
      "Epoch  10 [10550/10697 ( 98.6%)] Loss: 0.032903 L1: 0.019124 Grad: 0.137469 Thermal: 0.000656 LR: 9.62e-06\n",
      "Epoch  10 [10600/10697 ( 99.1%)] Loss: 0.037485 L1: 0.021512 Grad: 0.159298 Thermal: 0.000863 LR: 9.62e-06\n",
      "Epoch  10 [10600/10697 ( 99.1%)] Loss: 0.037485 L1: 0.021512 Grad: 0.159298 Thermal: 0.000863 LR: 9.62e-06\n",
      "Epoch  10 [10650/10697 ( 99.6%)] Loss: 0.028236 L1: 0.016679 Grad: 0.115317 Thermal: 0.000501 LR: 9.62e-06\n",
      "Epoch  10 [10650/10697 ( 99.6%)] Loss: 0.028236 L1: 0.016679 Grad: 0.115317 Thermal: 0.000501 LR: 9.62e-06\n",
      "üí´ New best model saved! PSNR: 33.82\n",
      "Epoch  10 Summary: Loss=0.026761 (L1:0.0156, Grad:0.1116, Thermal:0.0005) Val_PSNR=33.82dB Best=33.82dB Time=39.5min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "üí´ New best model saved! PSNR: 33.82\n",
      "Epoch  10 Summary: Loss=0.026761 (L1:0.0156, Grad:0.1116, Thermal:0.0005) Val_PSNR=33.82dB Best=33.82dB Time=39.5min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  11 [   0/10697 (  0.0%)] Loss: 0.031897 L1: 0.018807 Grad: 0.130569 Thermal: 0.000651 LR: 9.55e-06\n",
      "Epoch  11 [   0/10697 (  0.0%)] Loss: 0.031897 L1: 0.018807 Grad: 0.130569 Thermal: 0.000651 LR: 9.55e-06\n",
      "Epoch  11 [  50/10697 (  0.5%)] Loss: 0.035230 L1: 0.020154 Grad: 0.150322 Thermal: 0.000866 LR: 9.55e-06\n",
      "Epoch  11 [  50/10697 (  0.5%)] Loss: 0.035230 L1: 0.020154 Grad: 0.150322 Thermal: 0.000866 LR: 9.55e-06\n",
      "Epoch  11 [ 100/10697 (  0.9%)] Loss: 0.021747 L1: 0.012603 Grad: 0.091284 Thermal: 0.000312 LR: 9.55e-06\n",
      "Epoch  11 [ 100/10697 (  0.9%)] Loss: 0.021747 L1: 0.012603 Grad: 0.091284 Thermal: 0.000312 LR: 9.55e-06\n",
      "Epoch  11 [ 150/10697 (  1.4%)] Loss: 0.023248 L1: 0.013252 Grad: 0.099768 Thermal: 0.000374 LR: 9.55e-06\n",
      "Epoch  11 [ 150/10697 (  1.4%)] Loss: 0.023248 L1: 0.013252 Grad: 0.099768 Thermal: 0.000374 LR: 9.55e-06\n",
      "Epoch  11 [ 200/10697 (  1.9%)] Loss: 0.028903 L1: 0.016528 Grad: 0.123502 Thermal: 0.000499 LR: 9.55e-06\n",
      "Epoch  11 [ 200/10697 (  1.9%)] Loss: 0.028903 L1: 0.016528 Grad: 0.123502 Thermal: 0.000499 LR: 9.55e-06\n",
      "Epoch  11 [ 250/10697 (  2.3%)] Loss: 0.025917 L1: 0.014509 Grad: 0.113889 Thermal: 0.000387 LR: 9.55e-06\n",
      "Epoch  11 [ 250/10697 (  2.3%)] Loss: 0.025917 L1: 0.014509 Grad: 0.113889 Thermal: 0.000387 LR: 9.55e-06\n",
      "Epoch  11 [ 300/10697 (  2.8%)] Loss: 0.030244 L1: 0.017664 Grad: 0.125516 Thermal: 0.000574 LR: 9.55e-06\n",
      "Epoch  11 [ 300/10697 (  2.8%)] Loss: 0.030244 L1: 0.017664 Grad: 0.125516 Thermal: 0.000574 LR: 9.55e-06\n",
      "Epoch  11 [ 350/10697 (  3.3%)] Loss: 0.024170 L1: 0.014371 Grad: 0.097790 Thermal: 0.000403 LR: 9.55e-06\n",
      "Epoch  11 [ 350/10697 (  3.3%)] Loss: 0.024170 L1: 0.014371 Grad: 0.097790 Thermal: 0.000403 LR: 9.55e-06\n",
      "Epoch  11 [ 400/10697 (  3.7%)] Loss: 0.023887 L1: 0.013765 Grad: 0.101035 Thermal: 0.000367 LR: 9.55e-06\n",
      "Epoch  11 [ 400/10697 (  3.7%)] Loss: 0.023887 L1: 0.013765 Grad: 0.101035 Thermal: 0.000367 LR: 9.55e-06\n",
      "Epoch  11 [ 450/10697 (  4.2%)] Loss: 0.025808 L1: 0.014801 Grad: 0.109853 Thermal: 0.000431 LR: 9.55e-06\n",
      "Epoch  11 [ 450/10697 (  4.2%)] Loss: 0.025808 L1: 0.014801 Grad: 0.109853 Thermal: 0.000431 LR: 9.55e-06\n",
      "Epoch  11 [ 500/10697 (  4.7%)] Loss: 0.020766 L1: 0.011806 Grad: 0.089470 Thermal: 0.000275 LR: 9.55e-06\n",
      "Epoch  11 [ 500/10697 (  4.7%)] Loss: 0.020766 L1: 0.011806 Grad: 0.089470 Thermal: 0.000275 LR: 9.55e-06\n",
      "Epoch  11 [ 550/10697 (  5.1%)] Loss: 0.020194 L1: 0.011767 Grad: 0.084117 Thermal: 0.000305 LR: 9.55e-06\n",
      "Epoch  11 [ 550/10697 (  5.1%)] Loss: 0.020194 L1: 0.011767 Grad: 0.084117 Thermal: 0.000305 LR: 9.55e-06\n",
      "Epoch  11 [ 600/10697 (  5.6%)] Loss: 0.030287 L1: 0.017676 Grad: 0.125832 Thermal: 0.000550 LR: 9.55e-06\n",
      "Epoch  11 [ 600/10697 (  5.6%)] Loss: 0.030287 L1: 0.017676 Grad: 0.125832 Thermal: 0.000550 LR: 9.55e-06\n",
      "Epoch  11 [ 650/10697 (  6.1%)] Loss: 0.031376 L1: 0.018237 Grad: 0.131094 Thermal: 0.000589 LR: 9.55e-06\n",
      "Epoch  11 [ 650/10697 (  6.1%)] Loss: 0.031376 L1: 0.018237 Grad: 0.131094 Thermal: 0.000589 LR: 9.55e-06\n",
      "Epoch  11 [ 700/10697 (  6.5%)] Loss: 0.023002 L1: 0.013513 Grad: 0.094711 Thermal: 0.000347 LR: 9.55e-06\n",
      "Epoch  11 [ 700/10697 (  6.5%)] Loss: 0.023002 L1: 0.013513 Grad: 0.094711 Thermal: 0.000347 LR: 9.55e-06\n",
      "Epoch  11 [ 750/10697 (  7.0%)] Loss: 0.026990 L1: 0.015637 Grad: 0.113249 Thermal: 0.000552 LR: 9.55e-06\n",
      "Epoch  11 [ 750/10697 (  7.0%)] Loss: 0.026990 L1: 0.015637 Grad: 0.113249 Thermal: 0.000552 LR: 9.55e-06\n",
      "Epoch  11 [ 800/10697 (  7.5%)] Loss: 0.026786 L1: 0.015179 Grad: 0.115843 Thermal: 0.000444 LR: 9.55e-06\n",
      "Epoch  11 [ 800/10697 (  7.5%)] Loss: 0.026786 L1: 0.015179 Grad: 0.115843 Thermal: 0.000444 LR: 9.55e-06\n",
      "Epoch  11 [ 850/10697 (  7.9%)] Loss: 0.027620 L1: 0.015784 Grad: 0.118148 Thermal: 0.000414 LR: 9.55e-06\n",
      "Epoch  11 [ 850/10697 (  7.9%)] Loss: 0.027620 L1: 0.015784 Grad: 0.118148 Thermal: 0.000414 LR: 9.55e-06\n",
      "Epoch  11 [ 900/10697 (  8.4%)] Loss: 0.027564 L1: 0.016147 Grad: 0.113923 Thermal: 0.000491 LR: 9.55e-06\n",
      "Epoch  11 [ 900/10697 (  8.4%)] Loss: 0.027564 L1: 0.016147 Grad: 0.113923 Thermal: 0.000491 LR: 9.55e-06\n",
      "Epoch  11 [ 950/10697 (  8.9%)] Loss: 0.022890 L1: 0.013251 Grad: 0.096227 Thermal: 0.000333 LR: 9.55e-06\n",
      "Epoch  11 [ 950/10697 (  8.9%)] Loss: 0.022890 L1: 0.013251 Grad: 0.096227 Thermal: 0.000333 LR: 9.55e-06\n",
      "Epoch  11 [1000/10697 (  9.3%)] Loss: 0.028418 L1: 0.016712 Grad: 0.116805 Thermal: 0.000520 LR: 9.55e-06\n",
      "Epoch  11 [1000/10697 (  9.3%)] Loss: 0.028418 L1: 0.016712 Grad: 0.116805 Thermal: 0.000520 LR: 9.55e-06\n",
      "Epoch  11 [1050/10697 (  9.8%)] Loss: 0.026993 L1: 0.015809 Grad: 0.111613 Thermal: 0.000446 LR: 9.55e-06\n",
      "Epoch  11 [1050/10697 (  9.8%)] Loss: 0.026993 L1: 0.015809 Grad: 0.111613 Thermal: 0.000446 LR: 9.55e-06\n",
      "Epoch  11 [1100/10697 ( 10.3%)] Loss: 0.020646 L1: 0.012160 Grad: 0.084709 Thermal: 0.000300 LR: 9.55e-06\n",
      "Epoch  11 [1100/10697 ( 10.3%)] Loss: 0.020646 L1: 0.012160 Grad: 0.084709 Thermal: 0.000300 LR: 9.55e-06\n",
      "Epoch  11 [1150/10697 ( 10.8%)] Loss: 0.031745 L1: 0.018754 Grad: 0.129592 Thermal: 0.000633 LR: 9.55e-06\n",
      "Epoch  11 [1150/10697 ( 10.8%)] Loss: 0.031745 L1: 0.018754 Grad: 0.129592 Thermal: 0.000633 LR: 9.55e-06\n",
      "Epoch  11 [1200/10697 ( 11.2%)] Loss: 0.028027 L1: 0.016620 Grad: 0.113810 Thermal: 0.000530 LR: 9.55e-06\n",
      "Epoch  11 [1200/10697 ( 11.2%)] Loss: 0.028027 L1: 0.016620 Grad: 0.113810 Thermal: 0.000530 LR: 9.55e-06\n",
      "Epoch  11 [1250/10697 ( 11.7%)] Loss: 0.023383 L1: 0.013088 Grad: 0.102796 Thermal: 0.000323 LR: 9.55e-06\n",
      "Epoch  11 [1250/10697 ( 11.7%)] Loss: 0.023383 L1: 0.013088 Grad: 0.102796 Thermal: 0.000323 LR: 9.55e-06\n",
      "Epoch  11 [1300/10697 ( 12.2%)] Loss: 0.027593 L1: 0.015992 Grad: 0.115733 Thermal: 0.000562 LR: 9.55e-06\n",
      "Epoch  11 [1300/10697 ( 12.2%)] Loss: 0.027593 L1: 0.015992 Grad: 0.115733 Thermal: 0.000562 LR: 9.55e-06\n",
      "Epoch  11 [1350/10697 ( 12.6%)] Loss: 0.028888 L1: 0.016739 Grad: 0.121227 Thermal: 0.000538 LR: 9.55e-06\n",
      "Epoch  11 [1350/10697 ( 12.6%)] Loss: 0.028888 L1: 0.016739 Grad: 0.121227 Thermal: 0.000538 LR: 9.55e-06\n",
      "Epoch  11 [1400/10697 ( 13.1%)] Loss: 0.025669 L1: 0.014944 Grad: 0.107036 Thermal: 0.000425 LR: 9.55e-06\n",
      "Epoch  11 [1400/10697 ( 13.1%)] Loss: 0.025669 L1: 0.014944 Grad: 0.107036 Thermal: 0.000425 LR: 9.55e-06\n",
      "Epoch  11 [1450/10697 ( 13.6%)] Loss: 0.020854 L1: 0.011921 Grad: 0.089186 Thermal: 0.000296 LR: 9.55e-06\n",
      "Epoch  11 [1450/10697 ( 13.6%)] Loss: 0.020854 L1: 0.011921 Grad: 0.089186 Thermal: 0.000296 LR: 9.55e-06\n",
      "Epoch  11 [1500/10697 ( 14.0%)] Loss: 0.028051 L1: 0.016255 Grad: 0.117740 Thermal: 0.000458 LR: 9.55e-06\n",
      "Epoch  11 [1500/10697 ( 14.0%)] Loss: 0.028051 L1: 0.016255 Grad: 0.117740 Thermal: 0.000458 LR: 9.55e-06\n",
      "Epoch  11 [1550/10697 ( 14.5%)] Loss: 0.027764 L1: 0.015783 Grad: 0.119588 Thermal: 0.000444 LR: 9.55e-06\n",
      "Epoch  11 [1550/10697 ( 14.5%)] Loss: 0.027764 L1: 0.015783 Grad: 0.119588 Thermal: 0.000444 LR: 9.55e-06\n",
      "Epoch  11 [1600/10697 ( 15.0%)] Loss: 0.027184 L1: 0.015228 Grad: 0.119335 Thermal: 0.000456 LR: 9.55e-06\n",
      "Epoch  11 [1600/10697 ( 15.0%)] Loss: 0.027184 L1: 0.015228 Grad: 0.119335 Thermal: 0.000456 LR: 9.55e-06\n",
      "Epoch  11 [1650/10697 ( 15.4%)] Loss: 0.027015 L1: 0.015643 Grad: 0.113462 Thermal: 0.000500 LR: 9.55e-06\n",
      "Epoch  11 [1650/10697 ( 15.4%)] Loss: 0.027015 L1: 0.015643 Grad: 0.113462 Thermal: 0.000500 LR: 9.55e-06\n",
      "Epoch  11 [1700/10697 ( 15.9%)] Loss: 0.021092 L1: 0.012346 Grad: 0.087300 Thermal: 0.000324 LR: 9.55e-06\n",
      "Epoch  11 [1700/10697 ( 15.9%)] Loss: 0.021092 L1: 0.012346 Grad: 0.087300 Thermal: 0.000324 LR: 9.55e-06\n",
      "Epoch  11 [1750/10697 ( 16.4%)] Loss: 0.033190 L1: 0.019238 Grad: 0.139201 Thermal: 0.000639 LR: 9.55e-06\n",
      "Epoch  11 [1750/10697 ( 16.4%)] Loss: 0.033190 L1: 0.019238 Grad: 0.139201 Thermal: 0.000639 LR: 9.55e-06\n",
      "Epoch  11 [1800/10697 ( 16.8%)] Loss: 0.024232 L1: 0.013474 Grad: 0.107409 Thermal: 0.000344 LR: 9.55e-06\n",
      "Epoch  11 [1800/10697 ( 16.8%)] Loss: 0.024232 L1: 0.013474 Grad: 0.107409 Thermal: 0.000344 LR: 9.55e-06\n",
      "Epoch  11 [1850/10697 ( 17.3%)] Loss: 0.026329 L1: 0.015301 Grad: 0.110053 Thermal: 0.000451 LR: 9.55e-06\n",
      "Epoch  11 [1850/10697 ( 17.3%)] Loss: 0.026329 L1: 0.015301 Grad: 0.110053 Thermal: 0.000451 LR: 9.55e-06\n",
      "Epoch  11 [1900/10697 ( 17.8%)] Loss: 0.031031 L1: 0.018056 Grad: 0.129453 Thermal: 0.000583 LR: 9.55e-06\n",
      "Epoch  11 [1900/10697 ( 17.8%)] Loss: 0.031031 L1: 0.018056 Grad: 0.129453 Thermal: 0.000583 LR: 9.55e-06\n",
      "Epoch  11 [1950/10697 ( 18.2%)] Loss: 0.025078 L1: 0.014567 Grad: 0.104915 Thermal: 0.000392 LR: 9.55e-06\n",
      "Epoch  11 [1950/10697 ( 18.2%)] Loss: 0.025078 L1: 0.014567 Grad: 0.104915 Thermal: 0.000392 LR: 9.55e-06\n",
      "Epoch  11 [2000/10697 ( 18.7%)] Loss: 0.022636 L1: 0.013008 Grad: 0.096119 Thermal: 0.000331 LR: 9.55e-06\n",
      "Epoch  11 [2000/10697 ( 18.7%)] Loss: 0.022636 L1: 0.013008 Grad: 0.096119 Thermal: 0.000331 LR: 9.55e-06\n",
      "Epoch  11 [2050/10697 ( 19.2%)] Loss: 0.025081 L1: 0.014640 Grad: 0.104215 Thermal: 0.000392 LR: 9.55e-06\n",
      "Epoch  11 [2050/10697 ( 19.2%)] Loss: 0.025081 L1: 0.014640 Grad: 0.104215 Thermal: 0.000392 LR: 9.55e-06\n",
      "Epoch  11 [2100/10697 ( 19.6%)] Loss: 0.028701 L1: 0.016757 Grad: 0.119199 Thermal: 0.000477 LR: 9.55e-06\n",
      "Epoch  11 [2100/10697 ( 19.6%)] Loss: 0.028701 L1: 0.016757 Grad: 0.119199 Thermal: 0.000477 LR: 9.55e-06\n",
      "Epoch  11 [2150/10697 ( 20.1%)] Loss: 0.028145 L1: 0.015985 Grad: 0.121376 Thermal: 0.000466 LR: 9.55e-06\n",
      "Epoch  11 [2150/10697 ( 20.1%)] Loss: 0.028145 L1: 0.015985 Grad: 0.121376 Thermal: 0.000466 LR: 9.55e-06\n",
      "Epoch  11 [2200/10697 ( 20.6%)] Loss: 0.025571 L1: 0.015031 Grad: 0.105183 Thermal: 0.000430 LR: 9.55e-06\n",
      "Epoch  11 [2200/10697 ( 20.6%)] Loss: 0.025571 L1: 0.015031 Grad: 0.105183 Thermal: 0.000430 LR: 9.55e-06\n",
      "Epoch  11 [2250/10697 ( 21.0%)] Loss: 0.024151 L1: 0.014310 Grad: 0.098213 Thermal: 0.000393 LR: 9.55e-06\n",
      "Epoch  11 [2250/10697 ( 21.0%)] Loss: 0.024151 L1: 0.014310 Grad: 0.098213 Thermal: 0.000393 LR: 9.55e-06\n",
      "Epoch  11 [2300/10697 ( 21.5%)] Loss: 0.022494 L1: 0.013373 Grad: 0.091032 Thermal: 0.000360 LR: 9.55e-06\n",
      "Epoch  11 [2300/10697 ( 21.5%)] Loss: 0.022494 L1: 0.013373 Grad: 0.091032 Thermal: 0.000360 LR: 9.55e-06\n",
      "Epoch  11 [2350/10697 ( 22.0%)] Loss: 0.030082 L1: 0.017493 Grad: 0.125626 Thermal: 0.000539 LR: 9.55e-06\n",
      "Epoch  11 [2350/10697 ( 22.0%)] Loss: 0.030082 L1: 0.017493 Grad: 0.125626 Thermal: 0.000539 LR: 9.55e-06\n",
      "Epoch  11 [2400/10697 ( 22.4%)] Loss: 0.029383 L1: 0.017469 Grad: 0.118871 Thermal: 0.000529 LR: 9.55e-06\n",
      "Epoch  11 [2400/10697 ( 22.4%)] Loss: 0.029383 L1: 0.017469 Grad: 0.118871 Thermal: 0.000529 LR: 9.55e-06\n",
      "Epoch  11 [2450/10697 ( 22.9%)] Loss: 0.024208 L1: 0.014352 Grad: 0.098364 Thermal: 0.000400 LR: 9.55e-06\n",
      "Epoch  11 [2450/10697 ( 22.9%)] Loss: 0.024208 L1: 0.014352 Grad: 0.098364 Thermal: 0.000400 LR: 9.55e-06\n",
      "Epoch  11 [2500/10697 ( 23.4%)] Loss: 0.029213 L1: 0.017151 Grad: 0.120364 Thermal: 0.000510 LR: 9.55e-06\n",
      "Epoch  11 [2500/10697 ( 23.4%)] Loss: 0.029213 L1: 0.017151 Grad: 0.120364 Thermal: 0.000510 LR: 9.55e-06\n",
      "Epoch  11 [2550/10697 ( 23.8%)] Loss: 0.020272 L1: 0.011770 Grad: 0.084861 Thermal: 0.000314 LR: 9.55e-06\n",
      "Epoch  11 [2550/10697 ( 23.8%)] Loss: 0.020272 L1: 0.011770 Grad: 0.084861 Thermal: 0.000314 LR: 9.55e-06\n",
      "Epoch  11 [2600/10697 ( 24.3%)] Loss: 0.028509 L1: 0.016654 Grad: 0.118288 Thermal: 0.000534 LR: 9.55e-06\n",
      "Epoch  11 [2600/10697 ( 24.3%)] Loss: 0.028509 L1: 0.016654 Grad: 0.118288 Thermal: 0.000534 LR: 9.55e-06\n",
      "Epoch  11 [2650/10697 ( 24.8%)] Loss: 0.029533 L1: 0.016941 Grad: 0.125626 Thermal: 0.000588 LR: 9.55e-06\n",
      "Epoch  11 [2650/10697 ( 24.8%)] Loss: 0.029533 L1: 0.016941 Grad: 0.125626 Thermal: 0.000588 LR: 9.55e-06\n",
      "Epoch  11 [2700/10697 ( 25.2%)] Loss: 0.020257 L1: 0.011537 Grad: 0.087031 Thermal: 0.000335 LR: 9.55e-06\n",
      "Epoch  11 [2700/10697 ( 25.2%)] Loss: 0.020257 L1: 0.011537 Grad: 0.087031 Thermal: 0.000335 LR: 9.55e-06\n",
      "Epoch  11 [2750/10697 ( 25.7%)] Loss: 0.030562 L1: 0.017263 Grad: 0.132647 Thermal: 0.000677 LR: 9.55e-06\n",
      "Epoch  11 [2750/10697 ( 25.7%)] Loss: 0.030562 L1: 0.017263 Grad: 0.132647 Thermal: 0.000677 LR: 9.55e-06\n",
      "Epoch  11 [2800/10697 ( 26.2%)] Loss: 0.023516 L1: 0.013862 Grad: 0.096366 Thermal: 0.000359 LR: 9.55e-06\n",
      "Epoch  11 [2800/10697 ( 26.2%)] Loss: 0.023516 L1: 0.013862 Grad: 0.096366 Thermal: 0.000359 LR: 9.55e-06\n",
      "Epoch  11 [2850/10697 ( 26.6%)] Loss: 0.026172 L1: 0.015226 Grad: 0.109254 Thermal: 0.000420 LR: 9.55e-06\n",
      "Epoch  11 [2850/10697 ( 26.6%)] Loss: 0.026172 L1: 0.015226 Grad: 0.109254 Thermal: 0.000420 LR: 9.55e-06\n",
      "Epoch  11 [2900/10697 ( 27.1%)] Loss: 0.030736 L1: 0.017480 Grad: 0.132206 Thermal: 0.000705 LR: 9.55e-06\n",
      "Epoch  11 [2900/10697 ( 27.1%)] Loss: 0.030736 L1: 0.017480 Grad: 0.132206 Thermal: 0.000705 LR: 9.55e-06\n",
      "Epoch  11 [2950/10697 ( 27.6%)] Loss: 0.021215 L1: 0.012295 Grad: 0.089045 Thermal: 0.000317 LR: 9.55e-06\n",
      "Epoch  11 [2950/10697 ( 27.6%)] Loss: 0.021215 L1: 0.012295 Grad: 0.089045 Thermal: 0.000317 LR: 9.55e-06\n",
      "Epoch  11 [3000/10697 ( 28.0%)] Loss: 0.031311 L1: 0.017728 Grad: 0.135551 Thermal: 0.000563 LR: 9.55e-06\n",
      "Epoch  11 [3000/10697 ( 28.0%)] Loss: 0.031311 L1: 0.017728 Grad: 0.135551 Thermal: 0.000563 LR: 9.55e-06\n",
      "Epoch  11 [3050/10697 ( 28.5%)] Loss: 0.029507 L1: 0.017261 Grad: 0.122192 Thermal: 0.000552 LR: 9.55e-06\n",
      "Epoch  11 [3050/10697 ( 28.5%)] Loss: 0.029507 L1: 0.017261 Grad: 0.122192 Thermal: 0.000552 LR: 9.55e-06\n",
      "Epoch  11 [3100/10697 ( 29.0%)] Loss: 0.025177 L1: 0.014845 Grad: 0.103111 Thermal: 0.000420 LR: 9.55e-06\n",
      "Epoch  11 [3100/10697 ( 29.0%)] Loss: 0.025177 L1: 0.014845 Grad: 0.103111 Thermal: 0.000420 LR: 9.55e-06\n",
      "Epoch  11 [3150/10697 ( 29.4%)] Loss: 0.025757 L1: 0.015162 Grad: 0.105713 Thermal: 0.000469 LR: 9.55e-06\n",
      "Epoch  11 [3150/10697 ( 29.4%)] Loss: 0.025757 L1: 0.015162 Grad: 0.105713 Thermal: 0.000469 LR: 9.55e-06\n",
      "Epoch  11 [3200/10697 ( 29.9%)] Loss: 0.026808 L1: 0.015945 Grad: 0.108396 Thermal: 0.000471 LR: 9.55e-06\n",
      "Epoch  11 [3200/10697 ( 29.9%)] Loss: 0.026808 L1: 0.015945 Grad: 0.108396 Thermal: 0.000471 LR: 9.55e-06\n",
      "Epoch  11 [3250/10697 ( 30.4%)] Loss: 0.025444 L1: 0.014923 Grad: 0.105005 Thermal: 0.000406 LR: 9.55e-06\n",
      "Epoch  11 [3250/10697 ( 30.4%)] Loss: 0.025444 L1: 0.014923 Grad: 0.105005 Thermal: 0.000406 LR: 9.55e-06\n",
      "Epoch  11 [3300/10697 ( 30.8%)] Loss: 0.028476 L1: 0.016948 Grad: 0.115037 Thermal: 0.000494 LR: 9.55e-06\n",
      "Epoch  11 [3300/10697 ( 30.8%)] Loss: 0.028476 L1: 0.016948 Grad: 0.115037 Thermal: 0.000494 LR: 9.55e-06\n",
      "Epoch  11 [3350/10697 ( 31.3%)] Loss: 0.024408 L1: 0.013960 Grad: 0.104285 Thermal: 0.000392 LR: 9.55e-06\n",
      "Epoch  11 [3350/10697 ( 31.3%)] Loss: 0.024408 L1: 0.013960 Grad: 0.104285 Thermal: 0.000392 LR: 9.55e-06\n",
      "Epoch  11 [3400/10697 ( 31.8%)] Loss: 0.027364 L1: 0.015715 Grad: 0.116272 Thermal: 0.000444 LR: 9.55e-06\n",
      "Epoch  11 [3400/10697 ( 31.8%)] Loss: 0.027364 L1: 0.015715 Grad: 0.116272 Thermal: 0.000444 LR: 9.55e-06\n",
      "Epoch  11 [3450/10697 ( 32.3%)] Loss: 0.026827 L1: 0.015475 Grad: 0.113312 Thermal: 0.000420 LR: 9.55e-06\n",
      "Epoch  11 [3450/10697 ( 32.3%)] Loss: 0.026827 L1: 0.015475 Grad: 0.113312 Thermal: 0.000420 LR: 9.55e-06\n",
      "Epoch  11 [3500/10697 ( 32.7%)] Loss: 0.024110 L1: 0.014200 Grad: 0.098896 Thermal: 0.000411 LR: 9.55e-06\n",
      "Epoch  11 [3500/10697 ( 32.7%)] Loss: 0.024110 L1: 0.014200 Grad: 0.098896 Thermal: 0.000411 LR: 9.55e-06\n",
      "Epoch  11 [3550/10697 ( 33.2%)] Loss: 0.032228 L1: 0.018253 Grad: 0.139436 Thermal: 0.000640 LR: 9.55e-06\n",
      "Epoch  11 [3550/10697 ( 33.2%)] Loss: 0.032228 L1: 0.018253 Grad: 0.139436 Thermal: 0.000640 LR: 9.55e-06\n",
      "Epoch  11 [3600/10697 ( 33.7%)] Loss: 0.030411 L1: 0.017490 Grad: 0.128929 Thermal: 0.000570 LR: 9.55e-06\n",
      "Epoch  11 [3600/10697 ( 33.7%)] Loss: 0.030411 L1: 0.017490 Grad: 0.128929 Thermal: 0.000570 LR: 9.55e-06\n",
      "Epoch  11 [3650/10697 ( 34.1%)] Loss: 0.024849 L1: 0.014120 Grad: 0.107110 Thermal: 0.000372 LR: 9.55e-06\n",
      "Epoch  11 [3650/10697 ( 34.1%)] Loss: 0.024849 L1: 0.014120 Grad: 0.107110 Thermal: 0.000372 LR: 9.55e-06\n",
      "Epoch  11 [3700/10697 ( 34.6%)] Loss: 0.026254 L1: 0.015607 Grad: 0.106253 Thermal: 0.000431 LR: 9.55e-06\n",
      "Epoch  11 [3700/10697 ( 34.6%)] Loss: 0.026254 L1: 0.015607 Grad: 0.106253 Thermal: 0.000431 LR: 9.55e-06\n",
      "Epoch  11 [3750/10697 ( 35.1%)] Loss: 0.026765 L1: 0.016162 Grad: 0.105803 Thermal: 0.000461 LR: 9.55e-06\n",
      "Epoch  11 [3750/10697 ( 35.1%)] Loss: 0.026765 L1: 0.016162 Grad: 0.105803 Thermal: 0.000461 LR: 9.55e-06\n",
      "Epoch  11 [3800/10697 ( 35.5%)] Loss: 0.024561 L1: 0.013861 Grad: 0.106823 Thermal: 0.000367 LR: 9.55e-06\n",
      "Epoch  11 [3800/10697 ( 35.5%)] Loss: 0.024561 L1: 0.013861 Grad: 0.106823 Thermal: 0.000367 LR: 9.55e-06\n",
      "Epoch  11 [3850/10697 ( 36.0%)] Loss: 0.024912 L1: 0.014454 Grad: 0.104370 Thermal: 0.000413 LR: 9.55e-06\n",
      "Epoch  11 [3850/10697 ( 36.0%)] Loss: 0.024912 L1: 0.014454 Grad: 0.104370 Thermal: 0.000413 LR: 9.55e-06\n",
      "Epoch  11 [3900/10697 ( 36.5%)] Loss: 0.025328 L1: 0.015029 Grad: 0.102782 Thermal: 0.000414 LR: 9.55e-06\n",
      "Epoch  11 [3900/10697 ( 36.5%)] Loss: 0.025328 L1: 0.015029 Grad: 0.102782 Thermal: 0.000414 LR: 9.55e-06\n",
      "Epoch  11 [3950/10697 ( 36.9%)] Loss: 0.024279 L1: 0.014531 Grad: 0.097284 Thermal: 0.000393 LR: 9.55e-06\n",
      "Epoch  11 [3950/10697 ( 36.9%)] Loss: 0.024279 L1: 0.014531 Grad: 0.097284 Thermal: 0.000393 LR: 9.55e-06\n",
      "Epoch  11 [4000/10697 ( 37.4%)] Loss: 0.030155 L1: 0.017422 Grad: 0.127037 Thermal: 0.000587 LR: 9.55e-06\n",
      "Epoch  11 [4000/10697 ( 37.4%)] Loss: 0.030155 L1: 0.017422 Grad: 0.127037 Thermal: 0.000587 LR: 9.55e-06\n",
      "Epoch  11 [4050/10697 ( 37.9%)] Loss: 0.022628 L1: 0.013219 Grad: 0.093907 Thermal: 0.000367 LR: 9.55e-06\n",
      "Epoch  11 [4050/10697 ( 37.9%)] Loss: 0.022628 L1: 0.013219 Grad: 0.093907 Thermal: 0.000367 LR: 9.55e-06\n",
      "Epoch  11 [4100/10697 ( 38.3%)] Loss: 0.023137 L1: 0.013461 Grad: 0.096576 Thermal: 0.000371 LR: 9.55e-06\n",
      "Epoch  11 [4100/10697 ( 38.3%)] Loss: 0.023137 L1: 0.013461 Grad: 0.096576 Thermal: 0.000371 LR: 9.55e-06\n",
      "Epoch  11 [4150/10697 ( 38.8%)] Loss: 0.028049 L1: 0.016570 Grad: 0.114539 Thermal: 0.000501 LR: 9.55e-06\n",
      "Epoch  11 [4150/10697 ( 38.8%)] Loss: 0.028049 L1: 0.016570 Grad: 0.114539 Thermal: 0.000501 LR: 9.55e-06\n",
      "Epoch  11 [4200/10697 ( 39.3%)] Loss: 0.026451 L1: 0.014996 Grad: 0.114327 Thermal: 0.000451 LR: 9.55e-06\n",
      "Epoch  11 [4200/10697 ( 39.3%)] Loss: 0.026451 L1: 0.014996 Grad: 0.114327 Thermal: 0.000451 LR: 9.55e-06\n",
      "Epoch  11 [4250/10697 ( 39.7%)] Loss: 0.027679 L1: 0.016516 Grad: 0.111383 Thermal: 0.000506 LR: 9.55e-06\n",
      "Epoch  11 [4250/10697 ( 39.7%)] Loss: 0.027679 L1: 0.016516 Grad: 0.111383 Thermal: 0.000506 LR: 9.55e-06\n",
      "Epoch  11 [4300/10697 ( 40.2%)] Loss: 0.035646 L1: 0.020371 Grad: 0.152375 Thermal: 0.000754 LR: 9.55e-06\n",
      "Epoch  11 [4300/10697 ( 40.2%)] Loss: 0.035646 L1: 0.020371 Grad: 0.152375 Thermal: 0.000754 LR: 9.55e-06\n",
      "Epoch  11 [4350/10697 ( 40.7%)] Loss: 0.027299 L1: 0.015967 Grad: 0.113081 Thermal: 0.000465 LR: 9.55e-06\n",
      "Epoch  11 [4350/10697 ( 40.7%)] Loss: 0.027299 L1: 0.015967 Grad: 0.113081 Thermal: 0.000465 LR: 9.55e-06\n",
      "Epoch  11 [4400/10697 ( 41.1%)] Loss: 0.024150 L1: 0.013869 Grad: 0.102620 Thermal: 0.000387 LR: 9.55e-06\n",
      "Epoch  11 [4400/10697 ( 41.1%)] Loss: 0.024150 L1: 0.013869 Grad: 0.102620 Thermal: 0.000387 LR: 9.55e-06\n",
      "Epoch  11 [4450/10697 ( 41.6%)] Loss: 0.020925 L1: 0.012162 Grad: 0.087482 Thermal: 0.000312 LR: 9.55e-06\n",
      "Epoch  11 [4450/10697 ( 41.6%)] Loss: 0.020925 L1: 0.012162 Grad: 0.087482 Thermal: 0.000312 LR: 9.55e-06\n",
      "Epoch  11 [4500/10697 ( 42.1%)] Loss: 0.033434 L1: 0.019199 Grad: 0.142017 Thermal: 0.000668 LR: 9.55e-06\n",
      "Epoch  11 [4500/10697 ( 42.1%)] Loss: 0.033434 L1: 0.019199 Grad: 0.142017 Thermal: 0.000668 LR: 9.55e-06\n",
      "Epoch  11 [4550/10697 ( 42.5%)] Loss: 0.032481 L1: 0.018888 Grad: 0.135622 Thermal: 0.000620 LR: 9.55e-06\n",
      "Epoch  11 [4550/10697 ( 42.5%)] Loss: 0.032481 L1: 0.018888 Grad: 0.135622 Thermal: 0.000620 LR: 9.55e-06\n",
      "Epoch  11 [4600/10697 ( 43.0%)] Loss: 0.027631 L1: 0.016217 Grad: 0.113897 Thermal: 0.000481 LR: 9.55e-06\n",
      "Epoch  11 [4600/10697 ( 43.0%)] Loss: 0.027631 L1: 0.016217 Grad: 0.113897 Thermal: 0.000481 LR: 9.55e-06\n",
      "Epoch  11 [4650/10697 ( 43.5%)] Loss: 0.025595 L1: 0.015364 Grad: 0.102090 Thermal: 0.000431 LR: 9.55e-06\n",
      "Epoch  11 [4650/10697 ( 43.5%)] Loss: 0.025595 L1: 0.015364 Grad: 0.102090 Thermal: 0.000431 LR: 9.55e-06\n",
      "Epoch  11 [4700/10697 ( 43.9%)] Loss: 0.026866 L1: 0.015286 Grad: 0.115565 Thermal: 0.000483 LR: 9.55e-06\n",
      "Epoch  11 [4700/10697 ( 43.9%)] Loss: 0.026866 L1: 0.015286 Grad: 0.115565 Thermal: 0.000483 LR: 9.55e-06\n",
      "Epoch  11 [4750/10697 ( 44.4%)] Loss: 0.025764 L1: 0.014839 Grad: 0.109033 Thermal: 0.000424 LR: 9.55e-06\n",
      "Epoch  11 [4750/10697 ( 44.4%)] Loss: 0.025764 L1: 0.014839 Grad: 0.109033 Thermal: 0.000424 LR: 9.55e-06\n",
      "Epoch  11 [4800/10697 ( 44.9%)] Loss: 0.019455 L1: 0.011210 Grad: 0.082324 Thermal: 0.000261 LR: 9.55e-06\n",
      "Epoch  11 [4800/10697 ( 44.9%)] Loss: 0.019455 L1: 0.011210 Grad: 0.082324 Thermal: 0.000261 LR: 9.55e-06\n",
      "Epoch  11 [4850/10697 ( 45.3%)] Loss: 0.024037 L1: 0.013972 Grad: 0.100480 Thermal: 0.000334 LR: 9.55e-06\n",
      "Epoch  11 [4850/10697 ( 45.3%)] Loss: 0.024037 L1: 0.013972 Grad: 0.100480 Thermal: 0.000334 LR: 9.55e-06\n",
      "Epoch  11 [4900/10697 ( 45.8%)] Loss: 0.022007 L1: 0.012480 Grad: 0.095106 Thermal: 0.000338 LR: 9.55e-06\n",
      "Epoch  11 [4900/10697 ( 45.8%)] Loss: 0.022007 L1: 0.012480 Grad: 0.095106 Thermal: 0.000338 LR: 9.55e-06\n",
      "Epoch  11 [4950/10697 ( 46.3%)] Loss: 0.030324 L1: 0.017240 Grad: 0.130557 Thermal: 0.000571 LR: 9.55e-06\n",
      "Epoch  11 [4950/10697 ( 46.3%)] Loss: 0.030324 L1: 0.017240 Grad: 0.130557 Thermal: 0.000571 LR: 9.55e-06\n",
      "Epoch  11 [5000/10697 ( 46.7%)] Loss: 0.025417 L1: 0.014844 Grad: 0.105533 Thermal: 0.000406 LR: 9.55e-06\n",
      "Epoch  11 [5000/10697 ( 46.7%)] Loss: 0.025417 L1: 0.014844 Grad: 0.105533 Thermal: 0.000406 LR: 9.55e-06\n",
      "Epoch  11 [5050/10697 ( 47.2%)] Loss: 0.023886 L1: 0.013968 Grad: 0.098993 Thermal: 0.000375 LR: 9.55e-06\n",
      "Epoch  11 [5050/10697 ( 47.2%)] Loss: 0.023886 L1: 0.013968 Grad: 0.098993 Thermal: 0.000375 LR: 9.55e-06\n",
      "Epoch  11 [5100/10697 ( 47.7%)] Loss: 0.028447 L1: 0.016853 Grad: 0.115689 Thermal: 0.000503 LR: 9.55e-06\n",
      "Epoch  11 [5100/10697 ( 47.7%)] Loss: 0.028447 L1: 0.016853 Grad: 0.115689 Thermal: 0.000503 LR: 9.55e-06\n",
      "Epoch  11 [5150/10697 ( 48.1%)] Loss: 0.023765 L1: 0.014114 Grad: 0.096328 Thermal: 0.000364 LR: 9.55e-06\n",
      "Epoch  11 [5150/10697 ( 48.1%)] Loss: 0.023765 L1: 0.014114 Grad: 0.096328 Thermal: 0.000364 LR: 9.55e-06\n",
      "Epoch  11 [5200/10697 ( 48.6%)] Loss: 0.025289 L1: 0.014945 Grad: 0.103222 Thermal: 0.000425 LR: 9.55e-06\n",
      "Epoch  11 [5200/10697 ( 48.6%)] Loss: 0.025289 L1: 0.014945 Grad: 0.103222 Thermal: 0.000425 LR: 9.55e-06\n",
      "Epoch  11 [5250/10697 ( 49.1%)] Loss: 0.021374 L1: 0.012610 Grad: 0.087493 Thermal: 0.000300 LR: 9.55e-06\n",
      "Epoch  11 [5250/10697 ( 49.1%)] Loss: 0.021374 L1: 0.012610 Grad: 0.087493 Thermal: 0.000300 LR: 9.55e-06\n",
      "Epoch  11 [5300/10697 ( 49.5%)] Loss: 0.028129 L1: 0.016808 Grad: 0.112972 Thermal: 0.000487 LR: 9.55e-06\n",
      "Epoch  11 [5300/10697 ( 49.5%)] Loss: 0.028129 L1: 0.016808 Grad: 0.112972 Thermal: 0.000487 LR: 9.55e-06\n",
      "Epoch  11 [5350/10697 ( 50.0%)] Loss: 0.026830 L1: 0.015606 Grad: 0.112010 Thermal: 0.000464 LR: 9.55e-06\n",
      "Epoch  11 [5350/10697 ( 50.0%)] Loss: 0.026830 L1: 0.015606 Grad: 0.112010 Thermal: 0.000464 LR: 9.55e-06\n",
      "Epoch  11 [5400/10697 ( 50.5%)] Loss: 0.029559 L1: 0.017198 Grad: 0.123332 Thermal: 0.000558 LR: 9.55e-06\n",
      "Epoch  11 [5400/10697 ( 50.5%)] Loss: 0.029559 L1: 0.017198 Grad: 0.123332 Thermal: 0.000558 LR: 9.55e-06\n",
      "Epoch  11 [5450/10697 ( 50.9%)] Loss: 0.022492 L1: 0.013110 Grad: 0.093640 Thermal: 0.000363 LR: 9.55e-06\n",
      "Epoch  11 [5450/10697 ( 50.9%)] Loss: 0.022492 L1: 0.013110 Grad: 0.093640 Thermal: 0.000363 LR: 9.55e-06\n",
      "Epoch  11 [5500/10697 ( 51.4%)] Loss: 0.025493 L1: 0.014608 Grad: 0.108653 Thermal: 0.000396 LR: 9.55e-06\n",
      "Epoch  11 [5500/10697 ( 51.4%)] Loss: 0.025493 L1: 0.014608 Grad: 0.108653 Thermal: 0.000396 LR: 9.55e-06\n",
      "Epoch  11 [5550/10697 ( 51.9%)] Loss: 0.025233 L1: 0.014597 Grad: 0.106160 Thermal: 0.000408 LR: 9.55e-06\n",
      "Epoch  11 [5550/10697 ( 51.9%)] Loss: 0.025233 L1: 0.014597 Grad: 0.106160 Thermal: 0.000408 LR: 9.55e-06\n",
      "Epoch  11 [5600/10697 ( 52.4%)] Loss: 0.028406 L1: 0.017044 Grad: 0.113358 Thermal: 0.000526 LR: 9.55e-06\n",
      "Epoch  11 [5600/10697 ( 52.4%)] Loss: 0.028406 L1: 0.017044 Grad: 0.113358 Thermal: 0.000526 LR: 9.55e-06\n",
      "Epoch  11 [5650/10697 ( 52.8%)] Loss: 0.026841 L1: 0.015785 Grad: 0.110324 Thermal: 0.000468 LR: 9.55e-06\n",
      "Epoch  11 [5650/10697 ( 52.8%)] Loss: 0.026841 L1: 0.015785 Grad: 0.110324 Thermal: 0.000468 LR: 9.55e-06\n",
      "Epoch  11 [5700/10697 ( 53.3%)] Loss: 0.024915 L1: 0.014375 Grad: 0.105170 Thermal: 0.000464 LR: 9.55e-06\n",
      "Epoch  11 [5700/10697 ( 53.3%)] Loss: 0.024915 L1: 0.014375 Grad: 0.105170 Thermal: 0.000464 LR: 9.55e-06\n",
      "Epoch  11 [5750/10697 ( 53.8%)] Loss: 0.027602 L1: 0.016205 Grad: 0.113720 Thermal: 0.000493 LR: 9.55e-06\n",
      "Epoch  11 [5750/10697 ( 53.8%)] Loss: 0.027602 L1: 0.016205 Grad: 0.113720 Thermal: 0.000493 LR: 9.55e-06\n",
      "Epoch  11 [5800/10697 ( 54.2%)] Loss: 0.021432 L1: 0.012783 Grad: 0.086317 Thermal: 0.000333 LR: 9.55e-06\n",
      "Epoch  11 [5800/10697 ( 54.2%)] Loss: 0.021432 L1: 0.012783 Grad: 0.086317 Thermal: 0.000333 LR: 9.55e-06\n",
      "Epoch  11 [5850/10697 ( 54.7%)] Loss: 0.031602 L1: 0.018129 Grad: 0.134430 Thermal: 0.000604 LR: 9.55e-06\n",
      "Epoch  11 [5850/10697 ( 54.7%)] Loss: 0.031602 L1: 0.018129 Grad: 0.134430 Thermal: 0.000604 LR: 9.55e-06\n",
      "Epoch  11 [5900/10697 ( 55.2%)] Loss: 0.027966 L1: 0.016290 Grad: 0.116518 Thermal: 0.000474 LR: 9.55e-06\n",
      "Epoch  11 [5900/10697 ( 55.2%)] Loss: 0.027966 L1: 0.016290 Grad: 0.116518 Thermal: 0.000474 LR: 9.55e-06\n",
      "Epoch  11 [5950/10697 ( 55.6%)] Loss: 0.019326 L1: 0.010830 Grad: 0.084823 Thermal: 0.000284 LR: 9.55e-06\n",
      "Epoch  11 [5950/10697 ( 55.6%)] Loss: 0.019326 L1: 0.010830 Grad: 0.084823 Thermal: 0.000284 LR: 9.55e-06\n",
      "Epoch  11 [6000/10697 ( 56.1%)] Loss: 0.024443 L1: 0.014523 Grad: 0.099001 Thermal: 0.000391 LR: 9.55e-06\n",
      "Epoch  11 [6000/10697 ( 56.1%)] Loss: 0.024443 L1: 0.014523 Grad: 0.099001 Thermal: 0.000391 LR: 9.55e-06\n",
      "Epoch  11 [6050/10697 ( 56.6%)] Loss: 0.024245 L1: 0.013873 Grad: 0.103525 Thermal: 0.000391 LR: 9.55e-06\n",
      "Epoch  11 [6050/10697 ( 56.6%)] Loss: 0.024245 L1: 0.013873 Grad: 0.103525 Thermal: 0.000391 LR: 9.55e-06\n",
      "Epoch  11 [6100/10697 ( 57.0%)] Loss: 0.030563 L1: 0.017052 Grad: 0.134841 Thermal: 0.000551 LR: 9.55e-06\n",
      "Epoch  11 [6100/10697 ( 57.0%)] Loss: 0.030563 L1: 0.017052 Grad: 0.134841 Thermal: 0.000551 LR: 9.55e-06\n",
      "Epoch  11 [6150/10697 ( 57.5%)] Loss: 0.029361 L1: 0.016848 Grad: 0.124859 Thermal: 0.000535 LR: 9.55e-06\n",
      "Epoch  11 [6150/10697 ( 57.5%)] Loss: 0.029361 L1: 0.016848 Grad: 0.124859 Thermal: 0.000535 LR: 9.55e-06\n",
      "Epoch  11 [6200/10697 ( 58.0%)] Loss: 0.024965 L1: 0.014759 Grad: 0.101831 Thermal: 0.000462 LR: 9.55e-06\n",
      "Epoch  11 [6200/10697 ( 58.0%)] Loss: 0.024965 L1: 0.014759 Grad: 0.101831 Thermal: 0.000462 LR: 9.55e-06\n",
      "Epoch  11 [6250/10697 ( 58.4%)] Loss: 0.023884 L1: 0.013680 Grad: 0.101857 Thermal: 0.000361 LR: 9.55e-06\n",
      "Epoch  11 [6250/10697 ( 58.4%)] Loss: 0.023884 L1: 0.013680 Grad: 0.101857 Thermal: 0.000361 LR: 9.55e-06\n",
      "Epoch  11 [6300/10697 ( 58.9%)] Loss: 0.030815 L1: 0.017742 Grad: 0.130370 Thermal: 0.000722 LR: 9.55e-06\n",
      "Epoch  11 [6300/10697 ( 58.9%)] Loss: 0.030815 L1: 0.017742 Grad: 0.130370 Thermal: 0.000722 LR: 9.55e-06\n",
      "Epoch  11 [6350/10697 ( 59.4%)] Loss: 0.029421 L1: 0.017410 Grad: 0.119852 Thermal: 0.000521 LR: 9.55e-06\n",
      "Epoch  11 [6350/10697 ( 59.4%)] Loss: 0.029421 L1: 0.017410 Grad: 0.119852 Thermal: 0.000521 LR: 9.55e-06\n",
      "Epoch  11 [6400/10697 ( 59.8%)] Loss: 0.024890 L1: 0.014807 Grad: 0.100635 Thermal: 0.000399 LR: 9.55e-06\n",
      "Epoch  11 [6400/10697 ( 59.8%)] Loss: 0.024890 L1: 0.014807 Grad: 0.100635 Thermal: 0.000399 LR: 9.55e-06\n",
      "Epoch  11 [6450/10697 ( 60.3%)] Loss: 0.031885 L1: 0.018149 Grad: 0.137077 Thermal: 0.000572 LR: 9.55e-06\n",
      "Epoch  11 [6450/10697 ( 60.3%)] Loss: 0.031885 L1: 0.018149 Grad: 0.137077 Thermal: 0.000572 LR: 9.55e-06\n",
      "Epoch  11 [6500/10697 ( 60.8%)] Loss: 0.023959 L1: 0.014004 Grad: 0.099360 Thermal: 0.000374 LR: 9.55e-06\n",
      "Epoch  11 [6500/10697 ( 60.8%)] Loss: 0.023959 L1: 0.014004 Grad: 0.099360 Thermal: 0.000374 LR: 9.55e-06\n",
      "Epoch  11 [6550/10697 ( 61.2%)] Loss: 0.026345 L1: 0.015229 Grad: 0.110955 Thermal: 0.000411 LR: 9.55e-06\n",
      "Epoch  11 [6550/10697 ( 61.2%)] Loss: 0.026345 L1: 0.015229 Grad: 0.110955 Thermal: 0.000411 LR: 9.55e-06\n",
      "Epoch  11 [6600/10697 ( 61.7%)] Loss: 0.029817 L1: 0.017622 Grad: 0.121669 Thermal: 0.000555 LR: 9.55e-06\n",
      "Epoch  11 [6600/10697 ( 61.7%)] Loss: 0.029817 L1: 0.017622 Grad: 0.121669 Thermal: 0.000555 LR: 9.55e-06\n",
      "Epoch  11 [6650/10697 ( 62.2%)] Loss: 0.031978 L1: 0.018317 Grad: 0.136287 Thermal: 0.000646 LR: 9.55e-06\n",
      "Epoch  11 [6650/10697 ( 62.2%)] Loss: 0.031978 L1: 0.018317 Grad: 0.136287 Thermal: 0.000646 LR: 9.55e-06\n",
      "Epoch  11 [6700/10697 ( 62.6%)] Loss: 0.024612 L1: 0.014201 Grad: 0.103918 Thermal: 0.000383 LR: 9.55e-06\n",
      "Epoch  11 [6700/10697 ( 62.6%)] Loss: 0.024612 L1: 0.014201 Grad: 0.103918 Thermal: 0.000383 LR: 9.55e-06\n",
      "Epoch  11 [6750/10697 ( 63.1%)] Loss: 0.022953 L1: 0.013025 Grad: 0.099110 Thermal: 0.000340 LR: 9.55e-06\n",
      "Epoch  11 [6750/10697 ( 63.1%)] Loss: 0.022953 L1: 0.013025 Grad: 0.099110 Thermal: 0.000340 LR: 9.55e-06\n",
      "Epoch  11 [6800/10697 ( 63.6%)] Loss: 0.019608 L1: 0.011287 Grad: 0.083083 Thermal: 0.000246 LR: 9.55e-06\n",
      "Epoch  11 [6800/10697 ( 63.6%)] Loss: 0.019608 L1: 0.011287 Grad: 0.083083 Thermal: 0.000246 LR: 9.55e-06\n",
      "Epoch  11 [6850/10697 ( 64.0%)] Loss: 0.025296 L1: 0.014462 Grad: 0.108112 Thermal: 0.000457 LR: 9.55e-06\n",
      "Epoch  11 [6850/10697 ( 64.0%)] Loss: 0.025296 L1: 0.014462 Grad: 0.108112 Thermal: 0.000457 LR: 9.55e-06\n",
      "Epoch  11 [6900/10697 ( 64.5%)] Loss: 0.026293 L1: 0.015528 Grad: 0.107434 Thermal: 0.000415 LR: 9.55e-06\n",
      "Epoch  11 [6900/10697 ( 64.5%)] Loss: 0.026293 L1: 0.015528 Grad: 0.107434 Thermal: 0.000415 LR: 9.55e-06\n",
      "Epoch  11 [6950/10697 ( 65.0%)] Loss: 0.022866 L1: 0.013292 Grad: 0.095565 Thermal: 0.000349 LR: 9.55e-06\n",
      "Epoch  11 [6950/10697 ( 65.0%)] Loss: 0.022866 L1: 0.013292 Grad: 0.095565 Thermal: 0.000349 LR: 9.55e-06\n",
      "Epoch  11 [7000/10697 ( 65.4%)] Loss: 0.031578 L1: 0.018902 Grad: 0.126431 Thermal: 0.000655 LR: 9.55e-06\n",
      "Epoch  11 [7000/10697 ( 65.4%)] Loss: 0.031578 L1: 0.018902 Grad: 0.126431 Thermal: 0.000655 LR: 9.55e-06\n",
      "Epoch  11 [7050/10697 ( 65.9%)] Loss: 0.026859 L1: 0.015559 Grad: 0.112783 Thermal: 0.000427 LR: 9.55e-06\n",
      "Epoch  11 [7050/10697 ( 65.9%)] Loss: 0.026859 L1: 0.015559 Grad: 0.112783 Thermal: 0.000427 LR: 9.55e-06\n",
      "Epoch  11 [7100/10697 ( 66.4%)] Loss: 0.038129 L1: 0.021755 Grad: 0.163316 Thermal: 0.000863 LR: 9.55e-06\n",
      "Epoch  11 [7100/10697 ( 66.4%)] Loss: 0.038129 L1: 0.021755 Grad: 0.163316 Thermal: 0.000863 LR: 9.55e-06\n",
      "Epoch  11 [7150/10697 ( 66.8%)] Loss: 0.025914 L1: 0.015389 Grad: 0.105034 Thermal: 0.000435 LR: 9.55e-06\n",
      "Epoch  11 [7150/10697 ( 66.8%)] Loss: 0.025914 L1: 0.015389 Grad: 0.105034 Thermal: 0.000435 LR: 9.55e-06\n",
      "Epoch  11 [7200/10697 ( 67.3%)] Loss: 0.025940 L1: 0.014998 Grad: 0.109187 Thermal: 0.000452 LR: 9.55e-06\n",
      "Epoch  11 [7200/10697 ( 67.3%)] Loss: 0.025940 L1: 0.014998 Grad: 0.109187 Thermal: 0.000452 LR: 9.55e-06\n",
      "Epoch  11 [7250/10697 ( 67.8%)] Loss: 0.029360 L1: 0.016851 Grad: 0.124836 Thermal: 0.000526 LR: 9.55e-06\n",
      "Epoch  11 [7250/10697 ( 67.8%)] Loss: 0.029360 L1: 0.016851 Grad: 0.124836 Thermal: 0.000526 LR: 9.55e-06\n",
      "Epoch  11 [7300/10697 ( 68.2%)] Loss: 0.028442 L1: 0.016728 Grad: 0.116886 Thermal: 0.000517 LR: 9.55e-06\n",
      "Epoch  11 [7300/10697 ( 68.2%)] Loss: 0.028442 L1: 0.016728 Grad: 0.116886 Thermal: 0.000517 LR: 9.55e-06\n",
      "Epoch  11 [7350/10697 ( 68.7%)] Loss: 0.029942 L1: 0.016766 Grad: 0.131477 Thermal: 0.000567 LR: 9.55e-06\n",
      "Epoch  11 [7350/10697 ( 68.7%)] Loss: 0.029942 L1: 0.016766 Grad: 0.131477 Thermal: 0.000567 LR: 9.55e-06\n",
      "Epoch  11 [7400/10697 ( 69.2%)] Loss: 0.026754 L1: 0.015581 Grad: 0.111506 Thermal: 0.000436 LR: 9.55e-06\n",
      "Epoch  11 [7400/10697 ( 69.2%)] Loss: 0.026754 L1: 0.015581 Grad: 0.111506 Thermal: 0.000436 LR: 9.55e-06\n",
      "Epoch  11 [7450/10697 ( 69.6%)] Loss: 0.025756 L1: 0.015076 Grad: 0.106588 Thermal: 0.000428 LR: 9.55e-06\n",
      "Epoch  11 [7450/10697 ( 69.6%)] Loss: 0.025756 L1: 0.015076 Grad: 0.106588 Thermal: 0.000428 LR: 9.55e-06\n",
      "Epoch  11 [7500/10697 ( 70.1%)] Loss: 0.027288 L1: 0.016123 Grad: 0.111395 Thermal: 0.000515 LR: 9.55e-06\n",
      "Epoch  11 [7500/10697 ( 70.1%)] Loss: 0.027288 L1: 0.016123 Grad: 0.111395 Thermal: 0.000515 LR: 9.55e-06\n",
      "Epoch  11 [7550/10697 ( 70.6%)] Loss: 0.023038 L1: 0.013275 Grad: 0.097436 Thermal: 0.000391 LR: 9.55e-06\n",
      "Epoch  11 [7550/10697 ( 70.6%)] Loss: 0.023038 L1: 0.013275 Grad: 0.097436 Thermal: 0.000391 LR: 9.55e-06\n",
      "Epoch  11 [7600/10697 ( 71.0%)] Loss: 0.023048 L1: 0.013598 Grad: 0.094322 Thermal: 0.000348 LR: 9.55e-06\n",
      "Epoch  11 [7600/10697 ( 71.0%)] Loss: 0.023048 L1: 0.013598 Grad: 0.094322 Thermal: 0.000348 LR: 9.55e-06\n",
      "Epoch  11 [7650/10697 ( 71.5%)] Loss: 0.025335 L1: 0.015107 Grad: 0.102070 Thermal: 0.000423 LR: 9.55e-06\n",
      "Epoch  11 [7650/10697 ( 71.5%)] Loss: 0.025335 L1: 0.015107 Grad: 0.102070 Thermal: 0.000423 LR: 9.55e-06\n",
      "Epoch  11 [7700/10697 ( 72.0%)] Loss: 0.029097 L1: 0.016978 Grad: 0.120923 Thermal: 0.000524 LR: 9.55e-06\n",
      "Epoch  11 [7700/10697 ( 72.0%)] Loss: 0.029097 L1: 0.016978 Grad: 0.120923 Thermal: 0.000524 LR: 9.55e-06\n",
      "Epoch  11 [7750/10697 ( 72.5%)] Loss: 0.021356 L1: 0.012481 Grad: 0.088586 Thermal: 0.000325 LR: 9.55e-06\n",
      "Epoch  11 [7750/10697 ( 72.5%)] Loss: 0.021356 L1: 0.012481 Grad: 0.088586 Thermal: 0.000325 LR: 9.55e-06\n",
      "Epoch  11 [7800/10697 ( 72.9%)] Loss: 0.021911 L1: 0.012907 Grad: 0.089869 Thermal: 0.000335 LR: 9.55e-06\n",
      "Epoch  11 [7800/10697 ( 72.9%)] Loss: 0.021911 L1: 0.012907 Grad: 0.089869 Thermal: 0.000335 LR: 9.55e-06\n",
      "Epoch  11 [7850/10697 ( 73.4%)] Loss: 0.028905 L1: 0.016722 Grad: 0.121547 Thermal: 0.000562 LR: 9.55e-06\n",
      "Epoch  11 [7850/10697 ( 73.4%)] Loss: 0.028905 L1: 0.016722 Grad: 0.121547 Thermal: 0.000562 LR: 9.55e-06\n",
      "Epoch  11 [7900/10697 ( 73.9%)] Loss: 0.027640 L1: 0.016253 Grad: 0.113649 Thermal: 0.000458 LR: 9.55e-06\n",
      "Epoch  11 [7900/10697 ( 73.9%)] Loss: 0.027640 L1: 0.016253 Grad: 0.113649 Thermal: 0.000458 LR: 9.55e-06\n",
      "Epoch  11 [7950/10697 ( 74.3%)] Loss: 0.029267 L1: 0.016843 Grad: 0.123931 Thermal: 0.000625 LR: 9.55e-06\n",
      "Epoch  11 [7950/10697 ( 74.3%)] Loss: 0.029267 L1: 0.016843 Grad: 0.123931 Thermal: 0.000625 LR: 9.55e-06\n",
      "Epoch  11 [8000/10697 ( 74.8%)] Loss: 0.027893 L1: 0.016203 Grad: 0.116677 Thermal: 0.000459 LR: 9.55e-06\n",
      "Epoch  11 [8000/10697 ( 74.8%)] Loss: 0.027893 L1: 0.016203 Grad: 0.116677 Thermal: 0.000459 LR: 9.55e-06\n",
      "Epoch  11 [8050/10697 ( 75.3%)] Loss: 0.027113 L1: 0.016015 Grad: 0.110754 Thermal: 0.000451 LR: 9.55e-06\n",
      "Epoch  11 [8050/10697 ( 75.3%)] Loss: 0.027113 L1: 0.016015 Grad: 0.110754 Thermal: 0.000451 LR: 9.55e-06\n",
      "Epoch  11 [8100/10697 ( 75.7%)] Loss: 0.022844 L1: 0.013202 Grad: 0.096245 Thermal: 0.000352 LR: 9.55e-06\n",
      "Epoch  11 [8100/10697 ( 75.7%)] Loss: 0.022844 L1: 0.013202 Grad: 0.096245 Thermal: 0.000352 LR: 9.55e-06\n",
      "Epoch  11 [8150/10697 ( 76.2%)] Loss: 0.026564 L1: 0.015992 Grad: 0.105486 Thermal: 0.000473 LR: 9.55e-06\n",
      "Epoch  11 [8150/10697 ( 76.2%)] Loss: 0.026564 L1: 0.015992 Grad: 0.105486 Thermal: 0.000473 LR: 9.55e-06\n",
      "Epoch  11 [8200/10697 ( 76.7%)] Loss: 0.027619 L1: 0.015803 Grad: 0.117915 Thermal: 0.000490 LR: 9.55e-06\n",
      "Epoch  11 [8200/10697 ( 76.7%)] Loss: 0.027619 L1: 0.015803 Grad: 0.117915 Thermal: 0.000490 LR: 9.55e-06\n",
      "Epoch  11 [8250/10697 ( 77.1%)] Loss: 0.029658 L1: 0.017702 Grad: 0.119293 Thermal: 0.000538 LR: 9.55e-06\n",
      "Epoch  11 [8250/10697 ( 77.1%)] Loss: 0.029658 L1: 0.017702 Grad: 0.119293 Thermal: 0.000538 LR: 9.55e-06\n",
      "Epoch  11 [8300/10697 ( 77.6%)] Loss: 0.024679 L1: 0.014954 Grad: 0.097045 Thermal: 0.000405 LR: 9.55e-06\n",
      "Epoch  11 [8300/10697 ( 77.6%)] Loss: 0.024679 L1: 0.014954 Grad: 0.097045 Thermal: 0.000405 LR: 9.55e-06\n",
      "Epoch  11 [8350/10697 ( 78.1%)] Loss: 0.027202 L1: 0.015530 Grad: 0.116465 Thermal: 0.000517 LR: 9.55e-06\n",
      "Epoch  11 [8350/10697 ( 78.1%)] Loss: 0.027202 L1: 0.015530 Grad: 0.116465 Thermal: 0.000517 LR: 9.55e-06\n",
      "Epoch  11 [8400/10697 ( 78.5%)] Loss: 0.024346 L1: 0.014183 Grad: 0.101431 Thermal: 0.000392 LR: 9.55e-06\n",
      "Epoch  11 [8400/10697 ( 78.5%)] Loss: 0.024346 L1: 0.014183 Grad: 0.101431 Thermal: 0.000392 LR: 9.55e-06\n",
      "Epoch  11 [8450/10697 ( 79.0%)] Loss: 0.026820 L1: 0.015382 Grad: 0.114153 Thermal: 0.000442 LR: 9.55e-06\n",
      "Epoch  11 [8450/10697 ( 79.0%)] Loss: 0.026820 L1: 0.015382 Grad: 0.114153 Thermal: 0.000442 LR: 9.55e-06\n",
      "Epoch  11 [8500/10697 ( 79.5%)] Loss: 0.024094 L1: 0.014221 Grad: 0.098542 Thermal: 0.000372 LR: 9.55e-06\n",
      "Epoch  11 [8500/10697 ( 79.5%)] Loss: 0.024094 L1: 0.014221 Grad: 0.098542 Thermal: 0.000372 LR: 9.55e-06\n",
      "Epoch  11 [8550/10697 ( 79.9%)] Loss: 0.027953 L1: 0.016515 Grad: 0.114122 Thermal: 0.000512 LR: 9.55e-06\n",
      "Epoch  11 [8550/10697 ( 79.9%)] Loss: 0.027953 L1: 0.016515 Grad: 0.114122 Thermal: 0.000512 LR: 9.55e-06\n",
      "Epoch  11 [8600/10697 ( 80.4%)] Loss: 0.024649 L1: 0.014474 Grad: 0.101546 Thermal: 0.000398 LR: 9.55e-06\n",
      "Epoch  11 [8600/10697 ( 80.4%)] Loss: 0.024649 L1: 0.014474 Grad: 0.101546 Thermal: 0.000398 LR: 9.55e-06\n",
      "Epoch  11 [8650/10697 ( 80.9%)] Loss: 0.026705 L1: 0.015961 Grad: 0.107207 Thermal: 0.000473 LR: 9.55e-06\n",
      "Epoch  11 [8650/10697 ( 80.9%)] Loss: 0.026705 L1: 0.015961 Grad: 0.107207 Thermal: 0.000473 LR: 9.55e-06\n",
      "Epoch  11 [8700/10697 ( 81.3%)] Loss: 0.029401 L1: 0.017392 Grad: 0.119785 Thermal: 0.000600 LR: 9.55e-06\n",
      "Epoch  11 [8700/10697 ( 81.3%)] Loss: 0.029401 L1: 0.017392 Grad: 0.119785 Thermal: 0.000600 LR: 9.55e-06\n",
      "Epoch  11 [8750/10697 ( 81.8%)] Loss: 0.026943 L1: 0.015300 Grad: 0.116178 Thermal: 0.000495 LR: 9.55e-06\n",
      "Epoch  11 [8750/10697 ( 81.8%)] Loss: 0.026943 L1: 0.015300 Grad: 0.116178 Thermal: 0.000495 LR: 9.55e-06\n",
      "Epoch  11 [8800/10697 ( 82.3%)] Loss: 0.028123 L1: 0.016474 Grad: 0.116223 Thermal: 0.000519 LR: 9.55e-06\n",
      "Epoch  11 [8800/10697 ( 82.3%)] Loss: 0.028123 L1: 0.016474 Grad: 0.116223 Thermal: 0.000519 LR: 9.55e-06\n",
      "Epoch  11 [8850/10697 ( 82.7%)] Loss: 0.024838 L1: 0.014644 Grad: 0.101742 Thermal: 0.000413 LR: 9.55e-06\n",
      "Epoch  11 [8850/10697 ( 82.7%)] Loss: 0.024838 L1: 0.014644 Grad: 0.101742 Thermal: 0.000413 LR: 9.55e-06\n",
      "Epoch  11 [8900/10697 ( 83.2%)] Loss: 0.026596 L1: 0.015476 Grad: 0.110967 Thermal: 0.000468 LR: 9.55e-06\n",
      "Epoch  11 [8900/10697 ( 83.2%)] Loss: 0.026596 L1: 0.015476 Grad: 0.110967 Thermal: 0.000468 LR: 9.55e-06\n",
      "Epoch  11 [8950/10697 ( 83.7%)] Loss: 0.025777 L1: 0.015373 Grad: 0.103826 Thermal: 0.000435 LR: 9.55e-06\n",
      "Epoch  11 [8950/10697 ( 83.7%)] Loss: 0.025777 L1: 0.015373 Grad: 0.103826 Thermal: 0.000435 LR: 9.55e-06\n",
      "Epoch  11 [9000/10697 ( 84.1%)] Loss: 0.027255 L1: 0.015926 Grad: 0.113050 Thermal: 0.000483 LR: 9.55e-06\n",
      "Epoch  11 [9000/10697 ( 84.1%)] Loss: 0.027255 L1: 0.015926 Grad: 0.113050 Thermal: 0.000483 LR: 9.55e-06\n",
      "Epoch  11 [9050/10697 ( 84.6%)] Loss: 0.021538 L1: 0.012365 Grad: 0.091579 Thermal: 0.000301 LR: 9.55e-06\n",
      "Epoch  11 [9050/10697 ( 84.6%)] Loss: 0.021538 L1: 0.012365 Grad: 0.091579 Thermal: 0.000301 LR: 9.55e-06\n",
      "Epoch  11 [9100/10697 ( 85.1%)] Loss: 0.019474 L1: 0.010963 Grad: 0.084953 Thermal: 0.000306 LR: 9.55e-06\n",
      "Epoch  11 [9100/10697 ( 85.1%)] Loss: 0.019474 L1: 0.010963 Grad: 0.084953 Thermal: 0.000306 LR: 9.55e-06\n",
      "Epoch  11 [9150/10697 ( 85.5%)] Loss: 0.024246 L1: 0.014056 Grad: 0.101698 Thermal: 0.000403 LR: 9.55e-06\n",
      "Epoch  11 [9150/10697 ( 85.5%)] Loss: 0.024246 L1: 0.014056 Grad: 0.101698 Thermal: 0.000403 LR: 9.55e-06\n",
      "Epoch  11 [9200/10697 ( 86.0%)] Loss: 0.034145 L1: 0.019389 Grad: 0.147212 Thermal: 0.000695 LR: 9.55e-06\n",
      "Epoch  11 [9200/10697 ( 86.0%)] Loss: 0.034145 L1: 0.019389 Grad: 0.147212 Thermal: 0.000695 LR: 9.55e-06\n",
      "Epoch  11 [9250/10697 ( 86.5%)] Loss: 0.018834 L1: 0.010412 Grad: 0.084111 Thermal: 0.000207 LR: 9.55e-06\n",
      "Epoch  11 [9250/10697 ( 86.5%)] Loss: 0.018834 L1: 0.010412 Grad: 0.084111 Thermal: 0.000207 LR: 9.55e-06\n",
      "Epoch  11 [9300/10697 ( 86.9%)] Loss: 0.025116 L1: 0.014573 Grad: 0.105227 Thermal: 0.000397 LR: 9.55e-06\n",
      "Epoch  11 [9300/10697 ( 86.9%)] Loss: 0.025116 L1: 0.014573 Grad: 0.105227 Thermal: 0.000397 LR: 9.55e-06\n",
      "Epoch  11 [9350/10697 ( 87.4%)] Loss: 0.024972 L1: 0.014572 Grad: 0.103792 Thermal: 0.000403 LR: 9.55e-06\n",
      "Epoch  11 [9350/10697 ( 87.4%)] Loss: 0.024972 L1: 0.014572 Grad: 0.103792 Thermal: 0.000403 LR: 9.55e-06\n",
      "Epoch  11 [9400/10697 ( 87.9%)] Loss: 0.028458 L1: 0.016884 Grad: 0.115487 Thermal: 0.000519 LR: 9.55e-06\n",
      "Epoch  11 [9400/10697 ( 87.9%)] Loss: 0.028458 L1: 0.016884 Grad: 0.115487 Thermal: 0.000519 LR: 9.55e-06\n",
      "Epoch  11 [9450/10697 ( 88.3%)] Loss: 0.022769 L1: 0.013017 Grad: 0.097349 Thermal: 0.000339 LR: 9.55e-06\n",
      "Epoch  11 [9450/10697 ( 88.3%)] Loss: 0.022769 L1: 0.013017 Grad: 0.097349 Thermal: 0.000339 LR: 9.55e-06\n",
      "Epoch  11 [9500/10697 ( 88.8%)] Loss: 0.024153 L1: 0.014267 Grad: 0.098667 Thermal: 0.000378 LR: 9.55e-06\n",
      "Epoch  11 [9500/10697 ( 88.8%)] Loss: 0.024153 L1: 0.014267 Grad: 0.098667 Thermal: 0.000378 LR: 9.55e-06\n",
      "Epoch  11 [9550/10697 ( 89.3%)] Loss: 0.032206 L1: 0.018955 Grad: 0.132192 Thermal: 0.000627 LR: 9.55e-06\n",
      "Epoch  11 [9550/10697 ( 89.3%)] Loss: 0.032206 L1: 0.018955 Grad: 0.132192 Thermal: 0.000627 LR: 9.55e-06\n",
      "Epoch  11 [9600/10697 ( 89.7%)] Loss: 0.022677 L1: 0.012916 Grad: 0.097437 Thermal: 0.000362 LR: 9.55e-06\n",
      "Epoch  11 [9600/10697 ( 89.7%)] Loss: 0.022677 L1: 0.012916 Grad: 0.097437 Thermal: 0.000362 LR: 9.55e-06\n",
      "Epoch  11 [9650/10697 ( 90.2%)] Loss: 0.032367 L1: 0.018646 Grad: 0.136896 Thermal: 0.000610 LR: 9.55e-06\n",
      "Epoch  11 [9650/10697 ( 90.2%)] Loss: 0.032367 L1: 0.018646 Grad: 0.136896 Thermal: 0.000610 LR: 9.55e-06\n",
      "Epoch  11 [9700/10697 ( 90.7%)] Loss: 0.026117 L1: 0.015080 Grad: 0.110170 Thermal: 0.000399 LR: 9.55e-06\n",
      "Epoch  11 [9700/10697 ( 90.7%)] Loss: 0.026117 L1: 0.015080 Grad: 0.110170 Thermal: 0.000399 LR: 9.55e-06\n",
      "Epoch  11 [9750/10697 ( 91.1%)] Loss: 0.025841 L1: 0.015078 Grad: 0.107431 Thermal: 0.000406 LR: 9.55e-06\n",
      "Epoch  11 [9750/10697 ( 91.1%)] Loss: 0.025841 L1: 0.015078 Grad: 0.107431 Thermal: 0.000406 LR: 9.55e-06\n",
      "Epoch  11 [9800/10697 ( 91.6%)] Loss: 0.028078 L1: 0.016242 Grad: 0.118093 Thermal: 0.000522 LR: 9.55e-06\n",
      "Epoch  11 [9800/10697 ( 91.6%)] Loss: 0.028078 L1: 0.016242 Grad: 0.118093 Thermal: 0.000522 LR: 9.55e-06\n",
      "Epoch  11 [9850/10697 ( 92.1%)] Loss: 0.025319 L1: 0.014583 Grad: 0.107166 Thermal: 0.000387 LR: 9.55e-06\n",
      "Epoch  11 [9850/10697 ( 92.1%)] Loss: 0.025319 L1: 0.014583 Grad: 0.107166 Thermal: 0.000387 LR: 9.55e-06\n",
      "Epoch  11 [9900/10697 ( 92.5%)] Loss: 0.029164 L1: 0.016740 Grad: 0.123982 Thermal: 0.000535 LR: 9.55e-06\n",
      "Epoch  11 [9900/10697 ( 92.5%)] Loss: 0.029164 L1: 0.016740 Grad: 0.123982 Thermal: 0.000535 LR: 9.55e-06\n",
      "Epoch  11 [9950/10697 ( 93.0%)] Loss: 0.024460 L1: 0.013644 Grad: 0.107933 Thermal: 0.000459 LR: 9.55e-06\n",
      "Epoch  11 [9950/10697 ( 93.0%)] Loss: 0.024460 L1: 0.013644 Grad: 0.107933 Thermal: 0.000459 LR: 9.55e-06\n",
      "Epoch  11 [10000/10697 ( 93.5%)] Loss: 0.028328 L1: 0.016715 Grad: 0.115868 Thermal: 0.000525 LR: 9.55e-06\n",
      "Epoch  11 [10000/10697 ( 93.5%)] Loss: 0.028328 L1: 0.016715 Grad: 0.115868 Thermal: 0.000525 LR: 9.55e-06\n",
      "Epoch  11 [10050/10697 ( 94.0%)] Loss: 0.026315 L1: 0.015373 Grad: 0.109202 Thermal: 0.000434 LR: 9.55e-06\n",
      "Epoch  11 [10050/10697 ( 94.0%)] Loss: 0.026315 L1: 0.015373 Grad: 0.109202 Thermal: 0.000434 LR: 9.55e-06\n",
      "Epoch  11 [10100/10697 ( 94.4%)] Loss: 0.033958 L1: 0.019849 Grad: 0.140666 Thermal: 0.000840 LR: 9.55e-06\n",
      "Epoch  11 [10100/10697 ( 94.4%)] Loss: 0.033958 L1: 0.019849 Grad: 0.140666 Thermal: 0.000840 LR: 9.55e-06\n",
      "Epoch  11 [10150/10697 ( 94.9%)] Loss: 0.028295 L1: 0.015773 Grad: 0.124996 Thermal: 0.000449 LR: 9.55e-06\n",
      "Epoch  11 [10150/10697 ( 94.9%)] Loss: 0.028295 L1: 0.015773 Grad: 0.124996 Thermal: 0.000449 LR: 9.55e-06\n",
      "Epoch  11 [10200/10697 ( 95.4%)] Loss: 0.025260 L1: 0.014792 Grad: 0.104471 Thermal: 0.000417 LR: 9.55e-06\n",
      "Epoch  11 [10200/10697 ( 95.4%)] Loss: 0.025260 L1: 0.014792 Grad: 0.104471 Thermal: 0.000417 LR: 9.55e-06\n",
      "Epoch  11 [10250/10697 ( 95.8%)] Loss: 0.027755 L1: 0.016043 Grad: 0.116869 Thermal: 0.000486 LR: 9.55e-06\n",
      "Epoch  11 [10250/10697 ( 95.8%)] Loss: 0.027755 L1: 0.016043 Grad: 0.116869 Thermal: 0.000486 LR: 9.55e-06\n",
      "Epoch  11 [10300/10697 ( 96.3%)] Loss: 0.027461 L1: 0.016068 Grad: 0.113654 Thermal: 0.000551 LR: 9.55e-06\n",
      "Epoch  11 [10300/10697 ( 96.3%)] Loss: 0.027461 L1: 0.016068 Grad: 0.113654 Thermal: 0.000551 LR: 9.55e-06\n",
      "Epoch  11 [10350/10697 ( 96.8%)] Loss: 0.025297 L1: 0.014910 Grad: 0.103679 Thermal: 0.000398 LR: 9.55e-06\n",
      "Epoch  11 [10350/10697 ( 96.8%)] Loss: 0.025297 L1: 0.014910 Grad: 0.103679 Thermal: 0.000398 LR: 9.55e-06\n",
      "Epoch  11 [10400/10697 ( 97.2%)] Loss: 0.025226 L1: 0.014862 Grad: 0.103394 Thermal: 0.000481 LR: 9.55e-06\n",
      "Epoch  11 [10400/10697 ( 97.2%)] Loss: 0.025226 L1: 0.014862 Grad: 0.103394 Thermal: 0.000481 LR: 9.55e-06\n",
      "Epoch  11 [10450/10697 ( 97.7%)] Loss: 0.030431 L1: 0.017802 Grad: 0.125997 Thermal: 0.000573 LR: 9.55e-06\n",
      "Epoch  11 [10450/10697 ( 97.7%)] Loss: 0.030431 L1: 0.017802 Grad: 0.125997 Thermal: 0.000573 LR: 9.55e-06\n",
      "Epoch  11 [10500/10697 ( 98.2%)] Loss: 0.023231 L1: 0.013034 Grad: 0.101785 Thermal: 0.000375 LR: 9.55e-06\n",
      "Epoch  11 [10500/10697 ( 98.2%)] Loss: 0.023231 L1: 0.013034 Grad: 0.101785 Thermal: 0.000375 LR: 9.55e-06\n",
      "Epoch  11 [10550/10697 ( 98.6%)] Loss: 0.026520 L1: 0.015553 Grad: 0.109449 Thermal: 0.000447 LR: 9.55e-06\n",
      "Epoch  11 [10550/10697 ( 98.6%)] Loss: 0.026520 L1: 0.015553 Grad: 0.109449 Thermal: 0.000447 LR: 9.55e-06\n",
      "Epoch  11 [10600/10697 ( 99.1%)] Loss: 0.024979 L1: 0.015042 Grad: 0.099163 Thermal: 0.000425 LR: 9.55e-06\n",
      "Epoch  11 [10600/10697 ( 99.1%)] Loss: 0.024979 L1: 0.015042 Grad: 0.099163 Thermal: 0.000425 LR: 9.55e-06\n",
      "Epoch  11 [10650/10697 ( 99.6%)] Loss: 0.024873 L1: 0.014237 Grad: 0.106173 Thermal: 0.000371 LR: 9.55e-06\n",
      "Epoch  11 [10650/10697 ( 99.6%)] Loss: 0.024873 L1: 0.014237 Grad: 0.106173 Thermal: 0.000371 LR: 9.55e-06\n",
      "Epoch  11 Summary: Loss=0.026730 (L1:0.0156, Grad:0.1114, Thermal:0.0005) Val_PSNR=0.00dB Best=33.82dB Time=43.1min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  11 Summary: Loss=0.026730 (L1:0.0156, Grad:0.1114, Thermal:0.0005) Val_PSNR=0.00dB Best=33.82dB Time=43.1min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  12 [   0/10697 (  0.0%)] Loss: 0.026281 L1: 0.015623 Grad: 0.106360 Thermal: 0.000441 LR: 9.46e-06\n",
      "Epoch  12 [   0/10697 (  0.0%)] Loss: 0.026281 L1: 0.015623 Grad: 0.106360 Thermal: 0.000441 LR: 9.46e-06\n",
      "Epoch  12 [  50/10697 (  0.5%)] Loss: 0.024741 L1: 0.014266 Grad: 0.104504 Thermal: 0.000483 LR: 9.46e-06\n",
      "Epoch  12 [  50/10697 (  0.5%)] Loss: 0.024741 L1: 0.014266 Grad: 0.104504 Thermal: 0.000483 LR: 9.46e-06\n",
      "Epoch  12 [ 100/10697 (  0.9%)] Loss: 0.026132 L1: 0.015238 Grad: 0.108705 Thermal: 0.000455 LR: 9.46e-06\n",
      "Epoch  12 [ 100/10697 (  0.9%)] Loss: 0.026132 L1: 0.015238 Grad: 0.108705 Thermal: 0.000455 LR: 9.46e-06\n",
      "Epoch  12 [ 150/10697 (  1.4%)] Loss: 0.027094 L1: 0.015785 Grad: 0.112840 Thermal: 0.000506 LR: 9.46e-06\n",
      "Epoch  12 [ 150/10697 (  1.4%)] Loss: 0.027094 L1: 0.015785 Grad: 0.112840 Thermal: 0.000506 LR: 9.46e-06\n",
      "Epoch  12 [ 200/10697 (  1.9%)] Loss: 0.026068 L1: 0.015474 Grad: 0.105727 Thermal: 0.000431 LR: 9.46e-06\n",
      "Epoch  12 [ 200/10697 (  1.9%)] Loss: 0.026068 L1: 0.015474 Grad: 0.105727 Thermal: 0.000431 LR: 9.46e-06\n",
      "Epoch  12 [ 250/10697 (  2.3%)] Loss: 0.021360 L1: 0.012787 Grad: 0.085555 Thermal: 0.000352 LR: 9.46e-06\n",
      "Epoch  12 [ 250/10697 (  2.3%)] Loss: 0.021360 L1: 0.012787 Grad: 0.085555 Thermal: 0.000352 LR: 9.46e-06\n",
      "Epoch  12 [ 300/10697 (  2.8%)] Loss: 0.022223 L1: 0.012958 Grad: 0.092483 Thermal: 0.000324 LR: 9.46e-06\n",
      "Epoch  12 [ 300/10697 (  2.8%)] Loss: 0.022223 L1: 0.012958 Grad: 0.092483 Thermal: 0.000324 LR: 9.46e-06\n",
      "Epoch  12 [ 350/10697 (  3.3%)] Loss: 0.026657 L1: 0.015796 Grad: 0.108384 Thermal: 0.000450 LR: 9.46e-06\n",
      "Epoch  12 [ 350/10697 (  3.3%)] Loss: 0.026657 L1: 0.015796 Grad: 0.108384 Thermal: 0.000450 LR: 9.46e-06\n",
      "Epoch  12 [ 400/10697 (  3.7%)] Loss: 0.023511 L1: 0.013787 Grad: 0.097062 Thermal: 0.000350 LR: 9.46e-06\n",
      "Epoch  12 [ 400/10697 (  3.7%)] Loss: 0.023511 L1: 0.013787 Grad: 0.097062 Thermal: 0.000350 LR: 9.46e-06\n",
      "Epoch  12 [ 450/10697 (  4.2%)] Loss: 0.026616 L1: 0.015478 Grad: 0.111159 Thermal: 0.000440 LR: 9.46e-06\n",
      "Epoch  12 [ 450/10697 (  4.2%)] Loss: 0.026616 L1: 0.015478 Grad: 0.111159 Thermal: 0.000440 LR: 9.46e-06\n",
      "Epoch  12 [ 500/10697 (  4.7%)] Loss: 0.028189 L1: 0.015831 Grad: 0.123357 Thermal: 0.000445 LR: 9.46e-06\n",
      "Epoch  12 [ 500/10697 (  4.7%)] Loss: 0.028189 L1: 0.015831 Grad: 0.123357 Thermal: 0.000445 LR: 9.46e-06\n",
      "Epoch  12 [ 550/10697 (  5.1%)] Loss: 0.024819 L1: 0.014945 Grad: 0.098551 Thermal: 0.000395 LR: 9.46e-06\n",
      "Epoch  12 [ 550/10697 (  5.1%)] Loss: 0.024819 L1: 0.014945 Grad: 0.098551 Thermal: 0.000395 LR: 9.46e-06\n",
      "Epoch  12 [ 600/10697 (  5.6%)] Loss: 0.027973 L1: 0.016293 Grad: 0.116523 Thermal: 0.000545 LR: 9.46e-06\n",
      "Epoch  12 [ 600/10697 (  5.6%)] Loss: 0.027973 L1: 0.016293 Grad: 0.116523 Thermal: 0.000545 LR: 9.46e-06\n",
      "Epoch  12 [ 650/10697 (  6.1%)] Loss: 0.026514 L1: 0.015515 Grad: 0.109780 Thermal: 0.000429 LR: 9.46e-06\n",
      "Epoch  12 [ 650/10697 (  6.1%)] Loss: 0.026514 L1: 0.015515 Grad: 0.109780 Thermal: 0.000429 LR: 9.46e-06\n",
      "Epoch  12 [ 700/10697 (  6.5%)] Loss: 0.027933 L1: 0.016444 Grad: 0.114663 Thermal: 0.000463 LR: 9.46e-06\n",
      "Epoch  12 [ 700/10697 (  6.5%)] Loss: 0.027933 L1: 0.016444 Grad: 0.114663 Thermal: 0.000463 LR: 9.46e-06\n",
      "Epoch  12 [ 750/10697 (  7.0%)] Loss: 0.025583 L1: 0.015002 Grad: 0.105611 Thermal: 0.000404 LR: 9.46e-06\n",
      "Epoch  12 [ 750/10697 (  7.0%)] Loss: 0.025583 L1: 0.015002 Grad: 0.105611 Thermal: 0.000404 LR: 9.46e-06\n",
      "Epoch  12 [ 800/10697 (  7.5%)] Loss: 0.024011 L1: 0.014225 Grad: 0.097684 Thermal: 0.000352 LR: 9.46e-06\n",
      "Epoch  12 [ 800/10697 (  7.5%)] Loss: 0.024011 L1: 0.014225 Grad: 0.097684 Thermal: 0.000352 LR: 9.46e-06\n",
      "Epoch  12 [ 850/10697 (  7.9%)] Loss: 0.028053 L1: 0.016399 Grad: 0.116292 Thermal: 0.000501 LR: 9.46e-06\n",
      "Epoch  12 [ 850/10697 (  7.9%)] Loss: 0.028053 L1: 0.016399 Grad: 0.116292 Thermal: 0.000501 LR: 9.46e-06\n",
      "Epoch  12 [ 900/10697 (  8.4%)] Loss: 0.028059 L1: 0.016488 Grad: 0.115477 Thermal: 0.000468 LR: 9.46e-06\n",
      "Epoch  12 [ 900/10697 (  8.4%)] Loss: 0.028059 L1: 0.016488 Grad: 0.115477 Thermal: 0.000468 LR: 9.46e-06\n",
      "Epoch  12 [ 950/10697 (  8.9%)] Loss: 0.028659 L1: 0.016608 Grad: 0.120252 Thermal: 0.000521 LR: 9.46e-06\n",
      "Epoch  12 [ 950/10697 (  8.9%)] Loss: 0.028659 L1: 0.016608 Grad: 0.120252 Thermal: 0.000521 LR: 9.46e-06\n",
      "Epoch  12 [1000/10697 (  9.3%)] Loss: 0.026535 L1: 0.015320 Grad: 0.111929 Thermal: 0.000453 LR: 9.46e-06\n",
      "Epoch  12 [1000/10697 (  9.3%)] Loss: 0.026535 L1: 0.015320 Grad: 0.111929 Thermal: 0.000453 LR: 9.46e-06\n",
      "Epoch  12 [1050/10697 (  9.8%)] Loss: 0.032048 L1: 0.018649 Grad: 0.133658 Thermal: 0.000655 LR: 9.46e-06\n",
      "Epoch  12 [1050/10697 (  9.8%)] Loss: 0.032048 L1: 0.018649 Grad: 0.133658 Thermal: 0.000655 LR: 9.46e-06\n",
      "Epoch  12 [1100/10697 ( 10.3%)] Loss: 0.024601 L1: 0.014724 Grad: 0.098560 Thermal: 0.000408 LR: 9.46e-06\n",
      "Epoch  12 [1100/10697 ( 10.3%)] Loss: 0.024601 L1: 0.014724 Grad: 0.098560 Thermal: 0.000408 LR: 9.46e-06\n",
      "Epoch  12 [1150/10697 ( 10.8%)] Loss: 0.026629 L1: 0.016038 Grad: 0.105678 Thermal: 0.000464 LR: 9.46e-06\n",
      "Epoch  12 [1150/10697 ( 10.8%)] Loss: 0.026629 L1: 0.016038 Grad: 0.105678 Thermal: 0.000464 LR: 9.46e-06\n",
      "Epoch  12 [1200/10697 ( 11.2%)] Loss: 0.029944 L1: 0.017778 Grad: 0.121365 Thermal: 0.000600 LR: 9.46e-06\n",
      "Epoch  12 [1200/10697 ( 11.2%)] Loss: 0.029944 L1: 0.017778 Grad: 0.121365 Thermal: 0.000600 LR: 9.46e-06\n",
      "Epoch  12 [1250/10697 ( 11.7%)] Loss: 0.029957 L1: 0.017438 Grad: 0.124905 Thermal: 0.000571 LR: 9.46e-06\n",
      "Epoch  12 [1250/10697 ( 11.7%)] Loss: 0.029957 L1: 0.017438 Grad: 0.124905 Thermal: 0.000571 LR: 9.46e-06\n",
      "Epoch  12 [1300/10697 ( 12.2%)] Loss: 0.021856 L1: 0.012794 Grad: 0.090457 Thermal: 0.000319 LR: 9.46e-06\n",
      "Epoch  12 [1300/10697 ( 12.2%)] Loss: 0.021856 L1: 0.012794 Grad: 0.090457 Thermal: 0.000319 LR: 9.46e-06\n",
      "Epoch  12 [1350/10697 ( 12.6%)] Loss: 0.023024 L1: 0.013125 Grad: 0.098816 Thermal: 0.000351 LR: 9.46e-06\n",
      "Epoch  12 [1350/10697 ( 12.6%)] Loss: 0.023024 L1: 0.013125 Grad: 0.098816 Thermal: 0.000351 LR: 9.46e-06\n",
      "Epoch  12 [1400/10697 ( 13.1%)] Loss: 0.027283 L1: 0.016396 Grad: 0.108646 Thermal: 0.000460 LR: 9.46e-06\n",
      "Epoch  12 [1400/10697 ( 13.1%)] Loss: 0.027283 L1: 0.016396 Grad: 0.108646 Thermal: 0.000460 LR: 9.46e-06\n",
      "Epoch  12 [1450/10697 ( 13.6%)] Loss: 0.033781 L1: 0.018748 Grad: 0.149971 Thermal: 0.000706 LR: 9.46e-06\n",
      "Epoch  12 [1450/10697 ( 13.6%)] Loss: 0.033781 L1: 0.018748 Grad: 0.149971 Thermal: 0.000706 LR: 9.46e-06\n",
      "Epoch  12 [1500/10697 ( 14.0%)] Loss: 0.026998 L1: 0.015487 Grad: 0.114842 Thermal: 0.000548 LR: 9.46e-06\n",
      "Epoch  12 [1500/10697 ( 14.0%)] Loss: 0.026998 L1: 0.015487 Grad: 0.114842 Thermal: 0.000548 LR: 9.46e-06\n",
      "Epoch  12 [1550/10697 ( 14.5%)] Loss: 0.026207 L1: 0.015065 Grad: 0.111215 Thermal: 0.000411 LR: 9.46e-06\n",
      "Epoch  12 [1550/10697 ( 14.5%)] Loss: 0.026207 L1: 0.015065 Grad: 0.111215 Thermal: 0.000411 LR: 9.46e-06\n",
      "Epoch  12 [1600/10697 ( 15.0%)] Loss: 0.028773 L1: 0.017136 Grad: 0.116114 Thermal: 0.000515 LR: 9.46e-06\n",
      "Epoch  12 [1600/10697 ( 15.0%)] Loss: 0.028773 L1: 0.017136 Grad: 0.116114 Thermal: 0.000515 LR: 9.46e-06\n",
      "Epoch  12 [1650/10697 ( 15.4%)] Loss: 0.026643 L1: 0.015350 Grad: 0.112712 Thermal: 0.000427 LR: 9.46e-06\n",
      "Epoch  12 [1650/10697 ( 15.4%)] Loss: 0.026643 L1: 0.015350 Grad: 0.112712 Thermal: 0.000427 LR: 9.46e-06\n",
      "Epoch  12 [1700/10697 ( 15.9%)] Loss: 0.026701 L1: 0.015921 Grad: 0.107570 Thermal: 0.000470 LR: 9.46e-06\n",
      "Epoch  12 [1700/10697 ( 15.9%)] Loss: 0.026701 L1: 0.015921 Grad: 0.107570 Thermal: 0.000470 LR: 9.46e-06\n",
      "Epoch  12 [1750/10697 ( 16.4%)] Loss: 0.022247 L1: 0.012744 Grad: 0.094867 Thermal: 0.000332 LR: 9.46e-06\n",
      "Epoch  12 [1750/10697 ( 16.4%)] Loss: 0.022247 L1: 0.012744 Grad: 0.094867 Thermal: 0.000332 LR: 9.46e-06\n",
      "Epoch  12 [1800/10697 ( 16.8%)] Loss: 0.026763 L1: 0.015734 Grad: 0.110077 Thermal: 0.000435 LR: 9.46e-06\n",
      "Epoch  12 [1800/10697 ( 16.8%)] Loss: 0.026763 L1: 0.015734 Grad: 0.110077 Thermal: 0.000435 LR: 9.46e-06\n",
      "Epoch  12 [1850/10697 ( 17.3%)] Loss: 0.027525 L1: 0.016140 Grad: 0.113612 Thermal: 0.000475 LR: 9.46e-06\n",
      "Epoch  12 [1850/10697 ( 17.3%)] Loss: 0.027525 L1: 0.016140 Grad: 0.113612 Thermal: 0.000475 LR: 9.46e-06\n",
      "Epoch  12 [1900/10697 ( 17.8%)] Loss: 0.027675 L1: 0.016016 Grad: 0.116326 Thermal: 0.000520 LR: 9.46e-06\n",
      "Epoch  12 [1900/10697 ( 17.8%)] Loss: 0.027675 L1: 0.016016 Grad: 0.116326 Thermal: 0.000520 LR: 9.46e-06\n",
      "Epoch  12 [1950/10697 ( 18.2%)] Loss: 0.029893 L1: 0.017391 Grad: 0.124713 Thermal: 0.000616 LR: 9.46e-06\n",
      "Epoch  12 [1950/10697 ( 18.2%)] Loss: 0.029893 L1: 0.017391 Grad: 0.124713 Thermal: 0.000616 LR: 9.46e-06\n",
      "Epoch  12 [2000/10697 ( 18.7%)] Loss: 0.033673 L1: 0.019335 Grad: 0.143039 Thermal: 0.000676 LR: 9.46e-06\n",
      "Epoch  12 [2000/10697 ( 18.7%)] Loss: 0.033673 L1: 0.019335 Grad: 0.143039 Thermal: 0.000676 LR: 9.46e-06\n",
      "Epoch  12 [2050/10697 ( 19.2%)] Loss: 0.023468 L1: 0.013973 Grad: 0.094749 Thermal: 0.000389 LR: 9.46e-06\n",
      "Epoch  12 [2050/10697 ( 19.2%)] Loss: 0.023468 L1: 0.013973 Grad: 0.094749 Thermal: 0.000389 LR: 9.46e-06\n",
      "Epoch  12 [2100/10697 ( 19.6%)] Loss: 0.029210 L1: 0.016450 Grad: 0.127327 Thermal: 0.000541 LR: 9.46e-06\n",
      "Epoch  12 [2100/10697 ( 19.6%)] Loss: 0.029210 L1: 0.016450 Grad: 0.127327 Thermal: 0.000541 LR: 9.46e-06\n",
      "Epoch  12 [2150/10697 ( 20.1%)] Loss: 0.022783 L1: 0.013351 Grad: 0.094148 Thermal: 0.000330 LR: 9.46e-06\n",
      "Epoch  12 [2150/10697 ( 20.1%)] Loss: 0.022783 L1: 0.013351 Grad: 0.094148 Thermal: 0.000330 LR: 9.46e-06\n",
      "Epoch  12 [2200/10697 ( 20.6%)] Loss: 0.024548 L1: 0.013819 Grad: 0.107090 Thermal: 0.000391 LR: 9.46e-06\n",
      "Epoch  12 [2200/10697 ( 20.6%)] Loss: 0.024548 L1: 0.013819 Grad: 0.107090 Thermal: 0.000391 LR: 9.46e-06\n",
      "Epoch  12 [2250/10697 ( 21.0%)] Loss: 0.024889 L1: 0.014811 Grad: 0.100584 Thermal: 0.000396 LR: 9.46e-06\n",
      "Epoch  12 [2250/10697 ( 21.0%)] Loss: 0.024889 L1: 0.014811 Grad: 0.100584 Thermal: 0.000396 LR: 9.46e-06\n",
      "Epoch  12 [2300/10697 ( 21.5%)] Loss: 0.023279 L1: 0.013401 Grad: 0.098589 Thermal: 0.000395 LR: 9.46e-06\n",
      "Epoch  12 [2300/10697 ( 21.5%)] Loss: 0.023279 L1: 0.013401 Grad: 0.098589 Thermal: 0.000395 LR: 9.46e-06\n",
      "Epoch  12 [2350/10697 ( 22.0%)] Loss: 0.026020 L1: 0.015297 Grad: 0.107009 Thermal: 0.000439 LR: 9.46e-06\n",
      "Epoch  12 [2350/10697 ( 22.0%)] Loss: 0.026020 L1: 0.015297 Grad: 0.107009 Thermal: 0.000439 LR: 9.46e-06\n",
      "Epoch  12 [2400/10697 ( 22.4%)] Loss: 0.028093 L1: 0.016493 Grad: 0.115768 Thermal: 0.000456 LR: 9.46e-06\n",
      "Epoch  12 [2400/10697 ( 22.4%)] Loss: 0.028093 L1: 0.016493 Grad: 0.115768 Thermal: 0.000456 LR: 9.46e-06\n",
      "Epoch  12 [2450/10697 ( 22.9%)] Loss: 0.022903 L1: 0.013360 Grad: 0.095261 Thermal: 0.000334 LR: 9.46e-06\n",
      "Epoch  12 [2450/10697 ( 22.9%)] Loss: 0.022903 L1: 0.013360 Grad: 0.095261 Thermal: 0.000334 LR: 9.46e-06\n",
      "Epoch  12 [2500/10697 ( 23.4%)] Loss: 0.029205 L1: 0.016925 Grad: 0.122537 Thermal: 0.000529 LR: 9.46e-06\n",
      "Epoch  12 [2500/10697 ( 23.4%)] Loss: 0.029205 L1: 0.016925 Grad: 0.122537 Thermal: 0.000529 LR: 9.46e-06\n",
      "Epoch  12 [2550/10697 ( 23.8%)] Loss: 0.023200 L1: 0.013336 Grad: 0.098471 Thermal: 0.000345 LR: 9.46e-06\n",
      "Epoch  12 [2550/10697 ( 23.8%)] Loss: 0.023200 L1: 0.013336 Grad: 0.098471 Thermal: 0.000345 LR: 9.46e-06\n",
      "Epoch  12 [2600/10697 ( 24.3%)] Loss: 0.022876 L1: 0.013341 Grad: 0.095160 Thermal: 0.000370 LR: 9.46e-06\n",
      "Epoch  12 [2600/10697 ( 24.3%)] Loss: 0.022876 L1: 0.013341 Grad: 0.095160 Thermal: 0.000370 LR: 9.46e-06\n",
      "Epoch  12 [2650/10697 ( 24.8%)] Loss: 0.023852 L1: 0.013861 Grad: 0.099710 Thermal: 0.000394 LR: 9.46e-06\n",
      "Epoch  12 [2650/10697 ( 24.8%)] Loss: 0.023852 L1: 0.013861 Grad: 0.099710 Thermal: 0.000394 LR: 9.46e-06\n",
      "Epoch  12 [2700/10697 ( 25.2%)] Loss: 0.027900 L1: 0.016087 Grad: 0.117874 Thermal: 0.000513 LR: 9.46e-06\n",
      "Epoch  12 [2700/10697 ( 25.2%)] Loss: 0.027900 L1: 0.016087 Grad: 0.117874 Thermal: 0.000513 LR: 9.46e-06\n",
      "Epoch  12 [2750/10697 ( 25.7%)] Loss: 0.030184 L1: 0.017140 Grad: 0.130166 Thermal: 0.000539 LR: 9.46e-06\n",
      "Epoch  12 [2750/10697 ( 25.7%)] Loss: 0.030184 L1: 0.017140 Grad: 0.130166 Thermal: 0.000539 LR: 9.46e-06\n",
      "Epoch  12 [2800/10697 ( 26.2%)] Loss: 0.022829 L1: 0.012907 Grad: 0.099008 Thermal: 0.000423 LR: 9.46e-06\n",
      "Epoch  12 [2800/10697 ( 26.2%)] Loss: 0.022829 L1: 0.012907 Grad: 0.099008 Thermal: 0.000423 LR: 9.46e-06\n",
      "Epoch  12 [2850/10697 ( 26.6%)] Loss: 0.032763 L1: 0.019294 Grad: 0.134345 Thermal: 0.000700 LR: 9.46e-06\n",
      "Epoch  12 [2850/10697 ( 26.6%)] Loss: 0.032763 L1: 0.019294 Grad: 0.134345 Thermal: 0.000700 LR: 9.46e-06\n",
      "Epoch  12 [2900/10697 ( 27.1%)] Loss: 0.024249 L1: 0.014273 Grad: 0.099566 Thermal: 0.000402 LR: 9.46e-06\n",
      "Epoch  12 [2900/10697 ( 27.1%)] Loss: 0.024249 L1: 0.014273 Grad: 0.099566 Thermal: 0.000402 LR: 9.46e-06\n",
      "Epoch  12 [2950/10697 ( 27.6%)] Loss: 0.024881 L1: 0.014564 Grad: 0.102963 Thermal: 0.000414 LR: 9.46e-06\n",
      "Epoch  12 [2950/10697 ( 27.6%)] Loss: 0.024881 L1: 0.014564 Grad: 0.102963 Thermal: 0.000414 LR: 9.46e-06\n",
      "Epoch  12 [3000/10697 ( 28.0%)] Loss: 0.023201 L1: 0.013644 Grad: 0.095383 Thermal: 0.000362 LR: 9.46e-06\n",
      "Epoch  12 [3000/10697 ( 28.0%)] Loss: 0.023201 L1: 0.013644 Grad: 0.095383 Thermal: 0.000362 LR: 9.46e-06\n",
      "Epoch  12 [3050/10697 ( 28.5%)] Loss: 0.027514 L1: 0.015813 Grad: 0.116771 Thermal: 0.000473 LR: 9.46e-06\n",
      "Epoch  12 [3050/10697 ( 28.5%)] Loss: 0.027514 L1: 0.015813 Grad: 0.116771 Thermal: 0.000473 LR: 9.46e-06\n",
      "Epoch  12 [3100/10697 ( 29.0%)] Loss: 0.029155 L1: 0.016870 Grad: 0.122586 Thermal: 0.000523 LR: 9.46e-06\n",
      "Epoch  12 [3100/10697 ( 29.0%)] Loss: 0.029155 L1: 0.016870 Grad: 0.122586 Thermal: 0.000523 LR: 9.46e-06\n",
      "Epoch  12 [3150/10697 ( 29.4%)] Loss: 0.026231 L1: 0.015594 Grad: 0.106150 Thermal: 0.000438 LR: 9.46e-06\n",
      "Epoch  12 [3150/10697 ( 29.4%)] Loss: 0.026231 L1: 0.015594 Grad: 0.106150 Thermal: 0.000438 LR: 9.46e-06\n",
      "Epoch  12 [3200/10697 ( 29.9%)] Loss: 0.024452 L1: 0.014472 Grad: 0.099590 Thermal: 0.000403 LR: 9.46e-06\n",
      "Epoch  12 [3200/10697 ( 29.9%)] Loss: 0.024452 L1: 0.014472 Grad: 0.099590 Thermal: 0.000403 LR: 9.46e-06\n",
      "Epoch  12 [3250/10697 ( 30.4%)] Loss: 0.028916 L1: 0.016954 Grad: 0.119358 Thermal: 0.000541 LR: 9.46e-06\n",
      "Epoch  12 [3250/10697 ( 30.4%)] Loss: 0.028916 L1: 0.016954 Grad: 0.119358 Thermal: 0.000541 LR: 9.46e-06\n",
      "Epoch  12 [3300/10697 ( 30.8%)] Loss: 0.024342 L1: 0.013905 Grad: 0.104191 Thermal: 0.000368 LR: 9.46e-06\n",
      "Epoch  12 [3300/10697 ( 30.8%)] Loss: 0.024342 L1: 0.013905 Grad: 0.104191 Thermal: 0.000368 LR: 9.46e-06\n",
      "Epoch  12 [3350/10697 ( 31.3%)] Loss: 0.023705 L1: 0.013875 Grad: 0.098105 Thermal: 0.000388 LR: 9.46e-06\n",
      "Epoch  12 [3350/10697 ( 31.3%)] Loss: 0.023705 L1: 0.013875 Grad: 0.098105 Thermal: 0.000388 LR: 9.46e-06\n",
      "Epoch  12 [3400/10697 ( 31.8%)] Loss: 0.027547 L1: 0.015823 Grad: 0.117006 Thermal: 0.000460 LR: 9.46e-06\n",
      "Epoch  12 [3400/10697 ( 31.8%)] Loss: 0.027547 L1: 0.015823 Grad: 0.117006 Thermal: 0.000460 LR: 9.46e-06\n",
      "Epoch  12 [3450/10697 ( 32.3%)] Loss: 0.024622 L1: 0.014316 Grad: 0.102858 Thermal: 0.000390 LR: 9.46e-06\n",
      "Epoch  12 [3450/10697 ( 32.3%)] Loss: 0.024622 L1: 0.014316 Grad: 0.102858 Thermal: 0.000390 LR: 9.46e-06\n",
      "Epoch  12 [3500/10697 ( 32.7%)] Loss: 0.027287 L1: 0.015670 Grad: 0.115891 Thermal: 0.000568 LR: 9.46e-06\n",
      "Epoch  12 [3500/10697 ( 32.7%)] Loss: 0.027287 L1: 0.015670 Grad: 0.115891 Thermal: 0.000568 LR: 9.46e-06\n",
      "Epoch  12 [3550/10697 ( 33.2%)] Loss: 0.026384 L1: 0.015158 Grad: 0.112049 Thermal: 0.000422 LR: 9.46e-06\n",
      "Epoch  12 [3550/10697 ( 33.2%)] Loss: 0.026384 L1: 0.015158 Grad: 0.112049 Thermal: 0.000422 LR: 9.46e-06\n",
      "Epoch  12 [3600/10697 ( 33.7%)] Loss: 0.035460 L1: 0.019943 Grad: 0.154727 Thermal: 0.000871 LR: 9.46e-06\n",
      "Epoch  12 [3600/10697 ( 33.7%)] Loss: 0.035460 L1: 0.019943 Grad: 0.154727 Thermal: 0.000871 LR: 9.46e-06\n",
      "Epoch  12 [3650/10697 ( 34.1%)] Loss: 0.024176 L1: 0.014398 Grad: 0.097568 Thermal: 0.000417 LR: 9.46e-06\n",
      "Epoch  12 [3650/10697 ( 34.1%)] Loss: 0.024176 L1: 0.014398 Grad: 0.097568 Thermal: 0.000417 LR: 9.46e-06\n",
      "Epoch  12 [3700/10697 ( 34.6%)] Loss: 0.022652 L1: 0.013024 Grad: 0.096107 Thermal: 0.000341 LR: 9.46e-06\n",
      "Epoch  12 [3700/10697 ( 34.6%)] Loss: 0.022652 L1: 0.013024 Grad: 0.096107 Thermal: 0.000341 LR: 9.46e-06\n",
      "Epoch  12 [3750/10697 ( 35.1%)] Loss: 0.024224 L1: 0.014454 Grad: 0.097506 Thermal: 0.000374 LR: 9.46e-06\n",
      "Epoch  12 [3750/10697 ( 35.1%)] Loss: 0.024224 L1: 0.014454 Grad: 0.097506 Thermal: 0.000374 LR: 9.46e-06\n",
      "Epoch  12 [3800/10697 ( 35.5%)] Loss: 0.035375 L1: 0.020178 Grad: 0.151575 Thermal: 0.000787 LR: 9.46e-06\n",
      "Epoch  12 [3800/10697 ( 35.5%)] Loss: 0.035375 L1: 0.020178 Grad: 0.151575 Thermal: 0.000787 LR: 9.46e-06\n",
      "Epoch  12 [3850/10697 ( 36.0%)] Loss: 0.022093 L1: 0.013059 Grad: 0.090183 Thermal: 0.000317 LR: 9.46e-06\n",
      "Epoch  12 [3850/10697 ( 36.0%)] Loss: 0.022093 L1: 0.013059 Grad: 0.090183 Thermal: 0.000317 LR: 9.46e-06\n",
      "Epoch  12 [3900/10697 ( 36.5%)] Loss: 0.023480 L1: 0.013558 Grad: 0.099020 Thermal: 0.000396 LR: 9.46e-06\n",
      "Epoch  12 [3900/10697 ( 36.5%)] Loss: 0.023480 L1: 0.013558 Grad: 0.099020 Thermal: 0.000396 LR: 9.46e-06\n",
      "Epoch  12 [3950/10697 ( 36.9%)] Loss: 0.027878 L1: 0.015901 Grad: 0.119523 Thermal: 0.000480 LR: 9.46e-06\n",
      "Epoch  12 [3950/10697 ( 36.9%)] Loss: 0.027878 L1: 0.015901 Grad: 0.119523 Thermal: 0.000480 LR: 9.46e-06\n",
      "Epoch  12 [4000/10697 ( 37.4%)] Loss: 0.016722 L1: 0.009420 Grad: 0.072923 Thermal: 0.000202 LR: 9.46e-06\n",
      "Epoch  12 [4000/10697 ( 37.4%)] Loss: 0.016722 L1: 0.009420 Grad: 0.072923 Thermal: 0.000202 LR: 9.46e-06\n",
      "Epoch  12 [4050/10697 ( 37.9%)] Loss: 0.025665 L1: 0.014701 Grad: 0.109461 Thermal: 0.000367 LR: 9.46e-06\n",
      "Epoch  12 [4050/10697 ( 37.9%)] Loss: 0.025665 L1: 0.014701 Grad: 0.109461 Thermal: 0.000367 LR: 9.46e-06\n",
      "Epoch  12 [4100/10697 ( 38.3%)] Loss: 0.027183 L1: 0.015913 Grad: 0.112455 Thermal: 0.000473 LR: 9.46e-06\n",
      "Epoch  12 [4100/10697 ( 38.3%)] Loss: 0.027183 L1: 0.015913 Grad: 0.112455 Thermal: 0.000473 LR: 9.46e-06\n",
      "Epoch  12 [4150/10697 ( 38.8%)] Loss: 0.025279 L1: 0.014353 Grad: 0.109040 Thermal: 0.000445 LR: 9.46e-06\n",
      "Epoch  12 [4150/10697 ( 38.8%)] Loss: 0.025279 L1: 0.014353 Grad: 0.109040 Thermal: 0.000445 LR: 9.46e-06\n",
      "Epoch  12 [4200/10697 ( 39.3%)] Loss: 0.026232 L1: 0.015434 Grad: 0.107756 Thermal: 0.000449 LR: 9.46e-06\n",
      "Epoch  12 [4200/10697 ( 39.3%)] Loss: 0.026232 L1: 0.015434 Grad: 0.107756 Thermal: 0.000449 LR: 9.46e-06\n",
      "Epoch  12 [4250/10697 ( 39.7%)] Loss: 0.025230 L1: 0.014461 Grad: 0.107487 Thermal: 0.000391 LR: 9.46e-06\n",
      "Epoch  12 [4250/10697 ( 39.7%)] Loss: 0.025230 L1: 0.014461 Grad: 0.107487 Thermal: 0.000391 LR: 9.46e-06\n",
      "Epoch  12 [4300/10697 ( 40.2%)] Loss: 0.030146 L1: 0.017587 Grad: 0.125299 Thermal: 0.000582 LR: 9.46e-06\n",
      "Epoch  12 [4300/10697 ( 40.2%)] Loss: 0.030146 L1: 0.017587 Grad: 0.125299 Thermal: 0.000582 LR: 9.46e-06\n",
      "Epoch  12 [4350/10697 ( 40.7%)] Loss: 0.022525 L1: 0.012868 Grad: 0.096406 Thermal: 0.000324 LR: 9.46e-06\n",
      "Epoch  12 [4350/10697 ( 40.7%)] Loss: 0.022525 L1: 0.012868 Grad: 0.096406 Thermal: 0.000324 LR: 9.46e-06\n",
      "Epoch  12 [4400/10697 ( 41.1%)] Loss: 0.030071 L1: 0.017112 Grad: 0.129326 Thermal: 0.000533 LR: 9.46e-06\n",
      "Epoch  12 [4400/10697 ( 41.1%)] Loss: 0.030071 L1: 0.017112 Grad: 0.129326 Thermal: 0.000533 LR: 9.46e-06\n",
      "Epoch  12 [4450/10697 ( 41.6%)] Loss: 0.018904 L1: 0.010940 Grad: 0.079522 Thermal: 0.000240 LR: 9.46e-06\n",
      "Epoch  12 [4450/10697 ( 41.6%)] Loss: 0.018904 L1: 0.010940 Grad: 0.079522 Thermal: 0.000240 LR: 9.46e-06\n",
      "Epoch  12 [4500/10697 ( 42.1%)] Loss: 0.027816 L1: 0.016073 Grad: 0.117179 Thermal: 0.000489 LR: 9.46e-06\n",
      "Epoch  12 [4500/10697 ( 42.1%)] Loss: 0.027816 L1: 0.016073 Grad: 0.117179 Thermal: 0.000489 LR: 9.46e-06\n",
      "Epoch  12 [4550/10697 ( 42.5%)] Loss: 0.022528 L1: 0.013498 Grad: 0.090112 Thermal: 0.000372 LR: 9.46e-06\n",
      "Epoch  12 [4550/10697 ( 42.5%)] Loss: 0.022528 L1: 0.013498 Grad: 0.090112 Thermal: 0.000372 LR: 9.46e-06\n",
      "Epoch  12 [4600/10697 ( 43.0%)] Loss: 0.031981 L1: 0.018114 Grad: 0.138350 Thermal: 0.000630 LR: 9.46e-06\n",
      "Epoch  12 [4600/10697 ( 43.0%)] Loss: 0.031981 L1: 0.018114 Grad: 0.138350 Thermal: 0.000630 LR: 9.46e-06\n",
      "Epoch  12 [4650/10697 ( 43.5%)] Loss: 0.023818 L1: 0.014167 Grad: 0.096313 Thermal: 0.000392 LR: 9.46e-06\n",
      "Epoch  12 [4650/10697 ( 43.5%)] Loss: 0.023818 L1: 0.014167 Grad: 0.096313 Thermal: 0.000392 LR: 9.46e-06\n",
      "Epoch  12 [4700/10697 ( 43.9%)] Loss: 0.025637 L1: 0.014887 Grad: 0.107311 Thermal: 0.000382 LR: 9.46e-06\n",
      "Epoch  12 [4700/10697 ( 43.9%)] Loss: 0.025637 L1: 0.014887 Grad: 0.107311 Thermal: 0.000382 LR: 9.46e-06\n",
      "Epoch  12 [4750/10697 ( 44.4%)] Loss: 0.027649 L1: 0.015762 Grad: 0.118629 Thermal: 0.000485 LR: 9.46e-06\n",
      "Epoch  12 [4750/10697 ( 44.4%)] Loss: 0.027649 L1: 0.015762 Grad: 0.118629 Thermal: 0.000485 LR: 9.46e-06\n",
      "Epoch  12 [4800/10697 ( 44.9%)] Loss: 0.024668 L1: 0.014612 Grad: 0.100347 Thermal: 0.000422 LR: 9.46e-06\n",
      "Epoch  12 [4800/10697 ( 44.9%)] Loss: 0.024668 L1: 0.014612 Grad: 0.100347 Thermal: 0.000422 LR: 9.46e-06\n",
      "Epoch  12 [4850/10697 ( 45.3%)] Loss: 0.028136 L1: 0.016201 Grad: 0.119084 Thermal: 0.000523 LR: 9.46e-06\n",
      "Epoch  12 [4850/10697 ( 45.3%)] Loss: 0.028136 L1: 0.016201 Grad: 0.119084 Thermal: 0.000523 LR: 9.46e-06\n",
      "Epoch  12 [4900/10697 ( 45.8%)] Loss: 0.027933 L1: 0.016653 Grad: 0.112547 Thermal: 0.000515 LR: 9.46e-06\n",
      "Epoch  12 [4900/10697 ( 45.8%)] Loss: 0.027933 L1: 0.016653 Grad: 0.112547 Thermal: 0.000515 LR: 9.46e-06\n",
      "Epoch  12 [4950/10697 ( 46.3%)] Loss: 0.024022 L1: 0.013822 Grad: 0.101809 Thermal: 0.000383 LR: 9.46e-06\n",
      "Epoch  12 [4950/10697 ( 46.3%)] Loss: 0.024022 L1: 0.013822 Grad: 0.101809 Thermal: 0.000383 LR: 9.46e-06\n",
      "Epoch  12 [5000/10697 ( 46.7%)] Loss: 0.031691 L1: 0.018711 Grad: 0.129483 Thermal: 0.000618 LR: 9.46e-06\n",
      "Epoch  12 [5000/10697 ( 46.7%)] Loss: 0.031691 L1: 0.018711 Grad: 0.129483 Thermal: 0.000618 LR: 9.46e-06\n",
      "Epoch  12 [5050/10697 ( 47.2%)] Loss: 0.029362 L1: 0.016779 Grad: 0.125562 Thermal: 0.000539 LR: 9.46e-06\n",
      "Epoch  12 [5050/10697 ( 47.2%)] Loss: 0.029362 L1: 0.016779 Grad: 0.125562 Thermal: 0.000539 LR: 9.46e-06\n",
      "Epoch  12 [5100/10697 ( 47.7%)] Loss: 0.022017 L1: 0.013123 Grad: 0.088749 Thermal: 0.000373 LR: 9.46e-06\n",
      "Epoch  12 [5100/10697 ( 47.7%)] Loss: 0.022017 L1: 0.013123 Grad: 0.088749 Thermal: 0.000373 LR: 9.46e-06\n",
      "Epoch  12 [5150/10697 ( 48.1%)] Loss: 0.024714 L1: 0.014406 Grad: 0.102879 Thermal: 0.000387 LR: 9.46e-06\n",
      "Epoch  12 [5150/10697 ( 48.1%)] Loss: 0.024714 L1: 0.014406 Grad: 0.102879 Thermal: 0.000387 LR: 9.46e-06\n",
      "Epoch  12 [5200/10697 ( 48.6%)] Loss: 0.029705 L1: 0.017264 Grad: 0.124140 Thermal: 0.000539 LR: 9.46e-06\n",
      "Epoch  12 [5200/10697 ( 48.6%)] Loss: 0.029705 L1: 0.017264 Grad: 0.124140 Thermal: 0.000539 LR: 9.46e-06\n",
      "Epoch  12 [5250/10697 ( 49.1%)] Loss: 0.026822 L1: 0.015308 Grad: 0.114909 Thermal: 0.000457 LR: 9.46e-06\n",
      "Epoch  12 [5250/10697 ( 49.1%)] Loss: 0.026822 L1: 0.015308 Grad: 0.114909 Thermal: 0.000457 LR: 9.46e-06\n",
      "Epoch  12 [5300/10697 ( 49.5%)] Loss: 0.027420 L1: 0.016140 Grad: 0.112567 Thermal: 0.000467 LR: 9.46e-06\n",
      "Epoch  12 [5300/10697 ( 49.5%)] Loss: 0.027420 L1: 0.016140 Grad: 0.112567 Thermal: 0.000467 LR: 9.46e-06\n",
      "Epoch  12 [5350/10697 ( 50.0%)] Loss: 0.021804 L1: 0.012835 Grad: 0.089501 Thermal: 0.000375 LR: 9.46e-06\n",
      "Epoch  12 [5350/10697 ( 50.0%)] Loss: 0.021804 L1: 0.012835 Grad: 0.089501 Thermal: 0.000375 LR: 9.46e-06\n",
      "Epoch  12 [5400/10697 ( 50.5%)] Loss: 0.025989 L1: 0.015559 Grad: 0.104085 Thermal: 0.000433 LR: 9.46e-06\n",
      "Epoch  12 [5400/10697 ( 50.5%)] Loss: 0.025989 L1: 0.015559 Grad: 0.104085 Thermal: 0.000433 LR: 9.46e-06\n",
      "Epoch  12 [5450/10697 ( 50.9%)] Loss: 0.025711 L1: 0.014713 Grad: 0.109765 Thermal: 0.000424 LR: 9.46e-06\n",
      "Epoch  12 [5450/10697 ( 50.9%)] Loss: 0.025711 L1: 0.014713 Grad: 0.109765 Thermal: 0.000424 LR: 9.46e-06\n",
      "Epoch  12 [5500/10697 ( 51.4%)] Loss: 0.027576 L1: 0.015757 Grad: 0.117938 Thermal: 0.000498 LR: 9.46e-06\n",
      "Epoch  12 [5500/10697 ( 51.4%)] Loss: 0.027576 L1: 0.015757 Grad: 0.117938 Thermal: 0.000498 LR: 9.46e-06\n",
      "Epoch  12 [5550/10697 ( 51.9%)] Loss: 0.027747 L1: 0.016636 Grad: 0.110858 Thermal: 0.000518 LR: 9.46e-06\n",
      "Epoch  12 [5550/10697 ( 51.9%)] Loss: 0.027747 L1: 0.016636 Grad: 0.110858 Thermal: 0.000518 LR: 9.46e-06\n",
      "Epoch  12 [5600/10697 ( 52.4%)] Loss: 0.026509 L1: 0.015737 Grad: 0.107479 Thermal: 0.000469 LR: 9.46e-06\n",
      "Epoch  12 [5600/10697 ( 52.4%)] Loss: 0.026509 L1: 0.015737 Grad: 0.107479 Thermal: 0.000469 LR: 9.46e-06\n",
      "Epoch  12 [5650/10697 ( 52.8%)] Loss: 0.025718 L1: 0.014880 Grad: 0.108146 Thermal: 0.000459 LR: 9.46e-06\n",
      "Epoch  12 [5650/10697 ( 52.8%)] Loss: 0.025718 L1: 0.014880 Grad: 0.108146 Thermal: 0.000459 LR: 9.46e-06\n",
      "Epoch  12 [5700/10697 ( 53.3%)] Loss: 0.028395 L1: 0.016239 Grad: 0.121288 Thermal: 0.000532 LR: 9.46e-06\n",
      "Epoch  12 [5700/10697 ( 53.3%)] Loss: 0.028395 L1: 0.016239 Grad: 0.121288 Thermal: 0.000532 LR: 9.46e-06\n",
      "Epoch  12 [5750/10697 ( 53.8%)] Loss: 0.028226 L1: 0.016845 Grad: 0.113545 Thermal: 0.000522 LR: 9.46e-06\n",
      "Epoch  12 [5750/10697 ( 53.8%)] Loss: 0.028226 L1: 0.016845 Grad: 0.113545 Thermal: 0.000522 LR: 9.46e-06\n",
      "Epoch  12 [5800/10697 ( 54.2%)] Loss: 0.025631 L1: 0.015126 Grad: 0.104825 Thermal: 0.000448 LR: 9.46e-06\n",
      "Epoch  12 [5800/10697 ( 54.2%)] Loss: 0.025631 L1: 0.015126 Grad: 0.104825 Thermal: 0.000448 LR: 9.46e-06\n",
      "Epoch  12 [5850/10697 ( 54.7%)] Loss: 0.023083 L1: 0.013591 Grad: 0.094729 Thermal: 0.000375 LR: 9.46e-06\n",
      "Epoch  12 [5850/10697 ( 54.7%)] Loss: 0.023083 L1: 0.013591 Grad: 0.094729 Thermal: 0.000375 LR: 9.46e-06\n",
      "Epoch  12 [5900/10697 ( 55.2%)] Loss: 0.028210 L1: 0.016432 Grad: 0.117548 Thermal: 0.000481 LR: 9.46e-06\n",
      "Epoch  12 [5900/10697 ( 55.2%)] Loss: 0.028210 L1: 0.016432 Grad: 0.117548 Thermal: 0.000481 LR: 9.46e-06\n",
      "Epoch  12 [5950/10697 ( 55.6%)] Loss: 0.027196 L1: 0.015882 Grad: 0.112909 Thermal: 0.000467 LR: 9.46e-06\n",
      "Epoch  12 [5950/10697 ( 55.6%)] Loss: 0.027196 L1: 0.015882 Grad: 0.112909 Thermal: 0.000467 LR: 9.46e-06\n",
      "Epoch  12 [6000/10697 ( 56.1%)] Loss: 0.026019 L1: 0.015205 Grad: 0.107924 Thermal: 0.000435 LR: 9.46e-06\n",
      "Epoch  12 [6000/10697 ( 56.1%)] Loss: 0.026019 L1: 0.015205 Grad: 0.107924 Thermal: 0.000435 LR: 9.46e-06\n",
      "Epoch  12 [6050/10697 ( 56.6%)] Loss: 0.023206 L1: 0.013185 Grad: 0.100027 Thermal: 0.000365 LR: 9.46e-06\n",
      "Epoch  12 [6050/10697 ( 56.6%)] Loss: 0.023206 L1: 0.013185 Grad: 0.100027 Thermal: 0.000365 LR: 9.46e-06\n",
      "Epoch  12 [6100/10697 ( 57.0%)] Loss: 0.017566 L1: 0.009968 Grad: 0.075847 Thermal: 0.000268 LR: 9.46e-06\n",
      "Epoch  12 [6100/10697 ( 57.0%)] Loss: 0.017566 L1: 0.009968 Grad: 0.075847 Thermal: 0.000268 LR: 9.46e-06\n",
      "Epoch  12 [6150/10697 ( 57.5%)] Loss: 0.023359 L1: 0.013615 Grad: 0.097255 Thermal: 0.000373 LR: 9.46e-06\n",
      "Epoch  12 [6150/10697 ( 57.5%)] Loss: 0.023359 L1: 0.013615 Grad: 0.097255 Thermal: 0.000373 LR: 9.46e-06\n",
      "Epoch  12 [6200/10697 ( 58.0%)] Loss: 0.025343 L1: 0.015021 Grad: 0.103003 Thermal: 0.000428 LR: 9.46e-06\n",
      "Epoch  12 [6200/10697 ( 58.0%)] Loss: 0.025343 L1: 0.015021 Grad: 0.103003 Thermal: 0.000428 LR: 9.46e-06\n",
      "Epoch  12 [6250/10697 ( 58.4%)] Loss: 0.019499 L1: 0.011392 Grad: 0.080926 Thermal: 0.000282 LR: 9.46e-06\n",
      "Epoch  12 [6250/10697 ( 58.4%)] Loss: 0.019499 L1: 0.011392 Grad: 0.080926 Thermal: 0.000282 LR: 9.46e-06\n",
      "Epoch  12 [6300/10697 ( 58.9%)] Loss: 0.023274 L1: 0.013313 Grad: 0.099434 Thermal: 0.000352 LR: 9.46e-06\n",
      "Epoch  12 [6300/10697 ( 58.9%)] Loss: 0.023274 L1: 0.013313 Grad: 0.099434 Thermal: 0.000352 LR: 9.46e-06\n",
      "Epoch  12 [6350/10697 ( 59.4%)] Loss: 0.028785 L1: 0.016550 Grad: 0.122086 Thermal: 0.000540 LR: 9.46e-06\n",
      "Epoch  12 [6350/10697 ( 59.4%)] Loss: 0.028785 L1: 0.016550 Grad: 0.122086 Thermal: 0.000540 LR: 9.46e-06\n",
      "Epoch  12 [6400/10697 ( 59.8%)] Loss: 0.027048 L1: 0.016306 Grad: 0.107190 Thermal: 0.000458 LR: 9.46e-06\n",
      "Epoch  12 [6400/10697 ( 59.8%)] Loss: 0.027048 L1: 0.016306 Grad: 0.107190 Thermal: 0.000458 LR: 9.46e-06\n",
      "Epoch  12 [6450/10697 ( 60.3%)] Loss: 0.026902 L1: 0.016104 Grad: 0.107751 Thermal: 0.000461 LR: 9.46e-06\n",
      "Epoch  12 [6450/10697 ( 60.3%)] Loss: 0.026902 L1: 0.016104 Grad: 0.107751 Thermal: 0.000461 LR: 9.46e-06\n",
      "Epoch  12 [6500/10697 ( 60.8%)] Loss: 0.032271 L1: 0.019205 Grad: 0.130319 Thermal: 0.000677 LR: 9.46e-06\n",
      "Epoch  12 [6500/10697 ( 60.8%)] Loss: 0.032271 L1: 0.019205 Grad: 0.130319 Thermal: 0.000677 LR: 9.46e-06\n",
      "Epoch  12 [6550/10697 ( 61.2%)] Loss: 0.033084 L1: 0.018917 Grad: 0.141324 Thermal: 0.000688 LR: 9.46e-06\n",
      "Epoch  12 [6550/10697 ( 61.2%)] Loss: 0.033084 L1: 0.018917 Grad: 0.141324 Thermal: 0.000688 LR: 9.46e-06\n",
      "Epoch  12 [6600/10697 ( 61.7%)] Loss: 0.026871 L1: 0.015673 Grad: 0.111719 Thermal: 0.000532 LR: 9.46e-06\n",
      "Epoch  12 [6600/10697 ( 61.7%)] Loss: 0.026871 L1: 0.015673 Grad: 0.111719 Thermal: 0.000532 LR: 9.46e-06\n",
      "Epoch  12 [6650/10697 ( 62.2%)] Loss: 0.018303 L1: 0.010629 Grad: 0.076605 Thermal: 0.000269 LR: 9.46e-06\n",
      "Epoch  12 [6650/10697 ( 62.2%)] Loss: 0.018303 L1: 0.010629 Grad: 0.076605 Thermal: 0.000269 LR: 9.46e-06\n",
      "Epoch  12 [6700/10697 ( 62.6%)] Loss: 0.022858 L1: 0.013108 Grad: 0.097326 Thermal: 0.000346 LR: 9.46e-06\n",
      "Epoch  12 [6700/10697 ( 62.6%)] Loss: 0.022858 L1: 0.013108 Grad: 0.097326 Thermal: 0.000346 LR: 9.46e-06\n",
      "Epoch  12 [6750/10697 ( 63.1%)] Loss: 0.027275 L1: 0.015553 Grad: 0.116994 Thermal: 0.000453 LR: 9.46e-06\n",
      "Epoch  12 [6750/10697 ( 63.1%)] Loss: 0.027275 L1: 0.015553 Grad: 0.116994 Thermal: 0.000453 LR: 9.46e-06\n",
      "Epoch  12 [6800/10697 ( 63.6%)] Loss: 0.028259 L1: 0.016312 Grad: 0.119184 Thermal: 0.000558 LR: 9.46e-06\n",
      "Epoch  12 [6800/10697 ( 63.6%)] Loss: 0.028259 L1: 0.016312 Grad: 0.119184 Thermal: 0.000558 LR: 9.46e-06\n",
      "Epoch  12 [6850/10697 ( 64.0%)] Loss: 0.022360 L1: 0.012950 Grad: 0.093933 Thermal: 0.000334 LR: 9.46e-06\n",
      "Epoch  12 [6850/10697 ( 64.0%)] Loss: 0.022360 L1: 0.012950 Grad: 0.093933 Thermal: 0.000334 LR: 9.46e-06\n",
      "Epoch  12 [6900/10697 ( 64.5%)] Loss: 0.030526 L1: 0.017670 Grad: 0.128233 Thermal: 0.000650 LR: 9.46e-06\n",
      "Epoch  12 [6900/10697 ( 64.5%)] Loss: 0.030526 L1: 0.017670 Grad: 0.128233 Thermal: 0.000650 LR: 9.46e-06\n",
      "Epoch  12 [6950/10697 ( 65.0%)] Loss: 0.023176 L1: 0.013097 Grad: 0.100608 Thermal: 0.000360 LR: 9.46e-06\n",
      "Epoch  12 [6950/10697 ( 65.0%)] Loss: 0.023176 L1: 0.013097 Grad: 0.100608 Thermal: 0.000360 LR: 9.46e-06\n",
      "Epoch  12 [7000/10697 ( 65.4%)] Loss: 0.018287 L1: 0.010502 Grad: 0.077703 Thermal: 0.000300 LR: 9.46e-06\n",
      "Epoch  12 [7000/10697 ( 65.4%)] Loss: 0.018287 L1: 0.010502 Grad: 0.077703 Thermal: 0.000300 LR: 9.46e-06\n",
      "Epoch  12 [7050/10697 ( 65.9%)] Loss: 0.024900 L1: 0.014528 Grad: 0.103528 Thermal: 0.000391 LR: 9.46e-06\n",
      "Epoch  12 [7050/10697 ( 65.9%)] Loss: 0.024900 L1: 0.014528 Grad: 0.103528 Thermal: 0.000391 LR: 9.46e-06\n",
      "Epoch  12 [7100/10697 ( 66.4%)] Loss: 0.034907 L1: 0.019979 Grad: 0.148893 Thermal: 0.000773 LR: 9.46e-06\n",
      "Epoch  12 [7100/10697 ( 66.4%)] Loss: 0.034907 L1: 0.019979 Grad: 0.148893 Thermal: 0.000773 LR: 9.46e-06\n",
      "Epoch  12 [7150/10697 ( 66.8%)] Loss: 0.027841 L1: 0.016220 Grad: 0.115980 Thermal: 0.000463 LR: 9.46e-06\n",
      "Epoch  12 [7150/10697 ( 66.8%)] Loss: 0.027841 L1: 0.016220 Grad: 0.115980 Thermal: 0.000463 LR: 9.46e-06\n",
      "Epoch  12 [7200/10697 ( 67.3%)] Loss: 0.023621 L1: 0.013868 Grad: 0.097341 Thermal: 0.000377 LR: 9.46e-06\n",
      "Epoch  12 [7200/10697 ( 67.3%)] Loss: 0.023621 L1: 0.013868 Grad: 0.097341 Thermal: 0.000377 LR: 9.46e-06\n",
      "Epoch  12 [7250/10697 ( 67.8%)] Loss: 0.023606 L1: 0.013742 Grad: 0.098460 Thermal: 0.000357 LR: 9.46e-06\n",
      "Epoch  12 [7250/10697 ( 67.8%)] Loss: 0.023606 L1: 0.013742 Grad: 0.098460 Thermal: 0.000357 LR: 9.46e-06\n",
      "Epoch  12 [7300/10697 ( 68.2%)] Loss: 0.026814 L1: 0.015507 Grad: 0.112844 Thermal: 0.000439 LR: 9.46e-06\n",
      "Epoch  12 [7300/10697 ( 68.2%)] Loss: 0.026814 L1: 0.015507 Grad: 0.112844 Thermal: 0.000439 LR: 9.46e-06\n",
      "Epoch  12 [7350/10697 ( 68.7%)] Loss: 0.028074 L1: 0.016922 Grad: 0.111255 Thermal: 0.000520 LR: 9.46e-06\n",
      "Epoch  12 [7350/10697 ( 68.7%)] Loss: 0.028074 L1: 0.016922 Grad: 0.111255 Thermal: 0.000520 LR: 9.46e-06\n",
      "Epoch  12 [7400/10697 ( 69.2%)] Loss: 0.031169 L1: 0.017547 Grad: 0.135916 Thermal: 0.000618 LR: 9.46e-06\n",
      "Epoch  12 [7400/10697 ( 69.2%)] Loss: 0.031169 L1: 0.017547 Grad: 0.135916 Thermal: 0.000618 LR: 9.46e-06\n",
      "Epoch  12 [7450/10697 ( 69.6%)] Loss: 0.023261 L1: 0.013708 Grad: 0.095355 Thermal: 0.000348 LR: 9.46e-06\n",
      "Epoch  12 [7450/10697 ( 69.6%)] Loss: 0.023261 L1: 0.013708 Grad: 0.095355 Thermal: 0.000348 LR: 9.46e-06\n",
      "Epoch  12 [7500/10697 ( 70.1%)] Loss: 0.023134 L1: 0.013460 Grad: 0.096568 Thermal: 0.000353 LR: 9.46e-06\n",
      "Epoch  12 [7500/10697 ( 70.1%)] Loss: 0.023134 L1: 0.013460 Grad: 0.096568 Thermal: 0.000353 LR: 9.46e-06\n",
      "Epoch  12 [7550/10697 ( 70.6%)] Loss: 0.023961 L1: 0.013982 Grad: 0.099602 Thermal: 0.000368 LR: 9.46e-06\n",
      "Epoch  12 [7550/10697 ( 70.6%)] Loss: 0.023961 L1: 0.013982 Grad: 0.099602 Thermal: 0.000368 LR: 9.46e-06\n",
      "Epoch  12 [7600/10697 ( 71.0%)] Loss: 0.025091 L1: 0.014577 Grad: 0.104937 Thermal: 0.000413 LR: 9.46e-06\n",
      "Epoch  12 [7600/10697 ( 71.0%)] Loss: 0.025091 L1: 0.014577 Grad: 0.104937 Thermal: 0.000413 LR: 9.46e-06\n",
      "Epoch  12 [7650/10697 ( 71.5%)] Loss: 0.034940 L1: 0.019692 Grad: 0.152110 Thermal: 0.000744 LR: 9.46e-06\n",
      "Epoch  12 [7650/10697 ( 71.5%)] Loss: 0.034940 L1: 0.019692 Grad: 0.152110 Thermal: 0.000744 LR: 9.46e-06\n",
      "Epoch  12 [7700/10697 ( 72.0%)] Loss: 0.027550 L1: 0.016398 Grad: 0.111280 Thermal: 0.000487 LR: 9.46e-06\n",
      "Epoch  12 [7700/10697 ( 72.0%)] Loss: 0.027550 L1: 0.016398 Grad: 0.111280 Thermal: 0.000487 LR: 9.46e-06\n",
      "Epoch  12 [7750/10697 ( 72.5%)] Loss: 0.025813 L1: 0.015134 Grad: 0.106567 Thermal: 0.000440 LR: 9.46e-06\n",
      "Epoch  12 [7750/10697 ( 72.5%)] Loss: 0.025813 L1: 0.015134 Grad: 0.106567 Thermal: 0.000440 LR: 9.46e-06\n",
      "Epoch  12 [7800/10697 ( 72.9%)] Loss: 0.026396 L1: 0.015937 Grad: 0.104374 Thermal: 0.000448 LR: 9.46e-06\n",
      "Epoch  12 [7800/10697 ( 72.9%)] Loss: 0.026396 L1: 0.015937 Grad: 0.104374 Thermal: 0.000448 LR: 9.46e-06\n",
      "Epoch  12 [7850/10697 ( 73.4%)] Loss: 0.031035 L1: 0.018032 Grad: 0.129702 Thermal: 0.000656 LR: 9.46e-06\n",
      "Epoch  12 [7850/10697 ( 73.4%)] Loss: 0.031035 L1: 0.018032 Grad: 0.129702 Thermal: 0.000656 LR: 9.46e-06\n",
      "Epoch  12 [7900/10697 ( 73.9%)] Loss: 0.028731 L1: 0.016769 Grad: 0.119365 Thermal: 0.000510 LR: 9.46e-06\n",
      "Epoch  12 [7900/10697 ( 73.9%)] Loss: 0.028731 L1: 0.016769 Grad: 0.119365 Thermal: 0.000510 LR: 9.46e-06\n",
      "Epoch  12 [7950/10697 ( 74.3%)] Loss: 0.025283 L1: 0.015139 Grad: 0.101226 Thermal: 0.000434 LR: 9.46e-06\n",
      "Epoch  12 [7950/10697 ( 74.3%)] Loss: 0.025283 L1: 0.015139 Grad: 0.101226 Thermal: 0.000434 LR: 9.46e-06\n",
      "Epoch  12 [8000/10697 ( 74.8%)] Loss: 0.024051 L1: 0.013722 Grad: 0.103071 Thermal: 0.000433 LR: 9.46e-06\n",
      "Epoch  12 [8000/10697 ( 74.8%)] Loss: 0.024051 L1: 0.013722 Grad: 0.103071 Thermal: 0.000433 LR: 9.46e-06\n",
      "Epoch  12 [8050/10697 ( 75.3%)] Loss: 0.025884 L1: 0.015321 Grad: 0.105381 Thermal: 0.000492 LR: 9.46e-06\n",
      "Epoch  12 [8050/10697 ( 75.3%)] Loss: 0.025884 L1: 0.015321 Grad: 0.105381 Thermal: 0.000492 LR: 9.46e-06\n",
      "Epoch  12 [8100/10697 ( 75.7%)] Loss: 0.031362 L1: 0.018857 Grad: 0.124733 Thermal: 0.000638 LR: 9.46e-06\n",
      "Epoch  12 [8100/10697 ( 75.7%)] Loss: 0.031362 L1: 0.018857 Grad: 0.124733 Thermal: 0.000638 LR: 9.46e-06\n",
      "Epoch  12 [8150/10697 ( 76.2%)] Loss: 0.032622 L1: 0.018403 Grad: 0.141854 Thermal: 0.000681 LR: 9.46e-06\n",
      "Epoch  12 [8150/10697 ( 76.2%)] Loss: 0.032622 L1: 0.018403 Grad: 0.141854 Thermal: 0.000681 LR: 9.46e-06\n",
      "Epoch  12 [8200/10697 ( 76.7%)] Loss: 0.029810 L1: 0.017100 Grad: 0.126841 Thermal: 0.000528 LR: 9.46e-06\n",
      "Epoch  12 [8200/10697 ( 76.7%)] Loss: 0.029810 L1: 0.017100 Grad: 0.126841 Thermal: 0.000528 LR: 9.46e-06\n",
      "Epoch  12 [8250/10697 ( 77.1%)] Loss: 0.026647 L1: 0.015179 Grad: 0.114463 Thermal: 0.000442 LR: 9.46e-06\n",
      "Epoch  12 [8250/10697 ( 77.1%)] Loss: 0.026647 L1: 0.015179 Grad: 0.114463 Thermal: 0.000442 LR: 9.46e-06\n",
      "Epoch  12 [8300/10697 ( 77.6%)] Loss: 0.028136 L1: 0.015688 Grad: 0.124200 Thermal: 0.000551 LR: 9.46e-06\n",
      "Epoch  12 [8300/10697 ( 77.6%)] Loss: 0.028136 L1: 0.015688 Grad: 0.124200 Thermal: 0.000551 LR: 9.46e-06\n",
      "Epoch  12 [8350/10697 ( 78.1%)] Loss: 0.027959 L1: 0.016343 Grad: 0.115924 Thermal: 0.000471 LR: 9.46e-06\n",
      "Epoch  12 [8350/10697 ( 78.1%)] Loss: 0.027959 L1: 0.016343 Grad: 0.115924 Thermal: 0.000471 LR: 9.46e-06\n",
      "Epoch  12 [8400/10697 ( 78.5%)] Loss: 0.028137 L1: 0.015792 Grad: 0.123213 Thermal: 0.000484 LR: 9.46e-06\n",
      "Epoch  12 [8400/10697 ( 78.5%)] Loss: 0.028137 L1: 0.015792 Grad: 0.123213 Thermal: 0.000484 LR: 9.46e-06\n",
      "Epoch  12 [8450/10697 ( 79.0%)] Loss: 0.027657 L1: 0.016136 Grad: 0.114971 Thermal: 0.000474 LR: 9.46e-06\n",
      "Epoch  12 [8450/10697 ( 79.0%)] Loss: 0.027657 L1: 0.016136 Grad: 0.114971 Thermal: 0.000474 LR: 9.46e-06\n",
      "Epoch  12 [8500/10697 ( 79.5%)] Loss: 0.027227 L1: 0.015690 Grad: 0.115150 Thermal: 0.000432 LR: 9.46e-06\n",
      "Epoch  12 [8500/10697 ( 79.5%)] Loss: 0.027227 L1: 0.015690 Grad: 0.115150 Thermal: 0.000432 LR: 9.46e-06\n",
      "Epoch  12 [8550/10697 ( 79.9%)] Loss: 0.026448 L1: 0.015801 Grad: 0.106222 Thermal: 0.000482 LR: 9.46e-06\n",
      "Epoch  12 [8550/10697 ( 79.9%)] Loss: 0.026448 L1: 0.015801 Grad: 0.106222 Thermal: 0.000482 LR: 9.46e-06\n",
      "Epoch  12 [8600/10697 ( 80.4%)] Loss: 0.027016 L1: 0.015670 Grad: 0.113213 Thermal: 0.000502 LR: 9.46e-06\n",
      "Epoch  12 [8600/10697 ( 80.4%)] Loss: 0.027016 L1: 0.015670 Grad: 0.113213 Thermal: 0.000502 LR: 9.46e-06\n",
      "Epoch  12 [8650/10697 ( 80.9%)] Loss: 0.028998 L1: 0.016834 Grad: 0.121395 Thermal: 0.000493 LR: 9.46e-06\n",
      "Epoch  12 [8650/10697 ( 80.9%)] Loss: 0.028998 L1: 0.016834 Grad: 0.121395 Thermal: 0.000493 LR: 9.46e-06\n",
      "Epoch  12 [8700/10697 ( 81.3%)] Loss: 0.025302 L1: 0.015097 Grad: 0.101834 Thermal: 0.000423 LR: 9.46e-06\n",
      "Epoch  12 [8700/10697 ( 81.3%)] Loss: 0.025302 L1: 0.015097 Grad: 0.101834 Thermal: 0.000423 LR: 9.46e-06\n",
      "Epoch  12 [8750/10697 ( 81.8%)] Loss: 0.025803 L1: 0.015358 Grad: 0.104240 Thermal: 0.000425 LR: 9.46e-06\n",
      "Epoch  12 [8750/10697 ( 81.8%)] Loss: 0.025803 L1: 0.015358 Grad: 0.104240 Thermal: 0.000425 LR: 9.46e-06\n",
      "Epoch  12 [8800/10697 ( 82.3%)] Loss: 0.027903 L1: 0.016681 Grad: 0.111955 Thermal: 0.000523 LR: 9.46e-06\n",
      "Epoch  12 [8800/10697 ( 82.3%)] Loss: 0.027903 L1: 0.016681 Grad: 0.111955 Thermal: 0.000523 LR: 9.46e-06\n",
      "Epoch  12 [8850/10697 ( 82.7%)] Loss: 0.025349 L1: 0.015166 Grad: 0.101620 Thermal: 0.000420 LR: 9.46e-06\n",
      "Epoch  12 [8850/10697 ( 82.7%)] Loss: 0.025349 L1: 0.015166 Grad: 0.101620 Thermal: 0.000420 LR: 9.46e-06\n",
      "Epoch  12 [8900/10697 ( 83.2%)] Loss: 0.026601 L1: 0.016023 Grad: 0.105541 Thermal: 0.000482 LR: 9.46e-06\n",
      "Epoch  12 [8900/10697 ( 83.2%)] Loss: 0.026601 L1: 0.016023 Grad: 0.105541 Thermal: 0.000482 LR: 9.46e-06\n",
      "Epoch  12 [8950/10697 ( 83.7%)] Loss: 0.024689 L1: 0.014553 Grad: 0.101156 Thermal: 0.000399 LR: 9.46e-06\n",
      "Epoch  12 [8950/10697 ( 83.7%)] Loss: 0.024689 L1: 0.014553 Grad: 0.101156 Thermal: 0.000399 LR: 9.46e-06\n",
      "Epoch  12 [9000/10697 ( 84.1%)] Loss: 0.024748 L1: 0.014284 Grad: 0.104458 Thermal: 0.000362 LR: 9.46e-06\n",
      "Epoch  12 [9000/10697 ( 84.1%)] Loss: 0.024748 L1: 0.014284 Grad: 0.104458 Thermal: 0.000362 LR: 9.46e-06\n",
      "Epoch  12 [9050/10697 ( 84.6%)] Loss: 0.024827 L1: 0.014203 Grad: 0.106050 Thermal: 0.000385 LR: 9.46e-06\n",
      "Epoch  12 [9050/10697 ( 84.6%)] Loss: 0.024827 L1: 0.014203 Grad: 0.106050 Thermal: 0.000385 LR: 9.46e-06\n",
      "Epoch  12 [9100/10697 ( 85.1%)] Loss: 0.025941 L1: 0.015247 Grad: 0.106711 Thermal: 0.000460 LR: 9.46e-06\n",
      "Epoch  12 [9100/10697 ( 85.1%)] Loss: 0.025941 L1: 0.015247 Grad: 0.106711 Thermal: 0.000460 LR: 9.46e-06\n",
      "Epoch  12 [9150/10697 ( 85.5%)] Loss: 0.039977 L1: 0.022803 Grad: 0.171245 Thermal: 0.000994 LR: 9.46e-06\n",
      "Epoch  12 [9150/10697 ( 85.5%)] Loss: 0.039977 L1: 0.022803 Grad: 0.171245 Thermal: 0.000994 LR: 9.46e-06\n",
      "Epoch  12 [9200/10697 ( 86.0%)] Loss: 0.032561 L1: 0.018731 Grad: 0.137936 Thermal: 0.000729 LR: 9.46e-06\n",
      "Epoch  12 [9200/10697 ( 86.0%)] Loss: 0.032561 L1: 0.018731 Grad: 0.137936 Thermal: 0.000729 LR: 9.46e-06\n",
      "Epoch  12 [9250/10697 ( 86.5%)] Loss: 0.019052 L1: 0.011115 Grad: 0.079228 Thermal: 0.000269 LR: 9.46e-06\n",
      "Epoch  12 [9250/10697 ( 86.5%)] Loss: 0.019052 L1: 0.011115 Grad: 0.079228 Thermal: 0.000269 LR: 9.46e-06\n",
      "Epoch  12 [9300/10697 ( 86.9%)] Loss: 0.034258 L1: 0.019878 Grad: 0.143313 Thermal: 0.000983 LR: 9.46e-06\n",
      "Epoch  12 [9300/10697 ( 86.9%)] Loss: 0.034258 L1: 0.019878 Grad: 0.143313 Thermal: 0.000983 LR: 9.46e-06\n",
      "Epoch  12 [9350/10697 ( 87.4%)] Loss: 0.030930 L1: 0.018124 Grad: 0.127748 Thermal: 0.000612 LR: 9.46e-06\n",
      "Epoch  12 [9350/10697 ( 87.4%)] Loss: 0.030930 L1: 0.018124 Grad: 0.127748 Thermal: 0.000612 LR: 9.46e-06\n",
      "Epoch  12 [9400/10697 ( 87.9%)] Loss: 0.029750 L1: 0.017514 Grad: 0.122078 Thermal: 0.000553 LR: 9.46e-06\n",
      "Epoch  12 [9400/10697 ( 87.9%)] Loss: 0.029750 L1: 0.017514 Grad: 0.122078 Thermal: 0.000553 LR: 9.46e-06\n",
      "Epoch  12 [9450/10697 ( 88.3%)] Loss: 0.027232 L1: 0.015758 Grad: 0.114521 Thermal: 0.000449 LR: 9.46e-06\n",
      "Epoch  12 [9450/10697 ( 88.3%)] Loss: 0.027232 L1: 0.015758 Grad: 0.114521 Thermal: 0.000449 LR: 9.46e-06\n",
      "Epoch  12 [9500/10697 ( 88.8%)] Loss: 0.024901 L1: 0.014626 Grad: 0.102555 Thermal: 0.000388 LR: 9.46e-06\n",
      "Epoch  12 [9500/10697 ( 88.8%)] Loss: 0.024901 L1: 0.014626 Grad: 0.102555 Thermal: 0.000388 LR: 9.46e-06\n",
      "Epoch  12 [9550/10697 ( 89.3%)] Loss: 0.022888 L1: 0.013566 Grad: 0.093042 Thermal: 0.000350 LR: 9.46e-06\n",
      "Epoch  12 [9550/10697 ( 89.3%)] Loss: 0.022888 L1: 0.013566 Grad: 0.093042 Thermal: 0.000350 LR: 9.46e-06\n",
      "Epoch  12 [9600/10697 ( 89.7%)] Loss: 0.028017 L1: 0.016543 Grad: 0.114489 Thermal: 0.000502 LR: 9.46e-06\n",
      "Epoch  12 [9600/10697 ( 89.7%)] Loss: 0.028017 L1: 0.016543 Grad: 0.114489 Thermal: 0.000502 LR: 9.46e-06\n",
      "Epoch  12 [9650/10697 ( 90.2%)] Loss: 0.019076 L1: 0.011055 Grad: 0.080091 Thermal: 0.000246 LR: 9.46e-06\n",
      "Epoch  12 [9650/10697 ( 90.2%)] Loss: 0.019076 L1: 0.011055 Grad: 0.080091 Thermal: 0.000246 LR: 9.46e-06\n",
      "Epoch  12 [9700/10697 ( 90.7%)] Loss: 0.021960 L1: 0.012641 Grad: 0.093011 Thermal: 0.000368 LR: 9.46e-06\n",
      "Epoch  12 [9700/10697 ( 90.7%)] Loss: 0.021960 L1: 0.012641 Grad: 0.093011 Thermal: 0.000368 LR: 9.46e-06\n",
      "Epoch  12 [9750/10697 ( 91.1%)] Loss: 0.024069 L1: 0.014168 Grad: 0.098826 Thermal: 0.000377 LR: 9.46e-06\n",
      "Epoch  12 [9750/10697 ( 91.1%)] Loss: 0.024069 L1: 0.014168 Grad: 0.098826 Thermal: 0.000377 LR: 9.46e-06\n",
      "Epoch  12 [9800/10697 ( 91.6%)] Loss: 0.033261 L1: 0.019392 Grad: 0.138329 Thermal: 0.000721 LR: 9.46e-06\n",
      "Epoch  12 [9800/10697 ( 91.6%)] Loss: 0.033261 L1: 0.019392 Grad: 0.138329 Thermal: 0.000721 LR: 9.46e-06\n",
      "Epoch  12 [9850/10697 ( 92.1%)] Loss: 0.028744 L1: 0.016941 Grad: 0.117767 Thermal: 0.000532 LR: 9.46e-06\n",
      "Epoch  12 [9850/10697 ( 92.1%)] Loss: 0.028744 L1: 0.016941 Grad: 0.117767 Thermal: 0.000532 LR: 9.46e-06\n",
      "Epoch  12 [9900/10697 ( 92.5%)] Loss: 0.025946 L1: 0.015251 Grad: 0.106732 Thermal: 0.000440 LR: 9.46e-06\n",
      "Epoch  12 [9900/10697 ( 92.5%)] Loss: 0.025946 L1: 0.015251 Grad: 0.106732 Thermal: 0.000440 LR: 9.46e-06\n",
      "Epoch  12 [9950/10697 ( 93.0%)] Loss: 0.024901 L1: 0.014854 Grad: 0.100216 Thermal: 0.000502 LR: 9.46e-06\n",
      "Epoch  12 [9950/10697 ( 93.0%)] Loss: 0.024901 L1: 0.014854 Grad: 0.100216 Thermal: 0.000502 LR: 9.46e-06\n",
      "Epoch  12 [10000/10697 ( 93.5%)] Loss: 0.026792 L1: 0.015924 Grad: 0.108442 Thermal: 0.000463 LR: 9.46e-06\n",
      "Epoch  12 [10000/10697 ( 93.5%)] Loss: 0.026792 L1: 0.015924 Grad: 0.108442 Thermal: 0.000463 LR: 9.46e-06\n",
      "Epoch  12 [10050/10697 ( 94.0%)] Loss: 0.029288 L1: 0.017369 Grad: 0.118910 Thermal: 0.000565 LR: 9.46e-06\n",
      "Epoch  12 [10050/10697 ( 94.0%)] Loss: 0.029288 L1: 0.017369 Grad: 0.118910 Thermal: 0.000565 LR: 9.46e-06\n",
      "Epoch  12 [10100/10697 ( 94.4%)] Loss: 0.030493 L1: 0.017547 Grad: 0.129154 Thermal: 0.000602 LR: 9.46e-06\n",
      "Epoch  12 [10100/10697 ( 94.4%)] Loss: 0.030493 L1: 0.017547 Grad: 0.129154 Thermal: 0.000602 LR: 9.46e-06\n",
      "Epoch  12 [10150/10697 ( 94.9%)] Loss: 0.032514 L1: 0.018573 Grad: 0.139102 Thermal: 0.000626 LR: 9.46e-06\n",
      "Epoch  12 [10150/10697 ( 94.9%)] Loss: 0.032514 L1: 0.018573 Grad: 0.139102 Thermal: 0.000626 LR: 9.46e-06\n",
      "Epoch  12 [10200/10697 ( 95.4%)] Loss: 0.024591 L1: 0.014158 Grad: 0.104121 Thermal: 0.000411 LR: 9.46e-06\n",
      "Epoch  12 [10200/10697 ( 95.4%)] Loss: 0.024591 L1: 0.014158 Grad: 0.104121 Thermal: 0.000411 LR: 9.46e-06\n",
      "Epoch  12 [10250/10697 ( 95.8%)] Loss: 0.023206 L1: 0.013446 Grad: 0.097413 Thermal: 0.000375 LR: 9.46e-06\n",
      "Epoch  12 [10250/10697 ( 95.8%)] Loss: 0.023206 L1: 0.013446 Grad: 0.097413 Thermal: 0.000375 LR: 9.46e-06\n",
      "Epoch  12 [10300/10697 ( 96.3%)] Loss: 0.025802 L1: 0.015604 Grad: 0.101755 Thermal: 0.000442 LR: 9.46e-06\n",
      "Epoch  12 [10300/10697 ( 96.3%)] Loss: 0.025802 L1: 0.015604 Grad: 0.101755 Thermal: 0.000442 LR: 9.46e-06\n",
      "Epoch  12 [10350/10697 ( 96.8%)] Loss: 0.027933 L1: 0.016456 Grad: 0.114519 Thermal: 0.000506 LR: 9.46e-06\n",
      "Epoch  12 [10350/10697 ( 96.8%)] Loss: 0.027933 L1: 0.016456 Grad: 0.114519 Thermal: 0.000506 LR: 9.46e-06\n",
      "Epoch  12 [10400/10697 ( 97.2%)] Loss: 0.036065 L1: 0.020906 Grad: 0.151162 Thermal: 0.000866 LR: 9.46e-06\n",
      "Epoch  12 [10400/10697 ( 97.2%)] Loss: 0.036065 L1: 0.020906 Grad: 0.151162 Thermal: 0.000866 LR: 9.46e-06\n",
      "Epoch  12 [10450/10697 ( 97.7%)] Loss: 0.033470 L1: 0.019109 Grad: 0.143266 Thermal: 0.000683 LR: 9.46e-06\n",
      "Epoch  12 [10450/10697 ( 97.7%)] Loss: 0.033470 L1: 0.019109 Grad: 0.143266 Thermal: 0.000683 LR: 9.46e-06\n",
      "Epoch  12 [10500/10697 ( 98.2%)] Loss: 0.025175 L1: 0.014454 Grad: 0.107012 Thermal: 0.000407 LR: 9.46e-06\n",
      "Epoch  12 [10500/10697 ( 98.2%)] Loss: 0.025175 L1: 0.014454 Grad: 0.107012 Thermal: 0.000407 LR: 9.46e-06\n",
      "Epoch  12 [10550/10697 ( 98.6%)] Loss: 0.027912 L1: 0.015935 Grad: 0.119515 Thermal: 0.000495 LR: 9.46e-06\n",
      "Epoch  12 [10550/10697 ( 98.6%)] Loss: 0.027912 L1: 0.015935 Grad: 0.119515 Thermal: 0.000495 LR: 9.46e-06\n",
      "Epoch  12 [10600/10697 ( 99.1%)] Loss: 0.029410 L1: 0.017221 Grad: 0.121619 Thermal: 0.000542 LR: 9.46e-06\n",
      "Epoch  12 [10600/10697 ( 99.1%)] Loss: 0.029410 L1: 0.017221 Grad: 0.121619 Thermal: 0.000542 LR: 9.46e-06\n",
      "Epoch  12 [10650/10697 ( 99.6%)] Loss: 0.028899 L1: 0.016606 Grad: 0.122658 Thermal: 0.000542 LR: 9.46e-06\n",
      "Epoch  12 [10650/10697 ( 99.6%)] Loss: 0.028899 L1: 0.016606 Grad: 0.122658 Thermal: 0.000542 LR: 9.46e-06\n",
      "Epoch  12 Summary: Loss=0.026670 (L1:0.0155, Grad:0.1112, Thermal:0.0005) Val_PSNR=0.00dB Best=33.82dB Time=46.6min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  12 Summary: Loss=0.026670 (L1:0.0155, Grad:0.1112, Thermal:0.0005) Val_PSNR=0.00dB Best=33.82dB Time=46.6min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  13 [   0/10697 (  0.0%)] Loss: 0.028622 L1: 0.016645 Grad: 0.119540 Thermal: 0.000467 LR: 9.37e-06\n",
      "Epoch  13 [   0/10697 (  0.0%)] Loss: 0.028622 L1: 0.016645 Grad: 0.119540 Thermal: 0.000467 LR: 9.37e-06\n",
      "Epoch  13 [  50/10697 (  0.5%)] Loss: 0.026238 L1: 0.015071 Grad: 0.111440 Thermal: 0.000452 LR: 9.37e-06\n",
      "Epoch  13 [  50/10697 (  0.5%)] Loss: 0.026238 L1: 0.015071 Grad: 0.111440 Thermal: 0.000452 LR: 9.37e-06\n",
      "Epoch  13 [ 100/10697 (  0.9%)] Loss: 0.026614 L1: 0.015838 Grad: 0.107527 Thermal: 0.000460 LR: 9.37e-06\n",
      "Epoch  13 [ 100/10697 (  0.9%)] Loss: 0.026614 L1: 0.015838 Grad: 0.107527 Thermal: 0.000460 LR: 9.37e-06\n",
      "Epoch  13 [ 150/10697 (  1.4%)] Loss: 0.025685 L1: 0.014723 Grad: 0.109413 Thermal: 0.000423 LR: 9.37e-06\n",
      "Epoch  13 [ 150/10697 (  1.4%)] Loss: 0.025685 L1: 0.014723 Grad: 0.109413 Thermal: 0.000423 LR: 9.37e-06\n",
      "Epoch  13 [ 200/10697 (  1.9%)] Loss: 0.024995 L1: 0.014180 Grad: 0.107950 Thermal: 0.000413 LR: 9.37e-06\n",
      "Epoch  13 [ 200/10697 (  1.9%)] Loss: 0.024995 L1: 0.014180 Grad: 0.107950 Thermal: 0.000413 LR: 9.37e-06\n",
      "Epoch  13 [ 250/10697 (  2.3%)] Loss: 0.023320 L1: 0.013462 Grad: 0.098400 Thermal: 0.000357 LR: 9.37e-06\n",
      "Epoch  13 [ 250/10697 (  2.3%)] Loss: 0.023320 L1: 0.013462 Grad: 0.098400 Thermal: 0.000357 LR: 9.37e-06\n",
      "Epoch  13 [ 300/10697 (  2.8%)] Loss: 0.028722 L1: 0.016590 Grad: 0.121052 Thermal: 0.000529 LR: 9.37e-06\n",
      "Epoch  13 [ 300/10697 (  2.8%)] Loss: 0.028722 L1: 0.016590 Grad: 0.121052 Thermal: 0.000529 LR: 9.37e-06\n",
      "Epoch  13 [ 350/10697 (  3.3%)] Loss: 0.025245 L1: 0.014369 Grad: 0.108557 Thermal: 0.000414 LR: 9.37e-06\n",
      "Epoch  13 [ 350/10697 (  3.3%)] Loss: 0.025245 L1: 0.014369 Grad: 0.108557 Thermal: 0.000414 LR: 9.37e-06\n",
      "Epoch  13 [ 400/10697 (  3.7%)] Loss: 0.026709 L1: 0.015610 Grad: 0.110767 Thermal: 0.000451 LR: 9.37e-06\n",
      "Epoch  13 [ 400/10697 (  3.7%)] Loss: 0.026709 L1: 0.015610 Grad: 0.110767 Thermal: 0.000451 LR: 9.37e-06\n",
      "Epoch  13 [ 450/10697 (  4.2%)] Loss: 0.027015 L1: 0.015627 Grad: 0.113664 Thermal: 0.000430 LR: 9.37e-06\n",
      "Epoch  13 [ 450/10697 (  4.2%)] Loss: 0.027015 L1: 0.015627 Grad: 0.113664 Thermal: 0.000430 LR: 9.37e-06\n",
      "Epoch  13 [ 500/10697 (  4.7%)] Loss: 0.024119 L1: 0.014000 Grad: 0.100993 Thermal: 0.000396 LR: 9.37e-06\n",
      "Epoch  13 [ 500/10697 (  4.7%)] Loss: 0.024119 L1: 0.014000 Grad: 0.100993 Thermal: 0.000396 LR: 9.37e-06\n",
      "Epoch  13 [ 550/10697 (  5.1%)] Loss: 0.027371 L1: 0.015370 Grad: 0.119787 Thermal: 0.000447 LR: 9.37e-06\n",
      "Epoch  13 [ 550/10697 (  5.1%)] Loss: 0.027371 L1: 0.015370 Grad: 0.119787 Thermal: 0.000447 LR: 9.37e-06\n",
      "Epoch  13 [ 600/10697 (  5.6%)] Loss: 0.026246 L1: 0.015098 Grad: 0.111254 Thermal: 0.000456 LR: 9.37e-06\n",
      "Epoch  13 [ 600/10697 (  5.6%)] Loss: 0.026246 L1: 0.015098 Grad: 0.111254 Thermal: 0.000456 LR: 9.37e-06\n",
      "Epoch  13 [ 650/10697 (  6.1%)] Loss: 0.029844 L1: 0.017190 Grad: 0.126267 Thermal: 0.000551 LR: 9.37e-06\n",
      "Epoch  13 [ 650/10697 (  6.1%)] Loss: 0.029844 L1: 0.017190 Grad: 0.126267 Thermal: 0.000551 LR: 9.37e-06\n",
      "Epoch  13 [ 700/10697 (  6.5%)] Loss: 0.027985 L1: 0.016728 Grad: 0.112318 Thermal: 0.000511 LR: 9.37e-06\n",
      "Epoch  13 [ 700/10697 (  6.5%)] Loss: 0.027985 L1: 0.016728 Grad: 0.112318 Thermal: 0.000511 LR: 9.37e-06\n",
      "Epoch  13 [ 750/10697 (  7.0%)] Loss: 0.025037 L1: 0.014784 Grad: 0.102334 Thermal: 0.000395 LR: 9.37e-06\n",
      "Epoch  13 [ 750/10697 (  7.0%)] Loss: 0.025037 L1: 0.014784 Grad: 0.102334 Thermal: 0.000395 LR: 9.37e-06\n",
      "Epoch  13 [ 800/10697 (  7.5%)] Loss: 0.023485 L1: 0.013352 Grad: 0.101146 Thermal: 0.000361 LR: 9.37e-06\n",
      "Epoch  13 [ 800/10697 (  7.5%)] Loss: 0.023485 L1: 0.013352 Grad: 0.101146 Thermal: 0.000361 LR: 9.37e-06\n",
      "Epoch  13 [ 850/10697 (  7.9%)] Loss: 0.016887 L1: 0.009657 Grad: 0.072200 Thermal: 0.000212 LR: 9.37e-06\n",
      "Epoch  13 [ 850/10697 (  7.9%)] Loss: 0.016887 L1: 0.009657 Grad: 0.072200 Thermal: 0.000212 LR: 9.37e-06\n",
      "Epoch  13 [ 900/10697 (  8.4%)] Loss: 0.027996 L1: 0.016627 Grad: 0.113431 Thermal: 0.000509 LR: 9.37e-06\n",
      "Epoch  13 [ 900/10697 (  8.4%)] Loss: 0.027996 L1: 0.016627 Grad: 0.113431 Thermal: 0.000509 LR: 9.37e-06\n",
      "Epoch  13 [ 950/10697 (  8.9%)] Loss: 0.022924 L1: 0.013459 Grad: 0.094463 Thermal: 0.000376 LR: 9.37e-06\n",
      "Epoch  13 [ 950/10697 (  8.9%)] Loss: 0.022924 L1: 0.013459 Grad: 0.094463 Thermal: 0.000376 LR: 9.37e-06\n",
      "Epoch  13 [1000/10697 (  9.3%)] Loss: 0.023364 L1: 0.013479 Grad: 0.098667 Thermal: 0.000351 LR: 9.37e-06\n",
      "Epoch  13 [1000/10697 (  9.3%)] Loss: 0.023364 L1: 0.013479 Grad: 0.098667 Thermal: 0.000351 LR: 9.37e-06\n",
      "Epoch  13 [1050/10697 (  9.8%)] Loss: 0.029753 L1: 0.017434 Grad: 0.122915 Thermal: 0.000548 LR: 9.37e-06\n",
      "Epoch  13 [1050/10697 (  9.8%)] Loss: 0.029753 L1: 0.017434 Grad: 0.122915 Thermal: 0.000548 LR: 9.37e-06\n",
      "Epoch  13 [1100/10697 ( 10.3%)] Loss: 0.027461 L1: 0.016164 Grad: 0.112719 Thermal: 0.000492 LR: 9.37e-06\n",
      "Epoch  13 [1100/10697 ( 10.3%)] Loss: 0.027461 L1: 0.016164 Grad: 0.112719 Thermal: 0.000492 LR: 9.37e-06\n",
      "Epoch  13 [1150/10697 ( 10.8%)] Loss: 0.028139 L1: 0.016711 Grad: 0.114019 Thermal: 0.000519 LR: 9.37e-06\n",
      "Epoch  13 [1150/10697 ( 10.8%)] Loss: 0.028139 L1: 0.016711 Grad: 0.114019 Thermal: 0.000519 LR: 9.37e-06\n",
      "Epoch  13 [1200/10697 ( 11.2%)] Loss: 0.031825 L1: 0.018160 Grad: 0.136352 Thermal: 0.000602 LR: 9.37e-06\n",
      "Epoch  13 [1200/10697 ( 11.2%)] Loss: 0.031825 L1: 0.018160 Grad: 0.136352 Thermal: 0.000602 LR: 9.37e-06\n",
      "Epoch  13 [1250/10697 ( 11.7%)] Loss: 0.023743 L1: 0.013708 Grad: 0.100157 Thermal: 0.000388 LR: 9.37e-06\n",
      "Epoch  13 [1250/10697 ( 11.7%)] Loss: 0.023743 L1: 0.013708 Grad: 0.100157 Thermal: 0.000388 LR: 9.37e-06\n",
      "Epoch  13 [1300/10697 ( 12.2%)] Loss: 0.027558 L1: 0.016196 Grad: 0.113370 Thermal: 0.000497 LR: 9.37e-06\n",
      "Epoch  13 [1300/10697 ( 12.2%)] Loss: 0.027558 L1: 0.016196 Grad: 0.113370 Thermal: 0.000497 LR: 9.37e-06\n",
      "Epoch  13 [1350/10697 ( 12.6%)] Loss: 0.025031 L1: 0.014388 Grad: 0.106217 Thermal: 0.000427 LR: 9.37e-06\n",
      "Epoch  13 [1350/10697 ( 12.6%)] Loss: 0.025031 L1: 0.014388 Grad: 0.106217 Thermal: 0.000427 LR: 9.37e-06\n",
      "Epoch  13 [1400/10697 ( 13.1%)] Loss: 0.024403 L1: 0.014503 Grad: 0.098806 Thermal: 0.000383 LR: 9.37e-06\n",
      "Epoch  13 [1400/10697 ( 13.1%)] Loss: 0.024403 L1: 0.014503 Grad: 0.098806 Thermal: 0.000383 LR: 9.37e-06\n",
      "Epoch  13 [1450/10697 ( 13.6%)] Loss: 0.026945 L1: 0.016049 Grad: 0.108727 Thermal: 0.000468 LR: 9.37e-06\n",
      "Epoch  13 [1450/10697 ( 13.6%)] Loss: 0.026945 L1: 0.016049 Grad: 0.108727 Thermal: 0.000468 LR: 9.37e-06\n",
      "Epoch  13 [1500/10697 ( 14.0%)] Loss: 0.024503 L1: 0.014415 Grad: 0.100683 Thermal: 0.000378 LR: 9.37e-06\n",
      "Epoch  13 [1500/10697 ( 14.0%)] Loss: 0.024503 L1: 0.014415 Grad: 0.100683 Thermal: 0.000378 LR: 9.37e-06\n",
      "Epoch  13 [1550/10697 ( 14.5%)] Loss: 0.021991 L1: 0.012930 Grad: 0.090441 Thermal: 0.000343 LR: 9.37e-06\n",
      "Epoch  13 [1550/10697 ( 14.5%)] Loss: 0.021991 L1: 0.012930 Grad: 0.090441 Thermal: 0.000343 LR: 9.37e-06\n",
      "Epoch  13 [1600/10697 ( 15.0%)] Loss: 0.027151 L1: 0.015920 Grad: 0.112077 Thermal: 0.000472 LR: 9.37e-06\n",
      "Epoch  13 [1600/10697 ( 15.0%)] Loss: 0.027151 L1: 0.015920 Grad: 0.112077 Thermal: 0.000472 LR: 9.37e-06\n",
      "Epoch  13 [1650/10697 ( 15.4%)] Loss: 0.025360 L1: 0.014933 Grad: 0.104051 Thermal: 0.000442 LR: 9.37e-06\n",
      "Epoch  13 [1650/10697 ( 15.4%)] Loss: 0.025360 L1: 0.014933 Grad: 0.104051 Thermal: 0.000442 LR: 9.37e-06\n",
      "Epoch  13 [1700/10697 ( 15.9%)] Loss: 0.029245 L1: 0.016977 Grad: 0.122385 Thermal: 0.000590 LR: 9.37e-06\n",
      "Epoch  13 [1700/10697 ( 15.9%)] Loss: 0.029245 L1: 0.016977 Grad: 0.122385 Thermal: 0.000590 LR: 9.37e-06\n",
      "Epoch  13 [1750/10697 ( 16.4%)] Loss: 0.024016 L1: 0.013923 Grad: 0.100751 Thermal: 0.000370 LR: 9.37e-06\n",
      "Epoch  13 [1750/10697 ( 16.4%)] Loss: 0.024016 L1: 0.013923 Grad: 0.100751 Thermal: 0.000370 LR: 9.37e-06\n",
      "Epoch  13 [1800/10697 ( 16.8%)] Loss: 0.026746 L1: 0.015858 Grad: 0.108654 Thermal: 0.000447 LR: 9.37e-06\n",
      "Epoch  13 [1800/10697 ( 16.8%)] Loss: 0.026746 L1: 0.015858 Grad: 0.108654 Thermal: 0.000447 LR: 9.37e-06\n",
      "Epoch  13 [1850/10697 ( 17.3%)] Loss: 0.032673 L1: 0.018926 Grad: 0.137147 Thermal: 0.000640 LR: 9.37e-06\n",
      "Epoch  13 [1850/10697 ( 17.3%)] Loss: 0.032673 L1: 0.018926 Grad: 0.137147 Thermal: 0.000640 LR: 9.37e-06\n",
      "Epoch  13 [1900/10697 ( 17.8%)] Loss: 0.022291 L1: 0.013204 Grad: 0.090699 Thermal: 0.000337 LR: 9.37e-06\n",
      "Epoch  13 [1900/10697 ( 17.8%)] Loss: 0.022291 L1: 0.013204 Grad: 0.090699 Thermal: 0.000337 LR: 9.37e-06\n",
      "Epoch  13 [1950/10697 ( 18.2%)] Loss: 0.030416 L1: 0.017601 Grad: 0.127858 Thermal: 0.000573 LR: 9.37e-06\n",
      "Epoch  13 [1950/10697 ( 18.2%)] Loss: 0.030416 L1: 0.017601 Grad: 0.127858 Thermal: 0.000573 LR: 9.37e-06\n",
      "Epoch  13 [2000/10697 ( 18.7%)] Loss: 0.025224 L1: 0.014250 Grad: 0.109509 Thermal: 0.000469 LR: 9.37e-06\n",
      "Epoch  13 [2000/10697 ( 18.7%)] Loss: 0.025224 L1: 0.014250 Grad: 0.109509 Thermal: 0.000469 LR: 9.37e-06\n",
      "Epoch  13 [2050/10697 ( 19.2%)] Loss: 0.028221 L1: 0.016097 Grad: 0.121030 Thermal: 0.000431 LR: 9.37e-06\n",
      "Epoch  13 [2050/10697 ( 19.2%)] Loss: 0.028221 L1: 0.016097 Grad: 0.121030 Thermal: 0.000431 LR: 9.37e-06\n",
      "Epoch  13 [2100/10697 ( 19.6%)] Loss: 0.021209 L1: 0.012256 Grad: 0.089379 Thermal: 0.000297 LR: 9.37e-06\n",
      "Epoch  13 [2100/10697 ( 19.6%)] Loss: 0.021209 L1: 0.012256 Grad: 0.089379 Thermal: 0.000297 LR: 9.37e-06\n",
      "Epoch  13 [2150/10697 ( 20.1%)] Loss: 0.029504 L1: 0.017322 Grad: 0.121553 Thermal: 0.000533 LR: 9.37e-06\n",
      "Epoch  13 [2150/10697 ( 20.1%)] Loss: 0.029504 L1: 0.017322 Grad: 0.121553 Thermal: 0.000533 LR: 9.37e-06\n",
      "Epoch  13 [2200/10697 ( 20.6%)] Loss: 0.031353 L1: 0.018578 Grad: 0.127435 Thermal: 0.000632 LR: 9.37e-06\n",
      "Epoch  13 [2200/10697 ( 20.6%)] Loss: 0.031353 L1: 0.018578 Grad: 0.127435 Thermal: 0.000632 LR: 9.37e-06\n",
      "Epoch  13 [2250/10697 ( 21.0%)] Loss: 0.028117 L1: 0.016051 Grad: 0.120431 Thermal: 0.000452 LR: 9.37e-06\n",
      "Epoch  13 [2250/10697 ( 21.0%)] Loss: 0.028117 L1: 0.016051 Grad: 0.120431 Thermal: 0.000452 LR: 9.37e-06\n",
      "Epoch  13 [2300/10697 ( 21.5%)] Loss: 0.024094 L1: 0.013907 Grad: 0.101678 Thermal: 0.000387 LR: 9.37e-06\n",
      "Epoch  13 [2300/10697 ( 21.5%)] Loss: 0.024094 L1: 0.013907 Grad: 0.101678 Thermal: 0.000387 LR: 9.37e-06\n",
      "Epoch  13 [2350/10697 ( 22.0%)] Loss: 0.026481 L1: 0.015488 Grad: 0.109718 Thermal: 0.000437 LR: 9.37e-06\n",
      "Epoch  13 [2350/10697 ( 22.0%)] Loss: 0.026481 L1: 0.015488 Grad: 0.109718 Thermal: 0.000437 LR: 9.37e-06\n",
      "Epoch  13 [2400/10697 ( 22.4%)] Loss: 0.028191 L1: 0.015951 Grad: 0.122153 Thermal: 0.000503 LR: 9.37e-06\n",
      "Epoch  13 [2400/10697 ( 22.4%)] Loss: 0.028191 L1: 0.015951 Grad: 0.122153 Thermal: 0.000503 LR: 9.37e-06\n",
      "Epoch  13 [2450/10697 ( 22.9%)] Loss: 0.034495 L1: 0.019596 Grad: 0.148625 Thermal: 0.000731 LR: 9.37e-06\n",
      "Epoch  13 [2450/10697 ( 22.9%)] Loss: 0.034495 L1: 0.019596 Grad: 0.148625 Thermal: 0.000731 LR: 9.37e-06\n",
      "Epoch  13 [2500/10697 ( 23.4%)] Loss: 0.023335 L1: 0.013584 Grad: 0.097322 Thermal: 0.000369 LR: 9.37e-06\n",
      "Epoch  13 [2500/10697 ( 23.4%)] Loss: 0.023335 L1: 0.013584 Grad: 0.097322 Thermal: 0.000369 LR: 9.37e-06\n",
      "Epoch  13 [2550/10697 ( 23.8%)] Loss: 0.026748 L1: 0.015758 Grad: 0.109665 Thermal: 0.000463 LR: 9.37e-06\n",
      "Epoch  13 [2550/10697 ( 23.8%)] Loss: 0.026748 L1: 0.015758 Grad: 0.109665 Thermal: 0.000463 LR: 9.37e-06\n",
      "Epoch  13 [2600/10697 ( 24.3%)] Loss: 0.022509 L1: 0.013246 Grad: 0.092446 Thermal: 0.000361 LR: 9.37e-06\n",
      "Epoch  13 [2600/10697 ( 24.3%)] Loss: 0.022509 L1: 0.013246 Grad: 0.092446 Thermal: 0.000361 LR: 9.37e-06\n",
      "Epoch  13 [2650/10697 ( 24.8%)] Loss: 0.028812 L1: 0.016610 Grad: 0.121766 Thermal: 0.000500 LR: 9.37e-06\n",
      "Epoch  13 [2650/10697 ( 24.8%)] Loss: 0.028812 L1: 0.016610 Grad: 0.121766 Thermal: 0.000500 LR: 9.37e-06\n",
      "Epoch  13 [2700/10697 ( 25.2%)] Loss: 0.021617 L1: 0.012598 Grad: 0.090005 Thermal: 0.000363 LR: 9.37e-06\n",
      "Epoch  13 [2700/10697 ( 25.2%)] Loss: 0.021617 L1: 0.012598 Grad: 0.090005 Thermal: 0.000363 LR: 9.37e-06\n",
      "Epoch  13 [2750/10697 ( 25.7%)] Loss: 0.025152 L1: 0.014675 Grad: 0.104547 Thermal: 0.000434 LR: 9.37e-06\n",
      "Epoch  13 [2750/10697 ( 25.7%)] Loss: 0.025152 L1: 0.014675 Grad: 0.104547 Thermal: 0.000434 LR: 9.37e-06\n",
      "Epoch  13 [2800/10697 ( 26.2%)] Loss: 0.027371 L1: 0.015895 Grad: 0.114522 Thermal: 0.000473 LR: 9.37e-06\n",
      "Epoch  13 [2800/10697 ( 26.2%)] Loss: 0.027371 L1: 0.015895 Grad: 0.114522 Thermal: 0.000473 LR: 9.37e-06\n",
      "Epoch  13 [2850/10697 ( 26.6%)] Loss: 0.026557 L1: 0.016079 Grad: 0.104541 Thermal: 0.000477 LR: 9.37e-06\n",
      "Epoch  13 [2850/10697 ( 26.6%)] Loss: 0.026557 L1: 0.016079 Grad: 0.104541 Thermal: 0.000477 LR: 9.37e-06\n",
      "Epoch  13 [2900/10697 ( 27.1%)] Loss: 0.027542 L1: 0.015514 Grad: 0.120067 Thermal: 0.000433 LR: 9.37e-06\n",
      "Epoch  13 [2900/10697 ( 27.1%)] Loss: 0.027542 L1: 0.015514 Grad: 0.120067 Thermal: 0.000433 LR: 9.37e-06\n",
      "Epoch  13 [2950/10697 ( 27.6%)] Loss: 0.027648 L1: 0.016404 Grad: 0.112190 Thermal: 0.000486 LR: 9.37e-06\n",
      "Epoch  13 [2950/10697 ( 27.6%)] Loss: 0.027648 L1: 0.016404 Grad: 0.112190 Thermal: 0.000486 LR: 9.37e-06\n",
      "Epoch  13 [3000/10697 ( 28.0%)] Loss: 0.024096 L1: 0.014204 Grad: 0.098733 Thermal: 0.000379 LR: 9.37e-06\n",
      "Epoch  13 [3000/10697 ( 28.0%)] Loss: 0.024096 L1: 0.014204 Grad: 0.098733 Thermal: 0.000379 LR: 9.37e-06\n",
      "Epoch  13 [3050/10697 ( 28.5%)] Loss: 0.024940 L1: 0.014428 Grad: 0.104927 Thermal: 0.000379 LR: 9.37e-06\n",
      "Epoch  13 [3050/10697 ( 28.5%)] Loss: 0.024940 L1: 0.014428 Grad: 0.104927 Thermal: 0.000379 LR: 9.37e-06\n",
      "Epoch  13 [3100/10697 ( 29.0%)] Loss: 0.024604 L1: 0.014126 Grad: 0.104592 Thermal: 0.000368 LR: 9.37e-06\n",
      "Epoch  13 [3100/10697 ( 29.0%)] Loss: 0.024604 L1: 0.014126 Grad: 0.104592 Thermal: 0.000368 LR: 9.37e-06\n",
      "Epoch  13 [3150/10697 ( 29.4%)] Loss: 0.022609 L1: 0.013245 Grad: 0.093474 Thermal: 0.000349 LR: 9.37e-06\n",
      "Epoch  13 [3150/10697 ( 29.4%)] Loss: 0.022609 L1: 0.013245 Grad: 0.093474 Thermal: 0.000349 LR: 9.37e-06\n",
      "Epoch  13 [3200/10697 ( 29.9%)] Loss: 0.029648 L1: 0.017323 Grad: 0.122970 Thermal: 0.000546 LR: 9.37e-06\n",
      "Epoch  13 [3200/10697 ( 29.9%)] Loss: 0.029648 L1: 0.017323 Grad: 0.122970 Thermal: 0.000546 LR: 9.37e-06\n",
      "Epoch  13 [3250/10697 ( 30.4%)] Loss: 0.025091 L1: 0.014927 Grad: 0.101425 Thermal: 0.000419 LR: 9.37e-06\n",
      "Epoch  13 [3250/10697 ( 30.4%)] Loss: 0.025091 L1: 0.014927 Grad: 0.101425 Thermal: 0.000419 LR: 9.37e-06\n",
      "Epoch  13 [3300/10697 ( 30.8%)] Loss: 0.026297 L1: 0.015755 Grad: 0.105205 Thermal: 0.000446 LR: 9.37e-06\n",
      "Epoch  13 [3300/10697 ( 30.8%)] Loss: 0.026297 L1: 0.015755 Grad: 0.105205 Thermal: 0.000446 LR: 9.37e-06\n",
      "Epoch  13 [3350/10697 ( 31.3%)] Loss: 0.028556 L1: 0.016054 Grad: 0.124769 Thermal: 0.000487 LR: 9.37e-06\n",
      "Epoch  13 [3350/10697 ( 31.3%)] Loss: 0.028556 L1: 0.016054 Grad: 0.124769 Thermal: 0.000487 LR: 9.37e-06\n",
      "Epoch  13 [3400/10697 ( 31.8%)] Loss: 0.023517 L1: 0.013712 Grad: 0.097869 Thermal: 0.000368 LR: 9.37e-06\n",
      "Epoch  13 [3400/10697 ( 31.8%)] Loss: 0.023517 L1: 0.013712 Grad: 0.097869 Thermal: 0.000368 LR: 9.37e-06\n",
      "Epoch  13 [3450/10697 ( 32.3%)] Loss: 0.029592 L1: 0.017210 Grad: 0.123548 Thermal: 0.000544 LR: 9.37e-06\n",
      "Epoch  13 [3450/10697 ( 32.3%)] Loss: 0.029592 L1: 0.017210 Grad: 0.123548 Thermal: 0.000544 LR: 9.37e-06\n",
      "Epoch  13 [3500/10697 ( 32.7%)] Loss: 0.027037 L1: 0.015931 Grad: 0.110821 Thermal: 0.000484 LR: 9.37e-06\n",
      "Epoch  13 [3500/10697 ( 32.7%)] Loss: 0.027037 L1: 0.015931 Grad: 0.110821 Thermal: 0.000484 LR: 9.37e-06\n",
      "Epoch  13 [3550/10697 ( 33.2%)] Loss: 0.029138 L1: 0.017468 Grad: 0.116431 Thermal: 0.000538 LR: 9.37e-06\n",
      "Epoch  13 [3550/10697 ( 33.2%)] Loss: 0.029138 L1: 0.017468 Grad: 0.116431 Thermal: 0.000538 LR: 9.37e-06\n",
      "Epoch  13 [3600/10697 ( 33.7%)] Loss: 0.034293 L1: 0.019266 Grad: 0.149888 Thermal: 0.000782 LR: 9.37e-06\n",
      "Epoch  13 [3600/10697 ( 33.7%)] Loss: 0.034293 L1: 0.019266 Grad: 0.149888 Thermal: 0.000782 LR: 9.37e-06\n",
      "Epoch  13 [3650/10697 ( 34.1%)] Loss: 0.026044 L1: 0.015480 Grad: 0.105399 Thermal: 0.000473 LR: 9.37e-06\n",
      "Epoch  13 [3650/10697 ( 34.1%)] Loss: 0.026044 L1: 0.015480 Grad: 0.105399 Thermal: 0.000473 LR: 9.37e-06\n",
      "Epoch  13 [3700/10697 ( 34.6%)] Loss: 0.029134 L1: 0.017217 Grad: 0.118908 Thermal: 0.000528 LR: 9.37e-06\n",
      "Epoch  13 [3700/10697 ( 34.6%)] Loss: 0.029134 L1: 0.017217 Grad: 0.118908 Thermal: 0.000528 LR: 9.37e-06\n",
      "Epoch  13 [3750/10697 ( 35.1%)] Loss: 0.027543 L1: 0.016269 Grad: 0.112506 Thermal: 0.000467 LR: 9.37e-06\n",
      "Epoch  13 [3750/10697 ( 35.1%)] Loss: 0.027543 L1: 0.016269 Grad: 0.112506 Thermal: 0.000467 LR: 9.37e-06\n",
      "Epoch  13 [3800/10697 ( 35.5%)] Loss: 0.018407 L1: 0.010761 Grad: 0.076337 Thermal: 0.000242 LR: 9.37e-06\n",
      "Epoch  13 [3800/10697 ( 35.5%)] Loss: 0.018407 L1: 0.010761 Grad: 0.076337 Thermal: 0.000242 LR: 9.37e-06\n",
      "Epoch  13 [3850/10697 ( 36.0%)] Loss: 0.030968 L1: 0.018165 Grad: 0.127736 Thermal: 0.000598 LR: 9.37e-06\n",
      "Epoch  13 [3850/10697 ( 36.0%)] Loss: 0.030968 L1: 0.018165 Grad: 0.127736 Thermal: 0.000598 LR: 9.37e-06\n",
      "Epoch  13 [3900/10697 ( 36.5%)] Loss: 0.027090 L1: 0.015789 Grad: 0.112780 Thermal: 0.000451 LR: 9.37e-06\n",
      "Epoch  13 [3900/10697 ( 36.5%)] Loss: 0.027090 L1: 0.015789 Grad: 0.112780 Thermal: 0.000451 LR: 9.37e-06\n",
      "Epoch  13 [3950/10697 ( 36.9%)] Loss: 0.028906 L1: 0.016930 Grad: 0.119480 Thermal: 0.000547 LR: 9.37e-06\n",
      "Epoch  13 [3950/10697 ( 36.9%)] Loss: 0.028906 L1: 0.016930 Grad: 0.119480 Thermal: 0.000547 LR: 9.37e-06\n",
      "Epoch  13 [4000/10697 ( 37.4%)] Loss: 0.024332 L1: 0.014821 Grad: 0.094915 Thermal: 0.000390 LR: 9.37e-06\n",
      "Epoch  13 [4000/10697 ( 37.4%)] Loss: 0.024332 L1: 0.014821 Grad: 0.094915 Thermal: 0.000390 LR: 9.37e-06\n",
      "Epoch  13 [4050/10697 ( 37.9%)] Loss: 0.028502 L1: 0.016356 Grad: 0.121200 Thermal: 0.000520 LR: 9.37e-06\n",
      "Epoch  13 [4050/10697 ( 37.9%)] Loss: 0.028502 L1: 0.016356 Grad: 0.121200 Thermal: 0.000520 LR: 9.37e-06\n",
      "Epoch  13 [4100/10697 ( 38.3%)] Loss: 0.025338 L1: 0.014961 Grad: 0.103575 Thermal: 0.000390 LR: 9.37e-06\n",
      "Epoch  13 [4100/10697 ( 38.3%)] Loss: 0.025338 L1: 0.014961 Grad: 0.103575 Thermal: 0.000390 LR: 9.37e-06\n",
      "Epoch  13 [4150/10697 ( 38.8%)] Loss: 0.025325 L1: 0.014601 Grad: 0.107042 Thermal: 0.000385 LR: 9.37e-06\n",
      "Epoch  13 [4150/10697 ( 38.8%)] Loss: 0.025325 L1: 0.014601 Grad: 0.107042 Thermal: 0.000385 LR: 9.37e-06\n",
      "Epoch  13 [4200/10697 ( 39.3%)] Loss: 0.021109 L1: 0.012393 Grad: 0.087005 Thermal: 0.000311 LR: 9.37e-06\n",
      "Epoch  13 [4200/10697 ( 39.3%)] Loss: 0.021109 L1: 0.012393 Grad: 0.087005 Thermal: 0.000311 LR: 9.37e-06\n",
      "Epoch  13 [4250/10697 ( 39.7%)] Loss: 0.026593 L1: 0.015155 Grad: 0.114130 Thermal: 0.000490 LR: 9.37e-06\n",
      "Epoch  13 [4250/10697 ( 39.7%)] Loss: 0.026593 L1: 0.015155 Grad: 0.114130 Thermal: 0.000490 LR: 9.37e-06\n",
      "Epoch  13 [4300/10697 ( 40.2%)] Loss: 0.025436 L1: 0.014435 Grad: 0.109819 Thermal: 0.000387 LR: 9.37e-06\n",
      "Epoch  13 [4300/10697 ( 40.2%)] Loss: 0.025436 L1: 0.014435 Grad: 0.109819 Thermal: 0.000387 LR: 9.37e-06\n",
      "Epoch  13 [4350/10697 ( 40.7%)] Loss: 0.021032 L1: 0.012349 Grad: 0.086660 Thermal: 0.000331 LR: 9.37e-06\n",
      "Epoch  13 [4350/10697 ( 40.7%)] Loss: 0.021032 L1: 0.012349 Grad: 0.086660 Thermal: 0.000331 LR: 9.37e-06\n",
      "Epoch  13 [4400/10697 ( 41.1%)] Loss: 0.028637 L1: 0.016345 Grad: 0.122652 Thermal: 0.000528 LR: 9.37e-06\n",
      "Epoch  13 [4400/10697 ( 41.1%)] Loss: 0.028637 L1: 0.016345 Grad: 0.122652 Thermal: 0.000528 LR: 9.37e-06\n",
      "Epoch  13 [4450/10697 ( 41.6%)] Loss: 0.025233 L1: 0.015031 Grad: 0.101821 Thermal: 0.000399 LR: 9.37e-06\n",
      "Epoch  13 [4450/10697 ( 41.6%)] Loss: 0.025233 L1: 0.015031 Grad: 0.101821 Thermal: 0.000399 LR: 9.37e-06\n",
      "Epoch  13 [4500/10697 ( 42.1%)] Loss: 0.024750 L1: 0.014783 Grad: 0.099464 Thermal: 0.000408 LR: 9.37e-06\n",
      "Epoch  13 [4500/10697 ( 42.1%)] Loss: 0.024750 L1: 0.014783 Grad: 0.099464 Thermal: 0.000408 LR: 9.37e-06\n",
      "Epoch  13 [4550/10697 ( 42.5%)] Loss: 0.024772 L1: 0.014185 Grad: 0.105660 Thermal: 0.000422 LR: 9.37e-06\n",
      "Epoch  13 [4550/10697 ( 42.5%)] Loss: 0.024772 L1: 0.014185 Grad: 0.105660 Thermal: 0.000422 LR: 9.37e-06\n",
      "Epoch  13 [4600/10697 ( 43.0%)] Loss: 0.028255 L1: 0.016745 Grad: 0.114857 Thermal: 0.000497 LR: 9.37e-06\n",
      "Epoch  13 [4600/10697 ( 43.0%)] Loss: 0.028255 L1: 0.016745 Grad: 0.114857 Thermal: 0.000497 LR: 9.37e-06\n",
      "Epoch  13 [4650/10697 ( 43.5%)] Loss: 0.028563 L1: 0.016859 Grad: 0.116769 Thermal: 0.000559 LR: 9.37e-06\n",
      "Epoch  13 [4650/10697 ( 43.5%)] Loss: 0.028563 L1: 0.016859 Grad: 0.116769 Thermal: 0.000559 LR: 9.37e-06\n",
      "Epoch  13 [4700/10697 ( 43.9%)] Loss: 0.027223 L1: 0.015583 Grad: 0.116155 Thermal: 0.000481 LR: 9.37e-06\n",
      "Epoch  13 [4700/10697 ( 43.9%)] Loss: 0.027223 L1: 0.015583 Grad: 0.116155 Thermal: 0.000481 LR: 9.37e-06\n",
      "Epoch  13 [4750/10697 ( 44.4%)] Loss: 0.020793 L1: 0.011504 Grad: 0.092755 Thermal: 0.000267 LR: 9.37e-06\n",
      "Epoch  13 [4750/10697 ( 44.4%)] Loss: 0.020793 L1: 0.011504 Grad: 0.092755 Thermal: 0.000267 LR: 9.37e-06\n",
      "Epoch  13 [4800/10697 ( 44.9%)] Loss: 0.026813 L1: 0.015420 Grad: 0.113711 Thermal: 0.000438 LR: 9.37e-06\n",
      "Epoch  13 [4800/10697 ( 44.9%)] Loss: 0.026813 L1: 0.015420 Grad: 0.113711 Thermal: 0.000438 LR: 9.37e-06\n",
      "Epoch  13 [4850/10697 ( 45.3%)] Loss: 0.033610 L1: 0.018701 Grad: 0.148642 Thermal: 0.000891 LR: 9.37e-06\n",
      "Epoch  13 [4850/10697 ( 45.3%)] Loss: 0.033610 L1: 0.018701 Grad: 0.148642 Thermal: 0.000891 LR: 9.37e-06\n",
      "Epoch  13 [4900/10697 ( 45.8%)] Loss: 0.022784 L1: 0.013502 Grad: 0.092646 Thermal: 0.000353 LR: 9.37e-06\n",
      "Epoch  13 [4900/10697 ( 45.8%)] Loss: 0.022784 L1: 0.013502 Grad: 0.092646 Thermal: 0.000353 LR: 9.37e-06\n",
      "Epoch  13 [4950/10697 ( 46.3%)] Loss: 0.036271 L1: 0.020293 Grad: 0.159435 Thermal: 0.000695 LR: 9.37e-06\n",
      "Epoch  13 [4950/10697 ( 46.3%)] Loss: 0.036271 L1: 0.020293 Grad: 0.159435 Thermal: 0.000695 LR: 9.37e-06\n",
      "Epoch  13 [5000/10697 ( 46.7%)] Loss: 0.019824 L1: 0.011593 Grad: 0.082170 Thermal: 0.000282 LR: 9.37e-06\n",
      "Epoch  13 [5000/10697 ( 46.7%)] Loss: 0.019824 L1: 0.011593 Grad: 0.082170 Thermal: 0.000282 LR: 9.37e-06\n",
      "Epoch  13 [5050/10697 ( 47.2%)] Loss: 0.024694 L1: 0.014492 Grad: 0.101808 Thermal: 0.000439 LR: 9.37e-06\n",
      "Epoch  13 [5050/10697 ( 47.2%)] Loss: 0.024694 L1: 0.014492 Grad: 0.101808 Thermal: 0.000439 LR: 9.37e-06\n",
      "Epoch  13 [5100/10697 ( 47.7%)] Loss: 0.026790 L1: 0.015181 Grad: 0.115862 Thermal: 0.000459 LR: 9.37e-06\n",
      "Epoch  13 [5100/10697 ( 47.7%)] Loss: 0.026790 L1: 0.015181 Grad: 0.115862 Thermal: 0.000459 LR: 9.37e-06\n",
      "Epoch  13 [5150/10697 ( 48.1%)] Loss: 0.029940 L1: 0.017117 Grad: 0.127977 Thermal: 0.000504 LR: 9.37e-06\n",
      "Epoch  13 [5150/10697 ( 48.1%)] Loss: 0.029940 L1: 0.017117 Grad: 0.127977 Thermal: 0.000504 LR: 9.37e-06\n",
      "Epoch  13 [5200/10697 ( 48.6%)] Loss: 0.025442 L1: 0.014697 Grad: 0.107232 Thermal: 0.000437 LR: 9.37e-06\n",
      "Epoch  13 [5200/10697 ( 48.6%)] Loss: 0.025442 L1: 0.014697 Grad: 0.107232 Thermal: 0.000437 LR: 9.37e-06\n",
      "Epoch  13 [5250/10697 ( 49.1%)] Loss: 0.027707 L1: 0.016244 Grad: 0.114380 Thermal: 0.000508 LR: 9.37e-06\n",
      "Epoch  13 [5250/10697 ( 49.1%)] Loss: 0.027707 L1: 0.016244 Grad: 0.114380 Thermal: 0.000508 LR: 9.37e-06\n",
      "Epoch  13 [5300/10697 ( 49.5%)] Loss: 0.026969 L1: 0.015841 Grad: 0.111059 Thermal: 0.000447 LR: 9.37e-06\n",
      "Epoch  13 [5300/10697 ( 49.5%)] Loss: 0.026969 L1: 0.015841 Grad: 0.111059 Thermal: 0.000447 LR: 9.37e-06\n",
      "Epoch  13 [5350/10697 ( 50.0%)] Loss: 0.033778 L1: 0.019854 Grad: 0.138859 Thermal: 0.000745 LR: 9.37e-06\n",
      "Epoch  13 [5350/10697 ( 50.0%)] Loss: 0.033778 L1: 0.019854 Grad: 0.138859 Thermal: 0.000745 LR: 9.37e-06\n",
      "Epoch  13 [5400/10697 ( 50.5%)] Loss: 0.027228 L1: 0.015728 Grad: 0.114758 Thermal: 0.000471 LR: 9.37e-06\n",
      "Epoch  13 [5400/10697 ( 50.5%)] Loss: 0.027228 L1: 0.015728 Grad: 0.114758 Thermal: 0.000471 LR: 9.37e-06\n",
      "Epoch  13 [5450/10697 ( 50.9%)] Loss: 0.023427 L1: 0.013672 Grad: 0.097359 Thermal: 0.000389 LR: 9.37e-06\n",
      "Epoch  13 [5450/10697 ( 50.9%)] Loss: 0.023427 L1: 0.013672 Grad: 0.097359 Thermal: 0.000389 LR: 9.37e-06\n",
      "Epoch  13 [5500/10697 ( 51.4%)] Loss: 0.035113 L1: 0.020178 Grad: 0.148946 Thermal: 0.000821 LR: 9.37e-06\n",
      "Epoch  13 [5500/10697 ( 51.4%)] Loss: 0.035113 L1: 0.020178 Grad: 0.148946 Thermal: 0.000821 LR: 9.37e-06\n",
      "Epoch  13 [5550/10697 ( 51.9%)] Loss: 0.025048 L1: 0.014879 Grad: 0.101472 Thermal: 0.000448 LR: 9.37e-06\n",
      "Epoch  13 [5550/10697 ( 51.9%)] Loss: 0.025048 L1: 0.014879 Grad: 0.101472 Thermal: 0.000448 LR: 9.37e-06\n",
      "Epoch  13 [5600/10697 ( 52.4%)] Loss: 0.028488 L1: 0.016741 Grad: 0.117212 Thermal: 0.000508 LR: 9.37e-06\n",
      "Epoch  13 [5600/10697 ( 52.4%)] Loss: 0.028488 L1: 0.016741 Grad: 0.117212 Thermal: 0.000508 LR: 9.37e-06\n",
      "Epoch  13 [5650/10697 ( 52.8%)] Loss: 0.029956 L1: 0.017266 Grad: 0.126643 Thermal: 0.000522 LR: 9.37e-06\n",
      "Epoch  13 [5650/10697 ( 52.8%)] Loss: 0.029956 L1: 0.017266 Grad: 0.126643 Thermal: 0.000522 LR: 9.37e-06\n",
      "Epoch  13 [5700/10697 ( 53.3%)] Loss: 0.027170 L1: 0.015581 Grad: 0.115642 Thermal: 0.000488 LR: 9.37e-06\n",
      "Epoch  13 [5700/10697 ( 53.3%)] Loss: 0.027170 L1: 0.015581 Grad: 0.115642 Thermal: 0.000488 LR: 9.37e-06\n",
      "Epoch  13 [5750/10697 ( 53.8%)] Loss: 0.029282 L1: 0.016962 Grad: 0.122933 Thermal: 0.000532 LR: 9.37e-06\n",
      "Epoch  13 [5750/10697 ( 53.8%)] Loss: 0.029282 L1: 0.016962 Grad: 0.122933 Thermal: 0.000532 LR: 9.37e-06\n",
      "Epoch  13 [5800/10697 ( 54.2%)] Loss: 0.027566 L1: 0.016219 Grad: 0.113227 Thermal: 0.000489 LR: 9.37e-06\n",
      "Epoch  13 [5800/10697 ( 54.2%)] Loss: 0.027566 L1: 0.016219 Grad: 0.113227 Thermal: 0.000489 LR: 9.37e-06\n",
      "Epoch  13 [5850/10697 ( 54.7%)] Loss: 0.027426 L1: 0.015703 Grad: 0.116990 Thermal: 0.000477 LR: 9.37e-06\n",
      "Epoch  13 [5850/10697 ( 54.7%)] Loss: 0.027426 L1: 0.015703 Grad: 0.116990 Thermal: 0.000477 LR: 9.37e-06\n",
      "Epoch  13 [5900/10697 ( 55.2%)] Loss: 0.027644 L1: 0.016522 Grad: 0.110977 Thermal: 0.000491 LR: 9.37e-06\n",
      "Epoch  13 [5900/10697 ( 55.2%)] Loss: 0.027644 L1: 0.016522 Grad: 0.110977 Thermal: 0.000491 LR: 9.37e-06\n",
      "Epoch  13 [5950/10697 ( 55.6%)] Loss: 0.028801 L1: 0.016992 Grad: 0.117838 Thermal: 0.000518 LR: 9.37e-06\n",
      "Epoch  13 [5950/10697 ( 55.6%)] Loss: 0.028801 L1: 0.016992 Grad: 0.117838 Thermal: 0.000518 LR: 9.37e-06\n",
      "Epoch  13 [6000/10697 ( 56.1%)] Loss: 0.025246 L1: 0.014831 Grad: 0.103930 Thermal: 0.000428 LR: 9.37e-06\n",
      "Epoch  13 [6000/10697 ( 56.1%)] Loss: 0.025246 L1: 0.014831 Grad: 0.103930 Thermal: 0.000428 LR: 9.37e-06\n",
      "Epoch  13 [6050/10697 ( 56.6%)] Loss: 0.025136 L1: 0.014826 Grad: 0.102881 Thermal: 0.000435 LR: 9.37e-06\n",
      "Epoch  13 [6050/10697 ( 56.6%)] Loss: 0.025136 L1: 0.014826 Grad: 0.102881 Thermal: 0.000435 LR: 9.37e-06\n",
      "Epoch  13 [6100/10697 ( 57.0%)] Loss: 0.034187 L1: 0.019875 Grad: 0.142755 Thermal: 0.000727 LR: 9.37e-06\n",
      "Epoch  13 [6100/10697 ( 57.0%)] Loss: 0.034187 L1: 0.019875 Grad: 0.142755 Thermal: 0.000727 LR: 9.37e-06\n",
      "Epoch  13 [6150/10697 ( 57.5%)] Loss: 0.038017 L1: 0.021921 Grad: 0.160519 Thermal: 0.000886 LR: 9.37e-06\n",
      "Epoch  13 [6150/10697 ( 57.5%)] Loss: 0.038017 L1: 0.021921 Grad: 0.160519 Thermal: 0.000886 LR: 9.37e-06\n",
      "Epoch  13 [6200/10697 ( 58.0%)] Loss: 0.026969 L1: 0.015625 Grad: 0.113210 Thermal: 0.000449 LR: 9.37e-06\n",
      "Epoch  13 [6200/10697 ( 58.0%)] Loss: 0.026969 L1: 0.015625 Grad: 0.113210 Thermal: 0.000449 LR: 9.37e-06\n",
      "Epoch  13 [6250/10697 ( 58.4%)] Loss: 0.028728 L1: 0.016403 Grad: 0.123017 Thermal: 0.000458 LR: 9.37e-06\n",
      "Epoch  13 [6250/10697 ( 58.4%)] Loss: 0.028728 L1: 0.016403 Grad: 0.123017 Thermal: 0.000458 LR: 9.37e-06\n",
      "Epoch  13 [6300/10697 ( 58.9%)] Loss: 0.027294 L1: 0.015924 Grad: 0.113456 Thermal: 0.000471 LR: 9.37e-06\n",
      "Epoch  13 [6300/10697 ( 58.9%)] Loss: 0.027294 L1: 0.015924 Grad: 0.113456 Thermal: 0.000471 LR: 9.37e-06\n",
      "Epoch  13 [6350/10697 ( 59.4%)] Loss: 0.028044 L1: 0.016557 Grad: 0.114600 Thermal: 0.000529 LR: 9.37e-06\n",
      "Epoch  13 [6350/10697 ( 59.4%)] Loss: 0.028044 L1: 0.016557 Grad: 0.114600 Thermal: 0.000529 LR: 9.37e-06\n",
      "Epoch  13 [6400/10697 ( 59.8%)] Loss: 0.020143 L1: 0.011976 Grad: 0.081511 Thermal: 0.000315 LR: 9.37e-06\n",
      "Epoch  13 [6400/10697 ( 59.8%)] Loss: 0.020143 L1: 0.011976 Grad: 0.081511 Thermal: 0.000315 LR: 9.37e-06\n",
      "Epoch  13 [6450/10697 ( 60.3%)] Loss: 0.023667 L1: 0.013812 Grad: 0.098368 Thermal: 0.000382 LR: 9.37e-06\n",
      "Epoch  13 [6450/10697 ( 60.3%)] Loss: 0.023667 L1: 0.013812 Grad: 0.098368 Thermal: 0.000382 LR: 9.37e-06\n",
      "Epoch  13 [6500/10697 ( 60.8%)] Loss: 0.023777 L1: 0.013999 Grad: 0.097602 Thermal: 0.000348 LR: 9.37e-06\n",
      "Epoch  13 [6500/10697 ( 60.8%)] Loss: 0.023777 L1: 0.013999 Grad: 0.097602 Thermal: 0.000348 LR: 9.37e-06\n",
      "Epoch  13 [6550/10697 ( 61.2%)] Loss: 0.021501 L1: 0.012903 Grad: 0.085810 Thermal: 0.000334 LR: 9.37e-06\n",
      "Epoch  13 [6550/10697 ( 61.2%)] Loss: 0.021501 L1: 0.012903 Grad: 0.085810 Thermal: 0.000334 LR: 9.37e-06\n",
      "Epoch  13 [6600/10697 ( 61.7%)] Loss: 0.025577 L1: 0.015007 Grad: 0.105487 Thermal: 0.000436 LR: 9.37e-06\n",
      "Epoch  13 [6600/10697 ( 61.7%)] Loss: 0.025577 L1: 0.015007 Grad: 0.105487 Thermal: 0.000436 LR: 9.37e-06\n",
      "Epoch  13 [6650/10697 ( 62.2%)] Loss: 0.032498 L1: 0.018868 Grad: 0.135962 Thermal: 0.000679 LR: 9.37e-06\n",
      "Epoch  13 [6650/10697 ( 62.2%)] Loss: 0.032498 L1: 0.018868 Grad: 0.135962 Thermal: 0.000679 LR: 9.37e-06\n",
      "Epoch  13 [6700/10697 ( 62.6%)] Loss: 0.022962 L1: 0.013512 Grad: 0.094320 Thermal: 0.000360 LR: 9.37e-06\n",
      "Epoch  13 [6700/10697 ( 62.6%)] Loss: 0.022962 L1: 0.013512 Grad: 0.094320 Thermal: 0.000360 LR: 9.37e-06\n",
      "Epoch  13 [6750/10697 ( 63.1%)] Loss: 0.026675 L1: 0.015490 Grad: 0.111624 Thermal: 0.000461 LR: 9.37e-06\n",
      "Epoch  13 [6750/10697 ( 63.1%)] Loss: 0.026675 L1: 0.015490 Grad: 0.111624 Thermal: 0.000461 LR: 9.37e-06\n",
      "Epoch  13 [6800/10697 ( 63.6%)] Loss: 0.025337 L1: 0.014887 Grad: 0.104280 Thermal: 0.000440 LR: 9.37e-06\n",
      "Epoch  13 [6800/10697 ( 63.6%)] Loss: 0.025337 L1: 0.014887 Grad: 0.104280 Thermal: 0.000440 LR: 9.37e-06\n",
      "Epoch  13 [6850/10697 ( 64.0%)] Loss: 0.028474 L1: 0.016376 Grad: 0.120681 Thermal: 0.000596 LR: 9.37e-06\n",
      "Epoch  13 [6850/10697 ( 64.0%)] Loss: 0.028474 L1: 0.016376 Grad: 0.120681 Thermal: 0.000596 LR: 9.37e-06\n",
      "Epoch  13 [6900/10697 ( 64.5%)] Loss: 0.027175 L1: 0.016184 Grad: 0.109673 Thermal: 0.000457 LR: 9.37e-06\n",
      "Epoch  13 [6900/10697 ( 64.5%)] Loss: 0.027175 L1: 0.016184 Grad: 0.109673 Thermal: 0.000457 LR: 9.37e-06\n",
      "Epoch  13 [6950/10697 ( 65.0%)] Loss: 0.026757 L1: 0.015468 Grad: 0.112672 Thermal: 0.000427 LR: 9.37e-06\n",
      "Epoch  13 [6950/10697 ( 65.0%)] Loss: 0.026757 L1: 0.015468 Grad: 0.112672 Thermal: 0.000427 LR: 9.37e-06\n",
      "Epoch  13 [7000/10697 ( 65.4%)] Loss: 0.028763 L1: 0.016964 Grad: 0.117743 Thermal: 0.000507 LR: 9.37e-06\n",
      "Epoch  13 [7000/10697 ( 65.4%)] Loss: 0.028763 L1: 0.016964 Grad: 0.117743 Thermal: 0.000507 LR: 9.37e-06\n",
      "Epoch  13 [7050/10697 ( 65.9%)] Loss: 0.026005 L1: 0.015164 Grad: 0.108179 Thermal: 0.000449 LR: 9.37e-06\n",
      "Epoch  13 [7050/10697 ( 65.9%)] Loss: 0.026005 L1: 0.015164 Grad: 0.108179 Thermal: 0.000449 LR: 9.37e-06\n",
      "Epoch  13 [7100/10697 ( 66.4%)] Loss: 0.026839 L1: 0.016074 Grad: 0.107407 Thermal: 0.000482 LR: 9.37e-06\n",
      "Epoch  13 [7100/10697 ( 66.4%)] Loss: 0.026839 L1: 0.016074 Grad: 0.107407 Thermal: 0.000482 LR: 9.37e-06\n",
      "Epoch  13 [7150/10697 ( 66.8%)] Loss: 0.029500 L1: 0.017139 Grad: 0.123349 Thermal: 0.000527 LR: 9.37e-06\n",
      "Epoch  13 [7150/10697 ( 66.8%)] Loss: 0.029500 L1: 0.017139 Grad: 0.123349 Thermal: 0.000527 LR: 9.37e-06\n",
      "Epoch  13 [7200/10697 ( 67.3%)] Loss: 0.031637 L1: 0.018460 Grad: 0.131480 Thermal: 0.000587 LR: 9.37e-06\n",
      "Epoch  13 [7200/10697 ( 67.3%)] Loss: 0.031637 L1: 0.018460 Grad: 0.131480 Thermal: 0.000587 LR: 9.37e-06\n",
      "Epoch  13 [7250/10697 ( 67.8%)] Loss: 0.031467 L1: 0.018108 Grad: 0.133304 Thermal: 0.000566 LR: 9.37e-06\n",
      "Epoch  13 [7250/10697 ( 67.8%)] Loss: 0.031467 L1: 0.018108 Grad: 0.133304 Thermal: 0.000566 LR: 9.37e-06\n",
      "Epoch  13 [7300/10697 ( 68.2%)] Loss: 0.026082 L1: 0.015112 Grad: 0.109492 Thermal: 0.000422 LR: 9.37e-06\n",
      "Epoch  13 [7300/10697 ( 68.2%)] Loss: 0.026082 L1: 0.015112 Grad: 0.109492 Thermal: 0.000422 LR: 9.37e-06\n",
      "Epoch  13 [7350/10697 ( 68.7%)] Loss: 0.023547 L1: 0.012867 Grad: 0.106571 Thermal: 0.000448 LR: 9.37e-06\n",
      "Epoch  13 [7350/10697 ( 68.7%)] Loss: 0.023547 L1: 0.012867 Grad: 0.106571 Thermal: 0.000448 LR: 9.37e-06\n",
      "Epoch  13 [7400/10697 ( 69.2%)] Loss: 0.024996 L1: 0.014670 Grad: 0.103054 Thermal: 0.000402 LR: 9.37e-06\n",
      "Epoch  13 [7400/10697 ( 69.2%)] Loss: 0.024996 L1: 0.014670 Grad: 0.103054 Thermal: 0.000402 LR: 9.37e-06\n",
      "Epoch  13 [7450/10697 ( 69.6%)] Loss: 0.027920 L1: 0.016598 Grad: 0.112974 Thermal: 0.000503 LR: 9.37e-06\n",
      "Epoch  13 [7450/10697 ( 69.6%)] Loss: 0.027920 L1: 0.016598 Grad: 0.112974 Thermal: 0.000503 LR: 9.37e-06\n",
      "Epoch  13 [7500/10697 ( 70.1%)] Loss: 0.029733 L1: 0.017112 Grad: 0.125958 Thermal: 0.000505 LR: 9.37e-06\n",
      "Epoch  13 [7500/10697 ( 70.1%)] Loss: 0.029733 L1: 0.017112 Grad: 0.125958 Thermal: 0.000505 LR: 9.37e-06\n",
      "Epoch  13 [7550/10697 ( 70.6%)] Loss: 0.027095 L1: 0.015475 Grad: 0.115976 Thermal: 0.000437 LR: 9.37e-06\n",
      "Epoch  13 [7550/10697 ( 70.6%)] Loss: 0.027095 L1: 0.015475 Grad: 0.115976 Thermal: 0.000437 LR: 9.37e-06\n",
      "Epoch  13 [7600/10697 ( 71.0%)] Loss: 0.028882 L1: 0.016740 Grad: 0.121173 Thermal: 0.000495 LR: 9.37e-06\n",
      "Epoch  13 [7600/10697 ( 71.0%)] Loss: 0.028882 L1: 0.016740 Grad: 0.121173 Thermal: 0.000495 LR: 9.37e-06\n",
      "Epoch  13 [7650/10697 ( 71.5%)] Loss: 0.026404 L1: 0.015438 Grad: 0.109442 Thermal: 0.000450 LR: 9.37e-06\n",
      "Epoch  13 [7650/10697 ( 71.5%)] Loss: 0.026404 L1: 0.015438 Grad: 0.109442 Thermal: 0.000450 LR: 9.37e-06\n",
      "Epoch  13 [7700/10697 ( 72.0%)] Loss: 0.025427 L1: 0.014602 Grad: 0.108028 Thermal: 0.000460 LR: 9.37e-06\n",
      "Epoch  13 [7700/10697 ( 72.0%)] Loss: 0.025427 L1: 0.014602 Grad: 0.108028 Thermal: 0.000460 LR: 9.37e-06\n",
      "Epoch  13 [7750/10697 ( 72.5%)] Loss: 0.023156 L1: 0.013661 Grad: 0.094753 Thermal: 0.000380 LR: 9.37e-06\n",
      "Epoch  13 [7750/10697 ( 72.5%)] Loss: 0.023156 L1: 0.013661 Grad: 0.094753 Thermal: 0.000380 LR: 9.37e-06\n",
      "Epoch  13 [7800/10697 ( 72.9%)] Loss: 0.029813 L1: 0.017204 Grad: 0.125787 Thermal: 0.000596 LR: 9.37e-06\n",
      "Epoch  13 [7800/10697 ( 72.9%)] Loss: 0.029813 L1: 0.017204 Grad: 0.125787 Thermal: 0.000596 LR: 9.37e-06\n",
      "Epoch  13 [7850/10697 ( 73.4%)] Loss: 0.027513 L1: 0.016032 Grad: 0.114548 Thermal: 0.000530 LR: 9.37e-06\n",
      "Epoch  13 [7850/10697 ( 73.4%)] Loss: 0.027513 L1: 0.016032 Grad: 0.114548 Thermal: 0.000530 LR: 9.37e-06\n",
      "Epoch  13 [7900/10697 ( 73.9%)] Loss: 0.020043 L1: 0.011695 Grad: 0.083335 Thermal: 0.000297 LR: 9.37e-06\n",
      "Epoch  13 [7900/10697 ( 73.9%)] Loss: 0.020043 L1: 0.011695 Grad: 0.083335 Thermal: 0.000297 LR: 9.37e-06\n",
      "Epoch  13 [7950/10697 ( 74.3%)] Loss: 0.028634 L1: 0.016585 Grad: 0.120246 Thermal: 0.000489 LR: 9.37e-06\n",
      "Epoch  13 [7950/10697 ( 74.3%)] Loss: 0.028634 L1: 0.016585 Grad: 0.120246 Thermal: 0.000489 LR: 9.37e-06\n",
      "Epoch  13 [8000/10697 ( 74.8%)] Loss: 0.027145 L1: 0.015964 Grad: 0.111585 Thermal: 0.000458 LR: 9.37e-06\n",
      "Epoch  13 [8000/10697 ( 74.8%)] Loss: 0.027145 L1: 0.015964 Grad: 0.111585 Thermal: 0.000458 LR: 9.37e-06\n",
      "Epoch  13 [8050/10697 ( 75.3%)] Loss: 0.028250 L1: 0.015802 Grad: 0.124158 Thermal: 0.000653 LR: 9.37e-06\n",
      "Epoch  13 [8050/10697 ( 75.3%)] Loss: 0.028250 L1: 0.015802 Grad: 0.124158 Thermal: 0.000653 LR: 9.37e-06\n",
      "Epoch  13 [8100/10697 ( 75.7%)] Loss: 0.025439 L1: 0.015047 Grad: 0.103705 Thermal: 0.000425 LR: 9.37e-06\n",
      "Epoch  13 [8100/10697 ( 75.7%)] Loss: 0.025439 L1: 0.015047 Grad: 0.103705 Thermal: 0.000425 LR: 9.37e-06\n",
      "Epoch  13 [8150/10697 ( 76.2%)] Loss: 0.028387 L1: 0.016762 Grad: 0.116000 Thermal: 0.000490 LR: 9.37e-06\n",
      "Epoch  13 [8150/10697 ( 76.2%)] Loss: 0.028387 L1: 0.016762 Grad: 0.116000 Thermal: 0.000490 LR: 9.37e-06\n",
      "Epoch  13 [8200/10697 ( 76.7%)] Loss: 0.025144 L1: 0.015086 Grad: 0.100359 Thermal: 0.000442 LR: 9.37e-06\n",
      "Epoch  13 [8200/10697 ( 76.7%)] Loss: 0.025144 L1: 0.015086 Grad: 0.100359 Thermal: 0.000442 LR: 9.37e-06\n",
      "Epoch  13 [8250/10697 ( 77.1%)] Loss: 0.023869 L1: 0.014227 Grad: 0.096232 Thermal: 0.000368 LR: 9.37e-06\n",
      "Epoch  13 [8250/10697 ( 77.1%)] Loss: 0.023869 L1: 0.014227 Grad: 0.096232 Thermal: 0.000368 LR: 9.37e-06\n",
      "Epoch  13 [8300/10697 ( 77.6%)] Loss: 0.023897 L1: 0.013929 Grad: 0.099497 Thermal: 0.000354 LR: 9.37e-06\n",
      "Epoch  13 [8300/10697 ( 77.6%)] Loss: 0.023897 L1: 0.013929 Grad: 0.099497 Thermal: 0.000354 LR: 9.37e-06\n",
      "Epoch  13 [8350/10697 ( 78.1%)] Loss: 0.025549 L1: 0.014962 Grad: 0.105632 Thermal: 0.000469 LR: 9.37e-06\n",
      "Epoch  13 [8350/10697 ( 78.1%)] Loss: 0.025549 L1: 0.014962 Grad: 0.105632 Thermal: 0.000469 LR: 9.37e-06\n",
      "Epoch  13 [8400/10697 ( 78.5%)] Loss: 0.023916 L1: 0.014125 Grad: 0.097725 Thermal: 0.000376 LR: 9.37e-06\n",
      "Epoch  13 [8400/10697 ( 78.5%)] Loss: 0.023916 L1: 0.014125 Grad: 0.097725 Thermal: 0.000376 LR: 9.37e-06\n",
      "Epoch  13 [8450/10697 ( 79.0%)] Loss: 0.031280 L1: 0.018262 Grad: 0.129861 Thermal: 0.000631 LR: 9.37e-06\n",
      "Epoch  13 [8450/10697 ( 79.0%)] Loss: 0.031280 L1: 0.018262 Grad: 0.129861 Thermal: 0.000631 LR: 9.37e-06\n",
      "Epoch  13 [8500/10697 ( 79.5%)] Loss: 0.027089 L1: 0.015792 Grad: 0.112754 Thermal: 0.000425 LR: 9.37e-06\n",
      "Epoch  13 [8500/10697 ( 79.5%)] Loss: 0.027089 L1: 0.015792 Grad: 0.112754 Thermal: 0.000425 LR: 9.37e-06\n",
      "Epoch  13 [8550/10697 ( 79.9%)] Loss: 0.024148 L1: 0.013731 Grad: 0.103971 Thermal: 0.000403 LR: 9.37e-06\n",
      "Epoch  13 [8550/10697 ( 79.9%)] Loss: 0.024148 L1: 0.013731 Grad: 0.103971 Thermal: 0.000403 LR: 9.37e-06\n",
      "Epoch  13 [8600/10697 ( 80.4%)] Loss: 0.030566 L1: 0.017839 Grad: 0.126970 Thermal: 0.000593 LR: 9.37e-06\n",
      "Epoch  13 [8600/10697 ( 80.4%)] Loss: 0.030566 L1: 0.017839 Grad: 0.126970 Thermal: 0.000593 LR: 9.37e-06\n",
      "Epoch  13 [8650/10697 ( 80.9%)] Loss: 0.030659 L1: 0.017968 Grad: 0.126608 Thermal: 0.000607 LR: 9.37e-06\n",
      "Epoch  13 [8650/10697 ( 80.9%)] Loss: 0.030659 L1: 0.017968 Grad: 0.126608 Thermal: 0.000607 LR: 9.37e-06\n",
      "Epoch  13 [8700/10697 ( 81.3%)] Loss: 0.028962 L1: 0.017116 Grad: 0.118199 Thermal: 0.000517 LR: 9.37e-06\n",
      "Epoch  13 [8700/10697 ( 81.3%)] Loss: 0.028962 L1: 0.017116 Grad: 0.118199 Thermal: 0.000517 LR: 9.37e-06\n",
      "Epoch  13 [8750/10697 ( 81.8%)] Loss: 0.030985 L1: 0.017701 Grad: 0.132498 Thermal: 0.000684 LR: 9.37e-06\n",
      "Epoch  13 [8750/10697 ( 81.8%)] Loss: 0.030985 L1: 0.017701 Grad: 0.132498 Thermal: 0.000684 LR: 9.37e-06\n",
      "Epoch  13 [8800/10697 ( 82.3%)] Loss: 0.026751 L1: 0.015702 Grad: 0.110265 Thermal: 0.000455 LR: 9.37e-06\n",
      "Epoch  13 [8800/10697 ( 82.3%)] Loss: 0.026751 L1: 0.015702 Grad: 0.110265 Thermal: 0.000455 LR: 9.37e-06\n",
      "Epoch  13 [8850/10697 ( 82.7%)] Loss: 0.022785 L1: 0.013087 Grad: 0.096798 Thermal: 0.000360 LR: 9.37e-06\n",
      "Epoch  13 [8850/10697 ( 82.7%)] Loss: 0.022785 L1: 0.013087 Grad: 0.096798 Thermal: 0.000360 LR: 9.37e-06\n",
      "Epoch  13 [8900/10697 ( 83.2%)] Loss: 0.026910 L1: 0.015593 Grad: 0.112927 Thermal: 0.000485 LR: 9.37e-06\n",
      "Epoch  13 [8900/10697 ( 83.2%)] Loss: 0.026910 L1: 0.015593 Grad: 0.112927 Thermal: 0.000485 LR: 9.37e-06\n",
      "Epoch  13 [8950/10697 ( 83.7%)] Loss: 0.028790 L1: 0.017356 Grad: 0.114078 Thermal: 0.000528 LR: 9.37e-06\n",
      "Epoch  13 [8950/10697 ( 83.7%)] Loss: 0.028790 L1: 0.017356 Grad: 0.114078 Thermal: 0.000528 LR: 9.37e-06\n",
      "Epoch  13 [9000/10697 ( 84.1%)] Loss: 0.026442 L1: 0.015391 Grad: 0.110298 Thermal: 0.000426 LR: 9.37e-06\n",
      "Epoch  13 [9000/10697 ( 84.1%)] Loss: 0.026442 L1: 0.015391 Grad: 0.110298 Thermal: 0.000426 LR: 9.37e-06\n",
      "Epoch  13 [9050/10697 ( 84.6%)] Loss: 0.022927 L1: 0.013125 Grad: 0.097858 Thermal: 0.000328 LR: 9.37e-06\n",
      "Epoch  13 [9050/10697 ( 84.6%)] Loss: 0.022927 L1: 0.013125 Grad: 0.097858 Thermal: 0.000328 LR: 9.37e-06\n",
      "Epoch  13 [9100/10697 ( 85.1%)] Loss: 0.034045 L1: 0.019051 Grad: 0.149593 Thermal: 0.000702 LR: 9.37e-06\n",
      "Epoch  13 [9100/10697 ( 85.1%)] Loss: 0.034045 L1: 0.019051 Grad: 0.149593 Thermal: 0.000702 LR: 9.37e-06\n",
      "Epoch  13 [9150/10697 ( 85.5%)] Loss: 0.028634 L1: 0.016667 Grad: 0.119327 Thermal: 0.000681 LR: 9.37e-06\n",
      "Epoch  13 [9150/10697 ( 85.5%)] Loss: 0.028634 L1: 0.016667 Grad: 0.119327 Thermal: 0.000681 LR: 9.37e-06\n",
      "Epoch  13 [9200/10697 ( 86.0%)] Loss: 0.030882 L1: 0.018098 Grad: 0.127559 Thermal: 0.000561 LR: 9.37e-06\n",
      "Epoch  13 [9200/10697 ( 86.0%)] Loss: 0.030882 L1: 0.018098 Grad: 0.127559 Thermal: 0.000561 LR: 9.37e-06\n",
      "Epoch  13 [9250/10697 ( 86.5%)] Loss: 0.027373 L1: 0.016369 Grad: 0.109797 Thermal: 0.000474 LR: 9.37e-06\n",
      "Epoch  13 [9250/10697 ( 86.5%)] Loss: 0.027373 L1: 0.016369 Grad: 0.109797 Thermal: 0.000474 LR: 9.37e-06\n",
      "Epoch  13 [9300/10697 ( 86.9%)] Loss: 0.025050 L1: 0.014468 Grad: 0.105628 Thermal: 0.000387 LR: 9.37e-06\n",
      "Epoch  13 [9300/10697 ( 86.9%)] Loss: 0.025050 L1: 0.014468 Grad: 0.105628 Thermal: 0.000387 LR: 9.37e-06\n",
      "Epoch  13 [9350/10697 ( 87.4%)] Loss: 0.027102 L1: 0.016388 Grad: 0.106897 Thermal: 0.000482 LR: 9.37e-06\n",
      "Epoch  13 [9350/10697 ( 87.4%)] Loss: 0.027102 L1: 0.016388 Grad: 0.106897 Thermal: 0.000482 LR: 9.37e-06\n",
      "Epoch  13 [9400/10697 ( 87.9%)] Loss: 0.026293 L1: 0.015137 Grad: 0.111338 Thermal: 0.000447 LR: 9.37e-06\n",
      "Epoch  13 [9400/10697 ( 87.9%)] Loss: 0.026293 L1: 0.015137 Grad: 0.111338 Thermal: 0.000447 LR: 9.37e-06\n",
      "Epoch  13 [9450/10697 ( 88.3%)] Loss: 0.023009 L1: 0.013466 Grad: 0.095240 Thermal: 0.000367 LR: 9.37e-06\n",
      "Epoch  13 [9450/10697 ( 88.3%)] Loss: 0.023009 L1: 0.013466 Grad: 0.095240 Thermal: 0.000367 LR: 9.37e-06\n",
      "Epoch  13 [9500/10697 ( 88.8%)] Loss: 0.030744 L1: 0.017390 Grad: 0.133247 Thermal: 0.000591 LR: 9.37e-06\n",
      "Epoch  13 [9500/10697 ( 88.8%)] Loss: 0.030744 L1: 0.017390 Grad: 0.133247 Thermal: 0.000591 LR: 9.37e-06\n",
      "Epoch  13 [9550/10697 ( 89.3%)] Loss: 0.025299 L1: 0.014822 Grad: 0.104567 Thermal: 0.000398 LR: 9.37e-06\n",
      "Epoch  13 [9550/10697 ( 89.3%)] Loss: 0.025299 L1: 0.014822 Grad: 0.104567 Thermal: 0.000398 LR: 9.37e-06\n",
      "Epoch  13 [9600/10697 ( 89.7%)] Loss: 0.025897 L1: 0.014899 Grad: 0.109738 Thermal: 0.000491 LR: 9.37e-06\n",
      "Epoch  13 [9600/10697 ( 89.7%)] Loss: 0.025897 L1: 0.014899 Grad: 0.109738 Thermal: 0.000491 LR: 9.37e-06\n",
      "Epoch  13 [9650/10697 ( 90.2%)] Loss: 0.029259 L1: 0.016963 Grad: 0.122695 Thermal: 0.000519 LR: 9.37e-06\n",
      "Epoch  13 [9650/10697 ( 90.2%)] Loss: 0.029259 L1: 0.016963 Grad: 0.122695 Thermal: 0.000519 LR: 9.37e-06\n",
      "Epoch  13 [9700/10697 ( 90.7%)] Loss: 0.022994 L1: 0.013727 Grad: 0.092480 Thermal: 0.000376 LR: 9.37e-06\n",
      "Epoch  13 [9700/10697 ( 90.7%)] Loss: 0.022994 L1: 0.013727 Grad: 0.092480 Thermal: 0.000376 LR: 9.37e-06\n",
      "Epoch  13 [9750/10697 ( 91.1%)] Loss: 0.030494 L1: 0.018157 Grad: 0.123088 Thermal: 0.000574 LR: 9.37e-06\n",
      "Epoch  13 [9750/10697 ( 91.1%)] Loss: 0.030494 L1: 0.018157 Grad: 0.123088 Thermal: 0.000574 LR: 9.37e-06\n",
      "Epoch  13 [9800/10697 ( 91.6%)] Loss: 0.025848 L1: 0.014686 Grad: 0.111415 Thermal: 0.000413 LR: 9.37e-06\n",
      "Epoch  13 [9800/10697 ( 91.6%)] Loss: 0.025848 L1: 0.014686 Grad: 0.111415 Thermal: 0.000413 LR: 9.37e-06\n",
      "Epoch  13 [9850/10697 ( 92.1%)] Loss: 0.025557 L1: 0.015026 Grad: 0.105111 Thermal: 0.000398 LR: 9.37e-06\n",
      "Epoch  13 [9850/10697 ( 92.1%)] Loss: 0.025557 L1: 0.015026 Grad: 0.105111 Thermal: 0.000398 LR: 9.37e-06\n",
      "Epoch  13 [9900/10697 ( 92.5%)] Loss: 0.029297 L1: 0.017088 Grad: 0.121832 Thermal: 0.000508 LR: 9.37e-06\n",
      "Epoch  13 [9900/10697 ( 92.5%)] Loss: 0.029297 L1: 0.017088 Grad: 0.121832 Thermal: 0.000508 LR: 9.37e-06\n",
      "Epoch  13 [9950/10697 ( 93.0%)] Loss: 0.023359 L1: 0.013584 Grad: 0.097549 Thermal: 0.000410 LR: 9.37e-06\n",
      "Epoch  13 [9950/10697 ( 93.0%)] Loss: 0.023359 L1: 0.013584 Grad: 0.097549 Thermal: 0.000410 LR: 9.37e-06\n",
      "Epoch  13 [10000/10697 ( 93.5%)] Loss: 0.030052 L1: 0.017303 Grad: 0.127225 Thermal: 0.000537 LR: 9.37e-06\n",
      "Epoch  13 [10000/10697 ( 93.5%)] Loss: 0.030052 L1: 0.017303 Grad: 0.127225 Thermal: 0.000537 LR: 9.37e-06\n",
      "Epoch  13 [10050/10697 ( 94.0%)] Loss: 0.035191 L1: 0.020287 Grad: 0.148596 Thermal: 0.000891 LR: 9.37e-06\n",
      "Epoch  13 [10050/10697 ( 94.0%)] Loss: 0.035191 L1: 0.020287 Grad: 0.148596 Thermal: 0.000891 LR: 9.37e-06\n",
      "Epoch  13 [10100/10697 ( 94.4%)] Loss: 0.028630 L1: 0.017169 Grad: 0.114340 Thermal: 0.000523 LR: 9.37e-06\n",
      "Epoch  13 [10100/10697 ( 94.4%)] Loss: 0.028630 L1: 0.017169 Grad: 0.114340 Thermal: 0.000523 LR: 9.37e-06\n",
      "Epoch  13 [10150/10697 ( 94.9%)] Loss: 0.029354 L1: 0.017620 Grad: 0.117076 Thermal: 0.000517 LR: 9.37e-06\n",
      "Epoch  13 [10150/10697 ( 94.9%)] Loss: 0.029354 L1: 0.017620 Grad: 0.117076 Thermal: 0.000517 LR: 9.37e-06\n",
      "Epoch  13 [10200/10697 ( 95.4%)] Loss: 0.024972 L1: 0.014918 Grad: 0.100324 Thermal: 0.000437 LR: 9.37e-06\n",
      "Epoch  13 [10200/10697 ( 95.4%)] Loss: 0.024972 L1: 0.014918 Grad: 0.100324 Thermal: 0.000437 LR: 9.37e-06\n",
      "Epoch  13 [10250/10697 ( 95.8%)] Loss: 0.029208 L1: 0.017175 Grad: 0.120068 Thermal: 0.000524 LR: 9.37e-06\n",
      "Epoch  13 [10250/10697 ( 95.8%)] Loss: 0.029208 L1: 0.017175 Grad: 0.120068 Thermal: 0.000524 LR: 9.37e-06\n",
      "Epoch  13 [10300/10697 ( 96.3%)] Loss: 0.021450 L1: 0.012296 Grad: 0.091384 Thermal: 0.000321 LR: 9.37e-06\n",
      "Epoch  13 [10300/10697 ( 96.3%)] Loss: 0.021450 L1: 0.012296 Grad: 0.091384 Thermal: 0.000321 LR: 9.37e-06\n",
      "Epoch  13 [10350/10697 ( 96.8%)] Loss: 0.024310 L1: 0.014680 Grad: 0.096095 Thermal: 0.000402 LR: 9.37e-06\n",
      "Epoch  13 [10350/10697 ( 96.8%)] Loss: 0.024310 L1: 0.014680 Grad: 0.096095 Thermal: 0.000402 LR: 9.37e-06\n",
      "Epoch  13 [10400/10697 ( 97.2%)] Loss: 0.029240 L1: 0.016723 Grad: 0.124914 Thermal: 0.000520 LR: 9.37e-06\n",
      "Epoch  13 [10400/10697 ( 97.2%)] Loss: 0.029240 L1: 0.016723 Grad: 0.124914 Thermal: 0.000520 LR: 9.37e-06\n",
      "Epoch  13 [10450/10697 ( 97.7%)] Loss: 0.016200 L1: 0.009356 Grad: 0.068333 Thermal: 0.000208 LR: 9.37e-06\n",
      "Epoch  13 [10450/10697 ( 97.7%)] Loss: 0.016200 L1: 0.009356 Grad: 0.068333 Thermal: 0.000208 LR: 9.37e-06\n",
      "Epoch  13 [10500/10697 ( 98.2%)] Loss: 0.034963 L1: 0.019949 Grad: 0.149776 Thermal: 0.000729 LR: 9.37e-06\n",
      "Epoch  13 [10500/10697 ( 98.2%)] Loss: 0.034963 L1: 0.019949 Grad: 0.149776 Thermal: 0.000729 LR: 9.37e-06\n",
      "Epoch  13 [10550/10697 ( 98.6%)] Loss: 0.028869 L1: 0.016465 Grad: 0.123792 Thermal: 0.000491 LR: 9.37e-06\n",
      "Epoch  13 [10550/10697 ( 98.6%)] Loss: 0.028869 L1: 0.016465 Grad: 0.123792 Thermal: 0.000491 LR: 9.37e-06\n",
      "Epoch  13 [10600/10697 ( 99.1%)] Loss: 0.030487 L1: 0.018117 Grad: 0.123411 Thermal: 0.000579 LR: 9.37e-06\n",
      "Epoch  13 [10600/10697 ( 99.1%)] Loss: 0.030487 L1: 0.018117 Grad: 0.123411 Thermal: 0.000579 LR: 9.37e-06\n",
      "Epoch  13 [10650/10697 ( 99.6%)] Loss: 0.028726 L1: 0.017065 Grad: 0.116336 Thermal: 0.000543 LR: 9.37e-06\n",
      "Epoch  13 [10650/10697 ( 99.6%)] Loss: 0.028726 L1: 0.017065 Grad: 0.116336 Thermal: 0.000543 LR: 9.37e-06\n",
      "Epoch  13 Summary: Loss=0.026666 (L1:0.0155, Grad:0.1111, Thermal:0.0005) Val_PSNR=0.00dB Best=33.82dB Time=50.2min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  13 Summary: Loss=0.026666 (L1:0.0155, Grad:0.1111, Thermal:0.0005) Val_PSNR=0.00dB Best=33.82dB Time=50.2min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  14 [   0/10697 (  0.0%)] Loss: 0.028190 L1: 0.016458 Grad: 0.117076 Thermal: 0.000496 LR: 9.27e-06\n",
      "Epoch  14 [   0/10697 (  0.0%)] Loss: 0.028190 L1: 0.016458 Grad: 0.117076 Thermal: 0.000496 LR: 9.27e-06\n",
      "Epoch  14 [  50/10697 (  0.5%)] Loss: 0.027108 L1: 0.016104 Grad: 0.109799 Thermal: 0.000490 LR: 9.27e-06\n",
      "Epoch  14 [  50/10697 (  0.5%)] Loss: 0.027108 L1: 0.016104 Grad: 0.109799 Thermal: 0.000490 LR: 9.27e-06\n",
      "Epoch  14 [ 100/10697 (  0.9%)] Loss: 0.032571 L1: 0.019230 Grad: 0.133083 Thermal: 0.000653 LR: 9.27e-06\n",
      "Epoch  14 [ 100/10697 (  0.9%)] Loss: 0.032571 L1: 0.019230 Grad: 0.133083 Thermal: 0.000653 LR: 9.27e-06\n",
      "Epoch  14 [ 150/10697 (  1.4%)] Loss: 0.027154 L1: 0.015970 Grad: 0.111603 Thermal: 0.000471 LR: 9.27e-06\n",
      "Epoch  14 [ 150/10697 (  1.4%)] Loss: 0.027154 L1: 0.015970 Grad: 0.111603 Thermal: 0.000471 LR: 9.27e-06\n",
      "Epoch  14 [ 200/10697 (  1.9%)] Loss: 0.029021 L1: 0.016577 Grad: 0.124147 Thermal: 0.000587 LR: 9.27e-06\n",
      "Epoch  14 [ 200/10697 (  1.9%)] Loss: 0.029021 L1: 0.016577 Grad: 0.124147 Thermal: 0.000587 LR: 9.27e-06\n",
      "Epoch  14 [ 250/10697 (  2.3%)] Loss: 0.025118 L1: 0.014532 Grad: 0.105592 Thermal: 0.000532 LR: 9.27e-06\n",
      "Epoch  14 [ 250/10697 (  2.3%)] Loss: 0.025118 L1: 0.014532 Grad: 0.105592 Thermal: 0.000532 LR: 9.27e-06\n",
      "Epoch  14 [ 300/10697 (  2.8%)] Loss: 0.016894 L1: 0.009490 Grad: 0.073942 Thermal: 0.000199 LR: 9.27e-06\n",
      "Epoch  14 [ 300/10697 (  2.8%)] Loss: 0.016894 L1: 0.009490 Grad: 0.073942 Thermal: 0.000199 LR: 9.27e-06\n",
      "Epoch  14 [ 350/10697 (  3.3%)] Loss: 0.027737 L1: 0.015552 Grad: 0.121571 Thermal: 0.000550 LR: 9.27e-06\n",
      "Epoch  14 [ 350/10697 (  3.3%)] Loss: 0.027737 L1: 0.015552 Grad: 0.121571 Thermal: 0.000550 LR: 9.27e-06\n",
      "Epoch  14 [ 400/10697 (  3.7%)] Loss: 0.025699 L1: 0.014856 Grad: 0.108209 Thermal: 0.000429 LR: 9.27e-06\n",
      "Epoch  14 [ 400/10697 (  3.7%)] Loss: 0.025699 L1: 0.014856 Grad: 0.108209 Thermal: 0.000429 LR: 9.27e-06\n",
      "Epoch  14 [ 450/10697 (  4.2%)] Loss: 0.028153 L1: 0.016571 Grad: 0.115560 Thermal: 0.000531 LR: 9.27e-06\n",
      "Epoch  14 [ 450/10697 (  4.2%)] Loss: 0.028153 L1: 0.016571 Grad: 0.115560 Thermal: 0.000531 LR: 9.27e-06\n",
      "Epoch  14 [ 500/10697 (  4.7%)] Loss: 0.027403 L1: 0.016187 Grad: 0.111937 Thermal: 0.000454 LR: 9.27e-06\n",
      "Epoch  14 [ 500/10697 (  4.7%)] Loss: 0.027403 L1: 0.016187 Grad: 0.111937 Thermal: 0.000454 LR: 9.27e-06\n",
      "Epoch  14 [ 550/10697 (  5.1%)] Loss: 0.028294 L1: 0.016670 Grad: 0.115997 Thermal: 0.000482 LR: 9.27e-06\n",
      "Epoch  14 [ 550/10697 (  5.1%)] Loss: 0.028294 L1: 0.016670 Grad: 0.115997 Thermal: 0.000482 LR: 9.27e-06\n",
      "Epoch  14 [ 600/10697 (  5.6%)] Loss: 0.030355 L1: 0.017708 Grad: 0.126133 Thermal: 0.000681 LR: 9.27e-06\n",
      "Epoch  14 [ 600/10697 (  5.6%)] Loss: 0.030355 L1: 0.017708 Grad: 0.126133 Thermal: 0.000681 LR: 9.27e-06\n",
      "Epoch  14 [ 650/10697 (  6.1%)] Loss: 0.029854 L1: 0.017419 Grad: 0.124065 Thermal: 0.000567 LR: 9.27e-06\n",
      "Epoch  14 [ 650/10697 (  6.1%)] Loss: 0.029854 L1: 0.017419 Grad: 0.124065 Thermal: 0.000567 LR: 9.27e-06\n",
      "Epoch  14 [ 700/10697 (  6.5%)] Loss: 0.026230 L1: 0.015538 Grad: 0.106694 Thermal: 0.000453 LR: 9.27e-06\n",
      "Epoch  14 [ 700/10697 (  6.5%)] Loss: 0.026230 L1: 0.015538 Grad: 0.106694 Thermal: 0.000453 LR: 9.27e-06\n",
      "Epoch  14 [ 750/10697 (  7.0%)] Loss: 0.039611 L1: 0.022922 Grad: 0.166393 Thermal: 0.000994 LR: 9.27e-06\n",
      "Epoch  14 [ 750/10697 (  7.0%)] Loss: 0.039611 L1: 0.022922 Grad: 0.166393 Thermal: 0.000994 LR: 9.27e-06\n",
      "Epoch  14 [ 800/10697 (  7.5%)] Loss: 0.027049 L1: 0.015854 Grad: 0.111724 Thermal: 0.000457 LR: 9.27e-06\n",
      "Epoch  14 [ 800/10697 (  7.5%)] Loss: 0.027049 L1: 0.015854 Grad: 0.111724 Thermal: 0.000457 LR: 9.27e-06\n",
      "Epoch  14 [ 850/10697 (  7.9%)] Loss: 0.027922 L1: 0.016159 Grad: 0.117389 Thermal: 0.000484 LR: 9.27e-06\n",
      "Epoch  14 [ 850/10697 (  7.9%)] Loss: 0.027922 L1: 0.016159 Grad: 0.117389 Thermal: 0.000484 LR: 9.27e-06\n",
      "Epoch  14 [ 900/10697 (  8.4%)] Loss: 0.026637 L1: 0.015707 Grad: 0.109074 Thermal: 0.000453 LR: 9.27e-06\n",
      "Epoch  14 [ 900/10697 (  8.4%)] Loss: 0.026637 L1: 0.015707 Grad: 0.109074 Thermal: 0.000453 LR: 9.27e-06\n",
      "Epoch  14 [ 950/10697 (  8.9%)] Loss: 0.028643 L1: 0.016835 Grad: 0.117807 Thermal: 0.000540 LR: 9.27e-06\n",
      "Epoch  14 [ 950/10697 (  8.9%)] Loss: 0.028643 L1: 0.016835 Grad: 0.117807 Thermal: 0.000540 LR: 9.27e-06\n",
      "Epoch  14 [1000/10697 (  9.3%)] Loss: 0.030415 L1: 0.017889 Grad: 0.124974 Thermal: 0.000587 LR: 9.27e-06\n",
      "Epoch  14 [1000/10697 (  9.3%)] Loss: 0.030415 L1: 0.017889 Grad: 0.124974 Thermal: 0.000587 LR: 9.27e-06\n",
      "Epoch  14 [1050/10697 (  9.8%)] Loss: 0.023265 L1: 0.013203 Grad: 0.100452 Thermal: 0.000338 LR: 9.27e-06\n",
      "Epoch  14 [1050/10697 (  9.8%)] Loss: 0.023265 L1: 0.013203 Grad: 0.100452 Thermal: 0.000338 LR: 9.27e-06\n",
      "Epoch  14 [1100/10697 ( 10.3%)] Loss: 0.026336 L1: 0.015331 Grad: 0.109833 Thermal: 0.000429 LR: 9.27e-06\n",
      "Epoch  14 [1100/10697 ( 10.3%)] Loss: 0.026336 L1: 0.015331 Grad: 0.109833 Thermal: 0.000429 LR: 9.27e-06\n",
      "Epoch  14 [1150/10697 ( 10.8%)] Loss: 0.029185 L1: 0.017194 Grad: 0.119641 Thermal: 0.000547 LR: 9.27e-06\n",
      "Epoch  14 [1150/10697 ( 10.8%)] Loss: 0.029185 L1: 0.017194 Grad: 0.119641 Thermal: 0.000547 LR: 9.27e-06\n",
      "Epoch  14 [1200/10697 ( 11.2%)] Loss: 0.022764 L1: 0.013236 Grad: 0.095112 Thermal: 0.000353 LR: 9.27e-06\n",
      "Epoch  14 [1200/10697 ( 11.2%)] Loss: 0.022764 L1: 0.013236 Grad: 0.095112 Thermal: 0.000353 LR: 9.27e-06\n",
      "Epoch  14 [1250/10697 ( 11.7%)] Loss: 0.025253 L1: 0.014311 Grad: 0.109202 Thermal: 0.000450 LR: 9.27e-06\n",
      "Epoch  14 [1250/10697 ( 11.7%)] Loss: 0.025253 L1: 0.014311 Grad: 0.109202 Thermal: 0.000450 LR: 9.27e-06\n",
      "Epoch  14 [1300/10697 ( 12.2%)] Loss: 0.026346 L1: 0.015834 Grad: 0.104896 Thermal: 0.000447 LR: 9.27e-06\n",
      "Epoch  14 [1300/10697 ( 12.2%)] Loss: 0.026346 L1: 0.015834 Grad: 0.104896 Thermal: 0.000447 LR: 9.27e-06\n",
      "Epoch  14 [1350/10697 ( 12.6%)] Loss: 0.027711 L1: 0.015793 Grad: 0.118929 Thermal: 0.000490 LR: 9.27e-06\n",
      "Epoch  14 [1350/10697 ( 12.6%)] Loss: 0.027711 L1: 0.015793 Grad: 0.118929 Thermal: 0.000490 LR: 9.27e-06\n",
      "Epoch  14 [1400/10697 ( 13.1%)] Loss: 0.020544 L1: 0.012133 Grad: 0.083956 Thermal: 0.000296 LR: 9.27e-06\n",
      "Epoch  14 [1400/10697 ( 13.1%)] Loss: 0.020544 L1: 0.012133 Grad: 0.083956 Thermal: 0.000296 LR: 9.27e-06\n",
      "Epoch  14 [1450/10697 ( 13.6%)] Loss: 0.026070 L1: 0.015622 Grad: 0.104263 Thermal: 0.000443 LR: 9.27e-06\n",
      "Epoch  14 [1450/10697 ( 13.6%)] Loss: 0.026070 L1: 0.015622 Grad: 0.104263 Thermal: 0.000443 LR: 9.27e-06\n",
      "Epoch  14 [1500/10697 ( 14.0%)] Loss: 0.024856 L1: 0.014891 Grad: 0.099449 Thermal: 0.000413 LR: 9.27e-06\n",
      "Epoch  14 [1500/10697 ( 14.0%)] Loss: 0.024856 L1: 0.014891 Grad: 0.099449 Thermal: 0.000413 LR: 9.27e-06\n",
      "Epoch  14 [1550/10697 ( 14.5%)] Loss: 0.020969 L1: 0.011901 Grad: 0.090539 Thermal: 0.000285 LR: 9.27e-06\n",
      "Epoch  14 [1550/10697 ( 14.5%)] Loss: 0.020969 L1: 0.011901 Grad: 0.090539 Thermal: 0.000285 LR: 9.27e-06\n",
      "Epoch  14 [1600/10697 ( 15.0%)] Loss: 0.027435 L1: 0.015698 Grad: 0.117136 Thermal: 0.000470 LR: 9.27e-06\n",
      "Epoch  14 [1600/10697 ( 15.0%)] Loss: 0.027435 L1: 0.015698 Grad: 0.117136 Thermal: 0.000470 LR: 9.27e-06\n",
      "Epoch  14 [1650/10697 ( 15.4%)] Loss: 0.032313 L1: 0.018053 Grad: 0.142292 Thermal: 0.000600 LR: 9.27e-06\n",
      "Epoch  14 [1650/10697 ( 15.4%)] Loss: 0.032313 L1: 0.018053 Grad: 0.142292 Thermal: 0.000600 LR: 9.27e-06\n",
      "Epoch  14 [1700/10697 ( 15.9%)] Loss: 0.027128 L1: 0.016074 Grad: 0.110303 Thermal: 0.000482 LR: 9.27e-06\n",
      "Epoch  14 [1700/10697 ( 15.9%)] Loss: 0.027128 L1: 0.016074 Grad: 0.110303 Thermal: 0.000482 LR: 9.27e-06\n",
      "Epoch  14 [1750/10697 ( 16.4%)] Loss: 0.029639 L1: 0.017165 Grad: 0.124486 Thermal: 0.000510 LR: 9.27e-06\n",
      "Epoch  14 [1750/10697 ( 16.4%)] Loss: 0.029639 L1: 0.017165 Grad: 0.124486 Thermal: 0.000510 LR: 9.27e-06\n",
      "Epoch  14 [1800/10697 ( 16.8%)] Loss: 0.028286 L1: 0.016452 Grad: 0.118087 Thermal: 0.000506 LR: 9.27e-06\n",
      "Epoch  14 [1800/10697 ( 16.8%)] Loss: 0.028286 L1: 0.016452 Grad: 0.118087 Thermal: 0.000506 LR: 9.27e-06\n",
      "Epoch  14 [1850/10697 ( 17.3%)] Loss: 0.030365 L1: 0.017750 Grad: 0.125848 Thermal: 0.000598 LR: 9.27e-06\n",
      "Epoch  14 [1850/10697 ( 17.3%)] Loss: 0.030365 L1: 0.017750 Grad: 0.125848 Thermal: 0.000598 LR: 9.27e-06\n",
      "Epoch  14 [1900/10697 ( 17.8%)] Loss: 0.033627 L1: 0.019290 Grad: 0.143005 Thermal: 0.000733 LR: 9.27e-06\n",
      "Epoch  14 [1900/10697 ( 17.8%)] Loss: 0.033627 L1: 0.019290 Grad: 0.143005 Thermal: 0.000733 LR: 9.27e-06\n",
      "Epoch  14 [1950/10697 ( 18.2%)] Loss: 0.026585 L1: 0.015411 Grad: 0.111502 Thermal: 0.000487 LR: 9.27e-06\n",
      "Epoch  14 [1950/10697 ( 18.2%)] Loss: 0.026585 L1: 0.015411 Grad: 0.111502 Thermal: 0.000487 LR: 9.27e-06\n",
      "Epoch  14 [2000/10697 ( 18.7%)] Loss: 0.026104 L1: 0.014761 Grad: 0.113222 Thermal: 0.000420 LR: 9.27e-06\n",
      "Epoch  14 [2000/10697 ( 18.7%)] Loss: 0.026104 L1: 0.014761 Grad: 0.113222 Thermal: 0.000420 LR: 9.27e-06\n",
      "Epoch  14 [2050/10697 ( 19.2%)] Loss: 0.024340 L1: 0.013713 Grad: 0.106043 Thermal: 0.000452 LR: 9.27e-06\n",
      "Epoch  14 [2050/10697 ( 19.2%)] Loss: 0.024340 L1: 0.013713 Grad: 0.106043 Thermal: 0.000452 LR: 9.27e-06\n",
      "Epoch  14 [2100/10697 ( 19.6%)] Loss: 0.023941 L1: 0.014024 Grad: 0.098984 Thermal: 0.000371 LR: 9.27e-06\n",
      "Epoch  14 [2100/10697 ( 19.6%)] Loss: 0.023941 L1: 0.014024 Grad: 0.098984 Thermal: 0.000371 LR: 9.27e-06\n",
      "Epoch  14 [2150/10697 ( 20.1%)] Loss: 0.027462 L1: 0.016149 Grad: 0.112897 Thermal: 0.000479 LR: 9.27e-06\n",
      "Epoch  14 [2150/10697 ( 20.1%)] Loss: 0.027462 L1: 0.016149 Grad: 0.112897 Thermal: 0.000479 LR: 9.27e-06\n",
      "Epoch  14 [2200/10697 ( 20.6%)] Loss: 0.029649 L1: 0.017714 Grad: 0.119058 Thermal: 0.000574 LR: 9.27e-06\n",
      "Epoch  14 [2200/10697 ( 20.6%)] Loss: 0.029649 L1: 0.017714 Grad: 0.119058 Thermal: 0.000574 LR: 9.27e-06\n",
      "Epoch  14 [2250/10697 ( 21.0%)] Loss: 0.026543 L1: 0.015543 Grad: 0.109772 Thermal: 0.000466 LR: 9.27e-06\n",
      "Epoch  14 [2250/10697 ( 21.0%)] Loss: 0.026543 L1: 0.015543 Grad: 0.109772 Thermal: 0.000466 LR: 9.27e-06\n",
      "Epoch  14 [2300/10697 ( 21.5%)] Loss: 0.025814 L1: 0.015197 Grad: 0.105928 Thermal: 0.000469 LR: 9.27e-06\n",
      "Epoch  14 [2300/10697 ( 21.5%)] Loss: 0.025814 L1: 0.015197 Grad: 0.105928 Thermal: 0.000469 LR: 9.27e-06\n",
      "Epoch  14 [2350/10697 ( 22.0%)] Loss: 0.023453 L1: 0.013729 Grad: 0.097050 Thermal: 0.000368 LR: 9.27e-06\n",
      "Epoch  14 [2350/10697 ( 22.0%)] Loss: 0.023453 L1: 0.013729 Grad: 0.097050 Thermal: 0.000368 LR: 9.27e-06\n",
      "Epoch  14 [2400/10697 ( 22.4%)] Loss: 0.028084 L1: 0.016432 Grad: 0.116231 Thermal: 0.000575 LR: 9.27e-06\n",
      "Epoch  14 [2400/10697 ( 22.4%)] Loss: 0.028084 L1: 0.016432 Grad: 0.116231 Thermal: 0.000575 LR: 9.27e-06\n",
      "Epoch  14 [2450/10697 ( 22.9%)] Loss: 0.024582 L1: 0.013881 Grad: 0.106835 Thermal: 0.000354 LR: 9.27e-06\n",
      "Epoch  14 [2450/10697 ( 22.9%)] Loss: 0.024582 L1: 0.013881 Grad: 0.106835 Thermal: 0.000354 LR: 9.27e-06\n",
      "Epoch  14 [2500/10697 ( 23.4%)] Loss: 0.023042 L1: 0.013388 Grad: 0.096359 Thermal: 0.000371 LR: 9.27e-06\n",
      "Epoch  14 [2500/10697 ( 23.4%)] Loss: 0.023042 L1: 0.013388 Grad: 0.096359 Thermal: 0.000371 LR: 9.27e-06\n",
      "Epoch  14 [2550/10697 ( 23.8%)] Loss: 0.027819 L1: 0.016476 Grad: 0.113177 Thermal: 0.000491 LR: 9.27e-06\n",
      "Epoch  14 [2550/10697 ( 23.8%)] Loss: 0.027819 L1: 0.016476 Grad: 0.113177 Thermal: 0.000491 LR: 9.27e-06\n",
      "Epoch  14 [2600/10697 ( 24.3%)] Loss: 0.023619 L1: 0.013713 Grad: 0.098858 Thermal: 0.000403 LR: 9.27e-06\n",
      "Epoch  14 [2600/10697 ( 24.3%)] Loss: 0.023619 L1: 0.013713 Grad: 0.098858 Thermal: 0.000403 LR: 9.27e-06\n",
      "Epoch  14 [2650/10697 ( 24.8%)] Loss: 0.023190 L1: 0.013188 Grad: 0.099860 Thermal: 0.000337 LR: 9.27e-06\n",
      "Epoch  14 [2650/10697 ( 24.8%)] Loss: 0.023190 L1: 0.013188 Grad: 0.099860 Thermal: 0.000337 LR: 9.27e-06\n",
      "Epoch  14 [2700/10697 ( 25.2%)] Loss: 0.034123 L1: 0.019544 Grad: 0.145426 Thermal: 0.000726 LR: 9.27e-06\n",
      "Epoch  14 [2700/10697 ( 25.2%)] Loss: 0.034123 L1: 0.019544 Grad: 0.145426 Thermal: 0.000726 LR: 9.27e-06\n",
      "Epoch  14 [2750/10697 ( 25.7%)] Loss: 0.020266 L1: 0.011731 Grad: 0.085216 Thermal: 0.000271 LR: 9.27e-06\n",
      "Epoch  14 [2750/10697 ( 25.7%)] Loss: 0.020266 L1: 0.011731 Grad: 0.085216 Thermal: 0.000271 LR: 9.27e-06\n",
      "Epoch  14 [2800/10697 ( 26.2%)] Loss: 0.027890 L1: 0.016781 Grad: 0.110819 Thermal: 0.000525 LR: 9.27e-06\n",
      "Epoch  14 [2800/10697 ( 26.2%)] Loss: 0.027890 L1: 0.016781 Grad: 0.110819 Thermal: 0.000525 LR: 9.27e-06\n",
      "Epoch  14 [2850/10697 ( 26.6%)] Loss: 0.023093 L1: 0.013582 Grad: 0.094940 Thermal: 0.000342 LR: 9.27e-06\n",
      "Epoch  14 [2850/10697 ( 26.6%)] Loss: 0.023093 L1: 0.013582 Grad: 0.094940 Thermal: 0.000342 LR: 9.27e-06\n",
      "Epoch  14 [2900/10697 ( 27.1%)] Loss: 0.027526 L1: 0.015495 Grad: 0.120042 Thermal: 0.000529 LR: 9.27e-06\n",
      "Epoch  14 [2900/10697 ( 27.1%)] Loss: 0.027526 L1: 0.015495 Grad: 0.120042 Thermal: 0.000529 LR: 9.27e-06\n",
      "Epoch  14 [2950/10697 ( 27.6%)] Loss: 0.030239 L1: 0.017527 Grad: 0.126798 Thermal: 0.000644 LR: 9.27e-06\n",
      "Epoch  14 [2950/10697 ( 27.6%)] Loss: 0.030239 L1: 0.017527 Grad: 0.126798 Thermal: 0.000644 LR: 9.27e-06\n",
      "Epoch  14 [3000/10697 ( 28.0%)] Loss: 0.028726 L1: 0.016818 Grad: 0.118824 Thermal: 0.000514 LR: 9.27e-06\n",
      "Epoch  14 [3000/10697 ( 28.0%)] Loss: 0.028726 L1: 0.016818 Grad: 0.118824 Thermal: 0.000514 LR: 9.27e-06\n",
      "Epoch  14 [3050/10697 ( 28.5%)] Loss: 0.025639 L1: 0.014706 Grad: 0.109110 Thermal: 0.000439 LR: 9.27e-06\n",
      "Epoch  14 [3050/10697 ( 28.5%)] Loss: 0.025639 L1: 0.014706 Grad: 0.109110 Thermal: 0.000439 LR: 9.27e-06\n",
      "Epoch  14 [3100/10697 ( 29.0%)] Loss: 0.025957 L1: 0.015652 Grad: 0.102833 Thermal: 0.000439 LR: 9.27e-06\n",
      "Epoch  14 [3100/10697 ( 29.0%)] Loss: 0.025957 L1: 0.015652 Grad: 0.102833 Thermal: 0.000439 LR: 9.27e-06\n",
      "Epoch  14 [3150/10697 ( 29.4%)] Loss: 0.029525 L1: 0.016853 Grad: 0.126422 Thermal: 0.000598 LR: 9.27e-06\n",
      "Epoch  14 [3150/10697 ( 29.4%)] Loss: 0.029525 L1: 0.016853 Grad: 0.126422 Thermal: 0.000598 LR: 9.27e-06\n",
      "Epoch  14 [3200/10697 ( 29.9%)] Loss: 0.026540 L1: 0.015245 Grad: 0.112734 Thermal: 0.000446 LR: 9.27e-06\n",
      "Epoch  14 [3200/10697 ( 29.9%)] Loss: 0.026540 L1: 0.015245 Grad: 0.112734 Thermal: 0.000446 LR: 9.27e-06\n",
      "Epoch  14 [3250/10697 ( 30.4%)] Loss: 0.024252 L1: 0.013774 Grad: 0.104600 Thermal: 0.000375 LR: 9.27e-06\n",
      "Epoch  14 [3250/10697 ( 30.4%)] Loss: 0.024252 L1: 0.013774 Grad: 0.104600 Thermal: 0.000375 LR: 9.27e-06\n",
      "Epoch  14 [3300/10697 ( 30.8%)] Loss: 0.021954 L1: 0.012295 Grad: 0.096387 Thermal: 0.000395 LR: 9.27e-06\n",
      "Epoch  14 [3300/10697 ( 30.8%)] Loss: 0.021954 L1: 0.012295 Grad: 0.096387 Thermal: 0.000395 LR: 9.27e-06\n",
      "Epoch  14 [3350/10697 ( 31.3%)] Loss: 0.027578 L1: 0.016432 Grad: 0.111217 Thermal: 0.000490 LR: 9.27e-06\n",
      "Epoch  14 [3350/10697 ( 31.3%)] Loss: 0.027578 L1: 0.016432 Grad: 0.111217 Thermal: 0.000490 LR: 9.27e-06\n",
      "Epoch  14 [3400/10697 ( 31.8%)] Loss: 0.026411 L1: 0.015779 Grad: 0.106103 Thermal: 0.000441 LR: 9.27e-06\n",
      "Epoch  14 [3400/10697 ( 31.8%)] Loss: 0.026411 L1: 0.015779 Grad: 0.106103 Thermal: 0.000441 LR: 9.27e-06\n",
      "Epoch  14 [3450/10697 ( 32.3%)] Loss: 0.028536 L1: 0.016774 Grad: 0.117373 Thermal: 0.000496 LR: 9.27e-06\n",
      "Epoch  14 [3450/10697 ( 32.3%)] Loss: 0.028536 L1: 0.016774 Grad: 0.117373 Thermal: 0.000496 LR: 9.27e-06\n",
      "Epoch  14 [3500/10697 ( 32.7%)] Loss: 0.024256 L1: 0.014282 Grad: 0.099515 Thermal: 0.000449 LR: 9.27e-06\n",
      "Epoch  14 [3500/10697 ( 32.7%)] Loss: 0.024256 L1: 0.014282 Grad: 0.099515 Thermal: 0.000449 LR: 9.27e-06\n",
      "Epoch  14 [3550/10697 ( 33.2%)] Loss: 0.026968 L1: 0.015793 Grad: 0.111525 Thermal: 0.000455 LR: 9.27e-06\n",
      "Epoch  14 [3550/10697 ( 33.2%)] Loss: 0.026968 L1: 0.015793 Grad: 0.111525 Thermal: 0.000455 LR: 9.27e-06\n",
      "Epoch  14 [3600/10697 ( 33.7%)] Loss: 0.027076 L1: 0.016096 Grad: 0.109567 Thermal: 0.000467 LR: 9.27e-06\n",
      "Epoch  14 [3600/10697 ( 33.7%)] Loss: 0.027076 L1: 0.016096 Grad: 0.109567 Thermal: 0.000467 LR: 9.27e-06\n",
      "Epoch  14 [3650/10697 ( 34.1%)] Loss: 0.025694 L1: 0.015236 Grad: 0.104361 Thermal: 0.000444 LR: 9.27e-06\n",
      "Epoch  14 [3650/10697 ( 34.1%)] Loss: 0.025694 L1: 0.015236 Grad: 0.104361 Thermal: 0.000444 LR: 9.27e-06\n",
      "Epoch  14 [3700/10697 ( 34.6%)] Loss: 0.026291 L1: 0.015264 Grad: 0.110016 Thermal: 0.000507 LR: 9.27e-06\n",
      "Epoch  14 [3700/10697 ( 34.6%)] Loss: 0.026291 L1: 0.015264 Grad: 0.110016 Thermal: 0.000507 LR: 9.27e-06\n",
      "Epoch  14 [3750/10697 ( 35.1%)] Loss: 0.027966 L1: 0.016319 Grad: 0.116219 Thermal: 0.000504 LR: 9.27e-06\n",
      "Epoch  14 [3750/10697 ( 35.1%)] Loss: 0.027966 L1: 0.016319 Grad: 0.116219 Thermal: 0.000504 LR: 9.27e-06\n",
      "Epoch  14 [3800/10697 ( 35.5%)] Loss: 0.028056 L1: 0.016244 Grad: 0.117889 Thermal: 0.000468 LR: 9.27e-06\n",
      "Epoch  14 [3800/10697 ( 35.5%)] Loss: 0.028056 L1: 0.016244 Grad: 0.117889 Thermal: 0.000468 LR: 9.27e-06\n",
      "Epoch  14 [3850/10697 ( 36.0%)] Loss: 0.025992 L1: 0.015103 Grad: 0.108688 Thermal: 0.000403 LR: 9.27e-06\n",
      "Epoch  14 [3850/10697 ( 36.0%)] Loss: 0.025992 L1: 0.015103 Grad: 0.108688 Thermal: 0.000403 LR: 9.27e-06\n",
      "Epoch  14 [3900/10697 ( 36.5%)] Loss: 0.026827 L1: 0.015678 Grad: 0.111220 Thermal: 0.000539 LR: 9.27e-06\n",
      "Epoch  14 [3900/10697 ( 36.5%)] Loss: 0.026827 L1: 0.015678 Grad: 0.111220 Thermal: 0.000539 LR: 9.27e-06\n",
      "Epoch  14 [3950/10697 ( 36.9%)] Loss: 0.025527 L1: 0.015164 Grad: 0.103429 Thermal: 0.000393 LR: 9.27e-06\n",
      "Epoch  14 [3950/10697 ( 36.9%)] Loss: 0.025527 L1: 0.015164 Grad: 0.103429 Thermal: 0.000393 LR: 9.27e-06\n",
      "Epoch  14 [4000/10697 ( 37.4%)] Loss: 0.021407 L1: 0.012614 Grad: 0.087761 Thermal: 0.000332 LR: 9.27e-06\n",
      "Epoch  14 [4000/10697 ( 37.4%)] Loss: 0.021407 L1: 0.012614 Grad: 0.087761 Thermal: 0.000332 LR: 9.27e-06\n",
      "Epoch  14 [4050/10697 ( 37.9%)] Loss: 0.027621 L1: 0.016208 Grad: 0.113892 Thermal: 0.000488 LR: 9.27e-06\n",
      "Epoch  14 [4050/10697 ( 37.9%)] Loss: 0.027621 L1: 0.016208 Grad: 0.113892 Thermal: 0.000488 LR: 9.27e-06\n",
      "Epoch  14 [4100/10697 ( 38.3%)] Loss: 0.027757 L1: 0.016353 Grad: 0.113771 Thermal: 0.000536 LR: 9.27e-06\n",
      "Epoch  14 [4100/10697 ( 38.3%)] Loss: 0.027757 L1: 0.016353 Grad: 0.113771 Thermal: 0.000536 LR: 9.27e-06\n",
      "Epoch  14 [4150/10697 ( 38.8%)] Loss: 0.031887 L1: 0.018469 Grad: 0.133855 Thermal: 0.000632 LR: 9.27e-06\n",
      "Epoch  14 [4150/10697 ( 38.8%)] Loss: 0.031887 L1: 0.018469 Grad: 0.133855 Thermal: 0.000632 LR: 9.27e-06\n",
      "Epoch  14 [4200/10697 ( 39.3%)] Loss: 0.027730 L1: 0.016354 Grad: 0.113523 Thermal: 0.000482 LR: 9.27e-06\n",
      "Epoch  14 [4200/10697 ( 39.3%)] Loss: 0.027730 L1: 0.016354 Grad: 0.113523 Thermal: 0.000482 LR: 9.27e-06\n",
      "Epoch  14 [4250/10697 ( 39.7%)] Loss: 0.025752 L1: 0.014744 Grad: 0.109872 Thermal: 0.000421 LR: 9.27e-06\n",
      "Epoch  14 [4250/10697 ( 39.7%)] Loss: 0.025752 L1: 0.014744 Grad: 0.109872 Thermal: 0.000421 LR: 9.27e-06\n",
      "Epoch  14 [4300/10697 ( 40.2%)] Loss: 0.020227 L1: 0.011754 Grad: 0.084591 Thermal: 0.000290 LR: 9.27e-06\n",
      "Epoch  14 [4300/10697 ( 40.2%)] Loss: 0.020227 L1: 0.011754 Grad: 0.084591 Thermal: 0.000290 LR: 9.27e-06\n",
      "Epoch  14 [4350/10697 ( 40.7%)] Loss: 0.027408 L1: 0.016215 Grad: 0.111697 Thermal: 0.000465 LR: 9.27e-06\n",
      "Epoch  14 [4350/10697 ( 40.7%)] Loss: 0.027408 L1: 0.016215 Grad: 0.111697 Thermal: 0.000465 LR: 9.27e-06\n",
      "Epoch  14 [4400/10697 ( 41.1%)] Loss: 0.027280 L1: 0.015329 Grad: 0.119244 Thermal: 0.000539 LR: 9.27e-06\n",
      "Epoch  14 [4400/10697 ( 41.1%)] Loss: 0.027280 L1: 0.015329 Grad: 0.119244 Thermal: 0.000539 LR: 9.27e-06\n",
      "Epoch  14 [4450/10697 ( 41.6%)] Loss: 0.021279 L1: 0.012281 Grad: 0.089806 Thermal: 0.000357 LR: 9.27e-06\n",
      "Epoch  14 [4450/10697 ( 41.6%)] Loss: 0.021279 L1: 0.012281 Grad: 0.089806 Thermal: 0.000357 LR: 9.27e-06\n",
      "Epoch  14 [4500/10697 ( 42.1%)] Loss: 0.026635 L1: 0.015474 Grad: 0.111383 Thermal: 0.000438 LR: 9.27e-06\n",
      "Epoch  14 [4500/10697 ( 42.1%)] Loss: 0.026635 L1: 0.015474 Grad: 0.111383 Thermal: 0.000438 LR: 9.27e-06\n",
      "Epoch  14 [4550/10697 ( 42.5%)] Loss: 0.026948 L1: 0.016000 Grad: 0.109225 Thermal: 0.000494 LR: 9.27e-06\n",
      "Epoch  14 [4550/10697 ( 42.5%)] Loss: 0.026948 L1: 0.016000 Grad: 0.109225 Thermal: 0.000494 LR: 9.27e-06\n",
      "Epoch  14 [4600/10697 ( 43.0%)] Loss: 0.025435 L1: 0.014703 Grad: 0.107098 Thermal: 0.000426 LR: 9.27e-06\n",
      "Epoch  14 [4600/10697 ( 43.0%)] Loss: 0.025435 L1: 0.014703 Grad: 0.107098 Thermal: 0.000426 LR: 9.27e-06\n",
      "Epoch  14 [4650/10697 ( 43.5%)] Loss: 0.019822 L1: 0.011408 Grad: 0.084002 Thermal: 0.000274 LR: 9.27e-06\n",
      "Epoch  14 [4650/10697 ( 43.5%)] Loss: 0.019822 L1: 0.011408 Grad: 0.084002 Thermal: 0.000274 LR: 9.27e-06\n",
      "Epoch  14 [4700/10697 ( 43.9%)] Loss: 0.019314 L1: 0.011450 Grad: 0.078502 Thermal: 0.000270 LR: 9.27e-06\n",
      "Epoch  14 [4700/10697 ( 43.9%)] Loss: 0.019314 L1: 0.011450 Grad: 0.078502 Thermal: 0.000270 LR: 9.27e-06\n",
      "Epoch  14 [4750/10697 ( 44.4%)] Loss: 0.024847 L1: 0.014473 Grad: 0.103522 Thermal: 0.000441 LR: 9.27e-06\n",
      "Epoch  14 [4750/10697 ( 44.4%)] Loss: 0.024847 L1: 0.014473 Grad: 0.103522 Thermal: 0.000441 LR: 9.27e-06\n",
      "Epoch  14 [4800/10697 ( 44.9%)] Loss: 0.024498 L1: 0.014141 Grad: 0.103374 Thermal: 0.000398 LR: 9.27e-06\n",
      "Epoch  14 [4800/10697 ( 44.9%)] Loss: 0.024498 L1: 0.014141 Grad: 0.103374 Thermal: 0.000398 LR: 9.27e-06\n",
      "Epoch  14 [4850/10697 ( 45.3%)] Loss: 0.019070 L1: 0.010682 Grad: 0.083743 Thermal: 0.000272 LR: 9.27e-06\n",
      "Epoch  14 [4850/10697 ( 45.3%)] Loss: 0.019070 L1: 0.010682 Grad: 0.083743 Thermal: 0.000272 LR: 9.27e-06\n",
      "Epoch  14 [4900/10697 ( 45.8%)] Loss: 0.019223 L1: 0.011152 Grad: 0.080580 Thermal: 0.000256 LR: 9.27e-06\n",
      "Epoch  14 [4900/10697 ( 45.8%)] Loss: 0.019223 L1: 0.011152 Grad: 0.080580 Thermal: 0.000256 LR: 9.27e-06\n",
      "Epoch  14 [4950/10697 ( 46.3%)] Loss: 0.020851 L1: 0.012095 Grad: 0.087431 Thermal: 0.000275 LR: 9.27e-06\n",
      "Epoch  14 [4950/10697 ( 46.3%)] Loss: 0.020851 L1: 0.012095 Grad: 0.087431 Thermal: 0.000275 LR: 9.27e-06\n",
      "Epoch  14 [5000/10697 ( 46.7%)] Loss: 0.016744 L1: 0.009645 Grad: 0.070889 Thermal: 0.000212 LR: 9.27e-06\n",
      "Epoch  14 [5000/10697 ( 46.7%)] Loss: 0.016744 L1: 0.009645 Grad: 0.070889 Thermal: 0.000212 LR: 9.27e-06\n",
      "Epoch  14 [5050/10697 ( 47.2%)] Loss: 0.024351 L1: 0.014229 Grad: 0.101001 Thermal: 0.000428 LR: 9.27e-06\n",
      "Epoch  14 [5050/10697 ( 47.2%)] Loss: 0.024351 L1: 0.014229 Grad: 0.101001 Thermal: 0.000428 LR: 9.27e-06\n",
      "Epoch  14 [5100/10697 ( 47.7%)] Loss: 0.020144 L1: 0.011806 Grad: 0.083245 Thermal: 0.000279 LR: 9.27e-06\n",
      "Epoch  14 [5100/10697 ( 47.7%)] Loss: 0.020144 L1: 0.011806 Grad: 0.083245 Thermal: 0.000279 LR: 9.27e-06\n",
      "Epoch  14 [5150/10697 ( 48.1%)] Loss: 0.029940 L1: 0.017601 Grad: 0.123104 Thermal: 0.000565 LR: 9.27e-06\n",
      "Epoch  14 [5150/10697 ( 48.1%)] Loss: 0.029940 L1: 0.017601 Grad: 0.123104 Thermal: 0.000565 LR: 9.27e-06\n",
      "Epoch  14 [5200/10697 ( 48.6%)] Loss: 0.029346 L1: 0.016954 Grad: 0.123635 Thermal: 0.000563 LR: 9.27e-06\n",
      "Epoch  14 [5200/10697 ( 48.6%)] Loss: 0.029346 L1: 0.016954 Grad: 0.123635 Thermal: 0.000563 LR: 9.27e-06\n",
      "Epoch  14 [5250/10697 ( 49.1%)] Loss: 0.020656 L1: 0.011597 Grad: 0.090449 Thermal: 0.000281 LR: 9.27e-06\n",
      "Epoch  14 [5250/10697 ( 49.1%)] Loss: 0.020656 L1: 0.011597 Grad: 0.090449 Thermal: 0.000281 LR: 9.27e-06\n",
      "Epoch  14 [5300/10697 ( 49.5%)] Loss: 0.025528 L1: 0.015055 Grad: 0.104522 Thermal: 0.000420 LR: 9.27e-06\n",
      "Epoch  14 [5300/10697 ( 49.5%)] Loss: 0.025528 L1: 0.015055 Grad: 0.104522 Thermal: 0.000420 LR: 9.27e-06\n",
      "Epoch  14 [5350/10697 ( 50.0%)] Loss: 0.032835 L1: 0.018689 Grad: 0.141111 Thermal: 0.000684 LR: 9.27e-06\n",
      "Epoch  14 [5350/10697 ( 50.0%)] Loss: 0.032835 L1: 0.018689 Grad: 0.141111 Thermal: 0.000684 LR: 9.27e-06\n",
      "Epoch  14 [5400/10697 ( 50.5%)] Loss: 0.028485 L1: 0.016889 Grad: 0.115689 Thermal: 0.000555 LR: 9.27e-06\n",
      "Epoch  14 [5400/10697 ( 50.5%)] Loss: 0.028485 L1: 0.016889 Grad: 0.115689 Thermal: 0.000555 LR: 9.27e-06\n",
      "Epoch  14 [5450/10697 ( 50.9%)] Loss: 0.034994 L1: 0.019859 Grad: 0.150961 Thermal: 0.000769 LR: 9.27e-06\n",
      "Epoch  14 [5450/10697 ( 50.9%)] Loss: 0.034994 L1: 0.019859 Grad: 0.150961 Thermal: 0.000769 LR: 9.27e-06\n",
      "Epoch  14 [5500/10697 ( 51.4%)] Loss: 0.034399 L1: 0.019199 Grad: 0.151546 Thermal: 0.000912 LR: 9.27e-06\n",
      "Epoch  14 [5500/10697 ( 51.4%)] Loss: 0.034399 L1: 0.019199 Grad: 0.151546 Thermal: 0.000912 LR: 9.27e-06\n",
      "Epoch  14 [5550/10697 ( 51.9%)] Loss: 0.027618 L1: 0.016537 Grad: 0.110548 Thermal: 0.000511 LR: 9.27e-06\n",
      "Epoch  14 [5550/10697 ( 51.9%)] Loss: 0.027618 L1: 0.016537 Grad: 0.110548 Thermal: 0.000511 LR: 9.27e-06\n",
      "Epoch  14 [5600/10697 ( 52.4%)] Loss: 0.023719 L1: 0.013962 Grad: 0.097405 Thermal: 0.000339 LR: 9.27e-06\n",
      "Epoch  14 [5600/10697 ( 52.4%)] Loss: 0.023719 L1: 0.013962 Grad: 0.097405 Thermal: 0.000339 LR: 9.27e-06\n",
      "Epoch  14 [5650/10697 ( 52.8%)] Loss: 0.029967 L1: 0.017688 Grad: 0.122509 Thermal: 0.000565 LR: 9.27e-06\n",
      "Epoch  14 [5650/10697 ( 52.8%)] Loss: 0.029967 L1: 0.017688 Grad: 0.122509 Thermal: 0.000565 LR: 9.27e-06\n",
      "Epoch  14 [5700/10697 ( 53.3%)] Loss: 0.035117 L1: 0.020395 Grad: 0.146820 Thermal: 0.000790 LR: 9.27e-06\n",
      "Epoch  14 [5700/10697 ( 53.3%)] Loss: 0.035117 L1: 0.020395 Grad: 0.146820 Thermal: 0.000790 LR: 9.27e-06\n",
      "Epoch  14 [5750/10697 ( 53.8%)] Loss: 0.027489 L1: 0.016255 Grad: 0.112090 Thermal: 0.000490 LR: 9.27e-06\n",
      "Epoch  14 [5750/10697 ( 53.8%)] Loss: 0.027489 L1: 0.016255 Grad: 0.112090 Thermal: 0.000490 LR: 9.27e-06\n",
      "Epoch  14 [5800/10697 ( 54.2%)] Loss: 0.023113 L1: 0.013062 Grad: 0.100331 Thermal: 0.000353 LR: 9.27e-06\n",
      "Epoch  14 [5800/10697 ( 54.2%)] Loss: 0.023113 L1: 0.013062 Grad: 0.100331 Thermal: 0.000353 LR: 9.27e-06\n",
      "Epoch  14 [5850/10697 ( 54.7%)] Loss: 0.028882 L1: 0.016609 Grad: 0.122489 Thermal: 0.000491 LR: 9.27e-06\n",
      "Epoch  14 [5850/10697 ( 54.7%)] Loss: 0.028882 L1: 0.016609 Grad: 0.122489 Thermal: 0.000491 LR: 9.27e-06\n",
      "Epoch  14 [5900/10697 ( 55.2%)] Loss: 0.028055 L1: 0.016368 Grad: 0.116641 Thermal: 0.000471 LR: 9.27e-06\n",
      "Epoch  14 [5900/10697 ( 55.2%)] Loss: 0.028055 L1: 0.016368 Grad: 0.116641 Thermal: 0.000471 LR: 9.27e-06\n",
      "Epoch  14 [5950/10697 ( 55.6%)] Loss: 0.028356 L1: 0.016482 Grad: 0.118511 Thermal: 0.000470 LR: 9.27e-06\n",
      "Epoch  14 [5950/10697 ( 55.6%)] Loss: 0.028356 L1: 0.016482 Grad: 0.118511 Thermal: 0.000470 LR: 9.27e-06\n",
      "Epoch  14 [6000/10697 ( 56.1%)] Loss: 0.030502 L1: 0.017582 Grad: 0.128899 Thermal: 0.000605 LR: 9.27e-06\n",
      "Epoch  14 [6000/10697 ( 56.1%)] Loss: 0.030502 L1: 0.017582 Grad: 0.128899 Thermal: 0.000605 LR: 9.27e-06\n",
      "Epoch  14 [6050/10697 ( 56.6%)] Loss: 0.025202 L1: 0.015094 Grad: 0.100875 Thermal: 0.000414 LR: 9.27e-06\n",
      "Epoch  14 [6050/10697 ( 56.6%)] Loss: 0.025202 L1: 0.015094 Grad: 0.100875 Thermal: 0.000414 LR: 9.27e-06\n",
      "Epoch  14 [6100/10697 ( 57.0%)] Loss: 0.026779 L1: 0.015561 Grad: 0.111945 Thermal: 0.000477 LR: 9.27e-06\n",
      "Epoch  14 [6100/10697 ( 57.0%)] Loss: 0.026779 L1: 0.015561 Grad: 0.111945 Thermal: 0.000477 LR: 9.27e-06\n",
      "Epoch  14 [6150/10697 ( 57.5%)] Loss: 0.026512 L1: 0.015453 Grad: 0.110351 Thermal: 0.000480 LR: 9.27e-06\n",
      "Epoch  14 [6150/10697 ( 57.5%)] Loss: 0.026512 L1: 0.015453 Grad: 0.110351 Thermal: 0.000480 LR: 9.27e-06\n",
      "Epoch  14 [6200/10697 ( 58.0%)] Loss: 0.029854 L1: 0.017596 Grad: 0.122296 Thermal: 0.000567 LR: 9.27e-06\n",
      "Epoch  14 [6200/10697 ( 58.0%)] Loss: 0.029854 L1: 0.017596 Grad: 0.122296 Thermal: 0.000567 LR: 9.27e-06\n",
      "Epoch  14 [6250/10697 ( 58.4%)] Loss: 0.021248 L1: 0.012259 Grad: 0.089726 Thermal: 0.000331 LR: 9.27e-06\n",
      "Epoch  14 [6250/10697 ( 58.4%)] Loss: 0.021248 L1: 0.012259 Grad: 0.089726 Thermal: 0.000331 LR: 9.27e-06\n",
      "Epoch  14 [6300/10697 ( 58.9%)] Loss: 0.022063 L1: 0.013170 Grad: 0.088766 Thermal: 0.000309 LR: 9.27e-06\n",
      "Epoch  14 [6300/10697 ( 58.9%)] Loss: 0.022063 L1: 0.013170 Grad: 0.088766 Thermal: 0.000309 LR: 9.27e-06\n",
      "Epoch  14 [6350/10697 ( 59.4%)] Loss: 0.025064 L1: 0.014353 Grad: 0.106904 Thermal: 0.000421 LR: 9.27e-06\n",
      "Epoch  14 [6350/10697 ( 59.4%)] Loss: 0.025064 L1: 0.014353 Grad: 0.106904 Thermal: 0.000421 LR: 9.27e-06\n",
      "Epoch  14 [6400/10697 ( 59.8%)] Loss: 0.028913 L1: 0.017040 Grad: 0.118449 Thermal: 0.000559 LR: 9.27e-06\n",
      "Epoch  14 [6400/10697 ( 59.8%)] Loss: 0.028913 L1: 0.017040 Grad: 0.118449 Thermal: 0.000559 LR: 9.27e-06\n",
      "Epoch  14 [6450/10697 ( 60.3%)] Loss: 0.027037 L1: 0.015567 Grad: 0.114463 Thermal: 0.000473 LR: 9.27e-06\n",
      "Epoch  14 [6450/10697 ( 60.3%)] Loss: 0.027037 L1: 0.015567 Grad: 0.114463 Thermal: 0.000473 LR: 9.27e-06\n",
      "Epoch  14 [6500/10697 ( 60.8%)] Loss: 0.024322 L1: 0.014077 Grad: 0.102261 Thermal: 0.000370 LR: 9.27e-06\n",
      "Epoch  14 [6500/10697 ( 60.8%)] Loss: 0.024322 L1: 0.014077 Grad: 0.102261 Thermal: 0.000370 LR: 9.27e-06\n",
      "Epoch  14 [6550/10697 ( 61.2%)] Loss: 0.027509 L1: 0.016100 Grad: 0.113841 Thermal: 0.000491 LR: 9.27e-06\n",
      "Epoch  14 [6550/10697 ( 61.2%)] Loss: 0.027509 L1: 0.016100 Grad: 0.113841 Thermal: 0.000491 LR: 9.27e-06\n",
      "Epoch  14 [6600/10697 ( 61.7%)] Loss: 0.021085 L1: 0.012515 Grad: 0.085544 Thermal: 0.000320 LR: 9.27e-06\n",
      "Epoch  14 [6600/10697 ( 61.7%)] Loss: 0.021085 L1: 0.012515 Grad: 0.085544 Thermal: 0.000320 LR: 9.27e-06\n",
      "Epoch  14 [6650/10697 ( 62.2%)] Loss: 0.029152 L1: 0.016825 Grad: 0.122996 Thermal: 0.000557 LR: 9.27e-06\n",
      "Epoch  14 [6650/10697 ( 62.2%)] Loss: 0.029152 L1: 0.016825 Grad: 0.122996 Thermal: 0.000557 LR: 9.27e-06\n",
      "Epoch  14 [6700/10697 ( 62.6%)] Loss: 0.024270 L1: 0.013993 Grad: 0.102494 Thermal: 0.000540 LR: 9.27e-06\n",
      "Epoch  14 [6700/10697 ( 62.6%)] Loss: 0.024270 L1: 0.013993 Grad: 0.102494 Thermal: 0.000540 LR: 9.27e-06\n",
      "Epoch  14 [6750/10697 ( 63.1%)] Loss: 0.027991 L1: 0.016008 Grad: 0.119598 Thermal: 0.000456 LR: 9.27e-06\n",
      "Epoch  14 [6750/10697 ( 63.1%)] Loss: 0.027991 L1: 0.016008 Grad: 0.119598 Thermal: 0.000456 LR: 9.27e-06\n",
      "Epoch  14 [6800/10697 ( 63.6%)] Loss: 0.022475 L1: 0.013320 Grad: 0.091365 Thermal: 0.000362 LR: 9.27e-06\n",
      "Epoch  14 [6800/10697 ( 63.6%)] Loss: 0.022475 L1: 0.013320 Grad: 0.091365 Thermal: 0.000362 LR: 9.27e-06\n",
      "Epoch  14 [6850/10697 ( 64.0%)] Loss: 0.020834 L1: 0.012287 Grad: 0.085313 Thermal: 0.000324 LR: 9.27e-06\n",
      "Epoch  14 [6850/10697 ( 64.0%)] Loss: 0.020834 L1: 0.012287 Grad: 0.085313 Thermal: 0.000324 LR: 9.27e-06\n",
      "Epoch  14 [6900/10697 ( 64.5%)] Loss: 0.024940 L1: 0.014822 Grad: 0.100979 Thermal: 0.000399 LR: 9.27e-06\n",
      "Epoch  14 [6900/10697 ( 64.5%)] Loss: 0.024940 L1: 0.014822 Grad: 0.100979 Thermal: 0.000399 LR: 9.27e-06\n",
      "Epoch  14 [6950/10697 ( 65.0%)] Loss: 0.024733 L1: 0.014284 Grad: 0.104297 Thermal: 0.000391 LR: 9.27e-06\n",
      "Epoch  14 [6950/10697 ( 65.0%)] Loss: 0.024733 L1: 0.014284 Grad: 0.104297 Thermal: 0.000391 LR: 9.27e-06\n",
      "Epoch  14 [7000/10697 ( 65.4%)] Loss: 0.025760 L1: 0.014791 Grad: 0.109440 Thermal: 0.000497 LR: 9.27e-06\n",
      "Epoch  14 [7000/10697 ( 65.4%)] Loss: 0.025760 L1: 0.014791 Grad: 0.109440 Thermal: 0.000497 LR: 9.27e-06\n",
      "Epoch  14 [7050/10697 ( 65.9%)] Loss: 0.027020 L1: 0.015692 Grad: 0.113008 Thermal: 0.000541 LR: 9.27e-06\n",
      "Epoch  14 [7050/10697 ( 65.9%)] Loss: 0.027020 L1: 0.015692 Grad: 0.113008 Thermal: 0.000541 LR: 9.27e-06\n",
      "Epoch  14 [7100/10697 ( 66.4%)] Loss: 0.038392 L1: 0.022169 Grad: 0.161788 Thermal: 0.000882 LR: 9.27e-06\n",
      "Epoch  14 [7100/10697 ( 66.4%)] Loss: 0.038392 L1: 0.022169 Grad: 0.161788 Thermal: 0.000882 LR: 9.27e-06\n",
      "Epoch  14 [7150/10697 ( 66.8%)] Loss: 0.026111 L1: 0.015072 Grad: 0.110155 Thermal: 0.000462 LR: 9.27e-06\n",
      "Epoch  14 [7150/10697 ( 66.8%)] Loss: 0.026111 L1: 0.015072 Grad: 0.110155 Thermal: 0.000462 LR: 9.27e-06\n",
      "Epoch  14 [7200/10697 ( 67.3%)] Loss: 0.033259 L1: 0.019263 Grad: 0.139649 Thermal: 0.000626 LR: 9.27e-06\n",
      "Epoch  14 [7200/10697 ( 67.3%)] Loss: 0.033259 L1: 0.019263 Grad: 0.139649 Thermal: 0.000626 LR: 9.27e-06\n",
      "Epoch  14 [7250/10697 ( 67.8%)] Loss: 0.023951 L1: 0.013691 Grad: 0.102400 Thermal: 0.000396 LR: 9.27e-06\n",
      "Epoch  14 [7250/10697 ( 67.8%)] Loss: 0.023951 L1: 0.013691 Grad: 0.102400 Thermal: 0.000396 LR: 9.27e-06\n",
      "Epoch  14 [7300/10697 ( 68.2%)] Loss: 0.026841 L1: 0.016182 Grad: 0.106357 Thermal: 0.000475 LR: 9.27e-06\n",
      "Epoch  14 [7300/10697 ( 68.2%)] Loss: 0.026841 L1: 0.016182 Grad: 0.106357 Thermal: 0.000475 LR: 9.27e-06\n",
      "Epoch  14 [7350/10697 ( 68.7%)] Loss: 0.022509 L1: 0.013298 Grad: 0.091940 Thermal: 0.000343 LR: 9.27e-06\n",
      "Epoch  14 [7350/10697 ( 68.7%)] Loss: 0.022509 L1: 0.013298 Grad: 0.091940 Thermal: 0.000343 LR: 9.27e-06\n",
      "Epoch  14 [7400/10697 ( 69.2%)] Loss: 0.018275 L1: 0.010445 Grad: 0.078180 Thermal: 0.000243 LR: 9.27e-06\n",
      "Epoch  14 [7400/10697 ( 69.2%)] Loss: 0.018275 L1: 0.010445 Grad: 0.078180 Thermal: 0.000243 LR: 9.27e-06\n",
      "Epoch  14 [7450/10697 ( 69.6%)] Loss: 0.023022 L1: 0.013468 Grad: 0.095372 Thermal: 0.000326 LR: 9.27e-06\n",
      "Epoch  14 [7450/10697 ( 69.6%)] Loss: 0.023022 L1: 0.013468 Grad: 0.095372 Thermal: 0.000326 LR: 9.27e-06\n",
      "Epoch  14 [7500/10697 ( 70.1%)] Loss: 0.025437 L1: 0.014993 Grad: 0.104237 Thermal: 0.000407 LR: 9.27e-06\n",
      "Epoch  14 [7500/10697 ( 70.1%)] Loss: 0.025437 L1: 0.014993 Grad: 0.104237 Thermal: 0.000407 LR: 9.27e-06\n",
      "Epoch  14 [7550/10697 ( 70.6%)] Loss: 0.028028 L1: 0.015982 Grad: 0.120229 Thermal: 0.000467 LR: 9.27e-06\n",
      "Epoch  14 [7550/10697 ( 70.6%)] Loss: 0.028028 L1: 0.015982 Grad: 0.120229 Thermal: 0.000467 LR: 9.27e-06\n",
      "Epoch  14 [7600/10697 ( 71.0%)] Loss: 0.027220 L1: 0.015820 Grad: 0.113765 Thermal: 0.000466 LR: 9.27e-06\n",
      "Epoch  14 [7600/10697 ( 71.0%)] Loss: 0.027220 L1: 0.015820 Grad: 0.113765 Thermal: 0.000466 LR: 9.27e-06\n",
      "Epoch  14 [7650/10697 ( 71.5%)] Loss: 0.030044 L1: 0.017517 Grad: 0.124975 Thermal: 0.000580 LR: 9.27e-06\n",
      "Epoch  14 [7650/10697 ( 71.5%)] Loss: 0.030044 L1: 0.017517 Grad: 0.124975 Thermal: 0.000580 LR: 9.27e-06\n",
      "Epoch  14 [7700/10697 ( 72.0%)] Loss: 0.026653 L1: 0.015680 Grad: 0.109511 Thermal: 0.000447 LR: 9.27e-06\n",
      "Epoch  14 [7700/10697 ( 72.0%)] Loss: 0.026653 L1: 0.015680 Grad: 0.109511 Thermal: 0.000447 LR: 9.27e-06\n",
      "Epoch  14 [7750/10697 ( 72.5%)] Loss: 0.031231 L1: 0.018444 Grad: 0.127550 Thermal: 0.000653 LR: 9.27e-06\n",
      "Epoch  14 [7750/10697 ( 72.5%)] Loss: 0.031231 L1: 0.018444 Grad: 0.127550 Thermal: 0.000653 LR: 9.27e-06\n",
      "Epoch  14 [7800/10697 ( 72.9%)] Loss: 0.023655 L1: 0.013292 Grad: 0.103460 Thermal: 0.000329 LR: 9.27e-06\n",
      "Epoch  14 [7800/10697 ( 72.9%)] Loss: 0.023655 L1: 0.013292 Grad: 0.103460 Thermal: 0.000329 LR: 9.27e-06\n",
      "Epoch  14 [7850/10697 ( 73.4%)] Loss: 0.024869 L1: 0.014869 Grad: 0.099802 Thermal: 0.000393 LR: 9.27e-06\n",
      "Epoch  14 [7850/10697 ( 73.4%)] Loss: 0.024869 L1: 0.014869 Grad: 0.099802 Thermal: 0.000393 LR: 9.27e-06\n",
      "Epoch  14 [7900/10697 ( 73.9%)] Loss: 0.026082 L1: 0.015348 Grad: 0.107130 Thermal: 0.000437 LR: 9.27e-06\n",
      "Epoch  14 [7900/10697 ( 73.9%)] Loss: 0.026082 L1: 0.015348 Grad: 0.107130 Thermal: 0.000437 LR: 9.27e-06\n",
      "Epoch  14 [7950/10697 ( 74.3%)] Loss: 0.022472 L1: 0.012823 Grad: 0.096295 Thermal: 0.000398 LR: 9.27e-06\n",
      "Epoch  14 [7950/10697 ( 74.3%)] Loss: 0.022472 L1: 0.012823 Grad: 0.096295 Thermal: 0.000398 LR: 9.27e-06\n",
      "Epoch  14 [8000/10697 ( 74.8%)] Loss: 0.022659 L1: 0.013248 Grad: 0.093947 Thermal: 0.000317 LR: 9.27e-06\n",
      "Epoch  14 [8000/10697 ( 74.8%)] Loss: 0.022659 L1: 0.013248 Grad: 0.093947 Thermal: 0.000317 LR: 9.27e-06\n",
      "Epoch  14 [8050/10697 ( 75.3%)] Loss: 0.024867 L1: 0.014599 Grad: 0.102477 Thermal: 0.000396 LR: 9.27e-06\n",
      "Epoch  14 [8050/10697 ( 75.3%)] Loss: 0.024867 L1: 0.014599 Grad: 0.102477 Thermal: 0.000396 LR: 9.27e-06\n",
      "Epoch  14 [8100/10697 ( 75.7%)] Loss: 0.026663 L1: 0.015464 Grad: 0.111768 Thermal: 0.000442 LR: 9.27e-06\n",
      "Epoch  14 [8100/10697 ( 75.7%)] Loss: 0.026663 L1: 0.015464 Grad: 0.111768 Thermal: 0.000442 LR: 9.27e-06\n",
      "Epoch  14 [8150/10697 ( 76.2%)] Loss: 0.028234 L1: 0.016543 Grad: 0.116676 Thermal: 0.000458 LR: 9.27e-06\n",
      "Epoch  14 [8150/10697 ( 76.2%)] Loss: 0.028234 L1: 0.016543 Grad: 0.116676 Thermal: 0.000458 LR: 9.27e-06\n",
      "Epoch  14 [8200/10697 ( 76.7%)] Loss: 0.028748 L1: 0.016133 Grad: 0.125886 Thermal: 0.000527 LR: 9.27e-06\n",
      "Epoch  14 [8200/10697 ( 76.7%)] Loss: 0.028748 L1: 0.016133 Grad: 0.125886 Thermal: 0.000527 LR: 9.27e-06\n",
      "Epoch  14 [8250/10697 ( 77.1%)] Loss: 0.028513 L1: 0.016704 Grad: 0.117838 Thermal: 0.000508 LR: 9.27e-06\n",
      "Epoch  14 [8250/10697 ( 77.1%)] Loss: 0.028513 L1: 0.016704 Grad: 0.117838 Thermal: 0.000508 LR: 9.27e-06\n",
      "Epoch  14 [8300/10697 ( 77.6%)] Loss: 0.028663 L1: 0.016612 Grad: 0.120242 Thermal: 0.000532 LR: 9.27e-06\n",
      "Epoch  14 [8300/10697 ( 77.6%)] Loss: 0.028663 L1: 0.016612 Grad: 0.120242 Thermal: 0.000532 LR: 9.27e-06\n",
      "Epoch  14 [8350/10697 ( 78.1%)] Loss: 0.025078 L1: 0.014722 Grad: 0.103350 Thermal: 0.000402 LR: 9.27e-06\n",
      "Epoch  14 [8350/10697 ( 78.1%)] Loss: 0.025078 L1: 0.014722 Grad: 0.103350 Thermal: 0.000402 LR: 9.27e-06\n",
      "Epoch  14 [8400/10697 ( 78.5%)] Loss: 0.028806 L1: 0.017031 Grad: 0.117491 Thermal: 0.000517 LR: 9.27e-06\n",
      "Epoch  14 [8400/10697 ( 78.5%)] Loss: 0.028806 L1: 0.017031 Grad: 0.117491 Thermal: 0.000517 LR: 9.27e-06\n",
      "Epoch  14 [8450/10697 ( 79.0%)] Loss: 0.025914 L1: 0.014701 Grad: 0.111878 Thermal: 0.000511 LR: 9.27e-06\n",
      "Epoch  14 [8450/10697 ( 79.0%)] Loss: 0.025914 L1: 0.014701 Grad: 0.111878 Thermal: 0.000511 LR: 9.27e-06\n",
      "Epoch  14 [8500/10697 ( 79.5%)] Loss: 0.026215 L1: 0.015815 Grad: 0.103763 Thermal: 0.000460 LR: 9.27e-06\n",
      "Epoch  14 [8500/10697 ( 79.5%)] Loss: 0.026215 L1: 0.015815 Grad: 0.103763 Thermal: 0.000460 LR: 9.27e-06\n",
      "Epoch  14 [8550/10697 ( 79.9%)] Loss: 0.027779 L1: 0.015886 Grad: 0.118695 Thermal: 0.000466 LR: 9.27e-06\n",
      "Epoch  14 [8550/10697 ( 79.9%)] Loss: 0.027779 L1: 0.015886 Grad: 0.118695 Thermal: 0.000466 LR: 9.27e-06\n",
      "Epoch  14 [8600/10697 ( 80.4%)] Loss: 0.029824 L1: 0.017339 Grad: 0.124582 Thermal: 0.000537 LR: 9.27e-06\n",
      "Epoch  14 [8600/10697 ( 80.4%)] Loss: 0.029824 L1: 0.017339 Grad: 0.124582 Thermal: 0.000537 LR: 9.27e-06\n",
      "Epoch  14 [8650/10697 ( 80.9%)] Loss: 0.029403 L1: 0.017144 Grad: 0.122321 Thermal: 0.000530 LR: 9.27e-06\n",
      "Epoch  14 [8650/10697 ( 80.9%)] Loss: 0.029403 L1: 0.017144 Grad: 0.122321 Thermal: 0.000530 LR: 9.27e-06\n",
      "Epoch  14 [8700/10697 ( 81.3%)] Loss: 0.029175 L1: 0.017201 Grad: 0.119449 Thermal: 0.000595 LR: 9.27e-06\n",
      "Epoch  14 [8700/10697 ( 81.3%)] Loss: 0.029175 L1: 0.017201 Grad: 0.119449 Thermal: 0.000595 LR: 9.27e-06\n",
      "Epoch  14 [8750/10697 ( 81.8%)] Loss: 0.023617 L1: 0.014140 Grad: 0.094586 Thermal: 0.000378 LR: 9.27e-06\n",
      "Epoch  14 [8750/10697 ( 81.8%)] Loss: 0.023617 L1: 0.014140 Grad: 0.094586 Thermal: 0.000378 LR: 9.27e-06\n",
      "Epoch  14 [8800/10697 ( 82.3%)] Loss: 0.027777 L1: 0.016584 Grad: 0.111687 Thermal: 0.000486 LR: 9.27e-06\n",
      "Epoch  14 [8800/10697 ( 82.3%)] Loss: 0.027777 L1: 0.016584 Grad: 0.111687 Thermal: 0.000486 LR: 9.27e-06\n",
      "Epoch  14 [8850/10697 ( 82.7%)] Loss: 0.032940 L1: 0.019034 Grad: 0.138742 Thermal: 0.000647 LR: 9.27e-06\n",
      "Epoch  14 [8850/10697 ( 82.7%)] Loss: 0.032940 L1: 0.019034 Grad: 0.138742 Thermal: 0.000647 LR: 9.27e-06\n",
      "Epoch  14 [8900/10697 ( 83.2%)] Loss: 0.022641 L1: 0.013150 Grad: 0.094722 Thermal: 0.000359 LR: 9.27e-06\n",
      "Epoch  14 [8900/10697 ( 83.2%)] Loss: 0.022641 L1: 0.013150 Grad: 0.094722 Thermal: 0.000359 LR: 9.27e-06\n",
      "Epoch  14 [8950/10697 ( 83.7%)] Loss: 0.026955 L1: 0.015353 Grad: 0.115801 Thermal: 0.000440 LR: 9.27e-06\n",
      "Epoch  14 [8950/10697 ( 83.7%)] Loss: 0.026955 L1: 0.015353 Grad: 0.115801 Thermal: 0.000440 LR: 9.27e-06\n",
      "Epoch  14 [9000/10697 ( 84.1%)] Loss: 0.026915 L1: 0.015156 Grad: 0.117356 Thermal: 0.000474 LR: 9.27e-06\n",
      "Epoch  14 [9000/10697 ( 84.1%)] Loss: 0.026915 L1: 0.015156 Grad: 0.117356 Thermal: 0.000474 LR: 9.27e-06\n",
      "Epoch  14 [9050/10697 ( 84.6%)] Loss: 0.029146 L1: 0.017102 Grad: 0.120194 Thermal: 0.000502 LR: 9.27e-06\n",
      "Epoch  14 [9050/10697 ( 84.6%)] Loss: 0.029146 L1: 0.017102 Grad: 0.120194 Thermal: 0.000502 LR: 9.27e-06\n",
      "Epoch  14 [9100/10697 ( 85.1%)] Loss: 0.026072 L1: 0.015208 Grad: 0.108383 Thermal: 0.000523 LR: 9.27e-06\n",
      "Epoch  14 [9100/10697 ( 85.1%)] Loss: 0.026072 L1: 0.015208 Grad: 0.108383 Thermal: 0.000523 LR: 9.27e-06\n",
      "Epoch  14 [9150/10697 ( 85.5%)] Loss: 0.035780 L1: 0.020337 Grad: 0.154060 Thermal: 0.000741 LR: 9.27e-06\n",
      "Epoch  14 [9150/10697 ( 85.5%)] Loss: 0.035780 L1: 0.020337 Grad: 0.154060 Thermal: 0.000741 LR: 9.27e-06\n",
      "Epoch  14 [9200/10697 ( 86.0%)] Loss: 0.029601 L1: 0.017445 Grad: 0.121252 Thermal: 0.000614 LR: 9.27e-06\n",
      "Epoch  14 [9200/10697 ( 86.0%)] Loss: 0.029601 L1: 0.017445 Grad: 0.121252 Thermal: 0.000614 LR: 9.27e-06\n",
      "Epoch  14 [9250/10697 ( 86.5%)] Loss: 0.030709 L1: 0.017821 Grad: 0.128597 Thermal: 0.000581 LR: 9.27e-06\n",
      "Epoch  14 [9250/10697 ( 86.5%)] Loss: 0.030709 L1: 0.017821 Grad: 0.128597 Thermal: 0.000581 LR: 9.27e-06\n",
      "Epoch  14 [9300/10697 ( 86.9%)] Loss: 0.024723 L1: 0.014588 Grad: 0.101164 Thermal: 0.000387 LR: 9.27e-06\n",
      "Epoch  14 [9300/10697 ( 86.9%)] Loss: 0.024723 L1: 0.014588 Grad: 0.101164 Thermal: 0.000387 LR: 9.27e-06\n",
      "Epoch  14 [9350/10697 ( 87.4%)] Loss: 0.021709 L1: 0.012235 Grad: 0.094583 Thermal: 0.000318 LR: 9.27e-06\n",
      "Epoch  14 [9350/10697 ( 87.4%)] Loss: 0.021709 L1: 0.012235 Grad: 0.094583 Thermal: 0.000318 LR: 9.27e-06\n",
      "Epoch  14 [9400/10697 ( 87.9%)] Loss: 0.025351 L1: 0.014480 Grad: 0.108495 Thermal: 0.000439 LR: 9.27e-06\n",
      "Epoch  14 [9400/10697 ( 87.9%)] Loss: 0.025351 L1: 0.014480 Grad: 0.108495 Thermal: 0.000439 LR: 9.27e-06\n",
      "Epoch  14 [9450/10697 ( 88.3%)] Loss: 0.020768 L1: 0.011910 Grad: 0.088434 Thermal: 0.000288 LR: 9.27e-06\n",
      "Epoch  14 [9450/10697 ( 88.3%)] Loss: 0.020768 L1: 0.011910 Grad: 0.088434 Thermal: 0.000288 LR: 9.27e-06\n",
      "Epoch  14 [9500/10697 ( 88.8%)] Loss: 0.027974 L1: 0.016022 Grad: 0.119266 Thermal: 0.000516 LR: 9.27e-06\n",
      "Epoch  14 [9500/10697 ( 88.8%)] Loss: 0.027974 L1: 0.016022 Grad: 0.119266 Thermal: 0.000516 LR: 9.27e-06\n",
      "Epoch  14 [9550/10697 ( 89.3%)] Loss: 0.025800 L1: 0.014933 Grad: 0.108394 Thermal: 0.000548 LR: 9.27e-06\n",
      "Epoch  14 [9550/10697 ( 89.3%)] Loss: 0.025800 L1: 0.014933 Grad: 0.108394 Thermal: 0.000548 LR: 9.27e-06\n",
      "Epoch  14 [9600/10697 ( 89.7%)] Loss: 0.026815 L1: 0.015312 Grad: 0.114801 Thermal: 0.000469 LR: 9.27e-06\n",
      "Epoch  14 [9600/10697 ( 89.7%)] Loss: 0.026815 L1: 0.015312 Grad: 0.114801 Thermal: 0.000469 LR: 9.27e-06\n",
      "Epoch  14 [9650/10697 ( 90.2%)] Loss: 0.028654 L1: 0.016342 Grad: 0.122881 Thermal: 0.000484 LR: 9.27e-06\n",
      "Epoch  14 [9650/10697 ( 90.2%)] Loss: 0.028654 L1: 0.016342 Grad: 0.122881 Thermal: 0.000484 LR: 9.27e-06\n",
      "Epoch  14 [9700/10697 ( 90.7%)] Loss: 0.025311 L1: 0.014973 Grad: 0.103178 Thermal: 0.000404 LR: 9.27e-06\n",
      "Epoch  14 [9700/10697 ( 90.7%)] Loss: 0.025311 L1: 0.014973 Grad: 0.103178 Thermal: 0.000404 LR: 9.27e-06\n",
      "Epoch  14 [9750/10697 ( 91.1%)] Loss: 0.026317 L1: 0.015749 Grad: 0.105478 Thermal: 0.000421 LR: 9.27e-06\n",
      "Epoch  14 [9750/10697 ( 91.1%)] Loss: 0.026317 L1: 0.015749 Grad: 0.105478 Thermal: 0.000421 LR: 9.27e-06\n",
      "Epoch  14 [9800/10697 ( 91.6%)] Loss: 0.027457 L1: 0.015465 Grad: 0.119700 Thermal: 0.000442 LR: 9.27e-06\n",
      "Epoch  14 [9800/10697 ( 91.6%)] Loss: 0.027457 L1: 0.015465 Grad: 0.119700 Thermal: 0.000442 LR: 9.27e-06\n",
      "Epoch  14 [9850/10697 ( 92.1%)] Loss: 0.029179 L1: 0.017238 Grad: 0.119132 Thermal: 0.000552 LR: 9.27e-06\n",
      "Epoch  14 [9850/10697 ( 92.1%)] Loss: 0.029179 L1: 0.017238 Grad: 0.119132 Thermal: 0.000552 LR: 9.27e-06\n",
      "Epoch  14 [9900/10697 ( 92.5%)] Loss: 0.023937 L1: 0.014032 Grad: 0.098848 Thermal: 0.000410 LR: 9.27e-06\n",
      "Epoch  14 [9900/10697 ( 92.5%)] Loss: 0.023937 L1: 0.014032 Grad: 0.098848 Thermal: 0.000410 LR: 9.27e-06\n",
      "Epoch  14 [9950/10697 ( 93.0%)] Loss: 0.024508 L1: 0.014414 Grad: 0.100741 Thermal: 0.000402 LR: 9.27e-06\n",
      "Epoch  14 [9950/10697 ( 93.0%)] Loss: 0.024508 L1: 0.014414 Grad: 0.100741 Thermal: 0.000402 LR: 9.27e-06\n",
      "Epoch  14 [10000/10697 ( 93.5%)] Loss: 0.026667 L1: 0.015589 Grad: 0.110561 Thermal: 0.000447 LR: 9.27e-06\n",
      "Epoch  14 [10000/10697 ( 93.5%)] Loss: 0.026667 L1: 0.015589 Grad: 0.110561 Thermal: 0.000447 LR: 9.27e-06\n",
      "Epoch  14 [10050/10697 ( 94.0%)] Loss: 0.029534 L1: 0.017292 Grad: 0.122164 Thermal: 0.000519 LR: 9.27e-06\n",
      "Epoch  14 [10050/10697 ( 94.0%)] Loss: 0.029534 L1: 0.017292 Grad: 0.122164 Thermal: 0.000519 LR: 9.27e-06\n",
      "Epoch  14 [10100/10697 ( 94.4%)] Loss: 0.028912 L1: 0.016710 Grad: 0.121768 Thermal: 0.000503 LR: 9.27e-06\n",
      "Epoch  14 [10100/10697 ( 94.4%)] Loss: 0.028912 L1: 0.016710 Grad: 0.121768 Thermal: 0.000503 LR: 9.27e-06\n",
      "Epoch  14 [10150/10697 ( 94.9%)] Loss: 0.028397 L1: 0.015938 Grad: 0.124347 Thermal: 0.000467 LR: 9.27e-06\n",
      "Epoch  14 [10150/10697 ( 94.9%)] Loss: 0.028397 L1: 0.015938 Grad: 0.124347 Thermal: 0.000467 LR: 9.27e-06\n",
      "Epoch  14 [10200/10697 ( 95.4%)] Loss: 0.027487 L1: 0.016443 Grad: 0.110202 Thermal: 0.000478 LR: 9.27e-06\n",
      "Epoch  14 [10200/10697 ( 95.4%)] Loss: 0.027487 L1: 0.016443 Grad: 0.110202 Thermal: 0.000478 LR: 9.27e-06\n",
      "Epoch  14 [10250/10697 ( 95.8%)] Loss: 0.024004 L1: 0.014019 Grad: 0.099646 Thermal: 0.000402 LR: 9.27e-06\n",
      "Epoch  14 [10250/10697 ( 95.8%)] Loss: 0.024004 L1: 0.014019 Grad: 0.099646 Thermal: 0.000402 LR: 9.27e-06\n",
      "Epoch  14 [10300/10697 ( 96.3%)] Loss: 0.026236 L1: 0.015576 Grad: 0.106391 Thermal: 0.000412 LR: 9.27e-06\n",
      "Epoch  14 [10300/10697 ( 96.3%)] Loss: 0.026236 L1: 0.015576 Grad: 0.106391 Thermal: 0.000412 LR: 9.27e-06\n",
      "Epoch  14 [10350/10697 ( 96.8%)] Loss: 0.032840 L1: 0.019079 Grad: 0.137295 Thermal: 0.000633 LR: 9.27e-06\n",
      "Epoch  14 [10350/10697 ( 96.8%)] Loss: 0.032840 L1: 0.019079 Grad: 0.137295 Thermal: 0.000633 LR: 9.27e-06\n",
      "Epoch  14 [10400/10697 ( 97.2%)] Loss: 0.029640 L1: 0.017752 Grad: 0.118588 Thermal: 0.000585 LR: 9.27e-06\n",
      "Epoch  14 [10400/10697 ( 97.2%)] Loss: 0.029640 L1: 0.017752 Grad: 0.118588 Thermal: 0.000585 LR: 9.27e-06\n",
      "Epoch  14 [10450/10697 ( 97.7%)] Loss: 0.027357 L1: 0.016060 Grad: 0.112724 Thermal: 0.000478 LR: 9.27e-06\n",
      "Epoch  14 [10450/10697 ( 97.7%)] Loss: 0.027357 L1: 0.016060 Grad: 0.112724 Thermal: 0.000478 LR: 9.27e-06\n",
      "Epoch  14 [10500/10697 ( 98.2%)] Loss: 0.018794 L1: 0.010874 Grad: 0.079055 Thermal: 0.000292 LR: 9.27e-06\n",
      "Epoch  14 [10500/10697 ( 98.2%)] Loss: 0.018794 L1: 0.010874 Grad: 0.079055 Thermal: 0.000292 LR: 9.27e-06\n",
      "Epoch  14 [10550/10697 ( 98.6%)] Loss: 0.026220 L1: 0.015040 Grad: 0.111573 Thermal: 0.000449 LR: 9.27e-06\n",
      "Epoch  14 [10550/10697 ( 98.6%)] Loss: 0.026220 L1: 0.015040 Grad: 0.111573 Thermal: 0.000449 LR: 9.27e-06\n",
      "Epoch  14 [10600/10697 ( 99.1%)] Loss: 0.027516 L1: 0.015837 Grad: 0.116555 Thermal: 0.000476 LR: 9.27e-06\n",
      "Epoch  14 [10600/10697 ( 99.1%)] Loss: 0.027516 L1: 0.015837 Grad: 0.116555 Thermal: 0.000476 LR: 9.27e-06\n",
      "Epoch  14 [10650/10697 ( 99.6%)] Loss: 0.025034 L1: 0.015190 Grad: 0.098225 Thermal: 0.000431 LR: 9.27e-06\n",
      "Epoch  14 [10650/10697 ( 99.6%)] Loss: 0.025034 L1: 0.015190 Grad: 0.098225 Thermal: 0.000431 LR: 9.27e-06\n",
      "Epoch  14 Summary: Loss=0.026680 (L1:0.0155, Grad:0.1112, Thermal:0.0005) Val_PSNR=0.00dB Best=33.82dB Time=53.8min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  14 Summary: Loss=0.026680 (L1:0.0155, Grad:0.1112, Thermal:0.0005) Val_PSNR=0.00dB Best=33.82dB Time=53.8min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  15 [   0/10697 (  0.0%)] Loss: 0.028620 L1: 0.016810 Grad: 0.117858 Thermal: 0.000496 LR: 9.17e-06\n",
      "Epoch  15 [   0/10697 (  0.0%)] Loss: 0.028620 L1: 0.016810 Grad: 0.117858 Thermal: 0.000496 LR: 9.17e-06\n",
      "Epoch  15 [  50/10697 (  0.5%)] Loss: 0.022222 L1: 0.012783 Grad: 0.094206 Thermal: 0.000362 LR: 9.17e-06\n",
      "Epoch  15 [  50/10697 (  0.5%)] Loss: 0.022222 L1: 0.012783 Grad: 0.094206 Thermal: 0.000362 LR: 9.17e-06\n",
      "Epoch  15 [ 100/10697 (  0.9%)] Loss: 0.027575 L1: 0.015372 Grad: 0.121766 Thermal: 0.000530 LR: 9.17e-06\n",
      "Epoch  15 [ 100/10697 (  0.9%)] Loss: 0.027575 L1: 0.015372 Grad: 0.121766 Thermal: 0.000530 LR: 9.17e-06\n",
      "Epoch  15 [ 150/10697 (  1.4%)] Loss: 0.027170 L1: 0.015807 Grad: 0.113401 Thermal: 0.000448 LR: 9.17e-06\n",
      "Epoch  15 [ 150/10697 (  1.4%)] Loss: 0.027170 L1: 0.015807 Grad: 0.113401 Thermal: 0.000448 LR: 9.17e-06\n",
      "Epoch  15 [ 200/10697 (  1.9%)] Loss: 0.027774 L1: 0.015879 Grad: 0.118702 Thermal: 0.000492 LR: 9.17e-06\n",
      "Epoch  15 [ 200/10697 (  1.9%)] Loss: 0.027774 L1: 0.015879 Grad: 0.118702 Thermal: 0.000492 LR: 9.17e-06\n",
      "Epoch  15 [ 250/10697 (  2.3%)] Loss: 0.026310 L1: 0.015833 Grad: 0.104540 Thermal: 0.000460 LR: 9.17e-06\n",
      "Epoch  15 [ 250/10697 (  2.3%)] Loss: 0.026310 L1: 0.015833 Grad: 0.104540 Thermal: 0.000460 LR: 9.17e-06\n",
      "Epoch  15 [ 300/10697 (  2.8%)] Loss: 0.027782 L1: 0.016271 Grad: 0.114838 Thermal: 0.000528 LR: 9.17e-06\n",
      "Epoch  15 [ 300/10697 (  2.8%)] Loss: 0.027782 L1: 0.016271 Grad: 0.114838 Thermal: 0.000528 LR: 9.17e-06\n",
      "Epoch  15 [ 350/10697 (  3.3%)] Loss: 0.027079 L1: 0.015676 Grad: 0.113800 Thermal: 0.000467 LR: 9.17e-06\n",
      "Epoch  15 [ 350/10697 (  3.3%)] Loss: 0.027079 L1: 0.015676 Grad: 0.113800 Thermal: 0.000467 LR: 9.17e-06\n",
      "Epoch  15 [ 400/10697 (  3.7%)] Loss: 0.025655 L1: 0.015390 Grad: 0.102450 Thermal: 0.000411 LR: 9.17e-06\n",
      "Epoch  15 [ 400/10697 (  3.7%)] Loss: 0.025655 L1: 0.015390 Grad: 0.102450 Thermal: 0.000411 LR: 9.17e-06\n",
      "Epoch  15 [ 450/10697 (  4.2%)] Loss: 0.023269 L1: 0.013463 Grad: 0.097862 Thermal: 0.000389 LR: 9.17e-06\n",
      "Epoch  15 [ 450/10697 (  4.2%)] Loss: 0.023269 L1: 0.013463 Grad: 0.097862 Thermal: 0.000389 LR: 9.17e-06\n",
      "Epoch  15 [ 500/10697 (  4.7%)] Loss: 0.029369 L1: 0.017405 Grad: 0.119356 Thermal: 0.000564 LR: 9.17e-06\n",
      "Epoch  15 [ 500/10697 (  4.7%)] Loss: 0.029369 L1: 0.017405 Grad: 0.119356 Thermal: 0.000564 LR: 9.17e-06\n",
      "Epoch  15 [ 550/10697 (  5.1%)] Loss: 0.023665 L1: 0.013971 Grad: 0.096758 Thermal: 0.000364 LR: 9.17e-06\n",
      "Epoch  15 [ 550/10697 (  5.1%)] Loss: 0.023665 L1: 0.013971 Grad: 0.096758 Thermal: 0.000364 LR: 9.17e-06\n",
      "Epoch  15 [ 600/10697 (  5.6%)] Loss: 0.026129 L1: 0.015579 Grad: 0.105275 Thermal: 0.000447 LR: 9.17e-06\n",
      "Epoch  15 [ 600/10697 (  5.6%)] Loss: 0.026129 L1: 0.015579 Grad: 0.105275 Thermal: 0.000447 LR: 9.17e-06\n",
      "Epoch  15 [ 650/10697 (  6.1%)] Loss: 0.024210 L1: 0.014229 Grad: 0.099622 Thermal: 0.000381 LR: 9.17e-06\n",
      "Epoch  15 [ 650/10697 (  6.1%)] Loss: 0.024210 L1: 0.014229 Grad: 0.099622 Thermal: 0.000381 LR: 9.17e-06\n",
      "Epoch  15 [ 700/10697 (  6.5%)] Loss: 0.029114 L1: 0.017261 Grad: 0.118255 Thermal: 0.000546 LR: 9.17e-06\n",
      "Epoch  15 [ 700/10697 (  6.5%)] Loss: 0.029114 L1: 0.017261 Grad: 0.118255 Thermal: 0.000546 LR: 9.17e-06\n",
      "Epoch  15 [ 750/10697 (  7.0%)] Loss: 0.027274 L1: 0.016122 Grad: 0.111274 Thermal: 0.000475 LR: 9.17e-06\n",
      "Epoch  15 [ 750/10697 (  7.0%)] Loss: 0.027274 L1: 0.016122 Grad: 0.111274 Thermal: 0.000475 LR: 9.17e-06\n",
      "Epoch  15 [ 800/10697 (  7.5%)] Loss: 0.028868 L1: 0.016837 Grad: 0.120060 Thermal: 0.000519 LR: 9.17e-06\n",
      "Epoch  15 [ 800/10697 (  7.5%)] Loss: 0.028868 L1: 0.016837 Grad: 0.120060 Thermal: 0.000519 LR: 9.17e-06\n",
      "Epoch  15 [ 850/10697 (  7.9%)] Loss: 0.029369 L1: 0.016630 Grad: 0.127113 Thermal: 0.000541 LR: 9.17e-06\n",
      "Epoch  15 [ 850/10697 (  7.9%)] Loss: 0.029369 L1: 0.016630 Grad: 0.127113 Thermal: 0.000541 LR: 9.17e-06\n",
      "Epoch  15 [ 900/10697 (  8.4%)] Loss: 0.024820 L1: 0.014792 Grad: 0.100077 Thermal: 0.000408 LR: 9.17e-06\n",
      "Epoch  15 [ 900/10697 (  8.4%)] Loss: 0.024820 L1: 0.014792 Grad: 0.100077 Thermal: 0.000408 LR: 9.17e-06\n",
      "Epoch  15 [ 950/10697 (  8.9%)] Loss: 0.023790 L1: 0.013435 Grad: 0.103356 Thermal: 0.000387 LR: 9.17e-06\n",
      "Epoch  15 [ 950/10697 (  8.9%)] Loss: 0.023790 L1: 0.013435 Grad: 0.103356 Thermal: 0.000387 LR: 9.17e-06\n",
      "Epoch  15 [1000/10697 (  9.3%)] Loss: 0.028047 L1: 0.016153 Grad: 0.118683 Thermal: 0.000508 LR: 9.17e-06\n",
      "Epoch  15 [1000/10697 (  9.3%)] Loss: 0.028047 L1: 0.016153 Grad: 0.118683 Thermal: 0.000508 LR: 9.17e-06\n",
      "Epoch  15 [1050/10697 (  9.8%)] Loss: 0.024116 L1: 0.014347 Grad: 0.097487 Thermal: 0.000394 LR: 9.17e-06\n",
      "Epoch  15 [1050/10697 (  9.8%)] Loss: 0.024116 L1: 0.014347 Grad: 0.097487 Thermal: 0.000394 LR: 9.17e-06\n",
      "Epoch  15 [1100/10697 ( 10.3%)] Loss: 0.031709 L1: 0.017817 Grad: 0.138621 Thermal: 0.000609 LR: 9.17e-06\n",
      "Epoch  15 [1100/10697 ( 10.3%)] Loss: 0.031709 L1: 0.017817 Grad: 0.138621 Thermal: 0.000609 LR: 9.17e-06\n",
      "Epoch  15 [1150/10697 ( 10.8%)] Loss: 0.035027 L1: 0.019755 Grad: 0.152351 Thermal: 0.000730 LR: 9.17e-06\n",
      "Epoch  15 [1150/10697 ( 10.8%)] Loss: 0.035027 L1: 0.019755 Grad: 0.152351 Thermal: 0.000730 LR: 9.17e-06\n",
      "Epoch  15 [1200/10697 ( 11.2%)] Loss: 0.027884 L1: 0.016251 Grad: 0.116062 Thermal: 0.000534 LR: 9.17e-06\n",
      "Epoch  15 [1200/10697 ( 11.2%)] Loss: 0.027884 L1: 0.016251 Grad: 0.116062 Thermal: 0.000534 LR: 9.17e-06\n",
      "Epoch  15 [1250/10697 ( 11.7%)] Loss: 0.030047 L1: 0.017755 Grad: 0.122634 Thermal: 0.000577 LR: 9.17e-06\n",
      "Epoch  15 [1250/10697 ( 11.7%)] Loss: 0.030047 L1: 0.017755 Grad: 0.122634 Thermal: 0.000577 LR: 9.17e-06\n",
      "Epoch  15 [1300/10697 ( 12.2%)] Loss: 0.026794 L1: 0.015466 Grad: 0.113040 Thermal: 0.000485 LR: 9.17e-06\n",
      "Epoch  15 [1300/10697 ( 12.2%)] Loss: 0.026794 L1: 0.015466 Grad: 0.113040 Thermal: 0.000485 LR: 9.17e-06\n",
      "Epoch  15 [1350/10697 ( 12.6%)] Loss: 0.031533 L1: 0.017467 Grad: 0.140329 Thermal: 0.000664 LR: 9.17e-06\n",
      "Epoch  15 [1350/10697 ( 12.6%)] Loss: 0.031533 L1: 0.017467 Grad: 0.140329 Thermal: 0.000664 LR: 9.17e-06\n",
      "Epoch  15 [1400/10697 ( 13.1%)] Loss: 0.029994 L1: 0.017604 Grad: 0.123611 Thermal: 0.000577 LR: 9.17e-06\n",
      "Epoch  15 [1400/10697 ( 13.1%)] Loss: 0.029994 L1: 0.017604 Grad: 0.123611 Thermal: 0.000577 LR: 9.17e-06\n",
      "Epoch  15 [1450/10697 ( 13.6%)] Loss: 0.018330 L1: 0.010322 Grad: 0.079969 Thermal: 0.000225 LR: 9.17e-06\n",
      "Epoch  15 [1450/10697 ( 13.6%)] Loss: 0.018330 L1: 0.010322 Grad: 0.079969 Thermal: 0.000225 LR: 9.17e-06\n",
      "Epoch  15 [1500/10697 ( 14.0%)] Loss: 0.028078 L1: 0.016822 Grad: 0.112311 Thermal: 0.000497 LR: 9.17e-06\n",
      "Epoch  15 [1500/10697 ( 14.0%)] Loss: 0.028078 L1: 0.016822 Grad: 0.112311 Thermal: 0.000497 LR: 9.17e-06\n",
      "Epoch  15 [1550/10697 ( 14.5%)] Loss: 0.030617 L1: 0.017742 Grad: 0.128481 Thermal: 0.000534 LR: 9.17e-06\n",
      "Epoch  15 [1550/10697 ( 14.5%)] Loss: 0.030617 L1: 0.017742 Grad: 0.128481 Thermal: 0.000534 LR: 9.17e-06\n",
      "Epoch  15 [1600/10697 ( 15.0%)] Loss: 0.025131 L1: 0.014911 Grad: 0.101995 Thermal: 0.000404 LR: 9.17e-06\n",
      "Epoch  15 [1600/10697 ( 15.0%)] Loss: 0.025131 L1: 0.014911 Grad: 0.101995 Thermal: 0.000404 LR: 9.17e-06\n",
      "Epoch  15 [1650/10697 ( 15.4%)] Loss: 0.029885 L1: 0.017937 Grad: 0.119205 Thermal: 0.000560 LR: 9.17e-06\n",
      "Epoch  15 [1650/10697 ( 15.4%)] Loss: 0.029885 L1: 0.017937 Grad: 0.119205 Thermal: 0.000560 LR: 9.17e-06\n",
      "Epoch  15 [1700/10697 ( 15.9%)] Loss: 0.027886 L1: 0.016541 Grad: 0.113204 Thermal: 0.000489 LR: 9.17e-06\n",
      "Epoch  15 [1700/10697 ( 15.9%)] Loss: 0.027886 L1: 0.016541 Grad: 0.113204 Thermal: 0.000489 LR: 9.17e-06\n",
      "Epoch  15 [1750/10697 ( 16.4%)] Loss: 0.026339 L1: 0.015428 Grad: 0.108881 Thermal: 0.000455 LR: 9.17e-06\n",
      "Epoch  15 [1750/10697 ( 16.4%)] Loss: 0.026339 L1: 0.015428 Grad: 0.108881 Thermal: 0.000455 LR: 9.17e-06\n",
      "Epoch  15 [1800/10697 ( 16.8%)] Loss: 0.024253 L1: 0.013449 Grad: 0.107836 Thermal: 0.000394 LR: 9.17e-06\n",
      "Epoch  15 [1800/10697 ( 16.8%)] Loss: 0.024253 L1: 0.013449 Grad: 0.107836 Thermal: 0.000394 LR: 9.17e-06\n",
      "Epoch  15 [1850/10697 ( 17.3%)] Loss: 0.026021 L1: 0.015527 Grad: 0.104735 Thermal: 0.000426 LR: 9.17e-06\n",
      "Epoch  15 [1850/10697 ( 17.3%)] Loss: 0.026021 L1: 0.015527 Grad: 0.104735 Thermal: 0.000426 LR: 9.17e-06\n",
      "Epoch  15 [1900/10697 ( 17.8%)] Loss: 0.035159 L1: 0.020510 Grad: 0.146089 Thermal: 0.000810 LR: 9.17e-06\n",
      "Epoch  15 [1900/10697 ( 17.8%)] Loss: 0.035159 L1: 0.020510 Grad: 0.146089 Thermal: 0.000810 LR: 9.17e-06\n",
      "Epoch  15 [1950/10697 ( 18.2%)] Loss: 0.029408 L1: 0.016745 Grad: 0.126356 Thermal: 0.000544 LR: 9.17e-06\n",
      "Epoch  15 [1950/10697 ( 18.2%)] Loss: 0.029408 L1: 0.016745 Grad: 0.126356 Thermal: 0.000544 LR: 9.17e-06\n",
      "Epoch  15 [2000/10697 ( 18.7%)] Loss: 0.027663 L1: 0.015895 Grad: 0.117452 Thermal: 0.000466 LR: 9.17e-06\n",
      "Epoch  15 [2000/10697 ( 18.7%)] Loss: 0.027663 L1: 0.015895 Grad: 0.117452 Thermal: 0.000466 LR: 9.17e-06\n",
      "Epoch  15 [2050/10697 ( 19.2%)] Loss: 0.020787 L1: 0.012077 Grad: 0.086945 Thermal: 0.000303 LR: 9.17e-06\n",
      "Epoch  15 [2050/10697 ( 19.2%)] Loss: 0.020787 L1: 0.012077 Grad: 0.086945 Thermal: 0.000303 LR: 9.17e-06\n",
      "Epoch  15 [2100/10697 ( 19.6%)] Loss: 0.029690 L1: 0.017512 Grad: 0.121519 Thermal: 0.000527 LR: 9.17e-06\n",
      "Epoch  15 [2100/10697 ( 19.6%)] Loss: 0.029690 L1: 0.017512 Grad: 0.121519 Thermal: 0.000527 LR: 9.17e-06\n",
      "Epoch  15 [2150/10697 ( 20.1%)] Loss: 0.026373 L1: 0.015772 Grad: 0.105786 Thermal: 0.000460 LR: 9.17e-06\n",
      "Epoch  15 [2150/10697 ( 20.1%)] Loss: 0.026373 L1: 0.015772 Grad: 0.105786 Thermal: 0.000460 LR: 9.17e-06\n",
      "Epoch  15 [2200/10697 ( 20.6%)] Loss: 0.027993 L1: 0.016221 Grad: 0.117459 Thermal: 0.000522 LR: 9.17e-06\n",
      "Epoch  15 [2200/10697 ( 20.6%)] Loss: 0.027993 L1: 0.016221 Grad: 0.117459 Thermal: 0.000522 LR: 9.17e-06\n",
      "Epoch  15 [2250/10697 ( 21.0%)] Loss: 0.021429 L1: 0.012221 Grad: 0.091935 Thermal: 0.000289 LR: 9.17e-06\n",
      "Epoch  15 [2250/10697 ( 21.0%)] Loss: 0.021429 L1: 0.012221 Grad: 0.091935 Thermal: 0.000289 LR: 9.17e-06\n",
      "Epoch  15 [2300/10697 ( 21.5%)] Loss: 0.024533 L1: 0.014080 Grad: 0.104328 Thermal: 0.000409 LR: 9.17e-06\n",
      "Epoch  15 [2300/10697 ( 21.5%)] Loss: 0.024533 L1: 0.014080 Grad: 0.104328 Thermal: 0.000409 LR: 9.17e-06\n",
      "Epoch  15 [2350/10697 ( 22.0%)] Loss: 0.023976 L1: 0.014030 Grad: 0.099261 Thermal: 0.000394 LR: 9.17e-06\n",
      "Epoch  15 [2350/10697 ( 22.0%)] Loss: 0.023976 L1: 0.014030 Grad: 0.099261 Thermal: 0.000394 LR: 9.17e-06\n",
      "Epoch  15 [2400/10697 ( 22.4%)] Loss: 0.029354 L1: 0.017179 Grad: 0.121482 Thermal: 0.000520 LR: 9.17e-06\n",
      "Epoch  15 [2400/10697 ( 22.4%)] Loss: 0.029354 L1: 0.017179 Grad: 0.121482 Thermal: 0.000520 LR: 9.17e-06\n",
      "Epoch  15 [2450/10697 ( 22.9%)] Loss: 0.025719 L1: 0.014858 Grad: 0.108404 Thermal: 0.000417 LR: 9.17e-06\n",
      "Epoch  15 [2450/10697 ( 22.9%)] Loss: 0.025719 L1: 0.014858 Grad: 0.108404 Thermal: 0.000417 LR: 9.17e-06\n",
      "Epoch  15 [2500/10697 ( 23.4%)] Loss: 0.026191 L1: 0.015501 Grad: 0.106694 Thermal: 0.000419 LR: 9.17e-06\n",
      "Epoch  15 [2500/10697 ( 23.4%)] Loss: 0.026191 L1: 0.015501 Grad: 0.106694 Thermal: 0.000419 LR: 9.17e-06\n",
      "Epoch  15 [2550/10697 ( 23.8%)] Loss: 0.021805 L1: 0.012460 Grad: 0.093286 Thermal: 0.000335 LR: 9.17e-06\n",
      "Epoch  15 [2550/10697 ( 23.8%)] Loss: 0.021805 L1: 0.012460 Grad: 0.093286 Thermal: 0.000335 LR: 9.17e-06\n",
      "Epoch  15 [2600/10697 ( 24.3%)] Loss: 0.027195 L1: 0.015787 Grad: 0.113853 Thermal: 0.000465 LR: 9.17e-06\n",
      "Epoch  15 [2600/10697 ( 24.3%)] Loss: 0.027195 L1: 0.015787 Grad: 0.113853 Thermal: 0.000465 LR: 9.17e-06\n",
      "Epoch  15 [2650/10697 ( 24.8%)] Loss: 0.027364 L1: 0.015998 Grad: 0.113422 Thermal: 0.000477 LR: 9.17e-06\n",
      "Epoch  15 [2650/10697 ( 24.8%)] Loss: 0.027364 L1: 0.015998 Grad: 0.113422 Thermal: 0.000477 LR: 9.17e-06\n",
      "Epoch  15 [2700/10697 ( 25.2%)] Loss: 0.026810 L1: 0.015549 Grad: 0.112384 Thermal: 0.000455 LR: 9.17e-06\n",
      "Epoch  15 [2700/10697 ( 25.2%)] Loss: 0.026810 L1: 0.015549 Grad: 0.112384 Thermal: 0.000455 LR: 9.17e-06\n",
      "Epoch  15 [2750/10697 ( 25.7%)] Loss: 0.035945 L1: 0.020416 Grad: 0.154903 Thermal: 0.000777 LR: 9.17e-06\n",
      "Epoch  15 [2750/10697 ( 25.7%)] Loss: 0.035945 L1: 0.020416 Grad: 0.154903 Thermal: 0.000777 LR: 9.17e-06\n",
      "Epoch  15 [2800/10697 ( 26.2%)] Loss: 0.025106 L1: 0.014604 Grad: 0.104816 Thermal: 0.000406 LR: 9.17e-06\n",
      "Epoch  15 [2800/10697 ( 26.2%)] Loss: 0.025106 L1: 0.014604 Grad: 0.104816 Thermal: 0.000406 LR: 9.17e-06\n",
      "Epoch  15 [2850/10697 ( 26.6%)] Loss: 0.030410 L1: 0.017963 Grad: 0.124193 Thermal: 0.000560 LR: 9.17e-06\n",
      "Epoch  15 [2850/10697 ( 26.6%)] Loss: 0.030410 L1: 0.017963 Grad: 0.124193 Thermal: 0.000560 LR: 9.17e-06\n",
      "Epoch  15 [2900/10697 ( 27.1%)] Loss: 0.025919 L1: 0.015407 Grad: 0.104909 Thermal: 0.000416 LR: 9.17e-06\n",
      "Epoch  15 [2900/10697 ( 27.1%)] Loss: 0.025919 L1: 0.015407 Grad: 0.104909 Thermal: 0.000416 LR: 9.17e-06\n",
      "Epoch  15 [2950/10697 ( 27.6%)] Loss: 0.028449 L1: 0.016556 Grad: 0.118687 Thermal: 0.000489 LR: 9.17e-06\n",
      "Epoch  15 [2950/10697 ( 27.6%)] Loss: 0.028449 L1: 0.016556 Grad: 0.118687 Thermal: 0.000489 LR: 9.17e-06\n",
      "Epoch  15 [3000/10697 ( 28.0%)] Loss: 0.021959 L1: 0.012624 Grad: 0.093173 Thermal: 0.000344 LR: 9.17e-06\n",
      "Epoch  15 [3000/10697 ( 28.0%)] Loss: 0.021959 L1: 0.012624 Grad: 0.093173 Thermal: 0.000344 LR: 9.17e-06\n",
      "Epoch  15 [3050/10697 ( 28.5%)] Loss: 0.038256 L1: 0.021693 Grad: 0.165199 Thermal: 0.000874 LR: 9.17e-06\n",
      "Epoch  15 [3050/10697 ( 28.5%)] Loss: 0.038256 L1: 0.021693 Grad: 0.165199 Thermal: 0.000874 LR: 9.17e-06\n",
      "Epoch  15 [3100/10697 ( 29.0%)] Loss: 0.024067 L1: 0.014181 Grad: 0.098646 Thermal: 0.000433 LR: 9.17e-06\n",
      "Epoch  15 [3100/10697 ( 29.0%)] Loss: 0.024067 L1: 0.014181 Grad: 0.098646 Thermal: 0.000433 LR: 9.17e-06\n",
      "Epoch  15 [3150/10697 ( 29.4%)] Loss: 0.029643 L1: 0.017093 Grad: 0.125190 Thermal: 0.000606 LR: 9.17e-06\n",
      "Epoch  15 [3150/10697 ( 29.4%)] Loss: 0.029643 L1: 0.017093 Grad: 0.125190 Thermal: 0.000606 LR: 9.17e-06\n",
      "Epoch  15 [3200/10697 ( 29.9%)] Loss: 0.026490 L1: 0.015609 Grad: 0.108590 Thermal: 0.000441 LR: 9.17e-06\n",
      "Epoch  15 [3200/10697 ( 29.9%)] Loss: 0.026490 L1: 0.015609 Grad: 0.108590 Thermal: 0.000441 LR: 9.17e-06\n",
      "Epoch  15 [3250/10697 ( 30.4%)] Loss: 0.021196 L1: 0.012163 Grad: 0.090179 Thermal: 0.000305 LR: 9.17e-06\n",
      "Epoch  15 [3250/10697 ( 30.4%)] Loss: 0.021196 L1: 0.012163 Grad: 0.090179 Thermal: 0.000305 LR: 9.17e-06\n",
      "Epoch  15 [3300/10697 ( 30.8%)] Loss: 0.029555 L1: 0.017188 Grad: 0.123398 Thermal: 0.000542 LR: 9.17e-06\n",
      "Epoch  15 [3300/10697 ( 30.8%)] Loss: 0.029555 L1: 0.017188 Grad: 0.123398 Thermal: 0.000542 LR: 9.17e-06\n",
      "Epoch  15 [3350/10697 ( 31.3%)] Loss: 0.028775 L1: 0.017237 Grad: 0.115112 Thermal: 0.000522 LR: 9.17e-06\n",
      "Epoch  15 [3350/10697 ( 31.3%)] Loss: 0.028775 L1: 0.017237 Grad: 0.115112 Thermal: 0.000522 LR: 9.17e-06\n",
      "Epoch  15 [3400/10697 ( 31.8%)] Loss: 0.029339 L1: 0.017407 Grad: 0.119035 Thermal: 0.000580 LR: 9.17e-06\n",
      "Epoch  15 [3400/10697 ( 31.8%)] Loss: 0.029339 L1: 0.017407 Grad: 0.119035 Thermal: 0.000580 LR: 9.17e-06\n",
      "Epoch  15 [3450/10697 ( 32.3%)] Loss: 0.026051 L1: 0.015310 Grad: 0.107180 Thermal: 0.000457 LR: 9.17e-06\n",
      "Epoch  15 [3450/10697 ( 32.3%)] Loss: 0.026051 L1: 0.015310 Grad: 0.107180 Thermal: 0.000457 LR: 9.17e-06\n",
      "Epoch  15 [3500/10697 ( 32.7%)] Loss: 0.017186 L1: 0.009912 Grad: 0.072622 Thermal: 0.000239 LR: 9.17e-06\n",
      "Epoch  15 [3500/10697 ( 32.7%)] Loss: 0.017186 L1: 0.009912 Grad: 0.072622 Thermal: 0.000239 LR: 9.17e-06\n",
      "Epoch  15 [3550/10697 ( 33.2%)] Loss: 0.021435 L1: 0.012676 Grad: 0.087430 Thermal: 0.000317 LR: 9.17e-06\n",
      "Epoch  15 [3550/10697 ( 33.2%)] Loss: 0.021435 L1: 0.012676 Grad: 0.087430 Thermal: 0.000317 LR: 9.17e-06\n",
      "Epoch  15 [3600/10697 ( 33.7%)] Loss: 0.027660 L1: 0.016244 Grad: 0.113928 Thermal: 0.000465 LR: 9.17e-06\n",
      "Epoch  15 [3600/10697 ( 33.7%)] Loss: 0.027660 L1: 0.016244 Grad: 0.113928 Thermal: 0.000465 LR: 9.17e-06\n",
      "Epoch  15 [3650/10697 ( 34.1%)] Loss: 0.027328 L1: 0.016324 Grad: 0.109784 Thermal: 0.000511 LR: 9.17e-06\n",
      "Epoch  15 [3650/10697 ( 34.1%)] Loss: 0.027328 L1: 0.016324 Grad: 0.109784 Thermal: 0.000511 LR: 9.17e-06\n",
      "Epoch  15 [3700/10697 ( 34.6%)] Loss: 0.027397 L1: 0.016017 Grad: 0.113543 Thermal: 0.000509 LR: 9.17e-06\n",
      "Epoch  15 [3700/10697 ( 34.6%)] Loss: 0.027397 L1: 0.016017 Grad: 0.113543 Thermal: 0.000509 LR: 9.17e-06\n",
      "Epoch  15 [3750/10697 ( 35.1%)] Loss: 0.033658 L1: 0.019355 Grad: 0.142702 Thermal: 0.000653 LR: 9.17e-06\n",
      "Epoch  15 [3750/10697 ( 35.1%)] Loss: 0.033658 L1: 0.019355 Grad: 0.142702 Thermal: 0.000653 LR: 9.17e-06\n",
      "Epoch  15 [3800/10697 ( 35.5%)] Loss: 0.025925 L1: 0.015211 Grad: 0.106931 Thermal: 0.000424 LR: 9.17e-06\n",
      "Epoch  15 [3800/10697 ( 35.5%)] Loss: 0.025925 L1: 0.015211 Grad: 0.106931 Thermal: 0.000424 LR: 9.17e-06\n",
      "Epoch  15 [3850/10697 ( 36.0%)] Loss: 0.031267 L1: 0.018384 Grad: 0.128503 Thermal: 0.000653 LR: 9.17e-06\n",
      "Epoch  15 [3850/10697 ( 36.0%)] Loss: 0.031267 L1: 0.018384 Grad: 0.128503 Thermal: 0.000653 LR: 9.17e-06\n",
      "Epoch  15 [3900/10697 ( 36.5%)] Loss: 0.025335 L1: 0.014485 Grad: 0.108264 Thermal: 0.000472 LR: 9.17e-06\n",
      "Epoch  15 [3900/10697 ( 36.5%)] Loss: 0.025335 L1: 0.014485 Grad: 0.108264 Thermal: 0.000472 LR: 9.17e-06\n",
      "Epoch  15 [3950/10697 ( 36.9%)] Loss: 0.023591 L1: 0.013633 Grad: 0.099380 Thermal: 0.000405 LR: 9.17e-06\n",
      "Epoch  15 [3950/10697 ( 36.9%)] Loss: 0.023591 L1: 0.013633 Grad: 0.099380 Thermal: 0.000405 LR: 9.17e-06\n",
      "Epoch  15 [4000/10697 ( 37.4%)] Loss: 0.032462 L1: 0.018881 Grad: 0.135463 Thermal: 0.000685 LR: 9.17e-06\n",
      "Epoch  15 [4000/10697 ( 37.4%)] Loss: 0.032462 L1: 0.018881 Grad: 0.135463 Thermal: 0.000685 LR: 9.17e-06\n",
      "Epoch  15 [4050/10697 ( 37.9%)] Loss: 0.028144 L1: 0.016680 Grad: 0.114386 Thermal: 0.000510 LR: 9.17e-06\n",
      "Epoch  15 [4050/10697 ( 37.9%)] Loss: 0.028144 L1: 0.016680 Grad: 0.114386 Thermal: 0.000510 LR: 9.17e-06\n",
      "Epoch  15 [4100/10697 ( 38.3%)] Loss: 0.027322 L1: 0.015693 Grad: 0.116059 Thermal: 0.000464 LR: 9.17e-06\n",
      "Epoch  15 [4100/10697 ( 38.3%)] Loss: 0.027322 L1: 0.015693 Grad: 0.116059 Thermal: 0.000464 LR: 9.17e-06\n",
      "Epoch  15 [4150/10697 ( 38.8%)] Loss: 0.029886 L1: 0.017628 Grad: 0.122292 Thermal: 0.000570 LR: 9.17e-06\n",
      "Epoch  15 [4150/10697 ( 38.8%)] Loss: 0.029886 L1: 0.017628 Grad: 0.122292 Thermal: 0.000570 LR: 9.17e-06\n",
      "Epoch  15 [4200/10697 ( 39.3%)] Loss: 0.027546 L1: 0.016108 Grad: 0.114155 Thermal: 0.000446 LR: 9.17e-06\n",
      "Epoch  15 [4200/10697 ( 39.3%)] Loss: 0.027546 L1: 0.016108 Grad: 0.114155 Thermal: 0.000446 LR: 9.17e-06\n",
      "Epoch  15 [4250/10697 ( 39.7%)] Loss: 0.032725 L1: 0.019137 Grad: 0.135534 Thermal: 0.000693 LR: 9.17e-06\n",
      "Epoch  15 [4250/10697 ( 39.7%)] Loss: 0.032725 L1: 0.019137 Grad: 0.135534 Thermal: 0.000693 LR: 9.17e-06\n",
      "Epoch  15 [4300/10697 ( 40.2%)] Loss: 0.025299 L1: 0.014775 Grad: 0.105038 Thermal: 0.000418 LR: 9.17e-06\n",
      "Epoch  15 [4300/10697 ( 40.2%)] Loss: 0.025299 L1: 0.014775 Grad: 0.105038 Thermal: 0.000418 LR: 9.17e-06\n",
      "Epoch  15 [4350/10697 ( 40.7%)] Loss: 0.021834 L1: 0.013068 Grad: 0.087484 Thermal: 0.000361 LR: 9.17e-06\n",
      "Epoch  15 [4350/10697 ( 40.7%)] Loss: 0.021834 L1: 0.013068 Grad: 0.087484 Thermal: 0.000361 LR: 9.17e-06\n",
      "Epoch  15 [4400/10697 ( 41.1%)] Loss: 0.025497 L1: 0.014981 Grad: 0.104951 Thermal: 0.000416 LR: 9.17e-06\n",
      "Epoch  15 [4400/10697 ( 41.1%)] Loss: 0.025497 L1: 0.014981 Grad: 0.104951 Thermal: 0.000416 LR: 9.17e-06\n",
      "Epoch  15 [4450/10697 ( 41.6%)] Loss: 0.024488 L1: 0.014234 Grad: 0.102335 Thermal: 0.000407 LR: 9.17e-06\n",
      "Epoch  15 [4450/10697 ( 41.6%)] Loss: 0.024488 L1: 0.014234 Grad: 0.102335 Thermal: 0.000407 LR: 9.17e-06\n",
      "Epoch  15 [4500/10697 ( 42.1%)] Loss: 0.030590 L1: 0.017901 Grad: 0.126592 Thermal: 0.000595 LR: 9.17e-06\n",
      "Epoch  15 [4500/10697 ( 42.1%)] Loss: 0.030590 L1: 0.017901 Grad: 0.126592 Thermal: 0.000595 LR: 9.17e-06\n",
      "Epoch  15 [4550/10697 ( 42.5%)] Loss: 0.028892 L1: 0.016950 Grad: 0.119171 Thermal: 0.000496 LR: 9.17e-06\n",
      "Epoch  15 [4550/10697 ( 42.5%)] Loss: 0.028892 L1: 0.016950 Grad: 0.119171 Thermal: 0.000496 LR: 9.17e-06\n",
      "Epoch  15 [4600/10697 ( 43.0%)] Loss: 0.027865 L1: 0.016640 Grad: 0.112017 Thermal: 0.000476 LR: 9.17e-06\n",
      "Epoch  15 [4600/10697 ( 43.0%)] Loss: 0.027865 L1: 0.016640 Grad: 0.112017 Thermal: 0.000476 LR: 9.17e-06\n",
      "Epoch  15 [4650/10697 ( 43.5%)] Loss: 0.022448 L1: 0.013273 Grad: 0.091582 Thermal: 0.000353 LR: 9.17e-06\n",
      "Epoch  15 [4650/10697 ( 43.5%)] Loss: 0.022448 L1: 0.013273 Grad: 0.091582 Thermal: 0.000353 LR: 9.17e-06\n",
      "Epoch  15 [4700/10697 ( 43.9%)] Loss: 0.024030 L1: 0.013861 Grad: 0.101473 Thermal: 0.000427 LR: 9.17e-06\n",
      "Epoch  15 [4700/10697 ( 43.9%)] Loss: 0.024030 L1: 0.013861 Grad: 0.101473 Thermal: 0.000427 LR: 9.17e-06\n",
      "Epoch  15 [4750/10697 ( 44.4%)] Loss: 0.023254 L1: 0.013786 Grad: 0.094507 Thermal: 0.000361 LR: 9.17e-06\n",
      "Epoch  15 [4750/10697 ( 44.4%)] Loss: 0.023254 L1: 0.013786 Grad: 0.094507 Thermal: 0.000361 LR: 9.17e-06\n",
      "Epoch  15 [4800/10697 ( 44.9%)] Loss: 0.022973 L1: 0.013614 Grad: 0.093422 Thermal: 0.000338 LR: 9.17e-06\n",
      "Epoch  15 [4800/10697 ( 44.9%)] Loss: 0.022973 L1: 0.013614 Grad: 0.093422 Thermal: 0.000338 LR: 9.17e-06\n",
      "Epoch  15 [4850/10697 ( 45.3%)] Loss: 0.025844 L1: 0.015118 Grad: 0.107038 Thermal: 0.000432 LR: 9.17e-06\n",
      "Epoch  15 [4850/10697 ( 45.3%)] Loss: 0.025844 L1: 0.015118 Grad: 0.107038 Thermal: 0.000432 LR: 9.17e-06\n",
      "Epoch  15 [4900/10697 ( 45.8%)] Loss: 0.024988 L1: 0.014616 Grad: 0.103522 Thermal: 0.000387 LR: 9.17e-06\n",
      "Epoch  15 [4900/10697 ( 45.8%)] Loss: 0.024988 L1: 0.014616 Grad: 0.103522 Thermal: 0.000387 LR: 9.17e-06\n",
      "Epoch  15 [4950/10697 ( 46.3%)] Loss: 0.028642 L1: 0.016292 Grad: 0.123248 Thermal: 0.000512 LR: 9.17e-06\n",
      "Epoch  15 [4950/10697 ( 46.3%)] Loss: 0.028642 L1: 0.016292 Grad: 0.123248 Thermal: 0.000512 LR: 9.17e-06\n",
      "Epoch  15 [5000/10697 ( 46.7%)] Loss: 0.030179 L1: 0.017563 Grad: 0.125889 Thermal: 0.000541 LR: 9.17e-06\n",
      "Epoch  15 [5000/10697 ( 46.7%)] Loss: 0.030179 L1: 0.017563 Grad: 0.125889 Thermal: 0.000541 LR: 9.17e-06\n",
      "Epoch  15 [5050/10697 ( 47.2%)] Loss: 0.025791 L1: 0.015103 Grad: 0.106662 Thermal: 0.000438 LR: 9.17e-06\n",
      "Epoch  15 [5050/10697 ( 47.2%)] Loss: 0.025791 L1: 0.015103 Grad: 0.106662 Thermal: 0.000438 LR: 9.17e-06\n",
      "Epoch  15 [5100/10697 ( 47.7%)] Loss: 0.030831 L1: 0.017979 Grad: 0.128249 Thermal: 0.000541 LR: 9.17e-06\n",
      "Epoch  15 [5100/10697 ( 47.7%)] Loss: 0.030831 L1: 0.017979 Grad: 0.128249 Thermal: 0.000541 LR: 9.17e-06\n",
      "Epoch  15 [5150/10697 ( 48.1%)] Loss: 0.027179 L1: 0.015945 Grad: 0.112113 Thermal: 0.000464 LR: 9.17e-06\n",
      "Epoch  15 [5150/10697 ( 48.1%)] Loss: 0.027179 L1: 0.015945 Grad: 0.112113 Thermal: 0.000464 LR: 9.17e-06\n",
      "Epoch  15 [5200/10697 ( 48.6%)] Loss: 0.031371 L1: 0.017990 Grad: 0.133499 Thermal: 0.000624 LR: 9.17e-06\n",
      "Epoch  15 [5200/10697 ( 48.6%)] Loss: 0.031371 L1: 0.017990 Grad: 0.133499 Thermal: 0.000624 LR: 9.17e-06\n",
      "Epoch  15 [5250/10697 ( 49.1%)] Loss: 0.027806 L1: 0.016039 Grad: 0.117447 Thermal: 0.000441 LR: 9.17e-06\n",
      "Epoch  15 [5250/10697 ( 49.1%)] Loss: 0.027806 L1: 0.016039 Grad: 0.117447 Thermal: 0.000441 LR: 9.17e-06\n",
      "Epoch  15 [5300/10697 ( 49.5%)] Loss: 0.027662 L1: 0.016381 Grad: 0.112536 Thermal: 0.000539 LR: 9.17e-06\n",
      "Epoch  15 [5300/10697 ( 49.5%)] Loss: 0.027662 L1: 0.016381 Grad: 0.112536 Thermal: 0.000539 LR: 9.17e-06\n",
      "Epoch  15 [5350/10697 ( 50.0%)] Loss: 0.029582 L1: 0.017314 Grad: 0.122388 Thermal: 0.000581 LR: 9.17e-06\n",
      "Epoch  15 [5350/10697 ( 50.0%)] Loss: 0.029582 L1: 0.017314 Grad: 0.122388 Thermal: 0.000581 LR: 9.17e-06\n",
      "Epoch  15 [5400/10697 ( 50.5%)] Loss: 0.021595 L1: 0.012410 Grad: 0.091696 Thermal: 0.000313 LR: 9.17e-06\n",
      "Epoch  15 [5400/10697 ( 50.5%)] Loss: 0.021595 L1: 0.012410 Grad: 0.091696 Thermal: 0.000313 LR: 9.17e-06\n",
      "Epoch  15 [5450/10697 ( 50.9%)] Loss: 0.034982 L1: 0.019809 Grad: 0.151351 Thermal: 0.000760 LR: 9.17e-06\n",
      "Epoch  15 [5450/10697 ( 50.9%)] Loss: 0.034982 L1: 0.019809 Grad: 0.151351 Thermal: 0.000760 LR: 9.17e-06\n",
      "Epoch  15 [5500/10697 ( 51.4%)] Loss: 0.028671 L1: 0.016950 Grad: 0.116946 Thermal: 0.000525 LR: 9.17e-06\n",
      "Epoch  15 [5500/10697 ( 51.4%)] Loss: 0.028671 L1: 0.016950 Grad: 0.116946 Thermal: 0.000525 LR: 9.17e-06\n",
      "Epoch  15 [5550/10697 ( 51.9%)] Loss: 0.029576 L1: 0.017513 Grad: 0.120360 Thermal: 0.000551 LR: 9.17e-06\n",
      "Epoch  15 [5550/10697 ( 51.9%)] Loss: 0.029576 L1: 0.017513 Grad: 0.120360 Thermal: 0.000551 LR: 9.17e-06\n",
      "Epoch  15 [5600/10697 ( 52.4%)] Loss: 0.027493 L1: 0.016516 Grad: 0.109534 Thermal: 0.000468 LR: 9.17e-06\n",
      "Epoch  15 [5600/10697 ( 52.4%)] Loss: 0.027493 L1: 0.016516 Grad: 0.109534 Thermal: 0.000468 LR: 9.17e-06\n",
      "Epoch  15 [5650/10697 ( 52.8%)] Loss: 0.027190 L1: 0.015861 Grad: 0.113067 Thermal: 0.000454 LR: 9.17e-06\n",
      "Epoch  15 [5650/10697 ( 52.8%)] Loss: 0.027190 L1: 0.015861 Grad: 0.113067 Thermal: 0.000454 LR: 9.17e-06\n",
      "Epoch  15 [5700/10697 ( 53.3%)] Loss: 0.023448 L1: 0.013719 Grad: 0.097109 Thermal: 0.000360 LR: 9.17e-06\n",
      "Epoch  15 [5700/10697 ( 53.3%)] Loss: 0.023448 L1: 0.013719 Grad: 0.097109 Thermal: 0.000360 LR: 9.17e-06\n",
      "Epoch  15 [5750/10697 ( 53.8%)] Loss: 0.028671 L1: 0.016771 Grad: 0.118722 Thermal: 0.000561 LR: 9.17e-06\n",
      "Epoch  15 [5750/10697 ( 53.8%)] Loss: 0.028671 L1: 0.016771 Grad: 0.118722 Thermal: 0.000561 LR: 9.17e-06\n",
      "Epoch  15 [5800/10697 ( 54.2%)] Loss: 0.026754 L1: 0.015496 Grad: 0.112346 Thermal: 0.000458 LR: 9.17e-06\n",
      "Epoch  15 [5800/10697 ( 54.2%)] Loss: 0.026754 L1: 0.015496 Grad: 0.112346 Thermal: 0.000458 LR: 9.17e-06\n",
      "Epoch  15 [5850/10697 ( 54.7%)] Loss: 0.023366 L1: 0.013541 Grad: 0.098070 Thermal: 0.000366 LR: 9.17e-06\n",
      "Epoch  15 [5850/10697 ( 54.7%)] Loss: 0.023366 L1: 0.013541 Grad: 0.098070 Thermal: 0.000366 LR: 9.17e-06\n",
      "Epoch  15 [5900/10697 ( 55.2%)] Loss: 0.023892 L1: 0.013868 Grad: 0.100037 Thermal: 0.000418 LR: 9.17e-06\n",
      "Epoch  15 [5900/10697 ( 55.2%)] Loss: 0.023892 L1: 0.013868 Grad: 0.100037 Thermal: 0.000418 LR: 9.17e-06\n",
      "Epoch  15 [5950/10697 ( 55.6%)] Loss: 0.029830 L1: 0.017581 Grad: 0.122208 Thermal: 0.000568 LR: 9.17e-06\n",
      "Epoch  15 [5950/10697 ( 55.6%)] Loss: 0.029830 L1: 0.017581 Grad: 0.122208 Thermal: 0.000568 LR: 9.17e-06\n",
      "Epoch  15 [6000/10697 ( 56.1%)] Loss: 0.028568 L1: 0.016499 Grad: 0.120418 Thermal: 0.000544 LR: 9.17e-06\n",
      "Epoch  15 [6000/10697 ( 56.1%)] Loss: 0.028568 L1: 0.016499 Grad: 0.120418 Thermal: 0.000544 LR: 9.17e-06\n",
      "Epoch  15 [6050/10697 ( 56.6%)] Loss: 0.026485 L1: 0.015510 Grad: 0.109521 Thermal: 0.000447 LR: 9.17e-06\n",
      "Epoch  15 [6050/10697 ( 56.6%)] Loss: 0.026485 L1: 0.015510 Grad: 0.109521 Thermal: 0.000447 LR: 9.17e-06\n",
      "Epoch  15 [6100/10697 ( 57.0%)] Loss: 0.030771 L1: 0.017589 Grad: 0.131528 Thermal: 0.000580 LR: 9.17e-06\n",
      "Epoch  15 [6100/10697 ( 57.0%)] Loss: 0.030771 L1: 0.017589 Grad: 0.131528 Thermal: 0.000580 LR: 9.17e-06\n",
      "Epoch  15 [6150/10697 ( 57.5%)] Loss: 0.020146 L1: 0.011876 Grad: 0.082543 Thermal: 0.000306 LR: 9.17e-06\n",
      "Epoch  15 [6150/10697 ( 57.5%)] Loss: 0.020146 L1: 0.011876 Grad: 0.082543 Thermal: 0.000306 LR: 9.17e-06\n",
      "Epoch  15 [6200/10697 ( 58.0%)] Loss: 0.022410 L1: 0.013258 Grad: 0.091354 Thermal: 0.000348 LR: 9.17e-06\n",
      "Epoch  15 [6200/10697 ( 58.0%)] Loss: 0.022410 L1: 0.013258 Grad: 0.091354 Thermal: 0.000348 LR: 9.17e-06\n",
      "Epoch  15 [6250/10697 ( 58.4%)] Loss: 0.027956 L1: 0.016471 Grad: 0.114608 Thermal: 0.000482 LR: 9.17e-06\n",
      "Epoch  15 [6250/10697 ( 58.4%)] Loss: 0.027956 L1: 0.016471 Grad: 0.114608 Thermal: 0.000482 LR: 9.17e-06\n",
      "Epoch  15 [6300/10697 ( 58.9%)] Loss: 0.026867 L1: 0.015977 Grad: 0.108674 Thermal: 0.000452 LR: 9.17e-06\n",
      "Epoch  15 [6300/10697 ( 58.9%)] Loss: 0.026867 L1: 0.015977 Grad: 0.108674 Thermal: 0.000452 LR: 9.17e-06\n",
      "Epoch  15 [6350/10697 ( 59.4%)] Loss: 0.030050 L1: 0.017490 Grad: 0.125324 Thermal: 0.000564 LR: 9.17e-06\n",
      "Epoch  15 [6350/10697 ( 59.4%)] Loss: 0.030050 L1: 0.017490 Grad: 0.125324 Thermal: 0.000564 LR: 9.17e-06\n",
      "Epoch  15 [6400/10697 ( 59.8%)] Loss: 0.025667 L1: 0.014908 Grad: 0.107375 Thermal: 0.000436 LR: 9.17e-06\n",
      "Epoch  15 [6400/10697 ( 59.8%)] Loss: 0.025667 L1: 0.014908 Grad: 0.107375 Thermal: 0.000436 LR: 9.17e-06\n",
      "Epoch  15 [6450/10697 ( 60.3%)] Loss: 0.026595 L1: 0.015376 Grad: 0.111955 Thermal: 0.000458 LR: 9.17e-06\n",
      "Epoch  15 [6450/10697 ( 60.3%)] Loss: 0.026595 L1: 0.015376 Grad: 0.111955 Thermal: 0.000458 LR: 9.17e-06\n",
      "Epoch  15 [6500/10697 ( 60.8%)] Loss: 0.023891 L1: 0.013659 Grad: 0.102142 Thermal: 0.000344 LR: 9.17e-06\n",
      "Epoch  15 [6500/10697 ( 60.8%)] Loss: 0.023891 L1: 0.013659 Grad: 0.102142 Thermal: 0.000344 LR: 9.17e-06\n",
      "Epoch  15 [6550/10697 ( 61.2%)] Loss: 0.029332 L1: 0.017234 Grad: 0.120718 Thermal: 0.000521 LR: 9.17e-06\n",
      "Epoch  15 [6550/10697 ( 61.2%)] Loss: 0.029332 L1: 0.017234 Grad: 0.120718 Thermal: 0.000521 LR: 9.17e-06\n",
      "Epoch  15 [6600/10697 ( 61.7%)] Loss: 0.024007 L1: 0.013541 Grad: 0.104468 Thermal: 0.000393 LR: 9.17e-06\n",
      "Epoch  15 [6600/10697 ( 61.7%)] Loss: 0.024007 L1: 0.013541 Grad: 0.104468 Thermal: 0.000393 LR: 9.17e-06\n",
      "Epoch  15 [6650/10697 ( 62.2%)] Loss: 0.017967 L1: 0.010126 Grad: 0.078292 Thermal: 0.000239 LR: 9.17e-06\n",
      "Epoch  15 [6650/10697 ( 62.2%)] Loss: 0.017967 L1: 0.010126 Grad: 0.078292 Thermal: 0.000239 LR: 9.17e-06\n",
      "Epoch  15 [6700/10697 ( 62.6%)] Loss: 0.027947 L1: 0.016051 Grad: 0.118705 Thermal: 0.000514 LR: 9.17e-06\n",
      "Epoch  15 [6700/10697 ( 62.6%)] Loss: 0.027947 L1: 0.016051 Grad: 0.118705 Thermal: 0.000514 LR: 9.17e-06\n",
      "Epoch  15 [6750/10697 ( 63.1%)] Loss: 0.030158 L1: 0.017456 Grad: 0.126682 Thermal: 0.000685 LR: 9.17e-06\n",
      "Epoch  15 [6750/10697 ( 63.1%)] Loss: 0.030158 L1: 0.017456 Grad: 0.126682 Thermal: 0.000685 LR: 9.17e-06\n",
      "Epoch  15 [6800/10697 ( 63.6%)] Loss: 0.028974 L1: 0.016639 Grad: 0.123070 Thermal: 0.000560 LR: 9.17e-06\n",
      "Epoch  15 [6800/10697 ( 63.6%)] Loss: 0.028974 L1: 0.016639 Grad: 0.123070 Thermal: 0.000560 LR: 9.17e-06\n",
      "Epoch  15 [6850/10697 ( 64.0%)] Loss: 0.030746 L1: 0.017700 Grad: 0.130166 Thermal: 0.000593 LR: 9.17e-06\n",
      "Epoch  15 [6850/10697 ( 64.0%)] Loss: 0.030746 L1: 0.017700 Grad: 0.130166 Thermal: 0.000593 LR: 9.17e-06\n",
      "Epoch  15 [6900/10697 ( 64.5%)] Loss: 0.024165 L1: 0.013737 Grad: 0.104092 Thermal: 0.000387 LR: 9.17e-06\n",
      "Epoch  15 [6900/10697 ( 64.5%)] Loss: 0.024165 L1: 0.013737 Grad: 0.104092 Thermal: 0.000387 LR: 9.17e-06\n",
      "Epoch  15 [6950/10697 ( 65.0%)] Loss: 0.028012 L1: 0.016297 Grad: 0.116885 Thermal: 0.000523 LR: 9.17e-06\n",
      "Epoch  15 [6950/10697 ( 65.0%)] Loss: 0.028012 L1: 0.016297 Grad: 0.116885 Thermal: 0.000523 LR: 9.17e-06\n",
      "Epoch  15 [7000/10697 ( 65.4%)] Loss: 0.029365 L1: 0.017140 Grad: 0.121950 Thermal: 0.000605 LR: 9.17e-06\n",
      "Epoch  15 [7000/10697 ( 65.4%)] Loss: 0.029365 L1: 0.017140 Grad: 0.121950 Thermal: 0.000605 LR: 9.17e-06\n",
      "Epoch  15 [7050/10697 ( 65.9%)] Loss: 0.022105 L1: 0.012838 Grad: 0.092510 Thermal: 0.000333 LR: 9.17e-06\n",
      "Epoch  15 [7050/10697 ( 65.9%)] Loss: 0.022105 L1: 0.012838 Grad: 0.092510 Thermal: 0.000333 LR: 9.17e-06\n",
      "Epoch  15 [7100/10697 ( 66.4%)] Loss: 0.024839 L1: 0.014611 Grad: 0.102064 Thermal: 0.000419 LR: 9.17e-06\n",
      "Epoch  15 [7100/10697 ( 66.4%)] Loss: 0.024839 L1: 0.014611 Grad: 0.102064 Thermal: 0.000419 LR: 9.17e-06\n",
      "Epoch  15 [7150/10697 ( 66.8%)] Loss: 0.030036 L1: 0.017551 Grad: 0.124567 Thermal: 0.000570 LR: 9.17e-06\n",
      "Epoch  15 [7150/10697 ( 66.8%)] Loss: 0.030036 L1: 0.017551 Grad: 0.124567 Thermal: 0.000570 LR: 9.17e-06\n",
      "Epoch  15 [7200/10697 ( 67.3%)] Loss: 0.022818 L1: 0.013145 Grad: 0.096564 Thermal: 0.000344 LR: 9.17e-06\n",
      "Epoch  15 [7200/10697 ( 67.3%)] Loss: 0.022818 L1: 0.013145 Grad: 0.096564 Thermal: 0.000344 LR: 9.17e-06\n",
      "Epoch  15 [7250/10697 ( 67.8%)] Loss: 0.030286 L1: 0.017678 Grad: 0.125785 Thermal: 0.000583 LR: 9.17e-06\n",
      "Epoch  15 [7250/10697 ( 67.8%)] Loss: 0.030286 L1: 0.017678 Grad: 0.125785 Thermal: 0.000583 LR: 9.17e-06\n",
      "Epoch  15 [7300/10697 ( 68.2%)] Loss: 0.033354 L1: 0.019361 Grad: 0.139583 Thermal: 0.000684 LR: 9.17e-06\n",
      "Epoch  15 [7300/10697 ( 68.2%)] Loss: 0.033354 L1: 0.019361 Grad: 0.139583 Thermal: 0.000684 LR: 9.17e-06\n",
      "Epoch  15 [7350/10697 ( 68.7%)] Loss: 0.027626 L1: 0.015962 Grad: 0.116385 Thermal: 0.000507 LR: 9.17e-06\n",
      "Epoch  15 [7350/10697 ( 68.7%)] Loss: 0.027626 L1: 0.015962 Grad: 0.116385 Thermal: 0.000507 LR: 9.17e-06\n",
      "Epoch  15 [7400/10697 ( 69.2%)] Loss: 0.026230 L1: 0.015502 Grad: 0.107047 Thermal: 0.000465 LR: 9.17e-06\n",
      "Epoch  15 [7400/10697 ( 69.2%)] Loss: 0.026230 L1: 0.015502 Grad: 0.107047 Thermal: 0.000465 LR: 9.17e-06\n",
      "Epoch  15 [7450/10697 ( 69.6%)] Loss: 0.018804 L1: 0.010698 Grad: 0.080934 Thermal: 0.000246 LR: 9.17e-06\n",
      "Epoch  15 [7450/10697 ( 69.6%)] Loss: 0.018804 L1: 0.010698 Grad: 0.080934 Thermal: 0.000246 LR: 9.17e-06\n",
      "Epoch  15 [7500/10697 ( 70.1%)] Loss: 0.028931 L1: 0.016730 Grad: 0.121750 Thermal: 0.000515 LR: 9.17e-06\n",
      "Epoch  15 [7500/10697 ( 70.1%)] Loss: 0.028931 L1: 0.016730 Grad: 0.121750 Thermal: 0.000515 LR: 9.17e-06\n",
      "Epoch  15 [7550/10697 ( 70.6%)] Loss: 0.029017 L1: 0.016704 Grad: 0.122807 Thermal: 0.000645 LR: 9.17e-06\n",
      "Epoch  15 [7550/10697 ( 70.6%)] Loss: 0.029017 L1: 0.016704 Grad: 0.122807 Thermal: 0.000645 LR: 9.17e-06\n",
      "Epoch  15 [7600/10697 ( 71.0%)] Loss: 0.026860 L1: 0.015525 Grad: 0.113130 Thermal: 0.000433 LR: 9.17e-06\n",
      "Epoch  15 [7600/10697 ( 71.0%)] Loss: 0.026860 L1: 0.015525 Grad: 0.113130 Thermal: 0.000433 LR: 9.17e-06\n",
      "Epoch  15 [7650/10697 ( 71.5%)] Loss: 0.027482 L1: 0.015716 Grad: 0.117389 Thermal: 0.000541 LR: 9.17e-06\n",
      "Epoch  15 [7650/10697 ( 71.5%)] Loss: 0.027482 L1: 0.015716 Grad: 0.117389 Thermal: 0.000541 LR: 9.17e-06\n",
      "Epoch  15 [7700/10697 ( 72.0%)] Loss: 0.034394 L1: 0.019601 Grad: 0.147585 Thermal: 0.000692 LR: 9.17e-06\n",
      "Epoch  15 [7700/10697 ( 72.0%)] Loss: 0.034394 L1: 0.019601 Grad: 0.147585 Thermal: 0.000692 LR: 9.17e-06\n",
      "Epoch  15 [7750/10697 ( 72.5%)] Loss: 0.027323 L1: 0.015945 Grad: 0.113540 Thermal: 0.000482 LR: 9.17e-06\n",
      "Epoch  15 [7750/10697 ( 72.5%)] Loss: 0.027323 L1: 0.015945 Grad: 0.113540 Thermal: 0.000482 LR: 9.17e-06\n",
      "Epoch  15 [7800/10697 ( 72.9%)] Loss: 0.023305 L1: 0.013506 Grad: 0.097806 Thermal: 0.000369 LR: 9.17e-06\n",
      "Epoch  15 [7800/10697 ( 72.9%)] Loss: 0.023305 L1: 0.013506 Grad: 0.097806 Thermal: 0.000369 LR: 9.17e-06\n",
      "Epoch  15 [7850/10697 ( 73.4%)] Loss: 0.027912 L1: 0.016413 Grad: 0.114748 Thermal: 0.000498 LR: 9.17e-06\n",
      "Epoch  15 [7850/10697 ( 73.4%)] Loss: 0.027912 L1: 0.016413 Grad: 0.114748 Thermal: 0.000498 LR: 9.17e-06\n",
      "Epoch  15 [7900/10697 ( 73.9%)] Loss: 0.024045 L1: 0.014066 Grad: 0.099595 Thermal: 0.000385 LR: 9.17e-06\n",
      "Epoch  15 [7900/10697 ( 73.9%)] Loss: 0.024045 L1: 0.014066 Grad: 0.099595 Thermal: 0.000385 LR: 9.17e-06\n",
      "Epoch  15 [7950/10697 ( 74.3%)] Loss: 0.026788 L1: 0.016015 Grad: 0.107509 Thermal: 0.000441 LR: 9.17e-06\n",
      "Epoch  15 [7950/10697 ( 74.3%)] Loss: 0.026788 L1: 0.016015 Grad: 0.107509 Thermal: 0.000441 LR: 9.17e-06\n",
      "Epoch  15 [8000/10697 ( 74.8%)] Loss: 0.027169 L1: 0.015851 Grad: 0.112949 Thermal: 0.000458 LR: 9.17e-06\n",
      "Epoch  15 [8000/10697 ( 74.8%)] Loss: 0.027169 L1: 0.015851 Grad: 0.112949 Thermal: 0.000458 LR: 9.17e-06\n",
      "Epoch  15 [8050/10697 ( 75.3%)] Loss: 0.028327 L1: 0.016820 Grad: 0.114812 Thermal: 0.000527 LR: 9.17e-06\n",
      "Epoch  15 [8050/10697 ( 75.3%)] Loss: 0.028327 L1: 0.016820 Grad: 0.114812 Thermal: 0.000527 LR: 9.17e-06\n",
      "Epoch  15 [8100/10697 ( 75.7%)] Loss: 0.028539 L1: 0.016836 Grad: 0.116777 Thermal: 0.000508 LR: 9.17e-06\n",
      "Epoch  15 [8100/10697 ( 75.7%)] Loss: 0.028539 L1: 0.016836 Grad: 0.116777 Thermal: 0.000508 LR: 9.17e-06\n",
      "Epoch  15 [8150/10697 ( 76.2%)] Loss: 0.024593 L1: 0.014170 Grad: 0.104048 Thermal: 0.000356 LR: 9.17e-06\n",
      "Epoch  15 [8150/10697 ( 76.2%)] Loss: 0.024593 L1: 0.014170 Grad: 0.104048 Thermal: 0.000356 LR: 9.17e-06\n",
      "Epoch  15 [8200/10697 ( 76.7%)] Loss: 0.024798 L1: 0.014295 Grad: 0.104821 Thermal: 0.000411 LR: 9.17e-06\n",
      "Epoch  15 [8200/10697 ( 76.7%)] Loss: 0.024798 L1: 0.014295 Grad: 0.104821 Thermal: 0.000411 LR: 9.17e-06\n",
      "Epoch  15 [8250/10697 ( 77.1%)] Loss: 0.030467 L1: 0.017363 Grad: 0.130750 Thermal: 0.000568 LR: 9.17e-06\n",
      "Epoch  15 [8250/10697 ( 77.1%)] Loss: 0.030467 L1: 0.017363 Grad: 0.130750 Thermal: 0.000568 LR: 9.17e-06\n",
      "Epoch  15 [8300/10697 ( 77.6%)] Loss: 0.029732 L1: 0.016983 Grad: 0.127193 Thermal: 0.000587 LR: 9.17e-06\n",
      "Epoch  15 [8300/10697 ( 77.6%)] Loss: 0.029732 L1: 0.016983 Grad: 0.127193 Thermal: 0.000587 LR: 9.17e-06\n",
      "Epoch  15 [8350/10697 ( 78.1%)] Loss: 0.025706 L1: 0.014921 Grad: 0.107657 Thermal: 0.000392 LR: 9.17e-06\n",
      "Epoch  15 [8350/10697 ( 78.1%)] Loss: 0.025706 L1: 0.014921 Grad: 0.107657 Thermal: 0.000392 LR: 9.17e-06\n",
      "Epoch  15 [8400/10697 ( 78.5%)] Loss: 0.029688 L1: 0.017390 Grad: 0.122689 Thermal: 0.000591 LR: 9.17e-06\n",
      "Epoch  15 [8400/10697 ( 78.5%)] Loss: 0.029688 L1: 0.017390 Grad: 0.122689 Thermal: 0.000591 LR: 9.17e-06\n",
      "Epoch  15 [8450/10697 ( 79.0%)] Loss: 0.028360 L1: 0.016583 Grad: 0.117512 Thermal: 0.000509 LR: 9.17e-06\n",
      "Epoch  15 [8450/10697 ( 79.0%)] Loss: 0.028360 L1: 0.016583 Grad: 0.117512 Thermal: 0.000509 LR: 9.17e-06\n",
      "Epoch  15 [8500/10697 ( 79.5%)] Loss: 0.030808 L1: 0.017567 Grad: 0.132125 Thermal: 0.000585 LR: 9.17e-06\n",
      "Epoch  15 [8500/10697 ( 79.5%)] Loss: 0.030808 L1: 0.017567 Grad: 0.132125 Thermal: 0.000585 LR: 9.17e-06\n",
      "Epoch  15 [8550/10697 ( 79.9%)] Loss: 0.025512 L1: 0.014840 Grad: 0.106505 Thermal: 0.000437 LR: 9.17e-06\n",
      "Epoch  15 [8550/10697 ( 79.9%)] Loss: 0.025512 L1: 0.014840 Grad: 0.106505 Thermal: 0.000437 LR: 9.17e-06\n",
      "Epoch  15 [8600/10697 ( 80.4%)] Loss: 0.026590 L1: 0.015767 Grad: 0.108007 Thermal: 0.000456 LR: 9.17e-06\n",
      "Epoch  15 [8600/10697 ( 80.4%)] Loss: 0.026590 L1: 0.015767 Grad: 0.108007 Thermal: 0.000456 LR: 9.17e-06\n",
      "Epoch  15 [8650/10697 ( 80.9%)] Loss: 0.026048 L1: 0.015605 Grad: 0.104212 Thermal: 0.000436 LR: 9.17e-06\n",
      "Epoch  15 [8650/10697 ( 80.9%)] Loss: 0.026048 L1: 0.015605 Grad: 0.104212 Thermal: 0.000436 LR: 9.17e-06\n",
      "Epoch  15 [8700/10697 ( 81.3%)] Loss: 0.022070 L1: 0.012800 Grad: 0.092523 Thermal: 0.000349 LR: 9.17e-06\n",
      "Epoch  15 [8700/10697 ( 81.3%)] Loss: 0.022070 L1: 0.012800 Grad: 0.092523 Thermal: 0.000349 LR: 9.17e-06\n",
      "Epoch  15 [8750/10697 ( 81.8%)] Loss: 0.026837 L1: 0.015854 Grad: 0.109604 Thermal: 0.000454 LR: 9.17e-06\n",
      "Epoch  15 [8750/10697 ( 81.8%)] Loss: 0.026837 L1: 0.015854 Grad: 0.109604 Thermal: 0.000454 LR: 9.17e-06\n",
      "Epoch  15 [8800/10697 ( 82.3%)] Loss: 0.023257 L1: 0.013882 Grad: 0.093569 Thermal: 0.000373 LR: 9.17e-06\n",
      "Epoch  15 [8800/10697 ( 82.3%)] Loss: 0.023257 L1: 0.013882 Grad: 0.093569 Thermal: 0.000373 LR: 9.17e-06\n",
      "Epoch  15 [8850/10697 ( 82.7%)] Loss: 0.021954 L1: 0.012736 Grad: 0.092027 Thermal: 0.000321 LR: 9.17e-06\n",
      "Epoch  15 [8850/10697 ( 82.7%)] Loss: 0.021954 L1: 0.012736 Grad: 0.092027 Thermal: 0.000321 LR: 9.17e-06\n",
      "Epoch  15 [8900/10697 ( 83.2%)] Loss: 0.027499 L1: 0.016103 Grad: 0.113727 Thermal: 0.000471 LR: 9.17e-06\n",
      "Epoch  15 [8900/10697 ( 83.2%)] Loss: 0.027499 L1: 0.016103 Grad: 0.113727 Thermal: 0.000471 LR: 9.17e-06\n",
      "Epoch  15 [8950/10697 ( 83.7%)] Loss: 0.031788 L1: 0.018412 Grad: 0.133400 Thermal: 0.000709 LR: 9.17e-06\n",
      "Epoch  15 [8950/10697 ( 83.7%)] Loss: 0.031788 L1: 0.018412 Grad: 0.133400 Thermal: 0.000709 LR: 9.17e-06\n",
      "Epoch  15 [9000/10697 ( 84.1%)] Loss: 0.027650 L1: 0.016038 Grad: 0.115865 Thermal: 0.000514 LR: 9.17e-06\n",
      "Epoch  15 [9000/10697 ( 84.1%)] Loss: 0.027650 L1: 0.016038 Grad: 0.115865 Thermal: 0.000514 LR: 9.17e-06\n",
      "Epoch  15 [9050/10697 ( 84.6%)] Loss: 0.025117 L1: 0.014465 Grad: 0.106324 Thermal: 0.000394 LR: 9.17e-06\n",
      "Epoch  15 [9050/10697 ( 84.6%)] Loss: 0.025117 L1: 0.014465 Grad: 0.106324 Thermal: 0.000394 LR: 9.17e-06\n",
      "Epoch  15 [9100/10697 ( 85.1%)] Loss: 0.031242 L1: 0.017855 Grad: 0.133581 Thermal: 0.000586 LR: 9.17e-06\n",
      "Epoch  15 [9100/10697 ( 85.1%)] Loss: 0.031242 L1: 0.017855 Grad: 0.133581 Thermal: 0.000586 LR: 9.17e-06\n",
      "Epoch  15 [9150/10697 ( 85.5%)] Loss: 0.025258 L1: 0.014861 Grad: 0.103767 Thermal: 0.000401 LR: 9.17e-06\n",
      "Epoch  15 [9150/10697 ( 85.5%)] Loss: 0.025258 L1: 0.014861 Grad: 0.103767 Thermal: 0.000401 LR: 9.17e-06\n",
      "Epoch  15 [9200/10697 ( 86.0%)] Loss: 0.030393 L1: 0.017686 Grad: 0.126798 Thermal: 0.000551 LR: 9.17e-06\n",
      "Epoch  15 [9200/10697 ( 86.0%)] Loss: 0.030393 L1: 0.017686 Grad: 0.126798 Thermal: 0.000551 LR: 9.17e-06\n",
      "Epoch  15 [9250/10697 ( 86.5%)] Loss: 0.026657 L1: 0.016014 Grad: 0.106203 Thermal: 0.000456 LR: 9.17e-06\n",
      "Epoch  15 [9250/10697 ( 86.5%)] Loss: 0.026657 L1: 0.016014 Grad: 0.106203 Thermal: 0.000456 LR: 9.17e-06\n",
      "Epoch  15 [9300/10697 ( 86.9%)] Loss: 0.020726 L1: 0.011908 Grad: 0.088024 Thermal: 0.000318 LR: 9.17e-06\n",
      "Epoch  15 [9300/10697 ( 86.9%)] Loss: 0.020726 L1: 0.011908 Grad: 0.088024 Thermal: 0.000318 LR: 9.17e-06\n",
      "Epoch  15 [9350/10697 ( 87.4%)] Loss: 0.027837 L1: 0.016411 Grad: 0.113999 Thermal: 0.000519 LR: 9.17e-06\n",
      "Epoch  15 [9350/10697 ( 87.4%)] Loss: 0.027837 L1: 0.016411 Grad: 0.113999 Thermal: 0.000519 LR: 9.17e-06\n",
      "Epoch  15 [9400/10697 ( 87.9%)] Loss: 0.026940 L1: 0.015936 Grad: 0.109804 Thermal: 0.000475 LR: 9.17e-06\n",
      "Epoch  15 [9400/10697 ( 87.9%)] Loss: 0.026940 L1: 0.015936 Grad: 0.109804 Thermal: 0.000475 LR: 9.17e-06\n",
      "Epoch  15 [9450/10697 ( 88.3%)] Loss: 0.028103 L1: 0.016476 Grad: 0.116034 Thermal: 0.000487 LR: 9.17e-06\n",
      "Epoch  15 [9450/10697 ( 88.3%)] Loss: 0.028103 L1: 0.016476 Grad: 0.116034 Thermal: 0.000487 LR: 9.17e-06\n",
      "Epoch  15 [9500/10697 ( 88.8%)] Loss: 0.032474 L1: 0.018481 Grad: 0.139552 Thermal: 0.000763 LR: 9.17e-06\n",
      "Epoch  15 [9500/10697 ( 88.8%)] Loss: 0.032474 L1: 0.018481 Grad: 0.139552 Thermal: 0.000763 LR: 9.17e-06\n",
      "Epoch  15 [9550/10697 ( 89.3%)] Loss: 0.026894 L1: 0.015615 Grad: 0.112576 Thermal: 0.000435 LR: 9.17e-06\n",
      "Epoch  15 [9550/10697 ( 89.3%)] Loss: 0.026894 L1: 0.015615 Grad: 0.112576 Thermal: 0.000435 LR: 9.17e-06\n",
      "Epoch  15 [9600/10697 ( 89.7%)] Loss: 0.027175 L1: 0.015817 Grad: 0.113362 Thermal: 0.000450 LR: 9.17e-06\n",
      "Epoch  15 [9600/10697 ( 89.7%)] Loss: 0.027175 L1: 0.015817 Grad: 0.113362 Thermal: 0.000450 LR: 9.17e-06\n",
      "Epoch  15 [9650/10697 ( 90.2%)] Loss: 0.028372 L1: 0.016734 Grad: 0.116121 Thermal: 0.000518 LR: 9.17e-06\n",
      "Epoch  15 [9650/10697 ( 90.2%)] Loss: 0.028372 L1: 0.016734 Grad: 0.116121 Thermal: 0.000518 LR: 9.17e-06\n",
      "Epoch  15 [9700/10697 ( 90.7%)] Loss: 0.021327 L1: 0.012385 Grad: 0.089264 Thermal: 0.000301 LR: 9.17e-06\n",
      "Epoch  15 [9700/10697 ( 90.7%)] Loss: 0.021327 L1: 0.012385 Grad: 0.089264 Thermal: 0.000301 LR: 9.17e-06\n",
      "Epoch  15 [9750/10697 ( 91.1%)] Loss: 0.023990 L1: 0.013967 Grad: 0.100037 Thermal: 0.000380 LR: 9.17e-06\n",
      "Epoch  15 [9750/10697 ( 91.1%)] Loss: 0.023990 L1: 0.013967 Grad: 0.100037 Thermal: 0.000380 LR: 9.17e-06\n",
      "Epoch  15 [9800/10697 ( 91.6%)] Loss: 0.021516 L1: 0.012825 Grad: 0.086760 Thermal: 0.000308 LR: 9.17e-06\n",
      "Epoch  15 [9800/10697 ( 91.6%)] Loss: 0.021516 L1: 0.012825 Grad: 0.086760 Thermal: 0.000308 LR: 9.17e-06\n",
      "Epoch  15 [9850/10697 ( 92.1%)] Loss: 0.018290 L1: 0.010357 Grad: 0.079219 Thermal: 0.000230 LR: 9.17e-06\n",
      "Epoch  15 [9850/10697 ( 92.1%)] Loss: 0.018290 L1: 0.010357 Grad: 0.079219 Thermal: 0.000230 LR: 9.17e-06\n",
      "Epoch  15 [9900/10697 ( 92.5%)] Loss: 0.029507 L1: 0.017723 Grad: 0.117541 Thermal: 0.000598 LR: 9.17e-06\n",
      "Epoch  15 [9900/10697 ( 92.5%)] Loss: 0.029507 L1: 0.017723 Grad: 0.117541 Thermal: 0.000598 LR: 9.17e-06\n",
      "Epoch  15 [9950/10697 ( 93.0%)] Loss: 0.023609 L1: 0.013669 Grad: 0.099219 Thermal: 0.000373 LR: 9.17e-06\n",
      "Epoch  15 [9950/10697 ( 93.0%)] Loss: 0.023609 L1: 0.013669 Grad: 0.099219 Thermal: 0.000373 LR: 9.17e-06\n",
      "Epoch  15 [10000/10697 ( 93.5%)] Loss: 0.023928 L1: 0.013904 Grad: 0.100056 Thermal: 0.000361 LR: 9.17e-06\n",
      "Epoch  15 [10000/10697 ( 93.5%)] Loss: 0.023928 L1: 0.013904 Grad: 0.100056 Thermal: 0.000361 LR: 9.17e-06\n",
      "Epoch  15 [10050/10697 ( 94.0%)] Loss: 0.027213 L1: 0.015867 Grad: 0.113234 Thermal: 0.000461 LR: 9.17e-06\n",
      "Epoch  15 [10050/10697 ( 94.0%)] Loss: 0.027213 L1: 0.015867 Grad: 0.113234 Thermal: 0.000461 LR: 9.17e-06\n",
      "Epoch  15 [10100/10697 ( 94.4%)] Loss: 0.020459 L1: 0.011956 Grad: 0.084875 Thermal: 0.000311 LR: 9.17e-06\n",
      "Epoch  15 [10100/10697 ( 94.4%)] Loss: 0.020459 L1: 0.011956 Grad: 0.084875 Thermal: 0.000311 LR: 9.17e-06\n",
      "Epoch  15 [10150/10697 ( 94.9%)] Loss: 0.025441 L1: 0.014918 Grad: 0.105010 Thermal: 0.000436 LR: 9.17e-06\n",
      "Epoch  15 [10150/10697 ( 94.9%)] Loss: 0.025441 L1: 0.014918 Grad: 0.105010 Thermal: 0.000436 LR: 9.17e-06\n",
      "Epoch  15 [10200/10697 ( 95.4%)] Loss: 0.026844 L1: 0.015582 Grad: 0.112353 Thermal: 0.000525 LR: 9.17e-06\n",
      "Epoch  15 [10200/10697 ( 95.4%)] Loss: 0.026844 L1: 0.015582 Grad: 0.112353 Thermal: 0.000525 LR: 9.17e-06\n",
      "Epoch  15 [10250/10697 ( 95.8%)] Loss: 0.024362 L1: 0.014377 Grad: 0.099642 Thermal: 0.000406 LR: 9.17e-06\n",
      "Epoch  15 [10250/10697 ( 95.8%)] Loss: 0.024362 L1: 0.014377 Grad: 0.099642 Thermal: 0.000406 LR: 9.17e-06\n",
      "Epoch  15 [10300/10697 ( 96.3%)] Loss: 0.024325 L1: 0.014184 Grad: 0.101217 Thermal: 0.000386 LR: 9.17e-06\n",
      "Epoch  15 [10300/10697 ( 96.3%)] Loss: 0.024325 L1: 0.014184 Grad: 0.101217 Thermal: 0.000386 LR: 9.17e-06\n",
      "Epoch  15 [10350/10697 ( 96.8%)] Loss: 0.032174 L1: 0.017558 Grad: 0.145876 Thermal: 0.000573 LR: 9.17e-06\n",
      "Epoch  15 [10350/10697 ( 96.8%)] Loss: 0.032174 L1: 0.017558 Grad: 0.145876 Thermal: 0.000573 LR: 9.17e-06\n",
      "Epoch  15 [10400/10697 ( 97.2%)] Loss: 0.026469 L1: 0.015629 Grad: 0.108185 Thermal: 0.000429 LR: 9.17e-06\n",
      "Epoch  15 [10400/10697 ( 97.2%)] Loss: 0.026469 L1: 0.015629 Grad: 0.108185 Thermal: 0.000429 LR: 9.17e-06\n",
      "Epoch  15 [10450/10697 ( 97.7%)] Loss: 0.024415 L1: 0.013857 Grad: 0.105413 Thermal: 0.000351 LR: 9.17e-06\n",
      "Epoch  15 [10450/10697 ( 97.7%)] Loss: 0.024415 L1: 0.013857 Grad: 0.105413 Thermal: 0.000351 LR: 9.17e-06\n",
      "Epoch  15 [10500/10697 ( 98.2%)] Loss: 0.024367 L1: 0.013944 Grad: 0.104043 Thermal: 0.000381 LR: 9.17e-06\n",
      "Epoch  15 [10500/10697 ( 98.2%)] Loss: 0.024367 L1: 0.013944 Grad: 0.104043 Thermal: 0.000381 LR: 9.17e-06\n",
      "Epoch  15 [10550/10697 ( 98.6%)] Loss: 0.025362 L1: 0.014951 Grad: 0.103908 Thermal: 0.000407 LR: 9.17e-06\n",
      "Epoch  15 [10550/10697 ( 98.6%)] Loss: 0.025362 L1: 0.014951 Grad: 0.103908 Thermal: 0.000407 LR: 9.17e-06\n",
      "Epoch  15 [10600/10697 ( 99.1%)] Loss: 0.027020 L1: 0.015501 Grad: 0.114981 Thermal: 0.000422 LR: 9.17e-06\n",
      "Epoch  15 [10600/10697 ( 99.1%)] Loss: 0.027020 L1: 0.015501 Grad: 0.114981 Thermal: 0.000422 LR: 9.17e-06\n",
      "Epoch  15 [10650/10697 ( 99.6%)] Loss: 0.028266 L1: 0.016810 Grad: 0.114303 Thermal: 0.000519 LR: 9.17e-06\n",
      "Epoch  15 [10650/10697 ( 99.6%)] Loss: 0.028266 L1: 0.016810 Grad: 0.114303 Thermal: 0.000519 LR: 9.17e-06\n",
      "üí´ New best model saved! PSNR: 33.84\n",
      "Epoch  15 Summary: Loss=0.026639 (L1:0.0155, Grad:0.1110, Thermal:0.0005) Val_PSNR=33.84dB Best=33.84dB Time=57.5min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "üí´ New best model saved! PSNR: 33.84\n",
      "Epoch  15 Summary: Loss=0.026639 (L1:0.0155, Grad:0.1110, Thermal:0.0005) Val_PSNR=33.84dB Best=33.84dB Time=57.5min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  16 [   0/10697 (  0.0%)] Loss: 0.029506 L1: 0.017532 Grad: 0.119454 Thermal: 0.000572 LR: 9.05e-06\n",
      "Epoch  16 [   0/10697 (  0.0%)] Loss: 0.029506 L1: 0.017532 Grad: 0.119454 Thermal: 0.000572 LR: 9.05e-06\n",
      "Epoch  16 [  50/10697 (  0.5%)] Loss: 0.033077 L1: 0.018713 Grad: 0.143332 Thermal: 0.000616 LR: 9.05e-06\n",
      "Epoch  16 [  50/10697 (  0.5%)] Loss: 0.033077 L1: 0.018713 Grad: 0.143332 Thermal: 0.000616 LR: 9.05e-06\n",
      "Epoch  16 [ 100/10697 (  0.9%)] Loss: 0.023678 L1: 0.014349 Grad: 0.093100 Thermal: 0.000384 LR: 9.05e-06\n",
      "Epoch  16 [ 100/10697 (  0.9%)] Loss: 0.023678 L1: 0.014349 Grad: 0.093100 Thermal: 0.000384 LR: 9.05e-06\n",
      "Epoch  16 [ 150/10697 (  1.4%)] Loss: 0.029400 L1: 0.017000 Grad: 0.123693 Thermal: 0.000607 LR: 9.05e-06\n",
      "Epoch  16 [ 150/10697 (  1.4%)] Loss: 0.029400 L1: 0.017000 Grad: 0.123693 Thermal: 0.000607 LR: 9.05e-06\n",
      "Epoch  16 [ 200/10697 (  1.9%)] Loss: 0.025839 L1: 0.015132 Grad: 0.106847 Thermal: 0.000451 LR: 9.05e-06\n",
      "Epoch  16 [ 200/10697 (  1.9%)] Loss: 0.025839 L1: 0.015132 Grad: 0.106847 Thermal: 0.000451 LR: 9.05e-06\n",
      "Epoch  16 [ 250/10697 (  2.3%)] Loss: 0.023844 L1: 0.013528 Grad: 0.102969 Thermal: 0.000381 LR: 9.05e-06\n",
      "Epoch  16 [ 250/10697 (  2.3%)] Loss: 0.023844 L1: 0.013528 Grad: 0.102969 Thermal: 0.000381 LR: 9.05e-06\n",
      "Epoch  16 [ 300/10697 (  2.8%)] Loss: 0.023910 L1: 0.013809 Grad: 0.100839 Thermal: 0.000348 LR: 9.05e-06\n",
      "Epoch  16 [ 300/10697 (  2.8%)] Loss: 0.023910 L1: 0.013809 Grad: 0.100839 Thermal: 0.000348 LR: 9.05e-06\n",
      "Epoch  16 [ 350/10697 (  3.3%)] Loss: 0.031291 L1: 0.018035 Grad: 0.132286 Thermal: 0.000556 LR: 9.05e-06\n",
      "Epoch  16 [ 350/10697 (  3.3%)] Loss: 0.031291 L1: 0.018035 Grad: 0.132286 Thermal: 0.000556 LR: 9.05e-06\n",
      "Epoch  16 [ 400/10697 (  3.7%)] Loss: 0.023770 L1: 0.013416 Grad: 0.103346 Thermal: 0.000383 LR: 9.05e-06\n",
      "Epoch  16 [ 400/10697 (  3.7%)] Loss: 0.023770 L1: 0.013416 Grad: 0.103346 Thermal: 0.000383 LR: 9.05e-06\n",
      "Epoch  16 [ 450/10697 (  4.2%)] Loss: 0.024160 L1: 0.014397 Grad: 0.097440 Thermal: 0.000383 LR: 9.05e-06\n",
      "Epoch  16 [ 450/10697 (  4.2%)] Loss: 0.024160 L1: 0.014397 Grad: 0.097440 Thermal: 0.000383 LR: 9.05e-06\n",
      "Epoch  16 [ 500/10697 (  4.7%)] Loss: 0.028237 L1: 0.016710 Grad: 0.114970 Thermal: 0.000599 LR: 9.05e-06\n",
      "Epoch  16 [ 500/10697 (  4.7%)] Loss: 0.028237 L1: 0.016710 Grad: 0.114970 Thermal: 0.000599 LR: 9.05e-06\n",
      "Epoch  16 [ 550/10697 (  5.1%)] Loss: 0.031678 L1: 0.018508 Grad: 0.131379 Thermal: 0.000648 LR: 9.05e-06\n",
      "Epoch  16 [ 550/10697 (  5.1%)] Loss: 0.031678 L1: 0.018508 Grad: 0.131379 Thermal: 0.000648 LR: 9.05e-06\n",
      "Epoch  16 [ 600/10697 (  5.6%)] Loss: 0.025189 L1: 0.014980 Grad: 0.101882 Thermal: 0.000421 LR: 9.05e-06\n",
      "Epoch  16 [ 600/10697 (  5.6%)] Loss: 0.025189 L1: 0.014980 Grad: 0.101882 Thermal: 0.000421 LR: 9.05e-06\n",
      "Epoch  16 [ 650/10697 (  6.1%)] Loss: 0.022819 L1: 0.013239 Grad: 0.095626 Thermal: 0.000355 LR: 9.05e-06\n",
      "Epoch  16 [ 650/10697 (  6.1%)] Loss: 0.022819 L1: 0.013239 Grad: 0.095626 Thermal: 0.000355 LR: 9.05e-06\n",
      "Epoch  16 [ 700/10697 (  6.5%)] Loss: 0.026825 L1: 0.016186 Grad: 0.106157 Thermal: 0.000460 LR: 9.05e-06\n",
      "Epoch  16 [ 700/10697 (  6.5%)] Loss: 0.026825 L1: 0.016186 Grad: 0.106157 Thermal: 0.000460 LR: 9.05e-06\n",
      "Epoch  16 [ 750/10697 (  7.0%)] Loss: 0.024543 L1: 0.014160 Grad: 0.103630 Thermal: 0.000400 LR: 9.05e-06\n",
      "Epoch  16 [ 750/10697 (  7.0%)] Loss: 0.024543 L1: 0.014160 Grad: 0.103630 Thermal: 0.000400 LR: 9.05e-06\n",
      "Epoch  16 [ 800/10697 (  7.5%)] Loss: 0.031138 L1: 0.018160 Grad: 0.129478 Thermal: 0.000607 LR: 9.05e-06\n",
      "Epoch  16 [ 800/10697 (  7.5%)] Loss: 0.031138 L1: 0.018160 Grad: 0.129478 Thermal: 0.000607 LR: 9.05e-06\n",
      "Epoch  16 [ 850/10697 (  7.9%)] Loss: 0.026847 L1: 0.015398 Grad: 0.114256 Thermal: 0.000462 LR: 9.05e-06\n",
      "Epoch  16 [ 850/10697 (  7.9%)] Loss: 0.026847 L1: 0.015398 Grad: 0.114256 Thermal: 0.000462 LR: 9.05e-06\n",
      "Epoch  16 [ 900/10697 (  8.4%)] Loss: 0.023984 L1: 0.014380 Grad: 0.095851 Thermal: 0.000377 LR: 9.05e-06\n",
      "Epoch  16 [ 900/10697 (  8.4%)] Loss: 0.023984 L1: 0.014380 Grad: 0.095851 Thermal: 0.000377 LR: 9.05e-06\n",
      "Epoch  16 [ 950/10697 (  8.9%)] Loss: 0.023879 L1: 0.014092 Grad: 0.097681 Thermal: 0.000379 LR: 9.05e-06\n",
      "Epoch  16 [ 950/10697 (  8.9%)] Loss: 0.023879 L1: 0.014092 Grad: 0.097681 Thermal: 0.000379 LR: 9.05e-06\n",
      "Epoch  16 [1000/10697 (  9.3%)] Loss: 0.027476 L1: 0.016404 Grad: 0.110475 Thermal: 0.000482 LR: 9.05e-06\n",
      "Epoch  16 [1000/10697 (  9.3%)] Loss: 0.027476 L1: 0.016404 Grad: 0.110475 Thermal: 0.000482 LR: 9.05e-06\n",
      "Epoch  16 [1050/10697 (  9.8%)] Loss: 0.030974 L1: 0.018261 Grad: 0.126824 Thermal: 0.000600 LR: 9.05e-06\n",
      "Epoch  16 [1050/10697 (  9.8%)] Loss: 0.030974 L1: 0.018261 Grad: 0.126824 Thermal: 0.000600 LR: 9.05e-06\n",
      "Epoch  16 [1100/10697 ( 10.3%)] Loss: 0.027010 L1: 0.015646 Grad: 0.113404 Thermal: 0.000462 LR: 9.05e-06\n",
      "Epoch  16 [1100/10697 ( 10.3%)] Loss: 0.027010 L1: 0.015646 Grad: 0.113404 Thermal: 0.000462 LR: 9.05e-06\n",
      "Epoch  16 [1150/10697 ( 10.8%)] Loss: 0.031393 L1: 0.018150 Grad: 0.132141 Thermal: 0.000584 LR: 9.05e-06\n",
      "Epoch  16 [1150/10697 ( 10.8%)] Loss: 0.031393 L1: 0.018150 Grad: 0.132141 Thermal: 0.000584 LR: 9.05e-06\n",
      "Epoch  16 [1200/10697 ( 11.2%)] Loss: 0.038342 L1: 0.022169 Grad: 0.161274 Thermal: 0.000905 LR: 9.05e-06\n",
      "Epoch  16 [1200/10697 ( 11.2%)] Loss: 0.038342 L1: 0.022169 Grad: 0.161274 Thermal: 0.000905 LR: 9.05e-06\n",
      "Epoch  16 [1250/10697 ( 11.7%)] Loss: 0.024026 L1: 0.013885 Grad: 0.101187 Thermal: 0.000449 LR: 9.05e-06\n",
      "Epoch  16 [1250/10697 ( 11.7%)] Loss: 0.024026 L1: 0.013885 Grad: 0.101187 Thermal: 0.000449 LR: 9.05e-06\n",
      "Epoch  16 [1300/10697 ( 12.2%)] Loss: 0.024558 L1: 0.014326 Grad: 0.102122 Thermal: 0.000384 LR: 9.05e-06\n",
      "Epoch  16 [1300/10697 ( 12.2%)] Loss: 0.024558 L1: 0.014326 Grad: 0.102122 Thermal: 0.000384 LR: 9.05e-06\n",
      "Epoch  16 [1350/10697 ( 12.6%)] Loss: 0.025558 L1: 0.015002 Grad: 0.105356 Thermal: 0.000402 LR: 9.05e-06\n",
      "Epoch  16 [1350/10697 ( 12.6%)] Loss: 0.025558 L1: 0.015002 Grad: 0.105356 Thermal: 0.000402 LR: 9.05e-06\n",
      "Epoch  16 [1400/10697 ( 13.1%)] Loss: 0.024669 L1: 0.014378 Grad: 0.102707 Thermal: 0.000404 LR: 9.05e-06\n",
      "Epoch  16 [1400/10697 ( 13.1%)] Loss: 0.024669 L1: 0.014378 Grad: 0.102707 Thermal: 0.000404 LR: 9.05e-06\n",
      "Epoch  16 [1450/10697 ( 13.6%)] Loss: 0.022044 L1: 0.012896 Grad: 0.091325 Thermal: 0.000314 LR: 9.05e-06\n",
      "Epoch  16 [1450/10697 ( 13.6%)] Loss: 0.022044 L1: 0.012896 Grad: 0.091325 Thermal: 0.000314 LR: 9.05e-06\n",
      "Epoch  16 [1500/10697 ( 14.0%)] Loss: 0.024550 L1: 0.014244 Grad: 0.102842 Thermal: 0.000422 LR: 9.05e-06\n",
      "Epoch  16 [1500/10697 ( 14.0%)] Loss: 0.024550 L1: 0.014244 Grad: 0.102842 Thermal: 0.000422 LR: 9.05e-06\n",
      "Epoch  16 [1550/10697 ( 14.5%)] Loss: 0.027161 L1: 0.016217 Grad: 0.109207 Thermal: 0.000480 LR: 9.05e-06\n",
      "Epoch  16 [1550/10697 ( 14.5%)] Loss: 0.027161 L1: 0.016217 Grad: 0.109207 Thermal: 0.000480 LR: 9.05e-06\n",
      "Epoch  16 [1600/10697 ( 15.0%)] Loss: 0.024287 L1: 0.014123 Grad: 0.101460 Thermal: 0.000366 LR: 9.05e-06\n",
      "Epoch  16 [1600/10697 ( 15.0%)] Loss: 0.024287 L1: 0.014123 Grad: 0.101460 Thermal: 0.000366 LR: 9.05e-06\n",
      "Epoch  16 [1650/10697 ( 15.4%)] Loss: 0.023370 L1: 0.013632 Grad: 0.097193 Thermal: 0.000373 LR: 9.05e-06\n",
      "Epoch  16 [1650/10697 ( 15.4%)] Loss: 0.023370 L1: 0.013632 Grad: 0.097193 Thermal: 0.000373 LR: 9.05e-06\n",
      "Epoch  16 [1700/10697 ( 15.9%)] Loss: 0.023712 L1: 0.013706 Grad: 0.099879 Thermal: 0.000361 LR: 9.05e-06\n",
      "Epoch  16 [1700/10697 ( 15.9%)] Loss: 0.023712 L1: 0.013706 Grad: 0.099879 Thermal: 0.000361 LR: 9.05e-06\n",
      "Epoch  16 [1750/10697 ( 16.4%)] Loss: 0.023741 L1: 0.013863 Grad: 0.098591 Thermal: 0.000380 LR: 9.05e-06\n",
      "Epoch  16 [1750/10697 ( 16.4%)] Loss: 0.023741 L1: 0.013863 Grad: 0.098591 Thermal: 0.000380 LR: 9.05e-06\n",
      "Epoch  16 [1800/10697 ( 16.8%)] Loss: 0.032469 L1: 0.018860 Grad: 0.135826 Thermal: 0.000514 LR: 9.05e-06\n",
      "Epoch  16 [1800/10697 ( 16.8%)] Loss: 0.032469 L1: 0.018860 Grad: 0.135826 Thermal: 0.000514 LR: 9.05e-06\n",
      "Epoch  16 [1850/10697 ( 17.3%)] Loss: 0.026412 L1: 0.015562 Grad: 0.108285 Thermal: 0.000422 LR: 9.05e-06\n",
      "Epoch  16 [1850/10697 ( 17.3%)] Loss: 0.026412 L1: 0.015562 Grad: 0.108285 Thermal: 0.000422 LR: 9.05e-06\n",
      "Epoch  16 [1900/10697 ( 17.8%)] Loss: 0.025845 L1: 0.015061 Grad: 0.107617 Thermal: 0.000432 LR: 9.05e-06\n",
      "Epoch  16 [1900/10697 ( 17.8%)] Loss: 0.025845 L1: 0.015061 Grad: 0.107617 Thermal: 0.000432 LR: 9.05e-06\n",
      "Epoch  16 [1950/10697 ( 18.2%)] Loss: 0.022106 L1: 0.013076 Grad: 0.090124 Thermal: 0.000340 LR: 9.05e-06\n",
      "Epoch  16 [1950/10697 ( 18.2%)] Loss: 0.022106 L1: 0.013076 Grad: 0.090124 Thermal: 0.000340 LR: 9.05e-06\n",
      "Epoch  16 [2000/10697 ( 18.7%)] Loss: 0.022033 L1: 0.012846 Grad: 0.091680 Thermal: 0.000370 LR: 9.05e-06\n",
      "Epoch  16 [2000/10697 ( 18.7%)] Loss: 0.022033 L1: 0.012846 Grad: 0.091680 Thermal: 0.000370 LR: 9.05e-06\n",
      "Epoch  16 [2050/10697 ( 19.2%)] Loss: 0.022308 L1: 0.012669 Grad: 0.096240 Thermal: 0.000299 LR: 9.05e-06\n",
      "Epoch  16 [2050/10697 ( 19.2%)] Loss: 0.022308 L1: 0.012669 Grad: 0.096240 Thermal: 0.000299 LR: 9.05e-06\n",
      "Epoch  16 [2100/10697 ( 19.6%)] Loss: 0.031535 L1: 0.018407 Grad: 0.130949 Thermal: 0.000665 LR: 9.05e-06\n",
      "Epoch  16 [2100/10697 ( 19.6%)] Loss: 0.031535 L1: 0.018407 Grad: 0.130949 Thermal: 0.000665 LR: 9.05e-06\n",
      "Epoch  16 [2150/10697 ( 20.1%)] Loss: 0.028062 L1: 0.016379 Grad: 0.116591 Thermal: 0.000465 LR: 9.05e-06\n",
      "Epoch  16 [2150/10697 ( 20.1%)] Loss: 0.028062 L1: 0.016379 Grad: 0.116591 Thermal: 0.000465 LR: 9.05e-06\n",
      "Epoch  16 [2200/10697 ( 20.6%)] Loss: 0.024508 L1: 0.014382 Grad: 0.101060 Thermal: 0.000406 LR: 9.05e-06\n",
      "Epoch  16 [2200/10697 ( 20.6%)] Loss: 0.024508 L1: 0.014382 Grad: 0.101060 Thermal: 0.000406 LR: 9.05e-06\n",
      "Epoch  16 [2250/10697 ( 21.0%)] Loss: 0.031962 L1: 0.019176 Grad: 0.127536 Thermal: 0.000666 LR: 9.05e-06\n",
      "Epoch  16 [2250/10697 ( 21.0%)] Loss: 0.031962 L1: 0.019176 Grad: 0.127536 Thermal: 0.000666 LR: 9.05e-06\n",
      "Epoch  16 [2300/10697 ( 21.5%)] Loss: 0.019945 L1: 0.011368 Grad: 0.085639 Thermal: 0.000279 LR: 9.05e-06\n",
      "Epoch  16 [2300/10697 ( 21.5%)] Loss: 0.019945 L1: 0.011368 Grad: 0.085639 Thermal: 0.000279 LR: 9.05e-06\n",
      "Epoch  16 [2350/10697 ( 22.0%)] Loss: 0.026133 L1: 0.015244 Grad: 0.108671 Thermal: 0.000445 LR: 9.05e-06\n",
      "Epoch  16 [2350/10697 ( 22.0%)] Loss: 0.026133 L1: 0.015244 Grad: 0.108671 Thermal: 0.000445 LR: 9.05e-06\n",
      "Epoch  16 [2400/10697 ( 22.4%)] Loss: 0.030712 L1: 0.017515 Grad: 0.131684 Thermal: 0.000574 LR: 9.05e-06\n",
      "Epoch  16 [2400/10697 ( 22.4%)] Loss: 0.030712 L1: 0.017515 Grad: 0.131684 Thermal: 0.000574 LR: 9.05e-06\n",
      "Epoch  16 [2450/10697 ( 22.9%)] Loss: 0.025836 L1: 0.015055 Grad: 0.107592 Thermal: 0.000427 LR: 9.05e-06\n",
      "Epoch  16 [2450/10697 ( 22.9%)] Loss: 0.025836 L1: 0.015055 Grad: 0.107592 Thermal: 0.000427 LR: 9.05e-06\n",
      "Epoch  16 [2500/10697 ( 23.4%)] Loss: 0.021419 L1: 0.012698 Grad: 0.087027 Thermal: 0.000364 LR: 9.05e-06\n",
      "Epoch  16 [2500/10697 ( 23.4%)] Loss: 0.021419 L1: 0.012698 Grad: 0.087027 Thermal: 0.000364 LR: 9.05e-06\n",
      "Epoch  16 [2550/10697 ( 23.8%)] Loss: 0.030131 L1: 0.017476 Grad: 0.126271 Thermal: 0.000568 LR: 9.05e-06\n",
      "Epoch  16 [2550/10697 ( 23.8%)] Loss: 0.030131 L1: 0.017476 Grad: 0.126271 Thermal: 0.000568 LR: 9.05e-06\n",
      "Epoch  16 [2600/10697 ( 24.3%)] Loss: 0.036084 L1: 0.020985 Grad: 0.150584 Thermal: 0.000798 LR: 9.05e-06\n",
      "Epoch  16 [2600/10697 ( 24.3%)] Loss: 0.036084 L1: 0.020985 Grad: 0.150584 Thermal: 0.000798 LR: 9.05e-06\n",
      "Epoch  16 [2650/10697 ( 24.8%)] Loss: 0.030588 L1: 0.017699 Grad: 0.128611 Thermal: 0.000548 LR: 9.05e-06\n",
      "Epoch  16 [2650/10697 ( 24.8%)] Loss: 0.030588 L1: 0.017699 Grad: 0.128611 Thermal: 0.000548 LR: 9.05e-06\n",
      "Epoch  16 [2700/10697 ( 25.2%)] Loss: 0.023517 L1: 0.013546 Grad: 0.099528 Thermal: 0.000370 LR: 9.05e-06\n",
      "Epoch  16 [2700/10697 ( 25.2%)] Loss: 0.023517 L1: 0.013546 Grad: 0.099528 Thermal: 0.000370 LR: 9.05e-06\n",
      "Epoch  16 [2750/10697 ( 25.7%)] Loss: 0.025703 L1: 0.015284 Grad: 0.103972 Thermal: 0.000428 LR: 9.05e-06\n",
      "Epoch  16 [2750/10697 ( 25.7%)] Loss: 0.025703 L1: 0.015284 Grad: 0.103972 Thermal: 0.000428 LR: 9.05e-06\n",
      "Epoch  16 [2800/10697 ( 26.2%)] Loss: 0.022852 L1: 0.012943 Grad: 0.098894 Thermal: 0.000376 LR: 9.05e-06\n",
      "Epoch  16 [2800/10697 ( 26.2%)] Loss: 0.022852 L1: 0.012943 Grad: 0.098894 Thermal: 0.000376 LR: 9.05e-06\n",
      "Epoch  16 [2850/10697 ( 26.6%)] Loss: 0.026552 L1: 0.015660 Grad: 0.108686 Thermal: 0.000465 LR: 9.05e-06\n",
      "Epoch  16 [2850/10697 ( 26.6%)] Loss: 0.026552 L1: 0.015660 Grad: 0.108686 Thermal: 0.000465 LR: 9.05e-06\n",
      "Epoch  16 [2900/10697 ( 27.1%)] Loss: 0.030782 L1: 0.017860 Grad: 0.128936 Thermal: 0.000564 LR: 9.05e-06\n",
      "Epoch  16 [2900/10697 ( 27.1%)] Loss: 0.030782 L1: 0.017860 Grad: 0.128936 Thermal: 0.000564 LR: 9.05e-06\n",
      "Epoch  16 [2950/10697 ( 27.6%)] Loss: 0.027185 L1: 0.015938 Grad: 0.112231 Thermal: 0.000478 LR: 9.05e-06\n",
      "Epoch  16 [2950/10697 ( 27.6%)] Loss: 0.027185 L1: 0.015938 Grad: 0.112231 Thermal: 0.000478 LR: 9.05e-06\n",
      "Epoch  16 [3000/10697 ( 28.0%)] Loss: 0.024529 L1: 0.014564 Grad: 0.099469 Thermal: 0.000365 LR: 9.05e-06\n",
      "Epoch  16 [3000/10697 ( 28.0%)] Loss: 0.024529 L1: 0.014564 Grad: 0.099469 Thermal: 0.000365 LR: 9.05e-06\n",
      "Epoch  16 [3050/10697 ( 28.5%)] Loss: 0.023122 L1: 0.013473 Grad: 0.096308 Thermal: 0.000355 LR: 9.05e-06\n",
      "Epoch  16 [3050/10697 ( 28.5%)] Loss: 0.023122 L1: 0.013473 Grad: 0.096308 Thermal: 0.000355 LR: 9.05e-06\n",
      "Epoch  16 [3100/10697 ( 29.0%)] Loss: 0.026841 L1: 0.015040 Grad: 0.117796 Thermal: 0.000435 LR: 9.05e-06\n",
      "Epoch  16 [3100/10697 ( 29.0%)] Loss: 0.026841 L1: 0.015040 Grad: 0.117796 Thermal: 0.000435 LR: 9.05e-06\n",
      "Epoch  16 [3150/10697 ( 29.4%)] Loss: 0.028739 L1: 0.017206 Grad: 0.115063 Thermal: 0.000528 LR: 9.05e-06\n",
      "Epoch  16 [3150/10697 ( 29.4%)] Loss: 0.028739 L1: 0.017206 Grad: 0.115063 Thermal: 0.000528 LR: 9.05e-06\n",
      "Epoch  16 [3200/10697 ( 29.9%)] Loss: 0.034932 L1: 0.019766 Grad: 0.151330 Thermal: 0.000659 LR: 9.05e-06\n",
      "Epoch  16 [3200/10697 ( 29.9%)] Loss: 0.034932 L1: 0.019766 Grad: 0.151330 Thermal: 0.000659 LR: 9.05e-06\n",
      "Epoch  16 [3250/10697 ( 30.4%)] Loss: 0.030838 L1: 0.018062 Grad: 0.127461 Thermal: 0.000610 LR: 9.05e-06\n",
      "Epoch  16 [3250/10697 ( 30.4%)] Loss: 0.030838 L1: 0.018062 Grad: 0.127461 Thermal: 0.000610 LR: 9.05e-06\n",
      "Epoch  16 [3300/10697 ( 30.8%)] Loss: 0.035278 L1: 0.020132 Grad: 0.151085 Thermal: 0.000748 LR: 9.05e-06\n",
      "Epoch  16 [3300/10697 ( 30.8%)] Loss: 0.035278 L1: 0.020132 Grad: 0.151085 Thermal: 0.000748 LR: 9.05e-06\n",
      "Epoch  16 [3350/10697 ( 31.3%)] Loss: 0.029373 L1: 0.017389 Grad: 0.119566 Thermal: 0.000536 LR: 9.05e-06\n",
      "Epoch  16 [3350/10697 ( 31.3%)] Loss: 0.029373 L1: 0.017389 Grad: 0.119566 Thermal: 0.000536 LR: 9.05e-06\n",
      "Epoch  16 [3400/10697 ( 31.8%)] Loss: 0.034935 L1: 0.020532 Grad: 0.143637 Thermal: 0.000777 LR: 9.05e-06\n",
      "Epoch  16 [3400/10697 ( 31.8%)] Loss: 0.034935 L1: 0.020532 Grad: 0.143637 Thermal: 0.000777 LR: 9.05e-06\n",
      "Epoch  16 [3450/10697 ( 32.3%)] Loss: 0.030408 L1: 0.017289 Grad: 0.130920 Thermal: 0.000556 LR: 9.05e-06\n",
      "Epoch  16 [3450/10697 ( 32.3%)] Loss: 0.030408 L1: 0.017289 Grad: 0.130920 Thermal: 0.000556 LR: 9.05e-06\n",
      "Epoch  16 [3500/10697 ( 32.7%)] Loss: 0.026307 L1: 0.014760 Grad: 0.115262 Thermal: 0.000403 LR: 9.05e-06\n",
      "Epoch  16 [3500/10697 ( 32.7%)] Loss: 0.026307 L1: 0.014760 Grad: 0.115262 Thermal: 0.000403 LR: 9.05e-06\n",
      "Epoch  16 [3550/10697 ( 33.2%)] Loss: 0.025634 L1: 0.014821 Grad: 0.107926 Thermal: 0.000413 LR: 9.05e-06\n",
      "Epoch  16 [3550/10697 ( 33.2%)] Loss: 0.025634 L1: 0.014821 Grad: 0.107926 Thermal: 0.000413 LR: 9.05e-06\n",
      "Epoch  16 [3600/10697 ( 33.7%)] Loss: 0.028829 L1: 0.017045 Grad: 0.117577 Thermal: 0.000515 LR: 9.05e-06\n",
      "Epoch  16 [3600/10697 ( 33.7%)] Loss: 0.028829 L1: 0.017045 Grad: 0.117577 Thermal: 0.000515 LR: 9.05e-06\n",
      "Epoch  16 [3650/10697 ( 34.1%)] Loss: 0.029649 L1: 0.017574 Grad: 0.120484 Thermal: 0.000537 LR: 9.05e-06\n",
      "Epoch  16 [3650/10697 ( 34.1%)] Loss: 0.029649 L1: 0.017574 Grad: 0.120484 Thermal: 0.000537 LR: 9.05e-06\n",
      "Epoch  16 [3700/10697 ( 34.6%)] Loss: 0.024635 L1: 0.014346 Grad: 0.102692 Thermal: 0.000381 LR: 9.05e-06\n",
      "Epoch  16 [3700/10697 ( 34.6%)] Loss: 0.024635 L1: 0.014346 Grad: 0.102692 Thermal: 0.000381 LR: 9.05e-06\n",
      "Epoch  16 [3750/10697 ( 35.1%)] Loss: 0.024603 L1: 0.014167 Grad: 0.104149 Thermal: 0.000412 LR: 9.05e-06\n",
      "Epoch  16 [3750/10697 ( 35.1%)] Loss: 0.024603 L1: 0.014167 Grad: 0.104149 Thermal: 0.000412 LR: 9.05e-06\n",
      "Epoch  16 [3800/10697 ( 35.5%)] Loss: 0.024275 L1: 0.013734 Grad: 0.105229 Thermal: 0.000370 LR: 9.05e-06\n",
      "Epoch  16 [3800/10697 ( 35.5%)] Loss: 0.024275 L1: 0.013734 Grad: 0.105229 Thermal: 0.000370 LR: 9.05e-06\n",
      "Epoch  16 [3850/10697 ( 36.0%)] Loss: 0.023970 L1: 0.014001 Grad: 0.099509 Thermal: 0.000353 LR: 9.05e-06\n",
      "Epoch  16 [3850/10697 ( 36.0%)] Loss: 0.023970 L1: 0.014001 Grad: 0.099509 Thermal: 0.000353 LR: 9.05e-06\n",
      "Epoch  16 [3900/10697 ( 36.5%)] Loss: 0.027709 L1: 0.016320 Grad: 0.113637 Thermal: 0.000502 LR: 9.05e-06\n",
      "Epoch  16 [3900/10697 ( 36.5%)] Loss: 0.027709 L1: 0.016320 Grad: 0.113637 Thermal: 0.000502 LR: 9.05e-06\n",
      "Epoch  16 [3950/10697 ( 36.9%)] Loss: 0.027176 L1: 0.015958 Grad: 0.111917 Thermal: 0.000516 LR: 9.05e-06\n",
      "Epoch  16 [3950/10697 ( 36.9%)] Loss: 0.027176 L1: 0.015958 Grad: 0.111917 Thermal: 0.000516 LR: 9.05e-06\n",
      "Epoch  16 [4000/10697 ( 37.4%)] Loss: 0.029082 L1: 0.016522 Grad: 0.125343 Thermal: 0.000502 LR: 9.05e-06\n",
      "Epoch  16 [4000/10697 ( 37.4%)] Loss: 0.029082 L1: 0.016522 Grad: 0.125343 Thermal: 0.000502 LR: 9.05e-06\n",
      "Epoch  16 [4050/10697 ( 37.9%)] Loss: 0.028723 L1: 0.016816 Grad: 0.118817 Thermal: 0.000511 LR: 9.05e-06\n",
      "Epoch  16 [4050/10697 ( 37.9%)] Loss: 0.028723 L1: 0.016816 Grad: 0.118817 Thermal: 0.000511 LR: 9.05e-06\n",
      "Epoch  16 [4100/10697 ( 38.3%)] Loss: 0.025718 L1: 0.015125 Grad: 0.105729 Thermal: 0.000404 LR: 9.05e-06\n",
      "Epoch  16 [4100/10697 ( 38.3%)] Loss: 0.025718 L1: 0.015125 Grad: 0.105729 Thermal: 0.000404 LR: 9.05e-06\n",
      "Epoch  16 [4150/10697 ( 38.8%)] Loss: 0.022283 L1: 0.012976 Grad: 0.092898 Thermal: 0.000351 LR: 9.05e-06\n",
      "Epoch  16 [4150/10697 ( 38.8%)] Loss: 0.022283 L1: 0.012976 Grad: 0.092898 Thermal: 0.000351 LR: 9.05e-06\n",
      "Epoch  16 [4200/10697 ( 39.3%)] Loss: 0.025843 L1: 0.015266 Grad: 0.105553 Thermal: 0.000440 LR: 9.05e-06\n",
      "Epoch  16 [4200/10697 ( 39.3%)] Loss: 0.025843 L1: 0.015266 Grad: 0.105553 Thermal: 0.000440 LR: 9.05e-06\n",
      "Epoch  16 [4250/10697 ( 39.7%)] Loss: 0.024367 L1: 0.014212 Grad: 0.101357 Thermal: 0.000382 LR: 9.05e-06\n",
      "Epoch  16 [4250/10697 ( 39.7%)] Loss: 0.024367 L1: 0.014212 Grad: 0.101357 Thermal: 0.000382 LR: 9.05e-06\n",
      "Epoch  16 [4300/10697 ( 40.2%)] Loss: 0.025523 L1: 0.014965 Grad: 0.105389 Thermal: 0.000387 LR: 9.05e-06\n",
      "Epoch  16 [4300/10697 ( 40.2%)] Loss: 0.025523 L1: 0.014965 Grad: 0.105389 Thermal: 0.000387 LR: 9.05e-06\n",
      "Epoch  16 [4350/10697 ( 40.7%)] Loss: 0.025595 L1: 0.014856 Grad: 0.107182 Thermal: 0.000423 LR: 9.05e-06\n",
      "Epoch  16 [4350/10697 ( 40.7%)] Loss: 0.025595 L1: 0.014856 Grad: 0.107182 Thermal: 0.000423 LR: 9.05e-06\n",
      "Epoch  16 [4400/10697 ( 41.1%)] Loss: 0.025395 L1: 0.014608 Grad: 0.107668 Thermal: 0.000404 LR: 9.05e-06\n",
      "Epoch  16 [4400/10697 ( 41.1%)] Loss: 0.025395 L1: 0.014608 Grad: 0.107668 Thermal: 0.000404 LR: 9.05e-06\n",
      "Epoch  16 [4450/10697 ( 41.6%)] Loss: 0.021520 L1: 0.012536 Grad: 0.089677 Thermal: 0.000337 LR: 9.05e-06\n",
      "Epoch  16 [4450/10697 ( 41.6%)] Loss: 0.021520 L1: 0.012536 Grad: 0.089677 Thermal: 0.000337 LR: 9.05e-06\n",
      "Epoch  16 [4500/10697 ( 42.1%)] Loss: 0.039143 L1: 0.021932 Grad: 0.171684 Thermal: 0.000853 LR: 9.05e-06\n",
      "Epoch  16 [4500/10697 ( 42.1%)] Loss: 0.039143 L1: 0.021932 Grad: 0.171684 Thermal: 0.000853 LR: 9.05e-06\n",
      "Epoch  16 [4550/10697 ( 42.5%)] Loss: 0.022475 L1: 0.012749 Grad: 0.097100 Thermal: 0.000327 LR: 9.05e-06\n",
      "Epoch  16 [4550/10697 ( 42.5%)] Loss: 0.022475 L1: 0.012749 Grad: 0.097100 Thermal: 0.000327 LR: 9.05e-06\n",
      "Epoch  16 [4600/10697 ( 43.0%)] Loss: 0.026355 L1: 0.015656 Grad: 0.106767 Thermal: 0.000455 LR: 9.05e-06\n",
      "Epoch  16 [4600/10697 ( 43.0%)] Loss: 0.026355 L1: 0.015656 Grad: 0.106767 Thermal: 0.000455 LR: 9.05e-06\n",
      "Epoch  16 [4650/10697 ( 43.5%)] Loss: 0.021789 L1: 0.013027 Grad: 0.087469 Thermal: 0.000318 LR: 9.05e-06\n",
      "Epoch  16 [4650/10697 ( 43.5%)] Loss: 0.021789 L1: 0.013027 Grad: 0.087469 Thermal: 0.000318 LR: 9.05e-06\n",
      "Epoch  16 [4700/10697 ( 43.9%)] Loss: 0.022798 L1: 0.013507 Grad: 0.092731 Thermal: 0.000351 LR: 9.05e-06\n",
      "Epoch  16 [4700/10697 ( 43.9%)] Loss: 0.022798 L1: 0.013507 Grad: 0.092731 Thermal: 0.000351 LR: 9.05e-06\n",
      "Epoch  16 [4750/10697 ( 44.4%)] Loss: 0.027608 L1: 0.015949 Grad: 0.116359 Thermal: 0.000463 LR: 9.05e-06\n",
      "Epoch  16 [4750/10697 ( 44.4%)] Loss: 0.027608 L1: 0.015949 Grad: 0.116359 Thermal: 0.000463 LR: 9.05e-06\n",
      "Epoch  16 [4800/10697 ( 44.9%)] Loss: 0.025959 L1: 0.015251 Grad: 0.106853 Thermal: 0.000446 LR: 9.05e-06\n",
      "Epoch  16 [4800/10697 ( 44.9%)] Loss: 0.025959 L1: 0.015251 Grad: 0.106853 Thermal: 0.000446 LR: 9.05e-06\n",
      "Epoch  16 [4850/10697 ( 45.3%)] Loss: 0.022545 L1: 0.013415 Grad: 0.091135 Thermal: 0.000344 LR: 9.05e-06\n",
      "Epoch  16 [4850/10697 ( 45.3%)] Loss: 0.022545 L1: 0.013415 Grad: 0.091135 Thermal: 0.000344 LR: 9.05e-06\n",
      "Epoch  16 [4900/10697 ( 45.8%)] Loss: 0.027630 L1: 0.016572 Grad: 0.110336 Thermal: 0.000490 LR: 9.05e-06\n",
      "Epoch  16 [4900/10697 ( 45.8%)] Loss: 0.027630 L1: 0.016572 Grad: 0.110336 Thermal: 0.000490 LR: 9.05e-06\n",
      "Epoch  16 [4950/10697 ( 46.3%)] Loss: 0.027214 L1: 0.015732 Grad: 0.114546 Thermal: 0.000554 LR: 9.05e-06\n",
      "Epoch  16 [4950/10697 ( 46.3%)] Loss: 0.027214 L1: 0.015732 Grad: 0.114546 Thermal: 0.000554 LR: 9.05e-06\n",
      "Epoch  16 [5000/10697 ( 46.7%)] Loss: 0.023135 L1: 0.013843 Grad: 0.092729 Thermal: 0.000377 LR: 9.05e-06\n",
      "Epoch  16 [5000/10697 ( 46.7%)] Loss: 0.023135 L1: 0.013843 Grad: 0.092729 Thermal: 0.000377 LR: 9.05e-06\n",
      "Epoch  16 [5050/10697 ( 47.2%)] Loss: 0.023928 L1: 0.014096 Grad: 0.098128 Thermal: 0.000389 LR: 9.05e-06\n",
      "Epoch  16 [5050/10697 ( 47.2%)] Loss: 0.023928 L1: 0.014096 Grad: 0.098128 Thermal: 0.000389 LR: 9.05e-06\n",
      "Epoch  16 [5100/10697 ( 47.7%)] Loss: 0.026155 L1: 0.015607 Grad: 0.105257 Thermal: 0.000440 LR: 9.05e-06\n",
      "Epoch  16 [5100/10697 ( 47.7%)] Loss: 0.026155 L1: 0.015607 Grad: 0.105257 Thermal: 0.000440 LR: 9.05e-06\n",
      "Epoch  16 [5150/10697 ( 48.1%)] Loss: 0.022187 L1: 0.013095 Grad: 0.090750 Thermal: 0.000345 LR: 9.05e-06\n",
      "Epoch  16 [5150/10697 ( 48.1%)] Loss: 0.022187 L1: 0.013095 Grad: 0.090750 Thermal: 0.000345 LR: 9.05e-06\n",
      "Epoch  16 [5200/10697 ( 48.6%)] Loss: 0.028160 L1: 0.016358 Grad: 0.117769 Thermal: 0.000515 LR: 9.05e-06\n",
      "Epoch  16 [5200/10697 ( 48.6%)] Loss: 0.028160 L1: 0.016358 Grad: 0.117769 Thermal: 0.000515 LR: 9.05e-06\n",
      "Epoch  16 [5250/10697 ( 49.1%)] Loss: 0.026423 L1: 0.015362 Grad: 0.110393 Thermal: 0.000443 LR: 9.05e-06\n",
      "Epoch  16 [5250/10697 ( 49.1%)] Loss: 0.026423 L1: 0.015362 Grad: 0.110393 Thermal: 0.000443 LR: 9.05e-06\n",
      "Epoch  16 [5300/10697 ( 49.5%)] Loss: 0.029522 L1: 0.017571 Grad: 0.119223 Thermal: 0.000561 LR: 9.05e-06\n",
      "Epoch  16 [5300/10697 ( 49.5%)] Loss: 0.029522 L1: 0.017571 Grad: 0.119223 Thermal: 0.000561 LR: 9.05e-06\n",
      "Epoch  16 [5350/10697 ( 50.0%)] Loss: 0.025947 L1: 0.015155 Grad: 0.107706 Thermal: 0.000425 LR: 9.05e-06\n",
      "Epoch  16 [5350/10697 ( 50.0%)] Loss: 0.025947 L1: 0.015155 Grad: 0.107706 Thermal: 0.000425 LR: 9.05e-06\n",
      "Epoch  16 [5400/10697 ( 50.5%)] Loss: 0.033552 L1: 0.019390 Grad: 0.141282 Thermal: 0.000672 LR: 9.05e-06\n",
      "Epoch  16 [5400/10697 ( 50.5%)] Loss: 0.033552 L1: 0.019390 Grad: 0.141282 Thermal: 0.000672 LR: 9.05e-06\n",
      "Epoch  16 [5450/10697 ( 50.9%)] Loss: 0.027699 L1: 0.015709 Grad: 0.119647 Thermal: 0.000513 LR: 9.05e-06\n",
      "Epoch  16 [5450/10697 ( 50.9%)] Loss: 0.027699 L1: 0.015709 Grad: 0.119647 Thermal: 0.000513 LR: 9.05e-06\n",
      "Epoch  16 [5500/10697 ( 51.4%)] Loss: 0.025758 L1: 0.014620 Grad: 0.111168 Thermal: 0.000436 LR: 9.05e-06\n",
      "Epoch  16 [5500/10697 ( 51.4%)] Loss: 0.025758 L1: 0.014620 Grad: 0.111168 Thermal: 0.000436 LR: 9.05e-06\n",
      "Epoch  16 [5550/10697 ( 51.9%)] Loss: 0.028207 L1: 0.016443 Grad: 0.117385 Thermal: 0.000497 LR: 9.05e-06\n",
      "Epoch  16 [5550/10697 ( 51.9%)] Loss: 0.028207 L1: 0.016443 Grad: 0.117385 Thermal: 0.000497 LR: 9.05e-06\n",
      "Epoch  16 [5600/10697 ( 52.4%)] Loss: 0.028978 L1: 0.016727 Grad: 0.122270 Thermal: 0.000476 LR: 9.05e-06\n",
      "Epoch  16 [5600/10697 ( 52.4%)] Loss: 0.028978 L1: 0.016727 Grad: 0.122270 Thermal: 0.000476 LR: 9.05e-06\n",
      "Epoch  16 [5650/10697 ( 52.8%)] Loss: 0.028590 L1: 0.016668 Grad: 0.118942 Thermal: 0.000547 LR: 9.05e-06\n",
      "Epoch  16 [5650/10697 ( 52.8%)] Loss: 0.028590 L1: 0.016668 Grad: 0.118942 Thermal: 0.000547 LR: 9.05e-06\n",
      "Epoch  16 [5700/10697 ( 53.3%)] Loss: 0.027175 L1: 0.015665 Grad: 0.114851 Thermal: 0.000489 LR: 9.05e-06\n",
      "Epoch  16 [5700/10697 ( 53.3%)] Loss: 0.027175 L1: 0.015665 Grad: 0.114851 Thermal: 0.000489 LR: 9.05e-06\n",
      "Epoch  16 [5750/10697 ( 53.8%)] Loss: 0.025341 L1: 0.014981 Grad: 0.103393 Thermal: 0.000418 LR: 9.05e-06\n",
      "Epoch  16 [5750/10697 ( 53.8%)] Loss: 0.025341 L1: 0.014981 Grad: 0.103393 Thermal: 0.000418 LR: 9.05e-06\n",
      "Epoch  16 [5800/10697 ( 54.2%)] Loss: 0.027751 L1: 0.016177 Grad: 0.115452 Thermal: 0.000582 LR: 9.05e-06\n",
      "Epoch  16 [5800/10697 ( 54.2%)] Loss: 0.027751 L1: 0.016177 Grad: 0.115452 Thermal: 0.000582 LR: 9.05e-06\n",
      "Epoch  16 [5850/10697 ( 54.7%)] Loss: 0.029936 L1: 0.017585 Grad: 0.123227 Thermal: 0.000570 LR: 9.05e-06\n",
      "Epoch  16 [5850/10697 ( 54.7%)] Loss: 0.029936 L1: 0.017585 Grad: 0.123227 Thermal: 0.000570 LR: 9.05e-06\n",
      "Epoch  16 [5900/10697 ( 55.2%)] Loss: 0.021800 L1: 0.012814 Grad: 0.089692 Thermal: 0.000339 LR: 9.05e-06\n",
      "Epoch  16 [5900/10697 ( 55.2%)] Loss: 0.021800 L1: 0.012814 Grad: 0.089692 Thermal: 0.000339 LR: 9.05e-06\n",
      "Epoch  16 [5950/10697 ( 55.6%)] Loss: 0.025951 L1: 0.015540 Grad: 0.103870 Thermal: 0.000467 LR: 9.05e-06\n",
      "Epoch  16 [5950/10697 ( 55.6%)] Loss: 0.025951 L1: 0.015540 Grad: 0.103870 Thermal: 0.000467 LR: 9.05e-06\n",
      "Epoch  16 [6000/10697 ( 56.1%)] Loss: 0.029328 L1: 0.017437 Grad: 0.118649 Thermal: 0.000523 LR: 9.05e-06\n",
      "Epoch  16 [6000/10697 ( 56.1%)] Loss: 0.029328 L1: 0.017437 Grad: 0.118649 Thermal: 0.000523 LR: 9.05e-06\n",
      "Epoch  16 [6050/10697 ( 56.6%)] Loss: 0.026452 L1: 0.015409 Grad: 0.110220 Thermal: 0.000431 LR: 9.05e-06\n",
      "Epoch  16 [6050/10697 ( 56.6%)] Loss: 0.026452 L1: 0.015409 Grad: 0.110220 Thermal: 0.000431 LR: 9.05e-06\n",
      "Epoch  16 [6100/10697 ( 57.0%)] Loss: 0.030997 L1: 0.018080 Grad: 0.128861 Thermal: 0.000614 LR: 9.05e-06\n",
      "Epoch  16 [6100/10697 ( 57.0%)] Loss: 0.030997 L1: 0.018080 Grad: 0.128861 Thermal: 0.000614 LR: 9.05e-06\n",
      "Epoch  16 [6150/10697 ( 57.5%)] Loss: 0.025380 L1: 0.015140 Grad: 0.102181 Thermal: 0.000428 LR: 9.05e-06\n",
      "Epoch  16 [6150/10697 ( 57.5%)] Loss: 0.025380 L1: 0.015140 Grad: 0.102181 Thermal: 0.000428 LR: 9.05e-06\n",
      "Epoch  16 [6200/10697 ( 58.0%)] Loss: 0.031231 L1: 0.018423 Grad: 0.127765 Thermal: 0.000620 LR: 9.05e-06\n",
      "Epoch  16 [6200/10697 ( 58.0%)] Loss: 0.031231 L1: 0.018423 Grad: 0.127765 Thermal: 0.000620 LR: 9.05e-06\n",
      "Epoch  16 [6250/10697 ( 58.4%)] Loss: 0.031270 L1: 0.017541 Grad: 0.137011 Thermal: 0.000550 LR: 9.05e-06\n",
      "Epoch  16 [6250/10697 ( 58.4%)] Loss: 0.031270 L1: 0.017541 Grad: 0.137011 Thermal: 0.000550 LR: 9.05e-06\n",
      "Epoch  16 [6300/10697 ( 58.9%)] Loss: 0.029884 L1: 0.017378 Grad: 0.124806 Thermal: 0.000521 LR: 9.05e-06\n",
      "Epoch  16 [6300/10697 ( 58.9%)] Loss: 0.029884 L1: 0.017378 Grad: 0.124806 Thermal: 0.000521 LR: 9.05e-06\n",
      "Epoch  16 [6350/10697 ( 59.4%)] Loss: 0.027957 L1: 0.016666 Grad: 0.112660 Thermal: 0.000510 LR: 9.05e-06\n",
      "Epoch  16 [6350/10697 ( 59.4%)] Loss: 0.027957 L1: 0.016666 Grad: 0.112660 Thermal: 0.000510 LR: 9.05e-06\n",
      "Epoch  16 [6400/10697 ( 59.8%)] Loss: 0.029152 L1: 0.016773 Grad: 0.123524 Thermal: 0.000527 LR: 9.05e-06\n",
      "Epoch  16 [6400/10697 ( 59.8%)] Loss: 0.029152 L1: 0.016773 Grad: 0.123524 Thermal: 0.000527 LR: 9.05e-06\n",
      "Epoch  16 [6450/10697 ( 60.3%)] Loss: 0.025128 L1: 0.014527 Grad: 0.105802 Thermal: 0.000401 LR: 9.05e-06\n",
      "Epoch  16 [6450/10697 ( 60.3%)] Loss: 0.025128 L1: 0.014527 Grad: 0.105802 Thermal: 0.000401 LR: 9.05e-06\n",
      "Epoch  16 [6500/10697 ( 60.8%)] Loss: 0.029890 L1: 0.017570 Grad: 0.122919 Thermal: 0.000565 LR: 9.05e-06\n",
      "Epoch  16 [6500/10697 ( 60.8%)] Loss: 0.029890 L1: 0.017570 Grad: 0.122919 Thermal: 0.000565 LR: 9.05e-06\n",
      "Epoch  16 [6550/10697 ( 61.2%)] Loss: 0.021331 L1: 0.012721 Grad: 0.085936 Thermal: 0.000342 LR: 9.05e-06\n",
      "Epoch  16 [6550/10697 ( 61.2%)] Loss: 0.021331 L1: 0.012721 Grad: 0.085936 Thermal: 0.000342 LR: 9.05e-06\n",
      "Epoch  16 [6600/10697 ( 61.7%)] Loss: 0.027043 L1: 0.015659 Grad: 0.113624 Thermal: 0.000436 LR: 9.05e-06\n",
      "Epoch  16 [6600/10697 ( 61.7%)] Loss: 0.027043 L1: 0.015659 Grad: 0.113624 Thermal: 0.000436 LR: 9.05e-06\n",
      "Epoch  16 [6650/10697 ( 62.2%)] Loss: 0.029726 L1: 0.017280 Grad: 0.124181 Thermal: 0.000552 LR: 9.05e-06\n",
      "Epoch  16 [6650/10697 ( 62.2%)] Loss: 0.029726 L1: 0.017280 Grad: 0.124181 Thermal: 0.000552 LR: 9.05e-06\n",
      "Epoch  16 [6700/10697 ( 62.6%)] Loss: 0.024682 L1: 0.014640 Grad: 0.100214 Thermal: 0.000413 LR: 9.05e-06\n",
      "Epoch  16 [6700/10697 ( 62.6%)] Loss: 0.024682 L1: 0.014640 Grad: 0.100214 Thermal: 0.000413 LR: 9.05e-06\n",
      "Epoch  16 [6750/10697 ( 63.1%)] Loss: 0.025802 L1: 0.014648 Grad: 0.111325 Thermal: 0.000425 LR: 9.05e-06\n",
      "Epoch  16 [6750/10697 ( 63.1%)] Loss: 0.025802 L1: 0.014648 Grad: 0.111325 Thermal: 0.000425 LR: 9.05e-06\n",
      "Epoch  16 [6800/10697 ( 63.6%)] Loss: 0.031993 L1: 0.018163 Grad: 0.137993 Thermal: 0.000600 LR: 9.05e-06\n",
      "Epoch  16 [6800/10697 ( 63.6%)] Loss: 0.031993 L1: 0.018163 Grad: 0.137993 Thermal: 0.000600 LR: 9.05e-06\n",
      "Epoch  16 [6850/10697 ( 64.0%)] Loss: 0.022396 L1: 0.013191 Grad: 0.091873 Thermal: 0.000360 LR: 9.05e-06\n",
      "Epoch  16 [6850/10697 ( 64.0%)] Loss: 0.022396 L1: 0.013191 Grad: 0.091873 Thermal: 0.000360 LR: 9.05e-06\n",
      "Epoch  16 [6900/10697 ( 64.5%)] Loss: 0.030792 L1: 0.017967 Grad: 0.127983 Thermal: 0.000542 LR: 9.05e-06\n",
      "Epoch  16 [6900/10697 ( 64.5%)] Loss: 0.030792 L1: 0.017967 Grad: 0.127983 Thermal: 0.000542 LR: 9.05e-06\n",
      "Epoch  16 [6950/10697 ( 65.0%)] Loss: 0.023311 L1: 0.013352 Grad: 0.099402 Thermal: 0.000366 LR: 9.05e-06\n",
      "Epoch  16 [6950/10697 ( 65.0%)] Loss: 0.023311 L1: 0.013352 Grad: 0.099402 Thermal: 0.000366 LR: 9.05e-06\n",
      "Epoch  16 [7000/10697 ( 65.4%)] Loss: 0.028373 L1: 0.016611 Grad: 0.117381 Thermal: 0.000486 LR: 9.05e-06\n",
      "Epoch  16 [7000/10697 ( 65.4%)] Loss: 0.028373 L1: 0.016611 Grad: 0.117381 Thermal: 0.000486 LR: 9.05e-06\n",
      "Epoch  16 [7050/10697 ( 65.9%)] Loss: 0.026449 L1: 0.014710 Grad: 0.117189 Thermal: 0.000405 LR: 9.05e-06\n",
      "Epoch  16 [7050/10697 ( 65.9%)] Loss: 0.026449 L1: 0.014710 Grad: 0.117189 Thermal: 0.000405 LR: 9.05e-06\n",
      "Epoch  16 [7100/10697 ( 66.4%)] Loss: 0.024208 L1: 0.013932 Grad: 0.102563 Thermal: 0.000395 LR: 9.05e-06\n",
      "Epoch  16 [7100/10697 ( 66.4%)] Loss: 0.024208 L1: 0.013932 Grad: 0.102563 Thermal: 0.000395 LR: 9.05e-06\n",
      "Epoch  16 [7150/10697 ( 66.8%)] Loss: 0.023694 L1: 0.014010 Grad: 0.096659 Thermal: 0.000360 LR: 9.05e-06\n",
      "Epoch  16 [7150/10697 ( 66.8%)] Loss: 0.023694 L1: 0.014010 Grad: 0.096659 Thermal: 0.000360 LR: 9.05e-06\n",
      "Epoch  16 [7200/10697 ( 67.3%)] Loss: 0.032256 L1: 0.018869 Grad: 0.133546 Thermal: 0.000645 LR: 9.05e-06\n",
      "Epoch  16 [7200/10697 ( 67.3%)] Loss: 0.032256 L1: 0.018869 Grad: 0.133546 Thermal: 0.000645 LR: 9.05e-06\n",
      "Epoch  16 [7250/10697 ( 67.8%)] Loss: 0.028749 L1: 0.016442 Grad: 0.122822 Thermal: 0.000493 LR: 9.05e-06\n",
      "Epoch  16 [7250/10697 ( 67.8%)] Loss: 0.028749 L1: 0.016442 Grad: 0.122822 Thermal: 0.000493 LR: 9.05e-06\n",
      "Epoch  16 [7300/10697 ( 68.2%)] Loss: 0.026127 L1: 0.014868 Grad: 0.112380 Thermal: 0.000422 LR: 9.05e-06\n",
      "Epoch  16 [7300/10697 ( 68.2%)] Loss: 0.026127 L1: 0.014868 Grad: 0.112380 Thermal: 0.000422 LR: 9.05e-06\n",
      "Epoch  16 [7350/10697 ( 68.7%)] Loss: 0.029353 L1: 0.016893 Grad: 0.124329 Thermal: 0.000537 LR: 9.05e-06\n",
      "Epoch  16 [7350/10697 ( 68.7%)] Loss: 0.029353 L1: 0.016893 Grad: 0.124329 Thermal: 0.000537 LR: 9.05e-06\n",
      "Epoch  16 [7400/10697 ( 69.2%)] Loss: 0.027442 L1: 0.015313 Grad: 0.121070 Thermal: 0.000441 LR: 9.05e-06\n",
      "Epoch  16 [7400/10697 ( 69.2%)] Loss: 0.027442 L1: 0.015313 Grad: 0.121070 Thermal: 0.000441 LR: 9.05e-06\n",
      "Epoch  16 [7450/10697 ( 69.6%)] Loss: 0.032528 L1: 0.018933 Grad: 0.135642 Thermal: 0.000626 LR: 9.05e-06\n",
      "Epoch  16 [7450/10697 ( 69.6%)] Loss: 0.032528 L1: 0.018933 Grad: 0.135642 Thermal: 0.000626 LR: 9.05e-06\n",
      "Epoch  16 [7500/10697 ( 70.1%)] Loss: 0.024823 L1: 0.014581 Grad: 0.102216 Thermal: 0.000399 LR: 9.05e-06\n",
      "Epoch  16 [7500/10697 ( 70.1%)] Loss: 0.024823 L1: 0.014581 Grad: 0.102216 Thermal: 0.000399 LR: 9.05e-06\n",
      "Epoch  16 [7550/10697 ( 70.6%)] Loss: 0.021512 L1: 0.012635 Grad: 0.088602 Thermal: 0.000327 LR: 9.05e-06\n",
      "Epoch  16 [7550/10697 ( 70.6%)] Loss: 0.021512 L1: 0.012635 Grad: 0.088602 Thermal: 0.000327 LR: 9.05e-06\n",
      "Epoch  16 [7600/10697 ( 71.0%)] Loss: 0.031176 L1: 0.018435 Grad: 0.127115 Thermal: 0.000596 LR: 9.05e-06\n",
      "Epoch  16 [7600/10697 ( 71.0%)] Loss: 0.031176 L1: 0.018435 Grad: 0.127115 Thermal: 0.000596 LR: 9.05e-06\n",
      "Epoch  16 [7650/10697 ( 71.5%)] Loss: 0.023313 L1: 0.013362 Grad: 0.099324 Thermal: 0.000369 LR: 9.05e-06\n",
      "Epoch  16 [7650/10697 ( 71.5%)] Loss: 0.023313 L1: 0.013362 Grad: 0.099324 Thermal: 0.000369 LR: 9.05e-06\n",
      "Epoch  16 [7700/10697 ( 72.0%)] Loss: 0.026906 L1: 0.016079 Grad: 0.108046 Thermal: 0.000464 LR: 9.05e-06\n",
      "Epoch  16 [7700/10697 ( 72.0%)] Loss: 0.026906 L1: 0.016079 Grad: 0.108046 Thermal: 0.000464 LR: 9.05e-06\n",
      "Epoch  16 [7750/10697 ( 72.5%)] Loss: 0.028018 L1: 0.016642 Grad: 0.113521 Thermal: 0.000486 LR: 9.05e-06\n",
      "Epoch  16 [7750/10697 ( 72.5%)] Loss: 0.028018 L1: 0.016642 Grad: 0.113521 Thermal: 0.000486 LR: 9.05e-06\n",
      "Epoch  16 [7800/10697 ( 72.9%)] Loss: 0.028333 L1: 0.016944 Grad: 0.113661 Thermal: 0.000477 LR: 9.05e-06\n",
      "Epoch  16 [7800/10697 ( 72.9%)] Loss: 0.028333 L1: 0.016944 Grad: 0.113661 Thermal: 0.000477 LR: 9.05e-06\n",
      "Epoch  16 [7850/10697 ( 73.4%)] Loss: 0.024523 L1: 0.014234 Grad: 0.102698 Thermal: 0.000396 LR: 9.05e-06\n",
      "Epoch  16 [7850/10697 ( 73.4%)] Loss: 0.024523 L1: 0.014234 Grad: 0.102698 Thermal: 0.000396 LR: 9.05e-06\n",
      "Epoch  16 [7900/10697 ( 73.9%)] Loss: 0.025021 L1: 0.014414 Grad: 0.105873 Thermal: 0.000391 LR: 9.05e-06\n",
      "Epoch  16 [7900/10697 ( 73.9%)] Loss: 0.025021 L1: 0.014414 Grad: 0.105873 Thermal: 0.000391 LR: 9.05e-06\n",
      "Epoch  16 [7950/10697 ( 74.3%)] Loss: 0.021897 L1: 0.012986 Grad: 0.088938 Thermal: 0.000339 LR: 9.05e-06\n",
      "Epoch  16 [7950/10697 ( 74.3%)] Loss: 0.021897 L1: 0.012986 Grad: 0.088938 Thermal: 0.000339 LR: 9.05e-06\n",
      "Epoch  16 [8000/10697 ( 74.8%)] Loss: 0.029203 L1: 0.016741 Grad: 0.124340 Thermal: 0.000547 LR: 9.05e-06\n",
      "Epoch  16 [8000/10697 ( 74.8%)] Loss: 0.029203 L1: 0.016741 Grad: 0.124340 Thermal: 0.000547 LR: 9.05e-06\n",
      "Epoch  16 [8050/10697 ( 75.3%)] Loss: 0.025059 L1: 0.014703 Grad: 0.103336 Thermal: 0.000454 LR: 9.05e-06\n",
      "Epoch  16 [8050/10697 ( 75.3%)] Loss: 0.025059 L1: 0.014703 Grad: 0.103336 Thermal: 0.000454 LR: 9.05e-06\n",
      "Epoch  16 [8100/10697 ( 75.7%)] Loss: 0.024049 L1: 0.014157 Grad: 0.098721 Thermal: 0.000400 LR: 9.05e-06\n",
      "Epoch  16 [8100/10697 ( 75.7%)] Loss: 0.024049 L1: 0.014157 Grad: 0.098721 Thermal: 0.000400 LR: 9.05e-06\n",
      "Epoch  16 [8150/10697 ( 76.2%)] Loss: 0.023079 L1: 0.013835 Grad: 0.092260 Thermal: 0.000375 LR: 9.05e-06\n",
      "Epoch  16 [8150/10697 ( 76.2%)] Loss: 0.023079 L1: 0.013835 Grad: 0.092260 Thermal: 0.000375 LR: 9.05e-06\n",
      "Epoch  16 [8200/10697 ( 76.7%)] Loss: 0.024752 L1: 0.014634 Grad: 0.100974 Thermal: 0.000415 LR: 9.05e-06\n",
      "Epoch  16 [8200/10697 ( 76.7%)] Loss: 0.024752 L1: 0.014634 Grad: 0.100974 Thermal: 0.000415 LR: 9.05e-06\n",
      "Epoch  16 [8250/10697 ( 77.1%)] Loss: 0.024968 L1: 0.014406 Grad: 0.105380 Thermal: 0.000465 LR: 9.05e-06\n",
      "Epoch  16 [8250/10697 ( 77.1%)] Loss: 0.024968 L1: 0.014406 Grad: 0.105380 Thermal: 0.000465 LR: 9.05e-06\n",
      "Epoch  16 [8300/10697 ( 77.6%)] Loss: 0.019666 L1: 0.011309 Grad: 0.083445 Thermal: 0.000251 LR: 9.05e-06\n",
      "Epoch  16 [8300/10697 ( 77.6%)] Loss: 0.019666 L1: 0.011309 Grad: 0.083445 Thermal: 0.000251 LR: 9.05e-06\n",
      "Epoch  16 [8350/10697 ( 78.1%)] Loss: 0.020504 L1: 0.011760 Grad: 0.087295 Thermal: 0.000281 LR: 9.05e-06\n",
      "Epoch  16 [8350/10697 ( 78.1%)] Loss: 0.020504 L1: 0.011760 Grad: 0.087295 Thermal: 0.000281 LR: 9.05e-06\n",
      "Epoch  16 [8400/10697 ( 78.5%)] Loss: 0.024160 L1: 0.013962 Grad: 0.101803 Thermal: 0.000358 LR: 9.05e-06\n",
      "Epoch  16 [8400/10697 ( 78.5%)] Loss: 0.024160 L1: 0.013962 Grad: 0.101803 Thermal: 0.000358 LR: 9.05e-06\n",
      "Epoch  16 [8450/10697 ( 79.0%)] Loss: 0.025218 L1: 0.014787 Grad: 0.104105 Thermal: 0.000422 LR: 9.05e-06\n",
      "Epoch  16 [8450/10697 ( 79.0%)] Loss: 0.025218 L1: 0.014787 Grad: 0.104105 Thermal: 0.000422 LR: 9.05e-06\n",
      "Epoch  16 [8500/10697 ( 79.5%)] Loss: 0.025003 L1: 0.014428 Grad: 0.105561 Thermal: 0.000387 LR: 9.05e-06\n",
      "Epoch  16 [8500/10697 ( 79.5%)] Loss: 0.025003 L1: 0.014428 Grad: 0.105561 Thermal: 0.000387 LR: 9.05e-06\n",
      "Epoch  16 [8550/10697 ( 79.9%)] Loss: 0.024246 L1: 0.013905 Grad: 0.103222 Thermal: 0.000386 LR: 9.05e-06\n",
      "Epoch  16 [8550/10697 ( 79.9%)] Loss: 0.024246 L1: 0.013905 Grad: 0.103222 Thermal: 0.000386 LR: 9.05e-06\n",
      "Epoch  16 [8600/10697 ( 80.4%)] Loss: 0.028799 L1: 0.016668 Grad: 0.121019 Thermal: 0.000586 LR: 9.05e-06\n",
      "Epoch  16 [8600/10697 ( 80.4%)] Loss: 0.028799 L1: 0.016668 Grad: 0.121019 Thermal: 0.000586 LR: 9.05e-06\n",
      "Epoch  16 [8650/10697 ( 80.9%)] Loss: 0.026286 L1: 0.015308 Grad: 0.109557 Thermal: 0.000453 LR: 9.05e-06\n",
      "Epoch  16 [8650/10697 ( 80.9%)] Loss: 0.026286 L1: 0.015308 Grad: 0.109557 Thermal: 0.000453 LR: 9.05e-06\n",
      "Epoch  16 [8700/10697 ( 81.3%)] Loss: 0.020615 L1: 0.011986 Grad: 0.086139 Thermal: 0.000311 LR: 9.05e-06\n",
      "Epoch  16 [8700/10697 ( 81.3%)] Loss: 0.020615 L1: 0.011986 Grad: 0.086139 Thermal: 0.000311 LR: 9.05e-06\n",
      "Epoch  16 [8750/10697 ( 81.8%)] Loss: 0.026518 L1: 0.016027 Grad: 0.104686 Thermal: 0.000455 LR: 9.05e-06\n",
      "Epoch  16 [8750/10697 ( 81.8%)] Loss: 0.026518 L1: 0.016027 Grad: 0.104686 Thermal: 0.000455 LR: 9.05e-06\n",
      "Epoch  16 [8800/10697 ( 82.3%)] Loss: 0.025715 L1: 0.014783 Grad: 0.109108 Thermal: 0.000412 LR: 9.05e-06\n",
      "Epoch  16 [8800/10697 ( 82.3%)] Loss: 0.025715 L1: 0.014783 Grad: 0.109108 Thermal: 0.000412 LR: 9.05e-06\n",
      "Epoch  16 [8850/10697 ( 82.7%)] Loss: 0.026685 L1: 0.015836 Grad: 0.108259 Thermal: 0.000458 LR: 9.05e-06\n",
      "Epoch  16 [8850/10697 ( 82.7%)] Loss: 0.026685 L1: 0.015836 Grad: 0.108259 Thermal: 0.000458 LR: 9.05e-06\n",
      "Epoch  16 [8900/10697 ( 83.2%)] Loss: 0.023800 L1: 0.013869 Grad: 0.099132 Thermal: 0.000371 LR: 9.05e-06\n",
      "Epoch  16 [8900/10697 ( 83.2%)] Loss: 0.023800 L1: 0.013869 Grad: 0.099132 Thermal: 0.000371 LR: 9.05e-06\n",
      "Epoch  16 [8950/10697 ( 83.7%)] Loss: 0.025339 L1: 0.014576 Grad: 0.107424 Thermal: 0.000407 LR: 9.05e-06\n",
      "Epoch  16 [8950/10697 ( 83.7%)] Loss: 0.025339 L1: 0.014576 Grad: 0.107424 Thermal: 0.000407 LR: 9.05e-06\n",
      "Epoch  16 [9000/10697 ( 84.1%)] Loss: 0.029535 L1: 0.017569 Grad: 0.119384 Thermal: 0.000555 LR: 9.05e-06\n",
      "Epoch  16 [9000/10697 ( 84.1%)] Loss: 0.029535 L1: 0.017569 Grad: 0.119384 Thermal: 0.000555 LR: 9.05e-06\n",
      "Epoch  16 [9050/10697 ( 84.6%)] Loss: 0.026323 L1: 0.015324 Grad: 0.109760 Thermal: 0.000450 LR: 9.05e-06\n",
      "Epoch  16 [9050/10697 ( 84.6%)] Loss: 0.026323 L1: 0.015324 Grad: 0.109760 Thermal: 0.000450 LR: 9.05e-06\n",
      "Epoch  16 [9100/10697 ( 85.1%)] Loss: 0.026277 L1: 0.015241 Grad: 0.110143 Thermal: 0.000436 LR: 9.05e-06\n",
      "Epoch  16 [9100/10697 ( 85.1%)] Loss: 0.026277 L1: 0.015241 Grad: 0.110143 Thermal: 0.000436 LR: 9.05e-06\n",
      "Epoch  16 [9150/10697 ( 85.5%)] Loss: 0.025426 L1: 0.014808 Grad: 0.105952 Thermal: 0.000443 LR: 9.05e-06\n",
      "Epoch  16 [9150/10697 ( 85.5%)] Loss: 0.025426 L1: 0.014808 Grad: 0.105952 Thermal: 0.000443 LR: 9.05e-06\n",
      "Epoch  16 [9200/10697 ( 86.0%)] Loss: 0.021080 L1: 0.012222 Grad: 0.088424 Thermal: 0.000307 LR: 9.05e-06\n",
      "Epoch  16 [9200/10697 ( 86.0%)] Loss: 0.021080 L1: 0.012222 Grad: 0.088424 Thermal: 0.000307 LR: 9.05e-06\n",
      "Epoch  16 [9250/10697 ( 86.5%)] Loss: 0.025859 L1: 0.015630 Grad: 0.102072 Thermal: 0.000445 LR: 9.05e-06\n",
      "Epoch  16 [9250/10697 ( 86.5%)] Loss: 0.025859 L1: 0.015630 Grad: 0.102072 Thermal: 0.000445 LR: 9.05e-06\n",
      "Epoch  16 [9300/10697 ( 86.9%)] Loss: 0.031082 L1: 0.018187 Grad: 0.128636 Thermal: 0.000625 LR: 9.05e-06\n",
      "Epoch  16 [9300/10697 ( 86.9%)] Loss: 0.031082 L1: 0.018187 Grad: 0.128636 Thermal: 0.000625 LR: 9.05e-06\n",
      "Epoch  16 [9350/10697 ( 87.4%)] Loss: 0.034957 L1: 0.020082 Grad: 0.148352 Thermal: 0.000794 LR: 9.05e-06\n",
      "Epoch  16 [9350/10697 ( 87.4%)] Loss: 0.034957 L1: 0.020082 Grad: 0.148352 Thermal: 0.000794 LR: 9.05e-06\n",
      "Epoch  16 [9400/10697 ( 87.9%)] Loss: 0.031769 L1: 0.017833 Grad: 0.139069 Thermal: 0.000585 LR: 9.05e-06\n",
      "Epoch  16 [9400/10697 ( 87.9%)] Loss: 0.031769 L1: 0.017833 Grad: 0.139069 Thermal: 0.000585 LR: 9.05e-06\n",
      "Epoch  16 [9450/10697 ( 88.3%)] Loss: 0.028365 L1: 0.016886 Grad: 0.114520 Thermal: 0.000522 LR: 9.05e-06\n",
      "Epoch  16 [9450/10697 ( 88.3%)] Loss: 0.028365 L1: 0.016886 Grad: 0.114520 Thermal: 0.000522 LR: 9.05e-06\n",
      "Epoch  16 [9500/10697 ( 88.8%)] Loss: 0.026282 L1: 0.015287 Grad: 0.109738 Thermal: 0.000421 LR: 9.05e-06\n",
      "Epoch  16 [9500/10697 ( 88.8%)] Loss: 0.026282 L1: 0.015287 Grad: 0.109738 Thermal: 0.000421 LR: 9.05e-06\n",
      "Epoch  16 [9550/10697 ( 89.3%)] Loss: 0.029091 L1: 0.017146 Grad: 0.119190 Thermal: 0.000531 LR: 9.05e-06\n",
      "Epoch  16 [9550/10697 ( 89.3%)] Loss: 0.029091 L1: 0.017146 Grad: 0.119190 Thermal: 0.000531 LR: 9.05e-06\n",
      "Epoch  16 [9600/10697 ( 89.7%)] Loss: 0.026889 L1: 0.015911 Grad: 0.109533 Thermal: 0.000481 LR: 9.05e-06\n",
      "Epoch  16 [9600/10697 ( 89.7%)] Loss: 0.026889 L1: 0.015911 Grad: 0.109533 Thermal: 0.000481 LR: 9.05e-06\n",
      "Epoch  16 [9650/10697 ( 90.2%)] Loss: 0.020236 L1: 0.011757 Grad: 0.084625 Thermal: 0.000324 LR: 9.05e-06\n",
      "Epoch  16 [9650/10697 ( 90.2%)] Loss: 0.020236 L1: 0.011757 Grad: 0.084625 Thermal: 0.000324 LR: 9.05e-06\n",
      "Epoch  16 [9700/10697 ( 90.7%)] Loss: 0.023882 L1: 0.013885 Grad: 0.099799 Thermal: 0.000335 LR: 9.05e-06\n",
      "Epoch  16 [9700/10697 ( 90.7%)] Loss: 0.023882 L1: 0.013885 Grad: 0.099799 Thermal: 0.000335 LR: 9.05e-06\n",
      "Epoch  16 [9750/10697 ( 91.1%)] Loss: 0.033253 L1: 0.019362 Grad: 0.138562 Thermal: 0.000684 LR: 9.05e-06\n",
      "Epoch  16 [9750/10697 ( 91.1%)] Loss: 0.033253 L1: 0.019362 Grad: 0.138562 Thermal: 0.000684 LR: 9.05e-06\n",
      "Epoch  16 [9800/10697 ( 91.6%)] Loss: 0.021171 L1: 0.011870 Grad: 0.092849 Thermal: 0.000321 LR: 9.05e-06\n",
      "Epoch  16 [9800/10697 ( 91.6%)] Loss: 0.021171 L1: 0.011870 Grad: 0.092849 Thermal: 0.000321 LR: 9.05e-06\n",
      "Epoch  16 [9850/10697 ( 92.1%)] Loss: 0.028791 L1: 0.016963 Grad: 0.118029 Thermal: 0.000490 LR: 9.05e-06\n",
      "Epoch  16 [9850/10697 ( 92.1%)] Loss: 0.028791 L1: 0.016963 Grad: 0.118029 Thermal: 0.000490 LR: 9.05e-06\n",
      "Epoch  16 [9900/10697 ( 92.5%)] Loss: 0.026465 L1: 0.015516 Grad: 0.109274 Thermal: 0.000425 LR: 9.05e-06\n",
      "Epoch  16 [9900/10697 ( 92.5%)] Loss: 0.026465 L1: 0.015516 Grad: 0.109274 Thermal: 0.000425 LR: 9.05e-06\n",
      "Epoch  16 [9950/10697 ( 93.0%)] Loss: 0.026587 L1: 0.015373 Grad: 0.111932 Thermal: 0.000429 LR: 9.05e-06\n",
      "Epoch  16 [9950/10697 ( 93.0%)] Loss: 0.026587 L1: 0.015373 Grad: 0.111932 Thermal: 0.000429 LR: 9.05e-06\n",
      "Epoch  16 [10000/10697 ( 93.5%)] Loss: 0.026717 L1: 0.015255 Grad: 0.114393 Thermal: 0.000446 LR: 9.05e-06\n",
      "Epoch  16 [10000/10697 ( 93.5%)] Loss: 0.026717 L1: 0.015255 Grad: 0.114393 Thermal: 0.000446 LR: 9.05e-06\n",
      "Epoch  16 [10050/10697 ( 94.0%)] Loss: 0.022275 L1: 0.012875 Grad: 0.093805 Thermal: 0.000395 LR: 9.05e-06\n",
      "Epoch  16 [10050/10697 ( 94.0%)] Loss: 0.022275 L1: 0.012875 Grad: 0.093805 Thermal: 0.000395 LR: 9.05e-06\n",
      "Epoch  16 [10100/10697 ( 94.4%)] Loss: 0.024899 L1: 0.014544 Grad: 0.103338 Thermal: 0.000408 LR: 9.05e-06\n",
      "Epoch  16 [10100/10697 ( 94.4%)] Loss: 0.024899 L1: 0.014544 Grad: 0.103338 Thermal: 0.000408 LR: 9.05e-06\n",
      "Epoch  16 [10150/10697 ( 94.9%)] Loss: 0.025667 L1: 0.014500 Grad: 0.111456 Thermal: 0.000431 LR: 9.05e-06\n",
      "Epoch  16 [10150/10697 ( 94.9%)] Loss: 0.025667 L1: 0.014500 Grad: 0.111456 Thermal: 0.000431 LR: 9.05e-06\n",
      "Epoch  16 [10200/10697 ( 95.4%)] Loss: 0.028237 L1: 0.016144 Grad: 0.120699 Thermal: 0.000472 LR: 9.05e-06\n",
      "Epoch  16 [10200/10697 ( 95.4%)] Loss: 0.028237 L1: 0.016144 Grad: 0.120699 Thermal: 0.000472 LR: 9.05e-06\n",
      "Epoch  16 [10250/10697 ( 95.8%)] Loss: 0.020644 L1: 0.012195 Grad: 0.084339 Thermal: 0.000303 LR: 9.05e-06\n",
      "Epoch  16 [10250/10697 ( 95.8%)] Loss: 0.020644 L1: 0.012195 Grad: 0.084339 Thermal: 0.000303 LR: 9.05e-06\n",
      "Epoch  16 [10300/10697 ( 96.3%)] Loss: 0.027224 L1: 0.016096 Grad: 0.111027 Thermal: 0.000509 LR: 9.05e-06\n",
      "Epoch  16 [10300/10697 ( 96.3%)] Loss: 0.027224 L1: 0.016096 Grad: 0.111027 Thermal: 0.000509 LR: 9.05e-06\n",
      "Epoch  16 [10350/10697 ( 96.8%)] Loss: 0.028516 L1: 0.016528 Grad: 0.119628 Thermal: 0.000511 LR: 9.05e-06\n",
      "Epoch  16 [10350/10697 ( 96.8%)] Loss: 0.028516 L1: 0.016528 Grad: 0.119628 Thermal: 0.000511 LR: 9.05e-06\n",
      "Epoch  16 [10400/10697 ( 97.2%)] Loss: 0.027311 L1: 0.016034 Grad: 0.112527 Thermal: 0.000476 LR: 9.05e-06\n",
      "Epoch  16 [10400/10697 ( 97.2%)] Loss: 0.027311 L1: 0.016034 Grad: 0.112527 Thermal: 0.000476 LR: 9.05e-06\n",
      "Epoch  16 [10450/10697 ( 97.7%)] Loss: 0.025940 L1: 0.014330 Grad: 0.115893 Thermal: 0.000411 LR: 9.05e-06\n",
      "Epoch  16 [10450/10697 ( 97.7%)] Loss: 0.025940 L1: 0.014330 Grad: 0.115893 Thermal: 0.000411 LR: 9.05e-06\n",
      "Epoch  16 [10500/10697 ( 98.2%)] Loss: 0.028325 L1: 0.016266 Grad: 0.120359 Thermal: 0.000474 LR: 9.05e-06\n",
      "Epoch  16 [10500/10697 ( 98.2%)] Loss: 0.028325 L1: 0.016266 Grad: 0.120359 Thermal: 0.000474 LR: 9.05e-06\n",
      "Epoch  16 [10550/10697 ( 98.6%)] Loss: 0.023187 L1: 0.013336 Grad: 0.098331 Thermal: 0.000368 LR: 9.05e-06\n",
      "Epoch  16 [10550/10697 ( 98.6%)] Loss: 0.023187 L1: 0.013336 Grad: 0.098331 Thermal: 0.000368 LR: 9.05e-06\n",
      "Epoch  16 [10600/10697 ( 99.1%)] Loss: 0.027841 L1: 0.016368 Grad: 0.114482 Thermal: 0.000500 LR: 9.05e-06\n",
      "Epoch  16 [10600/10697 ( 99.1%)] Loss: 0.027841 L1: 0.016368 Grad: 0.114482 Thermal: 0.000500 LR: 9.05e-06\n",
      "Epoch  16 [10650/10697 ( 99.6%)] Loss: 0.024218 L1: 0.013967 Grad: 0.102320 Thermal: 0.000386 LR: 9.05e-06\n",
      "Epoch  16 [10650/10697 ( 99.6%)] Loss: 0.024218 L1: 0.013967 Grad: 0.102320 Thermal: 0.000386 LR: 9.05e-06\n",
      "Epoch  16 Summary: Loss=0.026686 (L1:0.0155, Grad:0.1112, Thermal:0.0005) Val_PSNR=0.00dB Best=33.84dB Time=61.1min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  16 Summary: Loss=0.026686 (L1:0.0155, Grad:0.1112, Thermal:0.0005) Val_PSNR=0.00dB Best=33.84dB Time=61.1min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  17 [   0/10697 (  0.0%)] Loss: 0.027909 L1: 0.016438 Grad: 0.114459 Thermal: 0.000499 LR: 8.94e-06\n",
      "Epoch  17 [   0/10697 (  0.0%)] Loss: 0.027909 L1: 0.016438 Grad: 0.114459 Thermal: 0.000499 LR: 8.94e-06\n",
      "Epoch  17 [  50/10697 (  0.5%)] Loss: 0.025700 L1: 0.015236 Grad: 0.104432 Thermal: 0.000420 LR: 8.94e-06\n",
      "Epoch  17 [  50/10697 (  0.5%)] Loss: 0.025700 L1: 0.015236 Grad: 0.104432 Thermal: 0.000420 LR: 8.94e-06\n",
      "Epoch  17 [ 100/10697 (  0.9%)] Loss: 0.029074 L1: 0.016796 Grad: 0.122490 Thermal: 0.000579 LR: 8.94e-06\n",
      "Epoch  17 [ 100/10697 (  0.9%)] Loss: 0.029074 L1: 0.016796 Grad: 0.122490 Thermal: 0.000579 LR: 8.94e-06\n",
      "Epoch  17 [ 150/10697 (  1.4%)] Loss: 0.019991 L1: 0.011621 Grad: 0.083545 Thermal: 0.000299 LR: 8.94e-06\n",
      "Epoch  17 [ 150/10697 (  1.4%)] Loss: 0.019991 L1: 0.011621 Grad: 0.083545 Thermal: 0.000299 LR: 8.94e-06\n",
      "Epoch  17 [ 200/10697 (  1.9%)] Loss: 0.028236 L1: 0.016127 Grad: 0.120833 Thermal: 0.000516 LR: 8.94e-06\n",
      "Epoch  17 [ 200/10697 (  1.9%)] Loss: 0.028236 L1: 0.016127 Grad: 0.120833 Thermal: 0.000516 LR: 8.94e-06\n",
      "Epoch  17 [ 250/10697 (  2.3%)] Loss: 0.026096 L1: 0.015035 Grad: 0.110396 Thermal: 0.000433 LR: 8.94e-06\n",
      "Epoch  17 [ 250/10697 (  2.3%)] Loss: 0.026096 L1: 0.015035 Grad: 0.110396 Thermal: 0.000433 LR: 8.94e-06\n",
      "Epoch  17 [ 300/10697 (  2.8%)] Loss: 0.027177 L1: 0.016161 Grad: 0.109926 Thermal: 0.000466 LR: 8.94e-06\n",
      "Epoch  17 [ 300/10697 (  2.8%)] Loss: 0.027177 L1: 0.016161 Grad: 0.109926 Thermal: 0.000466 LR: 8.94e-06\n",
      "Epoch  17 [ 350/10697 (  3.3%)] Loss: 0.021255 L1: 0.012278 Grad: 0.089611 Thermal: 0.000328 LR: 8.94e-06\n",
      "Epoch  17 [ 350/10697 (  3.3%)] Loss: 0.021255 L1: 0.012278 Grad: 0.089611 Thermal: 0.000328 LR: 8.94e-06\n",
      "Epoch  17 [ 400/10697 (  3.7%)] Loss: 0.023839 L1: 0.014075 Grad: 0.097441 Thermal: 0.000401 LR: 8.94e-06\n",
      "Epoch  17 [ 400/10697 (  3.7%)] Loss: 0.023839 L1: 0.014075 Grad: 0.097441 Thermal: 0.000401 LR: 8.94e-06\n",
      "Epoch  17 [ 450/10697 (  4.2%)] Loss: 0.028626 L1: 0.016366 Grad: 0.122296 Thermal: 0.000620 LR: 8.94e-06\n",
      "Epoch  17 [ 450/10697 (  4.2%)] Loss: 0.028626 L1: 0.016366 Grad: 0.122296 Thermal: 0.000620 LR: 8.94e-06\n",
      "Epoch  17 [ 500/10697 (  4.7%)] Loss: 0.030193 L1: 0.017590 Grad: 0.125695 Thermal: 0.000676 LR: 8.94e-06\n",
      "Epoch  17 [ 500/10697 (  4.7%)] Loss: 0.030193 L1: 0.017590 Grad: 0.125695 Thermal: 0.000676 LR: 8.94e-06\n",
      "Epoch  17 [ 550/10697 (  5.1%)] Loss: 0.027815 L1: 0.016458 Grad: 0.113331 Thermal: 0.000474 LR: 8.94e-06\n",
      "Epoch  17 [ 550/10697 (  5.1%)] Loss: 0.027815 L1: 0.016458 Grad: 0.113331 Thermal: 0.000474 LR: 8.94e-06\n",
      "Epoch  17 [ 600/10697 (  5.6%)] Loss: 0.023254 L1: 0.013399 Grad: 0.098384 Thermal: 0.000342 LR: 8.94e-06\n",
      "Epoch  17 [ 600/10697 (  5.6%)] Loss: 0.023254 L1: 0.013399 Grad: 0.098384 Thermal: 0.000342 LR: 8.94e-06\n",
      "Epoch  17 [ 650/10697 (  6.1%)] Loss: 0.020384 L1: 0.011805 Grad: 0.085638 Thermal: 0.000309 LR: 8.94e-06\n",
      "Epoch  17 [ 650/10697 (  6.1%)] Loss: 0.020384 L1: 0.011805 Grad: 0.085638 Thermal: 0.000309 LR: 8.94e-06\n",
      "Epoch  17 [ 700/10697 (  6.5%)] Loss: 0.024508 L1: 0.014121 Grad: 0.103673 Thermal: 0.000403 LR: 8.94e-06\n",
      "Epoch  17 [ 700/10697 (  6.5%)] Loss: 0.024508 L1: 0.014121 Grad: 0.103673 Thermal: 0.000403 LR: 8.94e-06\n",
      "Epoch  17 [ 750/10697 (  7.0%)] Loss: 0.027282 L1: 0.015850 Grad: 0.114093 Thermal: 0.000461 LR: 8.94e-06\n",
      "Epoch  17 [ 750/10697 (  7.0%)] Loss: 0.027282 L1: 0.015850 Grad: 0.114093 Thermal: 0.000461 LR: 8.94e-06\n",
      "Epoch  17 [ 800/10697 (  7.5%)] Loss: 0.029958 L1: 0.017450 Grad: 0.124814 Thermal: 0.000535 LR: 8.94e-06\n",
      "Epoch  17 [ 800/10697 (  7.5%)] Loss: 0.029958 L1: 0.017450 Grad: 0.124814 Thermal: 0.000535 LR: 8.94e-06\n",
      "Epoch  17 [ 850/10697 (  7.9%)] Loss: 0.023156 L1: 0.013140 Grad: 0.099962 Thermal: 0.000381 LR: 8.94e-06\n",
      "Epoch  17 [ 850/10697 (  7.9%)] Loss: 0.023156 L1: 0.013140 Grad: 0.099962 Thermal: 0.000381 LR: 8.94e-06\n",
      "Epoch  17 [ 900/10697 (  8.4%)] Loss: 0.026401 L1: 0.015357 Grad: 0.110229 Thermal: 0.000432 LR: 8.94e-06\n",
      "Epoch  17 [ 900/10697 (  8.4%)] Loss: 0.026401 L1: 0.015357 Grad: 0.110229 Thermal: 0.000432 LR: 8.94e-06\n",
      "Epoch  17 [ 950/10697 (  8.9%)] Loss: 0.028507 L1: 0.016613 Grad: 0.118707 Thermal: 0.000479 LR: 8.94e-06\n",
      "Epoch  17 [ 950/10697 (  8.9%)] Loss: 0.028507 L1: 0.016613 Grad: 0.118707 Thermal: 0.000479 LR: 8.94e-06\n",
      "Epoch  17 [1000/10697 (  9.3%)] Loss: 0.026849 L1: 0.015737 Grad: 0.110900 Thermal: 0.000449 LR: 8.94e-06\n",
      "Epoch  17 [1000/10697 (  9.3%)] Loss: 0.026849 L1: 0.015737 Grad: 0.110900 Thermal: 0.000449 LR: 8.94e-06\n",
      "Epoch  17 [1050/10697 (  9.8%)] Loss: 0.026236 L1: 0.015421 Grad: 0.107937 Thermal: 0.000435 LR: 8.94e-06\n",
      "Epoch  17 [1050/10697 (  9.8%)] Loss: 0.026236 L1: 0.015421 Grad: 0.107937 Thermal: 0.000435 LR: 8.94e-06\n",
      "Epoch  17 [1100/10697 ( 10.3%)] Loss: 0.027536 L1: 0.015997 Grad: 0.115161 Thermal: 0.000440 LR: 8.94e-06\n",
      "Epoch  17 [1100/10697 ( 10.3%)] Loss: 0.027536 L1: 0.015997 Grad: 0.115161 Thermal: 0.000440 LR: 8.94e-06\n",
      "Epoch  17 [1150/10697 ( 10.8%)] Loss: 0.029066 L1: 0.017272 Grad: 0.117673 Thermal: 0.000539 LR: 8.94e-06\n",
      "Epoch  17 [1150/10697 ( 10.8%)] Loss: 0.029066 L1: 0.017272 Grad: 0.117673 Thermal: 0.000539 LR: 8.94e-06\n",
      "Epoch  17 [1200/10697 ( 11.2%)] Loss: 0.029369 L1: 0.017337 Grad: 0.120043 Thermal: 0.000545 LR: 8.94e-06\n",
      "Epoch  17 [1200/10697 ( 11.2%)] Loss: 0.029369 L1: 0.017337 Grad: 0.120043 Thermal: 0.000545 LR: 8.94e-06\n",
      "Epoch  17 [1250/10697 ( 11.7%)] Loss: 0.025646 L1: 0.015171 Grad: 0.104528 Thermal: 0.000444 LR: 8.94e-06\n",
      "Epoch  17 [1250/10697 ( 11.7%)] Loss: 0.025646 L1: 0.015171 Grad: 0.104528 Thermal: 0.000444 LR: 8.94e-06\n",
      "Epoch  17 [1300/10697 ( 12.2%)] Loss: 0.027412 L1: 0.016251 Grad: 0.111374 Thermal: 0.000465 LR: 8.94e-06\n",
      "Epoch  17 [1300/10697 ( 12.2%)] Loss: 0.027412 L1: 0.016251 Grad: 0.111374 Thermal: 0.000465 LR: 8.94e-06\n",
      "Epoch  17 [1350/10697 ( 12.6%)] Loss: 0.020470 L1: 0.012167 Grad: 0.082873 Thermal: 0.000310 LR: 8.94e-06\n",
      "Epoch  17 [1350/10697 ( 12.6%)] Loss: 0.020470 L1: 0.012167 Grad: 0.082873 Thermal: 0.000310 LR: 8.94e-06\n",
      "Epoch  17 [1400/10697 ( 13.1%)] Loss: 0.024554 L1: 0.014204 Grad: 0.103309 Thermal: 0.000391 LR: 8.94e-06\n",
      "Epoch  17 [1400/10697 ( 13.1%)] Loss: 0.024554 L1: 0.014204 Grad: 0.103309 Thermal: 0.000391 LR: 8.94e-06\n",
      "Epoch  17 [1450/10697 ( 13.6%)] Loss: 0.020622 L1: 0.011891 Grad: 0.087152 Thermal: 0.000300 LR: 8.94e-06\n",
      "Epoch  17 [1450/10697 ( 13.6%)] Loss: 0.020622 L1: 0.011891 Grad: 0.087152 Thermal: 0.000300 LR: 8.94e-06\n",
      "Epoch  17 [1500/10697 ( 14.0%)] Loss: 0.030804 L1: 0.017793 Grad: 0.129808 Thermal: 0.000616 LR: 8.94e-06\n",
      "Epoch  17 [1500/10697 ( 14.0%)] Loss: 0.030804 L1: 0.017793 Grad: 0.129808 Thermal: 0.000616 LR: 8.94e-06\n",
      "Epoch  17 [1550/10697 ( 14.5%)] Loss: 0.026810 L1: 0.015286 Grad: 0.114995 Thermal: 0.000500 LR: 8.94e-06\n",
      "Epoch  17 [1550/10697 ( 14.5%)] Loss: 0.026810 L1: 0.015286 Grad: 0.114995 Thermal: 0.000500 LR: 8.94e-06\n",
      "Epoch  17 [1600/10697 ( 15.0%)] Loss: 0.025851 L1: 0.015033 Grad: 0.107934 Thermal: 0.000485 LR: 8.94e-06\n",
      "Epoch  17 [1600/10697 ( 15.0%)] Loss: 0.025851 L1: 0.015033 Grad: 0.107934 Thermal: 0.000485 LR: 8.94e-06\n",
      "Epoch  17 [1650/10697 ( 15.4%)] Loss: 0.027994 L1: 0.016446 Grad: 0.115245 Thermal: 0.000479 LR: 8.94e-06\n",
      "Epoch  17 [1650/10697 ( 15.4%)] Loss: 0.027994 L1: 0.016446 Grad: 0.115245 Thermal: 0.000479 LR: 8.94e-06\n",
      "Epoch  17 [1700/10697 ( 15.9%)] Loss: 0.025802 L1: 0.015185 Grad: 0.105946 Thermal: 0.000434 LR: 8.94e-06\n",
      "Epoch  17 [1700/10697 ( 15.9%)] Loss: 0.025802 L1: 0.015185 Grad: 0.105946 Thermal: 0.000434 LR: 8.94e-06\n",
      "Epoch  17 [1750/10697 ( 16.4%)] Loss: 0.024217 L1: 0.014042 Grad: 0.101551 Thermal: 0.000416 LR: 8.94e-06\n",
      "Epoch  17 [1750/10697 ( 16.4%)] Loss: 0.024217 L1: 0.014042 Grad: 0.101551 Thermal: 0.000416 LR: 8.94e-06\n",
      "Epoch  17 [1800/10697 ( 16.8%)] Loss: 0.020356 L1: 0.011917 Grad: 0.084241 Thermal: 0.000300 LR: 8.94e-06\n",
      "Epoch  17 [1800/10697 ( 16.8%)] Loss: 0.020356 L1: 0.011917 Grad: 0.084241 Thermal: 0.000300 LR: 8.94e-06\n",
      "Epoch  17 [1850/10697 ( 17.3%)] Loss: 0.028298 L1: 0.016402 Grad: 0.118710 Thermal: 0.000512 LR: 8.94e-06\n",
      "Epoch  17 [1850/10697 ( 17.3%)] Loss: 0.028298 L1: 0.016402 Grad: 0.118710 Thermal: 0.000512 LR: 8.94e-06\n",
      "Epoch  17 [1900/10697 ( 17.8%)] Loss: 0.025755 L1: 0.014715 Grad: 0.110210 Thermal: 0.000390 LR: 8.94e-06\n",
      "Epoch  17 [1900/10697 ( 17.8%)] Loss: 0.025755 L1: 0.014715 Grad: 0.110210 Thermal: 0.000390 LR: 8.94e-06\n",
      "Epoch  17 [1950/10697 ( 18.2%)] Loss: 0.029479 L1: 0.017084 Grad: 0.123685 Thermal: 0.000525 LR: 8.94e-06\n",
      "Epoch  17 [1950/10697 ( 18.2%)] Loss: 0.029479 L1: 0.017084 Grad: 0.123685 Thermal: 0.000525 LR: 8.94e-06\n",
      "Epoch  17 [2000/10697 ( 18.7%)] Loss: 0.034169 L1: 0.019645 Grad: 0.144874 Thermal: 0.000730 LR: 8.94e-06\n",
      "Epoch  17 [2000/10697 ( 18.7%)] Loss: 0.034169 L1: 0.019645 Grad: 0.144874 Thermal: 0.000730 LR: 8.94e-06\n",
      "Epoch  17 [2050/10697 ( 19.2%)] Loss: 0.024185 L1: 0.014293 Grad: 0.098729 Thermal: 0.000384 LR: 8.94e-06\n",
      "Epoch  17 [2050/10697 ( 19.2%)] Loss: 0.024185 L1: 0.014293 Grad: 0.098729 Thermal: 0.000384 LR: 8.94e-06\n",
      "Epoch  17 [2100/10697 ( 19.6%)] Loss: 0.026054 L1: 0.015555 Grad: 0.104785 Thermal: 0.000429 LR: 8.94e-06\n",
      "Epoch  17 [2100/10697 ( 19.6%)] Loss: 0.026054 L1: 0.015555 Grad: 0.104785 Thermal: 0.000429 LR: 8.94e-06\n",
      "Epoch  17 [2150/10697 ( 20.1%)] Loss: 0.021831 L1: 0.012190 Grad: 0.096266 Thermal: 0.000291 LR: 8.94e-06\n",
      "Epoch  17 [2150/10697 ( 20.1%)] Loss: 0.021831 L1: 0.012190 Grad: 0.096266 Thermal: 0.000291 LR: 8.94e-06\n",
      "Epoch  17 [2200/10697 ( 20.6%)] Loss: 0.027042 L1: 0.015672 Grad: 0.113480 Thermal: 0.000440 LR: 8.94e-06\n",
      "Epoch  17 [2200/10697 ( 20.6%)] Loss: 0.027042 L1: 0.015672 Grad: 0.113480 Thermal: 0.000440 LR: 8.94e-06\n",
      "Epoch  17 [2250/10697 ( 21.0%)] Loss: 0.028563 L1: 0.016432 Grad: 0.120987 Thermal: 0.000653 LR: 8.94e-06\n",
      "Epoch  17 [2250/10697 ( 21.0%)] Loss: 0.028563 L1: 0.016432 Grad: 0.120987 Thermal: 0.000653 LR: 8.94e-06\n",
      "Epoch  17 [2300/10697 ( 21.5%)] Loss: 0.019024 L1: 0.010981 Grad: 0.080292 Thermal: 0.000259 LR: 8.94e-06\n",
      "Epoch  17 [2300/10697 ( 21.5%)] Loss: 0.019024 L1: 0.010981 Grad: 0.080292 Thermal: 0.000259 LR: 8.94e-06\n",
      "Epoch  17 [2350/10697 ( 22.0%)] Loss: 0.025099 L1: 0.014865 Grad: 0.102127 Thermal: 0.000421 LR: 8.94e-06\n",
      "Epoch  17 [2350/10697 ( 22.0%)] Loss: 0.025099 L1: 0.014865 Grad: 0.102127 Thermal: 0.000421 LR: 8.94e-06\n",
      "Epoch  17 [2400/10697 ( 22.4%)] Loss: 0.026742 L1: 0.015973 Grad: 0.107461 Thermal: 0.000458 LR: 8.94e-06\n",
      "Epoch  17 [2400/10697 ( 22.4%)] Loss: 0.026742 L1: 0.015973 Grad: 0.107461 Thermal: 0.000458 LR: 8.94e-06\n",
      "Epoch  17 [2450/10697 ( 22.9%)] Loss: 0.029866 L1: 0.017176 Grad: 0.126623 Thermal: 0.000548 LR: 8.94e-06\n",
      "Epoch  17 [2450/10697 ( 22.9%)] Loss: 0.029866 L1: 0.017176 Grad: 0.126623 Thermal: 0.000548 LR: 8.94e-06\n",
      "Epoch  17 [2500/10697 ( 23.4%)] Loss: 0.023469 L1: 0.013778 Grad: 0.096717 Thermal: 0.000377 LR: 8.94e-06\n",
      "Epoch  17 [2500/10697 ( 23.4%)] Loss: 0.023469 L1: 0.013778 Grad: 0.096717 Thermal: 0.000377 LR: 8.94e-06\n",
      "Epoch  17 [2550/10697 ( 23.8%)] Loss: 0.026692 L1: 0.015859 Grad: 0.108099 Thermal: 0.000447 LR: 8.94e-06\n",
      "Epoch  17 [2550/10697 ( 23.8%)] Loss: 0.026692 L1: 0.015859 Grad: 0.108099 Thermal: 0.000447 LR: 8.94e-06\n",
      "Epoch  17 [2600/10697 ( 24.3%)] Loss: 0.021768 L1: 0.012954 Grad: 0.087968 Thermal: 0.000340 LR: 8.94e-06\n",
      "Epoch  17 [2600/10697 ( 24.3%)] Loss: 0.021768 L1: 0.012954 Grad: 0.087968 Thermal: 0.000340 LR: 8.94e-06\n",
      "Epoch  17 [2650/10697 ( 24.8%)] Loss: 0.025291 L1: 0.014883 Grad: 0.103865 Thermal: 0.000425 LR: 8.94e-06\n",
      "Epoch  17 [2650/10697 ( 24.8%)] Loss: 0.025291 L1: 0.014883 Grad: 0.103865 Thermal: 0.000425 LR: 8.94e-06\n",
      "Epoch  17 [2700/10697 ( 25.2%)] Loss: 0.024165 L1: 0.014223 Grad: 0.099223 Thermal: 0.000388 LR: 8.94e-06\n",
      "Epoch  17 [2700/10697 ( 25.2%)] Loss: 0.024165 L1: 0.014223 Grad: 0.099223 Thermal: 0.000388 LR: 8.94e-06\n",
      "Epoch  17 [2750/10697 ( 25.7%)] Loss: 0.027054 L1: 0.015751 Grad: 0.112791 Thermal: 0.000470 LR: 8.94e-06\n",
      "Epoch  17 [2750/10697 ( 25.7%)] Loss: 0.027054 L1: 0.015751 Grad: 0.112791 Thermal: 0.000470 LR: 8.94e-06\n",
      "Epoch  17 [2800/10697 ( 26.2%)] Loss: 0.031536 L1: 0.018697 Grad: 0.128086 Thermal: 0.000616 LR: 8.94e-06\n",
      "Epoch  17 [2800/10697 ( 26.2%)] Loss: 0.031536 L1: 0.018697 Grad: 0.128086 Thermal: 0.000616 LR: 8.94e-06\n",
      "Epoch  17 [2850/10697 ( 26.6%)] Loss: 0.030346 L1: 0.017787 Grad: 0.125284 Thermal: 0.000597 LR: 8.94e-06\n",
      "Epoch  17 [2850/10697 ( 26.6%)] Loss: 0.030346 L1: 0.017787 Grad: 0.125284 Thermal: 0.000597 LR: 8.94e-06\n",
      "Epoch  17 [2900/10697 ( 27.1%)] Loss: 0.020214 L1: 0.011401 Grad: 0.087980 Thermal: 0.000297 LR: 8.94e-06\n",
      "Epoch  17 [2900/10697 ( 27.1%)] Loss: 0.020214 L1: 0.011401 Grad: 0.087980 Thermal: 0.000297 LR: 8.94e-06\n",
      "Epoch  17 [2950/10697 ( 27.6%)] Loss: 0.026017 L1: 0.015491 Grad: 0.105040 Thermal: 0.000438 LR: 8.94e-06\n",
      "Epoch  17 [2950/10697 ( 27.6%)] Loss: 0.026017 L1: 0.015491 Grad: 0.105040 Thermal: 0.000438 LR: 8.94e-06\n",
      "Epoch  17 [3000/10697 ( 28.0%)] Loss: 0.033482 L1: 0.019197 Grad: 0.142535 Thermal: 0.000638 LR: 8.94e-06\n",
      "Epoch  17 [3000/10697 ( 28.0%)] Loss: 0.033482 L1: 0.019197 Grad: 0.142535 Thermal: 0.000638 LR: 8.94e-06\n",
      "Epoch  17 [3050/10697 ( 28.5%)] Loss: 0.024997 L1: 0.014694 Grad: 0.102826 Thermal: 0.000414 LR: 8.94e-06\n",
      "Epoch  17 [3050/10697 ( 28.5%)] Loss: 0.024997 L1: 0.014694 Grad: 0.102826 Thermal: 0.000414 LR: 8.94e-06\n",
      "Epoch  17 [3100/10697 ( 29.0%)] Loss: 0.027875 L1: 0.016052 Grad: 0.117988 Thermal: 0.000473 LR: 8.94e-06\n",
      "Epoch  17 [3100/10697 ( 29.0%)] Loss: 0.027875 L1: 0.016052 Grad: 0.117988 Thermal: 0.000473 LR: 8.94e-06\n",
      "Epoch  17 [3150/10697 ( 29.4%)] Loss: 0.027522 L1: 0.016410 Grad: 0.110858 Thermal: 0.000537 LR: 8.94e-06\n",
      "Epoch  17 [3150/10697 ( 29.4%)] Loss: 0.027522 L1: 0.016410 Grad: 0.110858 Thermal: 0.000537 LR: 8.94e-06\n",
      "Epoch  17 [3200/10697 ( 29.9%)] Loss: 0.022379 L1: 0.013218 Grad: 0.091437 Thermal: 0.000340 LR: 8.94e-06\n",
      "Epoch  17 [3200/10697 ( 29.9%)] Loss: 0.022379 L1: 0.013218 Grad: 0.091437 Thermal: 0.000340 LR: 8.94e-06\n",
      "Epoch  17 [3250/10697 ( 30.4%)] Loss: 0.025666 L1: 0.014909 Grad: 0.107370 Thermal: 0.000405 LR: 8.94e-06\n",
      "Epoch  17 [3250/10697 ( 30.4%)] Loss: 0.025666 L1: 0.014909 Grad: 0.107370 Thermal: 0.000405 LR: 8.94e-06\n",
      "Epoch  17 [3300/10697 ( 30.8%)] Loss: 0.030308 L1: 0.017327 Grad: 0.129550 Thermal: 0.000514 LR: 8.94e-06\n",
      "Epoch  17 [3300/10697 ( 30.8%)] Loss: 0.030308 L1: 0.017327 Grad: 0.129550 Thermal: 0.000514 LR: 8.94e-06\n",
      "Epoch  17 [3350/10697 ( 31.3%)] Loss: 0.032039 L1: 0.018260 Grad: 0.137504 Thermal: 0.000561 LR: 8.94e-06\n",
      "Epoch  17 [3350/10697 ( 31.3%)] Loss: 0.032039 L1: 0.018260 Grad: 0.137504 Thermal: 0.000561 LR: 8.94e-06\n",
      "Epoch  17 [3400/10697 ( 31.8%)] Loss: 0.028816 L1: 0.016906 Grad: 0.118835 Thermal: 0.000522 LR: 8.94e-06\n",
      "Epoch  17 [3400/10697 ( 31.8%)] Loss: 0.028816 L1: 0.016906 Grad: 0.118835 Thermal: 0.000522 LR: 8.94e-06\n",
      "Epoch  17 [3450/10697 ( 32.3%)] Loss: 0.026844 L1: 0.016181 Grad: 0.106398 Thermal: 0.000472 LR: 8.94e-06\n",
      "Epoch  17 [3450/10697 ( 32.3%)] Loss: 0.026844 L1: 0.016181 Grad: 0.106398 Thermal: 0.000472 LR: 8.94e-06\n",
      "Epoch  17 [3500/10697 ( 32.7%)] Loss: 0.031899 L1: 0.018326 Grad: 0.135421 Thermal: 0.000613 LR: 8.94e-06\n",
      "Epoch  17 [3500/10697 ( 32.7%)] Loss: 0.031899 L1: 0.018326 Grad: 0.135421 Thermal: 0.000613 LR: 8.94e-06\n",
      "Epoch  17 [3550/10697 ( 33.2%)] Loss: 0.030655 L1: 0.018308 Grad: 0.123178 Thermal: 0.000573 LR: 8.94e-06\n",
      "Epoch  17 [3550/10697 ( 33.2%)] Loss: 0.030655 L1: 0.018308 Grad: 0.123178 Thermal: 0.000573 LR: 8.94e-06\n",
      "Epoch  17 [3600/10697 ( 33.7%)] Loss: 0.030055 L1: 0.017915 Grad: 0.121094 Thermal: 0.000616 LR: 8.94e-06\n",
      "Epoch  17 [3600/10697 ( 33.7%)] Loss: 0.030055 L1: 0.017915 Grad: 0.121094 Thermal: 0.000616 LR: 8.94e-06\n",
      "Epoch  17 [3650/10697 ( 34.1%)] Loss: 0.028752 L1: 0.016961 Grad: 0.117634 Thermal: 0.000542 LR: 8.94e-06\n",
      "Epoch  17 [3650/10697 ( 34.1%)] Loss: 0.028752 L1: 0.016961 Grad: 0.117634 Thermal: 0.000542 LR: 8.94e-06\n",
      "Epoch  17 [3700/10697 ( 34.6%)] Loss: 0.028587 L1: 0.017283 Grad: 0.112779 Thermal: 0.000514 LR: 8.94e-06\n",
      "Epoch  17 [3700/10697 ( 34.6%)] Loss: 0.028587 L1: 0.017283 Grad: 0.112779 Thermal: 0.000514 LR: 8.94e-06\n",
      "Epoch  17 [3750/10697 ( 35.1%)] Loss: 0.026602 L1: 0.015188 Grad: 0.113875 Thermal: 0.000547 LR: 8.94e-06\n",
      "Epoch  17 [3750/10697 ( 35.1%)] Loss: 0.026602 L1: 0.015188 Grad: 0.113875 Thermal: 0.000547 LR: 8.94e-06\n",
      "Epoch  17 [3800/10697 ( 35.5%)] Loss: 0.017420 L1: 0.010158 Grad: 0.072501 Thermal: 0.000254 LR: 8.94e-06\n",
      "Epoch  17 [3800/10697 ( 35.5%)] Loss: 0.017420 L1: 0.010158 Grad: 0.072501 Thermal: 0.000254 LR: 8.94e-06\n",
      "Epoch  17 [3850/10697 ( 36.0%)] Loss: 0.028484 L1: 0.016273 Grad: 0.121872 Thermal: 0.000477 LR: 8.94e-06\n",
      "Epoch  17 [3850/10697 ( 36.0%)] Loss: 0.028484 L1: 0.016273 Grad: 0.121872 Thermal: 0.000477 LR: 8.94e-06\n",
      "Epoch  17 [3900/10697 ( 36.5%)] Loss: 0.028467 L1: 0.016588 Grad: 0.118554 Thermal: 0.000480 LR: 8.94e-06\n",
      "Epoch  17 [3900/10697 ( 36.5%)] Loss: 0.028467 L1: 0.016588 Grad: 0.118554 Thermal: 0.000480 LR: 8.94e-06\n",
      "Epoch  17 [3950/10697 ( 36.9%)] Loss: 0.024801 L1: 0.014394 Grad: 0.103884 Thermal: 0.000382 LR: 8.94e-06\n",
      "Epoch  17 [3950/10697 ( 36.9%)] Loss: 0.024801 L1: 0.014394 Grad: 0.103884 Thermal: 0.000382 LR: 8.94e-06\n",
      "Epoch  17 [4000/10697 ( 37.4%)] Loss: 0.027947 L1: 0.016403 Grad: 0.115192 Thermal: 0.000480 LR: 8.94e-06\n",
      "Epoch  17 [4000/10697 ( 37.4%)] Loss: 0.027947 L1: 0.016403 Grad: 0.115192 Thermal: 0.000480 LR: 8.94e-06\n",
      "Epoch  17 [4050/10697 ( 37.9%)] Loss: 0.026990 L1: 0.015587 Grad: 0.113778 Thermal: 0.000510 LR: 8.94e-06\n",
      "Epoch  17 [4050/10697 ( 37.9%)] Loss: 0.026990 L1: 0.015587 Grad: 0.113778 Thermal: 0.000510 LR: 8.94e-06\n",
      "Epoch  17 [4100/10697 ( 38.3%)] Loss: 0.024864 L1: 0.014645 Grad: 0.101990 Thermal: 0.000397 LR: 8.94e-06\n",
      "Epoch  17 [4100/10697 ( 38.3%)] Loss: 0.024864 L1: 0.014645 Grad: 0.101990 Thermal: 0.000397 LR: 8.94e-06\n",
      "Epoch  17 [4150/10697 ( 38.8%)] Loss: 0.026750 L1: 0.015372 Grad: 0.113548 Thermal: 0.000457 LR: 8.94e-06\n",
      "Epoch  17 [4150/10697 ( 38.8%)] Loss: 0.026750 L1: 0.015372 Grad: 0.113548 Thermal: 0.000457 LR: 8.94e-06\n",
      "Epoch  17 [4200/10697 ( 39.3%)] Loss: 0.028839 L1: 0.016635 Grad: 0.121767 Thermal: 0.000547 LR: 8.94e-06\n",
      "Epoch  17 [4200/10697 ( 39.3%)] Loss: 0.028839 L1: 0.016635 Grad: 0.121767 Thermal: 0.000547 LR: 8.94e-06\n",
      "Epoch  17 [4250/10697 ( 39.7%)] Loss: 0.027456 L1: 0.015409 Grad: 0.120255 Thermal: 0.000427 LR: 8.94e-06\n",
      "Epoch  17 [4250/10697 ( 39.7%)] Loss: 0.027456 L1: 0.015409 Grad: 0.120255 Thermal: 0.000427 LR: 8.94e-06\n",
      "Epoch  17 [4300/10697 ( 40.2%)] Loss: 0.020858 L1: 0.011995 Grad: 0.088485 Thermal: 0.000299 LR: 8.94e-06\n",
      "Epoch  17 [4300/10697 ( 40.2%)] Loss: 0.020858 L1: 0.011995 Grad: 0.088485 Thermal: 0.000299 LR: 8.94e-06\n",
      "Epoch  17 [4350/10697 ( 40.7%)] Loss: 0.028224 L1: 0.016254 Grad: 0.119379 Thermal: 0.000629 LR: 8.94e-06\n",
      "Epoch  17 [4350/10697 ( 40.7%)] Loss: 0.028224 L1: 0.016254 Grad: 0.119379 Thermal: 0.000629 LR: 8.94e-06\n",
      "Epoch  17 [4400/10697 ( 41.1%)] Loss: 0.025290 L1: 0.014680 Grad: 0.105884 Thermal: 0.000428 LR: 8.94e-06\n",
      "Epoch  17 [4400/10697 ( 41.1%)] Loss: 0.025290 L1: 0.014680 Grad: 0.105884 Thermal: 0.000428 LR: 8.94e-06\n",
      "Epoch  17 [4450/10697 ( 41.6%)] Loss: 0.026995 L1: 0.016278 Grad: 0.106940 Thermal: 0.000469 LR: 8.94e-06\n",
      "Epoch  17 [4450/10697 ( 41.6%)] Loss: 0.026995 L1: 0.016278 Grad: 0.106940 Thermal: 0.000469 LR: 8.94e-06\n",
      "Epoch  17 [4500/10697 ( 42.1%)] Loss: 0.023571 L1: 0.013319 Grad: 0.102345 Thermal: 0.000363 LR: 8.94e-06\n",
      "Epoch  17 [4500/10697 ( 42.1%)] Loss: 0.023571 L1: 0.013319 Grad: 0.102345 Thermal: 0.000363 LR: 8.94e-06\n",
      "Epoch  17 [4550/10697 ( 42.5%)] Loss: 0.029569 L1: 0.016956 Grad: 0.125851 Thermal: 0.000548 LR: 8.94e-06\n",
      "Epoch  17 [4550/10697 ( 42.5%)] Loss: 0.029569 L1: 0.016956 Grad: 0.125851 Thermal: 0.000548 LR: 8.94e-06\n",
      "Epoch  17 [4600/10697 ( 43.0%)] Loss: 0.029166 L1: 0.016930 Grad: 0.122073 Thermal: 0.000563 LR: 8.94e-06\n",
      "Epoch  17 [4600/10697 ( 43.0%)] Loss: 0.029166 L1: 0.016930 Grad: 0.122073 Thermal: 0.000563 LR: 8.94e-06\n",
      "Epoch  17 [4650/10697 ( 43.5%)] Loss: 0.027437 L1: 0.015831 Grad: 0.115796 Thermal: 0.000530 LR: 8.94e-06\n",
      "Epoch  17 [4650/10697 ( 43.5%)] Loss: 0.027437 L1: 0.015831 Grad: 0.115796 Thermal: 0.000530 LR: 8.94e-06\n",
      "Epoch  17 [4700/10697 ( 43.9%)] Loss: 0.028479 L1: 0.016589 Grad: 0.118639 Thermal: 0.000523 LR: 8.94e-06\n",
      "Epoch  17 [4700/10697 ( 43.9%)] Loss: 0.028479 L1: 0.016589 Grad: 0.118639 Thermal: 0.000523 LR: 8.94e-06\n",
      "Epoch  17 [4750/10697 ( 44.4%)] Loss: 0.025255 L1: 0.015130 Grad: 0.101045 Thermal: 0.000414 LR: 8.94e-06\n",
      "Epoch  17 [4750/10697 ( 44.4%)] Loss: 0.025255 L1: 0.015130 Grad: 0.101045 Thermal: 0.000414 LR: 8.94e-06\n",
      "Epoch  17 [4800/10697 ( 44.9%)] Loss: 0.018127 L1: 0.010494 Grad: 0.076214 Thermal: 0.000239 LR: 8.94e-06\n",
      "Epoch  17 [4800/10697 ( 44.9%)] Loss: 0.018127 L1: 0.010494 Grad: 0.076214 Thermal: 0.000239 LR: 8.94e-06\n",
      "Epoch  17 [4850/10697 ( 45.3%)] Loss: 0.023976 L1: 0.013982 Grad: 0.099756 Thermal: 0.000359 LR: 8.94e-06\n",
      "Epoch  17 [4850/10697 ( 45.3%)] Loss: 0.023976 L1: 0.013982 Grad: 0.099756 Thermal: 0.000359 LR: 8.94e-06\n",
      "Epoch  17 [4900/10697 ( 45.8%)] Loss: 0.026340 L1: 0.014937 Grad: 0.113806 Thermal: 0.000448 LR: 8.94e-06\n",
      "Epoch  17 [4900/10697 ( 45.8%)] Loss: 0.026340 L1: 0.014937 Grad: 0.113806 Thermal: 0.000448 LR: 8.94e-06\n",
      "Epoch  17 [4950/10697 ( 46.3%)] Loss: 0.022781 L1: 0.013145 Grad: 0.096174 Thermal: 0.000376 LR: 8.94e-06\n",
      "Epoch  17 [4950/10697 ( 46.3%)] Loss: 0.022781 L1: 0.013145 Grad: 0.096174 Thermal: 0.000376 LR: 8.94e-06\n",
      "Epoch  17 [5000/10697 ( 46.7%)] Loss: 0.030960 L1: 0.017918 Grad: 0.130122 Thermal: 0.000610 LR: 8.94e-06\n",
      "Epoch  17 [5000/10697 ( 46.7%)] Loss: 0.030960 L1: 0.017918 Grad: 0.130122 Thermal: 0.000610 LR: 8.94e-06\n",
      "Epoch  17 [5050/10697 ( 47.2%)] Loss: 0.029980 L1: 0.017622 Grad: 0.123297 Thermal: 0.000559 LR: 8.94e-06\n",
      "Epoch  17 [5050/10697 ( 47.2%)] Loss: 0.029980 L1: 0.017622 Grad: 0.123297 Thermal: 0.000559 LR: 8.94e-06\n",
      "Epoch  17 [5100/10697 ( 47.7%)] Loss: 0.021540 L1: 0.012552 Grad: 0.089723 Thermal: 0.000316 LR: 8.94e-06\n",
      "Epoch  17 [5100/10697 ( 47.7%)] Loss: 0.021540 L1: 0.012552 Grad: 0.089723 Thermal: 0.000316 LR: 8.94e-06\n",
      "Epoch  17 [5150/10697 ( 48.1%)] Loss: 0.027584 L1: 0.015846 Grad: 0.117144 Thermal: 0.000466 LR: 8.94e-06\n",
      "Epoch  17 [5150/10697 ( 48.1%)] Loss: 0.027584 L1: 0.015846 Grad: 0.117144 Thermal: 0.000466 LR: 8.94e-06\n",
      "Epoch  17 [5200/10697 ( 48.6%)] Loss: 0.029450 L1: 0.017230 Grad: 0.121931 Thermal: 0.000531 LR: 8.94e-06\n",
      "Epoch  17 [5200/10697 ( 48.6%)] Loss: 0.029450 L1: 0.017230 Grad: 0.121931 Thermal: 0.000531 LR: 8.94e-06\n",
      "Epoch  17 [5250/10697 ( 49.1%)] Loss: 0.027409 L1: 0.016294 Grad: 0.110921 Thermal: 0.000464 LR: 8.94e-06\n",
      "Epoch  17 [5250/10697 ( 49.1%)] Loss: 0.027409 L1: 0.016294 Grad: 0.110921 Thermal: 0.000464 LR: 8.94e-06\n",
      "Epoch  17 [5300/10697 ( 49.5%)] Loss: 0.026616 L1: 0.015693 Grad: 0.109016 Thermal: 0.000440 LR: 8.94e-06\n",
      "Epoch  17 [5300/10697 ( 49.5%)] Loss: 0.026616 L1: 0.015693 Grad: 0.109016 Thermal: 0.000440 LR: 8.94e-06\n",
      "Epoch  17 [5350/10697 ( 50.0%)] Loss: 0.027039 L1: 0.015746 Grad: 0.112678 Thermal: 0.000496 LR: 8.94e-06\n",
      "Epoch  17 [5350/10697 ( 50.0%)] Loss: 0.027039 L1: 0.015746 Grad: 0.112678 Thermal: 0.000496 LR: 8.94e-06\n",
      "Epoch  17 [5400/10697 ( 50.5%)] Loss: 0.028617 L1: 0.016888 Grad: 0.117037 Thermal: 0.000512 LR: 8.94e-06\n",
      "Epoch  17 [5400/10697 ( 50.5%)] Loss: 0.028617 L1: 0.016888 Grad: 0.117037 Thermal: 0.000512 LR: 8.94e-06\n",
      "Epoch  17 [5450/10697 ( 50.9%)] Loss: 0.025552 L1: 0.014310 Grad: 0.112236 Thermal: 0.000366 LR: 8.94e-06\n",
      "Epoch  17 [5450/10697 ( 50.9%)] Loss: 0.025552 L1: 0.014310 Grad: 0.112236 Thermal: 0.000366 LR: 8.94e-06\n",
      "Epoch  17 [5500/10697 ( 51.4%)] Loss: 0.021500 L1: 0.012179 Grad: 0.093046 Thermal: 0.000331 LR: 8.94e-06\n",
      "Epoch  17 [5500/10697 ( 51.4%)] Loss: 0.021500 L1: 0.012179 Grad: 0.093046 Thermal: 0.000331 LR: 8.94e-06\n",
      "Epoch  17 [5550/10697 ( 51.9%)] Loss: 0.021852 L1: 0.012255 Grad: 0.095828 Thermal: 0.000278 LR: 8.94e-06\n",
      "Epoch  17 [5550/10697 ( 51.9%)] Loss: 0.021852 L1: 0.012255 Grad: 0.095828 Thermal: 0.000278 LR: 8.94e-06\n",
      "Epoch  17 [5600/10697 ( 52.4%)] Loss: 0.029686 L1: 0.017492 Grad: 0.121658 Thermal: 0.000557 LR: 8.94e-06\n",
      "Epoch  17 [5600/10697 ( 52.4%)] Loss: 0.029686 L1: 0.017492 Grad: 0.121658 Thermal: 0.000557 LR: 8.94e-06\n",
      "Epoch  17 [5650/10697 ( 52.8%)] Loss: 0.028597 L1: 0.016391 Grad: 0.121770 Thermal: 0.000590 LR: 8.94e-06\n",
      "Epoch  17 [5650/10697 ( 52.8%)] Loss: 0.028597 L1: 0.016391 Grad: 0.121770 Thermal: 0.000590 LR: 8.94e-06\n",
      "Epoch  17 [5700/10697 ( 53.3%)] Loss: 0.028475 L1: 0.016311 Grad: 0.121392 Thermal: 0.000497 LR: 8.94e-06\n",
      "Epoch  17 [5700/10697 ( 53.3%)] Loss: 0.028475 L1: 0.016311 Grad: 0.121392 Thermal: 0.000497 LR: 8.94e-06\n",
      "Epoch  17 [5750/10697 ( 53.8%)] Loss: 0.027598 L1: 0.015877 Grad: 0.116990 Thermal: 0.000446 LR: 8.94e-06\n",
      "Epoch  17 [5750/10697 ( 53.8%)] Loss: 0.027598 L1: 0.015877 Grad: 0.116990 Thermal: 0.000446 LR: 8.94e-06\n",
      "Epoch  17 [5800/10697 ( 54.2%)] Loss: 0.029283 L1: 0.017436 Grad: 0.118206 Thermal: 0.000534 LR: 8.94e-06\n",
      "Epoch  17 [5800/10697 ( 54.2%)] Loss: 0.029283 L1: 0.017436 Grad: 0.118206 Thermal: 0.000534 LR: 8.94e-06\n",
      "Epoch  17 [5850/10697 ( 54.7%)] Loss: 0.024220 L1: 0.014394 Grad: 0.098052 Thermal: 0.000404 LR: 8.94e-06\n",
      "Epoch  17 [5850/10697 ( 54.7%)] Loss: 0.024220 L1: 0.014394 Grad: 0.098052 Thermal: 0.000404 LR: 8.94e-06\n",
      "Epoch  17 [5900/10697 ( 55.2%)] Loss: 0.025124 L1: 0.014373 Grad: 0.107294 Thermal: 0.000448 LR: 8.94e-06\n",
      "Epoch  17 [5900/10697 ( 55.2%)] Loss: 0.025124 L1: 0.014373 Grad: 0.107294 Thermal: 0.000448 LR: 8.94e-06\n",
      "Epoch  17 [5950/10697 ( 55.6%)] Loss: 0.025151 L1: 0.014831 Grad: 0.102989 Thermal: 0.000418 LR: 8.94e-06\n",
      "Epoch  17 [5950/10697 ( 55.6%)] Loss: 0.025151 L1: 0.014831 Grad: 0.102989 Thermal: 0.000418 LR: 8.94e-06\n",
      "Epoch  17 [6000/10697 ( 56.1%)] Loss: 0.029644 L1: 0.017334 Grad: 0.122849 Thermal: 0.000502 LR: 8.94e-06\n",
      "Epoch  17 [6000/10697 ( 56.1%)] Loss: 0.029644 L1: 0.017334 Grad: 0.122849 Thermal: 0.000502 LR: 8.94e-06\n",
      "Epoch  17 [6050/10697 ( 56.6%)] Loss: 0.031562 L1: 0.018235 Grad: 0.132983 Thermal: 0.000566 LR: 8.94e-06\n",
      "Epoch  17 [6050/10697 ( 56.6%)] Loss: 0.031562 L1: 0.018235 Grad: 0.132983 Thermal: 0.000566 LR: 8.94e-06\n",
      "Epoch  17 [6100/10697 ( 57.0%)] Loss: 0.023485 L1: 0.013881 Grad: 0.095839 Thermal: 0.000391 LR: 8.94e-06\n",
      "Epoch  17 [6100/10697 ( 57.0%)] Loss: 0.023485 L1: 0.013881 Grad: 0.095839 Thermal: 0.000391 LR: 8.94e-06\n",
      "Epoch  17 [6150/10697 ( 57.5%)] Loss: 0.030042 L1: 0.017713 Grad: 0.123006 Thermal: 0.000561 LR: 8.94e-06\n",
      "Epoch  17 [6150/10697 ( 57.5%)] Loss: 0.030042 L1: 0.017713 Grad: 0.123006 Thermal: 0.000561 LR: 8.94e-06\n",
      "Epoch  17 [6200/10697 ( 58.0%)] Loss: 0.026289 L1: 0.015065 Grad: 0.112037 Thermal: 0.000423 LR: 8.94e-06\n",
      "Epoch  17 [6200/10697 ( 58.0%)] Loss: 0.026289 L1: 0.015065 Grad: 0.112037 Thermal: 0.000423 LR: 8.94e-06\n",
      "Epoch  17 [6250/10697 ( 58.4%)] Loss: 0.021106 L1: 0.012230 Grad: 0.088624 Thermal: 0.000274 LR: 8.94e-06\n",
      "Epoch  17 [6250/10697 ( 58.4%)] Loss: 0.021106 L1: 0.012230 Grad: 0.088624 Thermal: 0.000274 LR: 8.94e-06\n",
      "Epoch  17 [6300/10697 ( 58.9%)] Loss: 0.032507 L1: 0.018935 Grad: 0.135386 Thermal: 0.000672 LR: 8.94e-06\n",
      "Epoch  17 [6300/10697 ( 58.9%)] Loss: 0.032507 L1: 0.018935 Grad: 0.135386 Thermal: 0.000672 LR: 8.94e-06\n",
      "Epoch  17 [6350/10697 ( 59.4%)] Loss: 0.028094 L1: 0.016646 Grad: 0.114224 Thermal: 0.000519 LR: 8.94e-06\n",
      "Epoch  17 [6350/10697 ( 59.4%)] Loss: 0.028094 L1: 0.016646 Grad: 0.114224 Thermal: 0.000519 LR: 8.94e-06\n",
      "Epoch  17 [6400/10697 ( 59.8%)] Loss: 0.023634 L1: 0.013593 Grad: 0.100235 Thermal: 0.000340 LR: 8.94e-06\n",
      "Epoch  17 [6400/10697 ( 59.8%)] Loss: 0.023634 L1: 0.013593 Grad: 0.100235 Thermal: 0.000340 LR: 8.94e-06\n",
      "Epoch  17 [6450/10697 ( 60.3%)] Loss: 0.025602 L1: 0.014801 Grad: 0.107791 Thermal: 0.000431 LR: 8.94e-06\n",
      "Epoch  17 [6450/10697 ( 60.3%)] Loss: 0.025602 L1: 0.014801 Grad: 0.107791 Thermal: 0.000431 LR: 8.94e-06\n",
      "Epoch  17 [6500/10697 ( 60.8%)] Loss: 0.024455 L1: 0.013904 Grad: 0.105318 Thermal: 0.000385 LR: 8.94e-06\n",
      "Epoch  17 [6500/10697 ( 60.8%)] Loss: 0.024455 L1: 0.013904 Grad: 0.105318 Thermal: 0.000385 LR: 8.94e-06\n",
      "Epoch  17 [6550/10697 ( 61.2%)] Loss: 0.025716 L1: 0.015341 Grad: 0.103530 Thermal: 0.000424 LR: 8.94e-06\n",
      "Epoch  17 [6550/10697 ( 61.2%)] Loss: 0.025716 L1: 0.015341 Grad: 0.103530 Thermal: 0.000424 LR: 8.94e-06\n",
      "Epoch  17 [6600/10697 ( 61.7%)] Loss: 0.031407 L1: 0.017964 Grad: 0.134094 Thermal: 0.000662 LR: 8.94e-06\n",
      "Epoch  17 [6600/10697 ( 61.7%)] Loss: 0.031407 L1: 0.017964 Grad: 0.134094 Thermal: 0.000662 LR: 8.94e-06\n",
      "Epoch  17 [6650/10697 ( 62.2%)] Loss: 0.025732 L1: 0.014904 Grad: 0.108067 Thermal: 0.000432 LR: 8.94e-06\n",
      "Epoch  17 [6650/10697 ( 62.2%)] Loss: 0.025732 L1: 0.014904 Grad: 0.108067 Thermal: 0.000432 LR: 8.94e-06\n",
      "Epoch  17 [6700/10697 ( 62.6%)] Loss: 0.026155 L1: 0.015027 Grad: 0.111059 Thermal: 0.000436 LR: 8.94e-06\n",
      "Epoch  17 [6700/10697 ( 62.6%)] Loss: 0.026155 L1: 0.015027 Grad: 0.111059 Thermal: 0.000436 LR: 8.94e-06\n",
      "Epoch  17 [6750/10697 ( 63.1%)] Loss: 0.025817 L1: 0.015029 Grad: 0.107688 Thermal: 0.000402 LR: 8.94e-06\n",
      "Epoch  17 [6750/10697 ( 63.1%)] Loss: 0.025817 L1: 0.015029 Grad: 0.107688 Thermal: 0.000402 LR: 8.94e-06\n",
      "Epoch  17 [6800/10697 ( 63.6%)] Loss: 0.025949 L1: 0.014979 Grad: 0.109491 Thermal: 0.000412 LR: 8.94e-06\n",
      "Epoch  17 [6800/10697 ( 63.6%)] Loss: 0.025949 L1: 0.014979 Grad: 0.109491 Thermal: 0.000412 LR: 8.94e-06\n",
      "Epoch  17 [6850/10697 ( 64.0%)] Loss: 0.024501 L1: 0.013908 Grad: 0.105748 Thermal: 0.000373 LR: 8.94e-06\n",
      "Epoch  17 [6850/10697 ( 64.0%)] Loss: 0.024501 L1: 0.013908 Grad: 0.105748 Thermal: 0.000373 LR: 8.94e-06\n",
      "Epoch  17 [6900/10697 ( 64.5%)] Loss: 0.023522 L1: 0.013560 Grad: 0.099446 Thermal: 0.000346 LR: 8.94e-06\n",
      "Epoch  17 [6900/10697 ( 64.5%)] Loss: 0.023522 L1: 0.013560 Grad: 0.099446 Thermal: 0.000346 LR: 8.94e-06\n",
      "Epoch  17 [6950/10697 ( 65.0%)] Loss: 0.033263 L1: 0.019398 Grad: 0.138339 Thermal: 0.000612 LR: 8.94e-06\n",
      "Epoch  17 [6950/10697 ( 65.0%)] Loss: 0.033263 L1: 0.019398 Grad: 0.138339 Thermal: 0.000612 LR: 8.94e-06\n",
      "Epoch  17 [7000/10697 ( 65.4%)] Loss: 0.023525 L1: 0.013581 Grad: 0.099256 Thermal: 0.000363 LR: 8.94e-06\n",
      "Epoch  17 [7000/10697 ( 65.4%)] Loss: 0.023525 L1: 0.013581 Grad: 0.099256 Thermal: 0.000363 LR: 8.94e-06\n",
      "Epoch  17 [7050/10697 ( 65.9%)] Loss: 0.027098 L1: 0.015852 Grad: 0.112207 Thermal: 0.000499 LR: 8.94e-06\n",
      "Epoch  17 [7050/10697 ( 65.9%)] Loss: 0.027098 L1: 0.015852 Grad: 0.112207 Thermal: 0.000499 LR: 8.94e-06\n",
      "Epoch  17 [7100/10697 ( 66.4%)] Loss: 0.024241 L1: 0.013778 Grad: 0.104415 Thermal: 0.000429 LR: 8.94e-06\n",
      "Epoch  17 [7100/10697 ( 66.4%)] Loss: 0.024241 L1: 0.013778 Grad: 0.104415 Thermal: 0.000429 LR: 8.94e-06\n",
      "Epoch  17 [7150/10697 ( 66.8%)] Loss: 0.024842 L1: 0.014854 Grad: 0.099666 Thermal: 0.000415 LR: 8.94e-06\n",
      "Epoch  17 [7150/10697 ( 66.8%)] Loss: 0.024842 L1: 0.014854 Grad: 0.099666 Thermal: 0.000415 LR: 8.94e-06\n",
      "Epoch  17 [7200/10697 ( 67.3%)] Loss: 0.025681 L1: 0.015247 Grad: 0.104128 Thermal: 0.000416 LR: 8.94e-06\n",
      "Epoch  17 [7200/10697 ( 67.3%)] Loss: 0.025681 L1: 0.015247 Grad: 0.104128 Thermal: 0.000416 LR: 8.94e-06\n",
      "Epoch  17 [7250/10697 ( 67.8%)] Loss: 0.026158 L1: 0.015390 Grad: 0.107467 Thermal: 0.000422 LR: 8.94e-06\n",
      "Epoch  17 [7250/10697 ( 67.8%)] Loss: 0.026158 L1: 0.015390 Grad: 0.107467 Thermal: 0.000422 LR: 8.94e-06\n",
      "Epoch  17 [7300/10697 ( 68.2%)] Loss: 0.031354 L1: 0.018455 Grad: 0.128691 Thermal: 0.000594 LR: 8.94e-06\n",
      "Epoch  17 [7300/10697 ( 68.2%)] Loss: 0.031354 L1: 0.018455 Grad: 0.128691 Thermal: 0.000594 LR: 8.94e-06\n",
      "Epoch  17 [7350/10697 ( 68.7%)] Loss: 0.029177 L1: 0.016973 Grad: 0.121756 Thermal: 0.000568 LR: 8.94e-06\n",
      "Epoch  17 [7350/10697 ( 68.7%)] Loss: 0.029177 L1: 0.016973 Grad: 0.121756 Thermal: 0.000568 LR: 8.94e-06\n",
      "Epoch  17 [7400/10697 ( 69.2%)] Loss: 0.028081 L1: 0.016322 Grad: 0.117346 Thermal: 0.000484 LR: 8.94e-06\n",
      "Epoch  17 [7400/10697 ( 69.2%)] Loss: 0.028081 L1: 0.016322 Grad: 0.117346 Thermal: 0.000484 LR: 8.94e-06\n",
      "Epoch  17 [7450/10697 ( 69.6%)] Loss: 0.022483 L1: 0.013371 Grad: 0.090929 Thermal: 0.000371 LR: 8.94e-06\n",
      "Epoch  17 [7450/10697 ( 69.6%)] Loss: 0.022483 L1: 0.013371 Grad: 0.090929 Thermal: 0.000371 LR: 8.94e-06\n",
      "Epoch  17 [7500/10697 ( 70.1%)] Loss: 0.024751 L1: 0.014319 Grad: 0.104104 Thermal: 0.000424 LR: 8.94e-06\n",
      "Epoch  17 [7500/10697 ( 70.1%)] Loss: 0.024751 L1: 0.014319 Grad: 0.104104 Thermal: 0.000424 LR: 8.94e-06\n",
      "Epoch  17 [7550/10697 ( 70.6%)] Loss: 0.027222 L1: 0.015880 Grad: 0.113177 Thermal: 0.000490 LR: 8.94e-06\n",
      "Epoch  17 [7550/10697 ( 70.6%)] Loss: 0.027222 L1: 0.015880 Grad: 0.113177 Thermal: 0.000490 LR: 8.94e-06\n",
      "Epoch  17 [7600/10697 ( 71.0%)] Loss: 0.031102 L1: 0.018034 Grad: 0.130377 Thermal: 0.000606 LR: 8.94e-06\n",
      "Epoch  17 [7600/10697 ( 71.0%)] Loss: 0.031102 L1: 0.018034 Grad: 0.130377 Thermal: 0.000606 LR: 8.94e-06\n",
      "Epoch  17 [7650/10697 ( 71.5%)] Loss: 0.021117 L1: 0.012221 Grad: 0.088806 Thermal: 0.000311 LR: 8.94e-06\n",
      "Epoch  17 [7650/10697 ( 71.5%)] Loss: 0.021117 L1: 0.012221 Grad: 0.088806 Thermal: 0.000311 LR: 8.94e-06\n",
      "Epoch  17 [7700/10697 ( 72.0%)] Loss: 0.032799 L1: 0.019200 Grad: 0.135641 Thermal: 0.000685 LR: 8.94e-06\n",
      "Epoch  17 [7700/10697 ( 72.0%)] Loss: 0.032799 L1: 0.019200 Grad: 0.135641 Thermal: 0.000685 LR: 8.94e-06\n",
      "Epoch  17 [7750/10697 ( 72.5%)] Loss: 0.025992 L1: 0.015322 Grad: 0.106472 Thermal: 0.000455 LR: 8.94e-06\n",
      "Epoch  17 [7750/10697 ( 72.5%)] Loss: 0.025992 L1: 0.015322 Grad: 0.106472 Thermal: 0.000455 LR: 8.94e-06\n",
      "Epoch  17 [7800/10697 ( 72.9%)] Loss: 0.028535 L1: 0.016151 Grad: 0.123591 Thermal: 0.000498 LR: 8.94e-06\n",
      "Epoch  17 [7800/10697 ( 72.9%)] Loss: 0.028535 L1: 0.016151 Grad: 0.123591 Thermal: 0.000498 LR: 8.94e-06\n",
      "Epoch  17 [7850/10697 ( 73.4%)] Loss: 0.022399 L1: 0.013058 Grad: 0.093251 Thermal: 0.000307 LR: 8.94e-06\n",
      "Epoch  17 [7850/10697 ( 73.4%)] Loss: 0.022399 L1: 0.013058 Grad: 0.093251 Thermal: 0.000307 LR: 8.94e-06\n",
      "Epoch  17 [7900/10697 ( 73.9%)] Loss: 0.032397 L1: 0.017973 Grad: 0.143923 Thermal: 0.000627 LR: 8.94e-06\n",
      "Epoch  17 [7900/10697 ( 73.9%)] Loss: 0.032397 L1: 0.017973 Grad: 0.143923 Thermal: 0.000627 LR: 8.94e-06\n",
      "Epoch  17 [7950/10697 ( 74.3%)] Loss: 0.026479 L1: 0.015929 Grad: 0.105275 Thermal: 0.000436 LR: 8.94e-06\n",
      "Epoch  17 [7950/10697 ( 74.3%)] Loss: 0.026479 L1: 0.015929 Grad: 0.105275 Thermal: 0.000436 LR: 8.94e-06\n",
      "Epoch  17 [8000/10697 ( 74.8%)] Loss: 0.031048 L1: 0.017972 Grad: 0.130496 Thermal: 0.000525 LR: 8.94e-06\n",
      "Epoch  17 [8000/10697 ( 74.8%)] Loss: 0.031048 L1: 0.017972 Grad: 0.130496 Thermal: 0.000525 LR: 8.94e-06\n",
      "Epoch  17 [8050/10697 ( 75.3%)] Loss: 0.025569 L1: 0.014566 Grad: 0.109821 Thermal: 0.000415 LR: 8.94e-06\n",
      "Epoch  17 [8050/10697 ( 75.3%)] Loss: 0.025569 L1: 0.014566 Grad: 0.109821 Thermal: 0.000415 LR: 8.94e-06\n",
      "Epoch  17 [8100/10697 ( 75.7%)] Loss: 0.029064 L1: 0.017253 Grad: 0.117848 Thermal: 0.000519 LR: 8.94e-06\n",
      "Epoch  17 [8100/10697 ( 75.7%)] Loss: 0.029064 L1: 0.017253 Grad: 0.117848 Thermal: 0.000519 LR: 8.94e-06\n",
      "Epoch  17 [8150/10697 ( 76.2%)] Loss: 0.032584 L1: 0.018785 Grad: 0.137667 Thermal: 0.000652 LR: 8.94e-06\n",
      "Epoch  17 [8150/10697 ( 76.2%)] Loss: 0.032584 L1: 0.018785 Grad: 0.137667 Thermal: 0.000652 LR: 8.94e-06\n",
      "Epoch  17 [8200/10697 ( 76.7%)] Loss: 0.024547 L1: 0.014053 Grad: 0.104754 Thermal: 0.000359 LR: 8.94e-06\n",
      "Epoch  17 [8200/10697 ( 76.7%)] Loss: 0.024547 L1: 0.014053 Grad: 0.104754 Thermal: 0.000359 LR: 8.94e-06\n",
      "Epoch  17 [8250/10697 ( 77.1%)] Loss: 0.024644 L1: 0.014292 Grad: 0.103316 Thermal: 0.000415 LR: 8.94e-06\n",
      "Epoch  17 [8250/10697 ( 77.1%)] Loss: 0.024644 L1: 0.014292 Grad: 0.103316 Thermal: 0.000415 LR: 8.94e-06\n",
      "Epoch  17 [8300/10697 ( 77.6%)] Loss: 0.030441 L1: 0.017711 Grad: 0.127025 Thermal: 0.000533 LR: 8.94e-06\n",
      "Epoch  17 [8300/10697 ( 77.6%)] Loss: 0.030441 L1: 0.017711 Grad: 0.127025 Thermal: 0.000533 LR: 8.94e-06\n",
      "Epoch  17 [8350/10697 ( 78.1%)] Loss: 0.017437 L1: 0.009972 Grad: 0.074535 Thermal: 0.000229 LR: 8.94e-06\n",
      "Epoch  17 [8350/10697 ( 78.1%)] Loss: 0.017437 L1: 0.009972 Grad: 0.074535 Thermal: 0.000229 LR: 8.94e-06\n",
      "Epoch  17 [8400/10697 ( 78.5%)] Loss: 0.027674 L1: 0.015826 Grad: 0.118233 Thermal: 0.000494 LR: 8.94e-06\n",
      "Epoch  17 [8400/10697 ( 78.5%)] Loss: 0.027674 L1: 0.015826 Grad: 0.118233 Thermal: 0.000494 LR: 8.94e-06\n",
      "Epoch  17 [8450/10697 ( 79.0%)] Loss: 0.027651 L1: 0.015995 Grad: 0.116320 Thermal: 0.000463 LR: 8.94e-06\n",
      "Epoch  17 [8450/10697 ( 79.0%)] Loss: 0.027651 L1: 0.015995 Grad: 0.116320 Thermal: 0.000463 LR: 8.94e-06\n",
      "Epoch  17 [8500/10697 ( 79.5%)] Loss: 0.026453 L1: 0.015785 Grad: 0.106463 Thermal: 0.000439 LR: 8.94e-06\n",
      "Epoch  17 [8500/10697 ( 79.5%)] Loss: 0.026453 L1: 0.015785 Grad: 0.106463 Thermal: 0.000439 LR: 8.94e-06\n",
      "Epoch  17 [8550/10697 ( 79.9%)] Loss: 0.024283 L1: 0.013781 Grad: 0.104841 Thermal: 0.000352 LR: 8.94e-06\n",
      "Epoch  17 [8550/10697 ( 79.9%)] Loss: 0.024283 L1: 0.013781 Grad: 0.104841 Thermal: 0.000352 LR: 8.94e-06\n",
      "Epoch  17 [8600/10697 ( 80.4%)] Loss: 0.021381 L1: 0.012324 Grad: 0.090401 Thermal: 0.000341 LR: 8.94e-06\n",
      "Epoch  17 [8600/10697 ( 80.4%)] Loss: 0.021381 L1: 0.012324 Grad: 0.090401 Thermal: 0.000341 LR: 8.94e-06\n",
      "Epoch  17 [8650/10697 ( 80.9%)] Loss: 0.032103 L1: 0.018582 Grad: 0.134908 Thermal: 0.000596 LR: 8.94e-06\n",
      "Epoch  17 [8650/10697 ( 80.9%)] Loss: 0.032103 L1: 0.018582 Grad: 0.134908 Thermal: 0.000596 LR: 8.94e-06\n",
      "Epoch  17 [8700/10697 ( 81.3%)] Loss: 0.027225 L1: 0.015778 Grad: 0.114221 Thermal: 0.000501 LR: 8.94e-06\n",
      "Epoch  17 [8700/10697 ( 81.3%)] Loss: 0.027225 L1: 0.015778 Grad: 0.114221 Thermal: 0.000501 LR: 8.94e-06\n",
      "Epoch  17 [8750/10697 ( 81.8%)] Loss: 0.028588 L1: 0.016809 Grad: 0.117537 Thermal: 0.000492 LR: 8.94e-06\n",
      "Epoch  17 [8750/10697 ( 81.8%)] Loss: 0.028588 L1: 0.016809 Grad: 0.117537 Thermal: 0.000492 LR: 8.94e-06\n",
      "Epoch  17 [8800/10697 ( 82.3%)] Loss: 0.029275 L1: 0.017162 Grad: 0.120860 Thermal: 0.000553 LR: 8.94e-06\n",
      "Epoch  17 [8800/10697 ( 82.3%)] Loss: 0.029275 L1: 0.017162 Grad: 0.120860 Thermal: 0.000553 LR: 8.94e-06\n",
      "Epoch  17 [8850/10697 ( 82.7%)] Loss: 0.028307 L1: 0.016169 Grad: 0.121116 Thermal: 0.000536 LR: 8.94e-06\n",
      "Epoch  17 [8850/10697 ( 82.7%)] Loss: 0.028307 L1: 0.016169 Grad: 0.121116 Thermal: 0.000536 LR: 8.94e-06\n",
      "Epoch  17 [8900/10697 ( 83.2%)] Loss: 0.027657 L1: 0.016251 Grad: 0.113813 Thermal: 0.000496 LR: 8.94e-06\n",
      "Epoch  17 [8900/10697 ( 83.2%)] Loss: 0.027657 L1: 0.016251 Grad: 0.113813 Thermal: 0.000496 LR: 8.94e-06\n",
      "Epoch  17 [8950/10697 ( 83.7%)] Loss: 0.033169 L1: 0.019410 Grad: 0.137254 Thermal: 0.000688 LR: 8.94e-06\n",
      "Epoch  17 [8950/10697 ( 83.7%)] Loss: 0.033169 L1: 0.019410 Grad: 0.137254 Thermal: 0.000688 LR: 8.94e-06\n",
      "Epoch  17 [9000/10697 ( 84.1%)] Loss: 0.022035 L1: 0.012838 Grad: 0.091803 Thermal: 0.000346 LR: 8.94e-06\n",
      "Epoch  17 [9000/10697 ( 84.1%)] Loss: 0.022035 L1: 0.012838 Grad: 0.091803 Thermal: 0.000346 LR: 8.94e-06\n",
      "Epoch  17 [9050/10697 ( 84.6%)] Loss: 0.024002 L1: 0.013713 Grad: 0.102697 Thermal: 0.000395 LR: 8.94e-06\n",
      "Epoch  17 [9050/10697 ( 84.6%)] Loss: 0.024002 L1: 0.013713 Grad: 0.102697 Thermal: 0.000395 LR: 8.94e-06\n",
      "Epoch  17 [9100/10697 ( 85.1%)] Loss: 0.031756 L1: 0.018478 Grad: 0.132439 Thermal: 0.000674 LR: 8.94e-06\n",
      "Epoch  17 [9100/10697 ( 85.1%)] Loss: 0.031756 L1: 0.018478 Grad: 0.132439 Thermal: 0.000674 LR: 8.94e-06\n",
      "Epoch  17 [9150/10697 ( 85.5%)] Loss: 0.022528 L1: 0.013237 Grad: 0.092741 Thermal: 0.000350 LR: 8.94e-06\n",
      "Epoch  17 [9150/10697 ( 85.5%)] Loss: 0.022528 L1: 0.013237 Grad: 0.092741 Thermal: 0.000350 LR: 8.94e-06\n",
      "Epoch  17 [9200/10697 ( 86.0%)] Loss: 0.028341 L1: 0.016234 Grad: 0.120801 Thermal: 0.000530 LR: 8.94e-06\n",
      "Epoch  17 [9200/10697 ( 86.0%)] Loss: 0.028341 L1: 0.016234 Grad: 0.120801 Thermal: 0.000530 LR: 8.94e-06\n",
      "Epoch  17 [9250/10697 ( 86.5%)] Loss: 0.028337 L1: 0.016414 Grad: 0.118994 Thermal: 0.000464 LR: 8.94e-06\n",
      "Epoch  17 [9250/10697 ( 86.5%)] Loss: 0.028337 L1: 0.016414 Grad: 0.118994 Thermal: 0.000464 LR: 8.94e-06\n",
      "Epoch  17 [9300/10697 ( 86.9%)] Loss: 0.025796 L1: 0.014549 Grad: 0.112274 Thermal: 0.000385 LR: 8.94e-06\n",
      "Epoch  17 [9300/10697 ( 86.9%)] Loss: 0.025796 L1: 0.014549 Grad: 0.112274 Thermal: 0.000385 LR: 8.94e-06\n",
      "Epoch  17 [9350/10697 ( 87.4%)] Loss: 0.024217 L1: 0.014073 Grad: 0.101238 Thermal: 0.000394 LR: 8.94e-06\n",
      "Epoch  17 [9350/10697 ( 87.4%)] Loss: 0.024217 L1: 0.014073 Grad: 0.101238 Thermal: 0.000394 LR: 8.94e-06\n",
      "Epoch  17 [9400/10697 ( 87.9%)] Loss: 0.023813 L1: 0.014086 Grad: 0.097094 Thermal: 0.000361 LR: 8.94e-06\n",
      "Epoch  17 [9400/10697 ( 87.9%)] Loss: 0.023813 L1: 0.014086 Grad: 0.097094 Thermal: 0.000361 LR: 8.94e-06\n",
      "Epoch  17 [9450/10697 ( 88.3%)] Loss: 0.026140 L1: 0.015131 Grad: 0.109875 Thermal: 0.000429 LR: 8.94e-06\n",
      "Epoch  17 [9450/10697 ( 88.3%)] Loss: 0.026140 L1: 0.015131 Grad: 0.109875 Thermal: 0.000429 LR: 8.94e-06\n",
      "Epoch  17 [9500/10697 ( 88.8%)] Loss: 0.026621 L1: 0.015489 Grad: 0.111072 Thermal: 0.000492 LR: 8.94e-06\n",
      "Epoch  17 [9500/10697 ( 88.8%)] Loss: 0.026621 L1: 0.015489 Grad: 0.111072 Thermal: 0.000492 LR: 8.94e-06\n",
      "Epoch  17 [9550/10697 ( 89.3%)] Loss: 0.026021 L1: 0.015293 Grad: 0.107062 Thermal: 0.000419 LR: 8.94e-06\n",
      "Epoch  17 [9550/10697 ( 89.3%)] Loss: 0.026021 L1: 0.015293 Grad: 0.107062 Thermal: 0.000419 LR: 8.94e-06\n",
      "Epoch  17 [9600/10697 ( 89.7%)] Loss: 0.027260 L1: 0.015836 Grad: 0.114007 Thermal: 0.000461 LR: 8.94e-06\n",
      "Epoch  17 [9600/10697 ( 89.7%)] Loss: 0.027260 L1: 0.015836 Grad: 0.114007 Thermal: 0.000461 LR: 8.94e-06\n",
      "Epoch  17 [9650/10697 ( 90.2%)] Loss: 0.019816 L1: 0.011361 Grad: 0.084412 Thermal: 0.000281 LR: 8.94e-06\n",
      "Epoch  17 [9650/10697 ( 90.2%)] Loss: 0.019816 L1: 0.011361 Grad: 0.084412 Thermal: 0.000281 LR: 8.94e-06\n",
      "Epoch  17 [9700/10697 ( 90.7%)] Loss: 0.027090 L1: 0.015853 Grad: 0.112129 Thermal: 0.000478 LR: 8.94e-06\n",
      "Epoch  17 [9700/10697 ( 90.7%)] Loss: 0.027090 L1: 0.015853 Grad: 0.112129 Thermal: 0.000478 LR: 8.94e-06\n",
      "Epoch  17 [9750/10697 ( 91.1%)] Loss: 0.025471 L1: 0.014662 Grad: 0.107882 Thermal: 0.000420 LR: 8.94e-06\n",
      "Epoch  17 [9750/10697 ( 91.1%)] Loss: 0.025471 L1: 0.014662 Grad: 0.107882 Thermal: 0.000420 LR: 8.94e-06\n",
      "Epoch  17 [9800/10697 ( 91.6%)] Loss: 0.028062 L1: 0.016340 Grad: 0.116980 Thermal: 0.000477 LR: 8.94e-06\n",
      "Epoch  17 [9800/10697 ( 91.6%)] Loss: 0.028062 L1: 0.016340 Grad: 0.116980 Thermal: 0.000477 LR: 8.94e-06\n",
      "Epoch  17 [9850/10697 ( 92.1%)] Loss: 0.025710 L1: 0.014766 Grad: 0.109216 Thermal: 0.000459 LR: 8.94e-06\n",
      "Epoch  17 [9850/10697 ( 92.1%)] Loss: 0.025710 L1: 0.014766 Grad: 0.109216 Thermal: 0.000459 LR: 8.94e-06\n",
      "Epoch  17 [9900/10697 ( 92.5%)] Loss: 0.018556 L1: 0.010550 Grad: 0.079946 Thermal: 0.000230 LR: 8.94e-06\n",
      "Epoch  17 [9900/10697 ( 92.5%)] Loss: 0.018556 L1: 0.010550 Grad: 0.079946 Thermal: 0.000230 LR: 8.94e-06\n",
      "Epoch  17 [9950/10697 ( 93.0%)] Loss: 0.025080 L1: 0.014663 Grad: 0.103939 Thermal: 0.000454 LR: 8.94e-06\n",
      "Epoch  17 [9950/10697 ( 93.0%)] Loss: 0.025080 L1: 0.014663 Grad: 0.103939 Thermal: 0.000454 LR: 8.94e-06\n",
      "Epoch  17 [10000/10697 ( 93.5%)] Loss: 0.018770 L1: 0.010512 Grad: 0.082444 Thermal: 0.000272 LR: 8.94e-06\n",
      "Epoch  17 [10000/10697 ( 93.5%)] Loss: 0.018770 L1: 0.010512 Grad: 0.082444 Thermal: 0.000272 LR: 8.94e-06\n",
      "Epoch  17 [10050/10697 ( 94.0%)] Loss: 0.020296 L1: 0.011873 Grad: 0.084085 Thermal: 0.000297 LR: 8.94e-06\n",
      "Epoch  17 [10050/10697 ( 94.0%)] Loss: 0.020296 L1: 0.011873 Grad: 0.084085 Thermal: 0.000297 LR: 8.94e-06\n",
      "Epoch  17 [10100/10697 ( 94.4%)] Loss: 0.020967 L1: 0.012320 Grad: 0.086312 Thermal: 0.000309 LR: 8.94e-06\n",
      "Epoch  17 [10100/10697 ( 94.4%)] Loss: 0.020967 L1: 0.012320 Grad: 0.086312 Thermal: 0.000309 LR: 8.94e-06\n",
      "Epoch  17 [10150/10697 ( 94.9%)] Loss: 0.029505 L1: 0.017103 Grad: 0.123777 Thermal: 0.000491 LR: 8.94e-06\n",
      "Epoch  17 [10150/10697 ( 94.9%)] Loss: 0.029505 L1: 0.017103 Grad: 0.123777 Thermal: 0.000491 LR: 8.94e-06\n",
      "Epoch  17 [10200/10697 ( 95.4%)] Loss: 0.028740 L1: 0.017188 Grad: 0.115251 Thermal: 0.000527 LR: 8.94e-06\n",
      "Epoch  17 [10200/10697 ( 95.4%)] Loss: 0.028740 L1: 0.017188 Grad: 0.115251 Thermal: 0.000527 LR: 8.94e-06\n",
      "Epoch  17 [10250/10697 ( 95.8%)] Loss: 0.028083 L1: 0.016309 Grad: 0.117467 Thermal: 0.000539 LR: 8.94e-06\n",
      "Epoch  17 [10250/10697 ( 95.8%)] Loss: 0.028083 L1: 0.016309 Grad: 0.117467 Thermal: 0.000539 LR: 8.94e-06\n",
      "Epoch  17 [10300/10697 ( 96.3%)] Loss: 0.023689 L1: 0.013621 Grad: 0.100506 Thermal: 0.000354 LR: 8.94e-06\n",
      "Epoch  17 [10300/10697 ( 96.3%)] Loss: 0.023689 L1: 0.013621 Grad: 0.100506 Thermal: 0.000354 LR: 8.94e-06\n",
      "Epoch  17 [10350/10697 ( 96.8%)] Loss: 0.024817 L1: 0.014675 Grad: 0.101233 Thermal: 0.000382 LR: 8.94e-06\n",
      "Epoch  17 [10350/10697 ( 96.8%)] Loss: 0.024817 L1: 0.014675 Grad: 0.101233 Thermal: 0.000382 LR: 8.94e-06\n",
      "Epoch  17 [10400/10697 ( 97.2%)] Loss: 0.025536 L1: 0.014220 Grad: 0.112943 Thermal: 0.000432 LR: 8.94e-06\n",
      "Epoch  17 [10400/10697 ( 97.2%)] Loss: 0.025536 L1: 0.014220 Grad: 0.112943 Thermal: 0.000432 LR: 8.94e-06\n",
      "Epoch  17 [10450/10697 ( 97.7%)] Loss: 0.023702 L1: 0.013537 Grad: 0.101470 Thermal: 0.000358 LR: 8.94e-06\n",
      "Epoch  17 [10450/10697 ( 97.7%)] Loss: 0.023702 L1: 0.013537 Grad: 0.101470 Thermal: 0.000358 LR: 8.94e-06\n",
      "Epoch  17 [10500/10697 ( 98.2%)] Loss: 0.032389 L1: 0.018916 Grad: 0.134394 Thermal: 0.000663 LR: 8.94e-06\n",
      "Epoch  17 [10500/10697 ( 98.2%)] Loss: 0.032389 L1: 0.018916 Grad: 0.134394 Thermal: 0.000663 LR: 8.94e-06\n",
      "Epoch  17 [10550/10697 ( 98.6%)] Loss: 0.029513 L1: 0.017250 Grad: 0.122358 Thermal: 0.000534 LR: 8.94e-06\n",
      "Epoch  17 [10550/10697 ( 98.6%)] Loss: 0.029513 L1: 0.017250 Grad: 0.122358 Thermal: 0.000534 LR: 8.94e-06\n",
      "Epoch  17 [10600/10697 ( 99.1%)] Loss: 0.028642 L1: 0.016532 Grad: 0.120843 Thermal: 0.000509 LR: 8.94e-06\n",
      "Epoch  17 [10600/10697 ( 99.1%)] Loss: 0.028642 L1: 0.016532 Grad: 0.120843 Thermal: 0.000509 LR: 8.94e-06\n",
      "Epoch  17 [10650/10697 ( 99.6%)] Loss: 0.023563 L1: 0.014036 Grad: 0.095094 Thermal: 0.000360 LR: 8.94e-06\n",
      "Epoch  17 [10650/10697 ( 99.6%)] Loss: 0.023563 L1: 0.014036 Grad: 0.095094 Thermal: 0.000360 LR: 8.94e-06\n",
      "Epoch  17 Summary: Loss=0.026618 (L1:0.0155, Grad:0.1109, Thermal:0.0005) Val_PSNR=0.00dB Best=33.84dB Time=64.6min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  17 Summary: Loss=0.026618 (L1:0.0155, Grad:0.1109, Thermal:0.0005) Val_PSNR=0.00dB Best=33.84dB Time=64.6min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  18 [   0/10697 (  0.0%)] Loss: 0.035539 L1: 0.020080 Grad: 0.154198 Thermal: 0.000779 LR: 8.81e-06\n",
      "Epoch  18 [   0/10697 (  0.0%)] Loss: 0.035539 L1: 0.020080 Grad: 0.154198 Thermal: 0.000779 LR: 8.81e-06\n",
      "Epoch  18 [  50/10697 (  0.5%)] Loss: 0.024157 L1: 0.013708 Grad: 0.104291 Thermal: 0.000411 LR: 8.81e-06\n",
      "Epoch  18 [  50/10697 (  0.5%)] Loss: 0.024157 L1: 0.013708 Grad: 0.104291 Thermal: 0.000411 LR: 8.81e-06\n",
      "Epoch  18 [ 100/10697 (  0.9%)] Loss: 0.024563 L1: 0.014221 Grad: 0.103209 Thermal: 0.000404 LR: 8.81e-06\n",
      "Epoch  18 [ 100/10697 (  0.9%)] Loss: 0.024563 L1: 0.014221 Grad: 0.103209 Thermal: 0.000404 LR: 8.81e-06\n",
      "Epoch  18 [ 150/10697 (  1.4%)] Loss: 0.025850 L1: 0.015450 Grad: 0.103780 Thermal: 0.000432 LR: 8.81e-06\n",
      "Epoch  18 [ 150/10697 (  1.4%)] Loss: 0.025850 L1: 0.015450 Grad: 0.103780 Thermal: 0.000432 LR: 8.81e-06\n",
      "Epoch  18 [ 200/10697 (  1.9%)] Loss: 0.034113 L1: 0.020220 Grad: 0.138580 Thermal: 0.000714 LR: 8.81e-06\n",
      "Epoch  18 [ 200/10697 (  1.9%)] Loss: 0.034113 L1: 0.020220 Grad: 0.138580 Thermal: 0.000714 LR: 8.81e-06\n",
      "Epoch  18 [ 250/10697 (  2.3%)] Loss: 0.026444 L1: 0.015384 Grad: 0.110376 Thermal: 0.000454 LR: 8.81e-06\n",
      "Epoch  18 [ 250/10697 (  2.3%)] Loss: 0.026444 L1: 0.015384 Grad: 0.110376 Thermal: 0.000454 LR: 8.81e-06\n",
      "Epoch  18 [ 300/10697 (  2.8%)] Loss: 0.029106 L1: 0.017325 Grad: 0.117539 Thermal: 0.000537 LR: 8.81e-06\n",
      "Epoch  18 [ 300/10697 (  2.8%)] Loss: 0.029106 L1: 0.017325 Grad: 0.117539 Thermal: 0.000537 LR: 8.81e-06\n",
      "Epoch  18 [ 350/10697 (  3.3%)] Loss: 0.023746 L1: 0.013593 Grad: 0.101327 Thermal: 0.000422 LR: 8.81e-06\n",
      "Epoch  18 [ 350/10697 (  3.3%)] Loss: 0.023746 L1: 0.013593 Grad: 0.101327 Thermal: 0.000422 LR: 8.81e-06\n",
      "Epoch  18 [ 400/10697 (  3.7%)] Loss: 0.031608 L1: 0.018491 Grad: 0.130853 Thermal: 0.000629 LR: 8.81e-06\n",
      "Epoch  18 [ 400/10697 (  3.7%)] Loss: 0.031608 L1: 0.018491 Grad: 0.130853 Thermal: 0.000629 LR: 8.81e-06\n",
      "Epoch  18 [ 450/10697 (  4.2%)] Loss: 0.028404 L1: 0.016521 Grad: 0.118576 Thermal: 0.000507 LR: 8.81e-06\n",
      "Epoch  18 [ 450/10697 (  4.2%)] Loss: 0.028404 L1: 0.016521 Grad: 0.118576 Thermal: 0.000507 LR: 8.81e-06\n",
      "Epoch  18 [ 500/10697 (  4.7%)] Loss: 0.030117 L1: 0.017739 Grad: 0.123477 Thermal: 0.000596 LR: 8.81e-06\n",
      "Epoch  18 [ 500/10697 (  4.7%)] Loss: 0.030117 L1: 0.017739 Grad: 0.123477 Thermal: 0.000596 LR: 8.81e-06\n",
      "Epoch  18 [ 550/10697 (  5.1%)] Loss: 0.031465 L1: 0.018439 Grad: 0.129934 Thermal: 0.000645 LR: 8.81e-06\n",
      "Epoch  18 [ 550/10697 (  5.1%)] Loss: 0.031465 L1: 0.018439 Grad: 0.129934 Thermal: 0.000645 LR: 8.81e-06\n",
      "Epoch  18 [ 600/10697 (  5.6%)] Loss: 0.024821 L1: 0.014647 Grad: 0.101489 Thermal: 0.000508 LR: 8.81e-06\n",
      "Epoch  18 [ 600/10697 (  5.6%)] Loss: 0.024821 L1: 0.014647 Grad: 0.101489 Thermal: 0.000508 LR: 8.81e-06\n",
      "Epoch  18 [ 650/10697 (  6.1%)] Loss: 0.032013 L1: 0.018441 Grad: 0.135424 Thermal: 0.000585 LR: 8.81e-06\n",
      "Epoch  18 [ 650/10697 (  6.1%)] Loss: 0.032013 L1: 0.018441 Grad: 0.135424 Thermal: 0.000585 LR: 8.81e-06\n",
      "Epoch  18 [ 700/10697 (  6.5%)] Loss: 0.029749 L1: 0.017149 Grad: 0.125662 Thermal: 0.000664 LR: 8.81e-06\n",
      "Epoch  18 [ 700/10697 (  6.5%)] Loss: 0.029749 L1: 0.017149 Grad: 0.125662 Thermal: 0.000664 LR: 8.81e-06\n",
      "Epoch  18 [ 750/10697 (  7.0%)] Loss: 0.028014 L1: 0.016400 Grad: 0.115881 Thermal: 0.000516 LR: 8.81e-06\n",
      "Epoch  18 [ 750/10697 (  7.0%)] Loss: 0.028014 L1: 0.016400 Grad: 0.115881 Thermal: 0.000516 LR: 8.81e-06\n",
      "Epoch  18 [ 800/10697 (  7.5%)] Loss: 0.027827 L1: 0.016199 Grad: 0.116043 Thermal: 0.000475 LR: 8.81e-06\n",
      "Epoch  18 [ 800/10697 (  7.5%)] Loss: 0.027827 L1: 0.016199 Grad: 0.116043 Thermal: 0.000475 LR: 8.81e-06\n",
      "Epoch  18 [ 850/10697 (  7.9%)] Loss: 0.026456 L1: 0.015459 Grad: 0.109747 Thermal: 0.000431 LR: 8.81e-06\n",
      "Epoch  18 [ 850/10697 (  7.9%)] Loss: 0.026456 L1: 0.015459 Grad: 0.109747 Thermal: 0.000431 LR: 8.81e-06\n",
      "Epoch  18 [ 900/10697 (  8.4%)] Loss: 0.025764 L1: 0.015286 Grad: 0.104576 Thermal: 0.000419 LR: 8.81e-06\n",
      "Epoch  18 [ 900/10697 (  8.4%)] Loss: 0.025764 L1: 0.015286 Grad: 0.104576 Thermal: 0.000419 LR: 8.81e-06\n",
      "Epoch  18 [ 950/10697 (  8.9%)] Loss: 0.025174 L1: 0.015115 Grad: 0.100377 Thermal: 0.000426 LR: 8.81e-06\n",
      "Epoch  18 [ 950/10697 (  8.9%)] Loss: 0.025174 L1: 0.015115 Grad: 0.100377 Thermal: 0.000426 LR: 8.81e-06\n",
      "Epoch  18 [1000/10697 (  9.3%)] Loss: 0.037355 L1: 0.021699 Grad: 0.156127 Thermal: 0.000857 LR: 8.81e-06\n",
      "Epoch  18 [1000/10697 (  9.3%)] Loss: 0.037355 L1: 0.021699 Grad: 0.156127 Thermal: 0.000857 LR: 8.81e-06\n",
      "Epoch  18 [1050/10697 (  9.8%)] Loss: 0.026939 L1: 0.015916 Grad: 0.109982 Thermal: 0.000486 LR: 8.81e-06\n",
      "Epoch  18 [1050/10697 (  9.8%)] Loss: 0.026939 L1: 0.015916 Grad: 0.109982 Thermal: 0.000486 LR: 8.81e-06\n",
      "Epoch  18 [1100/10697 ( 10.3%)] Loss: 0.028317 L1: 0.016692 Grad: 0.115994 Thermal: 0.000517 LR: 8.81e-06\n",
      "Epoch  18 [1100/10697 ( 10.3%)] Loss: 0.028317 L1: 0.016692 Grad: 0.115994 Thermal: 0.000517 LR: 8.81e-06\n",
      "Epoch  18 [1150/10697 ( 10.8%)] Loss: 0.027381 L1: 0.016298 Grad: 0.110599 Thermal: 0.000466 LR: 8.81e-06\n",
      "Epoch  18 [1150/10697 ( 10.8%)] Loss: 0.027381 L1: 0.016298 Grad: 0.110599 Thermal: 0.000466 LR: 8.81e-06\n",
      "Epoch  18 [1200/10697 ( 11.2%)] Loss: 0.026045 L1: 0.015399 Grad: 0.106242 Thermal: 0.000443 LR: 8.81e-06\n",
      "Epoch  18 [1200/10697 ( 11.2%)] Loss: 0.026045 L1: 0.015399 Grad: 0.106242 Thermal: 0.000443 LR: 8.81e-06\n",
      "Epoch  18 [1250/10697 ( 11.7%)] Loss: 0.028989 L1: 0.017000 Grad: 0.119639 Thermal: 0.000484 LR: 8.81e-06\n",
      "Epoch  18 [1250/10697 ( 11.7%)] Loss: 0.028989 L1: 0.017000 Grad: 0.119639 Thermal: 0.000484 LR: 8.81e-06\n",
      "Epoch  18 [1300/10697 ( 12.2%)] Loss: 0.022999 L1: 0.013396 Grad: 0.095864 Thermal: 0.000334 LR: 8.81e-06\n",
      "Epoch  18 [1300/10697 ( 12.2%)] Loss: 0.022999 L1: 0.013396 Grad: 0.095864 Thermal: 0.000334 LR: 8.81e-06\n",
      "Epoch  18 [1350/10697 ( 12.6%)] Loss: 0.027525 L1: 0.015660 Grad: 0.118403 Thermal: 0.000503 LR: 8.81e-06\n",
      "Epoch  18 [1350/10697 ( 12.6%)] Loss: 0.027525 L1: 0.015660 Grad: 0.118403 Thermal: 0.000503 LR: 8.81e-06\n",
      "Epoch  18 [1400/10697 ( 13.1%)] Loss: 0.033582 L1: 0.019099 Grad: 0.144492 Thermal: 0.000687 LR: 8.81e-06\n",
      "Epoch  18 [1400/10697 ( 13.1%)] Loss: 0.033582 L1: 0.019099 Grad: 0.144492 Thermal: 0.000687 LR: 8.81e-06\n",
      "Epoch  18 [1450/10697 ( 13.6%)] Loss: 0.023219 L1: 0.013449 Grad: 0.097529 Thermal: 0.000352 LR: 8.81e-06\n",
      "Epoch  18 [1450/10697 ( 13.6%)] Loss: 0.023219 L1: 0.013449 Grad: 0.097529 Thermal: 0.000352 LR: 8.81e-06\n",
      "Epoch  18 [1500/10697 ( 14.0%)] Loss: 0.023489 L1: 0.013762 Grad: 0.097098 Thermal: 0.000357 LR: 8.81e-06\n",
      "Epoch  18 [1500/10697 ( 14.0%)] Loss: 0.023489 L1: 0.013762 Grad: 0.097098 Thermal: 0.000357 LR: 8.81e-06\n",
      "Epoch  18 [1550/10697 ( 14.5%)] Loss: 0.028509 L1: 0.016149 Grad: 0.123320 Thermal: 0.000565 LR: 8.81e-06\n",
      "Epoch  18 [1550/10697 ( 14.5%)] Loss: 0.028509 L1: 0.016149 Grad: 0.123320 Thermal: 0.000565 LR: 8.81e-06\n",
      "Epoch  18 [1600/10697 ( 15.0%)] Loss: 0.025649 L1: 0.014877 Grad: 0.107502 Thermal: 0.000441 LR: 8.81e-06\n",
      "Epoch  18 [1600/10697 ( 15.0%)] Loss: 0.025649 L1: 0.014877 Grad: 0.107502 Thermal: 0.000441 LR: 8.81e-06\n",
      "Epoch  18 [1650/10697 ( 15.4%)] Loss: 0.028063 L1: 0.016799 Grad: 0.112378 Thermal: 0.000524 LR: 8.81e-06\n",
      "Epoch  18 [1650/10697 ( 15.4%)] Loss: 0.028063 L1: 0.016799 Grad: 0.112378 Thermal: 0.000524 LR: 8.81e-06\n",
      "Epoch  18 [1700/10697 ( 15.9%)] Loss: 0.021718 L1: 0.012539 Grad: 0.091626 Thermal: 0.000318 LR: 8.81e-06\n",
      "Epoch  18 [1700/10697 ( 15.9%)] Loss: 0.021718 L1: 0.012539 Grad: 0.091626 Thermal: 0.000318 LR: 8.81e-06\n",
      "Epoch  18 [1750/10697 ( 16.4%)] Loss: 0.022782 L1: 0.013254 Grad: 0.095096 Thermal: 0.000371 LR: 8.81e-06\n",
      "Epoch  18 [1750/10697 ( 16.4%)] Loss: 0.022782 L1: 0.013254 Grad: 0.095096 Thermal: 0.000371 LR: 8.81e-06\n",
      "Epoch  18 [1800/10697 ( 16.8%)] Loss: 0.021783 L1: 0.012305 Grad: 0.094598 Thermal: 0.000351 LR: 8.81e-06\n",
      "Epoch  18 [1800/10697 ( 16.8%)] Loss: 0.021783 L1: 0.012305 Grad: 0.094598 Thermal: 0.000351 LR: 8.81e-06\n",
      "Epoch  18 [1850/10697 ( 17.3%)] Loss: 0.023822 L1: 0.013852 Grad: 0.099503 Thermal: 0.000381 LR: 8.81e-06\n",
      "Epoch  18 [1850/10697 ( 17.3%)] Loss: 0.023822 L1: 0.013852 Grad: 0.099503 Thermal: 0.000381 LR: 8.81e-06\n",
      "Epoch  18 [1900/10697 ( 17.8%)] Loss: 0.029975 L1: 0.017725 Grad: 0.122188 Thermal: 0.000622 LR: 8.81e-06\n",
      "Epoch  18 [1900/10697 ( 17.8%)] Loss: 0.029975 L1: 0.017725 Grad: 0.122188 Thermal: 0.000622 LR: 8.81e-06\n",
      "Epoch  18 [1950/10697 ( 18.2%)] Loss: 0.026705 L1: 0.015896 Grad: 0.107869 Thermal: 0.000443 LR: 8.81e-06\n",
      "Epoch  18 [1950/10697 ( 18.2%)] Loss: 0.026705 L1: 0.015896 Grad: 0.107869 Thermal: 0.000443 LR: 8.81e-06\n",
      "Epoch  18 [2000/10697 ( 18.7%)] Loss: 0.022850 L1: 0.013285 Grad: 0.095460 Thermal: 0.000382 LR: 8.81e-06\n",
      "Epoch  18 [2000/10697 ( 18.7%)] Loss: 0.022850 L1: 0.013285 Grad: 0.095460 Thermal: 0.000382 LR: 8.81e-06\n",
      "Epoch  18 [2050/10697 ( 19.2%)] Loss: 0.028462 L1: 0.016182 Grad: 0.122545 Thermal: 0.000508 LR: 8.81e-06\n",
      "Epoch  18 [2050/10697 ( 19.2%)] Loss: 0.028462 L1: 0.016182 Grad: 0.122545 Thermal: 0.000508 LR: 8.81e-06\n",
      "Epoch  18 [2100/10697 ( 19.6%)] Loss: 0.022704 L1: 0.013080 Grad: 0.096066 Thermal: 0.000340 LR: 8.81e-06\n",
      "Epoch  18 [2100/10697 ( 19.6%)] Loss: 0.022704 L1: 0.013080 Grad: 0.096066 Thermal: 0.000340 LR: 8.81e-06\n",
      "Epoch  18 [2150/10697 ( 20.1%)] Loss: 0.024319 L1: 0.014282 Grad: 0.100170 Thermal: 0.000395 LR: 8.81e-06\n",
      "Epoch  18 [2150/10697 ( 20.1%)] Loss: 0.024319 L1: 0.014282 Grad: 0.100170 Thermal: 0.000395 LR: 8.81e-06\n",
      "Epoch  18 [2200/10697 ( 20.6%)] Loss: 0.022295 L1: 0.012761 Grad: 0.095162 Thermal: 0.000351 LR: 8.81e-06\n",
      "Epoch  18 [2200/10697 ( 20.6%)] Loss: 0.022295 L1: 0.012761 Grad: 0.095162 Thermal: 0.000351 LR: 8.81e-06\n",
      "Epoch  18 [2250/10697 ( 21.0%)] Loss: 0.021875 L1: 0.012744 Grad: 0.091130 Thermal: 0.000343 LR: 8.81e-06\n",
      "Epoch  18 [2250/10697 ( 21.0%)] Loss: 0.021875 L1: 0.012744 Grad: 0.091130 Thermal: 0.000343 LR: 8.81e-06\n",
      "Epoch  18 [2300/10697 ( 21.5%)] Loss: 0.020636 L1: 0.012101 Grad: 0.085196 Thermal: 0.000316 LR: 8.81e-06\n",
      "Epoch  18 [2300/10697 ( 21.5%)] Loss: 0.020636 L1: 0.012101 Grad: 0.085196 Thermal: 0.000316 LR: 8.81e-06\n",
      "Epoch  18 [2350/10697 ( 22.0%)] Loss: 0.028160 L1: 0.016360 Grad: 0.117761 Thermal: 0.000487 LR: 8.81e-06\n",
      "Epoch  18 [2350/10697 ( 22.0%)] Loss: 0.028160 L1: 0.016360 Grad: 0.117761 Thermal: 0.000487 LR: 8.81e-06\n",
      "Epoch  18 [2400/10697 ( 22.4%)] Loss: 0.033404 L1: 0.019136 Grad: 0.142328 Thermal: 0.000703 LR: 8.81e-06\n",
      "Epoch  18 [2400/10697 ( 22.4%)] Loss: 0.033404 L1: 0.019136 Grad: 0.142328 Thermal: 0.000703 LR: 8.81e-06\n",
      "Epoch  18 [2450/10697 ( 22.9%)] Loss: 0.027144 L1: 0.015495 Grad: 0.116252 Thermal: 0.000482 LR: 8.81e-06\n",
      "Epoch  18 [2450/10697 ( 22.9%)] Loss: 0.027144 L1: 0.015495 Grad: 0.116252 Thermal: 0.000482 LR: 8.81e-06\n",
      "Epoch  18 [2500/10697 ( 23.4%)] Loss: 0.026404 L1: 0.015333 Grad: 0.110494 Thermal: 0.000423 LR: 8.81e-06\n",
      "Epoch  18 [2500/10697 ( 23.4%)] Loss: 0.026404 L1: 0.015333 Grad: 0.110494 Thermal: 0.000423 LR: 8.81e-06\n",
      "Epoch  18 [2550/10697 ( 23.8%)] Loss: 0.026371 L1: 0.015240 Grad: 0.111109 Thermal: 0.000416 LR: 8.81e-06\n",
      "Epoch  18 [2550/10697 ( 23.8%)] Loss: 0.026371 L1: 0.015240 Grad: 0.111109 Thermal: 0.000416 LR: 8.81e-06\n",
      "Epoch  18 [2600/10697 ( 24.3%)] Loss: 0.027307 L1: 0.015791 Grad: 0.114925 Thermal: 0.000484 LR: 8.81e-06\n",
      "Epoch  18 [2600/10697 ( 24.3%)] Loss: 0.027307 L1: 0.015791 Grad: 0.114925 Thermal: 0.000484 LR: 8.81e-06\n",
      "Epoch  18 [2650/10697 ( 24.8%)] Loss: 0.031923 L1: 0.017966 Grad: 0.139277 Thermal: 0.000598 LR: 8.81e-06\n",
      "Epoch  18 [2650/10697 ( 24.8%)] Loss: 0.031923 L1: 0.017966 Grad: 0.139277 Thermal: 0.000598 LR: 8.81e-06\n",
      "Epoch  18 [2700/10697 ( 25.2%)] Loss: 0.030788 L1: 0.017893 Grad: 0.128658 Thermal: 0.000599 LR: 8.81e-06\n",
      "Epoch  18 [2700/10697 ( 25.2%)] Loss: 0.030788 L1: 0.017893 Grad: 0.128658 Thermal: 0.000599 LR: 8.81e-06\n",
      "Epoch  18 [2750/10697 ( 25.7%)] Loss: 0.032672 L1: 0.018921 Grad: 0.137193 Thermal: 0.000627 LR: 8.81e-06\n",
      "Epoch  18 [2750/10697 ( 25.7%)] Loss: 0.032672 L1: 0.018921 Grad: 0.137193 Thermal: 0.000627 LR: 8.81e-06\n",
      "Epoch  18 [2800/10697 ( 26.2%)] Loss: 0.028164 L1: 0.016597 Grad: 0.115425 Thermal: 0.000476 LR: 8.81e-06\n",
      "Epoch  18 [2800/10697 ( 26.2%)] Loss: 0.028164 L1: 0.016597 Grad: 0.115425 Thermal: 0.000476 LR: 8.81e-06\n",
      "Epoch  18 [2850/10697 ( 26.6%)] Loss: 0.028138 L1: 0.016293 Grad: 0.118213 Thermal: 0.000475 LR: 8.81e-06\n",
      "Epoch  18 [2850/10697 ( 26.6%)] Loss: 0.028138 L1: 0.016293 Grad: 0.118213 Thermal: 0.000475 LR: 8.81e-06\n",
      "Epoch  18 [2900/10697 ( 27.1%)] Loss: 0.029207 L1: 0.017330 Grad: 0.118508 Thermal: 0.000522 LR: 8.81e-06\n",
      "Epoch  18 [2900/10697 ( 27.1%)] Loss: 0.029207 L1: 0.017330 Grad: 0.118508 Thermal: 0.000522 LR: 8.81e-06\n",
      "Epoch  18 [2950/10697 ( 27.6%)] Loss: 0.020557 L1: 0.011625 Grad: 0.089167 Thermal: 0.000310 LR: 8.81e-06\n",
      "Epoch  18 [2950/10697 ( 27.6%)] Loss: 0.020557 L1: 0.011625 Grad: 0.089167 Thermal: 0.000310 LR: 8.81e-06\n",
      "Epoch  18 [3000/10697 ( 28.0%)] Loss: 0.025861 L1: 0.015106 Grad: 0.107327 Thermal: 0.000432 LR: 8.81e-06\n",
      "Epoch  18 [3000/10697 ( 28.0%)] Loss: 0.025861 L1: 0.015106 Grad: 0.107327 Thermal: 0.000432 LR: 8.81e-06\n",
      "Epoch  18 [3050/10697 ( 28.5%)] Loss: 0.029047 L1: 0.016891 Grad: 0.121290 Thermal: 0.000530 LR: 8.81e-06\n",
      "Epoch  18 [3050/10697 ( 28.5%)] Loss: 0.029047 L1: 0.016891 Grad: 0.121290 Thermal: 0.000530 LR: 8.81e-06\n",
      "Epoch  18 [3100/10697 ( 29.0%)] Loss: 0.030970 L1: 0.017994 Grad: 0.129464 Thermal: 0.000592 LR: 8.81e-06\n",
      "Epoch  18 [3100/10697 ( 29.0%)] Loss: 0.030970 L1: 0.017994 Grad: 0.129464 Thermal: 0.000592 LR: 8.81e-06\n",
      "Epoch  18 [3150/10697 ( 29.4%)] Loss: 0.025705 L1: 0.015201 Grad: 0.104839 Thermal: 0.000405 LR: 8.81e-06\n",
      "Epoch  18 [3150/10697 ( 29.4%)] Loss: 0.025705 L1: 0.015201 Grad: 0.104839 Thermal: 0.000405 LR: 8.81e-06\n",
      "Epoch  18 [3200/10697 ( 29.9%)] Loss: 0.020120 L1: 0.011384 Grad: 0.087232 Thermal: 0.000265 LR: 8.81e-06\n",
      "Epoch  18 [3200/10697 ( 29.9%)] Loss: 0.020120 L1: 0.011384 Grad: 0.087232 Thermal: 0.000265 LR: 8.81e-06\n",
      "Epoch  18 [3250/10697 ( 30.4%)] Loss: 0.025229 L1: 0.014869 Grad: 0.103403 Thermal: 0.000404 LR: 8.81e-06\n",
      "Epoch  18 [3250/10697 ( 30.4%)] Loss: 0.025229 L1: 0.014869 Grad: 0.103403 Thermal: 0.000404 LR: 8.81e-06\n",
      "Epoch  18 [3300/10697 ( 30.8%)] Loss: 0.026022 L1: 0.015293 Grad: 0.107087 Thermal: 0.000418 LR: 8.81e-06\n",
      "Epoch  18 [3300/10697 ( 30.8%)] Loss: 0.026022 L1: 0.015293 Grad: 0.107087 Thermal: 0.000418 LR: 8.81e-06\n",
      "Epoch  18 [3350/10697 ( 31.3%)] Loss: 0.027259 L1: 0.016097 Grad: 0.111340 Thermal: 0.000551 LR: 8.81e-06\n",
      "Epoch  18 [3350/10697 ( 31.3%)] Loss: 0.027259 L1: 0.016097 Grad: 0.111340 Thermal: 0.000551 LR: 8.81e-06\n",
      "Epoch  18 [3400/10697 ( 31.8%)] Loss: 0.024819 L1: 0.014474 Grad: 0.103234 Thermal: 0.000430 LR: 8.81e-06\n",
      "Epoch  18 [3400/10697 ( 31.8%)] Loss: 0.024819 L1: 0.014474 Grad: 0.103234 Thermal: 0.000430 LR: 8.81e-06\n",
      "Epoch  18 [3450/10697 ( 32.3%)] Loss: 0.030518 L1: 0.017807 Grad: 0.126834 Thermal: 0.000566 LR: 8.81e-06\n",
      "Epoch  18 [3450/10697 ( 32.3%)] Loss: 0.030518 L1: 0.017807 Grad: 0.126834 Thermal: 0.000566 LR: 8.81e-06\n",
      "Epoch  18 [3500/10697 ( 32.7%)] Loss: 0.024445 L1: 0.014203 Grad: 0.102230 Thermal: 0.000382 LR: 8.81e-06\n",
      "Epoch  18 [3500/10697 ( 32.7%)] Loss: 0.024445 L1: 0.014203 Grad: 0.102230 Thermal: 0.000382 LR: 8.81e-06\n",
      "Epoch  18 [3550/10697 ( 33.2%)] Loss: 0.033569 L1: 0.018936 Grad: 0.145995 Thermal: 0.000671 LR: 8.81e-06\n",
      "Epoch  18 [3550/10697 ( 33.2%)] Loss: 0.033569 L1: 0.018936 Grad: 0.145995 Thermal: 0.000671 LR: 8.81e-06\n",
      "Epoch  18 [3600/10697 ( 33.7%)] Loss: 0.026647 L1: 0.016245 Grad: 0.103793 Thermal: 0.000454 LR: 8.81e-06\n",
      "Epoch  18 [3600/10697 ( 33.7%)] Loss: 0.026647 L1: 0.016245 Grad: 0.103793 Thermal: 0.000454 LR: 8.81e-06\n",
      "Epoch  18 [3650/10697 ( 34.1%)] Loss: 0.030413 L1: 0.017467 Grad: 0.129155 Thermal: 0.000615 LR: 8.81e-06\n",
      "Epoch  18 [3650/10697 ( 34.1%)] Loss: 0.030413 L1: 0.017467 Grad: 0.129155 Thermal: 0.000615 LR: 8.81e-06\n",
      "Epoch  18 [3700/10697 ( 34.6%)] Loss: 0.029154 L1: 0.016729 Grad: 0.123968 Thermal: 0.000556 LR: 8.81e-06\n",
      "Epoch  18 [3700/10697 ( 34.6%)] Loss: 0.029154 L1: 0.016729 Grad: 0.123968 Thermal: 0.000556 LR: 8.81e-06\n",
      "Epoch  18 [3750/10697 ( 35.1%)] Loss: 0.024334 L1: 0.014350 Grad: 0.099645 Thermal: 0.000389 LR: 8.81e-06\n",
      "Epoch  18 [3750/10697 ( 35.1%)] Loss: 0.024334 L1: 0.014350 Grad: 0.099645 Thermal: 0.000389 LR: 8.81e-06\n",
      "Epoch  18 [3800/10697 ( 35.5%)] Loss: 0.022763 L1: 0.013074 Grad: 0.096745 Thermal: 0.000302 LR: 8.81e-06\n",
      "Epoch  18 [3800/10697 ( 35.5%)] Loss: 0.022763 L1: 0.013074 Grad: 0.096745 Thermal: 0.000302 LR: 8.81e-06\n",
      "Epoch  18 [3850/10697 ( 36.0%)] Loss: 0.024967 L1: 0.014773 Grad: 0.101716 Thermal: 0.000444 LR: 8.81e-06\n",
      "Epoch  18 [3850/10697 ( 36.0%)] Loss: 0.024967 L1: 0.014773 Grad: 0.101716 Thermal: 0.000444 LR: 8.81e-06\n",
      "Epoch  18 [3900/10697 ( 36.5%)] Loss: 0.024438 L1: 0.014474 Grad: 0.099405 Thermal: 0.000469 LR: 8.81e-06\n",
      "Epoch  18 [3900/10697 ( 36.5%)] Loss: 0.024438 L1: 0.014474 Grad: 0.099405 Thermal: 0.000469 LR: 8.81e-06\n",
      "Epoch  18 [3950/10697 ( 36.9%)] Loss: 0.029234 L1: 0.017306 Grad: 0.119002 Thermal: 0.000542 LR: 8.81e-06\n",
      "Epoch  18 [3950/10697 ( 36.9%)] Loss: 0.029234 L1: 0.017306 Grad: 0.119002 Thermal: 0.000542 LR: 8.81e-06\n",
      "Epoch  18 [4000/10697 ( 37.4%)] Loss: 0.026284 L1: 0.015478 Grad: 0.107837 Thermal: 0.000439 LR: 8.81e-06\n",
      "Epoch  18 [4000/10697 ( 37.4%)] Loss: 0.026284 L1: 0.015478 Grad: 0.107837 Thermal: 0.000439 LR: 8.81e-06\n",
      "Epoch  18 [4050/10697 ( 37.9%)] Loss: 0.028135 L1: 0.016022 Grad: 0.120881 Thermal: 0.000497 LR: 8.81e-06\n",
      "Epoch  18 [4050/10697 ( 37.9%)] Loss: 0.028135 L1: 0.016022 Grad: 0.120881 Thermal: 0.000497 LR: 8.81e-06\n",
      "Epoch  18 [4100/10697 ( 38.3%)] Loss: 0.029794 L1: 0.017371 Grad: 0.123924 Thermal: 0.000618 LR: 8.81e-06\n",
      "Epoch  18 [4100/10697 ( 38.3%)] Loss: 0.029794 L1: 0.017371 Grad: 0.123924 Thermal: 0.000618 LR: 8.81e-06\n",
      "Epoch  18 [4150/10697 ( 38.8%)] Loss: 0.028903 L1: 0.017077 Grad: 0.117996 Thermal: 0.000527 LR: 8.81e-06\n",
      "Epoch  18 [4150/10697 ( 38.8%)] Loss: 0.028903 L1: 0.017077 Grad: 0.117996 Thermal: 0.000527 LR: 8.81e-06\n",
      "Epoch  18 [4200/10697 ( 39.3%)] Loss: 0.024608 L1: 0.014258 Grad: 0.103301 Thermal: 0.000390 LR: 8.81e-06\n",
      "Epoch  18 [4200/10697 ( 39.3%)] Loss: 0.024608 L1: 0.014258 Grad: 0.103301 Thermal: 0.000390 LR: 8.81e-06\n",
      "Epoch  18 [4250/10697 ( 39.7%)] Loss: 0.026513 L1: 0.014788 Grad: 0.117044 Thermal: 0.000420 LR: 8.81e-06\n",
      "Epoch  18 [4250/10697 ( 39.7%)] Loss: 0.026513 L1: 0.014788 Grad: 0.117044 Thermal: 0.000420 LR: 8.81e-06\n",
      "Epoch  18 [4300/10697 ( 40.2%)] Loss: 0.026653 L1: 0.015463 Grad: 0.111652 Thermal: 0.000487 LR: 8.81e-06\n",
      "Epoch  18 [4300/10697 ( 40.2%)] Loss: 0.026653 L1: 0.015463 Grad: 0.111652 Thermal: 0.000487 LR: 8.81e-06\n",
      "Epoch  18 [4350/10697 ( 40.7%)] Loss: 0.026755 L1: 0.015725 Grad: 0.110075 Thermal: 0.000458 LR: 8.81e-06\n",
      "Epoch  18 [4350/10697 ( 40.7%)] Loss: 0.026755 L1: 0.015725 Grad: 0.110075 Thermal: 0.000458 LR: 8.81e-06\n",
      "Epoch  18 [4400/10697 ( 41.1%)] Loss: 0.028759 L1: 0.016800 Grad: 0.119342 Thermal: 0.000497 LR: 8.81e-06\n",
      "Epoch  18 [4400/10697 ( 41.1%)] Loss: 0.028759 L1: 0.016800 Grad: 0.119342 Thermal: 0.000497 LR: 8.81e-06\n",
      "Epoch  18 [4450/10697 ( 41.6%)] Loss: 0.022974 L1: 0.013029 Grad: 0.099242 Thermal: 0.000409 LR: 8.81e-06\n",
      "Epoch  18 [4450/10697 ( 41.6%)] Loss: 0.022974 L1: 0.013029 Grad: 0.099242 Thermal: 0.000409 LR: 8.81e-06\n",
      "Epoch  18 [4500/10697 ( 42.1%)] Loss: 0.031117 L1: 0.017276 Grad: 0.138123 Thermal: 0.000576 LR: 8.81e-06\n",
      "Epoch  18 [4500/10697 ( 42.1%)] Loss: 0.031117 L1: 0.017276 Grad: 0.138123 Thermal: 0.000576 LR: 8.81e-06\n",
      "Epoch  18 [4550/10697 ( 42.5%)] Loss: 0.023524 L1: 0.013659 Grad: 0.098474 Thermal: 0.000358 LR: 8.81e-06\n",
      "Epoch  18 [4550/10697 ( 42.5%)] Loss: 0.023524 L1: 0.013659 Grad: 0.098474 Thermal: 0.000358 LR: 8.81e-06\n",
      "Epoch  18 [4600/10697 ( 43.0%)] Loss: 0.025090 L1: 0.014978 Grad: 0.100921 Thermal: 0.000411 LR: 8.81e-06\n",
      "Epoch  18 [4600/10697 ( 43.0%)] Loss: 0.025090 L1: 0.014978 Grad: 0.100921 Thermal: 0.000411 LR: 8.81e-06\n",
      "Epoch  18 [4650/10697 ( 43.5%)] Loss: 0.021325 L1: 0.012410 Grad: 0.088984 Thermal: 0.000327 LR: 8.81e-06\n",
      "Epoch  18 [4650/10697 ( 43.5%)] Loss: 0.021325 L1: 0.012410 Grad: 0.088984 Thermal: 0.000327 LR: 8.81e-06\n",
      "Epoch  18 [4700/10697 ( 43.9%)] Loss: 0.018478 L1: 0.010726 Grad: 0.077368 Thermal: 0.000289 LR: 8.81e-06\n",
      "Epoch  18 [4700/10697 ( 43.9%)] Loss: 0.018478 L1: 0.010726 Grad: 0.077368 Thermal: 0.000289 LR: 8.81e-06\n",
      "Epoch  18 [4750/10697 ( 44.4%)] Loss: 0.027234 L1: 0.015839 Grad: 0.113710 Thermal: 0.000476 LR: 8.81e-06\n",
      "Epoch  18 [4750/10697 ( 44.4%)] Loss: 0.027234 L1: 0.015839 Grad: 0.113710 Thermal: 0.000476 LR: 8.81e-06\n",
      "Epoch  18 [4800/10697 ( 44.9%)] Loss: 0.026198 L1: 0.015063 Grad: 0.111141 Thermal: 0.000422 LR: 8.81e-06\n",
      "Epoch  18 [4800/10697 ( 44.9%)] Loss: 0.026198 L1: 0.015063 Grad: 0.111141 Thermal: 0.000422 LR: 8.81e-06\n",
      "Epoch  18 [4850/10697 ( 45.3%)] Loss: 0.025439 L1: 0.014992 Grad: 0.104252 Thermal: 0.000434 LR: 8.81e-06\n",
      "Epoch  18 [4850/10697 ( 45.3%)] Loss: 0.025439 L1: 0.014992 Grad: 0.104252 Thermal: 0.000434 LR: 8.81e-06\n",
      "Epoch  18 [4900/10697 ( 45.8%)] Loss: 0.020167 L1: 0.011522 Grad: 0.086313 Thermal: 0.000272 LR: 8.81e-06\n",
      "Epoch  18 [4900/10697 ( 45.8%)] Loss: 0.020167 L1: 0.011522 Grad: 0.086313 Thermal: 0.000272 LR: 8.81e-06\n",
      "Epoch  18 [4950/10697 ( 46.3%)] Loss: 0.030191 L1: 0.017547 Grad: 0.126161 Thermal: 0.000571 LR: 8.81e-06\n",
      "Epoch  18 [4950/10697 ( 46.3%)] Loss: 0.030191 L1: 0.017547 Grad: 0.126161 Thermal: 0.000571 LR: 8.81e-06\n",
      "Epoch  18 [5000/10697 ( 46.7%)] Loss: 0.030037 L1: 0.017282 Grad: 0.127255 Thermal: 0.000579 LR: 8.81e-06\n",
      "Epoch  18 [5000/10697 ( 46.7%)] Loss: 0.030037 L1: 0.017282 Grad: 0.127255 Thermal: 0.000579 LR: 8.81e-06\n",
      "Epoch  18 [5050/10697 ( 47.2%)] Loss: 0.025446 L1: 0.014875 Grad: 0.105509 Thermal: 0.000403 LR: 8.81e-06\n",
      "Epoch  18 [5050/10697 ( 47.2%)] Loss: 0.025446 L1: 0.014875 Grad: 0.105509 Thermal: 0.000403 LR: 8.81e-06\n",
      "Epoch  18 [5100/10697 ( 47.7%)] Loss: 0.026211 L1: 0.015302 Grad: 0.108863 Thermal: 0.000444 LR: 8.81e-06\n",
      "Epoch  18 [5100/10697 ( 47.7%)] Loss: 0.026211 L1: 0.015302 Grad: 0.108863 Thermal: 0.000444 LR: 8.81e-06\n",
      "Epoch  18 [5150/10697 ( 48.1%)] Loss: 0.025062 L1: 0.014992 Grad: 0.100499 Thermal: 0.000406 LR: 8.81e-06\n",
      "Epoch  18 [5150/10697 ( 48.1%)] Loss: 0.025062 L1: 0.014992 Grad: 0.100499 Thermal: 0.000406 LR: 8.81e-06\n",
      "Epoch  18 [5200/10697 ( 48.6%)] Loss: 0.027639 L1: 0.016057 Grad: 0.115576 Thermal: 0.000489 LR: 8.81e-06\n",
      "Epoch  18 [5200/10697 ( 48.6%)] Loss: 0.027639 L1: 0.016057 Grad: 0.115576 Thermal: 0.000489 LR: 8.81e-06\n",
      "Epoch  18 [5250/10697 ( 49.1%)] Loss: 0.023391 L1: 0.014110 Grad: 0.092616 Thermal: 0.000390 LR: 8.81e-06\n",
      "Epoch  18 [5250/10697 ( 49.1%)] Loss: 0.023391 L1: 0.014110 Grad: 0.092616 Thermal: 0.000390 LR: 8.81e-06\n",
      "Epoch  18 [5300/10697 ( 49.5%)] Loss: 0.030763 L1: 0.018256 Grad: 0.124784 Thermal: 0.000582 LR: 8.81e-06\n",
      "Epoch  18 [5300/10697 ( 49.5%)] Loss: 0.030763 L1: 0.018256 Grad: 0.124784 Thermal: 0.000582 LR: 8.81e-06\n",
      "Epoch  18 [5350/10697 ( 50.0%)] Loss: 0.029859 L1: 0.017378 Grad: 0.124544 Thermal: 0.000533 LR: 8.81e-06\n",
      "Epoch  18 [5350/10697 ( 50.0%)] Loss: 0.029859 L1: 0.017378 Grad: 0.124544 Thermal: 0.000533 LR: 8.81e-06\n",
      "Epoch  18 [5400/10697 ( 50.5%)] Loss: 0.026223 L1: 0.015335 Grad: 0.108668 Thermal: 0.000435 LR: 8.81e-06\n",
      "Epoch  18 [5400/10697 ( 50.5%)] Loss: 0.026223 L1: 0.015335 Grad: 0.108668 Thermal: 0.000435 LR: 8.81e-06\n",
      "Epoch  18 [5450/10697 ( 50.9%)] Loss: 0.031553 L1: 0.018624 Grad: 0.128964 Thermal: 0.000648 LR: 8.81e-06\n",
      "Epoch  18 [5450/10697 ( 50.9%)] Loss: 0.031553 L1: 0.018624 Grad: 0.128964 Thermal: 0.000648 LR: 8.81e-06\n",
      "Epoch  18 [5500/10697 ( 51.4%)] Loss: 0.029588 L1: 0.017517 Grad: 0.120392 Thermal: 0.000632 LR: 8.81e-06\n",
      "Epoch  18 [5500/10697 ( 51.4%)] Loss: 0.029588 L1: 0.017517 Grad: 0.120392 Thermal: 0.000632 LR: 8.81e-06\n",
      "Epoch  18 [5550/10697 ( 51.9%)] Loss: 0.022106 L1: 0.012761 Grad: 0.093289 Thermal: 0.000328 LR: 8.81e-06\n",
      "Epoch  18 [5550/10697 ( 51.9%)] Loss: 0.022106 L1: 0.012761 Grad: 0.093289 Thermal: 0.000328 LR: 8.81e-06\n",
      "Epoch  18 [5600/10697 ( 52.4%)] Loss: 0.019427 L1: 0.011351 Grad: 0.080630 Thermal: 0.000258 LR: 8.81e-06\n",
      "Epoch  18 [5600/10697 ( 52.4%)] Loss: 0.019427 L1: 0.011351 Grad: 0.080630 Thermal: 0.000258 LR: 8.81e-06\n",
      "Epoch  18 [5650/10697 ( 52.8%)] Loss: 0.025645 L1: 0.014752 Grad: 0.108727 Thermal: 0.000422 LR: 8.81e-06\n",
      "Epoch  18 [5650/10697 ( 52.8%)] Loss: 0.025645 L1: 0.014752 Grad: 0.108727 Thermal: 0.000422 LR: 8.81e-06\n",
      "Epoch  18 [5700/10697 ( 53.3%)] Loss: 0.022234 L1: 0.012800 Grad: 0.094178 Thermal: 0.000325 LR: 8.81e-06\n",
      "Epoch  18 [5700/10697 ( 53.3%)] Loss: 0.022234 L1: 0.012800 Grad: 0.094178 Thermal: 0.000325 LR: 8.81e-06\n",
      "Epoch  18 [5750/10697 ( 53.8%)] Loss: 0.017023 L1: 0.009688 Grad: 0.073231 Thermal: 0.000237 LR: 8.81e-06\n",
      "Epoch  18 [5750/10697 ( 53.8%)] Loss: 0.017023 L1: 0.009688 Grad: 0.073231 Thermal: 0.000237 LR: 8.81e-06\n",
      "Epoch  18 [5800/10697 ( 54.2%)] Loss: 0.025154 L1: 0.014787 Grad: 0.103471 Thermal: 0.000411 LR: 8.81e-06\n",
      "Epoch  18 [5800/10697 ( 54.2%)] Loss: 0.025154 L1: 0.014787 Grad: 0.103471 Thermal: 0.000411 LR: 8.81e-06\n",
      "Epoch  18 [5850/10697 ( 54.7%)] Loss: 0.020313 L1: 0.011749 Grad: 0.085513 Thermal: 0.000273 LR: 8.81e-06\n",
      "Epoch  18 [5850/10697 ( 54.7%)] Loss: 0.020313 L1: 0.011749 Grad: 0.085513 Thermal: 0.000273 LR: 8.81e-06\n",
      "Epoch  18 [5900/10697 ( 55.2%)] Loss: 0.020108 L1: 0.011588 Grad: 0.085064 Thermal: 0.000276 LR: 8.81e-06\n",
      "Epoch  18 [5900/10697 ( 55.2%)] Loss: 0.020108 L1: 0.011588 Grad: 0.085064 Thermal: 0.000276 LR: 8.81e-06\n",
      "Epoch  18 [5950/10697 ( 55.6%)] Loss: 0.042679 L1: 0.024910 Grad: 0.177113 Thermal: 0.001156 LR: 8.81e-06\n",
      "Epoch  18 [5950/10697 ( 55.6%)] Loss: 0.042679 L1: 0.024910 Grad: 0.177113 Thermal: 0.001156 LR: 8.81e-06\n",
      "Epoch  18 [6000/10697 ( 56.1%)] Loss: 0.020292 L1: 0.011943 Grad: 0.083334 Thermal: 0.000307 LR: 8.81e-06\n",
      "Epoch  18 [6000/10697 ( 56.1%)] Loss: 0.020292 L1: 0.011943 Grad: 0.083334 Thermal: 0.000307 LR: 8.81e-06\n",
      "Epoch  18 [6050/10697 ( 56.6%)] Loss: 0.026694 L1: 0.015473 Grad: 0.111990 Thermal: 0.000436 LR: 8.81e-06\n",
      "Epoch  18 [6050/10697 ( 56.6%)] Loss: 0.026694 L1: 0.015473 Grad: 0.111990 Thermal: 0.000436 LR: 8.81e-06\n",
      "Epoch  18 [6100/10697 ( 57.0%)] Loss: 0.031783 L1: 0.018133 Grad: 0.136190 Thermal: 0.000626 LR: 8.81e-06\n",
      "Epoch  18 [6100/10697 ( 57.0%)] Loss: 0.031783 L1: 0.018133 Grad: 0.136190 Thermal: 0.000626 LR: 8.81e-06\n",
      "Epoch  18 [6150/10697 ( 57.5%)] Loss: 0.025561 L1: 0.014817 Grad: 0.107218 Thermal: 0.000443 LR: 8.81e-06\n",
      "Epoch  18 [6150/10697 ( 57.5%)] Loss: 0.025561 L1: 0.014817 Grad: 0.107218 Thermal: 0.000443 LR: 8.81e-06\n",
      "Epoch  18 [6200/10697 ( 58.0%)] Loss: 0.021321 L1: 0.012533 Grad: 0.087734 Thermal: 0.000309 LR: 8.81e-06\n",
      "Epoch  18 [6200/10697 ( 58.0%)] Loss: 0.021321 L1: 0.012533 Grad: 0.087734 Thermal: 0.000309 LR: 8.81e-06\n",
      "Epoch  18 [6250/10697 ( 58.4%)] Loss: 0.030242 L1: 0.017412 Grad: 0.127971 Thermal: 0.000653 LR: 8.81e-06\n",
      "Epoch  18 [6250/10697 ( 58.4%)] Loss: 0.030242 L1: 0.017412 Grad: 0.127971 Thermal: 0.000653 LR: 8.81e-06\n",
      "Epoch  18 [6300/10697 ( 58.9%)] Loss: 0.026104 L1: 0.015103 Grad: 0.109774 Thermal: 0.000476 LR: 8.81e-06\n",
      "Epoch  18 [6300/10697 ( 58.9%)] Loss: 0.026104 L1: 0.015103 Grad: 0.109774 Thermal: 0.000476 LR: 8.81e-06\n",
      "Epoch  18 [6350/10697 ( 59.4%)] Loss: 0.023370 L1: 0.013726 Grad: 0.096258 Thermal: 0.000365 LR: 8.81e-06\n",
      "Epoch  18 [6350/10697 ( 59.4%)] Loss: 0.023370 L1: 0.013726 Grad: 0.096258 Thermal: 0.000365 LR: 8.81e-06\n",
      "Epoch  18 [6400/10697 ( 59.8%)] Loss: 0.024969 L1: 0.014574 Grad: 0.103745 Thermal: 0.000406 LR: 8.81e-06\n",
      "Epoch  18 [6400/10697 ( 59.8%)] Loss: 0.024969 L1: 0.014574 Grad: 0.103745 Thermal: 0.000406 LR: 8.81e-06\n",
      "Epoch  18 [6450/10697 ( 60.3%)] Loss: 0.026367 L1: 0.015222 Grad: 0.111251 Thermal: 0.000410 LR: 8.81e-06\n",
      "Epoch  18 [6450/10697 ( 60.3%)] Loss: 0.026367 L1: 0.015222 Grad: 0.111251 Thermal: 0.000410 LR: 8.81e-06\n",
      "Epoch  18 [6500/10697 ( 60.8%)] Loss: 0.031327 L1: 0.018461 Grad: 0.128348 Thermal: 0.000618 LR: 8.81e-06\n",
      "Epoch  18 [6500/10697 ( 60.8%)] Loss: 0.031327 L1: 0.018461 Grad: 0.128348 Thermal: 0.000618 LR: 8.81e-06\n",
      "Epoch  18 [6550/10697 ( 61.2%)] Loss: 0.026333 L1: 0.015517 Grad: 0.107922 Thermal: 0.000467 LR: 8.81e-06\n",
      "Epoch  18 [6550/10697 ( 61.2%)] Loss: 0.026333 L1: 0.015517 Grad: 0.107922 Thermal: 0.000467 LR: 8.81e-06\n",
      "Epoch  18 [6600/10697 ( 61.7%)] Loss: 0.025515 L1: 0.015183 Grad: 0.103101 Thermal: 0.000438 LR: 8.81e-06\n",
      "Epoch  18 [6600/10697 ( 61.7%)] Loss: 0.025515 L1: 0.015183 Grad: 0.103101 Thermal: 0.000438 LR: 8.81e-06\n",
      "Epoch  18 [6650/10697 ( 62.2%)] Loss: 0.027454 L1: 0.016262 Grad: 0.111685 Thermal: 0.000479 LR: 8.81e-06\n",
      "Epoch  18 [6650/10697 ( 62.2%)] Loss: 0.027454 L1: 0.016262 Grad: 0.111685 Thermal: 0.000479 LR: 8.81e-06\n",
      "Epoch  18 [6700/10697 ( 62.6%)] Loss: 0.025823 L1: 0.015295 Grad: 0.105055 Thermal: 0.000451 LR: 8.81e-06\n",
      "Epoch  18 [6700/10697 ( 62.6%)] Loss: 0.025823 L1: 0.015295 Grad: 0.105055 Thermal: 0.000451 LR: 8.81e-06\n",
      "Epoch  18 [6750/10697 ( 63.1%)] Loss: 0.022135 L1: 0.012897 Grad: 0.092223 Thermal: 0.000316 LR: 8.81e-06\n",
      "Epoch  18 [6750/10697 ( 63.1%)] Loss: 0.022135 L1: 0.012897 Grad: 0.092223 Thermal: 0.000316 LR: 8.81e-06\n",
      "Epoch  18 [6800/10697 ( 63.6%)] Loss: 0.025887 L1: 0.015321 Grad: 0.105442 Thermal: 0.000442 LR: 8.81e-06\n",
      "Epoch  18 [6800/10697 ( 63.6%)] Loss: 0.025887 L1: 0.015321 Grad: 0.105442 Thermal: 0.000442 LR: 8.81e-06\n",
      "Epoch  18 [6850/10697 ( 64.0%)] Loss: 0.017336 L1: 0.009997 Grad: 0.073275 Thermal: 0.000227 LR: 8.81e-06\n",
      "Epoch  18 [6850/10697 ( 64.0%)] Loss: 0.017336 L1: 0.009997 Grad: 0.073275 Thermal: 0.000227 LR: 8.81e-06\n",
      "Epoch  18 [6900/10697 ( 64.5%)] Loss: 0.032741 L1: 0.018437 Grad: 0.142741 Thermal: 0.000597 LR: 8.81e-06\n",
      "Epoch  18 [6900/10697 ( 64.5%)] Loss: 0.032741 L1: 0.018437 Grad: 0.142741 Thermal: 0.000597 LR: 8.81e-06\n",
      "Epoch  18 [6950/10697 ( 65.0%)] Loss: 0.023805 L1: 0.013927 Grad: 0.098584 Thermal: 0.000388 LR: 8.81e-06\n",
      "Epoch  18 [6950/10697 ( 65.0%)] Loss: 0.023805 L1: 0.013927 Grad: 0.098584 Thermal: 0.000388 LR: 8.81e-06\n",
      "Epoch  18 [7000/10697 ( 65.4%)] Loss: 0.025981 L1: 0.015118 Grad: 0.108398 Thermal: 0.000470 LR: 8.81e-06\n",
      "Epoch  18 [7000/10697 ( 65.4%)] Loss: 0.025981 L1: 0.015118 Grad: 0.108398 Thermal: 0.000470 LR: 8.81e-06\n",
      "Epoch  18 [7050/10697 ( 65.9%)] Loss: 0.025142 L1: 0.014689 Grad: 0.104293 Thermal: 0.000462 LR: 8.81e-06\n",
      "Epoch  18 [7050/10697 ( 65.9%)] Loss: 0.025142 L1: 0.014689 Grad: 0.104293 Thermal: 0.000462 LR: 8.81e-06\n",
      "Epoch  18 [7100/10697 ( 66.4%)] Loss: 0.023291 L1: 0.013665 Grad: 0.096074 Thermal: 0.000387 LR: 8.81e-06\n",
      "Epoch  18 [7100/10697 ( 66.4%)] Loss: 0.023291 L1: 0.013665 Grad: 0.096074 Thermal: 0.000387 LR: 8.81e-06\n",
      "Epoch  18 [7150/10697 ( 66.8%)] Loss: 0.024416 L1: 0.014138 Grad: 0.102583 Thermal: 0.000380 LR: 8.81e-06\n",
      "Epoch  18 [7150/10697 ( 66.8%)] Loss: 0.024416 L1: 0.014138 Grad: 0.102583 Thermal: 0.000380 LR: 8.81e-06\n",
      "Epoch  18 [7200/10697 ( 67.3%)] Loss: 0.023492 L1: 0.013636 Grad: 0.098384 Thermal: 0.000346 LR: 8.81e-06\n",
      "Epoch  18 [7200/10697 ( 67.3%)] Loss: 0.023492 L1: 0.013636 Grad: 0.098384 Thermal: 0.000346 LR: 8.81e-06\n",
      "Epoch  18 [7250/10697 ( 67.8%)] Loss: 0.026780 L1: 0.016126 Grad: 0.106294 Thermal: 0.000486 LR: 8.81e-06\n",
      "Epoch  18 [7250/10697 ( 67.8%)] Loss: 0.026780 L1: 0.016126 Grad: 0.106294 Thermal: 0.000486 LR: 8.81e-06\n",
      "Epoch  18 [7300/10697 ( 68.2%)] Loss: 0.026618 L1: 0.015464 Grad: 0.111298 Thermal: 0.000479 LR: 8.81e-06\n",
      "Epoch  18 [7300/10697 ( 68.2%)] Loss: 0.026618 L1: 0.015464 Grad: 0.111298 Thermal: 0.000479 LR: 8.81e-06\n",
      "Epoch  18 [7350/10697 ( 68.7%)] Loss: 0.032550 L1: 0.018414 Grad: 0.141022 Thermal: 0.000678 LR: 8.81e-06\n",
      "Epoch  18 [7350/10697 ( 68.7%)] Loss: 0.032550 L1: 0.018414 Grad: 0.141022 Thermal: 0.000678 LR: 8.81e-06\n",
      "Epoch  18 [7400/10697 ( 69.2%)] Loss: 0.026976 L1: 0.015937 Grad: 0.110140 Thermal: 0.000488 LR: 8.81e-06\n",
      "Epoch  18 [7400/10697 ( 69.2%)] Loss: 0.026976 L1: 0.015937 Grad: 0.110140 Thermal: 0.000488 LR: 8.81e-06\n",
      "Epoch  18 [7450/10697 ( 69.6%)] Loss: 0.023729 L1: 0.013918 Grad: 0.097929 Thermal: 0.000370 LR: 8.81e-06\n",
      "Epoch  18 [7450/10697 ( 69.6%)] Loss: 0.023729 L1: 0.013918 Grad: 0.097929 Thermal: 0.000370 LR: 8.81e-06\n",
      "Epoch  18 [7500/10697 ( 70.1%)] Loss: 0.027534 L1: 0.015969 Grad: 0.115404 Thermal: 0.000492 LR: 8.81e-06\n",
      "Epoch  18 [7500/10697 ( 70.1%)] Loss: 0.027534 L1: 0.015969 Grad: 0.115404 Thermal: 0.000492 LR: 8.81e-06\n",
      "Epoch  18 [7550/10697 ( 70.6%)] Loss: 0.027433 L1: 0.015842 Grad: 0.115649 Thermal: 0.000531 LR: 8.81e-06\n",
      "Epoch  18 [7550/10697 ( 70.6%)] Loss: 0.027433 L1: 0.015842 Grad: 0.115649 Thermal: 0.000531 LR: 8.81e-06\n",
      "Epoch  18 [7600/10697 ( 71.0%)] Loss: 0.032259 L1: 0.018946 Grad: 0.132801 Thermal: 0.000655 LR: 8.81e-06\n",
      "Epoch  18 [7600/10697 ( 71.0%)] Loss: 0.032259 L1: 0.018946 Grad: 0.132801 Thermal: 0.000655 LR: 8.81e-06\n",
      "Epoch  18 [7650/10697 ( 71.5%)] Loss: 0.020905 L1: 0.011750 Grad: 0.091402 Thermal: 0.000286 LR: 8.81e-06\n",
      "Epoch  18 [7650/10697 ( 71.5%)] Loss: 0.020905 L1: 0.011750 Grad: 0.091402 Thermal: 0.000286 LR: 8.81e-06\n",
      "Epoch  18 [7700/10697 ( 72.0%)] Loss: 0.025243 L1: 0.014543 Grad: 0.106796 Thermal: 0.000419 LR: 8.81e-06\n",
      "Epoch  18 [7700/10697 ( 72.0%)] Loss: 0.025243 L1: 0.014543 Grad: 0.106796 Thermal: 0.000419 LR: 8.81e-06\n",
      "Epoch  18 [7750/10697 ( 72.5%)] Loss: 0.031259 L1: 0.018200 Grad: 0.130277 Thermal: 0.000623 LR: 8.81e-06\n",
      "Epoch  18 [7750/10697 ( 72.5%)] Loss: 0.031259 L1: 0.018200 Grad: 0.130277 Thermal: 0.000623 LR: 8.81e-06\n",
      "Epoch  18 [7800/10697 ( 72.9%)] Loss: 0.023428 L1: 0.013547 Grad: 0.098611 Thermal: 0.000401 LR: 8.81e-06\n",
      "Epoch  18 [7800/10697 ( 72.9%)] Loss: 0.023428 L1: 0.013547 Grad: 0.098611 Thermal: 0.000401 LR: 8.81e-06\n",
      "Epoch  18 [7850/10697 ( 73.4%)] Loss: 0.027216 L1: 0.015792 Grad: 0.114014 Thermal: 0.000444 LR: 8.81e-06\n",
      "Epoch  18 [7850/10697 ( 73.4%)] Loss: 0.027216 L1: 0.015792 Grad: 0.114014 Thermal: 0.000444 LR: 8.81e-06\n",
      "Epoch  18 [7900/10697 ( 73.9%)] Loss: 0.035502 L1: 0.020504 Grad: 0.149546 Thermal: 0.000867 LR: 8.81e-06\n",
      "Epoch  18 [7900/10697 ( 73.9%)] Loss: 0.035502 L1: 0.020504 Grad: 0.149546 Thermal: 0.000867 LR: 8.81e-06\n",
      "Epoch  18 [7950/10697 ( 74.3%)] Loss: 0.028564 L1: 0.016947 Grad: 0.115906 Thermal: 0.000516 LR: 8.81e-06\n",
      "Epoch  18 [7950/10697 ( 74.3%)] Loss: 0.028564 L1: 0.016947 Grad: 0.115906 Thermal: 0.000516 LR: 8.81e-06\n",
      "Epoch  18 [8000/10697 ( 74.8%)] Loss: 0.028632 L1: 0.016282 Grad: 0.123254 Thermal: 0.000484 LR: 8.81e-06\n",
      "Epoch  18 [8000/10697 ( 74.8%)] Loss: 0.028632 L1: 0.016282 Grad: 0.123254 Thermal: 0.000484 LR: 8.81e-06\n",
      "Epoch  18 [8050/10697 ( 75.3%)] Loss: 0.022881 L1: 0.013604 Grad: 0.092592 Thermal: 0.000345 LR: 8.81e-06\n",
      "Epoch  18 [8050/10697 ( 75.3%)] Loss: 0.022881 L1: 0.013604 Grad: 0.092592 Thermal: 0.000345 LR: 8.81e-06\n",
      "Epoch  18 [8100/10697 ( 75.7%)] Loss: 0.027287 L1: 0.016137 Grad: 0.111255 Thermal: 0.000483 LR: 8.81e-06\n",
      "Epoch  18 [8100/10697 ( 75.7%)] Loss: 0.027287 L1: 0.016137 Grad: 0.111255 Thermal: 0.000483 LR: 8.81e-06\n",
      "Epoch  18 [8150/10697 ( 76.2%)] Loss: 0.031552 L1: 0.018462 Grad: 0.130568 Thermal: 0.000655 LR: 8.81e-06\n",
      "Epoch  18 [8150/10697 ( 76.2%)] Loss: 0.031552 L1: 0.018462 Grad: 0.130568 Thermal: 0.000655 LR: 8.81e-06\n",
      "Epoch  18 [8200/10697 ( 76.7%)] Loss: 0.030098 L1: 0.017547 Grad: 0.125227 Thermal: 0.000574 LR: 8.81e-06\n",
      "Epoch  18 [8200/10697 ( 76.7%)] Loss: 0.030098 L1: 0.017547 Grad: 0.125227 Thermal: 0.000574 LR: 8.81e-06\n",
      "Epoch  18 [8250/10697 ( 77.1%)] Loss: 0.029233 L1: 0.017264 Grad: 0.119428 Thermal: 0.000536 LR: 8.81e-06\n",
      "Epoch  18 [8250/10697 ( 77.1%)] Loss: 0.029233 L1: 0.017264 Grad: 0.119428 Thermal: 0.000536 LR: 8.81e-06\n",
      "Epoch  18 [8300/10697 ( 77.6%)] Loss: 0.025575 L1: 0.015019 Grad: 0.105338 Thermal: 0.000431 LR: 8.81e-06\n",
      "Epoch  18 [8300/10697 ( 77.6%)] Loss: 0.025575 L1: 0.015019 Grad: 0.105338 Thermal: 0.000431 LR: 8.81e-06\n",
      "Epoch  18 [8350/10697 ( 78.1%)] Loss: 0.029977 L1: 0.017369 Grad: 0.125799 Thermal: 0.000557 LR: 8.81e-06\n",
      "Epoch  18 [8350/10697 ( 78.1%)] Loss: 0.029977 L1: 0.017369 Grad: 0.125799 Thermal: 0.000557 LR: 8.81e-06\n",
      "Epoch  18 [8400/10697 ( 78.5%)] Loss: 0.033665 L1: 0.018918 Grad: 0.147113 Thermal: 0.000727 LR: 8.81e-06\n",
      "Epoch  18 [8400/10697 ( 78.5%)] Loss: 0.033665 L1: 0.018918 Grad: 0.147113 Thermal: 0.000727 LR: 8.81e-06\n",
      "Epoch  18 [8450/10697 ( 79.0%)] Loss: 0.024720 L1: 0.014052 Grad: 0.106465 Thermal: 0.000427 LR: 8.81e-06\n",
      "Epoch  18 [8450/10697 ( 79.0%)] Loss: 0.024720 L1: 0.014052 Grad: 0.106465 Thermal: 0.000427 LR: 8.81e-06\n",
      "Epoch  18 [8500/10697 ( 79.5%)] Loss: 0.024537 L1: 0.014200 Grad: 0.103175 Thermal: 0.000383 LR: 8.81e-06\n",
      "Epoch  18 [8500/10697 ( 79.5%)] Loss: 0.024537 L1: 0.014200 Grad: 0.103175 Thermal: 0.000383 LR: 8.81e-06\n",
      "Epoch  18 [8550/10697 ( 79.9%)] Loss: 0.021171 L1: 0.012075 Grad: 0.090796 Thermal: 0.000322 LR: 8.81e-06\n",
      "Epoch  18 [8550/10697 ( 79.9%)] Loss: 0.021171 L1: 0.012075 Grad: 0.090796 Thermal: 0.000322 LR: 8.81e-06\n",
      "Epoch  18 [8600/10697 ( 80.4%)] Loss: 0.024260 L1: 0.014115 Grad: 0.101256 Thermal: 0.000378 LR: 8.81e-06\n",
      "Epoch  18 [8600/10697 ( 80.4%)] Loss: 0.024260 L1: 0.014115 Grad: 0.101256 Thermal: 0.000378 LR: 8.81e-06\n",
      "Epoch  18 [8650/10697 ( 80.9%)] Loss: 0.038547 L1: 0.022261 Grad: 0.162361 Thermal: 0.001003 LR: 8.81e-06\n",
      "Epoch  18 [8650/10697 ( 80.9%)] Loss: 0.038547 L1: 0.022261 Grad: 0.162361 Thermal: 0.001003 LR: 8.81e-06\n",
      "Epoch  18 [8700/10697 ( 81.3%)] Loss: 0.028208 L1: 0.016510 Grad: 0.116731 Thermal: 0.000497 LR: 8.81e-06\n",
      "Epoch  18 [8700/10697 ( 81.3%)] Loss: 0.028208 L1: 0.016510 Grad: 0.116731 Thermal: 0.000497 LR: 8.81e-06\n",
      "Epoch  18 [8750/10697 ( 81.8%)] Loss: 0.032373 L1: 0.018996 Grad: 0.133435 Thermal: 0.000673 LR: 8.81e-06\n",
      "Epoch  18 [8750/10697 ( 81.8%)] Loss: 0.032373 L1: 0.018996 Grad: 0.133435 Thermal: 0.000673 LR: 8.81e-06\n",
      "Epoch  18 [8800/10697 ( 82.3%)] Loss: 0.027418 L1: 0.015363 Grad: 0.120324 Thermal: 0.000468 LR: 8.81e-06\n",
      "Epoch  18 [8800/10697 ( 82.3%)] Loss: 0.027418 L1: 0.015363 Grad: 0.120324 Thermal: 0.000468 LR: 8.81e-06\n",
      "Epoch  18 [8850/10697 ( 82.7%)] Loss: 0.029972 L1: 0.017598 Grad: 0.123449 Thermal: 0.000574 LR: 8.81e-06\n",
      "Epoch  18 [8850/10697 ( 82.7%)] Loss: 0.029972 L1: 0.017598 Grad: 0.123449 Thermal: 0.000574 LR: 8.81e-06\n",
      "Epoch  18 [8900/10697 ( 83.2%)] Loss: 0.030950 L1: 0.017458 Grad: 0.134631 Thermal: 0.000578 LR: 8.81e-06\n",
      "Epoch  18 [8900/10697 ( 83.2%)] Loss: 0.030950 L1: 0.017458 Grad: 0.134631 Thermal: 0.000578 LR: 8.81e-06\n",
      "Epoch  18 [8950/10697 ( 83.7%)] Loss: 0.028769 L1: 0.016715 Grad: 0.120272 Thermal: 0.000536 LR: 8.81e-06\n",
      "Epoch  18 [8950/10697 ( 83.7%)] Loss: 0.028769 L1: 0.016715 Grad: 0.120272 Thermal: 0.000536 LR: 8.81e-06\n",
      "Epoch  18 [9000/10697 ( 84.1%)] Loss: 0.027800 L1: 0.016745 Grad: 0.110299 Thermal: 0.000501 LR: 8.81e-06\n",
      "Epoch  18 [9000/10697 ( 84.1%)] Loss: 0.027800 L1: 0.016745 Grad: 0.110299 Thermal: 0.000501 LR: 8.81e-06\n",
      "Epoch  18 [9050/10697 ( 84.6%)] Loss: 0.025632 L1: 0.014982 Grad: 0.106284 Thermal: 0.000438 LR: 8.81e-06\n",
      "Epoch  18 [9050/10697 ( 84.6%)] Loss: 0.025632 L1: 0.014982 Grad: 0.106284 Thermal: 0.000438 LR: 8.81e-06\n",
      "Epoch  18 [9100/10697 ( 85.1%)] Loss: 0.023457 L1: 0.013588 Grad: 0.098515 Thermal: 0.000353 LR: 8.81e-06\n",
      "Epoch  18 [9100/10697 ( 85.1%)] Loss: 0.023457 L1: 0.013588 Grad: 0.098515 Thermal: 0.000353 LR: 8.81e-06\n",
      "Epoch  18 [9150/10697 ( 85.5%)] Loss: 0.022705 L1: 0.013241 Grad: 0.094463 Thermal: 0.000348 LR: 8.81e-06\n",
      "Epoch  18 [9150/10697 ( 85.5%)] Loss: 0.022705 L1: 0.013241 Grad: 0.094463 Thermal: 0.000348 LR: 8.81e-06\n",
      "Epoch  18 [9200/10697 ( 86.0%)] Loss: 0.027673 L1: 0.015875 Grad: 0.117744 Thermal: 0.000483 LR: 8.81e-06\n",
      "Epoch  18 [9200/10697 ( 86.0%)] Loss: 0.027673 L1: 0.015875 Grad: 0.117744 Thermal: 0.000483 LR: 8.81e-06\n",
      "Epoch  18 [9250/10697 ( 86.5%)] Loss: 0.026051 L1: 0.015347 Grad: 0.106823 Thermal: 0.000431 LR: 8.81e-06\n",
      "Epoch  18 [9250/10697 ( 86.5%)] Loss: 0.026051 L1: 0.015347 Grad: 0.106823 Thermal: 0.000431 LR: 8.81e-06\n",
      "Epoch  18 [9300/10697 ( 86.9%)] Loss: 0.027690 L1: 0.016079 Grad: 0.115861 Thermal: 0.000486 LR: 8.81e-06\n",
      "Epoch  18 [9300/10697 ( 86.9%)] Loss: 0.027690 L1: 0.016079 Grad: 0.115861 Thermal: 0.000486 LR: 8.81e-06\n",
      "Epoch  18 [9350/10697 ( 87.4%)] Loss: 0.024499 L1: 0.014446 Grad: 0.100335 Thermal: 0.000386 LR: 8.81e-06\n",
      "Epoch  18 [9350/10697 ( 87.4%)] Loss: 0.024499 L1: 0.014446 Grad: 0.100335 Thermal: 0.000386 LR: 8.81e-06\n",
      "Epoch  18 [9400/10697 ( 87.9%)] Loss: 0.024662 L1: 0.014731 Grad: 0.099099 Thermal: 0.000409 LR: 8.81e-06\n",
      "Epoch  18 [9400/10697 ( 87.9%)] Loss: 0.024662 L1: 0.014731 Grad: 0.099099 Thermal: 0.000409 LR: 8.81e-06\n",
      "Epoch  18 [9450/10697 ( 88.3%)] Loss: 0.027448 L1: 0.016275 Grad: 0.111486 Thermal: 0.000470 LR: 8.81e-06\n",
      "Epoch  18 [9450/10697 ( 88.3%)] Loss: 0.027448 L1: 0.016275 Grad: 0.111486 Thermal: 0.000470 LR: 8.81e-06\n",
      "Epoch  18 [9500/10697 ( 88.8%)] Loss: 0.025663 L1: 0.015417 Grad: 0.102234 Thermal: 0.000436 LR: 8.81e-06\n",
      "Epoch  18 [9500/10697 ( 88.8%)] Loss: 0.025663 L1: 0.015417 Grad: 0.102234 Thermal: 0.000436 LR: 8.81e-06\n",
      "Epoch  18 [9550/10697 ( 89.3%)] Loss: 0.027937 L1: 0.016143 Grad: 0.117702 Thermal: 0.000474 LR: 8.81e-06\n",
      "Epoch  18 [9550/10697 ( 89.3%)] Loss: 0.027937 L1: 0.016143 Grad: 0.117702 Thermal: 0.000474 LR: 8.81e-06\n",
      "Epoch  18 [9600/10697 ( 89.7%)] Loss: 0.027072 L1: 0.015904 Grad: 0.111457 Thermal: 0.000443 LR: 8.81e-06\n",
      "Epoch  18 [9600/10697 ( 89.7%)] Loss: 0.027072 L1: 0.015904 Grad: 0.111457 Thermal: 0.000443 LR: 8.81e-06\n",
      "Epoch  18 [9650/10697 ( 90.2%)] Loss: 0.035217 L1: 0.020256 Grad: 0.149247 Thermal: 0.000729 LR: 8.81e-06\n",
      "Epoch  18 [9650/10697 ( 90.2%)] Loss: 0.035217 L1: 0.020256 Grad: 0.149247 Thermal: 0.000729 LR: 8.81e-06\n",
      "Epoch  18 [9700/10697 ( 90.7%)] Loss: 0.020968 L1: 0.012434 Grad: 0.085176 Thermal: 0.000326 LR: 8.81e-06\n",
      "Epoch  18 [9700/10697 ( 90.7%)] Loss: 0.020968 L1: 0.012434 Grad: 0.085176 Thermal: 0.000326 LR: 8.81e-06\n",
      "Epoch  18 [9750/10697 ( 91.1%)] Loss: 0.027320 L1: 0.016117 Grad: 0.111793 Thermal: 0.000469 LR: 8.81e-06\n",
      "Epoch  18 [9750/10697 ( 91.1%)] Loss: 0.027320 L1: 0.016117 Grad: 0.111793 Thermal: 0.000469 LR: 8.81e-06\n",
      "Epoch  18 [9800/10697 ( 91.6%)] Loss: 0.024102 L1: 0.014078 Grad: 0.100043 Thermal: 0.000393 LR: 8.81e-06\n",
      "Epoch  18 [9800/10697 ( 91.6%)] Loss: 0.024102 L1: 0.014078 Grad: 0.100043 Thermal: 0.000393 LR: 8.81e-06\n",
      "Epoch  18 [9850/10697 ( 92.1%)] Loss: 0.029978 L1: 0.017292 Grad: 0.126586 Thermal: 0.000535 LR: 8.81e-06\n",
      "Epoch  18 [9850/10697 ( 92.1%)] Loss: 0.029978 L1: 0.017292 Grad: 0.126586 Thermal: 0.000535 LR: 8.81e-06\n",
      "Epoch  18 [9900/10697 ( 92.5%)] Loss: 0.026251 L1: 0.015313 Grad: 0.109160 Thermal: 0.000440 LR: 8.81e-06\n",
      "Epoch  18 [9900/10697 ( 92.5%)] Loss: 0.026251 L1: 0.015313 Grad: 0.109160 Thermal: 0.000440 LR: 8.81e-06\n",
      "Epoch  18 [9950/10697 ( 93.0%)] Loss: 0.026094 L1: 0.015626 Grad: 0.104463 Thermal: 0.000425 LR: 8.81e-06\n",
      "Epoch  18 [9950/10697 ( 93.0%)] Loss: 0.026094 L1: 0.015626 Grad: 0.104463 Thermal: 0.000425 LR: 8.81e-06\n",
      "Epoch  18 [10000/10697 ( 93.5%)] Loss: 0.026361 L1: 0.015504 Grad: 0.108342 Thermal: 0.000458 LR: 8.81e-06\n",
      "Epoch  18 [10000/10697 ( 93.5%)] Loss: 0.026361 L1: 0.015504 Grad: 0.108342 Thermal: 0.000458 LR: 8.81e-06\n",
      "Epoch  18 [10050/10697 ( 94.0%)] Loss: 0.025671 L1: 0.014941 Grad: 0.107093 Thermal: 0.000407 LR: 8.81e-06\n",
      "Epoch  18 [10050/10697 ( 94.0%)] Loss: 0.025671 L1: 0.014941 Grad: 0.107093 Thermal: 0.000407 LR: 8.81e-06\n",
      "Epoch  18 [10100/10697 ( 94.4%)] Loss: 0.023914 L1: 0.013926 Grad: 0.099704 Thermal: 0.000364 LR: 8.81e-06\n",
      "Epoch  18 [10100/10697 ( 94.4%)] Loss: 0.023914 L1: 0.013926 Grad: 0.099704 Thermal: 0.000364 LR: 8.81e-06\n",
      "Epoch  18 [10150/10697 ( 94.9%)] Loss: 0.028306 L1: 0.016879 Grad: 0.114027 Thermal: 0.000494 LR: 8.81e-06\n",
      "Epoch  18 [10150/10697 ( 94.9%)] Loss: 0.028306 L1: 0.016879 Grad: 0.114027 Thermal: 0.000494 LR: 8.81e-06\n",
      "Epoch  18 [10200/10697 ( 95.4%)] Loss: 0.030487 L1: 0.017411 Grad: 0.130465 Thermal: 0.000589 LR: 8.81e-06\n",
      "Epoch  18 [10200/10697 ( 95.4%)] Loss: 0.030487 L1: 0.017411 Grad: 0.130465 Thermal: 0.000589 LR: 8.81e-06\n",
      "Epoch  18 [10250/10697 ( 95.8%)] Loss: 0.026566 L1: 0.015677 Grad: 0.108660 Thermal: 0.000459 LR: 8.81e-06\n",
      "Epoch  18 [10250/10697 ( 95.8%)] Loss: 0.026566 L1: 0.015677 Grad: 0.108660 Thermal: 0.000459 LR: 8.81e-06\n",
      "Epoch  18 [10300/10697 ( 96.3%)] Loss: 0.028303 L1: 0.016827 Grad: 0.114486 Thermal: 0.000535 LR: 8.81e-06\n",
      "Epoch  18 [10300/10697 ( 96.3%)] Loss: 0.028303 L1: 0.016827 Grad: 0.114486 Thermal: 0.000535 LR: 8.81e-06\n",
      "Epoch  18 [10350/10697 ( 96.8%)] Loss: 0.028104 L1: 0.016720 Grad: 0.113594 Thermal: 0.000489 LR: 8.81e-06\n",
      "Epoch  18 [10350/10697 ( 96.8%)] Loss: 0.028104 L1: 0.016720 Grad: 0.113594 Thermal: 0.000489 LR: 8.81e-06\n",
      "Epoch  18 [10400/10697 ( 97.2%)] Loss: 0.025733 L1: 0.015202 Grad: 0.105093 Thermal: 0.000431 LR: 8.81e-06\n",
      "Epoch  18 [10400/10697 ( 97.2%)] Loss: 0.025733 L1: 0.015202 Grad: 0.105093 Thermal: 0.000431 LR: 8.81e-06\n",
      "Epoch  18 [10450/10697 ( 97.7%)] Loss: 0.026952 L1: 0.016240 Grad: 0.106868 Thermal: 0.000495 LR: 8.81e-06\n",
      "Epoch  18 [10450/10697 ( 97.7%)] Loss: 0.026952 L1: 0.016240 Grad: 0.106868 Thermal: 0.000495 LR: 8.81e-06\n",
      "Epoch  18 [10500/10697 ( 98.2%)] Loss: 0.026889 L1: 0.015318 Grad: 0.115476 Thermal: 0.000475 LR: 8.81e-06\n",
      "Epoch  18 [10500/10697 ( 98.2%)] Loss: 0.026889 L1: 0.015318 Grad: 0.115476 Thermal: 0.000475 LR: 8.81e-06\n",
      "Epoch  18 [10550/10697 ( 98.6%)] Loss: 0.027030 L1: 0.015661 Grad: 0.113463 Thermal: 0.000458 LR: 8.81e-06\n",
      "Epoch  18 [10550/10697 ( 98.6%)] Loss: 0.027030 L1: 0.015661 Grad: 0.113463 Thermal: 0.000458 LR: 8.81e-06\n",
      "Epoch  18 [10600/10697 ( 99.1%)] Loss: 0.028321 L1: 0.016912 Grad: 0.113841 Thermal: 0.000497 LR: 8.81e-06\n",
      "Epoch  18 [10600/10697 ( 99.1%)] Loss: 0.028321 L1: 0.016912 Grad: 0.113841 Thermal: 0.000497 LR: 8.81e-06\n",
      "Epoch  18 [10650/10697 ( 99.6%)] Loss: 0.031016 L1: 0.018104 Grad: 0.128780 Thermal: 0.000662 LR: 8.81e-06\n",
      "Epoch  18 [10650/10697 ( 99.6%)] Loss: 0.031016 L1: 0.018104 Grad: 0.128780 Thermal: 0.000662 LR: 8.81e-06\n",
      "Epoch  18 Summary: Loss=0.026633 (L1:0.0155, Grad:0.1110, Thermal:0.0005) Val_PSNR=0.00dB Best=33.84dB Time=67.7min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  18 Summary: Loss=0.026633 (L1:0.0155, Grad:0.1110, Thermal:0.0005) Val_PSNR=0.00dB Best=33.84dB Time=67.7min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  19 [   0/10697 (  0.0%)] Loss: 0.025665 L1: 0.014901 Grad: 0.107430 Thermal: 0.000426 LR: 8.68e-06\n",
      "Epoch  19 [   0/10697 (  0.0%)] Loss: 0.025665 L1: 0.014901 Grad: 0.107430 Thermal: 0.000426 LR: 8.68e-06\n",
      "Epoch  19 [  50/10697 (  0.5%)] Loss: 0.029533 L1: 0.017265 Grad: 0.122397 Thermal: 0.000557 LR: 8.68e-06\n",
      "Epoch  19 [  50/10697 (  0.5%)] Loss: 0.029533 L1: 0.017265 Grad: 0.122397 Thermal: 0.000557 LR: 8.68e-06\n",
      "Epoch  19 [ 100/10697 (  0.9%)] Loss: 0.022567 L1: 0.013423 Grad: 0.091258 Thermal: 0.000356 LR: 8.68e-06\n",
      "Epoch  19 [ 100/10697 (  0.9%)] Loss: 0.022567 L1: 0.013423 Grad: 0.091258 Thermal: 0.000356 LR: 8.68e-06\n",
      "Epoch  19 [ 150/10697 (  1.4%)] Loss: 0.022999 L1: 0.013688 Grad: 0.092917 Thermal: 0.000389 LR: 8.68e-06\n",
      "Epoch  19 [ 150/10697 (  1.4%)] Loss: 0.022999 L1: 0.013688 Grad: 0.092917 Thermal: 0.000389 LR: 8.68e-06\n",
      "Epoch  19 [ 200/10697 (  1.9%)] Loss: 0.026825 L1: 0.016239 Grad: 0.105623 Thermal: 0.000472 LR: 8.68e-06\n",
      "Epoch  19 [ 200/10697 (  1.9%)] Loss: 0.026825 L1: 0.016239 Grad: 0.105623 Thermal: 0.000472 LR: 8.68e-06\n",
      "Epoch  19 [ 250/10697 (  2.3%)] Loss: 0.032466 L1: 0.018333 Grad: 0.141001 Thermal: 0.000667 LR: 8.68e-06\n",
      "Epoch  19 [ 250/10697 (  2.3%)] Loss: 0.032466 L1: 0.018333 Grad: 0.141001 Thermal: 0.000667 LR: 8.68e-06\n",
      "Epoch  19 [ 300/10697 (  2.8%)] Loss: 0.028029 L1: 0.015711 Grad: 0.122949 Thermal: 0.000471 LR: 8.68e-06\n",
      "Epoch  19 [ 300/10697 (  2.8%)] Loss: 0.028029 L1: 0.015711 Grad: 0.122949 Thermal: 0.000471 LR: 8.68e-06\n",
      "Epoch  19 [ 350/10697 (  3.3%)] Loss: 0.019096 L1: 0.010796 Grad: 0.082877 Thermal: 0.000241 LR: 8.68e-06\n",
      "Epoch  19 [ 350/10697 (  3.3%)] Loss: 0.019096 L1: 0.010796 Grad: 0.082877 Thermal: 0.000241 LR: 8.68e-06\n",
      "Epoch  19 [ 400/10697 (  3.7%)] Loss: 0.027355 L1: 0.015945 Grad: 0.113872 Thermal: 0.000459 LR: 8.68e-06\n",
      "Epoch  19 [ 400/10697 (  3.7%)] Loss: 0.027355 L1: 0.015945 Grad: 0.113872 Thermal: 0.000459 LR: 8.68e-06\n",
      "Epoch  19 [ 450/10697 (  4.2%)] Loss: 0.027309 L1: 0.015528 Grad: 0.117565 Thermal: 0.000484 LR: 8.68e-06\n",
      "Epoch  19 [ 450/10697 (  4.2%)] Loss: 0.027309 L1: 0.015528 Grad: 0.117565 Thermal: 0.000484 LR: 8.68e-06\n",
      "Epoch  19 [ 500/10697 (  4.7%)] Loss: 0.021098 L1: 0.012083 Grad: 0.089990 Thermal: 0.000308 LR: 8.68e-06\n",
      "Epoch  19 [ 500/10697 (  4.7%)] Loss: 0.021098 L1: 0.012083 Grad: 0.089990 Thermal: 0.000308 LR: 8.68e-06\n",
      "Epoch  19 [ 550/10697 (  5.1%)] Loss: 0.032266 L1: 0.019005 Grad: 0.132293 Thermal: 0.000629 LR: 8.68e-06\n",
      "Epoch  19 [ 550/10697 (  5.1%)] Loss: 0.032266 L1: 0.019005 Grad: 0.132293 Thermal: 0.000629 LR: 8.68e-06\n",
      "Epoch  19 [ 600/10697 (  5.6%)] Loss: 0.026347 L1: 0.015438 Grad: 0.108858 Thermal: 0.000457 LR: 8.68e-06\n",
      "Epoch  19 [ 600/10697 (  5.6%)] Loss: 0.026347 L1: 0.015438 Grad: 0.108858 Thermal: 0.000457 LR: 8.68e-06\n",
      "Epoch  19 [ 650/10697 (  6.1%)] Loss: 0.024358 L1: 0.014070 Grad: 0.102703 Thermal: 0.000368 LR: 8.68e-06\n",
      "Epoch  19 [ 650/10697 (  6.1%)] Loss: 0.024358 L1: 0.014070 Grad: 0.102703 Thermal: 0.000368 LR: 8.68e-06\n",
      "Epoch  19 [ 700/10697 (  6.5%)] Loss: 0.028241 L1: 0.016812 Grad: 0.114031 Thermal: 0.000511 LR: 8.68e-06\n",
      "Epoch  19 [ 700/10697 (  6.5%)] Loss: 0.028241 L1: 0.016812 Grad: 0.114031 Thermal: 0.000511 LR: 8.68e-06\n",
      "Epoch  19 [ 750/10697 (  7.0%)] Loss: 0.026113 L1: 0.015264 Grad: 0.108259 Thermal: 0.000470 LR: 8.68e-06\n",
      "Epoch  19 [ 750/10697 (  7.0%)] Loss: 0.026113 L1: 0.015264 Grad: 0.108259 Thermal: 0.000470 LR: 8.68e-06\n",
      "Epoch  19 [ 800/10697 (  7.5%)] Loss: 0.025088 L1: 0.014722 Grad: 0.103445 Thermal: 0.000433 LR: 8.68e-06\n",
      "Epoch  19 [ 800/10697 (  7.5%)] Loss: 0.025088 L1: 0.014722 Grad: 0.103445 Thermal: 0.000433 LR: 8.68e-06\n",
      "Epoch  19 [ 850/10697 (  7.9%)] Loss: 0.023778 L1: 0.013909 Grad: 0.098511 Thermal: 0.000375 LR: 8.68e-06\n",
      "Epoch  19 [ 850/10697 (  7.9%)] Loss: 0.023778 L1: 0.013909 Grad: 0.098511 Thermal: 0.000375 LR: 8.68e-06\n",
      "Epoch  19 [ 900/10697 (  8.4%)] Loss: 0.024796 L1: 0.014592 Grad: 0.101851 Thermal: 0.000383 LR: 8.68e-06\n",
      "Epoch  19 [ 900/10697 (  8.4%)] Loss: 0.024796 L1: 0.014592 Grad: 0.101851 Thermal: 0.000383 LR: 8.68e-06\n",
      "Epoch  19 [ 950/10697 (  8.9%)] Loss: 0.032998 L1: 0.018823 Grad: 0.141384 Thermal: 0.000736 LR: 8.68e-06\n",
      "Epoch  19 [ 950/10697 (  8.9%)] Loss: 0.032998 L1: 0.018823 Grad: 0.141384 Thermal: 0.000736 LR: 8.68e-06\n",
      "Epoch  19 [1000/10697 (  9.3%)] Loss: 0.026372 L1: 0.015133 Grad: 0.112161 Thermal: 0.000456 LR: 8.68e-06\n",
      "Epoch  19 [1000/10697 (  9.3%)] Loss: 0.026372 L1: 0.015133 Grad: 0.112161 Thermal: 0.000456 LR: 8.68e-06\n",
      "Epoch  19 [1050/10697 (  9.8%)] Loss: 0.029559 L1: 0.017045 Grad: 0.124867 Thermal: 0.000559 LR: 8.68e-06\n",
      "Epoch  19 [1050/10697 (  9.8%)] Loss: 0.029559 L1: 0.017045 Grad: 0.124867 Thermal: 0.000559 LR: 8.68e-06\n",
      "Epoch  19 [1100/10697 ( 10.3%)] Loss: 0.022422 L1: 0.013111 Grad: 0.092933 Thermal: 0.000367 LR: 8.68e-06\n",
      "Epoch  19 [1100/10697 ( 10.3%)] Loss: 0.022422 L1: 0.013111 Grad: 0.092933 Thermal: 0.000367 LR: 8.68e-06\n",
      "Epoch  19 [1150/10697 ( 10.8%)] Loss: 0.027801 L1: 0.016321 Grad: 0.114561 Thermal: 0.000474 LR: 8.68e-06\n",
      "Epoch  19 [1150/10697 ( 10.8%)] Loss: 0.027801 L1: 0.016321 Grad: 0.114561 Thermal: 0.000474 LR: 8.68e-06\n",
      "Epoch  19 [1200/10697 ( 11.2%)] Loss: 0.031748 L1: 0.018380 Grad: 0.133360 Thermal: 0.000632 LR: 8.68e-06\n",
      "Epoch  19 [1200/10697 ( 11.2%)] Loss: 0.031748 L1: 0.018380 Grad: 0.133360 Thermal: 0.000632 LR: 8.68e-06\n",
      "Epoch  19 [1250/10697 ( 11.7%)] Loss: 0.029295 L1: 0.016981 Grad: 0.122872 Thermal: 0.000537 LR: 8.68e-06\n",
      "Epoch  19 [1250/10697 ( 11.7%)] Loss: 0.029295 L1: 0.016981 Grad: 0.122872 Thermal: 0.000537 LR: 8.68e-06\n",
      "Epoch  19 [1300/10697 ( 12.2%)] Loss: 0.026781 L1: 0.015535 Grad: 0.112242 Thermal: 0.000441 LR: 8.68e-06\n",
      "Epoch  19 [1300/10697 ( 12.2%)] Loss: 0.026781 L1: 0.015535 Grad: 0.112242 Thermal: 0.000441 LR: 8.68e-06\n",
      "Epoch  19 [1350/10697 ( 12.6%)] Loss: 0.024875 L1: 0.015017 Grad: 0.098384 Thermal: 0.000393 LR: 8.68e-06\n",
      "Epoch  19 [1350/10697 ( 12.6%)] Loss: 0.024875 L1: 0.015017 Grad: 0.098384 Thermal: 0.000393 LR: 8.68e-06\n",
      "Epoch  19 [1400/10697 ( 13.1%)] Loss: 0.022153 L1: 0.012870 Grad: 0.092665 Thermal: 0.000339 LR: 8.68e-06\n",
      "Epoch  19 [1400/10697 ( 13.1%)] Loss: 0.022153 L1: 0.012870 Grad: 0.092665 Thermal: 0.000339 LR: 8.68e-06\n",
      "Epoch  19 [1450/10697 ( 13.6%)] Loss: 0.025655 L1: 0.014538 Grad: 0.110960 Thermal: 0.000403 LR: 8.68e-06\n",
      "Epoch  19 [1450/10697 ( 13.6%)] Loss: 0.025655 L1: 0.014538 Grad: 0.110960 Thermal: 0.000403 LR: 8.68e-06\n",
      "Epoch  19 [1500/10697 ( 14.0%)] Loss: 0.026422 L1: 0.015376 Grad: 0.110217 Thermal: 0.000495 LR: 8.68e-06\n",
      "Epoch  19 [1500/10697 ( 14.0%)] Loss: 0.026422 L1: 0.015376 Grad: 0.110217 Thermal: 0.000495 LR: 8.68e-06\n",
      "Epoch  19 [1550/10697 ( 14.5%)] Loss: 0.024106 L1: 0.013686 Grad: 0.104019 Thermal: 0.000358 LR: 8.68e-06\n",
      "Epoch  19 [1550/10697 ( 14.5%)] Loss: 0.024106 L1: 0.013686 Grad: 0.104019 Thermal: 0.000358 LR: 8.68e-06\n",
      "Epoch  19 [1600/10697 ( 15.0%)] Loss: 0.023941 L1: 0.013942 Grad: 0.099800 Thermal: 0.000371 LR: 8.68e-06\n",
      "Epoch  19 [1600/10697 ( 15.0%)] Loss: 0.023941 L1: 0.013942 Grad: 0.099800 Thermal: 0.000371 LR: 8.68e-06\n",
      "Epoch  19 [1650/10697 ( 15.4%)] Loss: 0.033712 L1: 0.019804 Grad: 0.138716 Thermal: 0.000729 LR: 8.68e-06\n",
      "Epoch  19 [1650/10697 ( 15.4%)] Loss: 0.033712 L1: 0.019804 Grad: 0.138716 Thermal: 0.000729 LR: 8.68e-06\n",
      "Epoch  19 [1700/10697 ( 15.9%)] Loss: 0.025185 L1: 0.014486 Grad: 0.106793 Thermal: 0.000407 LR: 8.68e-06\n",
      "Epoch  19 [1700/10697 ( 15.9%)] Loss: 0.025185 L1: 0.014486 Grad: 0.106793 Thermal: 0.000407 LR: 8.68e-06\n",
      "Epoch  19 [1750/10697 ( 16.4%)] Loss: 0.037051 L1: 0.021311 Grad: 0.156925 Thermal: 0.000944 LR: 8.68e-06\n",
      "Epoch  19 [1750/10697 ( 16.4%)] Loss: 0.037051 L1: 0.021311 Grad: 0.156925 Thermal: 0.000944 LR: 8.68e-06\n",
      "Epoch  19 [1800/10697 ( 16.8%)] Loss: 0.031521 L1: 0.017910 Grad: 0.135831 Thermal: 0.000568 LR: 8.68e-06\n",
      "Epoch  19 [1800/10697 ( 16.8%)] Loss: 0.031521 L1: 0.017910 Grad: 0.135831 Thermal: 0.000568 LR: 8.68e-06\n",
      "Epoch  19 [1850/10697 ( 17.3%)] Loss: 0.027986 L1: 0.016252 Grad: 0.117107 Thermal: 0.000463 LR: 8.68e-06\n",
      "Epoch  19 [1850/10697 ( 17.3%)] Loss: 0.027986 L1: 0.016252 Grad: 0.117107 Thermal: 0.000463 LR: 8.68e-06\n",
      "Epoch  19 [1900/10697 ( 17.8%)] Loss: 0.022430 L1: 0.013302 Grad: 0.091099 Thermal: 0.000370 LR: 8.68e-06\n",
      "Epoch  19 [1900/10697 ( 17.8%)] Loss: 0.022430 L1: 0.013302 Grad: 0.091099 Thermal: 0.000370 LR: 8.68e-06\n",
      "Epoch  19 [1950/10697 ( 18.2%)] Loss: 0.034994 L1: 0.020057 Grad: 0.148985 Thermal: 0.000761 LR: 8.68e-06\n",
      "Epoch  19 [1950/10697 ( 18.2%)] Loss: 0.034994 L1: 0.020057 Grad: 0.148985 Thermal: 0.000761 LR: 8.68e-06\n",
      "Epoch  19 [2000/10697 ( 18.7%)] Loss: 0.030351 L1: 0.018002 Grad: 0.123202 Thermal: 0.000567 LR: 8.68e-06\n",
      "Epoch  19 [2000/10697 ( 18.7%)] Loss: 0.030351 L1: 0.018002 Grad: 0.123202 Thermal: 0.000567 LR: 8.68e-06\n",
      "Epoch  19 [2050/10697 ( 19.2%)] Loss: 0.026271 L1: 0.015505 Grad: 0.107439 Thermal: 0.000435 LR: 8.68e-06\n",
      "Epoch  19 [2050/10697 ( 19.2%)] Loss: 0.026271 L1: 0.015505 Grad: 0.107439 Thermal: 0.000435 LR: 8.68e-06\n",
      "Epoch  19 [2100/10697 ( 19.6%)] Loss: 0.027660 L1: 0.016684 Grad: 0.109508 Thermal: 0.000491 LR: 8.68e-06\n",
      "Epoch  19 [2100/10697 ( 19.6%)] Loss: 0.027660 L1: 0.016684 Grad: 0.109508 Thermal: 0.000491 LR: 8.68e-06\n",
      "Epoch  19 [2150/10697 ( 20.1%)] Loss: 0.020649 L1: 0.011966 Grad: 0.086684 Thermal: 0.000301 LR: 8.68e-06\n",
      "Epoch  19 [2150/10697 ( 20.1%)] Loss: 0.020649 L1: 0.011966 Grad: 0.086684 Thermal: 0.000301 LR: 8.68e-06\n",
      "Epoch  19 [2200/10697 ( 20.6%)] Loss: 0.022255 L1: 0.012837 Grad: 0.094016 Thermal: 0.000335 LR: 8.68e-06\n",
      "Epoch  19 [2200/10697 ( 20.6%)] Loss: 0.022255 L1: 0.012837 Grad: 0.094016 Thermal: 0.000335 LR: 8.68e-06\n",
      "Epoch  19 [2250/10697 ( 21.0%)] Loss: 0.026553 L1: 0.015901 Grad: 0.106299 Thermal: 0.000448 LR: 8.68e-06\n",
      "Epoch  19 [2250/10697 ( 21.0%)] Loss: 0.026553 L1: 0.015901 Grad: 0.106299 Thermal: 0.000448 LR: 8.68e-06\n",
      "Epoch  19 [2300/10697 ( 21.5%)] Loss: 0.034979 L1: 0.020121 Grad: 0.148176 Thermal: 0.000804 LR: 8.68e-06\n",
      "Epoch  19 [2300/10697 ( 21.5%)] Loss: 0.034979 L1: 0.020121 Grad: 0.148176 Thermal: 0.000804 LR: 8.68e-06\n",
      "Epoch  19 [2350/10697 ( 22.0%)] Loss: 0.024450 L1: 0.014271 Grad: 0.101602 Thermal: 0.000376 LR: 8.68e-06\n",
      "Epoch  19 [2350/10697 ( 22.0%)] Loss: 0.024450 L1: 0.014271 Grad: 0.101602 Thermal: 0.000376 LR: 8.68e-06\n",
      "Epoch  19 [2400/10697 ( 22.4%)] Loss: 0.023027 L1: 0.013194 Grad: 0.098168 Thermal: 0.000331 LR: 8.68e-06\n",
      "Epoch  19 [2400/10697 ( 22.4%)] Loss: 0.023027 L1: 0.013194 Grad: 0.098168 Thermal: 0.000331 LR: 8.68e-06\n",
      "Epoch  19 [2450/10697 ( 22.9%)] Loss: 0.028510 L1: 0.016645 Grad: 0.118401 Thermal: 0.000515 LR: 8.68e-06\n",
      "Epoch  19 [2450/10697 ( 22.9%)] Loss: 0.028510 L1: 0.016645 Grad: 0.118401 Thermal: 0.000515 LR: 8.68e-06\n",
      "Epoch  19 [2500/10697 ( 23.4%)] Loss: 0.031378 L1: 0.017976 Grad: 0.133716 Thermal: 0.000604 LR: 8.68e-06\n",
      "Epoch  19 [2500/10697 ( 23.4%)] Loss: 0.031378 L1: 0.017976 Grad: 0.133716 Thermal: 0.000604 LR: 8.68e-06\n",
      "Epoch  19 [2550/10697 ( 23.8%)] Loss: 0.017203 L1: 0.009872 Grad: 0.073182 Thermal: 0.000239 LR: 8.68e-06\n",
      "Epoch  19 [2550/10697 ( 23.8%)] Loss: 0.017203 L1: 0.009872 Grad: 0.073182 Thermal: 0.000239 LR: 8.68e-06\n",
      "Epoch  19 [2600/10697 ( 24.3%)] Loss: 0.022942 L1: 0.013257 Grad: 0.096675 Thermal: 0.000366 LR: 8.68e-06\n",
      "Epoch  19 [2600/10697 ( 24.3%)] Loss: 0.022942 L1: 0.013257 Grad: 0.096675 Thermal: 0.000366 LR: 8.68e-06\n",
      "Epoch  19 [2650/10697 ( 24.8%)] Loss: 0.027290 L1: 0.016125 Grad: 0.111411 Thermal: 0.000482 LR: 8.68e-06\n",
      "Epoch  19 [2650/10697 ( 24.8%)] Loss: 0.027290 L1: 0.016125 Grad: 0.111411 Thermal: 0.000482 LR: 8.68e-06\n",
      "Epoch  19 [2700/10697 ( 25.2%)] Loss: 0.024657 L1: 0.014661 Grad: 0.099764 Thermal: 0.000409 LR: 8.68e-06\n",
      "Epoch  19 [2700/10697 ( 25.2%)] Loss: 0.024657 L1: 0.014661 Grad: 0.099764 Thermal: 0.000409 LR: 8.68e-06\n",
      "Epoch  19 [2750/10697 ( 25.7%)] Loss: 0.026030 L1: 0.015583 Grad: 0.104245 Thermal: 0.000450 LR: 8.68e-06\n",
      "Epoch  19 [2750/10697 ( 25.7%)] Loss: 0.026030 L1: 0.015583 Grad: 0.104245 Thermal: 0.000450 LR: 8.68e-06\n",
      "Epoch  19 [2800/10697 ( 26.2%)] Loss: 0.024526 L1: 0.014121 Grad: 0.103859 Thermal: 0.000381 LR: 8.68e-06\n",
      "Epoch  19 [2800/10697 ( 26.2%)] Loss: 0.024526 L1: 0.014121 Grad: 0.103859 Thermal: 0.000381 LR: 8.68e-06\n",
      "Epoch  19 [2850/10697 ( 26.6%)] Loss: 0.023868 L1: 0.013868 Grad: 0.099801 Thermal: 0.000392 LR: 8.68e-06\n",
      "Epoch  19 [2850/10697 ( 26.6%)] Loss: 0.023868 L1: 0.013868 Grad: 0.099801 Thermal: 0.000392 LR: 8.68e-06\n",
      "Epoch  19 [2900/10697 ( 27.1%)] Loss: 0.032029 L1: 0.018737 Grad: 0.132602 Thermal: 0.000636 LR: 8.68e-06\n",
      "Epoch  19 [2900/10697 ( 27.1%)] Loss: 0.032029 L1: 0.018737 Grad: 0.132602 Thermal: 0.000636 LR: 8.68e-06\n",
      "Epoch  19 [2950/10697 ( 27.6%)] Loss: 0.025262 L1: 0.014476 Grad: 0.107666 Thermal: 0.000380 LR: 8.68e-06\n",
      "Epoch  19 [2950/10697 ( 27.6%)] Loss: 0.025262 L1: 0.014476 Grad: 0.107666 Thermal: 0.000380 LR: 8.68e-06\n",
      "Epoch  19 [3000/10697 ( 28.0%)] Loss: 0.025366 L1: 0.014380 Grad: 0.109661 Thermal: 0.000396 LR: 8.68e-06\n",
      "Epoch  19 [3000/10697 ( 28.0%)] Loss: 0.025366 L1: 0.014380 Grad: 0.109661 Thermal: 0.000396 LR: 8.68e-06\n",
      "Epoch  19 [3050/10697 ( 28.5%)] Loss: 0.034240 L1: 0.019455 Grad: 0.147522 Thermal: 0.000662 LR: 8.68e-06\n",
      "Epoch  19 [3050/10697 ( 28.5%)] Loss: 0.034240 L1: 0.019455 Grad: 0.147522 Thermal: 0.000662 LR: 8.68e-06\n",
      "Epoch  19 [3100/10697 ( 29.0%)] Loss: 0.028790 L1: 0.017000 Grad: 0.117626 Thermal: 0.000533 LR: 8.68e-06\n",
      "Epoch  19 [3100/10697 ( 29.0%)] Loss: 0.028790 L1: 0.017000 Grad: 0.117626 Thermal: 0.000533 LR: 8.68e-06\n",
      "Epoch  19 [3150/10697 ( 29.4%)] Loss: 0.028659 L1: 0.016627 Grad: 0.120021 Thermal: 0.000601 LR: 8.68e-06\n",
      "Epoch  19 [3150/10697 ( 29.4%)] Loss: 0.028659 L1: 0.016627 Grad: 0.120021 Thermal: 0.000601 LR: 8.68e-06\n",
      "Epoch  19 [3200/10697 ( 29.9%)] Loss: 0.029492 L1: 0.017386 Grad: 0.120761 Thermal: 0.000581 LR: 8.68e-06\n",
      "Epoch  19 [3200/10697 ( 29.9%)] Loss: 0.029492 L1: 0.017386 Grad: 0.120761 Thermal: 0.000581 LR: 8.68e-06\n",
      "Epoch  19 [3250/10697 ( 30.4%)] Loss: 0.026224 L1: 0.015282 Grad: 0.109192 Thermal: 0.000449 LR: 8.68e-06\n",
      "Epoch  19 [3250/10697 ( 30.4%)] Loss: 0.026224 L1: 0.015282 Grad: 0.109192 Thermal: 0.000449 LR: 8.68e-06\n",
      "Epoch  19 [3300/10697 ( 30.8%)] Loss: 0.028174 L1: 0.016832 Grad: 0.113160 Thermal: 0.000520 LR: 8.68e-06\n",
      "Epoch  19 [3300/10697 ( 30.8%)] Loss: 0.028174 L1: 0.016832 Grad: 0.113160 Thermal: 0.000520 LR: 8.68e-06\n",
      "Epoch  19 [3350/10697 ( 31.3%)] Loss: 0.025925 L1: 0.015403 Grad: 0.104992 Thermal: 0.000455 LR: 8.68e-06\n",
      "Epoch  19 [3350/10697 ( 31.3%)] Loss: 0.025925 L1: 0.015403 Grad: 0.104992 Thermal: 0.000455 LR: 8.68e-06\n",
      "Epoch  19 [3400/10697 ( 31.8%)] Loss: 0.024217 L1: 0.013825 Grad: 0.103734 Thermal: 0.000371 LR: 8.68e-06\n",
      "Epoch  19 [3400/10697 ( 31.8%)] Loss: 0.024217 L1: 0.013825 Grad: 0.103734 Thermal: 0.000371 LR: 8.68e-06\n",
      "Epoch  19 [3450/10697 ( 32.3%)] Loss: 0.025725 L1: 0.015249 Grad: 0.104557 Thermal: 0.000409 LR: 8.68e-06\n",
      "Epoch  19 [3450/10697 ( 32.3%)] Loss: 0.025725 L1: 0.015249 Grad: 0.104557 Thermal: 0.000409 LR: 8.68e-06\n",
      "Epoch  19 [3500/10697 ( 32.7%)] Loss: 0.025452 L1: 0.014838 Grad: 0.105916 Thermal: 0.000447 LR: 8.68e-06\n",
      "Epoch  19 [3500/10697 ( 32.7%)] Loss: 0.025452 L1: 0.014838 Grad: 0.105916 Thermal: 0.000447 LR: 8.68e-06\n",
      "Epoch  19 [3550/10697 ( 33.2%)] Loss: 0.026239 L1: 0.015126 Grad: 0.110890 Thermal: 0.000473 LR: 8.68e-06\n",
      "Epoch  19 [3550/10697 ( 33.2%)] Loss: 0.026239 L1: 0.015126 Grad: 0.110890 Thermal: 0.000473 LR: 8.68e-06\n",
      "Epoch  19 [3600/10697 ( 33.7%)] Loss: 0.024921 L1: 0.014769 Grad: 0.101320 Thermal: 0.000404 LR: 8.68e-06\n",
      "Epoch  19 [3600/10697 ( 33.7%)] Loss: 0.024921 L1: 0.014769 Grad: 0.101320 Thermal: 0.000404 LR: 8.68e-06\n",
      "Epoch  19 [3650/10697 ( 34.1%)] Loss: 0.026386 L1: 0.015581 Grad: 0.107824 Thermal: 0.000452 LR: 8.68e-06\n",
      "Epoch  19 [3650/10697 ( 34.1%)] Loss: 0.026386 L1: 0.015581 Grad: 0.107824 Thermal: 0.000452 LR: 8.68e-06\n",
      "Epoch  19 [3700/10697 ( 34.6%)] Loss: 0.021794 L1: 0.012524 Grad: 0.092544 Thermal: 0.000309 LR: 8.68e-06\n",
      "Epoch  19 [3700/10697 ( 34.6%)] Loss: 0.021794 L1: 0.012524 Grad: 0.092544 Thermal: 0.000309 LR: 8.68e-06\n",
      "Epoch  19 [3750/10697 ( 35.1%)] Loss: 0.027838 L1: 0.016160 Grad: 0.116547 Thermal: 0.000478 LR: 8.68e-06\n",
      "Epoch  19 [3750/10697 ( 35.1%)] Loss: 0.027838 L1: 0.016160 Grad: 0.116547 Thermal: 0.000478 LR: 8.68e-06\n",
      "Epoch  19 [3800/10697 ( 35.5%)] Loss: 0.024309 L1: 0.014256 Grad: 0.100348 Thermal: 0.000375 LR: 8.68e-06\n",
      "Epoch  19 [3800/10697 ( 35.5%)] Loss: 0.024309 L1: 0.014256 Grad: 0.100348 Thermal: 0.000375 LR: 8.68e-06\n",
      "Epoch  19 [3850/10697 ( 36.0%)] Loss: 0.031574 L1: 0.017858 Grad: 0.136882 Thermal: 0.000567 LR: 8.68e-06\n",
      "Epoch  19 [3850/10697 ( 36.0%)] Loss: 0.031574 L1: 0.017858 Grad: 0.136882 Thermal: 0.000567 LR: 8.68e-06\n",
      "Epoch  19 [3900/10697 ( 36.5%)] Loss: 0.023535 L1: 0.013540 Grad: 0.099752 Thermal: 0.000416 LR: 8.68e-06\n",
      "Epoch  19 [3900/10697 ( 36.5%)] Loss: 0.023535 L1: 0.013540 Grad: 0.099752 Thermal: 0.000416 LR: 8.68e-06\n",
      "Epoch  19 [3950/10697 ( 36.9%)] Loss: 0.027508 L1: 0.015603 Grad: 0.118760 Thermal: 0.000593 LR: 8.68e-06\n",
      "Epoch  19 [3950/10697 ( 36.9%)] Loss: 0.027508 L1: 0.015603 Grad: 0.118760 Thermal: 0.000593 LR: 8.68e-06\n",
      "Epoch  19 [4000/10697 ( 37.4%)] Loss: 0.027539 L1: 0.016081 Grad: 0.114288 Thermal: 0.000575 LR: 8.68e-06\n",
      "Epoch  19 [4000/10697 ( 37.4%)] Loss: 0.027539 L1: 0.016081 Grad: 0.114288 Thermal: 0.000575 LR: 8.68e-06\n",
      "Epoch  19 [4050/10697 ( 37.9%)] Loss: 0.027046 L1: 0.016318 Grad: 0.107048 Thermal: 0.000465 LR: 8.68e-06\n",
      "Epoch  19 [4050/10697 ( 37.9%)] Loss: 0.027046 L1: 0.016318 Grad: 0.107048 Thermal: 0.000465 LR: 8.68e-06\n",
      "Epoch  19 [4100/10697 ( 38.3%)] Loss: 0.031636 L1: 0.018279 Grad: 0.133239 Thermal: 0.000649 LR: 8.68e-06\n",
      "Epoch  19 [4100/10697 ( 38.3%)] Loss: 0.031636 L1: 0.018279 Grad: 0.133239 Thermal: 0.000649 LR: 8.68e-06\n",
      "Epoch  19 [4150/10697 ( 38.8%)] Loss: 0.028050 L1: 0.016385 Grad: 0.116403 Thermal: 0.000493 LR: 8.68e-06\n",
      "Epoch  19 [4150/10697 ( 38.8%)] Loss: 0.028050 L1: 0.016385 Grad: 0.116403 Thermal: 0.000493 LR: 8.68e-06\n",
      "Epoch  19 [4200/10697 ( 39.3%)] Loss: 0.025189 L1: 0.014859 Grad: 0.103100 Thermal: 0.000409 LR: 8.68e-06\n",
      "Epoch  19 [4200/10697 ( 39.3%)] Loss: 0.025189 L1: 0.014859 Grad: 0.103100 Thermal: 0.000409 LR: 8.68e-06\n",
      "Epoch  19 [4250/10697 ( 39.7%)] Loss: 0.026306 L1: 0.015831 Grad: 0.104528 Thermal: 0.000452 LR: 8.68e-06\n",
      "Epoch  19 [4250/10697 ( 39.7%)] Loss: 0.026306 L1: 0.015831 Grad: 0.104528 Thermal: 0.000452 LR: 8.68e-06\n",
      "Epoch  19 [4300/10697 ( 40.2%)] Loss: 0.028248 L1: 0.016685 Grad: 0.115377 Thermal: 0.000504 LR: 8.68e-06\n",
      "Epoch  19 [4300/10697 ( 40.2%)] Loss: 0.028248 L1: 0.016685 Grad: 0.115377 Thermal: 0.000504 LR: 8.68e-06\n",
      "Epoch  19 [4350/10697 ( 40.7%)] Loss: 0.026791 L1: 0.015137 Grad: 0.116288 Thermal: 0.000492 LR: 8.68e-06\n",
      "Epoch  19 [4350/10697 ( 40.7%)] Loss: 0.026791 L1: 0.015137 Grad: 0.116288 Thermal: 0.000492 LR: 8.68e-06\n",
      "Epoch  19 [4400/10697 ( 41.1%)] Loss: 0.025256 L1: 0.014792 Grad: 0.104436 Thermal: 0.000406 LR: 8.68e-06\n",
      "Epoch  19 [4400/10697 ( 41.1%)] Loss: 0.025256 L1: 0.014792 Grad: 0.104436 Thermal: 0.000406 LR: 8.68e-06\n",
      "Epoch  19 [4450/10697 ( 41.6%)] Loss: 0.028147 L1: 0.016451 Grad: 0.116717 Thermal: 0.000478 LR: 8.68e-06\n",
      "Epoch  19 [4450/10697 ( 41.6%)] Loss: 0.028147 L1: 0.016451 Grad: 0.116717 Thermal: 0.000478 LR: 8.68e-06\n",
      "Epoch  19 [4500/10697 ( 42.1%)] Loss: 0.024527 L1: 0.014489 Grad: 0.100177 Thermal: 0.000397 LR: 8.68e-06\n",
      "Epoch  19 [4500/10697 ( 42.1%)] Loss: 0.024527 L1: 0.014489 Grad: 0.100177 Thermal: 0.000397 LR: 8.68e-06\n",
      "Epoch  19 [4550/10697 ( 42.5%)] Loss: 0.027238 L1: 0.015867 Grad: 0.113428 Thermal: 0.000562 LR: 8.68e-06\n",
      "Epoch  19 [4550/10697 ( 42.5%)] Loss: 0.027238 L1: 0.015867 Grad: 0.113428 Thermal: 0.000562 LR: 8.68e-06\n",
      "Epoch  19 [4600/10697 ( 43.0%)] Loss: 0.032356 L1: 0.018622 Grad: 0.137014 Thermal: 0.000646 LR: 8.68e-06\n",
      "Epoch  19 [4600/10697 ( 43.0%)] Loss: 0.032356 L1: 0.018622 Grad: 0.137014 Thermal: 0.000646 LR: 8.68e-06\n",
      "Epoch  19 [4650/10697 ( 43.5%)] Loss: 0.026303 L1: 0.014971 Grad: 0.113120 Thermal: 0.000399 LR: 8.68e-06\n",
      "Epoch  19 [4650/10697 ( 43.5%)] Loss: 0.026303 L1: 0.014971 Grad: 0.113120 Thermal: 0.000399 LR: 8.68e-06\n",
      "Epoch  19 [4700/10697 ( 43.9%)] Loss: 0.026498 L1: 0.015396 Grad: 0.110788 Thermal: 0.000457 LR: 8.68e-06\n",
      "Epoch  19 [4700/10697 ( 43.9%)] Loss: 0.026498 L1: 0.015396 Grad: 0.110788 Thermal: 0.000457 LR: 8.68e-06\n",
      "Epoch  19 [4750/10697 ( 44.4%)] Loss: 0.020053 L1: 0.011645 Grad: 0.083933 Thermal: 0.000312 LR: 8.68e-06\n",
      "Epoch  19 [4750/10697 ( 44.4%)] Loss: 0.020053 L1: 0.011645 Grad: 0.083933 Thermal: 0.000312 LR: 8.68e-06\n",
      "Epoch  19 [4800/10697 ( 44.9%)] Loss: 0.024193 L1: 0.014271 Grad: 0.099029 Thermal: 0.000384 LR: 8.68e-06\n",
      "Epoch  19 [4800/10697 ( 44.9%)] Loss: 0.024193 L1: 0.014271 Grad: 0.099029 Thermal: 0.000384 LR: 8.68e-06\n",
      "Epoch  19 [4850/10697 ( 45.3%)] Loss: 0.027784 L1: 0.016586 Grad: 0.111735 Thermal: 0.000490 LR: 8.68e-06\n",
      "Epoch  19 [4850/10697 ( 45.3%)] Loss: 0.027784 L1: 0.016586 Grad: 0.111735 Thermal: 0.000490 LR: 8.68e-06\n",
      "Epoch  19 [4900/10697 ( 45.8%)] Loss: 0.026433 L1: 0.015385 Grad: 0.110264 Thermal: 0.000436 LR: 8.68e-06\n",
      "Epoch  19 [4900/10697 ( 45.8%)] Loss: 0.026433 L1: 0.015385 Grad: 0.110264 Thermal: 0.000436 LR: 8.68e-06\n",
      "Epoch  19 [4950/10697 ( 46.3%)] Loss: 0.031751 L1: 0.018208 Grad: 0.135106 Thermal: 0.000653 LR: 8.68e-06\n",
      "Epoch  19 [4950/10697 ( 46.3%)] Loss: 0.031751 L1: 0.018208 Grad: 0.135106 Thermal: 0.000653 LR: 8.68e-06\n",
      "Epoch  19 [5000/10697 ( 46.7%)] Loss: 0.021075 L1: 0.012073 Grad: 0.089870 Thermal: 0.000305 LR: 8.68e-06\n",
      "Epoch  19 [5000/10697 ( 46.7%)] Loss: 0.021075 L1: 0.012073 Grad: 0.089870 Thermal: 0.000305 LR: 8.68e-06\n",
      "Epoch  19 [5050/10697 ( 47.2%)] Loss: 0.028208 L1: 0.016518 Grad: 0.116641 Thermal: 0.000503 LR: 8.68e-06\n",
      "Epoch  19 [5050/10697 ( 47.2%)] Loss: 0.028208 L1: 0.016518 Grad: 0.116641 Thermal: 0.000503 LR: 8.68e-06\n",
      "Epoch  19 [5100/10697 ( 47.7%)] Loss: 0.026989 L1: 0.015971 Grad: 0.109950 Thermal: 0.000465 LR: 8.68e-06\n",
      "Epoch  19 [5100/10697 ( 47.7%)] Loss: 0.026989 L1: 0.015971 Grad: 0.109950 Thermal: 0.000465 LR: 8.68e-06\n",
      "Epoch  19 [5150/10697 ( 48.1%)] Loss: 0.026659 L1: 0.015737 Grad: 0.109001 Thermal: 0.000443 LR: 8.68e-06\n",
      "Epoch  19 [5150/10697 ( 48.1%)] Loss: 0.026659 L1: 0.015737 Grad: 0.109001 Thermal: 0.000443 LR: 8.68e-06\n",
      "Epoch  19 [5200/10697 ( 48.6%)] Loss: 0.030325 L1: 0.017656 Grad: 0.126381 Thermal: 0.000618 LR: 8.68e-06\n",
      "Epoch  19 [5200/10697 ( 48.6%)] Loss: 0.030325 L1: 0.017656 Grad: 0.126381 Thermal: 0.000618 LR: 8.68e-06\n",
      "Epoch  19 [5250/10697 ( 49.1%)] Loss: 0.027693 L1: 0.016219 Grad: 0.114503 Thermal: 0.000472 LR: 8.68e-06\n",
      "Epoch  19 [5250/10697 ( 49.1%)] Loss: 0.027693 L1: 0.016219 Grad: 0.114503 Thermal: 0.000472 LR: 8.68e-06\n",
      "Epoch  19 [5300/10697 ( 49.5%)] Loss: 0.023278 L1: 0.013320 Grad: 0.099389 Thermal: 0.000384 LR: 8.68e-06\n",
      "Epoch  19 [5300/10697 ( 49.5%)] Loss: 0.023278 L1: 0.013320 Grad: 0.099389 Thermal: 0.000384 LR: 8.68e-06\n",
      "Epoch  19 [5350/10697 ( 50.0%)] Loss: 0.025145 L1: 0.014778 Grad: 0.103464 Thermal: 0.000412 LR: 8.68e-06\n",
      "Epoch  19 [5350/10697 ( 50.0%)] Loss: 0.025145 L1: 0.014778 Grad: 0.103464 Thermal: 0.000412 LR: 8.68e-06\n",
      "Epoch  19 [5400/10697 ( 50.5%)] Loss: 0.026381 L1: 0.015374 Grad: 0.109878 Thermal: 0.000396 LR: 8.68e-06\n",
      "Epoch  19 [5400/10697 ( 50.5%)] Loss: 0.026381 L1: 0.015374 Grad: 0.109878 Thermal: 0.000396 LR: 8.68e-06\n",
      "Epoch  19 [5450/10697 ( 50.9%)] Loss: 0.024340 L1: 0.013863 Grad: 0.104506 Thermal: 0.000531 LR: 8.68e-06\n",
      "Epoch  19 [5450/10697 ( 50.9%)] Loss: 0.024340 L1: 0.013863 Grad: 0.104506 Thermal: 0.000531 LR: 8.68e-06\n",
      "Epoch  19 [5500/10697 ( 51.4%)] Loss: 0.023969 L1: 0.014015 Grad: 0.099354 Thermal: 0.000375 LR: 8.68e-06\n",
      "Epoch  19 [5500/10697 ( 51.4%)] Loss: 0.023969 L1: 0.014015 Grad: 0.099354 Thermal: 0.000375 LR: 8.68e-06\n",
      "Epoch  19 [5550/10697 ( 51.9%)] Loss: 0.025398 L1: 0.015010 Grad: 0.103653 Thermal: 0.000444 LR: 8.68e-06\n",
      "Epoch  19 [5550/10697 ( 51.9%)] Loss: 0.025398 L1: 0.015010 Grad: 0.103653 Thermal: 0.000444 LR: 8.68e-06\n",
      "Epoch  19 [5600/10697 ( 52.4%)] Loss: 0.022461 L1: 0.013351 Grad: 0.090916 Thermal: 0.000353 LR: 8.68e-06\n",
      "Epoch  19 [5600/10697 ( 52.4%)] Loss: 0.022461 L1: 0.013351 Grad: 0.090916 Thermal: 0.000353 LR: 8.68e-06\n",
      "Epoch  19 [5650/10697 ( 52.8%)] Loss: 0.031909 L1: 0.018858 Grad: 0.130187 Thermal: 0.000640 LR: 8.68e-06\n",
      "Epoch  19 [5650/10697 ( 52.8%)] Loss: 0.031909 L1: 0.018858 Grad: 0.130187 Thermal: 0.000640 LR: 8.68e-06\n",
      "Epoch  19 [5700/10697 ( 53.3%)] Loss: 0.025544 L1: 0.014122 Grad: 0.114016 Thermal: 0.000408 LR: 8.68e-06\n",
      "Epoch  19 [5700/10697 ( 53.3%)] Loss: 0.025544 L1: 0.014122 Grad: 0.114016 Thermal: 0.000408 LR: 8.68e-06\n",
      "Epoch  19 [5750/10697 ( 53.8%)] Loss: 0.022140 L1: 0.012940 Grad: 0.091826 Thermal: 0.000340 LR: 8.68e-06\n",
      "Epoch  19 [5750/10697 ( 53.8%)] Loss: 0.022140 L1: 0.012940 Grad: 0.091826 Thermal: 0.000340 LR: 8.68e-06\n",
      "Epoch  19 [5800/10697 ( 54.2%)] Loss: 0.028946 L1: 0.016581 Grad: 0.123397 Thermal: 0.000510 LR: 8.68e-06\n",
      "Epoch  19 [5800/10697 ( 54.2%)] Loss: 0.028946 L1: 0.016581 Grad: 0.123397 Thermal: 0.000510 LR: 8.68e-06\n",
      "Epoch  19 [5850/10697 ( 54.7%)] Loss: 0.026216 L1: 0.015356 Grad: 0.108387 Thermal: 0.000422 LR: 8.68e-06\n",
      "Epoch  19 [5850/10697 ( 54.7%)] Loss: 0.026216 L1: 0.015356 Grad: 0.108387 Thermal: 0.000422 LR: 8.68e-06\n",
      "Epoch  19 [5900/10697 ( 55.2%)] Loss: 0.030919 L1: 0.017899 Grad: 0.129906 Thermal: 0.000593 LR: 8.68e-06\n",
      "Epoch  19 [5900/10697 ( 55.2%)] Loss: 0.030919 L1: 0.017899 Grad: 0.129906 Thermal: 0.000593 LR: 8.68e-06\n",
      "Epoch  19 [5950/10697 ( 55.6%)] Loss: 0.033696 L1: 0.019591 Grad: 0.140702 Thermal: 0.000686 LR: 8.68e-06\n",
      "Epoch  19 [5950/10697 ( 55.6%)] Loss: 0.033696 L1: 0.019591 Grad: 0.140702 Thermal: 0.000686 LR: 8.68e-06\n",
      "Epoch  19 [6000/10697 ( 56.1%)] Loss: 0.027604 L1: 0.015962 Grad: 0.116178 Thermal: 0.000466 LR: 8.68e-06\n",
      "Epoch  19 [6000/10697 ( 56.1%)] Loss: 0.027604 L1: 0.015962 Grad: 0.116178 Thermal: 0.000466 LR: 8.68e-06\n",
      "Epoch  19 [6050/10697 ( 56.6%)] Loss: 0.023109 L1: 0.013286 Grad: 0.098058 Thermal: 0.000349 LR: 8.68e-06\n",
      "Epoch  19 [6050/10697 ( 56.6%)] Loss: 0.023109 L1: 0.013286 Grad: 0.098058 Thermal: 0.000349 LR: 8.68e-06\n",
      "Epoch  19 [6100/10697 ( 57.0%)] Loss: 0.029356 L1: 0.016527 Grad: 0.128008 Thermal: 0.000559 LR: 8.68e-06\n",
      "Epoch  19 [6100/10697 ( 57.0%)] Loss: 0.029356 L1: 0.016527 Grad: 0.128008 Thermal: 0.000559 LR: 8.68e-06\n",
      "Epoch  19 [6150/10697 ( 57.5%)] Loss: 0.021585 L1: 0.012609 Grad: 0.089598 Thermal: 0.000321 LR: 8.68e-06\n",
      "Epoch  19 [6150/10697 ( 57.5%)] Loss: 0.021585 L1: 0.012609 Grad: 0.089598 Thermal: 0.000321 LR: 8.68e-06\n",
      "Epoch  19 [6200/10697 ( 58.0%)] Loss: 0.027892 L1: 0.016192 Grad: 0.116727 Thermal: 0.000537 LR: 8.68e-06\n",
      "Epoch  19 [6200/10697 ( 58.0%)] Loss: 0.027892 L1: 0.016192 Grad: 0.116727 Thermal: 0.000537 LR: 8.68e-06\n",
      "Epoch  19 [6250/10697 ( 58.4%)] Loss: 0.021522 L1: 0.012560 Grad: 0.089467 Thermal: 0.000309 LR: 8.68e-06\n",
      "Epoch  19 [6250/10697 ( 58.4%)] Loss: 0.021522 L1: 0.012560 Grad: 0.089467 Thermal: 0.000309 LR: 8.68e-06\n",
      "Epoch  19 [6300/10697 ( 58.9%)] Loss: 0.024219 L1: 0.014542 Grad: 0.096571 Thermal: 0.000395 LR: 8.68e-06\n",
      "Epoch  19 [6300/10697 ( 58.9%)] Loss: 0.024219 L1: 0.014542 Grad: 0.096571 Thermal: 0.000395 LR: 8.68e-06\n",
      "Epoch  19 [6350/10697 ( 59.4%)] Loss: 0.022863 L1: 0.013101 Grad: 0.097435 Thermal: 0.000354 LR: 8.68e-06\n",
      "Epoch  19 [6350/10697 ( 59.4%)] Loss: 0.022863 L1: 0.013101 Grad: 0.097435 Thermal: 0.000354 LR: 8.68e-06\n",
      "Epoch  19 [6400/10697 ( 59.8%)] Loss: 0.024325 L1: 0.014320 Grad: 0.099855 Thermal: 0.000387 LR: 8.68e-06\n",
      "Epoch  19 [6400/10697 ( 59.8%)] Loss: 0.024325 L1: 0.014320 Grad: 0.099855 Thermal: 0.000387 LR: 8.68e-06\n",
      "Epoch  19 [6450/10697 ( 60.3%)] Loss: 0.026764 L1: 0.015110 Grad: 0.116308 Thermal: 0.000461 LR: 8.68e-06\n",
      "Epoch  19 [6450/10697 ( 60.3%)] Loss: 0.026764 L1: 0.015110 Grad: 0.116308 Thermal: 0.000461 LR: 8.68e-06\n",
      "Epoch  19 [6500/10697 ( 60.8%)] Loss: 0.029005 L1: 0.016758 Grad: 0.122211 Thermal: 0.000499 LR: 8.68e-06\n",
      "Epoch  19 [6500/10697 ( 60.8%)] Loss: 0.029005 L1: 0.016758 Grad: 0.122211 Thermal: 0.000499 LR: 8.68e-06\n",
      "Epoch  19 [6550/10697 ( 61.2%)] Loss: 0.025029 L1: 0.014440 Grad: 0.105649 Thermal: 0.000478 LR: 8.68e-06\n",
      "Epoch  19 [6550/10697 ( 61.2%)] Loss: 0.025029 L1: 0.014440 Grad: 0.105649 Thermal: 0.000478 LR: 8.68e-06\n",
      "Epoch  19 [6600/10697 ( 61.7%)] Loss: 0.025122 L1: 0.014736 Grad: 0.103651 Thermal: 0.000417 LR: 8.68e-06\n",
      "Epoch  19 [6600/10697 ( 61.7%)] Loss: 0.025122 L1: 0.014736 Grad: 0.103651 Thermal: 0.000417 LR: 8.68e-06\n",
      "Epoch  19 [6650/10697 ( 62.2%)] Loss: 0.019765 L1: 0.011648 Grad: 0.081027 Thermal: 0.000278 LR: 8.68e-06\n",
      "Epoch  19 [6650/10697 ( 62.2%)] Loss: 0.019765 L1: 0.011648 Grad: 0.081027 Thermal: 0.000278 LR: 8.68e-06\n",
      "Epoch  19 [6700/10697 ( 62.6%)] Loss: 0.033602 L1: 0.019401 Grad: 0.141650 Thermal: 0.000714 LR: 8.68e-06\n",
      "Epoch  19 [6700/10697 ( 62.6%)] Loss: 0.033602 L1: 0.019401 Grad: 0.141650 Thermal: 0.000714 LR: 8.68e-06\n",
      "Epoch  19 [6750/10697 ( 63.1%)] Loss: 0.025096 L1: 0.014716 Grad: 0.103596 Thermal: 0.000410 LR: 8.68e-06\n",
      "Epoch  19 [6750/10697 ( 63.1%)] Loss: 0.025096 L1: 0.014716 Grad: 0.103596 Thermal: 0.000410 LR: 8.68e-06\n",
      "Epoch  19 [6800/10697 ( 63.6%)] Loss: 0.025567 L1: 0.014956 Grad: 0.105886 Thermal: 0.000446 LR: 8.68e-06\n",
      "Epoch  19 [6800/10697 ( 63.6%)] Loss: 0.025567 L1: 0.014956 Grad: 0.105886 Thermal: 0.000446 LR: 8.68e-06\n",
      "Epoch  19 [6850/10697 ( 64.0%)] Loss: 0.023261 L1: 0.013291 Grad: 0.099525 Thermal: 0.000338 LR: 8.68e-06\n",
      "Epoch  19 [6850/10697 ( 64.0%)] Loss: 0.023261 L1: 0.013291 Grad: 0.099525 Thermal: 0.000338 LR: 8.68e-06\n",
      "Epoch  19 [6900/10697 ( 64.5%)] Loss: 0.025966 L1: 0.015109 Grad: 0.108369 Thermal: 0.000395 LR: 8.68e-06\n",
      "Epoch  19 [6900/10697 ( 64.5%)] Loss: 0.025966 L1: 0.015109 Grad: 0.108369 Thermal: 0.000395 LR: 8.68e-06\n",
      "Epoch  19 [6950/10697 ( 65.0%)] Loss: 0.025742 L1: 0.015203 Grad: 0.105180 Thermal: 0.000424 LR: 8.68e-06\n",
      "Epoch  19 [6950/10697 ( 65.0%)] Loss: 0.025742 L1: 0.015203 Grad: 0.105180 Thermal: 0.000424 LR: 8.68e-06\n",
      "Epoch  19 [7000/10697 ( 65.4%)] Loss: 0.026909 L1: 0.015764 Grad: 0.111227 Thermal: 0.000442 LR: 8.68e-06\n",
      "Epoch  19 [7000/10697 ( 65.4%)] Loss: 0.026909 L1: 0.015764 Grad: 0.111227 Thermal: 0.000442 LR: 8.68e-06\n",
      "Epoch  19 [7050/10697 ( 65.9%)] Loss: 0.027483 L1: 0.016232 Grad: 0.112266 Thermal: 0.000485 LR: 8.68e-06\n",
      "Epoch  19 [7050/10697 ( 65.9%)] Loss: 0.027483 L1: 0.016232 Grad: 0.112266 Thermal: 0.000485 LR: 8.68e-06\n",
      "Epoch  19 [7100/10697 ( 66.4%)] Loss: 0.031393 L1: 0.018774 Grad: 0.125880 Thermal: 0.000617 LR: 8.68e-06\n",
      "Epoch  19 [7100/10697 ( 66.4%)] Loss: 0.031393 L1: 0.018774 Grad: 0.125880 Thermal: 0.000617 LR: 8.68e-06\n",
      "Epoch  19 [7150/10697 ( 66.8%)] Loss: 0.027600 L1: 0.015992 Grad: 0.115843 Thermal: 0.000480 LR: 8.68e-06\n",
      "Epoch  19 [7150/10697 ( 66.8%)] Loss: 0.027600 L1: 0.015992 Grad: 0.115843 Thermal: 0.000480 LR: 8.68e-06\n",
      "Epoch  19 [7200/10697 ( 67.3%)] Loss: 0.027569 L1: 0.016082 Grad: 0.114622 Thermal: 0.000500 LR: 8.68e-06\n",
      "Epoch  19 [7200/10697 ( 67.3%)] Loss: 0.027569 L1: 0.016082 Grad: 0.114622 Thermal: 0.000500 LR: 8.68e-06\n",
      "Epoch  19 [7250/10697 ( 67.8%)] Loss: 0.025173 L1: 0.014828 Grad: 0.103251 Thermal: 0.000409 LR: 8.68e-06\n",
      "Epoch  19 [7250/10697 ( 67.8%)] Loss: 0.025173 L1: 0.014828 Grad: 0.103251 Thermal: 0.000409 LR: 8.68e-06\n",
      "Epoch  19 [7300/10697 ( 68.2%)] Loss: 0.020051 L1: 0.011723 Grad: 0.083134 Thermal: 0.000311 LR: 8.68e-06\n",
      "Epoch  19 [7300/10697 ( 68.2%)] Loss: 0.020051 L1: 0.011723 Grad: 0.083134 Thermal: 0.000311 LR: 8.68e-06\n",
      "Epoch  19 [7350/10697 ( 68.7%)] Loss: 0.022458 L1: 0.013420 Grad: 0.090192 Thermal: 0.000366 LR: 8.68e-06\n",
      "Epoch  19 [7350/10697 ( 68.7%)] Loss: 0.022458 L1: 0.013420 Grad: 0.090192 Thermal: 0.000366 LR: 8.68e-06\n",
      "Epoch  19 [7400/10697 ( 69.2%)] Loss: 0.023626 L1: 0.013912 Grad: 0.096948 Thermal: 0.000375 LR: 8.68e-06\n",
      "Epoch  19 [7400/10697 ( 69.2%)] Loss: 0.023626 L1: 0.013912 Grad: 0.096948 Thermal: 0.000375 LR: 8.68e-06\n",
      "Epoch  19 [7450/10697 ( 69.6%)] Loss: 0.026101 L1: 0.014734 Grad: 0.113451 Thermal: 0.000438 LR: 8.68e-06\n",
      "Epoch  19 [7450/10697 ( 69.6%)] Loss: 0.026101 L1: 0.014734 Grad: 0.113451 Thermal: 0.000438 LR: 8.68e-06\n",
      "Epoch  19 [7500/10697 ( 70.1%)] Loss: 0.026231 L1: 0.015577 Grad: 0.106305 Thermal: 0.000467 LR: 8.68e-06\n",
      "Epoch  19 [7500/10697 ( 70.1%)] Loss: 0.026231 L1: 0.015577 Grad: 0.106305 Thermal: 0.000467 LR: 8.68e-06\n",
      "Epoch  19 [7550/10697 ( 70.6%)] Loss: 0.020510 L1: 0.011962 Grad: 0.085329 Thermal: 0.000293 LR: 8.68e-06\n",
      "Epoch  19 [7550/10697 ( 70.6%)] Loss: 0.020510 L1: 0.011962 Grad: 0.085329 Thermal: 0.000293 LR: 8.68e-06\n",
      "Epoch  19 [7600/10697 ( 71.0%)] Loss: 0.025298 L1: 0.015167 Grad: 0.101094 Thermal: 0.000420 LR: 8.68e-06\n",
      "Epoch  19 [7600/10697 ( 71.0%)] Loss: 0.025298 L1: 0.015167 Grad: 0.101094 Thermal: 0.000420 LR: 8.68e-06\n",
      "Epoch  19 [7650/10697 ( 71.5%)] Loss: 0.027046 L1: 0.015672 Grad: 0.113490 Thermal: 0.000505 LR: 8.68e-06\n",
      "Epoch  19 [7650/10697 ( 71.5%)] Loss: 0.027046 L1: 0.015672 Grad: 0.113490 Thermal: 0.000505 LR: 8.68e-06\n",
      "Epoch  19 [7700/10697 ( 72.0%)] Loss: 0.033364 L1: 0.019748 Grad: 0.135811 Thermal: 0.000700 LR: 8.68e-06\n",
      "Epoch  19 [7700/10697 ( 72.0%)] Loss: 0.033364 L1: 0.019748 Grad: 0.135811 Thermal: 0.000700 LR: 8.68e-06\n",
      "Epoch  19 [7750/10697 ( 72.5%)] Loss: 0.019771 L1: 0.011398 Grad: 0.083600 Thermal: 0.000259 LR: 8.68e-06\n",
      "Epoch  19 [7750/10697 ( 72.5%)] Loss: 0.019771 L1: 0.011398 Grad: 0.083600 Thermal: 0.000259 LR: 8.68e-06\n",
      "Epoch  19 [7800/10697 ( 72.9%)] Loss: 0.028037 L1: 0.016711 Grad: 0.113013 Thermal: 0.000502 LR: 8.68e-06\n",
      "Epoch  19 [7800/10697 ( 72.9%)] Loss: 0.028037 L1: 0.016711 Grad: 0.113013 Thermal: 0.000502 LR: 8.68e-06\n",
      "Epoch  19 [7850/10697 ( 73.4%)] Loss: 0.028078 L1: 0.016224 Grad: 0.118284 Thermal: 0.000499 LR: 8.68e-06\n",
      "Epoch  19 [7850/10697 ( 73.4%)] Loss: 0.028078 L1: 0.016224 Grad: 0.118284 Thermal: 0.000499 LR: 8.68e-06\n",
      "Epoch  19 [7900/10697 ( 73.9%)] Loss: 0.028515 L1: 0.016482 Grad: 0.120076 Thermal: 0.000513 LR: 8.68e-06\n",
      "Epoch  19 [7900/10697 ( 73.9%)] Loss: 0.028515 L1: 0.016482 Grad: 0.120076 Thermal: 0.000513 LR: 8.68e-06\n",
      "Epoch  19 [7950/10697 ( 74.3%)] Loss: 0.029917 L1: 0.017385 Grad: 0.125013 Thermal: 0.000616 LR: 8.68e-06\n",
      "Epoch  19 [7950/10697 ( 74.3%)] Loss: 0.029917 L1: 0.017385 Grad: 0.125013 Thermal: 0.000616 LR: 8.68e-06\n",
      "Epoch  19 [8000/10697 ( 74.8%)] Loss: 0.029117 L1: 0.017062 Grad: 0.120297 Thermal: 0.000518 LR: 8.68e-06\n",
      "Epoch  19 [8000/10697 ( 74.8%)] Loss: 0.029117 L1: 0.017062 Grad: 0.120297 Thermal: 0.000518 LR: 8.68e-06\n",
      "Epoch  19 [8050/10697 ( 75.3%)] Loss: 0.031080 L1: 0.017754 Grad: 0.132961 Thermal: 0.000595 LR: 8.68e-06\n",
      "Epoch  19 [8050/10697 ( 75.3%)] Loss: 0.031080 L1: 0.017754 Grad: 0.132961 Thermal: 0.000595 LR: 8.68e-06\n",
      "Epoch  19 [8100/10697 ( 75.7%)] Loss: 0.025482 L1: 0.014595 Grad: 0.108666 Thermal: 0.000409 LR: 8.68e-06\n",
      "Epoch  19 [8100/10697 ( 75.7%)] Loss: 0.025482 L1: 0.014595 Grad: 0.108666 Thermal: 0.000409 LR: 8.68e-06\n",
      "Epoch  19 [8150/10697 ( 76.2%)] Loss: 0.023080 L1: 0.013131 Grad: 0.099320 Thermal: 0.000349 LR: 8.68e-06\n",
      "Epoch  19 [8150/10697 ( 76.2%)] Loss: 0.023080 L1: 0.013131 Grad: 0.099320 Thermal: 0.000349 LR: 8.68e-06\n",
      "Epoch  19 [8200/10697 ( 76.7%)] Loss: 0.027919 L1: 0.016239 Grad: 0.116553 Thermal: 0.000487 LR: 8.68e-06\n",
      "Epoch  19 [8200/10697 ( 76.7%)] Loss: 0.027919 L1: 0.016239 Grad: 0.116553 Thermal: 0.000487 LR: 8.68e-06\n",
      "Epoch  19 [8250/10697 ( 77.1%)] Loss: 0.022880 L1: 0.012982 Grad: 0.098761 Thermal: 0.000431 LR: 8.68e-06\n",
      "Epoch  19 [8250/10697 ( 77.1%)] Loss: 0.022880 L1: 0.012982 Grad: 0.098761 Thermal: 0.000431 LR: 8.68e-06\n",
      "Epoch  19 [8300/10697 ( 77.6%)] Loss: 0.025461 L1: 0.014718 Grad: 0.107197 Thermal: 0.000474 LR: 8.68e-06\n",
      "Epoch  19 [8300/10697 ( 77.6%)] Loss: 0.025461 L1: 0.014718 Grad: 0.107197 Thermal: 0.000474 LR: 8.68e-06\n",
      "Epoch  19 [8350/10697 ( 78.1%)] Loss: 0.025567 L1: 0.015234 Grad: 0.103127 Thermal: 0.000408 LR: 8.68e-06\n",
      "Epoch  19 [8350/10697 ( 78.1%)] Loss: 0.025567 L1: 0.015234 Grad: 0.103127 Thermal: 0.000408 LR: 8.68e-06\n",
      "Epoch  19 [8400/10697 ( 78.5%)] Loss: 0.028091 L1: 0.015989 Grad: 0.120785 Thermal: 0.000457 LR: 8.68e-06\n",
      "Epoch  19 [8400/10697 ( 78.5%)] Loss: 0.028091 L1: 0.015989 Grad: 0.120785 Thermal: 0.000457 LR: 8.68e-06\n",
      "Epoch  19 [8450/10697 ( 79.0%)] Loss: 0.032554 L1: 0.018468 Grad: 0.140562 Thermal: 0.000606 LR: 8.68e-06\n",
      "Epoch  19 [8450/10697 ( 79.0%)] Loss: 0.032554 L1: 0.018468 Grad: 0.140562 Thermal: 0.000606 LR: 8.68e-06\n",
      "Epoch  19 [8500/10697 ( 79.5%)] Loss: 0.029111 L1: 0.016928 Grad: 0.121566 Thermal: 0.000529 LR: 8.68e-06\n",
      "Epoch  19 [8500/10697 ( 79.5%)] Loss: 0.029111 L1: 0.016928 Grad: 0.121566 Thermal: 0.000529 LR: 8.68e-06\n",
      "Epoch  19 [8550/10697 ( 79.9%)] Loss: 0.024090 L1: 0.013833 Grad: 0.102391 Thermal: 0.000354 LR: 8.68e-06\n",
      "Epoch  19 [8550/10697 ( 79.9%)] Loss: 0.024090 L1: 0.013833 Grad: 0.102391 Thermal: 0.000354 LR: 8.68e-06\n",
      "Epoch  19 [8600/10697 ( 80.4%)] Loss: 0.025684 L1: 0.014230 Grad: 0.114319 Thermal: 0.000441 LR: 8.68e-06\n",
      "Epoch  19 [8600/10697 ( 80.4%)] Loss: 0.025684 L1: 0.014230 Grad: 0.114319 Thermal: 0.000441 LR: 8.68e-06\n",
      "Epoch  19 [8650/10697 ( 80.9%)] Loss: 0.027100 L1: 0.016245 Grad: 0.108308 Thermal: 0.000482 LR: 8.68e-06\n",
      "Epoch  19 [8650/10697 ( 80.9%)] Loss: 0.027100 L1: 0.016245 Grad: 0.108308 Thermal: 0.000482 LR: 8.68e-06\n",
      "Epoch  19 [8700/10697 ( 81.3%)] Loss: 0.026258 L1: 0.015086 Grad: 0.111501 Thermal: 0.000430 LR: 8.68e-06\n",
      "Epoch  19 [8700/10697 ( 81.3%)] Loss: 0.026258 L1: 0.015086 Grad: 0.111501 Thermal: 0.000430 LR: 8.68e-06\n",
      "Epoch  19 [8750/10697 ( 81.8%)] Loss: 0.024078 L1: 0.014003 Grad: 0.100550 Thermal: 0.000394 LR: 8.68e-06\n",
      "Epoch  19 [8750/10697 ( 81.8%)] Loss: 0.024078 L1: 0.014003 Grad: 0.100550 Thermal: 0.000394 LR: 8.68e-06\n",
      "Epoch  19 [8800/10697 ( 82.3%)] Loss: 0.028635 L1: 0.017061 Grad: 0.115478 Thermal: 0.000519 LR: 8.68e-06\n",
      "Epoch  19 [8800/10697 ( 82.3%)] Loss: 0.028635 L1: 0.017061 Grad: 0.115478 Thermal: 0.000519 LR: 8.68e-06\n",
      "Epoch  19 [8850/10697 ( 82.7%)] Loss: 0.028946 L1: 0.017304 Grad: 0.116142 Thermal: 0.000550 LR: 8.68e-06\n",
      "Epoch  19 [8850/10697 ( 82.7%)] Loss: 0.028946 L1: 0.017304 Grad: 0.116142 Thermal: 0.000550 LR: 8.68e-06\n",
      "Epoch  19 [8900/10697 ( 83.2%)] Loss: 0.020951 L1: 0.012271 Grad: 0.086649 Thermal: 0.000305 LR: 8.68e-06\n",
      "Epoch  19 [8900/10697 ( 83.2%)] Loss: 0.020951 L1: 0.012271 Grad: 0.086649 Thermal: 0.000305 LR: 8.68e-06\n",
      "Epoch  19 [8950/10697 ( 83.7%)] Loss: 0.024550 L1: 0.013994 Grad: 0.105367 Thermal: 0.000394 LR: 8.68e-06\n",
      "Epoch  19 [8950/10697 ( 83.7%)] Loss: 0.024550 L1: 0.013994 Grad: 0.105367 Thermal: 0.000394 LR: 8.68e-06\n",
      "Epoch  19 [9000/10697 ( 84.1%)] Loss: 0.024278 L1: 0.014477 Grad: 0.097819 Thermal: 0.000391 LR: 8.68e-06\n",
      "Epoch  19 [9000/10697 ( 84.1%)] Loss: 0.024278 L1: 0.014477 Grad: 0.097819 Thermal: 0.000391 LR: 8.68e-06\n",
      "Epoch  19 [9050/10697 ( 84.6%)] Loss: 0.022457 L1: 0.013187 Grad: 0.092526 Thermal: 0.000340 LR: 8.68e-06\n",
      "Epoch  19 [9050/10697 ( 84.6%)] Loss: 0.022457 L1: 0.013187 Grad: 0.092526 Thermal: 0.000340 LR: 8.68e-06\n",
      "Epoch  19 [9100/10697 ( 85.1%)] Loss: 0.024439 L1: 0.013886 Grad: 0.105340 Thermal: 0.000389 LR: 8.68e-06\n",
      "Epoch  19 [9100/10697 ( 85.1%)] Loss: 0.024439 L1: 0.013886 Grad: 0.105340 Thermal: 0.000389 LR: 8.68e-06\n",
      "Epoch  19 [9150/10697 ( 85.5%)] Loss: 0.025113 L1: 0.014803 Grad: 0.102904 Thermal: 0.000406 LR: 8.68e-06\n",
      "Epoch  19 [9150/10697 ( 85.5%)] Loss: 0.025113 L1: 0.014803 Grad: 0.102904 Thermal: 0.000406 LR: 8.68e-06\n",
      "Epoch  19 [9200/10697 ( 86.0%)] Loss: 0.026894 L1: 0.016205 Grad: 0.106653 Thermal: 0.000478 LR: 8.68e-06\n",
      "Epoch  19 [9200/10697 ( 86.0%)] Loss: 0.026894 L1: 0.016205 Grad: 0.106653 Thermal: 0.000478 LR: 8.68e-06\n",
      "Epoch  19 [9250/10697 ( 86.5%)] Loss: 0.020865 L1: 0.012294 Grad: 0.085550 Thermal: 0.000317 LR: 8.68e-06\n",
      "Epoch  19 [9250/10697 ( 86.5%)] Loss: 0.020865 L1: 0.012294 Grad: 0.085550 Thermal: 0.000317 LR: 8.68e-06\n",
      "Epoch  19 [9300/10697 ( 86.9%)] Loss: 0.025420 L1: 0.014835 Grad: 0.105624 Thermal: 0.000462 LR: 8.68e-06\n",
      "Epoch  19 [9300/10697 ( 86.9%)] Loss: 0.025420 L1: 0.014835 Grad: 0.105624 Thermal: 0.000462 LR: 8.68e-06\n",
      "Epoch  19 [9350/10697 ( 87.4%)] Loss: 0.027974 L1: 0.015748 Grad: 0.122013 Thermal: 0.000497 LR: 8.68e-06\n",
      "Epoch  19 [9350/10697 ( 87.4%)] Loss: 0.027974 L1: 0.015748 Grad: 0.122013 Thermal: 0.000497 LR: 8.68e-06\n",
      "Epoch  19 [9400/10697 ( 87.9%)] Loss: 0.029677 L1: 0.017398 Grad: 0.122501 Thermal: 0.000578 LR: 8.68e-06\n",
      "Epoch  19 [9400/10697 ( 87.9%)] Loss: 0.029677 L1: 0.017398 Grad: 0.122501 Thermal: 0.000578 LR: 8.68e-06\n",
      "Epoch  19 [9450/10697 ( 88.3%)] Loss: 0.034559 L1: 0.019801 Grad: 0.147223 Thermal: 0.000718 LR: 8.68e-06\n",
      "Epoch  19 [9450/10697 ( 88.3%)] Loss: 0.034559 L1: 0.019801 Grad: 0.147223 Thermal: 0.000718 LR: 8.68e-06\n",
      "Epoch  19 [9500/10697 ( 88.8%)] Loss: 0.027487 L1: 0.016116 Grad: 0.113476 Thermal: 0.000469 LR: 8.68e-06\n",
      "Epoch  19 [9500/10697 ( 88.8%)] Loss: 0.027487 L1: 0.016116 Grad: 0.113476 Thermal: 0.000469 LR: 8.68e-06\n",
      "Epoch  19 [9550/10697 ( 89.3%)] Loss: 0.026029 L1: 0.014780 Grad: 0.112282 Thermal: 0.000424 LR: 8.68e-06\n",
      "Epoch  19 [9550/10697 ( 89.3%)] Loss: 0.026029 L1: 0.014780 Grad: 0.112282 Thermal: 0.000424 LR: 8.68e-06\n",
      "Epoch  19 [9600/10697 ( 89.7%)] Loss: 0.028489 L1: 0.016629 Grad: 0.118352 Thermal: 0.000490 LR: 8.68e-06\n",
      "Epoch  19 [9600/10697 ( 89.7%)] Loss: 0.028489 L1: 0.016629 Grad: 0.118352 Thermal: 0.000490 LR: 8.68e-06\n",
      "Epoch  19 [9650/10697 ( 90.2%)] Loss: 0.032304 L1: 0.018920 Grad: 0.133499 Thermal: 0.000665 LR: 8.68e-06\n",
      "Epoch  19 [9650/10697 ( 90.2%)] Loss: 0.032304 L1: 0.018920 Grad: 0.133499 Thermal: 0.000665 LR: 8.68e-06\n",
      "Epoch  19 [9700/10697 ( 90.7%)] Loss: 0.023716 L1: 0.013898 Grad: 0.097993 Thermal: 0.000368 LR: 8.68e-06\n",
      "Epoch  19 [9700/10697 ( 90.7%)] Loss: 0.023716 L1: 0.013898 Grad: 0.097993 Thermal: 0.000368 LR: 8.68e-06\n",
      "Epoch  19 [9750/10697 ( 91.1%)] Loss: 0.022110 L1: 0.012824 Grad: 0.092710 Thermal: 0.000312 LR: 8.68e-06\n",
      "Epoch  19 [9750/10697 ( 91.1%)] Loss: 0.022110 L1: 0.012824 Grad: 0.092710 Thermal: 0.000312 LR: 8.68e-06\n",
      "Epoch  19 [9800/10697 ( 91.6%)] Loss: 0.026843 L1: 0.015567 Grad: 0.112513 Thermal: 0.000488 LR: 8.68e-06\n",
      "Epoch  19 [9800/10697 ( 91.6%)] Loss: 0.026843 L1: 0.015567 Grad: 0.112513 Thermal: 0.000488 LR: 8.68e-06\n",
      "Epoch  19 [9850/10697 ( 92.1%)] Loss: 0.028853 L1: 0.016872 Grad: 0.119565 Thermal: 0.000492 LR: 8.68e-06\n",
      "Epoch  19 [9850/10697 ( 92.1%)] Loss: 0.028853 L1: 0.016872 Grad: 0.119565 Thermal: 0.000492 LR: 8.68e-06\n",
      "Epoch  19 [9900/10697 ( 92.5%)] Loss: 0.028145 L1: 0.016471 Grad: 0.116496 Thermal: 0.000503 LR: 8.68e-06\n",
      "Epoch  19 [9900/10697 ( 92.5%)] Loss: 0.028145 L1: 0.016471 Grad: 0.116496 Thermal: 0.000503 LR: 8.68e-06\n",
      "Epoch  19 [9950/10697 ( 93.0%)] Loss: 0.025424 L1: 0.015149 Grad: 0.102529 Thermal: 0.000436 LR: 8.68e-06\n",
      "Epoch  19 [9950/10697 ( 93.0%)] Loss: 0.025424 L1: 0.015149 Grad: 0.102529 Thermal: 0.000436 LR: 8.68e-06\n",
      "Epoch  19 [10000/10697 ( 93.5%)] Loss: 0.026290 L1: 0.015144 Grad: 0.111247 Thermal: 0.000437 LR: 8.68e-06\n",
      "Epoch  19 [10000/10697 ( 93.5%)] Loss: 0.026290 L1: 0.015144 Grad: 0.111247 Thermal: 0.000437 LR: 8.68e-06\n",
      "Epoch  19 [10050/10697 ( 94.0%)] Loss: 0.025001 L1: 0.014875 Grad: 0.101051 Thermal: 0.000419 LR: 8.68e-06\n",
      "Epoch  19 [10050/10697 ( 94.0%)] Loss: 0.025001 L1: 0.014875 Grad: 0.101051 Thermal: 0.000419 LR: 8.68e-06\n",
      "Epoch  19 [10100/10697 ( 94.4%)] Loss: 0.030418 L1: 0.017728 Grad: 0.126511 Thermal: 0.000778 LR: 8.68e-06\n",
      "Epoch  19 [10100/10697 ( 94.4%)] Loss: 0.030418 L1: 0.017728 Grad: 0.126511 Thermal: 0.000778 LR: 8.68e-06\n",
      "Epoch  19 [10150/10697 ( 94.9%)] Loss: 0.025935 L1: 0.015075 Grad: 0.108372 Thermal: 0.000455 LR: 8.68e-06\n",
      "Epoch  19 [10150/10697 ( 94.9%)] Loss: 0.025935 L1: 0.015075 Grad: 0.108372 Thermal: 0.000455 LR: 8.68e-06\n",
      "Epoch  19 [10200/10697 ( 95.4%)] Loss: 0.038074 L1: 0.022739 Grad: 0.152852 Thermal: 0.000990 LR: 8.68e-06\n",
      "Epoch  19 [10200/10697 ( 95.4%)] Loss: 0.038074 L1: 0.022739 Grad: 0.152852 Thermal: 0.000990 LR: 8.68e-06\n",
      "Epoch  19 [10250/10697 ( 95.8%)] Loss: 0.027158 L1: 0.015954 Grad: 0.111792 Thermal: 0.000498 LR: 8.68e-06\n",
      "Epoch  19 [10250/10697 ( 95.8%)] Loss: 0.027158 L1: 0.015954 Grad: 0.111792 Thermal: 0.000498 LR: 8.68e-06\n",
      "Epoch  19 [10300/10697 ( 96.3%)] Loss: 0.025034 L1: 0.014418 Grad: 0.105954 Thermal: 0.000413 LR: 8.68e-06\n",
      "Epoch  19 [10300/10697 ( 96.3%)] Loss: 0.025034 L1: 0.014418 Grad: 0.105954 Thermal: 0.000413 LR: 8.68e-06\n",
      "Epoch  19 [10350/10697 ( 96.8%)] Loss: 0.024414 L1: 0.013709 Grad: 0.106838 Thermal: 0.000426 LR: 8.68e-06\n",
      "Epoch  19 [10350/10697 ( 96.8%)] Loss: 0.024414 L1: 0.013709 Grad: 0.106838 Thermal: 0.000426 LR: 8.68e-06\n",
      "Epoch  19 [10400/10697 ( 97.2%)] Loss: 0.026544 L1: 0.015086 Grad: 0.114369 Thermal: 0.000413 LR: 8.68e-06\n",
      "Epoch  19 [10400/10697 ( 97.2%)] Loss: 0.026544 L1: 0.015086 Grad: 0.114369 Thermal: 0.000413 LR: 8.68e-06\n",
      "Epoch  19 [10450/10697 ( 97.7%)] Loss: 0.027354 L1: 0.015493 Grad: 0.118379 Thermal: 0.000460 LR: 8.68e-06\n",
      "Epoch  19 [10450/10697 ( 97.7%)] Loss: 0.027354 L1: 0.015493 Grad: 0.118379 Thermal: 0.000460 LR: 8.68e-06\n",
      "Epoch  19 [10500/10697 ( 98.2%)] Loss: 0.025555 L1: 0.015180 Grad: 0.103528 Thermal: 0.000442 LR: 8.68e-06\n",
      "Epoch  19 [10500/10697 ( 98.2%)] Loss: 0.025555 L1: 0.015180 Grad: 0.103528 Thermal: 0.000442 LR: 8.68e-06\n",
      "Epoch  19 [10550/10697 ( 98.6%)] Loss: 0.028940 L1: 0.016725 Grad: 0.121889 Thermal: 0.000532 LR: 8.68e-06\n",
      "Epoch  19 [10550/10697 ( 98.6%)] Loss: 0.028940 L1: 0.016725 Grad: 0.121889 Thermal: 0.000532 LR: 8.68e-06\n",
      "Epoch  19 [10600/10697 ( 99.1%)] Loss: 0.022471 L1: 0.013031 Grad: 0.094232 Thermal: 0.000330 LR: 8.68e-06\n",
      "Epoch  19 [10600/10697 ( 99.1%)] Loss: 0.022471 L1: 0.013031 Grad: 0.094232 Thermal: 0.000330 LR: 8.68e-06\n",
      "Epoch  19 [10650/10697 ( 99.6%)] Loss: 0.030951 L1: 0.018002 Grad: 0.129198 Thermal: 0.000592 LR: 8.68e-06\n",
      "Epoch  19 [10650/10697 ( 99.6%)] Loss: 0.030951 L1: 0.018002 Grad: 0.129198 Thermal: 0.000592 LR: 8.68e-06\n",
      "Epoch  19 Summary: Loss=0.026636 (L1:0.0155, Grad:0.1110, Thermal:0.0005) Val_PSNR=0.00dB Best=33.84dB Time=70.8min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "üîì Unfreezing backbone layers\n",
      "Epoch  19 Summary: Loss=0.026636 (L1:0.0155, Grad:0.1110, Thermal:0.0005) Val_PSNR=0.00dB Best=33.84dB Time=70.8min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "üîì Unfreezing backbone layers\n",
      "Epoch  20 [   0/10697 (  0.0%)] Loss: 0.023020 L1: 0.013219 Grad: 0.097838 Thermal: 0.000334 LR: 4.28e-06\n",
      "Epoch  20 [   0/10697 (  0.0%)] Loss: 0.023020 L1: 0.013219 Grad: 0.097838 Thermal: 0.000334 LR: 4.28e-06\n",
      "Epoch  20 [  50/10697 (  0.5%)] Loss: 0.020671 L1: 0.011750 Grad: 0.089047 Thermal: 0.000323 LR: 4.28e-06\n",
      "Epoch  20 [  50/10697 (  0.5%)] Loss: 0.020671 L1: 0.011750 Grad: 0.089047 Thermal: 0.000323 LR: 4.28e-06\n",
      "Epoch  20 [ 100/10697 (  0.9%)] Loss: 0.025634 L1: 0.014678 Grad: 0.109334 Thermal: 0.000458 LR: 4.28e-06\n",
      "Epoch  20 [ 100/10697 (  0.9%)] Loss: 0.025634 L1: 0.014678 Grad: 0.109334 Thermal: 0.000458 LR: 4.28e-06\n",
      "Epoch  20 [ 150/10697 (  1.4%)] Loss: 0.022840 L1: 0.013391 Grad: 0.094309 Thermal: 0.000348 LR: 4.28e-06\n",
      "Epoch  20 [ 150/10697 (  1.4%)] Loss: 0.022840 L1: 0.013391 Grad: 0.094309 Thermal: 0.000348 LR: 4.28e-06\n",
      "Epoch  20 [ 200/10697 (  1.9%)] Loss: 0.027417 L1: 0.015666 Grad: 0.117299 Thermal: 0.000427 LR: 4.28e-06\n",
      "Epoch  20 [ 200/10697 (  1.9%)] Loss: 0.027417 L1: 0.015666 Grad: 0.117299 Thermal: 0.000427 LR: 4.28e-06\n",
      "Epoch  20 [ 250/10697 (  2.3%)] Loss: 0.029469 L1: 0.017257 Grad: 0.121850 Thermal: 0.000542 LR: 4.28e-06\n",
      "Epoch  20 [ 250/10697 (  2.3%)] Loss: 0.029469 L1: 0.017257 Grad: 0.121850 Thermal: 0.000542 LR: 4.28e-06\n",
      "Epoch  20 [ 300/10697 (  2.8%)] Loss: 0.029236 L1: 0.017029 Grad: 0.121786 Thermal: 0.000553 LR: 4.28e-06\n",
      "Epoch  20 [ 300/10697 (  2.8%)] Loss: 0.029236 L1: 0.017029 Grad: 0.121786 Thermal: 0.000553 LR: 4.28e-06\n",
      "Epoch  20 [ 350/10697 (  3.3%)] Loss: 0.028309 L1: 0.016627 Grad: 0.116578 Thermal: 0.000491 LR: 4.28e-06\n",
      "Epoch  20 [ 350/10697 (  3.3%)] Loss: 0.028309 L1: 0.016627 Grad: 0.116578 Thermal: 0.000491 LR: 4.28e-06\n",
      "Epoch  20 [ 400/10697 (  3.7%)] Loss: 0.030649 L1: 0.017478 Grad: 0.131398 Thermal: 0.000621 LR: 4.28e-06\n",
      "Epoch  20 [ 400/10697 (  3.7%)] Loss: 0.030649 L1: 0.017478 Grad: 0.131398 Thermal: 0.000621 LR: 4.28e-06\n",
      "Epoch  20 [ 450/10697 (  4.2%)] Loss: 0.021931 L1: 0.012827 Grad: 0.090877 Thermal: 0.000331 LR: 4.28e-06\n",
      "Epoch  20 [ 450/10697 (  4.2%)] Loss: 0.021931 L1: 0.012827 Grad: 0.090877 Thermal: 0.000331 LR: 4.28e-06\n",
      "Epoch  20 [ 500/10697 (  4.7%)] Loss: 0.027386 L1: 0.016563 Grad: 0.107990 Thermal: 0.000476 LR: 4.28e-06\n",
      "Epoch  20 [ 500/10697 (  4.7%)] Loss: 0.027386 L1: 0.016563 Grad: 0.107990 Thermal: 0.000476 LR: 4.28e-06\n",
      "Epoch  20 [ 550/10697 (  5.1%)] Loss: 0.030775 L1: 0.018109 Grad: 0.126368 Thermal: 0.000572 LR: 4.28e-06\n",
      "Epoch  20 [ 550/10697 (  5.1%)] Loss: 0.030775 L1: 0.018109 Grad: 0.126368 Thermal: 0.000572 LR: 4.28e-06\n",
      "Epoch  20 [ 600/10697 (  5.6%)] Loss: 0.020722 L1: 0.012103 Grad: 0.086051 Thermal: 0.000276 LR: 4.28e-06\n",
      "Epoch  20 [ 600/10697 (  5.6%)] Loss: 0.020722 L1: 0.012103 Grad: 0.086051 Thermal: 0.000276 LR: 4.28e-06\n",
      "Epoch  20 [ 650/10697 (  6.1%)] Loss: 0.025734 L1: 0.015233 Grad: 0.104784 Thermal: 0.000437 LR: 4.28e-06\n",
      "Epoch  20 [ 650/10697 (  6.1%)] Loss: 0.025734 L1: 0.015233 Grad: 0.104784 Thermal: 0.000437 LR: 4.28e-06\n",
      "Epoch  20 [ 700/10697 (  6.5%)] Loss: 0.022331 L1: 0.012643 Grad: 0.096717 Thermal: 0.000335 LR: 4.28e-06\n",
      "Epoch  20 [ 700/10697 (  6.5%)] Loss: 0.022331 L1: 0.012643 Grad: 0.096717 Thermal: 0.000335 LR: 4.28e-06\n",
      "Epoch  20 [ 750/10697 (  7.0%)] Loss: 0.030210 L1: 0.017633 Grad: 0.125487 Thermal: 0.000566 LR: 4.28e-06\n",
      "Epoch  20 [ 750/10697 (  7.0%)] Loss: 0.030210 L1: 0.017633 Grad: 0.125487 Thermal: 0.000566 LR: 4.28e-06\n",
      "Epoch  20 [ 800/10697 (  7.5%)] Loss: 0.026917 L1: 0.015844 Grad: 0.110486 Thermal: 0.000490 LR: 4.28e-06\n",
      "Epoch  20 [ 800/10697 (  7.5%)] Loss: 0.026917 L1: 0.015844 Grad: 0.110486 Thermal: 0.000490 LR: 4.28e-06\n",
      "Epoch  20 [ 850/10697 (  7.9%)] Loss: 0.023762 L1: 0.013885 Grad: 0.098591 Thermal: 0.000372 LR: 4.28e-06\n",
      "Epoch  20 [ 850/10697 (  7.9%)] Loss: 0.023762 L1: 0.013885 Grad: 0.098591 Thermal: 0.000372 LR: 4.28e-06\n",
      "Epoch  20 [ 900/10697 (  8.4%)] Loss: 0.027584 L1: 0.015917 Grad: 0.116438 Thermal: 0.000464 LR: 4.28e-06\n",
      "Epoch  20 [ 900/10697 (  8.4%)] Loss: 0.027584 L1: 0.015917 Grad: 0.116438 Thermal: 0.000464 LR: 4.28e-06\n",
      "Epoch  20 [ 950/10697 (  8.9%)] Loss: 0.026676 L1: 0.015805 Grad: 0.108471 Thermal: 0.000484 LR: 4.28e-06\n",
      "Epoch  20 [ 950/10697 (  8.9%)] Loss: 0.026676 L1: 0.015805 Grad: 0.108471 Thermal: 0.000484 LR: 4.28e-06\n",
      "Epoch  20 [1000/10697 (  9.3%)] Loss: 0.024746 L1: 0.014421 Grad: 0.103049 Thermal: 0.000397 LR: 4.28e-06\n",
      "Epoch  20 [1000/10697 (  9.3%)] Loss: 0.024746 L1: 0.014421 Grad: 0.103049 Thermal: 0.000397 LR: 4.28e-06\n",
      "Epoch  20 [1050/10697 (  9.8%)] Loss: 0.022380 L1: 0.012881 Grad: 0.094821 Thermal: 0.000335 LR: 4.28e-06\n",
      "Epoch  20 [1050/10697 (  9.8%)] Loss: 0.022380 L1: 0.012881 Grad: 0.094821 Thermal: 0.000335 LR: 4.28e-06\n",
      "Epoch  20 [1100/10697 ( 10.3%)] Loss: 0.025617 L1: 0.015009 Grad: 0.105868 Thermal: 0.000428 LR: 4.28e-06\n",
      "Epoch  20 [1100/10697 ( 10.3%)] Loss: 0.025617 L1: 0.015009 Grad: 0.105868 Thermal: 0.000428 LR: 4.28e-06\n",
      "Epoch  20 [1150/10697 ( 10.8%)] Loss: 0.023708 L1: 0.013456 Grad: 0.102354 Thermal: 0.000329 LR: 4.28e-06\n",
      "Epoch  20 [1150/10697 ( 10.8%)] Loss: 0.023708 L1: 0.013456 Grad: 0.102354 Thermal: 0.000329 LR: 4.28e-06\n",
      "Epoch  20 [1200/10697 ( 11.2%)] Loss: 0.021167 L1: 0.012333 Grad: 0.088188 Thermal: 0.000309 LR: 4.28e-06\n",
      "Epoch  20 [1200/10697 ( 11.2%)] Loss: 0.021167 L1: 0.012333 Grad: 0.088188 Thermal: 0.000309 LR: 4.28e-06\n",
      "Epoch  20 [1250/10697 ( 11.7%)] Loss: 0.030242 L1: 0.017280 Grad: 0.129363 Thermal: 0.000515 LR: 4.28e-06\n",
      "Epoch  20 [1250/10697 ( 11.7%)] Loss: 0.030242 L1: 0.017280 Grad: 0.129363 Thermal: 0.000515 LR: 4.28e-06\n",
      "Epoch  20 [1300/10697 ( 12.2%)] Loss: 0.025671 L1: 0.014632 Grad: 0.110191 Thermal: 0.000400 LR: 4.28e-06\n",
      "Epoch  20 [1300/10697 ( 12.2%)] Loss: 0.025671 L1: 0.014632 Grad: 0.110191 Thermal: 0.000400 LR: 4.28e-06\n",
      "Epoch  20 [1350/10697 ( 12.6%)] Loss: 0.022771 L1: 0.013258 Grad: 0.094959 Thermal: 0.000342 LR: 4.28e-06\n",
      "Epoch  20 [1350/10697 ( 12.6%)] Loss: 0.022771 L1: 0.013258 Grad: 0.094959 Thermal: 0.000342 LR: 4.28e-06\n",
      "Epoch  20 [1400/10697 ( 13.1%)] Loss: 0.024041 L1: 0.013681 Grad: 0.103414 Thermal: 0.000359 LR: 4.28e-06\n",
      "Epoch  20 [1400/10697 ( 13.1%)] Loss: 0.024041 L1: 0.013681 Grad: 0.103414 Thermal: 0.000359 LR: 4.28e-06\n",
      "Epoch  20 [1450/10697 ( 13.6%)] Loss: 0.029813 L1: 0.017440 Grad: 0.123436 Thermal: 0.000597 LR: 4.28e-06\n",
      "Epoch  20 [1450/10697 ( 13.6%)] Loss: 0.029813 L1: 0.017440 Grad: 0.123436 Thermal: 0.000597 LR: 4.28e-06\n",
      "Epoch  20 [1500/10697 ( 14.0%)] Loss: 0.024438 L1: 0.013874 Grad: 0.105455 Thermal: 0.000371 LR: 4.28e-06\n",
      "Epoch  20 [1500/10697 ( 14.0%)] Loss: 0.024438 L1: 0.013874 Grad: 0.105455 Thermal: 0.000371 LR: 4.28e-06\n",
      "Epoch  20 [1550/10697 ( 14.5%)] Loss: 0.027733 L1: 0.016743 Grad: 0.109652 Thermal: 0.000484 LR: 4.28e-06\n",
      "Epoch  20 [1550/10697 ( 14.5%)] Loss: 0.027733 L1: 0.016743 Grad: 0.109652 Thermal: 0.000484 LR: 4.28e-06\n",
      "Epoch  20 [1600/10697 ( 15.0%)] Loss: 0.026475 L1: 0.015494 Grad: 0.109591 Thermal: 0.000438 LR: 4.28e-06\n",
      "Epoch  20 [1600/10697 ( 15.0%)] Loss: 0.026475 L1: 0.015494 Grad: 0.109591 Thermal: 0.000438 LR: 4.28e-06\n",
      "Epoch  20 [1650/10697 ( 15.4%)] Loss: 0.028610 L1: 0.016952 Grad: 0.116321 Thermal: 0.000522 LR: 4.28e-06\n",
      "Epoch  20 [1650/10697 ( 15.4%)] Loss: 0.028610 L1: 0.016952 Grad: 0.116321 Thermal: 0.000522 LR: 4.28e-06\n",
      "Epoch  20 [1700/10697 ( 15.9%)] Loss: 0.027012 L1: 0.016063 Grad: 0.109250 Thermal: 0.000480 LR: 4.28e-06\n",
      "Epoch  20 [1700/10697 ( 15.9%)] Loss: 0.027012 L1: 0.016063 Grad: 0.109250 Thermal: 0.000480 LR: 4.28e-06\n",
      "Epoch  20 [1750/10697 ( 16.4%)] Loss: 0.027192 L1: 0.015799 Grad: 0.113675 Thermal: 0.000509 LR: 4.28e-06\n",
      "Epoch  20 [1750/10697 ( 16.4%)] Loss: 0.027192 L1: 0.015799 Grad: 0.113675 Thermal: 0.000509 LR: 4.28e-06\n",
      "Epoch  20 [1800/10697 ( 16.8%)] Loss: 0.023516 L1: 0.014053 Grad: 0.094443 Thermal: 0.000379 LR: 4.28e-06\n",
      "Epoch  20 [1800/10697 ( 16.8%)] Loss: 0.023516 L1: 0.014053 Grad: 0.094443 Thermal: 0.000379 LR: 4.28e-06\n",
      "Epoch  20 [1850/10697 ( 17.3%)] Loss: 0.025690 L1: 0.015197 Grad: 0.104727 Thermal: 0.000414 LR: 4.28e-06\n",
      "Epoch  20 [1850/10697 ( 17.3%)] Loss: 0.025690 L1: 0.015197 Grad: 0.104727 Thermal: 0.000414 LR: 4.28e-06\n",
      "Epoch  20 [1900/10697 ( 17.8%)] Loss: 0.030882 L1: 0.018483 Grad: 0.123593 Thermal: 0.000798 LR: 4.28e-06\n",
      "Epoch  20 [1900/10697 ( 17.8%)] Loss: 0.030882 L1: 0.018483 Grad: 0.123593 Thermal: 0.000798 LR: 4.28e-06\n",
      "Epoch  20 [1950/10697 ( 18.2%)] Loss: 0.025303 L1: 0.014716 Grad: 0.105657 Thermal: 0.000422 LR: 4.28e-06\n",
      "Epoch  20 [1950/10697 ( 18.2%)] Loss: 0.025303 L1: 0.014716 Grad: 0.105657 Thermal: 0.000422 LR: 4.28e-06\n",
      "Epoch  20 [2000/10697 ( 18.7%)] Loss: 0.027399 L1: 0.015623 Grad: 0.117529 Thermal: 0.000466 LR: 4.28e-06\n",
      "Epoch  20 [2000/10697 ( 18.7%)] Loss: 0.027399 L1: 0.015623 Grad: 0.117529 Thermal: 0.000466 LR: 4.28e-06\n",
      "Epoch  20 [2050/10697 ( 19.2%)] Loss: 0.023680 L1: 0.013931 Grad: 0.097297 Thermal: 0.000384 LR: 4.28e-06\n",
      "Epoch  20 [2050/10697 ( 19.2%)] Loss: 0.023680 L1: 0.013931 Grad: 0.097297 Thermal: 0.000384 LR: 4.28e-06\n",
      "Epoch  20 [2100/10697 ( 19.6%)] Loss: 0.029572 L1: 0.017310 Grad: 0.122333 Thermal: 0.000583 LR: 4.28e-06\n",
      "Epoch  20 [2100/10697 ( 19.6%)] Loss: 0.029572 L1: 0.017310 Grad: 0.122333 Thermal: 0.000583 LR: 4.28e-06\n",
      "Epoch  20 [2150/10697 ( 20.1%)] Loss: 0.028638 L1: 0.016944 Grad: 0.116679 Thermal: 0.000508 LR: 4.28e-06\n",
      "Epoch  20 [2150/10697 ( 20.1%)] Loss: 0.028638 L1: 0.016944 Grad: 0.116679 Thermal: 0.000508 LR: 4.28e-06\n",
      "Epoch  20 [2200/10697 ( 20.6%)] Loss: 0.023289 L1: 0.013504 Grad: 0.097674 Thermal: 0.000363 LR: 4.28e-06\n",
      "Epoch  20 [2200/10697 ( 20.6%)] Loss: 0.023289 L1: 0.013504 Grad: 0.097674 Thermal: 0.000363 LR: 4.28e-06\n",
      "Epoch  20 [2250/10697 ( 21.0%)] Loss: 0.020914 L1: 0.012028 Grad: 0.088689 Thermal: 0.000333 LR: 4.28e-06\n",
      "Epoch  20 [2250/10697 ( 21.0%)] Loss: 0.020914 L1: 0.012028 Grad: 0.088689 Thermal: 0.000333 LR: 4.28e-06\n",
      "Epoch  20 [2300/10697 ( 21.5%)] Loss: 0.029019 L1: 0.016898 Grad: 0.120955 Thermal: 0.000517 LR: 4.28e-06\n",
      "Epoch  20 [2300/10697 ( 21.5%)] Loss: 0.029019 L1: 0.016898 Grad: 0.120955 Thermal: 0.000517 LR: 4.28e-06\n",
      "Epoch  20 [2350/10697 ( 22.0%)] Loss: 0.023360 L1: 0.013735 Grad: 0.096078 Thermal: 0.000355 LR: 4.28e-06\n",
      "Epoch  20 [2350/10697 ( 22.0%)] Loss: 0.023360 L1: 0.013735 Grad: 0.096078 Thermal: 0.000355 LR: 4.28e-06\n",
      "Epoch  20 [2400/10697 ( 22.4%)] Loss: 0.026431 L1: 0.015860 Grad: 0.105474 Thermal: 0.000458 LR: 4.28e-06\n",
      "Epoch  20 [2400/10697 ( 22.4%)] Loss: 0.026431 L1: 0.015860 Grad: 0.105474 Thermal: 0.000458 LR: 4.28e-06\n",
      "Epoch  20 [2450/10697 ( 22.9%)] Loss: 0.030135 L1: 0.017232 Grad: 0.128731 Thermal: 0.000596 LR: 4.28e-06\n",
      "Epoch  20 [2450/10697 ( 22.9%)] Loss: 0.030135 L1: 0.017232 Grad: 0.128731 Thermal: 0.000596 LR: 4.28e-06\n",
      "Epoch  20 [2500/10697 ( 23.4%)] Loss: 0.027245 L1: 0.015870 Grad: 0.113505 Thermal: 0.000498 LR: 4.28e-06\n",
      "Epoch  20 [2500/10697 ( 23.4%)] Loss: 0.027245 L1: 0.015870 Grad: 0.113505 Thermal: 0.000498 LR: 4.28e-06\n",
      "Epoch  20 [2550/10697 ( 23.8%)] Loss: 0.024790 L1: 0.014386 Grad: 0.103853 Thermal: 0.000373 LR: 4.28e-06\n",
      "Epoch  20 [2550/10697 ( 23.8%)] Loss: 0.024790 L1: 0.014386 Grad: 0.103853 Thermal: 0.000373 LR: 4.28e-06\n",
      "Epoch  20 [2600/10697 ( 24.3%)] Loss: 0.027914 L1: 0.016584 Grad: 0.113056 Thermal: 0.000479 LR: 4.28e-06\n",
      "Epoch  20 [2600/10697 ( 24.3%)] Loss: 0.027914 L1: 0.016584 Grad: 0.113056 Thermal: 0.000479 LR: 4.28e-06\n",
      "Epoch  20 [2650/10697 ( 24.8%)] Loss: 0.023679 L1: 0.013981 Grad: 0.096782 Thermal: 0.000380 LR: 4.28e-06\n",
      "Epoch  20 [2650/10697 ( 24.8%)] Loss: 0.023679 L1: 0.013981 Grad: 0.096782 Thermal: 0.000380 LR: 4.28e-06\n",
      "Epoch  20 [2700/10697 ( 25.2%)] Loss: 0.025775 L1: 0.014971 Grad: 0.107823 Thermal: 0.000426 LR: 4.28e-06\n",
      "Epoch  20 [2700/10697 ( 25.2%)] Loss: 0.025775 L1: 0.014971 Grad: 0.107823 Thermal: 0.000426 LR: 4.28e-06\n",
      "Epoch  20 [2750/10697 ( 25.7%)] Loss: 0.027687 L1: 0.016163 Grad: 0.115007 Thermal: 0.000465 LR: 4.28e-06\n",
      "Epoch  20 [2750/10697 ( 25.7%)] Loss: 0.027687 L1: 0.016163 Grad: 0.115007 Thermal: 0.000465 LR: 4.28e-06\n",
      "Epoch  20 [2800/10697 ( 26.2%)] Loss: 0.025776 L1: 0.015047 Grad: 0.107053 Thermal: 0.000470 LR: 4.28e-06\n",
      "Epoch  20 [2800/10697 ( 26.2%)] Loss: 0.025776 L1: 0.015047 Grad: 0.107053 Thermal: 0.000470 LR: 4.28e-06\n",
      "Epoch  20 [2850/10697 ( 26.6%)] Loss: 0.026202 L1: 0.015018 Grad: 0.111620 Thermal: 0.000431 LR: 4.28e-06\n",
      "Epoch  20 [2850/10697 ( 26.6%)] Loss: 0.026202 L1: 0.015018 Grad: 0.111620 Thermal: 0.000431 LR: 4.28e-06\n",
      "Epoch  20 [2900/10697 ( 27.1%)] Loss: 0.027017 L1: 0.015832 Grad: 0.111609 Thermal: 0.000473 LR: 4.28e-06\n",
      "Epoch  20 [2900/10697 ( 27.1%)] Loss: 0.027017 L1: 0.015832 Grad: 0.111609 Thermal: 0.000473 LR: 4.28e-06\n",
      "Epoch  20 [2950/10697 ( 27.6%)] Loss: 0.026591 L1: 0.015800 Grad: 0.107682 Thermal: 0.000448 LR: 4.28e-06\n",
      "Epoch  20 [2950/10697 ( 27.6%)] Loss: 0.026591 L1: 0.015800 Grad: 0.107682 Thermal: 0.000448 LR: 4.28e-06\n",
      "Epoch  20 [3000/10697 ( 28.0%)] Loss: 0.025511 L1: 0.014967 Grad: 0.105230 Thermal: 0.000408 LR: 4.28e-06\n",
      "Epoch  20 [3000/10697 ( 28.0%)] Loss: 0.025511 L1: 0.014967 Grad: 0.105230 Thermal: 0.000408 LR: 4.28e-06\n",
      "Epoch  20 [3050/10697 ( 28.5%)] Loss: 0.027765 L1: 0.016546 Grad: 0.111940 Thermal: 0.000493 LR: 4.28e-06\n",
      "Epoch  20 [3050/10697 ( 28.5%)] Loss: 0.027765 L1: 0.016546 Grad: 0.111940 Thermal: 0.000493 LR: 4.28e-06\n",
      "Epoch  20 [3100/10697 ( 29.0%)] Loss: 0.020947 L1: 0.012138 Grad: 0.087921 Thermal: 0.000323 LR: 4.28e-06\n",
      "Epoch  20 [3100/10697 ( 29.0%)] Loss: 0.020947 L1: 0.012138 Grad: 0.087921 Thermal: 0.000323 LR: 4.28e-06\n",
      "Epoch  20 [3150/10697 ( 29.4%)] Loss: 0.015426 L1: 0.008794 Grad: 0.066231 Thermal: 0.000174 LR: 4.28e-06\n",
      "Epoch  20 [3150/10697 ( 29.4%)] Loss: 0.015426 L1: 0.008794 Grad: 0.066231 Thermal: 0.000174 LR: 4.28e-06\n",
      "Epoch  20 [3200/10697 ( 29.9%)] Loss: 0.024902 L1: 0.015081 Grad: 0.097997 Thermal: 0.000424 LR: 4.28e-06\n",
      "Epoch  20 [3200/10697 ( 29.9%)] Loss: 0.024902 L1: 0.015081 Grad: 0.097997 Thermal: 0.000424 LR: 4.28e-06\n",
      "Epoch  20 [3250/10697 ( 30.4%)] Loss: 0.026102 L1: 0.015064 Grad: 0.110142 Thermal: 0.000475 LR: 4.28e-06\n",
      "Epoch  20 [3250/10697 ( 30.4%)] Loss: 0.026102 L1: 0.015064 Grad: 0.110142 Thermal: 0.000475 LR: 4.28e-06\n",
      "Epoch  20 [3300/10697 ( 30.8%)] Loss: 0.024121 L1: 0.014154 Grad: 0.099473 Thermal: 0.000388 LR: 4.28e-06\n",
      "Epoch  20 [3300/10697 ( 30.8%)] Loss: 0.024121 L1: 0.014154 Grad: 0.099473 Thermal: 0.000388 LR: 4.28e-06\n",
      "Epoch  20 [3350/10697 ( 31.3%)] Loss: 0.027676 L1: 0.016324 Grad: 0.113275 Thermal: 0.000484 LR: 4.28e-06\n",
      "Epoch  20 [3350/10697 ( 31.3%)] Loss: 0.027676 L1: 0.016324 Grad: 0.113275 Thermal: 0.000484 LR: 4.28e-06\n",
      "Epoch  20 [3400/10697 ( 31.8%)] Loss: 0.025605 L1: 0.014989 Grad: 0.105929 Thermal: 0.000444 LR: 4.28e-06\n",
      "Epoch  20 [3400/10697 ( 31.8%)] Loss: 0.025605 L1: 0.014989 Grad: 0.105929 Thermal: 0.000444 LR: 4.28e-06\n",
      "Epoch  20 [3450/10697 ( 32.3%)] Loss: 0.024352 L1: 0.013993 Grad: 0.103382 Thermal: 0.000419 LR: 4.28e-06\n",
      "Epoch  20 [3450/10697 ( 32.3%)] Loss: 0.024352 L1: 0.013993 Grad: 0.103382 Thermal: 0.000419 LR: 4.28e-06\n",
      "Epoch  20 [3500/10697 ( 32.7%)] Loss: 0.024895 L1: 0.014772 Grad: 0.101033 Thermal: 0.000398 LR: 4.28e-06\n",
      "Epoch  20 [3500/10697 ( 32.7%)] Loss: 0.024895 L1: 0.014772 Grad: 0.101033 Thermal: 0.000398 LR: 4.28e-06\n",
      "Epoch  20 [3550/10697 ( 33.2%)] Loss: 0.017346 L1: 0.009596 Grad: 0.077398 Thermal: 0.000206 LR: 4.28e-06\n",
      "Epoch  20 [3550/10697 ( 33.2%)] Loss: 0.017346 L1: 0.009596 Grad: 0.077398 Thermal: 0.000206 LR: 4.28e-06\n",
      "Epoch  20 [3600/10697 ( 33.7%)] Loss: 0.025629 L1: 0.015366 Grad: 0.102412 Thermal: 0.000434 LR: 4.28e-06\n",
      "Epoch  20 [3600/10697 ( 33.7%)] Loss: 0.025629 L1: 0.015366 Grad: 0.102412 Thermal: 0.000434 LR: 4.28e-06\n",
      "Epoch  20 [3650/10697 ( 34.1%)] Loss: 0.021234 L1: 0.012142 Grad: 0.090780 Thermal: 0.000278 LR: 4.28e-06\n",
      "Epoch  20 [3650/10697 ( 34.1%)] Loss: 0.021234 L1: 0.012142 Grad: 0.090780 Thermal: 0.000278 LR: 4.28e-06\n",
      "Epoch  20 [3700/10697 ( 34.6%)] Loss: 0.020839 L1: 0.011912 Grad: 0.089095 Thermal: 0.000362 LR: 4.28e-06\n",
      "Epoch  20 [3700/10697 ( 34.6%)] Loss: 0.020839 L1: 0.011912 Grad: 0.089095 Thermal: 0.000362 LR: 4.28e-06\n",
      "Epoch  20 [3750/10697 ( 35.1%)] Loss: 0.031285 L1: 0.018556 Grad: 0.126997 Thermal: 0.000586 LR: 4.28e-06\n",
      "Epoch  20 [3750/10697 ( 35.1%)] Loss: 0.031285 L1: 0.018556 Grad: 0.126997 Thermal: 0.000586 LR: 4.28e-06\n",
      "Epoch  20 [3800/10697 ( 35.5%)] Loss: 0.027661 L1: 0.015988 Grad: 0.116507 Thermal: 0.000446 LR: 4.28e-06\n",
      "Epoch  20 [3800/10697 ( 35.5%)] Loss: 0.027661 L1: 0.015988 Grad: 0.116507 Thermal: 0.000446 LR: 4.28e-06\n",
      "Epoch  20 [3850/10697 ( 36.0%)] Loss: 0.025421 L1: 0.014743 Grad: 0.106575 Thermal: 0.000399 LR: 4.28e-06\n",
      "Epoch  20 [3850/10697 ( 36.0%)] Loss: 0.025421 L1: 0.014743 Grad: 0.106575 Thermal: 0.000399 LR: 4.28e-06\n",
      "Epoch  20 [3900/10697 ( 36.5%)] Loss: 0.025377 L1: 0.014771 Grad: 0.105825 Thermal: 0.000469 LR: 4.28e-06\n",
      "Epoch  20 [3900/10697 ( 36.5%)] Loss: 0.025377 L1: 0.014771 Grad: 0.105825 Thermal: 0.000469 LR: 4.28e-06\n",
      "Epoch  20 [3950/10697 ( 36.9%)] Loss: 0.027304 L1: 0.016116 Grad: 0.111651 Thermal: 0.000460 LR: 4.28e-06\n",
      "Epoch  20 [3950/10697 ( 36.9%)] Loss: 0.027304 L1: 0.016116 Grad: 0.111651 Thermal: 0.000460 LR: 4.28e-06\n",
      "Epoch  20 [4000/10697 ( 37.4%)] Loss: 0.026995 L1: 0.015777 Grad: 0.111942 Thermal: 0.000480 LR: 4.28e-06\n",
      "Epoch  20 [4000/10697 ( 37.4%)] Loss: 0.026995 L1: 0.015777 Grad: 0.111942 Thermal: 0.000480 LR: 4.28e-06\n",
      "Epoch  20 [4050/10697 ( 37.9%)] Loss: 0.025260 L1: 0.014907 Grad: 0.103306 Thermal: 0.000440 LR: 4.28e-06\n",
      "Epoch  20 [4050/10697 ( 37.9%)] Loss: 0.025260 L1: 0.014907 Grad: 0.103306 Thermal: 0.000440 LR: 4.28e-06\n",
      "Epoch  20 [4100/10697 ( 38.3%)] Loss: 0.030014 L1: 0.017464 Grad: 0.125199 Thermal: 0.000597 LR: 4.28e-06\n",
      "Epoch  20 [4100/10697 ( 38.3%)] Loss: 0.030014 L1: 0.017464 Grad: 0.125199 Thermal: 0.000597 LR: 4.28e-06\n",
      "Epoch  20 [4150/10697 ( 38.8%)] Loss: 0.023296 L1: 0.013940 Grad: 0.093371 Thermal: 0.000377 LR: 4.28e-06\n",
      "Epoch  20 [4150/10697 ( 38.8%)] Loss: 0.023296 L1: 0.013940 Grad: 0.093371 Thermal: 0.000377 LR: 4.28e-06\n",
      "Epoch  20 [4200/10697 ( 39.3%)] Loss: 0.023715 L1: 0.013512 Grad: 0.101850 Thermal: 0.000363 LR: 4.28e-06\n",
      "Epoch  20 [4200/10697 ( 39.3%)] Loss: 0.023715 L1: 0.013512 Grad: 0.101850 Thermal: 0.000363 LR: 4.28e-06\n",
      "Epoch  20 [4250/10697 ( 39.7%)] Loss: 0.026136 L1: 0.015189 Grad: 0.109258 Thermal: 0.000434 LR: 4.28e-06\n",
      "Epoch  20 [4250/10697 ( 39.7%)] Loss: 0.026136 L1: 0.015189 Grad: 0.109258 Thermal: 0.000434 LR: 4.28e-06\n",
      "Epoch  20 [4300/10697 ( 40.2%)] Loss: 0.032717 L1: 0.019735 Grad: 0.129437 Thermal: 0.000762 LR: 4.28e-06\n",
      "Epoch  20 [4300/10697 ( 40.2%)] Loss: 0.032717 L1: 0.019735 Grad: 0.129437 Thermal: 0.000762 LR: 4.28e-06\n",
      "Epoch  20 [4350/10697 ( 40.7%)] Loss: 0.025053 L1: 0.014547 Grad: 0.104857 Thermal: 0.000401 LR: 4.28e-06\n",
      "Epoch  20 [4350/10697 ( 40.7%)] Loss: 0.025053 L1: 0.014547 Grad: 0.104857 Thermal: 0.000401 LR: 4.28e-06\n",
      "Epoch  20 [4400/10697 ( 41.1%)] Loss: 0.025949 L1: 0.014780 Grad: 0.111461 Thermal: 0.000465 LR: 4.28e-06\n",
      "Epoch  20 [4400/10697 ( 41.1%)] Loss: 0.025949 L1: 0.014780 Grad: 0.111461 Thermal: 0.000465 LR: 4.28e-06\n",
      "Epoch  20 [4450/10697 ( 41.6%)] Loss: 0.034289 L1: 0.019440 Grad: 0.148123 Thermal: 0.000735 LR: 4.28e-06\n",
      "Epoch  20 [4450/10697 ( 41.6%)] Loss: 0.034289 L1: 0.019440 Grad: 0.148123 Thermal: 0.000735 LR: 4.28e-06\n",
      "Epoch  20 [4500/10697 ( 42.1%)] Loss: 0.022954 L1: 0.013569 Grad: 0.093654 Thermal: 0.000402 LR: 4.28e-06\n",
      "Epoch  20 [4500/10697 ( 42.1%)] Loss: 0.022954 L1: 0.013569 Grad: 0.093654 Thermal: 0.000402 LR: 4.28e-06\n",
      "Epoch  20 [4550/10697 ( 42.5%)] Loss: 0.024371 L1: 0.014270 Grad: 0.100803 Thermal: 0.000403 LR: 4.28e-06\n",
      "Epoch  20 [4550/10697 ( 42.5%)] Loss: 0.024371 L1: 0.014270 Grad: 0.100803 Thermal: 0.000403 LR: 4.28e-06\n",
      "Epoch  20 [4600/10697 ( 43.0%)] Loss: 0.031684 L1: 0.018705 Grad: 0.129461 Thermal: 0.000654 LR: 4.28e-06\n",
      "Epoch  20 [4600/10697 ( 43.0%)] Loss: 0.031684 L1: 0.018705 Grad: 0.129461 Thermal: 0.000654 LR: 4.28e-06\n",
      "Epoch  20 [4650/10697 ( 43.5%)] Loss: 0.026045 L1: 0.015319 Grad: 0.107040 Thermal: 0.000456 LR: 4.28e-06\n",
      "Epoch  20 [4650/10697 ( 43.5%)] Loss: 0.026045 L1: 0.015319 Grad: 0.107040 Thermal: 0.000456 LR: 4.28e-06\n",
      "Epoch  20 [4700/10697 ( 43.9%)] Loss: 0.022538 L1: 0.013467 Grad: 0.090534 Thermal: 0.000351 LR: 4.28e-06\n",
      "Epoch  20 [4700/10697 ( 43.9%)] Loss: 0.022538 L1: 0.013467 Grad: 0.090534 Thermal: 0.000351 LR: 4.28e-06\n",
      "Epoch  20 [4750/10697 ( 44.4%)] Loss: 0.023868 L1: 0.014209 Grad: 0.096397 Thermal: 0.000392 LR: 4.28e-06\n",
      "Epoch  20 [4750/10697 ( 44.4%)] Loss: 0.023868 L1: 0.014209 Grad: 0.096397 Thermal: 0.000392 LR: 4.28e-06\n",
      "Epoch  20 [4800/10697 ( 44.9%)] Loss: 0.024760 L1: 0.014364 Grad: 0.103754 Thermal: 0.000416 LR: 4.28e-06\n",
      "Epoch  20 [4800/10697 ( 44.9%)] Loss: 0.024760 L1: 0.014364 Grad: 0.103754 Thermal: 0.000416 LR: 4.28e-06\n",
      "Epoch  20 [4850/10697 ( 45.3%)] Loss: 0.034489 L1: 0.020155 Grad: 0.142949 Thermal: 0.000796 LR: 4.28e-06\n",
      "Epoch  20 [4850/10697 ( 45.3%)] Loss: 0.034489 L1: 0.020155 Grad: 0.142949 Thermal: 0.000796 LR: 4.28e-06\n",
      "Epoch  20 [4900/10697 ( 45.8%)] Loss: 0.028729 L1: 0.017089 Grad: 0.116138 Thermal: 0.000531 LR: 4.28e-06\n",
      "Epoch  20 [4900/10697 ( 45.8%)] Loss: 0.028729 L1: 0.017089 Grad: 0.116138 Thermal: 0.000531 LR: 4.28e-06\n",
      "Epoch  20 [4950/10697 ( 46.3%)] Loss: 0.029552 L1: 0.017180 Grad: 0.123449 Thermal: 0.000535 LR: 4.28e-06\n",
      "Epoch  20 [4950/10697 ( 46.3%)] Loss: 0.029552 L1: 0.017180 Grad: 0.123449 Thermal: 0.000535 LR: 4.28e-06\n",
      "Epoch  20 [5000/10697 ( 46.7%)] Loss: 0.029676 L1: 0.017269 Grad: 0.123780 Thermal: 0.000571 LR: 4.28e-06\n",
      "Epoch  20 [5000/10697 ( 46.7%)] Loss: 0.029676 L1: 0.017269 Grad: 0.123780 Thermal: 0.000571 LR: 4.28e-06\n",
      "Epoch  20 [5050/10697 ( 47.2%)] Loss: 0.025923 L1: 0.015676 Grad: 0.102248 Thermal: 0.000434 LR: 4.28e-06\n",
      "Epoch  20 [5050/10697 ( 47.2%)] Loss: 0.025923 L1: 0.015676 Grad: 0.102248 Thermal: 0.000434 LR: 4.28e-06\n",
      "Epoch  20 [5100/10697 ( 47.7%)] Loss: 0.030539 L1: 0.018185 Grad: 0.123239 Thermal: 0.000597 LR: 4.28e-06\n",
      "Epoch  20 [5100/10697 ( 47.7%)] Loss: 0.030539 L1: 0.018185 Grad: 0.123239 Thermal: 0.000597 LR: 4.28e-06\n",
      "Epoch  20 [5150/10697 ( 48.1%)] Loss: 0.027471 L1: 0.016516 Grad: 0.109296 Thermal: 0.000502 LR: 4.28e-06\n",
      "Epoch  20 [5150/10697 ( 48.1%)] Loss: 0.027471 L1: 0.016516 Grad: 0.109296 Thermal: 0.000502 LR: 4.28e-06\n",
      "Epoch  20 [5200/10697 ( 48.6%)] Loss: 0.029152 L1: 0.016925 Grad: 0.122009 Thermal: 0.000526 LR: 4.28e-06\n",
      "Epoch  20 [5200/10697 ( 48.6%)] Loss: 0.029152 L1: 0.016925 Grad: 0.122009 Thermal: 0.000526 LR: 4.28e-06\n",
      "Epoch  20 [5250/10697 ( 49.1%)] Loss: 0.027583 L1: 0.015833 Grad: 0.117252 Thermal: 0.000495 LR: 4.28e-06\n",
      "Epoch  20 [5250/10697 ( 49.1%)] Loss: 0.027583 L1: 0.015833 Grad: 0.117252 Thermal: 0.000495 LR: 4.28e-06\n",
      "Epoch  20 [5300/10697 ( 49.5%)] Loss: 0.031099 L1: 0.017785 Grad: 0.132856 Thermal: 0.000563 LR: 4.28e-06\n",
      "Epoch  20 [5300/10697 ( 49.5%)] Loss: 0.031099 L1: 0.017785 Grad: 0.132856 Thermal: 0.000563 LR: 4.28e-06\n",
      "Epoch  20 [5350/10697 ( 50.0%)] Loss: 0.019767 L1: 0.011498 Grad: 0.082548 Thermal: 0.000280 LR: 4.28e-06\n",
      "Epoch  20 [5350/10697 ( 50.0%)] Loss: 0.019767 L1: 0.011498 Grad: 0.082548 Thermal: 0.000280 LR: 4.28e-06\n",
      "Epoch  20 [5400/10697 ( 50.5%)] Loss: 0.032711 L1: 0.018937 Grad: 0.137405 Thermal: 0.000658 LR: 4.28e-06\n",
      "Epoch  20 [5400/10697 ( 50.5%)] Loss: 0.032711 L1: 0.018937 Grad: 0.137405 Thermal: 0.000658 LR: 4.28e-06\n",
      "Epoch  20 [5450/10697 ( 50.9%)] Loss: 0.024563 L1: 0.014177 Grad: 0.103672 Thermal: 0.000374 LR: 4.28e-06\n",
      "Epoch  20 [5450/10697 ( 50.9%)] Loss: 0.024563 L1: 0.014177 Grad: 0.103672 Thermal: 0.000374 LR: 4.28e-06\n",
      "Epoch  20 [5500/10697 ( 51.4%)] Loss: 0.028620 L1: 0.016578 Grad: 0.120166 Thermal: 0.000502 LR: 4.28e-06\n",
      "Epoch  20 [5500/10697 ( 51.4%)] Loss: 0.028620 L1: 0.016578 Grad: 0.120166 Thermal: 0.000502 LR: 4.28e-06\n",
      "Epoch  20 [5550/10697 ( 51.9%)] Loss: 0.027762 L1: 0.016189 Grad: 0.115484 Thermal: 0.000489 LR: 4.28e-06\n",
      "Epoch  20 [5550/10697 ( 51.9%)] Loss: 0.027762 L1: 0.016189 Grad: 0.115484 Thermal: 0.000489 LR: 4.28e-06\n",
      "Epoch  20 [5600/10697 ( 52.4%)] Loss: 0.024073 L1: 0.013794 Grad: 0.102568 Thermal: 0.000446 LR: 4.28e-06\n",
      "Epoch  20 [5600/10697 ( 52.4%)] Loss: 0.024073 L1: 0.013794 Grad: 0.102568 Thermal: 0.000446 LR: 4.28e-06\n",
      "Epoch  20 [5650/10697 ( 52.8%)] Loss: 0.024544 L1: 0.014443 Grad: 0.100818 Thermal: 0.000384 LR: 4.28e-06\n",
      "Epoch  20 [5650/10697 ( 52.8%)] Loss: 0.024544 L1: 0.014443 Grad: 0.100818 Thermal: 0.000384 LR: 4.28e-06\n",
      "Epoch  20 [5700/10697 ( 53.3%)] Loss: 0.026986 L1: 0.016148 Grad: 0.108145 Thermal: 0.000478 LR: 4.28e-06\n",
      "Epoch  20 [5700/10697 ( 53.3%)] Loss: 0.026986 L1: 0.016148 Grad: 0.108145 Thermal: 0.000478 LR: 4.28e-06\n",
      "Epoch  20 [5750/10697 ( 53.8%)] Loss: 0.028808 L1: 0.017217 Grad: 0.115650 Thermal: 0.000518 LR: 4.28e-06\n",
      "Epoch  20 [5750/10697 ( 53.8%)] Loss: 0.028808 L1: 0.017217 Grad: 0.115650 Thermal: 0.000518 LR: 4.28e-06\n",
      "Epoch  20 [5800/10697 ( 54.2%)] Loss: 0.034779 L1: 0.020241 Grad: 0.144995 Thermal: 0.000776 LR: 4.28e-06\n",
      "Epoch  20 [5800/10697 ( 54.2%)] Loss: 0.034779 L1: 0.020241 Grad: 0.144995 Thermal: 0.000776 LR: 4.28e-06\n",
      "Epoch  20 [5850/10697 ( 54.7%)] Loss: 0.024719 L1: 0.014775 Grad: 0.099229 Thermal: 0.000423 LR: 4.28e-06\n",
      "Epoch  20 [5850/10697 ( 54.7%)] Loss: 0.024719 L1: 0.014775 Grad: 0.099229 Thermal: 0.000423 LR: 4.28e-06\n",
      "Epoch  20 [5900/10697 ( 55.2%)] Loss: 0.027350 L1: 0.016158 Grad: 0.111675 Thermal: 0.000495 LR: 4.28e-06\n",
      "Epoch  20 [5900/10697 ( 55.2%)] Loss: 0.027350 L1: 0.016158 Grad: 0.111675 Thermal: 0.000495 LR: 4.28e-06\n",
      "Epoch  20 [5950/10697 ( 55.6%)] Loss: 0.024876 L1: 0.014763 Grad: 0.100931 Thermal: 0.000409 LR: 4.28e-06\n",
      "Epoch  20 [5950/10697 ( 55.6%)] Loss: 0.024876 L1: 0.014763 Grad: 0.100931 Thermal: 0.000409 LR: 4.28e-06\n",
      "Epoch  20 [6000/10697 ( 56.1%)] Loss: 0.020299 L1: 0.011511 Grad: 0.087742 Thermal: 0.000270 LR: 4.28e-06\n",
      "Epoch  20 [6000/10697 ( 56.1%)] Loss: 0.020299 L1: 0.011511 Grad: 0.087742 Thermal: 0.000270 LR: 4.28e-06\n",
      "Epoch  20 [6050/10697 ( 56.6%)] Loss: 0.025731 L1: 0.015318 Grad: 0.103911 Thermal: 0.000436 LR: 4.28e-06\n",
      "Epoch  20 [6050/10697 ( 56.6%)] Loss: 0.025731 L1: 0.015318 Grad: 0.103911 Thermal: 0.000436 LR: 4.28e-06\n",
      "Epoch  20 [6100/10697 ( 57.0%)] Loss: 0.024713 L1: 0.014827 Grad: 0.098670 Thermal: 0.000389 LR: 4.28e-06\n",
      "Epoch  20 [6100/10697 ( 57.0%)] Loss: 0.024713 L1: 0.014827 Grad: 0.098670 Thermal: 0.000389 LR: 4.28e-06\n",
      "Epoch  20 [6150/10697 ( 57.5%)] Loss: 0.029045 L1: 0.017083 Grad: 0.119357 Thermal: 0.000526 LR: 4.28e-06\n",
      "Epoch  20 [6150/10697 ( 57.5%)] Loss: 0.029045 L1: 0.017083 Grad: 0.119357 Thermal: 0.000526 LR: 4.28e-06\n",
      "Epoch  20 [6200/10697 ( 58.0%)] Loss: 0.025196 L1: 0.014073 Grad: 0.111024 Thermal: 0.000420 LR: 4.28e-06\n",
      "Epoch  20 [6200/10697 ( 58.0%)] Loss: 0.025196 L1: 0.014073 Grad: 0.111024 Thermal: 0.000420 LR: 4.28e-06\n",
      "Epoch  20 [6250/10697 ( 58.4%)] Loss: 0.026469 L1: 0.015439 Grad: 0.110085 Thermal: 0.000435 LR: 4.28e-06\n",
      "Epoch  20 [6250/10697 ( 58.4%)] Loss: 0.026469 L1: 0.015439 Grad: 0.110085 Thermal: 0.000435 LR: 4.28e-06\n",
      "Epoch  20 [6300/10697 ( 58.9%)] Loss: 0.026202 L1: 0.015344 Grad: 0.108365 Thermal: 0.000427 LR: 4.28e-06\n",
      "Epoch  20 [6300/10697 ( 58.9%)] Loss: 0.026202 L1: 0.015344 Grad: 0.108365 Thermal: 0.000427 LR: 4.28e-06\n",
      "Epoch  20 [6350/10697 ( 59.4%)] Loss: 0.025768 L1: 0.015168 Grad: 0.105784 Thermal: 0.000432 LR: 4.28e-06\n",
      "Epoch  20 [6350/10697 ( 59.4%)] Loss: 0.025768 L1: 0.015168 Grad: 0.105784 Thermal: 0.000432 LR: 4.28e-06\n",
      "Epoch  20 [6400/10697 ( 59.8%)] Loss: 0.023790 L1: 0.013845 Grad: 0.099263 Thermal: 0.000375 LR: 4.28e-06\n",
      "Epoch  20 [6400/10697 ( 59.8%)] Loss: 0.023790 L1: 0.013845 Grad: 0.099263 Thermal: 0.000375 LR: 4.28e-06\n",
      "Epoch  20 [6450/10697 ( 60.3%)] Loss: 0.027992 L1: 0.016618 Grad: 0.113497 Thermal: 0.000499 LR: 4.28e-06\n",
      "Epoch  20 [6450/10697 ( 60.3%)] Loss: 0.027992 L1: 0.016618 Grad: 0.113497 Thermal: 0.000499 LR: 4.28e-06\n",
      "Epoch  20 [6500/10697 ( 60.8%)] Loss: 0.029088 L1: 0.016516 Grad: 0.125460 Thermal: 0.000507 LR: 4.28e-06\n",
      "Epoch  20 [6500/10697 ( 60.8%)] Loss: 0.029088 L1: 0.016516 Grad: 0.125460 Thermal: 0.000507 LR: 4.28e-06\n",
      "Epoch  20 [6550/10697 ( 61.2%)] Loss: 0.022699 L1: 0.013052 Grad: 0.096297 Thermal: 0.000339 LR: 4.28e-06\n",
      "Epoch  20 [6550/10697 ( 61.2%)] Loss: 0.022699 L1: 0.013052 Grad: 0.096297 Thermal: 0.000339 LR: 4.28e-06\n",
      "Epoch  20 [6600/10697 ( 61.7%)] Loss: 0.022003 L1: 0.012728 Grad: 0.092575 Thermal: 0.000352 LR: 4.28e-06\n",
      "Epoch  20 [6600/10697 ( 61.7%)] Loss: 0.022003 L1: 0.012728 Grad: 0.092575 Thermal: 0.000352 LR: 4.28e-06\n",
      "Epoch  20 [6650/10697 ( 62.2%)] Loss: 0.034733 L1: 0.019969 Grad: 0.147283 Thermal: 0.000701 LR: 4.28e-06\n",
      "Epoch  20 [6650/10697 ( 62.2%)] Loss: 0.034733 L1: 0.019969 Grad: 0.147283 Thermal: 0.000701 LR: 4.28e-06\n",
      "Epoch  20 [6700/10697 ( 62.6%)] Loss: 0.021068 L1: 0.012173 Grad: 0.088803 Thermal: 0.000297 LR: 4.28e-06\n",
      "Epoch  20 [6700/10697 ( 62.6%)] Loss: 0.021068 L1: 0.012173 Grad: 0.088803 Thermal: 0.000297 LR: 4.28e-06\n",
      "Epoch  20 [6750/10697 ( 63.1%)] Loss: 0.019067 L1: 0.011120 Grad: 0.079348 Thermal: 0.000249 LR: 4.28e-06\n",
      "Epoch  20 [6750/10697 ( 63.1%)] Loss: 0.019067 L1: 0.011120 Grad: 0.079348 Thermal: 0.000249 LR: 4.28e-06\n",
      "Epoch  20 [6800/10697 ( 63.6%)] Loss: 0.027973 L1: 0.016794 Grad: 0.111525 Thermal: 0.000513 LR: 4.28e-06\n",
      "Epoch  20 [6800/10697 ( 63.6%)] Loss: 0.027973 L1: 0.016794 Grad: 0.111525 Thermal: 0.000513 LR: 4.28e-06\n",
      "Epoch  20 [6850/10697 ( 64.0%)] Loss: 0.025894 L1: 0.015486 Grad: 0.103869 Thermal: 0.000424 LR: 4.28e-06\n",
      "Epoch  20 [6850/10697 ( 64.0%)] Loss: 0.025894 L1: 0.015486 Grad: 0.103869 Thermal: 0.000424 LR: 4.28e-06\n",
      "Epoch  20 [6900/10697 ( 64.5%)] Loss: 0.028464 L1: 0.016747 Grad: 0.116927 Thermal: 0.000491 LR: 4.28e-06\n",
      "Epoch  20 [6900/10697 ( 64.5%)] Loss: 0.028464 L1: 0.016747 Grad: 0.116927 Thermal: 0.000491 LR: 4.28e-06\n",
      "Epoch  20 [6950/10697 ( 65.0%)] Loss: 0.030169 L1: 0.017871 Grad: 0.122702 Thermal: 0.000554 LR: 4.28e-06\n",
      "Epoch  20 [6950/10697 ( 65.0%)] Loss: 0.030169 L1: 0.017871 Grad: 0.122702 Thermal: 0.000554 LR: 4.28e-06\n",
      "Epoch  20 [7000/10697 ( 65.4%)] Loss: 0.027781 L1: 0.015962 Grad: 0.117955 Thermal: 0.000474 LR: 4.28e-06\n",
      "Epoch  20 [7000/10697 ( 65.4%)] Loss: 0.027781 L1: 0.015962 Grad: 0.117955 Thermal: 0.000474 LR: 4.28e-06\n",
      "Epoch  20 [7050/10697 ( 65.9%)] Loss: 0.025128 L1: 0.014832 Grad: 0.102755 Thermal: 0.000419 LR: 4.28e-06\n",
      "Epoch  20 [7050/10697 ( 65.9%)] Loss: 0.025128 L1: 0.014832 Grad: 0.102755 Thermal: 0.000419 LR: 4.28e-06\n",
      "Epoch  20 [7100/10697 ( 66.4%)] Loss: 0.032400 L1: 0.018410 Grad: 0.139542 Thermal: 0.000716 LR: 4.28e-06\n",
      "Epoch  20 [7100/10697 ( 66.4%)] Loss: 0.032400 L1: 0.018410 Grad: 0.139542 Thermal: 0.000716 LR: 4.28e-06\n",
      "Epoch  20 [7150/10697 ( 66.8%)] Loss: 0.029535 L1: 0.017022 Grad: 0.124819 Thermal: 0.000618 LR: 4.28e-06\n",
      "Epoch  20 [7150/10697 ( 66.8%)] Loss: 0.029535 L1: 0.017022 Grad: 0.124819 Thermal: 0.000618 LR: 4.28e-06\n",
      "Epoch  20 [7200/10697 ( 67.3%)] Loss: 0.023947 L1: 0.014388 Grad: 0.095390 Thermal: 0.000395 LR: 4.28e-06\n",
      "Epoch  20 [7200/10697 ( 67.3%)] Loss: 0.023947 L1: 0.014388 Grad: 0.095390 Thermal: 0.000395 LR: 4.28e-06\n",
      "Epoch  20 [7250/10697 ( 67.8%)] Loss: 0.022059 L1: 0.012909 Grad: 0.091341 Thermal: 0.000326 LR: 4.28e-06\n",
      "Epoch  20 [7250/10697 ( 67.8%)] Loss: 0.022059 L1: 0.012909 Grad: 0.091341 Thermal: 0.000326 LR: 4.28e-06\n",
      "Epoch  20 [7300/10697 ( 68.2%)] Loss: 0.027163 L1: 0.015988 Grad: 0.111526 Thermal: 0.000448 LR: 4.28e-06\n",
      "Epoch  20 [7300/10697 ( 68.2%)] Loss: 0.027163 L1: 0.015988 Grad: 0.111526 Thermal: 0.000448 LR: 4.28e-06\n",
      "Epoch  20 [7350/10697 ( 68.7%)] Loss: 0.028081 L1: 0.016415 Grad: 0.116413 Thermal: 0.000504 LR: 4.28e-06\n",
      "Epoch  20 [7350/10697 ( 68.7%)] Loss: 0.028081 L1: 0.016415 Grad: 0.116413 Thermal: 0.000504 LR: 4.28e-06\n",
      "Epoch  20 [7400/10697 ( 69.2%)] Loss: 0.025895 L1: 0.015018 Grad: 0.108545 Thermal: 0.000446 LR: 4.28e-06\n",
      "Epoch  20 [7400/10697 ( 69.2%)] Loss: 0.025895 L1: 0.015018 Grad: 0.108545 Thermal: 0.000446 LR: 4.28e-06\n",
      "Epoch  20 [7450/10697 ( 69.6%)] Loss: 0.026891 L1: 0.015740 Grad: 0.111286 Thermal: 0.000451 LR: 4.28e-06\n",
      "Epoch  20 [7450/10697 ( 69.6%)] Loss: 0.026891 L1: 0.015740 Grad: 0.111286 Thermal: 0.000451 LR: 4.28e-06\n",
      "Epoch  20 [7500/10697 ( 70.1%)] Loss: 0.024128 L1: 0.014461 Grad: 0.096484 Thermal: 0.000383 LR: 4.28e-06\n",
      "Epoch  20 [7500/10697 ( 70.1%)] Loss: 0.024128 L1: 0.014461 Grad: 0.096484 Thermal: 0.000383 LR: 4.28e-06\n",
      "Epoch  20 [7550/10697 ( 70.6%)] Loss: 0.023611 L1: 0.013678 Grad: 0.099149 Thermal: 0.000367 LR: 4.28e-06\n",
      "Epoch  20 [7550/10697 ( 70.6%)] Loss: 0.023611 L1: 0.013678 Grad: 0.099149 Thermal: 0.000367 LR: 4.28e-06\n",
      "Epoch  20 [7600/10697 ( 71.0%)] Loss: 0.022452 L1: 0.012952 Grad: 0.094827 Thermal: 0.000345 LR: 4.28e-06\n",
      "Epoch  20 [7600/10697 ( 71.0%)] Loss: 0.022452 L1: 0.012952 Grad: 0.094827 Thermal: 0.000345 LR: 4.28e-06\n",
      "Epoch  20 [7650/10697 ( 71.5%)] Loss: 0.031436 L1: 0.018254 Grad: 0.131475 Thermal: 0.000689 LR: 4.28e-06\n",
      "Epoch  20 [7650/10697 ( 71.5%)] Loss: 0.031436 L1: 0.018254 Grad: 0.131475 Thermal: 0.000689 LR: 4.28e-06\n",
      "Epoch  20 [7700/10697 ( 72.0%)] Loss: 0.024763 L1: 0.014115 Grad: 0.106274 Thermal: 0.000407 LR: 4.28e-06\n",
      "Epoch  20 [7700/10697 ( 72.0%)] Loss: 0.024763 L1: 0.014115 Grad: 0.106274 Thermal: 0.000407 LR: 4.28e-06\n",
      "Epoch  20 [7750/10697 ( 72.5%)] Loss: 0.028028 L1: 0.016486 Grad: 0.115186 Thermal: 0.000480 LR: 4.28e-06\n",
      "Epoch  20 [7750/10697 ( 72.5%)] Loss: 0.028028 L1: 0.016486 Grad: 0.115186 Thermal: 0.000480 LR: 4.28e-06\n",
      "Epoch  20 [7800/10697 ( 72.9%)] Loss: 0.029965 L1: 0.017702 Grad: 0.122356 Thermal: 0.000536 LR: 4.28e-06\n",
      "Epoch  20 [7800/10697 ( 72.9%)] Loss: 0.029965 L1: 0.017702 Grad: 0.122356 Thermal: 0.000536 LR: 4.28e-06\n",
      "Epoch  20 [7850/10697 ( 73.4%)] Loss: 0.022663 L1: 0.013348 Grad: 0.092956 Thermal: 0.000392 LR: 4.28e-06\n",
      "Epoch  20 [7850/10697 ( 73.4%)] Loss: 0.022663 L1: 0.013348 Grad: 0.092956 Thermal: 0.000392 LR: 4.28e-06\n",
      "Epoch  20 [7900/10697 ( 73.9%)] Loss: 0.025869 L1: 0.014759 Grad: 0.110892 Thermal: 0.000418 LR: 4.28e-06\n",
      "Epoch  20 [7900/10697 ( 73.9%)] Loss: 0.025869 L1: 0.014759 Grad: 0.110892 Thermal: 0.000418 LR: 4.28e-06\n",
      "Epoch  20 [7950/10697 ( 74.3%)] Loss: 0.029204 L1: 0.017094 Grad: 0.120832 Thermal: 0.000540 LR: 4.28e-06\n",
      "Epoch  20 [7950/10697 ( 74.3%)] Loss: 0.029204 L1: 0.017094 Grad: 0.120832 Thermal: 0.000540 LR: 4.28e-06\n",
      "Epoch  20 [8000/10697 ( 74.8%)] Loss: 0.023518 L1: 0.013617 Grad: 0.098838 Thermal: 0.000337 LR: 4.28e-06\n",
      "Epoch  20 [8000/10697 ( 74.8%)] Loss: 0.023518 L1: 0.013617 Grad: 0.098838 Thermal: 0.000337 LR: 4.28e-06\n",
      "Epoch  20 [8050/10697 ( 75.3%)] Loss: 0.026763 L1: 0.015366 Grad: 0.113754 Thermal: 0.000421 LR: 4.28e-06\n",
      "Epoch  20 [8050/10697 ( 75.3%)] Loss: 0.026763 L1: 0.015366 Grad: 0.113754 Thermal: 0.000421 LR: 4.28e-06\n",
      "Epoch  20 [8100/10697 ( 75.7%)] Loss: 0.025662 L1: 0.015031 Grad: 0.106100 Thermal: 0.000418 LR: 4.28e-06\n",
      "Epoch  20 [8100/10697 ( 75.7%)] Loss: 0.025662 L1: 0.015031 Grad: 0.106100 Thermal: 0.000418 LR: 4.28e-06\n",
      "Epoch  20 [8150/10697 ( 76.2%)] Loss: 0.022601 L1: 0.013280 Grad: 0.093029 Thermal: 0.000350 LR: 4.28e-06\n",
      "Epoch  20 [8150/10697 ( 76.2%)] Loss: 0.022601 L1: 0.013280 Grad: 0.093029 Thermal: 0.000350 LR: 4.28e-06\n",
      "Epoch  20 [8200/10697 ( 76.7%)] Loss: 0.027215 L1: 0.015746 Grad: 0.114461 Thermal: 0.000461 LR: 4.28e-06\n",
      "Epoch  20 [8200/10697 ( 76.7%)] Loss: 0.027215 L1: 0.015746 Grad: 0.114461 Thermal: 0.000461 LR: 4.28e-06\n",
      "Epoch  20 [8250/10697 ( 77.1%)] Loss: 0.023287 L1: 0.013477 Grad: 0.097908 Thermal: 0.000379 LR: 4.28e-06\n",
      "Epoch  20 [8250/10697 ( 77.1%)] Loss: 0.023287 L1: 0.013477 Grad: 0.097908 Thermal: 0.000379 LR: 4.28e-06\n",
      "Epoch  20 [8300/10697 ( 77.6%)] Loss: 0.025627 L1: 0.014908 Grad: 0.106966 Thermal: 0.000445 LR: 4.28e-06\n",
      "Epoch  20 [8300/10697 ( 77.6%)] Loss: 0.025627 L1: 0.014908 Grad: 0.106966 Thermal: 0.000445 LR: 4.28e-06\n",
      "Epoch  20 [8350/10697 ( 78.1%)] Loss: 0.026024 L1: 0.015503 Grad: 0.104991 Thermal: 0.000438 LR: 4.28e-06\n",
      "Epoch  20 [8350/10697 ( 78.1%)] Loss: 0.026024 L1: 0.015503 Grad: 0.104991 Thermal: 0.000438 LR: 4.28e-06\n",
      "Epoch  20 [8400/10697 ( 78.5%)] Loss: 0.030178 L1: 0.018003 Grad: 0.121449 Thermal: 0.000608 LR: 4.28e-06\n",
      "Epoch  20 [8400/10697 ( 78.5%)] Loss: 0.030178 L1: 0.018003 Grad: 0.121449 Thermal: 0.000608 LR: 4.28e-06\n",
      "Epoch  20 [8450/10697 ( 79.0%)] Loss: 0.027398 L1: 0.015643 Grad: 0.117319 Thermal: 0.000464 LR: 4.28e-06\n",
      "Epoch  20 [8450/10697 ( 79.0%)] Loss: 0.027398 L1: 0.015643 Grad: 0.117319 Thermal: 0.000464 LR: 4.28e-06\n",
      "Epoch  20 [8500/10697 ( 79.5%)] Loss: 0.027677 L1: 0.016162 Grad: 0.114906 Thermal: 0.000488 LR: 4.28e-06\n",
      "Epoch  20 [8500/10697 ( 79.5%)] Loss: 0.027677 L1: 0.016162 Grad: 0.114906 Thermal: 0.000488 LR: 4.28e-06\n",
      "Epoch  20 [8550/10697 ( 79.9%)] Loss: 0.024635 L1: 0.014272 Grad: 0.103423 Thermal: 0.000406 LR: 4.28e-06\n",
      "Epoch  20 [8550/10697 ( 79.9%)] Loss: 0.024635 L1: 0.014272 Grad: 0.103423 Thermal: 0.000406 LR: 4.28e-06\n",
      "Epoch  20 [8600/10697 ( 80.4%)] Loss: 0.025831 L1: 0.015287 Grad: 0.105209 Thermal: 0.000458 LR: 4.28e-06\n",
      "Epoch  20 [8600/10697 ( 80.4%)] Loss: 0.025831 L1: 0.015287 Grad: 0.105209 Thermal: 0.000458 LR: 4.28e-06\n",
      "Epoch  20 [8650/10697 ( 80.9%)] Loss: 0.020090 L1: 0.011587 Grad: 0.084889 Thermal: 0.000290 LR: 4.28e-06\n",
      "Epoch  20 [8650/10697 ( 80.9%)] Loss: 0.020090 L1: 0.011587 Grad: 0.084889 Thermal: 0.000290 LR: 4.28e-06\n",
      "Epoch  20 [8700/10697 ( 81.3%)] Loss: 0.030111 L1: 0.017697 Grad: 0.123852 Thermal: 0.000561 LR: 4.28e-06\n",
      "Epoch  20 [8700/10697 ( 81.3%)] Loss: 0.030111 L1: 0.017697 Grad: 0.123852 Thermal: 0.000561 LR: 4.28e-06\n",
      "Epoch  20 [8750/10697 ( 81.8%)] Loss: 0.023839 L1: 0.013962 Grad: 0.098544 Thermal: 0.000441 LR: 4.28e-06\n",
      "Epoch  20 [8750/10697 ( 81.8%)] Loss: 0.023839 L1: 0.013962 Grad: 0.098544 Thermal: 0.000441 LR: 4.28e-06\n",
      "Epoch  20 [8800/10697 ( 82.3%)] Loss: 0.023444 L1: 0.013708 Grad: 0.097178 Thermal: 0.000368 LR: 4.28e-06\n",
      "Epoch  20 [8800/10697 ( 82.3%)] Loss: 0.023444 L1: 0.013708 Grad: 0.097178 Thermal: 0.000368 LR: 4.28e-06\n",
      "Epoch  20 [8850/10697 ( 82.7%)] Loss: 0.027728 L1: 0.016142 Grad: 0.115617 Thermal: 0.000499 LR: 4.28e-06\n",
      "Epoch  20 [8850/10697 ( 82.7%)] Loss: 0.027728 L1: 0.016142 Grad: 0.115617 Thermal: 0.000499 LR: 4.28e-06\n",
      "Epoch  20 [8900/10697 ( 83.2%)] Loss: 0.023493 L1: 0.013387 Grad: 0.100874 Thermal: 0.000380 LR: 4.28e-06\n",
      "Epoch  20 [8900/10697 ( 83.2%)] Loss: 0.023493 L1: 0.013387 Grad: 0.100874 Thermal: 0.000380 LR: 4.28e-06\n",
      "Epoch  20 [8950/10697 ( 83.7%)] Loss: 0.028218 L1: 0.016157 Grad: 0.120340 Thermal: 0.000540 LR: 4.28e-06\n",
      "Epoch  20 [8950/10697 ( 83.7%)] Loss: 0.028218 L1: 0.016157 Grad: 0.120340 Thermal: 0.000540 LR: 4.28e-06\n",
      "Epoch  20 [9000/10697 ( 84.1%)] Loss: 0.026891 L1: 0.015356 Grad: 0.115137 Thermal: 0.000418 LR: 4.28e-06\n",
      "Epoch  20 [9000/10697 ( 84.1%)] Loss: 0.026891 L1: 0.015356 Grad: 0.115137 Thermal: 0.000418 LR: 4.28e-06\n",
      "Epoch  20 [9050/10697 ( 84.6%)] Loss: 0.021142 L1: 0.012326 Grad: 0.088015 Thermal: 0.000302 LR: 4.28e-06\n",
      "Epoch  20 [9050/10697 ( 84.6%)] Loss: 0.021142 L1: 0.012326 Grad: 0.088015 Thermal: 0.000302 LR: 4.28e-06\n",
      "Epoch  20 [9100/10697 ( 85.1%)] Loss: 0.031305 L1: 0.018157 Grad: 0.131188 Thermal: 0.000603 LR: 4.28e-06\n",
      "Epoch  20 [9100/10697 ( 85.1%)] Loss: 0.031305 L1: 0.018157 Grad: 0.131188 Thermal: 0.000603 LR: 4.28e-06\n",
      "Epoch  20 [9150/10697 ( 85.5%)] Loss: 0.025467 L1: 0.014666 Grad: 0.107795 Thermal: 0.000415 LR: 4.28e-06\n",
      "Epoch  20 [9150/10697 ( 85.5%)] Loss: 0.025467 L1: 0.014666 Grad: 0.107795 Thermal: 0.000415 LR: 4.28e-06\n",
      "Epoch  20 [9200/10697 ( 86.0%)] Loss: 0.026275 L1: 0.014850 Grad: 0.114029 Thermal: 0.000434 LR: 4.28e-06\n",
      "Epoch  20 [9200/10697 ( 86.0%)] Loss: 0.026275 L1: 0.014850 Grad: 0.114029 Thermal: 0.000434 LR: 4.28e-06\n",
      "Epoch  20 [9250/10697 ( 86.5%)] Loss: 0.027333 L1: 0.015925 Grad: 0.113838 Thermal: 0.000478 LR: 4.28e-06\n",
      "Epoch  20 [9250/10697 ( 86.5%)] Loss: 0.027333 L1: 0.015925 Grad: 0.113838 Thermal: 0.000478 LR: 4.28e-06\n",
      "Epoch  20 [9300/10697 ( 86.9%)] Loss: 0.027934 L1: 0.016497 Grad: 0.114120 Thermal: 0.000506 LR: 4.28e-06\n",
      "Epoch  20 [9300/10697 ( 86.9%)] Loss: 0.027934 L1: 0.016497 Grad: 0.114120 Thermal: 0.000506 LR: 4.28e-06\n",
      "Epoch  20 [9350/10697 ( 87.4%)] Loss: 0.027994 L1: 0.016330 Grad: 0.116397 Thermal: 0.000478 LR: 4.28e-06\n",
      "Epoch  20 [9350/10697 ( 87.4%)] Loss: 0.027994 L1: 0.016330 Grad: 0.116397 Thermal: 0.000478 LR: 4.28e-06\n",
      "Epoch  20 [9400/10697 ( 87.9%)] Loss: 0.025400 L1: 0.014613 Grad: 0.107638 Thermal: 0.000463 LR: 4.28e-06\n",
      "Epoch  20 [9400/10697 ( 87.9%)] Loss: 0.025400 L1: 0.014613 Grad: 0.107638 Thermal: 0.000463 LR: 4.28e-06\n",
      "Epoch  20 [9450/10697 ( 88.3%)] Loss: 0.031920 L1: 0.018245 Grad: 0.136430 Thermal: 0.000648 LR: 4.28e-06\n",
      "Epoch  20 [9450/10697 ( 88.3%)] Loss: 0.031920 L1: 0.018245 Grad: 0.136430 Thermal: 0.000648 LR: 4.28e-06\n",
      "Epoch  20 [9500/10697 ( 88.8%)] Loss: 0.031121 L1: 0.018090 Grad: 0.130005 Thermal: 0.000613 LR: 4.28e-06\n",
      "Epoch  20 [9500/10697 ( 88.8%)] Loss: 0.031121 L1: 0.018090 Grad: 0.130005 Thermal: 0.000613 LR: 4.28e-06\n",
      "Epoch  20 [9550/10697 ( 89.3%)] Loss: 0.026937 L1: 0.015349 Grad: 0.115644 Thermal: 0.000489 LR: 4.28e-06\n",
      "Epoch  20 [9550/10697 ( 89.3%)] Loss: 0.026937 L1: 0.015349 Grad: 0.115644 Thermal: 0.000489 LR: 4.28e-06\n",
      "Epoch  20 [9600/10697 ( 89.7%)] Loss: 0.028239 L1: 0.016211 Grad: 0.120050 Thermal: 0.000473 LR: 4.28e-06\n",
      "Epoch  20 [9600/10697 ( 89.7%)] Loss: 0.028239 L1: 0.016211 Grad: 0.120050 Thermal: 0.000473 LR: 4.28e-06\n",
      "Epoch  20 [9650/10697 ( 90.2%)] Loss: 0.028541 L1: 0.016981 Grad: 0.115340 Thermal: 0.000533 LR: 4.28e-06\n",
      "Epoch  20 [9650/10697 ( 90.2%)] Loss: 0.028541 L1: 0.016981 Grad: 0.115340 Thermal: 0.000533 LR: 4.28e-06\n",
      "Epoch  20 [9700/10697 ( 90.7%)] Loss: 0.025916 L1: 0.015483 Grad: 0.104103 Thermal: 0.000466 LR: 4.28e-06\n",
      "Epoch  20 [9700/10697 ( 90.7%)] Loss: 0.025916 L1: 0.015483 Grad: 0.104103 Thermal: 0.000466 LR: 4.28e-06\n",
      "Epoch  20 [9750/10697 ( 91.1%)] Loss: 0.023041 L1: 0.012969 Grad: 0.100544 Thermal: 0.000359 LR: 4.28e-06\n",
      "Epoch  20 [9750/10697 ( 91.1%)] Loss: 0.023041 L1: 0.012969 Grad: 0.100544 Thermal: 0.000359 LR: 4.28e-06\n",
      "Epoch  20 [9800/10697 ( 91.6%)] Loss: 0.024962 L1: 0.014145 Grad: 0.107963 Thermal: 0.000407 LR: 4.28e-06\n",
      "Epoch  20 [9800/10697 ( 91.6%)] Loss: 0.024962 L1: 0.014145 Grad: 0.107963 Thermal: 0.000407 LR: 4.28e-06\n",
      "Epoch  20 [9850/10697 ( 92.1%)] Loss: 0.025499 L1: 0.015333 Grad: 0.101453 Thermal: 0.000414 LR: 4.28e-06\n",
      "Epoch  20 [9850/10697 ( 92.1%)] Loss: 0.025499 L1: 0.015333 Grad: 0.101453 Thermal: 0.000414 LR: 4.28e-06\n",
      "Epoch  20 [9900/10697 ( 92.5%)] Loss: 0.025818 L1: 0.015127 Grad: 0.106683 Thermal: 0.000454 LR: 4.28e-06\n",
      "Epoch  20 [9900/10697 ( 92.5%)] Loss: 0.025818 L1: 0.015127 Grad: 0.106683 Thermal: 0.000454 LR: 4.28e-06\n",
      "Epoch  20 [9950/10697 ( 93.0%)] Loss: 0.027216 L1: 0.015320 Grad: 0.118732 Thermal: 0.000450 LR: 4.28e-06\n",
      "Epoch  20 [9950/10697 ( 93.0%)] Loss: 0.027216 L1: 0.015320 Grad: 0.118732 Thermal: 0.000450 LR: 4.28e-06\n",
      "Epoch  20 [10000/10697 ( 93.5%)] Loss: 0.023119 L1: 0.013673 Grad: 0.094267 Thermal: 0.000385 LR: 4.28e-06\n",
      "Epoch  20 [10000/10697 ( 93.5%)] Loss: 0.023119 L1: 0.013673 Grad: 0.094267 Thermal: 0.000385 LR: 4.28e-06\n",
      "Epoch  20 [10050/10697 ( 94.0%)] Loss: 0.025459 L1: 0.014973 Grad: 0.104658 Thermal: 0.000411 LR: 4.28e-06\n",
      "Epoch  20 [10050/10697 ( 94.0%)] Loss: 0.025459 L1: 0.014973 Grad: 0.104658 Thermal: 0.000411 LR: 4.28e-06\n",
      "Epoch  20 [10100/10697 ( 94.4%)] Loss: 0.027191 L1: 0.016325 Grad: 0.108415 Thermal: 0.000496 LR: 4.28e-06\n",
      "Epoch  20 [10100/10697 ( 94.4%)] Loss: 0.027191 L1: 0.016325 Grad: 0.108415 Thermal: 0.000496 LR: 4.28e-06\n",
      "Epoch  20 [10150/10697 ( 94.9%)] Loss: 0.024865 L1: 0.014516 Grad: 0.103292 Thermal: 0.000388 LR: 4.28e-06\n",
      "Epoch  20 [10150/10697 ( 94.9%)] Loss: 0.024865 L1: 0.014516 Grad: 0.103292 Thermal: 0.000388 LR: 4.28e-06\n",
      "Epoch  20 [10200/10697 ( 95.4%)] Loss: 0.028471 L1: 0.016855 Grad: 0.115910 Thermal: 0.000485 LR: 4.28e-06\n",
      "Epoch  20 [10200/10697 ( 95.4%)] Loss: 0.028471 L1: 0.016855 Grad: 0.115910 Thermal: 0.000485 LR: 4.28e-06\n",
      "Epoch  20 [10250/10697 ( 95.8%)] Loss: 0.027533 L1: 0.016487 Grad: 0.110213 Thermal: 0.000490 LR: 4.28e-06\n",
      "Epoch  20 [10250/10697 ( 95.8%)] Loss: 0.027533 L1: 0.016487 Grad: 0.110213 Thermal: 0.000490 LR: 4.28e-06\n",
      "Epoch  20 [10300/10697 ( 96.3%)] Loss: 0.029363 L1: 0.016769 Grad: 0.125681 Thermal: 0.000514 LR: 4.28e-06\n",
      "Epoch  20 [10300/10697 ( 96.3%)] Loss: 0.029363 L1: 0.016769 Grad: 0.125681 Thermal: 0.000514 LR: 4.28e-06\n",
      "Epoch  20 [10350/10697 ( 96.8%)] Loss: 0.027544 L1: 0.015968 Grad: 0.115504 Thermal: 0.000516 LR: 4.28e-06\n",
      "Epoch  20 [10350/10697 ( 96.8%)] Loss: 0.027544 L1: 0.015968 Grad: 0.115504 Thermal: 0.000516 LR: 4.28e-06\n",
      "Epoch  20 [10400/10697 ( 97.2%)] Loss: 0.028481 L1: 0.016065 Grad: 0.123909 Thermal: 0.000503 LR: 4.28e-06\n",
      "Epoch  20 [10400/10697 ( 97.2%)] Loss: 0.028481 L1: 0.016065 Grad: 0.123909 Thermal: 0.000503 LR: 4.28e-06\n",
      "Epoch  20 [10450/10697 ( 97.7%)] Loss: 0.027119 L1: 0.016038 Grad: 0.110583 Thermal: 0.000459 LR: 4.28e-06\n",
      "Epoch  20 [10450/10697 ( 97.7%)] Loss: 0.027119 L1: 0.016038 Grad: 0.110583 Thermal: 0.000459 LR: 4.28e-06\n",
      "Epoch  20 [10500/10697 ( 98.2%)] Loss: 0.022729 L1: 0.013238 Grad: 0.094748 Thermal: 0.000322 LR: 4.28e-06\n",
      "Epoch  20 [10500/10697 ( 98.2%)] Loss: 0.022729 L1: 0.013238 Grad: 0.094748 Thermal: 0.000322 LR: 4.28e-06\n",
      "Epoch  20 [10550/10697 ( 98.6%)] Loss: 0.024578 L1: 0.013802 Grad: 0.107582 Thermal: 0.000357 LR: 4.28e-06\n",
      "Epoch  20 [10550/10697 ( 98.6%)] Loss: 0.024578 L1: 0.013802 Grad: 0.107582 Thermal: 0.000357 LR: 4.28e-06\n",
      "Epoch  20 [10600/10697 ( 99.1%)] Loss: 0.024120 L1: 0.014414 Grad: 0.096866 Thermal: 0.000393 LR: 4.28e-06\n",
      "Epoch  20 [10600/10697 ( 99.1%)] Loss: 0.024120 L1: 0.014414 Grad: 0.096866 Thermal: 0.000393 LR: 4.28e-06\n",
      "Epoch  20 [10650/10697 ( 99.6%)] Loss: 0.020466 L1: 0.011921 Grad: 0.085284 Thermal: 0.000333 LR: 4.28e-06\n",
      "Epoch  20 [10650/10697 ( 99.6%)] Loss: 0.020466 L1: 0.011921 Grad: 0.085284 Thermal: 0.000333 LR: 4.28e-06\n",
      "üí´ New best model saved! PSNR: 33.92\n",
      "Epoch  20 Summary: Loss=0.026457 (L1:0.0154, Grad:0.1101, Thermal:0.0005) Val_PSNR=33.92dB Best=33.92dB Time=75.0min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "üí´ New best model saved! PSNR: 33.92\n",
      "Epoch  20 Summary: Loss=0.026457 (L1:0.0154, Grad:0.1101, Thermal:0.0005) Val_PSNR=33.92dB Best=33.92dB Time=75.0min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  21 [   0/10697 (  0.0%)] Loss: 0.022902 L1: 0.013582 Grad: 0.093028 Thermal: 0.000362 LR: 4.21e-06\n",
      "Epoch  21 [   0/10697 (  0.0%)] Loss: 0.022902 L1: 0.013582 Grad: 0.093028 Thermal: 0.000362 LR: 4.21e-06\n",
      "Epoch  21 [  50/10697 (  0.5%)] Loss: 0.022524 L1: 0.013179 Grad: 0.093286 Thermal: 0.000346 LR: 4.21e-06\n",
      "Epoch  21 [  50/10697 (  0.5%)] Loss: 0.022524 L1: 0.013179 Grad: 0.093286 Thermal: 0.000346 LR: 4.21e-06\n",
      "Epoch  21 [ 100/10697 (  0.9%)] Loss: 0.032159 L1: 0.018756 Grad: 0.133700 Thermal: 0.000665 LR: 4.21e-06\n",
      "Epoch  21 [ 100/10697 (  0.9%)] Loss: 0.032159 L1: 0.018756 Grad: 0.133700 Thermal: 0.000665 LR: 4.21e-06\n",
      "Epoch  21 [ 150/10697 (  1.4%)] Loss: 0.024904 L1: 0.014777 Grad: 0.101046 Thermal: 0.000437 LR: 4.21e-06\n",
      "Epoch  21 [ 150/10697 (  1.4%)] Loss: 0.024904 L1: 0.014777 Grad: 0.101046 Thermal: 0.000437 LR: 4.21e-06\n",
      "Epoch  21 [ 200/10697 (  1.9%)] Loss: 0.026873 L1: 0.015575 Grad: 0.112762 Thermal: 0.000442 LR: 4.21e-06\n",
      "Epoch  21 [ 200/10697 (  1.9%)] Loss: 0.026873 L1: 0.015575 Grad: 0.112762 Thermal: 0.000442 LR: 4.21e-06\n",
      "Epoch  21 [ 250/10697 (  2.3%)] Loss: 0.025139 L1: 0.014141 Grad: 0.109746 Thermal: 0.000476 LR: 4.21e-06\n",
      "Epoch  21 [ 250/10697 (  2.3%)] Loss: 0.025139 L1: 0.014141 Grad: 0.109746 Thermal: 0.000476 LR: 4.21e-06\n",
      "Epoch  21 [ 300/10697 (  2.8%)] Loss: 0.029098 L1: 0.017169 Grad: 0.119014 Thermal: 0.000555 LR: 4.21e-06\n",
      "Epoch  21 [ 300/10697 (  2.8%)] Loss: 0.029098 L1: 0.017169 Grad: 0.119014 Thermal: 0.000555 LR: 4.21e-06\n",
      "Epoch  21 [ 350/10697 (  3.3%)] Loss: 0.027755 L1: 0.016287 Grad: 0.114451 Thermal: 0.000472 LR: 4.21e-06\n",
      "Epoch  21 [ 350/10697 (  3.3%)] Loss: 0.027755 L1: 0.016287 Grad: 0.114451 Thermal: 0.000472 LR: 4.21e-06\n",
      "Epoch  21 [ 400/10697 (  3.7%)] Loss: 0.022795 L1: 0.012963 Grad: 0.098157 Thermal: 0.000326 LR: 4.21e-06\n",
      "Epoch  21 [ 400/10697 (  3.7%)] Loss: 0.022795 L1: 0.012963 Grad: 0.098157 Thermal: 0.000326 LR: 4.21e-06\n",
      "Epoch  21 [ 450/10697 (  4.2%)] Loss: 0.031962 L1: 0.018603 Grad: 0.133273 Thermal: 0.000627 LR: 4.21e-06\n",
      "Epoch  21 [ 450/10697 (  4.2%)] Loss: 0.031962 L1: 0.018603 Grad: 0.133273 Thermal: 0.000627 LR: 4.21e-06\n",
      "Epoch  21 [ 500/10697 (  4.7%)] Loss: 0.022381 L1: 0.013323 Grad: 0.090403 Thermal: 0.000354 LR: 4.21e-06\n",
      "Epoch  21 [ 500/10697 (  4.7%)] Loss: 0.022381 L1: 0.013323 Grad: 0.090403 Thermal: 0.000354 LR: 4.21e-06\n",
      "Epoch  21 [ 550/10697 (  5.1%)] Loss: 0.022243 L1: 0.013032 Grad: 0.091940 Thermal: 0.000351 LR: 4.21e-06\n",
      "Epoch  21 [ 550/10697 (  5.1%)] Loss: 0.022243 L1: 0.013032 Grad: 0.091940 Thermal: 0.000351 LR: 4.21e-06\n",
      "Epoch  21 [ 600/10697 (  5.6%)] Loss: 0.027094 L1: 0.016117 Grad: 0.109535 Thermal: 0.000470 LR: 4.21e-06\n",
      "Epoch  21 [ 600/10697 (  5.6%)] Loss: 0.027094 L1: 0.016117 Grad: 0.109535 Thermal: 0.000470 LR: 4.21e-06\n",
      "Epoch  21 [ 650/10697 (  6.1%)] Loss: 0.024547 L1: 0.014313 Grad: 0.102136 Thermal: 0.000404 LR: 4.21e-06\n",
      "Epoch  21 [ 650/10697 (  6.1%)] Loss: 0.024547 L1: 0.014313 Grad: 0.102136 Thermal: 0.000404 LR: 4.21e-06\n",
      "Epoch  21 [ 700/10697 (  6.5%)] Loss: 0.038269 L1: 0.021635 Grad: 0.165927 Thermal: 0.000812 LR: 4.21e-06\n",
      "Epoch  21 [ 700/10697 (  6.5%)] Loss: 0.038269 L1: 0.021635 Grad: 0.165927 Thermal: 0.000812 LR: 4.21e-06\n",
      "Epoch  21 [ 750/10697 (  7.0%)] Loss: 0.020533 L1: 0.011887 Grad: 0.086304 Thermal: 0.000313 LR: 4.21e-06\n",
      "Epoch  21 [ 750/10697 (  7.0%)] Loss: 0.020533 L1: 0.011887 Grad: 0.086304 Thermal: 0.000313 LR: 4.21e-06\n",
      "Epoch  21 [ 800/10697 (  7.5%)] Loss: 0.022734 L1: 0.013483 Grad: 0.092330 Thermal: 0.000377 LR: 4.21e-06\n",
      "Epoch  21 [ 800/10697 (  7.5%)] Loss: 0.022734 L1: 0.013483 Grad: 0.092330 Thermal: 0.000377 LR: 4.21e-06\n",
      "Epoch  21 [ 850/10697 (  7.9%)] Loss: 0.027045 L1: 0.015798 Grad: 0.112225 Thermal: 0.000508 LR: 4.21e-06\n",
      "Epoch  21 [ 850/10697 (  7.9%)] Loss: 0.027045 L1: 0.015798 Grad: 0.112225 Thermal: 0.000508 LR: 4.21e-06\n",
      "Epoch  21 [ 900/10697 (  8.4%)] Loss: 0.027350 L1: 0.015901 Grad: 0.114251 Thermal: 0.000474 LR: 4.21e-06\n",
      "Epoch  21 [ 900/10697 (  8.4%)] Loss: 0.027350 L1: 0.015901 Grad: 0.114251 Thermal: 0.000474 LR: 4.21e-06\n",
      "Epoch  21 [ 950/10697 (  8.9%)] Loss: 0.021833 L1: 0.012626 Grad: 0.091918 Thermal: 0.000293 LR: 4.21e-06\n",
      "Epoch  21 [ 950/10697 (  8.9%)] Loss: 0.021833 L1: 0.012626 Grad: 0.091918 Thermal: 0.000293 LR: 4.21e-06\n",
      "Epoch  21 [1000/10697 (  9.3%)] Loss: 0.023920 L1: 0.013924 Grad: 0.099775 Thermal: 0.000372 LR: 4.21e-06\n",
      "Epoch  21 [1000/10697 (  9.3%)] Loss: 0.023920 L1: 0.013924 Grad: 0.099775 Thermal: 0.000372 LR: 4.21e-06\n",
      "Epoch  21 [1050/10697 (  9.8%)] Loss: 0.019196 L1: 0.011080 Grad: 0.081033 Thermal: 0.000258 LR: 4.21e-06\n",
      "Epoch  21 [1050/10697 (  9.8%)] Loss: 0.019196 L1: 0.011080 Grad: 0.081033 Thermal: 0.000258 LR: 4.21e-06\n",
      "Epoch  21 [1100/10697 ( 10.3%)] Loss: 0.026831 L1: 0.015433 Grad: 0.113746 Thermal: 0.000465 LR: 4.21e-06\n",
      "Epoch  21 [1100/10697 ( 10.3%)] Loss: 0.026831 L1: 0.015433 Grad: 0.113746 Thermal: 0.000465 LR: 4.21e-06\n",
      "Epoch  21 [1150/10697 ( 10.8%)] Loss: 0.029892 L1: 0.017797 Grad: 0.120676 Thermal: 0.000550 LR: 4.21e-06\n",
      "Epoch  21 [1150/10697 ( 10.8%)] Loss: 0.029892 L1: 0.017797 Grad: 0.120676 Thermal: 0.000550 LR: 4.21e-06\n",
      "Epoch  21 [1200/10697 ( 11.2%)] Loss: 0.031246 L1: 0.017697 Grad: 0.135202 Thermal: 0.000589 LR: 4.21e-06\n",
      "Epoch  21 [1200/10697 ( 11.2%)] Loss: 0.031246 L1: 0.017697 Grad: 0.135202 Thermal: 0.000589 LR: 4.21e-06\n",
      "Epoch  21 [1250/10697 ( 11.7%)] Loss: 0.021275 L1: 0.012316 Grad: 0.089445 Thermal: 0.000305 LR: 4.21e-06\n",
      "Epoch  21 [1250/10697 ( 11.7%)] Loss: 0.021275 L1: 0.012316 Grad: 0.089445 Thermal: 0.000305 LR: 4.21e-06\n",
      "Epoch  21 [1300/10697 ( 12.2%)] Loss: 0.026729 L1: 0.015873 Grad: 0.108327 Thermal: 0.000449 LR: 4.21e-06\n",
      "Epoch  21 [1300/10697 ( 12.2%)] Loss: 0.026729 L1: 0.015873 Grad: 0.108327 Thermal: 0.000449 LR: 4.21e-06\n",
      "Epoch  21 [1350/10697 ( 12.6%)] Loss: 0.016917 L1: 0.009526 Grad: 0.073812 Thermal: 0.000200 LR: 4.21e-06\n",
      "Epoch  21 [1350/10697 ( 12.6%)] Loss: 0.016917 L1: 0.009526 Grad: 0.073812 Thermal: 0.000200 LR: 4.21e-06\n",
      "Epoch  21 [1400/10697 ( 13.1%)] Loss: 0.028987 L1: 0.017301 Grad: 0.116597 Thermal: 0.000531 LR: 4.21e-06\n",
      "Epoch  21 [1400/10697 ( 13.1%)] Loss: 0.028987 L1: 0.017301 Grad: 0.116597 Thermal: 0.000531 LR: 4.21e-06\n",
      "Epoch  21 [1450/10697 ( 13.6%)] Loss: 0.025460 L1: 0.014884 Grad: 0.105497 Thermal: 0.000530 LR: 4.21e-06\n",
      "Epoch  21 [1450/10697 ( 13.6%)] Loss: 0.025460 L1: 0.014884 Grad: 0.105497 Thermal: 0.000530 LR: 4.21e-06\n",
      "Epoch  21 [1500/10697 ( 14.0%)] Loss: 0.026406 L1: 0.015907 Grad: 0.104771 Thermal: 0.000436 LR: 4.21e-06\n",
      "Epoch  21 [1500/10697 ( 14.0%)] Loss: 0.026406 L1: 0.015907 Grad: 0.104771 Thermal: 0.000436 LR: 4.21e-06\n",
      "Epoch  21 [1550/10697 ( 14.5%)] Loss: 0.034147 L1: 0.019558 Grad: 0.145513 Thermal: 0.000758 LR: 4.21e-06\n",
      "Epoch  21 [1550/10697 ( 14.5%)] Loss: 0.034147 L1: 0.019558 Grad: 0.145513 Thermal: 0.000758 LR: 4.21e-06\n",
      "Epoch  21 [1600/10697 ( 15.0%)] Loss: 0.026791 L1: 0.015538 Grad: 0.112281 Thermal: 0.000482 LR: 4.21e-06\n",
      "Epoch  21 [1600/10697 ( 15.0%)] Loss: 0.026791 L1: 0.015538 Grad: 0.112281 Thermal: 0.000482 LR: 4.21e-06\n",
      "Epoch  21 [1650/10697 ( 15.4%)] Loss: 0.031475 L1: 0.018007 Grad: 0.134353 Thermal: 0.000664 LR: 4.21e-06\n",
      "Epoch  21 [1650/10697 ( 15.4%)] Loss: 0.031475 L1: 0.018007 Grad: 0.134353 Thermal: 0.000664 LR: 4.21e-06\n",
      "Epoch  21 [1700/10697 ( 15.9%)] Loss: 0.031543 L1: 0.017774 Grad: 0.137387 Thermal: 0.000599 LR: 4.21e-06\n",
      "Epoch  21 [1700/10697 ( 15.9%)] Loss: 0.031543 L1: 0.017774 Grad: 0.137387 Thermal: 0.000599 LR: 4.21e-06\n",
      "Epoch  21 [1750/10697 ( 16.4%)] Loss: 0.028955 L1: 0.017376 Grad: 0.115515 Thermal: 0.000547 LR: 4.21e-06\n",
      "Epoch  21 [1750/10697 ( 16.4%)] Loss: 0.028955 L1: 0.017376 Grad: 0.115515 Thermal: 0.000547 LR: 4.21e-06\n",
      "Epoch  21 [1800/10697 ( 16.8%)] Loss: 0.023593 L1: 0.013691 Grad: 0.098833 Thermal: 0.000382 LR: 4.21e-06\n",
      "Epoch  21 [1800/10697 ( 16.8%)] Loss: 0.023593 L1: 0.013691 Grad: 0.098833 Thermal: 0.000382 LR: 4.21e-06\n",
      "Epoch  21 [1850/10697 ( 17.3%)] Loss: 0.027220 L1: 0.016280 Grad: 0.109158 Thermal: 0.000469 LR: 4.21e-06\n",
      "Epoch  21 [1850/10697 ( 17.3%)] Loss: 0.027220 L1: 0.016280 Grad: 0.109158 Thermal: 0.000469 LR: 4.21e-06\n",
      "Epoch  21 [1900/10697 ( 17.8%)] Loss: 0.018220 L1: 0.010123 Grad: 0.080865 Thermal: 0.000217 LR: 4.21e-06\n",
      "Epoch  21 [1900/10697 ( 17.8%)] Loss: 0.018220 L1: 0.010123 Grad: 0.080865 Thermal: 0.000217 LR: 4.21e-06\n",
      "Epoch  21 [1950/10697 ( 18.2%)] Loss: 0.022066 L1: 0.012742 Grad: 0.093071 Thermal: 0.000349 LR: 4.21e-06\n",
      "Epoch  21 [1950/10697 ( 18.2%)] Loss: 0.022066 L1: 0.012742 Grad: 0.093071 Thermal: 0.000349 LR: 4.21e-06\n",
      "Epoch  21 [2000/10697 ( 18.7%)] Loss: 0.022629 L1: 0.013420 Grad: 0.091904 Thermal: 0.000359 LR: 4.21e-06\n",
      "Epoch  21 [2000/10697 ( 18.7%)] Loss: 0.022629 L1: 0.013420 Grad: 0.091904 Thermal: 0.000359 LR: 4.21e-06\n",
      "Epoch  21 [2050/10697 ( 19.2%)] Loss: 0.025438 L1: 0.014615 Grad: 0.108038 Thermal: 0.000372 LR: 4.21e-06\n",
      "Epoch  21 [2050/10697 ( 19.2%)] Loss: 0.025438 L1: 0.014615 Grad: 0.108038 Thermal: 0.000372 LR: 4.21e-06\n",
      "Epoch  21 [2100/10697 ( 19.6%)] Loss: 0.023870 L1: 0.013972 Grad: 0.098801 Thermal: 0.000368 LR: 4.21e-06\n",
      "Epoch  21 [2100/10697 ( 19.6%)] Loss: 0.023870 L1: 0.013972 Grad: 0.098801 Thermal: 0.000368 LR: 4.21e-06\n",
      "Epoch  21 [2150/10697 ( 20.1%)] Loss: 0.030011 L1: 0.017527 Grad: 0.124539 Thermal: 0.000594 LR: 4.21e-06\n",
      "Epoch  21 [2150/10697 ( 20.1%)] Loss: 0.030011 L1: 0.017527 Grad: 0.124539 Thermal: 0.000594 LR: 4.21e-06\n",
      "Epoch  21 [2200/10697 ( 20.6%)] Loss: 0.033332 L1: 0.019220 Grad: 0.140761 Thermal: 0.000720 LR: 4.21e-06\n",
      "Epoch  21 [2200/10697 ( 20.6%)] Loss: 0.033332 L1: 0.019220 Grad: 0.140761 Thermal: 0.000720 LR: 4.21e-06\n",
      "Epoch  21 [2250/10697 ( 21.0%)] Loss: 0.027531 L1: 0.016144 Grad: 0.113630 Thermal: 0.000486 LR: 4.21e-06\n",
      "Epoch  21 [2250/10697 ( 21.0%)] Loss: 0.027531 L1: 0.016144 Grad: 0.113630 Thermal: 0.000486 LR: 4.21e-06\n",
      "Epoch  21 [2300/10697 ( 21.5%)] Loss: 0.021734 L1: 0.012384 Grad: 0.093352 Thermal: 0.000309 LR: 4.21e-06\n",
      "Epoch  21 [2300/10697 ( 21.5%)] Loss: 0.021734 L1: 0.012384 Grad: 0.093352 Thermal: 0.000309 LR: 4.21e-06\n",
      "Epoch  21 [2350/10697 ( 22.0%)] Loss: 0.022823 L1: 0.012867 Grad: 0.099406 Thermal: 0.000314 LR: 4.21e-06\n",
      "Epoch  21 [2350/10697 ( 22.0%)] Loss: 0.022823 L1: 0.012867 Grad: 0.099406 Thermal: 0.000314 LR: 4.21e-06\n",
      "Epoch  21 [2400/10697 ( 22.4%)] Loss: 0.022317 L1: 0.012593 Grad: 0.097094 Thermal: 0.000304 LR: 4.21e-06\n",
      "Epoch  21 [2400/10697 ( 22.4%)] Loss: 0.022317 L1: 0.012593 Grad: 0.097094 Thermal: 0.000304 LR: 4.21e-06\n",
      "Epoch  21 [2450/10697 ( 22.9%)] Loss: 0.023752 L1: 0.013922 Grad: 0.098115 Thermal: 0.000356 LR: 4.21e-06\n",
      "Epoch  21 [2450/10697 ( 22.9%)] Loss: 0.023752 L1: 0.013922 Grad: 0.098115 Thermal: 0.000356 LR: 4.21e-06\n",
      "Epoch  21 [2500/10697 ( 23.4%)] Loss: 0.026396 L1: 0.015525 Grad: 0.108481 Thermal: 0.000466 LR: 4.21e-06\n",
      "Epoch  21 [2500/10697 ( 23.4%)] Loss: 0.026396 L1: 0.015525 Grad: 0.108481 Thermal: 0.000466 LR: 4.21e-06\n",
      "Epoch  21 [2550/10697 ( 23.8%)] Loss: 0.027283 L1: 0.015924 Grad: 0.113344 Thermal: 0.000489 LR: 4.21e-06\n",
      "Epoch  21 [2550/10697 ( 23.8%)] Loss: 0.027283 L1: 0.015924 Grad: 0.113344 Thermal: 0.000489 LR: 4.21e-06\n",
      "Epoch  21 [2600/10697 ( 24.3%)] Loss: 0.027213 L1: 0.015604 Grad: 0.115835 Thermal: 0.000519 LR: 4.21e-06\n",
      "Epoch  21 [2600/10697 ( 24.3%)] Loss: 0.027213 L1: 0.015604 Grad: 0.115835 Thermal: 0.000519 LR: 4.21e-06\n",
      "Epoch  21 [2650/10697 ( 24.8%)] Loss: 0.026262 L1: 0.015149 Grad: 0.110919 Thermal: 0.000424 LR: 4.21e-06\n",
      "Epoch  21 [2650/10697 ( 24.8%)] Loss: 0.026262 L1: 0.015149 Grad: 0.110919 Thermal: 0.000424 LR: 4.21e-06\n",
      "Epoch  21 [2700/10697 ( 25.2%)] Loss: 0.026535 L1: 0.015736 Grad: 0.107768 Thermal: 0.000442 LR: 4.21e-06\n",
      "Epoch  21 [2700/10697 ( 25.2%)] Loss: 0.026535 L1: 0.015736 Grad: 0.107768 Thermal: 0.000442 LR: 4.21e-06\n",
      "Epoch  21 [2750/10697 ( 25.7%)] Loss: 0.023772 L1: 0.013765 Grad: 0.099890 Thermal: 0.000365 LR: 4.21e-06\n",
      "Epoch  21 [2750/10697 ( 25.7%)] Loss: 0.023772 L1: 0.013765 Grad: 0.099890 Thermal: 0.000365 LR: 4.21e-06\n",
      "Epoch  21 [2800/10697 ( 26.2%)] Loss: 0.028396 L1: 0.016516 Grad: 0.118548 Thermal: 0.000492 LR: 4.21e-06\n",
      "Epoch  21 [2800/10697 ( 26.2%)] Loss: 0.028396 L1: 0.016516 Grad: 0.118548 Thermal: 0.000492 LR: 4.21e-06\n",
      "Epoch  21 [2850/10697 ( 26.6%)] Loss: 0.029229 L1: 0.016610 Grad: 0.125947 Thermal: 0.000501 LR: 4.21e-06\n",
      "Epoch  21 [2850/10697 ( 26.6%)] Loss: 0.029229 L1: 0.016610 Grad: 0.125947 Thermal: 0.000501 LR: 4.21e-06\n",
      "Epoch  21 [2900/10697 ( 27.1%)] Loss: 0.021908 L1: 0.012197 Grad: 0.096917 Thermal: 0.000390 LR: 4.21e-06\n",
      "Epoch  21 [2900/10697 ( 27.1%)] Loss: 0.021908 L1: 0.012197 Grad: 0.096917 Thermal: 0.000390 LR: 4.21e-06\n",
      "Epoch  21 [2950/10697 ( 27.6%)] Loss: 0.030548 L1: 0.017893 Grad: 0.126264 Thermal: 0.000582 LR: 4.21e-06\n",
      "Epoch  21 [2950/10697 ( 27.6%)] Loss: 0.030548 L1: 0.017893 Grad: 0.126264 Thermal: 0.000582 LR: 4.21e-06\n",
      "Epoch  21 [3000/10697 ( 28.0%)] Loss: 0.028363 L1: 0.016475 Grad: 0.118612 Thermal: 0.000553 LR: 4.21e-06\n",
      "Epoch  21 [3000/10697 ( 28.0%)] Loss: 0.028363 L1: 0.016475 Grad: 0.118612 Thermal: 0.000553 LR: 4.21e-06\n",
      "Epoch  21 [3050/10697 ( 28.5%)] Loss: 0.023577 L1: 0.013890 Grad: 0.096692 Thermal: 0.000352 LR: 4.21e-06\n",
      "Epoch  21 [3050/10697 ( 28.5%)] Loss: 0.023577 L1: 0.013890 Grad: 0.096692 Thermal: 0.000352 LR: 4.21e-06\n",
      "Epoch  21 [3100/10697 ( 29.0%)] Loss: 0.027577 L1: 0.016205 Grad: 0.113481 Thermal: 0.000483 LR: 4.21e-06\n",
      "Epoch  21 [3100/10697 ( 29.0%)] Loss: 0.027577 L1: 0.016205 Grad: 0.113481 Thermal: 0.000483 LR: 4.21e-06\n",
      "Epoch  21 [3150/10697 ( 29.4%)] Loss: 0.029937 L1: 0.017281 Grad: 0.126288 Thermal: 0.000536 LR: 4.21e-06\n",
      "Epoch  21 [3150/10697 ( 29.4%)] Loss: 0.029937 L1: 0.017281 Grad: 0.126288 Thermal: 0.000536 LR: 4.21e-06\n",
      "Epoch  21 [3200/10697 ( 29.9%)] Loss: 0.028194 L1: 0.016567 Grad: 0.116016 Thermal: 0.000522 LR: 4.21e-06\n",
      "Epoch  21 [3200/10697 ( 29.9%)] Loss: 0.028194 L1: 0.016567 Grad: 0.116016 Thermal: 0.000522 LR: 4.21e-06\n",
      "Epoch  21 [3250/10697 ( 30.4%)] Loss: 0.024450 L1: 0.014184 Grad: 0.102472 Thermal: 0.000372 LR: 4.21e-06\n",
      "Epoch  21 [3250/10697 ( 30.4%)] Loss: 0.024450 L1: 0.014184 Grad: 0.102472 Thermal: 0.000372 LR: 4.21e-06\n",
      "Epoch  21 [3300/10697 ( 30.8%)] Loss: 0.028775 L1: 0.016741 Grad: 0.120095 Thermal: 0.000477 LR: 4.21e-06\n",
      "Epoch  21 [3300/10697 ( 30.8%)] Loss: 0.028775 L1: 0.016741 Grad: 0.120095 Thermal: 0.000477 LR: 4.21e-06\n",
      "Epoch  21 [3350/10697 ( 31.3%)] Loss: 0.022072 L1: 0.012999 Grad: 0.090563 Thermal: 0.000336 LR: 4.21e-06\n",
      "Epoch  21 [3350/10697 ( 31.3%)] Loss: 0.022072 L1: 0.012999 Grad: 0.090563 Thermal: 0.000336 LR: 4.21e-06\n",
      "Epoch  21 [3400/10697 ( 31.8%)] Loss: 0.021999 L1: 0.012170 Grad: 0.098116 Thermal: 0.000338 LR: 4.21e-06\n",
      "Epoch  21 [3400/10697 ( 31.8%)] Loss: 0.021999 L1: 0.012170 Grad: 0.098116 Thermal: 0.000338 LR: 4.21e-06\n",
      "Epoch  21 [3450/10697 ( 32.3%)] Loss: 0.030300 L1: 0.017585 Grad: 0.126855 Thermal: 0.000605 LR: 4.21e-06\n",
      "Epoch  21 [3450/10697 ( 32.3%)] Loss: 0.030300 L1: 0.017585 Grad: 0.126855 Thermal: 0.000605 LR: 4.21e-06\n",
      "Epoch  21 [3500/10697 ( 32.7%)] Loss: 0.025662 L1: 0.014910 Grad: 0.107309 Thermal: 0.000427 LR: 4.21e-06\n",
      "Epoch  21 [3500/10697 ( 32.7%)] Loss: 0.025662 L1: 0.014910 Grad: 0.107309 Thermal: 0.000427 LR: 4.21e-06\n",
      "Epoch  21 [3550/10697 ( 33.2%)] Loss: 0.024397 L1: 0.014442 Grad: 0.099362 Thermal: 0.000380 LR: 4.21e-06\n",
      "Epoch  21 [3550/10697 ( 33.2%)] Loss: 0.024397 L1: 0.014442 Grad: 0.099362 Thermal: 0.000380 LR: 4.21e-06\n",
      "Epoch  21 [3600/10697 ( 33.7%)] Loss: 0.020161 L1: 0.011946 Grad: 0.081995 Thermal: 0.000301 LR: 4.21e-06\n",
      "Epoch  21 [3600/10697 ( 33.7%)] Loss: 0.020161 L1: 0.011946 Grad: 0.081995 Thermal: 0.000301 LR: 4.21e-06\n",
      "Epoch  21 [3650/10697 ( 34.1%)] Loss: 0.028178 L1: 0.016994 Grad: 0.111585 Thermal: 0.000508 LR: 4.21e-06\n",
      "Epoch  21 [3650/10697 ( 34.1%)] Loss: 0.028178 L1: 0.016994 Grad: 0.111585 Thermal: 0.000508 LR: 4.21e-06\n",
      "Epoch  21 [3700/10697 ( 34.6%)] Loss: 0.025995 L1: 0.014999 Grad: 0.109715 Thermal: 0.000478 LR: 4.21e-06\n",
      "Epoch  21 [3700/10697 ( 34.6%)] Loss: 0.025995 L1: 0.014999 Grad: 0.109715 Thermal: 0.000478 LR: 4.21e-06\n",
      "Epoch  21 [3750/10697 ( 35.1%)] Loss: 0.026724 L1: 0.015798 Grad: 0.109020 Thermal: 0.000494 LR: 4.21e-06\n",
      "Epoch  21 [3750/10697 ( 35.1%)] Loss: 0.026724 L1: 0.015798 Grad: 0.109020 Thermal: 0.000494 LR: 4.21e-06\n",
      "Epoch  21 [3800/10697 ( 35.5%)] Loss: 0.025385 L1: 0.014915 Grad: 0.104457 Thermal: 0.000490 LR: 4.21e-06\n",
      "Epoch  21 [3800/10697 ( 35.5%)] Loss: 0.025385 L1: 0.014915 Grad: 0.104457 Thermal: 0.000490 LR: 4.21e-06\n",
      "Epoch  21 [3850/10697 ( 36.0%)] Loss: 0.026865 L1: 0.015492 Grad: 0.113427 Thermal: 0.000604 LR: 4.21e-06\n",
      "Epoch  21 [3850/10697 ( 36.0%)] Loss: 0.026865 L1: 0.015492 Grad: 0.113427 Thermal: 0.000604 LR: 4.21e-06\n",
      "Epoch  21 [3900/10697 ( 36.5%)] Loss: 0.027341 L1: 0.016594 Grad: 0.107217 Thermal: 0.000508 LR: 4.21e-06\n",
      "Epoch  21 [3900/10697 ( 36.5%)] Loss: 0.027341 L1: 0.016594 Grad: 0.107217 Thermal: 0.000508 LR: 4.21e-06\n",
      "Epoch  21 [3950/10697 ( 36.9%)] Loss: 0.031328 L1: 0.018447 Grad: 0.128509 Thermal: 0.000599 LR: 4.21e-06\n",
      "Epoch  21 [3950/10697 ( 36.9%)] Loss: 0.031328 L1: 0.018447 Grad: 0.128509 Thermal: 0.000599 LR: 4.21e-06\n",
      "Epoch  21 [4000/10697 ( 37.4%)] Loss: 0.031683 L1: 0.018500 Grad: 0.131531 Thermal: 0.000610 LR: 4.21e-06\n",
      "Epoch  21 [4000/10697 ( 37.4%)] Loss: 0.031683 L1: 0.018500 Grad: 0.131531 Thermal: 0.000610 LR: 4.21e-06\n",
      "Epoch  21 [4050/10697 ( 37.9%)] Loss: 0.025616 L1: 0.015558 Grad: 0.100354 Thermal: 0.000446 LR: 4.21e-06\n",
      "Epoch  21 [4050/10697 ( 37.9%)] Loss: 0.025616 L1: 0.015558 Grad: 0.100354 Thermal: 0.000446 LR: 4.21e-06\n",
      "Epoch  21 [4100/10697 ( 38.3%)] Loss: 0.025720 L1: 0.015088 Grad: 0.106088 Thermal: 0.000459 LR: 4.21e-06\n",
      "Epoch  21 [4100/10697 ( 38.3%)] Loss: 0.025720 L1: 0.015088 Grad: 0.106088 Thermal: 0.000459 LR: 4.21e-06\n",
      "Epoch  21 [4150/10697 ( 38.8%)] Loss: 0.034740 L1: 0.020190 Grad: 0.145124 Thermal: 0.000766 LR: 4.21e-06\n",
      "Epoch  21 [4150/10697 ( 38.8%)] Loss: 0.034740 L1: 0.020190 Grad: 0.145124 Thermal: 0.000766 LR: 4.21e-06\n",
      "Epoch  21 [4200/10697 ( 39.3%)] Loss: 0.027994 L1: 0.016667 Grad: 0.113025 Thermal: 0.000502 LR: 4.21e-06\n",
      "Epoch  21 [4200/10697 ( 39.3%)] Loss: 0.027994 L1: 0.016667 Grad: 0.113025 Thermal: 0.000502 LR: 4.21e-06\n",
      "Epoch  21 [4250/10697 ( 39.7%)] Loss: 0.033453 L1: 0.018940 Grad: 0.144779 Thermal: 0.000713 LR: 4.21e-06\n",
      "Epoch  21 [4250/10697 ( 39.7%)] Loss: 0.033453 L1: 0.018940 Grad: 0.144779 Thermal: 0.000713 LR: 4.21e-06\n",
      "Epoch  21 [4300/10697 ( 40.2%)] Loss: 0.026987 L1: 0.015850 Grad: 0.111142 Thermal: 0.000454 LR: 4.21e-06\n",
      "Epoch  21 [4300/10697 ( 40.2%)] Loss: 0.026987 L1: 0.015850 Grad: 0.111142 Thermal: 0.000454 LR: 4.21e-06\n",
      "Epoch  21 [4350/10697 ( 40.7%)] Loss: 0.023647 L1: 0.013435 Grad: 0.101940 Thermal: 0.000342 LR: 4.21e-06\n",
      "Epoch  21 [4350/10697 ( 40.7%)] Loss: 0.023647 L1: 0.013435 Grad: 0.101940 Thermal: 0.000342 LR: 4.21e-06\n",
      "Epoch  21 [4400/10697 ( 41.1%)] Loss: 0.030576 L1: 0.018184 Grad: 0.123630 Thermal: 0.000591 LR: 4.21e-06\n",
      "Epoch  21 [4400/10697 ( 41.1%)] Loss: 0.030576 L1: 0.018184 Grad: 0.123630 Thermal: 0.000591 LR: 4.21e-06\n",
      "Epoch  21 [4450/10697 ( 41.6%)] Loss: 0.019800 L1: 0.011701 Grad: 0.080841 Thermal: 0.000304 LR: 4.21e-06\n",
      "Epoch  21 [4450/10697 ( 41.6%)] Loss: 0.019800 L1: 0.011701 Grad: 0.080841 Thermal: 0.000304 LR: 4.21e-06\n",
      "Epoch  21 [4500/10697 ( 42.1%)] Loss: 0.028764 L1: 0.016811 Grad: 0.119245 Thermal: 0.000562 LR: 4.21e-06\n",
      "Epoch  21 [4500/10697 ( 42.1%)] Loss: 0.028764 L1: 0.016811 Grad: 0.119245 Thermal: 0.000562 LR: 4.21e-06\n",
      "Epoch  21 [4550/10697 ( 42.5%)] Loss: 0.031281 L1: 0.018318 Grad: 0.129317 Thermal: 0.000630 LR: 4.21e-06\n",
      "Epoch  21 [4550/10697 ( 42.5%)] Loss: 0.031281 L1: 0.018318 Grad: 0.129317 Thermal: 0.000630 LR: 4.21e-06\n",
      "Epoch  21 [4600/10697 ( 43.0%)] Loss: 0.026861 L1: 0.016179 Grad: 0.106594 Thermal: 0.000450 LR: 4.21e-06\n",
      "Epoch  21 [4600/10697 ( 43.0%)] Loss: 0.026861 L1: 0.016179 Grad: 0.106594 Thermal: 0.000450 LR: 4.21e-06\n",
      "Epoch  21 [4650/10697 ( 43.5%)] Loss: 0.029661 L1: 0.017158 Grad: 0.124756 Thermal: 0.000551 LR: 4.21e-06\n",
      "Epoch  21 [4650/10697 ( 43.5%)] Loss: 0.029661 L1: 0.017158 Grad: 0.124756 Thermal: 0.000551 LR: 4.21e-06\n",
      "Epoch  21 [4700/10697 ( 43.9%)] Loss: 0.030057 L1: 0.017184 Grad: 0.128460 Thermal: 0.000530 LR: 4.21e-06\n",
      "Epoch  21 [4700/10697 ( 43.9%)] Loss: 0.030057 L1: 0.017184 Grad: 0.128460 Thermal: 0.000530 LR: 4.21e-06\n",
      "Epoch  21 [4750/10697 ( 44.4%)] Loss: 0.024819 L1: 0.014329 Grad: 0.104709 Thermal: 0.000386 LR: 4.21e-06\n",
      "Epoch  21 [4750/10697 ( 44.4%)] Loss: 0.024819 L1: 0.014329 Grad: 0.104709 Thermal: 0.000386 LR: 4.21e-06\n",
      "Epoch  21 [4800/10697 ( 44.9%)] Loss: 0.030592 L1: 0.017850 Grad: 0.127149 Thermal: 0.000545 LR: 4.21e-06\n",
      "Epoch  21 [4800/10697 ( 44.9%)] Loss: 0.030592 L1: 0.017850 Grad: 0.127149 Thermal: 0.000545 LR: 4.21e-06\n",
      "Epoch  21 [4850/10697 ( 45.3%)] Loss: 0.029531 L1: 0.017094 Grad: 0.124107 Thermal: 0.000523 LR: 4.21e-06\n",
      "Epoch  21 [4850/10697 ( 45.3%)] Loss: 0.029531 L1: 0.017094 Grad: 0.124107 Thermal: 0.000523 LR: 4.21e-06\n",
      "Epoch  21 [4900/10697 ( 45.8%)] Loss: 0.026341 L1: 0.015335 Grad: 0.109847 Thermal: 0.000439 LR: 4.21e-06\n",
      "Epoch  21 [4900/10697 ( 45.8%)] Loss: 0.026341 L1: 0.015335 Grad: 0.109847 Thermal: 0.000439 LR: 4.21e-06\n",
      "Epoch  21 [4950/10697 ( 46.3%)] Loss: 0.025590 L1: 0.015109 Grad: 0.104603 Thermal: 0.000413 LR: 4.21e-06\n",
      "Epoch  21 [4950/10697 ( 46.3%)] Loss: 0.025590 L1: 0.015109 Grad: 0.104603 Thermal: 0.000413 LR: 4.21e-06\n",
      "Epoch  21 [5000/10697 ( 46.7%)] Loss: 0.022772 L1: 0.013190 Grad: 0.095638 Thermal: 0.000364 LR: 4.21e-06\n",
      "Epoch  21 [5000/10697 ( 46.7%)] Loss: 0.022772 L1: 0.013190 Grad: 0.095638 Thermal: 0.000364 LR: 4.21e-06\n",
      "Epoch  21 [5050/10697 ( 47.2%)] Loss: 0.025672 L1: 0.014701 Grad: 0.109498 Thermal: 0.000409 LR: 4.21e-06\n",
      "Epoch  21 [5050/10697 ( 47.2%)] Loss: 0.025672 L1: 0.014701 Grad: 0.109498 Thermal: 0.000409 LR: 4.21e-06\n",
      "Epoch  21 [5100/10697 ( 47.7%)] Loss: 0.023353 L1: 0.013164 Grad: 0.101690 Thermal: 0.000401 LR: 4.21e-06\n",
      "Epoch  21 [5100/10697 ( 47.7%)] Loss: 0.023353 L1: 0.013164 Grad: 0.101690 Thermal: 0.000401 LR: 4.21e-06\n",
      "Epoch  21 [5150/10697 ( 48.1%)] Loss: 0.030600 L1: 0.017773 Grad: 0.127996 Thermal: 0.000555 LR: 4.21e-06\n",
      "Epoch  21 [5150/10697 ( 48.1%)] Loss: 0.030600 L1: 0.017773 Grad: 0.127996 Thermal: 0.000555 LR: 4.21e-06\n",
      "Epoch  21 [5200/10697 ( 48.6%)] Loss: 0.022644 L1: 0.013366 Grad: 0.092606 Thermal: 0.000343 LR: 4.21e-06\n",
      "Epoch  21 [5200/10697 ( 48.6%)] Loss: 0.022644 L1: 0.013366 Grad: 0.092606 Thermal: 0.000343 LR: 4.21e-06\n",
      "Epoch  21 [5250/10697 ( 49.1%)] Loss: 0.024804 L1: 0.014312 Grad: 0.104700 Thermal: 0.000425 LR: 4.21e-06\n",
      "Epoch  21 [5250/10697 ( 49.1%)] Loss: 0.024804 L1: 0.014312 Grad: 0.104700 Thermal: 0.000425 LR: 4.21e-06\n",
      "Epoch  21 [5300/10697 ( 49.5%)] Loss: 0.021901 L1: 0.012903 Grad: 0.089802 Thermal: 0.000339 LR: 4.21e-06\n",
      "Epoch  21 [5300/10697 ( 49.5%)] Loss: 0.021901 L1: 0.012903 Grad: 0.089802 Thermal: 0.000339 LR: 4.21e-06\n",
      "Epoch  21 [5350/10697 ( 50.0%)] Loss: 0.025504 L1: 0.015432 Grad: 0.100498 Thermal: 0.000447 LR: 4.21e-06\n",
      "Epoch  21 [5350/10697 ( 50.0%)] Loss: 0.025504 L1: 0.015432 Grad: 0.100498 Thermal: 0.000447 LR: 4.21e-06\n",
      "Epoch  21 [5400/10697 ( 50.5%)] Loss: 0.023839 L1: 0.014040 Grad: 0.097808 Thermal: 0.000364 LR: 4.21e-06\n",
      "Epoch  21 [5400/10697 ( 50.5%)] Loss: 0.023839 L1: 0.014040 Grad: 0.097808 Thermal: 0.000364 LR: 4.21e-06\n",
      "Epoch  21 [5450/10697 ( 50.9%)] Loss: 0.024962 L1: 0.014239 Grad: 0.107029 Thermal: 0.000412 LR: 4.21e-06\n",
      "Epoch  21 [5450/10697 ( 50.9%)] Loss: 0.024962 L1: 0.014239 Grad: 0.107029 Thermal: 0.000412 LR: 4.21e-06\n",
      "Epoch  21 [5500/10697 ( 51.4%)] Loss: 0.029019 L1: 0.016241 Grad: 0.127531 Thermal: 0.000497 LR: 4.21e-06\n",
      "Epoch  21 [5500/10697 ( 51.4%)] Loss: 0.029019 L1: 0.016241 Grad: 0.127531 Thermal: 0.000497 LR: 4.21e-06\n",
      "Epoch  21 [5550/10697 ( 51.9%)] Loss: 0.025494 L1: 0.014947 Grad: 0.105275 Thermal: 0.000399 LR: 4.21e-06\n",
      "Epoch  21 [5550/10697 ( 51.9%)] Loss: 0.025494 L1: 0.014947 Grad: 0.105275 Thermal: 0.000399 LR: 4.21e-06\n",
      "Epoch  21 [5600/10697 ( 52.4%)] Loss: 0.027420 L1: 0.016021 Grad: 0.113742 Thermal: 0.000496 LR: 4.21e-06\n",
      "Epoch  21 [5600/10697 ( 52.4%)] Loss: 0.027420 L1: 0.016021 Grad: 0.113742 Thermal: 0.000496 LR: 4.21e-06\n",
      "Epoch  21 [5650/10697 ( 52.8%)] Loss: 0.023707 L1: 0.013392 Grad: 0.102963 Thermal: 0.000375 LR: 4.21e-06\n",
      "Epoch  21 [5650/10697 ( 52.8%)] Loss: 0.023707 L1: 0.013392 Grad: 0.102963 Thermal: 0.000375 LR: 4.21e-06\n",
      "Epoch  21 [5700/10697 ( 53.3%)] Loss: 0.025852 L1: 0.015011 Grad: 0.108187 Thermal: 0.000443 LR: 4.21e-06\n",
      "Epoch  21 [5700/10697 ( 53.3%)] Loss: 0.025852 L1: 0.015011 Grad: 0.108187 Thermal: 0.000443 LR: 4.21e-06\n",
      "Epoch  21 [5750/10697 ( 53.8%)] Loss: 0.029437 L1: 0.016841 Grad: 0.125679 Thermal: 0.000561 LR: 4.21e-06\n",
      "Epoch  21 [5750/10697 ( 53.8%)] Loss: 0.029437 L1: 0.016841 Grad: 0.125679 Thermal: 0.000561 LR: 4.21e-06\n",
      "Epoch  21 [5800/10697 ( 54.2%)] Loss: 0.025744 L1: 0.015143 Grad: 0.105795 Thermal: 0.000440 LR: 4.21e-06\n",
      "Epoch  21 [5800/10697 ( 54.2%)] Loss: 0.025744 L1: 0.015143 Grad: 0.105795 Thermal: 0.000440 LR: 4.21e-06\n",
      "Epoch  21 [5850/10697 ( 54.7%)] Loss: 0.024343 L1: 0.014508 Grad: 0.098145 Thermal: 0.000415 LR: 4.21e-06\n",
      "Epoch  21 [5850/10697 ( 54.7%)] Loss: 0.024343 L1: 0.014508 Grad: 0.098145 Thermal: 0.000415 LR: 4.21e-06\n",
      "Epoch  21 [5900/10697 ( 55.2%)] Loss: 0.029424 L1: 0.017178 Grad: 0.122186 Thermal: 0.000549 LR: 4.21e-06\n",
      "Epoch  21 [5900/10697 ( 55.2%)] Loss: 0.029424 L1: 0.017178 Grad: 0.122186 Thermal: 0.000549 LR: 4.21e-06\n",
      "Epoch  21 [5950/10697 ( 55.6%)] Loss: 0.024737 L1: 0.014433 Grad: 0.102825 Thermal: 0.000447 LR: 4.21e-06\n",
      "Epoch  21 [5950/10697 ( 55.6%)] Loss: 0.024737 L1: 0.014433 Grad: 0.102825 Thermal: 0.000447 LR: 4.21e-06\n",
      "Epoch  21 [6000/10697 ( 56.1%)] Loss: 0.021976 L1: 0.012808 Grad: 0.091517 Thermal: 0.000328 LR: 4.21e-06\n",
      "Epoch  21 [6000/10697 ( 56.1%)] Loss: 0.021976 L1: 0.012808 Grad: 0.091517 Thermal: 0.000328 LR: 4.21e-06\n",
      "Epoch  21 [6050/10697 ( 56.6%)] Loss: 0.025579 L1: 0.014433 Grad: 0.111253 Thermal: 0.000413 LR: 4.21e-06\n",
      "Epoch  21 [6050/10697 ( 56.6%)] Loss: 0.025579 L1: 0.014433 Grad: 0.111253 Thermal: 0.000413 LR: 4.21e-06\n",
      "Epoch  21 [6100/10697 ( 57.0%)] Loss: 0.037956 L1: 0.021792 Grad: 0.161196 Thermal: 0.000874 LR: 4.21e-06\n",
      "Epoch  21 [6100/10697 ( 57.0%)] Loss: 0.037956 L1: 0.021792 Grad: 0.161196 Thermal: 0.000874 LR: 4.21e-06\n",
      "Epoch  21 [6150/10697 ( 57.5%)] Loss: 0.026428 L1: 0.015244 Grad: 0.111598 Thermal: 0.000474 LR: 4.21e-06\n",
      "Epoch  21 [6150/10697 ( 57.5%)] Loss: 0.026428 L1: 0.015244 Grad: 0.111598 Thermal: 0.000474 LR: 4.21e-06\n",
      "Epoch  21 [6200/10697 ( 58.0%)] Loss: 0.022509 L1: 0.013116 Grad: 0.093757 Thermal: 0.000334 LR: 4.21e-06\n",
      "Epoch  21 [6200/10697 ( 58.0%)] Loss: 0.022509 L1: 0.013116 Grad: 0.093757 Thermal: 0.000334 LR: 4.21e-06\n",
      "Epoch  21 [6250/10697 ( 58.4%)] Loss: 0.029258 L1: 0.017177 Grad: 0.120517 Thermal: 0.000576 LR: 4.21e-06\n",
      "Epoch  21 [6250/10697 ( 58.4%)] Loss: 0.029258 L1: 0.017177 Grad: 0.120517 Thermal: 0.000576 LR: 4.21e-06\n",
      "Epoch  21 [6300/10697 ( 58.9%)] Loss: 0.021788 L1: 0.012799 Grad: 0.089739 Thermal: 0.000304 LR: 4.21e-06\n",
      "Epoch  21 [6300/10697 ( 58.9%)] Loss: 0.021788 L1: 0.012799 Grad: 0.089739 Thermal: 0.000304 LR: 4.21e-06\n",
      "Epoch  21 [6350/10697 ( 59.4%)] Loss: 0.026126 L1: 0.015353 Grad: 0.107487 Thermal: 0.000484 LR: 4.21e-06\n",
      "Epoch  21 [6350/10697 ( 59.4%)] Loss: 0.026126 L1: 0.015353 Grad: 0.107487 Thermal: 0.000484 LR: 4.21e-06\n",
      "Epoch  21 [6400/10697 ( 59.8%)] Loss: 0.026891 L1: 0.016072 Grad: 0.107961 Thermal: 0.000463 LR: 4.21e-06\n",
      "Epoch  21 [6400/10697 ( 59.8%)] Loss: 0.026891 L1: 0.016072 Grad: 0.107961 Thermal: 0.000463 LR: 4.21e-06\n",
      "Epoch  21 [6450/10697 ( 60.3%)] Loss: 0.029865 L1: 0.016858 Grad: 0.129815 Thermal: 0.000503 LR: 4.21e-06\n",
      "Epoch  21 [6450/10697 ( 60.3%)] Loss: 0.029865 L1: 0.016858 Grad: 0.129815 Thermal: 0.000503 LR: 4.21e-06\n",
      "Epoch  21 [6500/10697 ( 60.8%)] Loss: 0.022152 L1: 0.012797 Grad: 0.093392 Thermal: 0.000314 LR: 4.21e-06\n",
      "Epoch  21 [6500/10697 ( 60.8%)] Loss: 0.022152 L1: 0.012797 Grad: 0.093392 Thermal: 0.000314 LR: 4.21e-06\n",
      "Epoch  21 [6550/10697 ( 61.2%)] Loss: 0.025992 L1: 0.015028 Grad: 0.109445 Thermal: 0.000387 LR: 4.21e-06\n",
      "Epoch  21 [6550/10697 ( 61.2%)] Loss: 0.025992 L1: 0.015028 Grad: 0.109445 Thermal: 0.000387 LR: 4.21e-06\n",
      "Epoch  21 [6600/10697 ( 61.7%)] Loss: 0.030111 L1: 0.018187 Grad: 0.118892 Thermal: 0.000699 LR: 4.21e-06\n",
      "Epoch  21 [6600/10697 ( 61.7%)] Loss: 0.030111 L1: 0.018187 Grad: 0.118892 Thermal: 0.000699 LR: 4.21e-06\n",
      "Epoch  21 [6650/10697 ( 62.2%)] Loss: 0.023411 L1: 0.013991 Grad: 0.094008 Thermal: 0.000370 LR: 4.21e-06\n",
      "Epoch  21 [6650/10697 ( 62.2%)] Loss: 0.023411 L1: 0.013991 Grad: 0.094008 Thermal: 0.000370 LR: 4.21e-06\n",
      "Epoch  21 [6700/10697 ( 62.6%)] Loss: 0.028733 L1: 0.016865 Grad: 0.118424 Thermal: 0.000518 LR: 4.21e-06\n",
      "Epoch  21 [6700/10697 ( 62.6%)] Loss: 0.028733 L1: 0.016865 Grad: 0.118424 Thermal: 0.000518 LR: 4.21e-06\n",
      "Epoch  21 [6750/10697 ( 63.1%)] Loss: 0.026322 L1: 0.015399 Grad: 0.109002 Thermal: 0.000466 LR: 4.21e-06\n",
      "Epoch  21 [6750/10697 ( 63.1%)] Loss: 0.026322 L1: 0.015399 Grad: 0.109002 Thermal: 0.000466 LR: 4.21e-06\n",
      "Epoch  21 [6800/10697 ( 63.6%)] Loss: 0.025731 L1: 0.015182 Grad: 0.105282 Thermal: 0.000425 LR: 4.21e-06\n",
      "Epoch  21 [6800/10697 ( 63.6%)] Loss: 0.025731 L1: 0.015182 Grad: 0.105282 Thermal: 0.000425 LR: 4.21e-06\n",
      "Epoch  21 [6850/10697 ( 64.0%)] Loss: 0.017591 L1: 0.009878 Grad: 0.077017 Thermal: 0.000225 LR: 4.21e-06\n",
      "Epoch  21 [6850/10697 ( 64.0%)] Loss: 0.017591 L1: 0.009878 Grad: 0.077017 Thermal: 0.000225 LR: 4.21e-06\n",
      "Epoch  21 [6900/10697 ( 64.5%)] Loss: 0.029942 L1: 0.017299 Grad: 0.126164 Thermal: 0.000540 LR: 4.21e-06\n",
      "Epoch  21 [6900/10697 ( 64.5%)] Loss: 0.029942 L1: 0.017299 Grad: 0.126164 Thermal: 0.000540 LR: 4.21e-06\n",
      "Epoch  21 [6950/10697 ( 65.0%)] Loss: 0.026495 L1: 0.015161 Grad: 0.113108 Thermal: 0.000474 LR: 4.21e-06\n",
      "Epoch  21 [6950/10697 ( 65.0%)] Loss: 0.026495 L1: 0.015161 Grad: 0.113108 Thermal: 0.000474 LR: 4.21e-06\n",
      "Epoch  21 [7000/10697 ( 65.4%)] Loss: 0.025388 L1: 0.015030 Grad: 0.103380 Thermal: 0.000394 LR: 4.21e-06\n",
      "Epoch  21 [7000/10697 ( 65.4%)] Loss: 0.025388 L1: 0.015030 Grad: 0.103380 Thermal: 0.000394 LR: 4.21e-06\n",
      "Epoch  21 [7050/10697 ( 65.9%)] Loss: 0.018976 L1: 0.011014 Grad: 0.079485 Thermal: 0.000274 LR: 4.21e-06\n",
      "Epoch  21 [7050/10697 ( 65.9%)] Loss: 0.018976 L1: 0.011014 Grad: 0.079485 Thermal: 0.000274 LR: 4.21e-06\n",
      "Epoch  21 [7100/10697 ( 66.4%)] Loss: 0.025269 L1: 0.014304 Grad: 0.109426 Thermal: 0.000448 LR: 4.21e-06\n",
      "Epoch  21 [7100/10697 ( 66.4%)] Loss: 0.025269 L1: 0.014304 Grad: 0.109426 Thermal: 0.000448 LR: 4.21e-06\n",
      "Epoch  21 [7150/10697 ( 66.8%)] Loss: 0.024310 L1: 0.014145 Grad: 0.101443 Thermal: 0.000419 LR: 4.21e-06\n",
      "Epoch  21 [7150/10697 ( 66.8%)] Loss: 0.024310 L1: 0.014145 Grad: 0.101443 Thermal: 0.000419 LR: 4.21e-06\n",
      "Epoch  21 [7200/10697 ( 67.3%)] Loss: 0.025858 L1: 0.014884 Grad: 0.109525 Thermal: 0.000432 LR: 4.21e-06\n",
      "Epoch  21 [7200/10697 ( 67.3%)] Loss: 0.025858 L1: 0.014884 Grad: 0.109525 Thermal: 0.000432 LR: 4.21e-06\n",
      "Epoch  21 [7250/10697 ( 67.8%)] Loss: 0.026755 L1: 0.015834 Grad: 0.108987 Thermal: 0.000436 LR: 4.21e-06\n",
      "Epoch  21 [7250/10697 ( 67.8%)] Loss: 0.026755 L1: 0.015834 Grad: 0.108987 Thermal: 0.000436 LR: 4.21e-06\n",
      "Epoch  21 [7300/10697 ( 68.2%)] Loss: 0.025246 L1: 0.014923 Grad: 0.103016 Thermal: 0.000416 LR: 4.21e-06\n",
      "Epoch  21 [7300/10697 ( 68.2%)] Loss: 0.025246 L1: 0.014923 Grad: 0.103016 Thermal: 0.000416 LR: 4.21e-06\n",
      "Epoch  21 [7350/10697 ( 68.7%)] Loss: 0.029195 L1: 0.017126 Grad: 0.120389 Thermal: 0.000591 LR: 4.21e-06\n",
      "Epoch  21 [7350/10697 ( 68.7%)] Loss: 0.029195 L1: 0.017126 Grad: 0.120389 Thermal: 0.000591 LR: 4.21e-06\n",
      "Epoch  21 [7400/10697 ( 69.2%)] Loss: 0.020937 L1: 0.012183 Grad: 0.087383 Thermal: 0.000316 LR: 4.21e-06\n",
      "Epoch  21 [7400/10697 ( 69.2%)] Loss: 0.020937 L1: 0.012183 Grad: 0.087383 Thermal: 0.000316 LR: 4.21e-06\n",
      "Epoch  21 [7450/10697 ( 69.6%)] Loss: 0.022544 L1: 0.013168 Grad: 0.093592 Thermal: 0.000338 LR: 4.21e-06\n",
      "Epoch  21 [7450/10697 ( 69.6%)] Loss: 0.022544 L1: 0.013168 Grad: 0.093592 Thermal: 0.000338 LR: 4.21e-06\n",
      "Epoch  21 [7500/10697 ( 70.1%)] Loss: 0.026089 L1: 0.015344 Grad: 0.107241 Thermal: 0.000424 LR: 4.21e-06\n",
      "Epoch  21 [7500/10697 ( 70.1%)] Loss: 0.026089 L1: 0.015344 Grad: 0.107241 Thermal: 0.000424 LR: 4.21e-06\n",
      "Epoch  21 [7550/10697 ( 70.6%)] Loss: 0.019847 L1: 0.011508 Grad: 0.083240 Thermal: 0.000290 LR: 4.21e-06\n",
      "Epoch  21 [7550/10697 ( 70.6%)] Loss: 0.019847 L1: 0.011508 Grad: 0.083240 Thermal: 0.000290 LR: 4.21e-06\n",
      "Epoch  21 [7600/10697 ( 71.0%)] Loss: 0.023918 L1: 0.014113 Grad: 0.097870 Thermal: 0.000377 LR: 4.21e-06\n",
      "Epoch  21 [7600/10697 ( 71.0%)] Loss: 0.023918 L1: 0.014113 Grad: 0.097870 Thermal: 0.000377 LR: 4.21e-06\n",
      "Epoch  21 [7650/10697 ( 71.5%)] Loss: 0.022253 L1: 0.012789 Grad: 0.094483 Thermal: 0.000319 LR: 4.21e-06\n",
      "Epoch  21 [7650/10697 ( 71.5%)] Loss: 0.022253 L1: 0.012789 Grad: 0.094483 Thermal: 0.000319 LR: 4.21e-06\n",
      "Epoch  21 [7700/10697 ( 72.0%)] Loss: 0.024160 L1: 0.014170 Grad: 0.099704 Thermal: 0.000377 LR: 4.21e-06\n",
      "Epoch  21 [7700/10697 ( 72.0%)] Loss: 0.024160 L1: 0.014170 Grad: 0.099704 Thermal: 0.000377 LR: 4.21e-06\n",
      "Epoch  21 [7750/10697 ( 72.5%)] Loss: 0.023687 L1: 0.013411 Grad: 0.102573 Thermal: 0.000372 LR: 4.21e-06\n",
      "Epoch  21 [7750/10697 ( 72.5%)] Loss: 0.023687 L1: 0.013411 Grad: 0.102573 Thermal: 0.000372 LR: 4.21e-06\n",
      "Epoch  21 [7800/10697 ( 72.9%)] Loss: 0.017514 L1: 0.010054 Grad: 0.074488 Thermal: 0.000222 LR: 4.21e-06\n",
      "Epoch  21 [7800/10697 ( 72.9%)] Loss: 0.017514 L1: 0.010054 Grad: 0.074488 Thermal: 0.000222 LR: 4.21e-06\n",
      "Epoch  21 [7850/10697 ( 73.4%)] Loss: 0.022810 L1: 0.013284 Grad: 0.095075 Thermal: 0.000374 LR: 4.21e-06\n",
      "Epoch  21 [7850/10697 ( 73.4%)] Loss: 0.022810 L1: 0.013284 Grad: 0.095075 Thermal: 0.000374 LR: 4.21e-06\n",
      "Epoch  21 [7900/10697 ( 73.9%)] Loss: 0.031758 L1: 0.018619 Grad: 0.131071 Thermal: 0.000649 LR: 4.21e-06\n",
      "Epoch  21 [7900/10697 ( 73.9%)] Loss: 0.031758 L1: 0.018619 Grad: 0.131071 Thermal: 0.000649 LR: 4.21e-06\n",
      "Epoch  21 [7950/10697 ( 74.3%)] Loss: 0.021268 L1: 0.012669 Grad: 0.085822 Thermal: 0.000334 LR: 4.21e-06\n",
      "Epoch  21 [7950/10697 ( 74.3%)] Loss: 0.021268 L1: 0.012669 Grad: 0.085822 Thermal: 0.000334 LR: 4.21e-06\n",
      "Epoch  21 [8000/10697 ( 74.8%)] Loss: 0.023452 L1: 0.013790 Grad: 0.096444 Thermal: 0.000353 LR: 4.21e-06\n",
      "Epoch  21 [8000/10697 ( 74.8%)] Loss: 0.023452 L1: 0.013790 Grad: 0.096444 Thermal: 0.000353 LR: 4.21e-06\n",
      "Epoch  21 [8050/10697 ( 75.3%)] Loss: 0.027591 L1: 0.015834 Grad: 0.117328 Thermal: 0.000487 LR: 4.21e-06\n",
      "Epoch  21 [8050/10697 ( 75.3%)] Loss: 0.027591 L1: 0.015834 Grad: 0.117328 Thermal: 0.000487 LR: 4.21e-06\n",
      "Epoch  21 [8100/10697 ( 75.7%)] Loss: 0.027588 L1: 0.015909 Grad: 0.116541 Thermal: 0.000495 LR: 4.21e-06\n",
      "Epoch  21 [8100/10697 ( 75.7%)] Loss: 0.027588 L1: 0.015909 Grad: 0.116541 Thermal: 0.000495 LR: 4.21e-06\n",
      "Epoch  21 [8150/10697 ( 76.2%)] Loss: 0.023782 L1: 0.013797 Grad: 0.099643 Thermal: 0.000403 LR: 4.21e-06\n",
      "Epoch  21 [8150/10697 ( 76.2%)] Loss: 0.023782 L1: 0.013797 Grad: 0.099643 Thermal: 0.000403 LR: 4.21e-06\n",
      "Epoch  21 [8200/10697 ( 76.7%)] Loss: 0.025177 L1: 0.014950 Grad: 0.102067 Thermal: 0.000416 LR: 4.21e-06\n",
      "Epoch  21 [8200/10697 ( 76.7%)] Loss: 0.025177 L1: 0.014950 Grad: 0.102067 Thermal: 0.000416 LR: 4.21e-06\n",
      "Epoch  21 [8250/10697 ( 77.1%)] Loss: 0.026774 L1: 0.015862 Grad: 0.108893 Thermal: 0.000454 LR: 4.21e-06\n",
      "Epoch  21 [8250/10697 ( 77.1%)] Loss: 0.026774 L1: 0.015862 Grad: 0.108893 Thermal: 0.000454 LR: 4.21e-06\n",
      "Epoch  21 [8300/10697 ( 77.6%)] Loss: 0.034759 L1: 0.020227 Grad: 0.144923 Thermal: 0.000811 LR: 4.21e-06\n",
      "Epoch  21 [8300/10697 ( 77.6%)] Loss: 0.034759 L1: 0.020227 Grad: 0.144923 Thermal: 0.000811 LR: 4.21e-06\n",
      "Epoch  21 [8350/10697 ( 78.1%)] Loss: 0.021768 L1: 0.012548 Grad: 0.092030 Thermal: 0.000327 LR: 4.21e-06\n",
      "Epoch  21 [8350/10697 ( 78.1%)] Loss: 0.021768 L1: 0.012548 Grad: 0.092030 Thermal: 0.000327 LR: 4.21e-06\n",
      "Epoch  21 [8400/10697 ( 78.5%)] Loss: 0.032131 L1: 0.018683 Grad: 0.134177 Thermal: 0.000619 LR: 4.21e-06\n",
      "Epoch  21 [8400/10697 ( 78.5%)] Loss: 0.032131 L1: 0.018683 Grad: 0.134177 Thermal: 0.000619 LR: 4.21e-06\n",
      "Epoch  21 [8450/10697 ( 79.0%)] Loss: 0.019910 L1: 0.011580 Grad: 0.083158 Thermal: 0.000282 LR: 4.21e-06\n",
      "Epoch  21 [8450/10697 ( 79.0%)] Loss: 0.019910 L1: 0.011580 Grad: 0.083158 Thermal: 0.000282 LR: 4.21e-06\n",
      "Epoch  21 [8500/10697 ( 79.5%)] Loss: 0.024925 L1: 0.014462 Grad: 0.104436 Thermal: 0.000395 LR: 4.21e-06\n",
      "Epoch  21 [8500/10697 ( 79.5%)] Loss: 0.024925 L1: 0.014462 Grad: 0.104436 Thermal: 0.000395 LR: 4.21e-06\n",
      "Epoch  21 [8550/10697 ( 79.9%)] Loss: 0.021450 L1: 0.012536 Grad: 0.088964 Thermal: 0.000358 LR: 4.21e-06\n",
      "Epoch  21 [8550/10697 ( 79.9%)] Loss: 0.021450 L1: 0.012536 Grad: 0.088964 Thermal: 0.000358 LR: 4.21e-06\n",
      "Epoch  21 [8600/10697 ( 80.4%)] Loss: 0.023909 L1: 0.013627 Grad: 0.102626 Thermal: 0.000399 LR: 4.21e-06\n",
      "Epoch  21 [8600/10697 ( 80.4%)] Loss: 0.023909 L1: 0.013627 Grad: 0.102626 Thermal: 0.000399 LR: 4.21e-06\n",
      "Epoch  21 [8650/10697 ( 80.9%)] Loss: 0.023846 L1: 0.013722 Grad: 0.101049 Thermal: 0.000383 LR: 4.21e-06\n",
      "Epoch  21 [8650/10697 ( 80.9%)] Loss: 0.023846 L1: 0.013722 Grad: 0.101049 Thermal: 0.000383 LR: 4.21e-06\n",
      "Epoch  21 [8700/10697 ( 81.3%)] Loss: 0.028581 L1: 0.016864 Grad: 0.116922 Thermal: 0.000483 LR: 4.21e-06\n",
      "Epoch  21 [8700/10697 ( 81.3%)] Loss: 0.028581 L1: 0.016864 Grad: 0.116922 Thermal: 0.000483 LR: 4.21e-06\n",
      "Epoch  21 [8750/10697 ( 81.8%)] Loss: 0.023862 L1: 0.014008 Grad: 0.098350 Thermal: 0.000369 LR: 4.21e-06\n",
      "Epoch  21 [8750/10697 ( 81.8%)] Loss: 0.023862 L1: 0.014008 Grad: 0.098350 Thermal: 0.000369 LR: 4.21e-06\n",
      "Epoch  21 [8800/10697 ( 82.3%)] Loss: 0.017827 L1: 0.010436 Grad: 0.073786 Thermal: 0.000258 LR: 4.21e-06\n",
      "Epoch  21 [8800/10697 ( 82.3%)] Loss: 0.017827 L1: 0.010436 Grad: 0.073786 Thermal: 0.000258 LR: 4.21e-06\n",
      "Epoch  21 [8850/10697 ( 82.7%)] Loss: 0.029245 L1: 0.017332 Grad: 0.118861 Thermal: 0.000531 LR: 4.21e-06\n",
      "Epoch  21 [8850/10697 ( 82.7%)] Loss: 0.029245 L1: 0.017332 Grad: 0.118861 Thermal: 0.000531 LR: 4.21e-06\n",
      "Epoch  21 [8900/10697 ( 83.2%)] Loss: 0.019712 L1: 0.011311 Grad: 0.083874 Thermal: 0.000274 LR: 4.21e-06\n",
      "Epoch  21 [8900/10697 ( 83.2%)] Loss: 0.019712 L1: 0.011311 Grad: 0.083874 Thermal: 0.000274 LR: 4.21e-06\n",
      "Epoch  21 [8950/10697 ( 83.7%)] Loss: 0.027182 L1: 0.015954 Grad: 0.112052 Thermal: 0.000464 LR: 4.21e-06\n",
      "Epoch  21 [8950/10697 ( 83.7%)] Loss: 0.027182 L1: 0.015954 Grad: 0.112052 Thermal: 0.000464 LR: 4.21e-06\n",
      "Epoch  21 [9000/10697 ( 84.1%)] Loss: 0.025936 L1: 0.015670 Grad: 0.102439 Thermal: 0.000434 LR: 4.21e-06\n",
      "Epoch  21 [9000/10697 ( 84.1%)] Loss: 0.025936 L1: 0.015670 Grad: 0.102439 Thermal: 0.000434 LR: 4.21e-06\n",
      "Epoch  21 [9050/10697 ( 84.6%)] Loss: 0.022961 L1: 0.013338 Grad: 0.096048 Thermal: 0.000369 LR: 4.21e-06\n",
      "Epoch  21 [9050/10697 ( 84.6%)] Loss: 0.022961 L1: 0.013338 Grad: 0.096048 Thermal: 0.000369 LR: 4.21e-06\n",
      "Epoch  21 [9100/10697 ( 85.1%)] Loss: 0.030883 L1: 0.018165 Grad: 0.126884 Thermal: 0.000585 LR: 4.21e-06\n",
      "Epoch  21 [9100/10697 ( 85.1%)] Loss: 0.030883 L1: 0.018165 Grad: 0.126884 Thermal: 0.000585 LR: 4.21e-06\n",
      "Epoch  21 [9150/10697 ( 85.5%)] Loss: 0.024519 L1: 0.014025 Grad: 0.104744 Thermal: 0.000396 LR: 4.21e-06\n",
      "Epoch  21 [9150/10697 ( 85.5%)] Loss: 0.024519 L1: 0.014025 Grad: 0.104744 Thermal: 0.000396 LR: 4.21e-06\n",
      "Epoch  21 [9200/10697 ( 86.0%)] Loss: 0.030604 L1: 0.017955 Grad: 0.126198 Thermal: 0.000583 LR: 4.21e-06\n",
      "Epoch  21 [9200/10697 ( 86.0%)] Loss: 0.030604 L1: 0.017955 Grad: 0.126198 Thermal: 0.000583 LR: 4.21e-06\n",
      "Epoch  21 [9250/10697 ( 86.5%)] Loss: 0.026618 L1: 0.015224 Grad: 0.113736 Thermal: 0.000401 LR: 4.21e-06\n",
      "Epoch  21 [9250/10697 ( 86.5%)] Loss: 0.026618 L1: 0.015224 Grad: 0.113736 Thermal: 0.000401 LR: 4.21e-06\n",
      "Epoch  21 [9300/10697 ( 86.9%)] Loss: 0.022667 L1: 0.013548 Grad: 0.091004 Thermal: 0.000369 LR: 4.21e-06\n",
      "Epoch  21 [9300/10697 ( 86.9%)] Loss: 0.022667 L1: 0.013548 Grad: 0.091004 Thermal: 0.000369 LR: 4.21e-06\n",
      "Epoch  21 [9350/10697 ( 87.4%)] Loss: 0.028513 L1: 0.016689 Grad: 0.117959 Thermal: 0.000573 LR: 4.21e-06\n",
      "Epoch  21 [9350/10697 ( 87.4%)] Loss: 0.028513 L1: 0.016689 Grad: 0.117959 Thermal: 0.000573 LR: 4.21e-06\n",
      "Epoch  21 [9400/10697 ( 87.9%)] Loss: 0.028907 L1: 0.016413 Grad: 0.124695 Thermal: 0.000486 LR: 4.21e-06\n",
      "Epoch  21 [9400/10697 ( 87.9%)] Loss: 0.028907 L1: 0.016413 Grad: 0.124695 Thermal: 0.000486 LR: 4.21e-06\n",
      "Epoch  21 [9450/10697 ( 88.3%)] Loss: 0.029180 L1: 0.016752 Grad: 0.123962 Thermal: 0.000638 LR: 4.21e-06\n",
      "Epoch  21 [9450/10697 ( 88.3%)] Loss: 0.029180 L1: 0.016752 Grad: 0.123962 Thermal: 0.000638 LR: 4.21e-06\n",
      "Epoch  21 [9500/10697 ( 88.8%)] Loss: 0.025919 L1: 0.014760 Grad: 0.111387 Thermal: 0.000405 LR: 4.21e-06\n",
      "Epoch  21 [9500/10697 ( 88.8%)] Loss: 0.025919 L1: 0.014760 Grad: 0.111387 Thermal: 0.000405 LR: 4.21e-06\n",
      "Epoch  21 [9550/10697 ( 89.3%)] Loss: 0.019028 L1: 0.011178 Grad: 0.078370 Thermal: 0.000268 LR: 4.21e-06\n",
      "Epoch  21 [9550/10697 ( 89.3%)] Loss: 0.019028 L1: 0.011178 Grad: 0.078370 Thermal: 0.000268 LR: 4.21e-06\n",
      "Epoch  21 [9600/10697 ( 89.7%)] Loss: 0.028829 L1: 0.016701 Grad: 0.121014 Thermal: 0.000521 LR: 4.21e-06\n",
      "Epoch  21 [9600/10697 ( 89.7%)] Loss: 0.028829 L1: 0.016701 Grad: 0.121014 Thermal: 0.000521 LR: 4.21e-06\n",
      "Epoch  21 [9650/10697 ( 90.2%)] Loss: 0.030398 L1: 0.017525 Grad: 0.128416 Thermal: 0.000616 LR: 4.21e-06\n",
      "Epoch  21 [9650/10697 ( 90.2%)] Loss: 0.030398 L1: 0.017525 Grad: 0.128416 Thermal: 0.000616 LR: 4.21e-06\n",
      "Epoch  21 [9700/10697 ( 90.7%)] Loss: 0.024078 L1: 0.013752 Grad: 0.103009 Thermal: 0.000497 LR: 4.21e-06\n",
      "Epoch  21 [9700/10697 ( 90.7%)] Loss: 0.024078 L1: 0.013752 Grad: 0.103009 Thermal: 0.000497 LR: 4.21e-06\n",
      "Epoch  21 [9750/10697 ( 91.1%)] Loss: 0.030669 L1: 0.017727 Grad: 0.129124 Thermal: 0.000592 LR: 4.21e-06\n",
      "Epoch  21 [9750/10697 ( 91.1%)] Loss: 0.030669 L1: 0.017727 Grad: 0.129124 Thermal: 0.000592 LR: 4.21e-06\n",
      "Epoch  21 [9800/10697 ( 91.6%)] Loss: 0.029532 L1: 0.017712 Grad: 0.117908 Thermal: 0.000578 LR: 4.21e-06\n",
      "Epoch  21 [9800/10697 ( 91.6%)] Loss: 0.029532 L1: 0.017712 Grad: 0.117908 Thermal: 0.000578 LR: 4.21e-06\n",
      "Epoch  21 [9850/10697 ( 92.1%)] Loss: 0.031178 L1: 0.017874 Grad: 0.132723 Thermal: 0.000636 LR: 4.21e-06\n",
      "Epoch  21 [9850/10697 ( 92.1%)] Loss: 0.031178 L1: 0.017874 Grad: 0.132723 Thermal: 0.000636 LR: 4.21e-06\n",
      "Epoch  21 [9900/10697 ( 92.5%)] Loss: 0.026622 L1: 0.015397 Grad: 0.112027 Thermal: 0.000445 LR: 4.21e-06\n",
      "Epoch  21 [9900/10697 ( 92.5%)] Loss: 0.026622 L1: 0.015397 Grad: 0.112027 Thermal: 0.000445 LR: 4.21e-06\n",
      "Epoch  21 [9950/10697 ( 93.0%)] Loss: 0.023601 L1: 0.013536 Grad: 0.100455 Thermal: 0.000387 LR: 4.21e-06\n",
      "Epoch  21 [9950/10697 ( 93.0%)] Loss: 0.023601 L1: 0.013536 Grad: 0.100455 Thermal: 0.000387 LR: 4.21e-06\n",
      "Epoch  21 [10000/10697 ( 93.5%)] Loss: 0.029784 L1: 0.017386 Grad: 0.123690 Thermal: 0.000573 LR: 4.21e-06\n",
      "Epoch  21 [10000/10697 ( 93.5%)] Loss: 0.029784 L1: 0.017386 Grad: 0.123690 Thermal: 0.000573 LR: 4.21e-06\n",
      "Epoch  21 [10050/10697 ( 94.0%)] Loss: 0.029470 L1: 0.016931 Grad: 0.125088 Thermal: 0.000587 LR: 4.21e-06\n",
      "Epoch  21 [10050/10697 ( 94.0%)] Loss: 0.029470 L1: 0.016931 Grad: 0.125088 Thermal: 0.000587 LR: 4.21e-06\n",
      "Epoch  21 [10100/10697 ( 94.4%)] Loss: 0.031435 L1: 0.017778 Grad: 0.136268 Thermal: 0.000591 LR: 4.21e-06\n",
      "Epoch  21 [10100/10697 ( 94.4%)] Loss: 0.031435 L1: 0.017778 Grad: 0.136268 Thermal: 0.000591 LR: 4.21e-06\n",
      "Epoch  21 [10150/10697 ( 94.9%)] Loss: 0.027106 L1: 0.015947 Grad: 0.111371 Thermal: 0.000440 LR: 4.21e-06\n",
      "Epoch  21 [10150/10697 ( 94.9%)] Loss: 0.027106 L1: 0.015947 Grad: 0.111371 Thermal: 0.000440 LR: 4.21e-06\n",
      "Epoch  21 [10200/10697 ( 95.4%)] Loss: 0.024098 L1: 0.013991 Grad: 0.100891 Thermal: 0.000362 LR: 4.21e-06\n",
      "Epoch  21 [10200/10697 ( 95.4%)] Loss: 0.024098 L1: 0.013991 Grad: 0.100891 Thermal: 0.000362 LR: 4.21e-06\n",
      "Epoch  21 [10250/10697 ( 95.8%)] Loss: 0.026362 L1: 0.015741 Grad: 0.105995 Thermal: 0.000426 LR: 4.21e-06\n",
      "Epoch  21 [10250/10697 ( 95.8%)] Loss: 0.026362 L1: 0.015741 Grad: 0.105995 Thermal: 0.000426 LR: 4.21e-06\n",
      "Epoch  21 [10300/10697 ( 96.3%)] Loss: 0.024970 L1: 0.014905 Grad: 0.100451 Thermal: 0.000405 LR: 4.21e-06\n",
      "Epoch  21 [10300/10697 ( 96.3%)] Loss: 0.024970 L1: 0.014905 Grad: 0.100451 Thermal: 0.000405 LR: 4.21e-06\n",
      "Epoch  21 [10350/10697 ( 96.8%)] Loss: 0.029285 L1: 0.017095 Grad: 0.121633 Thermal: 0.000523 LR: 4.21e-06\n",
      "Epoch  21 [10350/10697 ( 96.8%)] Loss: 0.029285 L1: 0.017095 Grad: 0.121633 Thermal: 0.000523 LR: 4.21e-06\n",
      "Epoch  21 [10400/10697 ( 97.2%)] Loss: 0.023992 L1: 0.014073 Grad: 0.099003 Thermal: 0.000363 LR: 4.21e-06\n",
      "Epoch  21 [10400/10697 ( 97.2%)] Loss: 0.023992 L1: 0.014073 Grad: 0.099003 Thermal: 0.000363 LR: 4.21e-06\n",
      "Epoch  21 [10450/10697 ( 97.7%)] Loss: 0.019803 L1: 0.011581 Grad: 0.082083 Thermal: 0.000269 LR: 4.21e-06\n",
      "Epoch  21 [10450/10697 ( 97.7%)] Loss: 0.019803 L1: 0.011581 Grad: 0.082083 Thermal: 0.000269 LR: 4.21e-06\n",
      "Epoch  21 [10500/10697 ( 98.2%)] Loss: 0.018564 L1: 0.010481 Grad: 0.080706 Thermal: 0.000242 LR: 4.21e-06\n",
      "Epoch  21 [10500/10697 ( 98.2%)] Loss: 0.018564 L1: 0.010481 Grad: 0.080706 Thermal: 0.000242 LR: 4.21e-06\n",
      "Epoch  21 [10550/10697 ( 98.6%)] Loss: 0.030576 L1: 0.018078 Grad: 0.124681 Thermal: 0.000598 LR: 4.21e-06\n",
      "Epoch  21 [10550/10697 ( 98.6%)] Loss: 0.030576 L1: 0.018078 Grad: 0.124681 Thermal: 0.000598 LR: 4.21e-06\n",
      "Epoch  21 [10600/10697 ( 99.1%)] Loss: 0.024532 L1: 0.014208 Grad: 0.103055 Thermal: 0.000362 LR: 4.21e-06\n",
      "Epoch  21 [10600/10697 ( 99.1%)] Loss: 0.024532 L1: 0.014208 Grad: 0.103055 Thermal: 0.000362 LR: 4.21e-06\n",
      "Epoch  21 [10650/10697 ( 99.6%)] Loss: 0.027296 L1: 0.016220 Grad: 0.110528 Thermal: 0.000464 LR: 4.21e-06\n",
      "Epoch  21 [10650/10697 ( 99.6%)] Loss: 0.027296 L1: 0.016220 Grad: 0.110528 Thermal: 0.000464 LR: 4.21e-06\n",
      "Epoch  21 Summary: Loss=0.026373 (L1:0.0154, Grad:0.1097, Thermal:0.0005) Val_PSNR=0.00dB Best=33.92dB Time=79.1min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  21 Summary: Loss=0.026373 (L1:0.0154, Grad:0.1097, Thermal:0.0005) Val_PSNR=0.00dB Best=33.92dB Time=79.1min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  22 [   0/10697 (  0.0%)] Loss: 0.027899 L1: 0.016018 Grad: 0.118567 Thermal: 0.000486 LR: 4.13e-06\n",
      "Epoch  22 [   0/10697 (  0.0%)] Loss: 0.027899 L1: 0.016018 Grad: 0.118567 Thermal: 0.000486 LR: 4.13e-06\n",
      "Epoch  22 [  50/10697 (  0.5%)] Loss: 0.026704 L1: 0.015291 Grad: 0.113896 Thermal: 0.000459 LR: 4.13e-06\n",
      "Epoch  22 [  50/10697 (  0.5%)] Loss: 0.026704 L1: 0.015291 Grad: 0.113896 Thermal: 0.000459 LR: 4.13e-06\n",
      "Epoch  22 [ 100/10697 (  0.9%)] Loss: 0.026898 L1: 0.016143 Grad: 0.107322 Thermal: 0.000455 LR: 4.13e-06\n",
      "Epoch  22 [ 100/10697 (  0.9%)] Loss: 0.026898 L1: 0.016143 Grad: 0.107322 Thermal: 0.000455 LR: 4.13e-06\n",
      "Epoch  22 [ 150/10697 (  1.4%)] Loss: 0.025092 L1: 0.015044 Grad: 0.100266 Thermal: 0.000423 LR: 4.13e-06\n",
      "Epoch  22 [ 150/10697 (  1.4%)] Loss: 0.025092 L1: 0.015044 Grad: 0.100266 Thermal: 0.000423 LR: 4.13e-06\n",
      "Epoch  22 [ 200/10697 (  1.9%)] Loss: 0.029550 L1: 0.017630 Grad: 0.118919 Thermal: 0.000558 LR: 4.13e-06\n",
      "Epoch  22 [ 200/10697 (  1.9%)] Loss: 0.029550 L1: 0.017630 Grad: 0.118919 Thermal: 0.000558 LR: 4.13e-06\n",
      "Epoch  22 [ 250/10697 (  2.3%)] Loss: 0.025574 L1: 0.014586 Grad: 0.109667 Thermal: 0.000419 LR: 4.13e-06\n",
      "Epoch  22 [ 250/10697 (  2.3%)] Loss: 0.025574 L1: 0.014586 Grad: 0.109667 Thermal: 0.000419 LR: 4.13e-06\n",
      "Epoch  22 [ 300/10697 (  2.8%)] Loss: 0.026264 L1: 0.015064 Grad: 0.111772 Thermal: 0.000450 LR: 4.13e-06\n",
      "Epoch  22 [ 300/10697 (  2.8%)] Loss: 0.026264 L1: 0.015064 Grad: 0.111772 Thermal: 0.000450 LR: 4.13e-06\n",
      "Epoch  22 [ 350/10697 (  3.3%)] Loss: 0.033740 L1: 0.019615 Grad: 0.140814 Thermal: 0.000859 LR: 4.13e-06\n",
      "Epoch  22 [ 350/10697 (  3.3%)] Loss: 0.033740 L1: 0.019615 Grad: 0.140814 Thermal: 0.000859 LR: 4.13e-06\n",
      "Epoch  22 [ 400/10697 (  3.7%)] Loss: 0.032531 L1: 0.019086 Grad: 0.134074 Thermal: 0.000736 LR: 4.13e-06\n",
      "Epoch  22 [ 400/10697 (  3.7%)] Loss: 0.032531 L1: 0.019086 Grad: 0.134074 Thermal: 0.000736 LR: 4.13e-06\n",
      "Epoch  22 [ 450/10697 (  4.2%)] Loss: 0.026845 L1: 0.015987 Grad: 0.108347 Thermal: 0.000471 LR: 4.13e-06\n",
      "Epoch  22 [ 450/10697 (  4.2%)] Loss: 0.026845 L1: 0.015987 Grad: 0.108347 Thermal: 0.000471 LR: 4.13e-06\n",
      "Epoch  22 [ 500/10697 (  4.7%)] Loss: 0.024642 L1: 0.014283 Grad: 0.103403 Thermal: 0.000361 LR: 4.13e-06\n",
      "Epoch  22 [ 500/10697 (  4.7%)] Loss: 0.024642 L1: 0.014283 Grad: 0.103403 Thermal: 0.000361 LR: 4.13e-06\n",
      "Epoch  22 [ 550/10697 (  5.1%)] Loss: 0.028727 L1: 0.016906 Grad: 0.117920 Thermal: 0.000582 LR: 4.13e-06\n",
      "Epoch  22 [ 550/10697 (  5.1%)] Loss: 0.028727 L1: 0.016906 Grad: 0.117920 Thermal: 0.000582 LR: 4.13e-06\n",
      "Epoch  22 [ 600/10697 (  5.6%)] Loss: 0.025858 L1: 0.015371 Grad: 0.104659 Thermal: 0.000429 LR: 4.13e-06\n",
      "Epoch  22 [ 600/10697 (  5.6%)] Loss: 0.025858 L1: 0.015371 Grad: 0.104659 Thermal: 0.000429 LR: 4.13e-06\n",
      "Epoch  22 [ 650/10697 (  6.1%)] Loss: 0.022898 L1: 0.013736 Grad: 0.091426 Thermal: 0.000372 LR: 4.13e-06\n",
      "Epoch  22 [ 650/10697 (  6.1%)] Loss: 0.022898 L1: 0.013736 Grad: 0.091426 Thermal: 0.000372 LR: 4.13e-06\n",
      "Epoch  22 [ 700/10697 (  6.5%)] Loss: 0.026744 L1: 0.015972 Grad: 0.107473 Thermal: 0.000486 LR: 4.13e-06\n",
      "Epoch  22 [ 700/10697 (  6.5%)] Loss: 0.026744 L1: 0.015972 Grad: 0.107473 Thermal: 0.000486 LR: 4.13e-06\n",
      "Epoch  22 [ 750/10697 (  7.0%)] Loss: 0.024498 L1: 0.014442 Grad: 0.100367 Thermal: 0.000382 LR: 4.13e-06\n",
      "Epoch  22 [ 750/10697 (  7.0%)] Loss: 0.024498 L1: 0.014442 Grad: 0.100367 Thermal: 0.000382 LR: 4.13e-06\n",
      "Epoch  22 [ 800/10697 (  7.5%)] Loss: 0.029744 L1: 0.017484 Grad: 0.122313 Thermal: 0.000562 LR: 4.13e-06\n",
      "Epoch  22 [ 800/10697 (  7.5%)] Loss: 0.029744 L1: 0.017484 Grad: 0.122313 Thermal: 0.000562 LR: 4.13e-06\n",
      "Epoch  22 [ 850/10697 (  7.9%)] Loss: 0.021726 L1: 0.012971 Grad: 0.087389 Thermal: 0.000328 LR: 4.13e-06\n",
      "Epoch  22 [ 850/10697 (  7.9%)] Loss: 0.021726 L1: 0.012971 Grad: 0.087389 Thermal: 0.000328 LR: 4.13e-06\n",
      "Epoch  22 [ 900/10697 (  8.4%)] Loss: 0.025235 L1: 0.015085 Grad: 0.101268 Thermal: 0.000461 LR: 4.13e-06\n",
      "Epoch  22 [ 900/10697 (  8.4%)] Loss: 0.025235 L1: 0.015085 Grad: 0.101268 Thermal: 0.000461 LR: 4.13e-06\n",
      "Epoch  22 [ 950/10697 (  8.9%)] Loss: 0.028431 L1: 0.017155 Grad: 0.112506 Thermal: 0.000501 LR: 4.13e-06\n",
      "Epoch  22 [ 950/10697 (  8.9%)] Loss: 0.028431 L1: 0.017155 Grad: 0.112506 Thermal: 0.000501 LR: 4.13e-06\n",
      "Epoch  22 [1000/10697 (  9.3%)] Loss: 0.032625 L1: 0.019445 Grad: 0.131451 Thermal: 0.000717 LR: 4.13e-06\n",
      "Epoch  22 [1000/10697 (  9.3%)] Loss: 0.032625 L1: 0.019445 Grad: 0.131451 Thermal: 0.000717 LR: 4.13e-06\n",
      "Epoch  22 [1050/10697 (  9.8%)] Loss: 0.019299 L1: 0.011102 Grad: 0.081840 Thermal: 0.000254 LR: 4.13e-06\n",
      "Epoch  22 [1050/10697 (  9.8%)] Loss: 0.019299 L1: 0.011102 Grad: 0.081840 Thermal: 0.000254 LR: 4.13e-06\n",
      "Epoch  22 [1100/10697 ( 10.3%)] Loss: 0.021966 L1: 0.012829 Grad: 0.091194 Thermal: 0.000342 LR: 4.13e-06\n",
      "Epoch  22 [1100/10697 ( 10.3%)] Loss: 0.021966 L1: 0.012829 Grad: 0.091194 Thermal: 0.000342 LR: 4.13e-06\n",
      "Epoch  22 [1150/10697 ( 10.8%)] Loss: 0.023463 L1: 0.013921 Grad: 0.095229 Thermal: 0.000385 LR: 4.13e-06\n",
      "Epoch  22 [1150/10697 ( 10.8%)] Loss: 0.023463 L1: 0.013921 Grad: 0.095229 Thermal: 0.000385 LR: 4.13e-06\n",
      "Epoch  22 [1200/10697 ( 11.2%)] Loss: 0.025511 L1: 0.015188 Grad: 0.103014 Thermal: 0.000419 LR: 4.13e-06\n",
      "Epoch  22 [1200/10697 ( 11.2%)] Loss: 0.025511 L1: 0.015188 Grad: 0.103014 Thermal: 0.000419 LR: 4.13e-06\n",
      "Epoch  22 [1250/10697 ( 11.7%)] Loss: 0.027655 L1: 0.015622 Grad: 0.120032 Thermal: 0.000602 LR: 4.13e-06\n",
      "Epoch  22 [1250/10697 ( 11.7%)] Loss: 0.027655 L1: 0.015622 Grad: 0.120032 Thermal: 0.000602 LR: 4.13e-06\n",
      "Epoch  22 [1300/10697 ( 12.2%)] Loss: 0.027014 L1: 0.015941 Grad: 0.110505 Thermal: 0.000451 LR: 4.13e-06\n",
      "Epoch  22 [1300/10697 ( 12.2%)] Loss: 0.027014 L1: 0.015941 Grad: 0.110505 Thermal: 0.000451 LR: 4.13e-06\n",
      "Epoch  22 [1350/10697 ( 12.6%)] Loss: 0.027335 L1: 0.015979 Grad: 0.113321 Thermal: 0.000476 LR: 4.13e-06\n",
      "Epoch  22 [1350/10697 ( 12.6%)] Loss: 0.027335 L1: 0.015979 Grad: 0.113321 Thermal: 0.000476 LR: 4.13e-06\n",
      "Epoch  22 [1400/10697 ( 13.1%)] Loss: 0.030045 L1: 0.017196 Grad: 0.128222 Thermal: 0.000538 LR: 4.13e-06\n",
      "Epoch  22 [1400/10697 ( 13.1%)] Loss: 0.030045 L1: 0.017196 Grad: 0.128222 Thermal: 0.000538 LR: 4.13e-06\n",
      "Epoch  22 [1450/10697 ( 13.6%)] Loss: 0.029961 L1: 0.016775 Grad: 0.131609 Thermal: 0.000505 LR: 4.13e-06\n",
      "Epoch  22 [1450/10697 ( 13.6%)] Loss: 0.029961 L1: 0.016775 Grad: 0.131609 Thermal: 0.000505 LR: 4.13e-06\n",
      "Epoch  22 [1500/10697 ( 14.0%)] Loss: 0.019145 L1: 0.010933 Grad: 0.081996 Thermal: 0.000242 LR: 4.13e-06\n",
      "Epoch  22 [1500/10697 ( 14.0%)] Loss: 0.019145 L1: 0.010933 Grad: 0.081996 Thermal: 0.000242 LR: 4.13e-06\n",
      "Epoch  22 [1550/10697 ( 14.5%)] Loss: 0.025439 L1: 0.014960 Grad: 0.104583 Thermal: 0.000396 LR: 4.13e-06\n",
      "Epoch  22 [1550/10697 ( 14.5%)] Loss: 0.025439 L1: 0.014960 Grad: 0.104583 Thermal: 0.000396 LR: 4.13e-06\n",
      "Epoch  22 [1600/10697 ( 15.0%)] Loss: 0.027788 L1: 0.016700 Grad: 0.110632 Thermal: 0.000491 LR: 4.13e-06\n",
      "Epoch  22 [1600/10697 ( 15.0%)] Loss: 0.027788 L1: 0.016700 Grad: 0.110632 Thermal: 0.000491 LR: 4.13e-06\n",
      "Epoch  22 [1650/10697 ( 15.4%)] Loss: 0.027142 L1: 0.016050 Grad: 0.110659 Thermal: 0.000521 LR: 4.13e-06\n",
      "Epoch  22 [1650/10697 ( 15.4%)] Loss: 0.027142 L1: 0.016050 Grad: 0.110659 Thermal: 0.000521 LR: 4.13e-06\n",
      "Epoch  22 [1700/10697 ( 15.9%)] Loss: 0.021106 L1: 0.012096 Grad: 0.089938 Thermal: 0.000323 LR: 4.13e-06\n",
      "Epoch  22 [1700/10697 ( 15.9%)] Loss: 0.021106 L1: 0.012096 Grad: 0.089938 Thermal: 0.000323 LR: 4.13e-06\n",
      "Epoch  22 [1750/10697 ( 16.4%)] Loss: 0.030224 L1: 0.017398 Grad: 0.127985 Thermal: 0.000545 LR: 4.13e-06\n",
      "Epoch  22 [1750/10697 ( 16.4%)] Loss: 0.030224 L1: 0.017398 Grad: 0.127985 Thermal: 0.000545 LR: 4.13e-06\n",
      "Epoch  22 [1800/10697 ( 16.8%)] Loss: 0.031936 L1: 0.018815 Grad: 0.130871 Thermal: 0.000672 LR: 4.13e-06\n",
      "Epoch  22 [1800/10697 ( 16.8%)] Loss: 0.031936 L1: 0.018815 Grad: 0.130871 Thermal: 0.000672 LR: 4.13e-06\n",
      "Epoch  22 [1850/10697 ( 17.3%)] Loss: 0.030182 L1: 0.017121 Grad: 0.130288 Thermal: 0.000631 LR: 4.13e-06\n",
      "Epoch  22 [1850/10697 ( 17.3%)] Loss: 0.030182 L1: 0.017121 Grad: 0.130288 Thermal: 0.000631 LR: 4.13e-06\n",
      "Epoch  22 [1900/10697 ( 17.8%)] Loss: 0.021471 L1: 0.012354 Grad: 0.091002 Thermal: 0.000340 LR: 4.13e-06\n",
      "Epoch  22 [1900/10697 ( 17.8%)] Loss: 0.021471 L1: 0.012354 Grad: 0.091002 Thermal: 0.000340 LR: 4.13e-06\n",
      "Epoch  22 [1950/10697 ( 18.2%)] Loss: 0.027539 L1: 0.015843 Grad: 0.116736 Thermal: 0.000455 LR: 4.13e-06\n",
      "Epoch  22 [1950/10697 ( 18.2%)] Loss: 0.027539 L1: 0.015843 Grad: 0.116736 Thermal: 0.000455 LR: 4.13e-06\n",
      "Epoch  22 [2000/10697 ( 18.7%)] Loss: 0.028594 L1: 0.016226 Grad: 0.123393 Thermal: 0.000574 LR: 4.13e-06\n",
      "Epoch  22 [2000/10697 ( 18.7%)] Loss: 0.028594 L1: 0.016226 Grad: 0.123393 Thermal: 0.000574 LR: 4.13e-06\n",
      "Epoch  22 [2050/10697 ( 19.2%)] Loss: 0.028294 L1: 0.016753 Grad: 0.115150 Thermal: 0.000527 LR: 4.13e-06\n",
      "Epoch  22 [2050/10697 ( 19.2%)] Loss: 0.028294 L1: 0.016753 Grad: 0.115150 Thermal: 0.000527 LR: 4.13e-06\n",
      "Epoch  22 [2100/10697 ( 19.6%)] Loss: 0.018229 L1: 0.010489 Grad: 0.077282 Thermal: 0.000235 LR: 4.13e-06\n",
      "Epoch  22 [2100/10697 ( 19.6%)] Loss: 0.018229 L1: 0.010489 Grad: 0.077282 Thermal: 0.000235 LR: 4.13e-06\n",
      "Epoch  22 [2150/10697 ( 20.1%)] Loss: 0.023764 L1: 0.013927 Grad: 0.098201 Thermal: 0.000343 LR: 4.13e-06\n",
      "Epoch  22 [2150/10697 ( 20.1%)] Loss: 0.023764 L1: 0.013927 Grad: 0.098201 Thermal: 0.000343 LR: 4.13e-06\n",
      "Epoch  22 [2200/10697 ( 20.6%)] Loss: 0.034385 L1: 0.019492 Grad: 0.148544 Thermal: 0.000761 LR: 4.13e-06\n",
      "Epoch  22 [2200/10697 ( 20.6%)] Loss: 0.034385 L1: 0.019492 Grad: 0.148544 Thermal: 0.000761 LR: 4.13e-06\n",
      "Epoch  22 [2250/10697 ( 21.0%)] Loss: 0.029973 L1: 0.017535 Grad: 0.124079 Thermal: 0.000600 LR: 4.13e-06\n",
      "Epoch  22 [2250/10697 ( 21.0%)] Loss: 0.029973 L1: 0.017535 Grad: 0.124079 Thermal: 0.000600 LR: 4.13e-06\n",
      "Epoch  22 [2300/10697 ( 21.5%)] Loss: 0.020774 L1: 0.012332 Grad: 0.084266 Thermal: 0.000301 LR: 4.13e-06\n",
      "Epoch  22 [2300/10697 ( 21.5%)] Loss: 0.020774 L1: 0.012332 Grad: 0.084266 Thermal: 0.000301 LR: 4.13e-06\n",
      "Epoch  22 [2350/10697 ( 22.0%)] Loss: 0.032791 L1: 0.018738 Grad: 0.140181 Thermal: 0.000703 LR: 4.13e-06\n",
      "Epoch  22 [2350/10697 ( 22.0%)] Loss: 0.032791 L1: 0.018738 Grad: 0.140181 Thermal: 0.000703 LR: 4.13e-06\n",
      "Epoch  22 [2400/10697 ( 22.4%)] Loss: 0.026058 L1: 0.015220 Grad: 0.108158 Thermal: 0.000433 LR: 4.13e-06\n",
      "Epoch  22 [2400/10697 ( 22.4%)] Loss: 0.026058 L1: 0.015220 Grad: 0.108158 Thermal: 0.000433 LR: 4.13e-06\n",
      "Epoch  22 [2450/10697 ( 22.9%)] Loss: 0.025271 L1: 0.015198 Grad: 0.100533 Thermal: 0.000391 LR: 4.13e-06\n",
      "Epoch  22 [2450/10697 ( 22.9%)] Loss: 0.025271 L1: 0.015198 Grad: 0.100533 Thermal: 0.000391 LR: 4.13e-06\n",
      "Epoch  22 [2500/10697 ( 23.4%)] Loss: 0.027155 L1: 0.016053 Grad: 0.110781 Thermal: 0.000475 LR: 4.13e-06\n",
      "Epoch  22 [2500/10697 ( 23.4%)] Loss: 0.027155 L1: 0.016053 Grad: 0.110781 Thermal: 0.000475 LR: 4.13e-06\n",
      "Epoch  22 [2550/10697 ( 23.8%)] Loss: 0.024165 L1: 0.014143 Grad: 0.100042 Thermal: 0.000361 LR: 4.13e-06\n",
      "Epoch  22 [2550/10697 ( 23.8%)] Loss: 0.024165 L1: 0.014143 Grad: 0.100042 Thermal: 0.000361 LR: 4.13e-06\n",
      "Epoch  22 [2600/10697 ( 24.3%)] Loss: 0.029467 L1: 0.017451 Grad: 0.119872 Thermal: 0.000576 LR: 4.13e-06\n",
      "Epoch  22 [2600/10697 ( 24.3%)] Loss: 0.029467 L1: 0.017451 Grad: 0.119872 Thermal: 0.000576 LR: 4.13e-06\n",
      "Epoch  22 [2650/10697 ( 24.8%)] Loss: 0.024425 L1: 0.014286 Grad: 0.101184 Thermal: 0.000406 LR: 4.13e-06\n",
      "Epoch  22 [2650/10697 ( 24.8%)] Loss: 0.024425 L1: 0.014286 Grad: 0.101184 Thermal: 0.000406 LR: 4.13e-06\n",
      "Epoch  22 [2700/10697 ( 25.2%)] Loss: 0.018632 L1: 0.010883 Grad: 0.077355 Thermal: 0.000269 LR: 4.13e-06\n",
      "Epoch  22 [2700/10697 ( 25.2%)] Loss: 0.018632 L1: 0.010883 Grad: 0.077355 Thermal: 0.000269 LR: 4.13e-06\n",
      "Epoch  22 [2750/10697 ( 25.7%)] Loss: 0.028046 L1: 0.016457 Grad: 0.115642 Thermal: 0.000493 LR: 4.13e-06\n",
      "Epoch  22 [2750/10697 ( 25.7%)] Loss: 0.028046 L1: 0.016457 Grad: 0.115642 Thermal: 0.000493 LR: 4.13e-06\n",
      "Epoch  22 [2800/10697 ( 26.2%)] Loss: 0.027917 L1: 0.016240 Grad: 0.116524 Thermal: 0.000482 LR: 4.13e-06\n",
      "Epoch  22 [2800/10697 ( 26.2%)] Loss: 0.027917 L1: 0.016240 Grad: 0.116524 Thermal: 0.000482 LR: 4.13e-06\n",
      "Epoch  22 [2850/10697 ( 26.6%)] Loss: 0.030005 L1: 0.017566 Grad: 0.124117 Thermal: 0.000547 LR: 4.13e-06\n",
      "Epoch  22 [2850/10697 ( 26.6%)] Loss: 0.030005 L1: 0.017566 Grad: 0.124117 Thermal: 0.000547 LR: 4.13e-06\n",
      "Epoch  22 [2900/10697 ( 27.1%)] Loss: 0.026669 L1: 0.015625 Grad: 0.110196 Thermal: 0.000490 LR: 4.13e-06\n",
      "Epoch  22 [2900/10697 ( 27.1%)] Loss: 0.026669 L1: 0.015625 Grad: 0.110196 Thermal: 0.000490 LR: 4.13e-06\n",
      "Epoch  22 [2950/10697 ( 27.6%)] Loss: 0.026380 L1: 0.015930 Grad: 0.104285 Thermal: 0.000440 LR: 4.13e-06\n",
      "Epoch  22 [2950/10697 ( 27.6%)] Loss: 0.026380 L1: 0.015930 Grad: 0.104285 Thermal: 0.000440 LR: 4.13e-06\n",
      "Epoch  22 [3000/10697 ( 28.0%)] Loss: 0.026215 L1: 0.015750 Grad: 0.104433 Thermal: 0.000438 LR: 4.13e-06\n",
      "Epoch  22 [3000/10697 ( 28.0%)] Loss: 0.026215 L1: 0.015750 Grad: 0.104433 Thermal: 0.000438 LR: 4.13e-06\n",
      "Epoch  22 [3050/10697 ( 28.5%)] Loss: 0.018118 L1: 0.010468 Grad: 0.076384 Thermal: 0.000228 LR: 4.13e-06\n",
      "Epoch  22 [3050/10697 ( 28.5%)] Loss: 0.018118 L1: 0.010468 Grad: 0.076384 Thermal: 0.000228 LR: 4.13e-06\n",
      "Epoch  22 [3100/10697 ( 29.0%)] Loss: 0.025157 L1: 0.015015 Grad: 0.101210 Thermal: 0.000401 LR: 4.13e-06\n",
      "Epoch  22 [3100/10697 ( 29.0%)] Loss: 0.025157 L1: 0.015015 Grad: 0.101210 Thermal: 0.000401 LR: 4.13e-06\n",
      "Epoch  22 [3150/10697 ( 29.4%)] Loss: 0.025750 L1: 0.015052 Grad: 0.106734 Thermal: 0.000509 LR: 4.13e-06\n",
      "Epoch  22 [3150/10697 ( 29.4%)] Loss: 0.025750 L1: 0.015052 Grad: 0.106734 Thermal: 0.000509 LR: 4.13e-06\n",
      "Epoch  22 [3200/10697 ( 29.9%)] Loss: 0.026532 L1: 0.015807 Grad: 0.107017 Thermal: 0.000462 LR: 4.13e-06\n",
      "Epoch  22 [3200/10697 ( 29.9%)] Loss: 0.026532 L1: 0.015807 Grad: 0.107017 Thermal: 0.000462 LR: 4.13e-06\n",
      "Epoch  22 [3250/10697 ( 30.4%)] Loss: 0.026587 L1: 0.016153 Grad: 0.104108 Thermal: 0.000465 LR: 4.13e-06\n",
      "Epoch  22 [3250/10697 ( 30.4%)] Loss: 0.026587 L1: 0.016153 Grad: 0.104108 Thermal: 0.000465 LR: 4.13e-06\n",
      "Epoch  22 [3300/10697 ( 30.8%)] Loss: 0.024379 L1: 0.014131 Grad: 0.102250 Thermal: 0.000454 LR: 4.13e-06\n",
      "Epoch  22 [3300/10697 ( 30.8%)] Loss: 0.024379 L1: 0.014131 Grad: 0.102250 Thermal: 0.000454 LR: 4.13e-06\n",
      "Epoch  22 [3350/10697 ( 31.3%)] Loss: 0.025251 L1: 0.014570 Grad: 0.106629 Thermal: 0.000371 LR: 4.13e-06\n",
      "Epoch  22 [3350/10697 ( 31.3%)] Loss: 0.025251 L1: 0.014570 Grad: 0.106629 Thermal: 0.000371 LR: 4.13e-06\n",
      "Epoch  22 [3400/10697 ( 31.8%)] Loss: 0.026598 L1: 0.015421 Grad: 0.111544 Thermal: 0.000449 LR: 4.13e-06\n",
      "Epoch  22 [3400/10697 ( 31.8%)] Loss: 0.026598 L1: 0.015421 Grad: 0.111544 Thermal: 0.000449 LR: 4.13e-06\n",
      "Epoch  22 [3450/10697 ( 32.3%)] Loss: 0.030539 L1: 0.018171 Grad: 0.123383 Thermal: 0.000598 LR: 4.13e-06\n",
      "Epoch  22 [3450/10697 ( 32.3%)] Loss: 0.030539 L1: 0.018171 Grad: 0.123383 Thermal: 0.000598 LR: 4.13e-06\n",
      "Epoch  22 [3500/10697 ( 32.7%)] Loss: 0.028705 L1: 0.016779 Grad: 0.118975 Thermal: 0.000552 LR: 4.13e-06\n",
      "Epoch  22 [3500/10697 ( 32.7%)] Loss: 0.028705 L1: 0.016779 Grad: 0.118975 Thermal: 0.000552 LR: 4.13e-06\n",
      "Epoch  22 [3550/10697 ( 33.2%)] Loss: 0.024204 L1: 0.014303 Grad: 0.098824 Thermal: 0.000375 LR: 4.13e-06\n",
      "Epoch  22 [3550/10697 ( 33.2%)] Loss: 0.024204 L1: 0.014303 Grad: 0.098824 Thermal: 0.000375 LR: 4.13e-06\n",
      "Epoch  22 [3600/10697 ( 33.7%)] Loss: 0.034052 L1: 0.019540 Grad: 0.144757 Thermal: 0.000711 LR: 4.13e-06\n",
      "Epoch  22 [3600/10697 ( 33.7%)] Loss: 0.034052 L1: 0.019540 Grad: 0.144757 Thermal: 0.000711 LR: 4.13e-06\n",
      "Epoch  22 [3650/10697 ( 34.1%)] Loss: 0.023159 L1: 0.013928 Grad: 0.092126 Thermal: 0.000378 LR: 4.13e-06\n",
      "Epoch  22 [3650/10697 ( 34.1%)] Loss: 0.023159 L1: 0.013928 Grad: 0.092126 Thermal: 0.000378 LR: 4.13e-06\n",
      "Epoch  22 [3700/10697 ( 34.6%)] Loss: 0.020844 L1: 0.011387 Grad: 0.094395 Thermal: 0.000343 LR: 4.13e-06\n",
      "Epoch  22 [3700/10697 ( 34.6%)] Loss: 0.020844 L1: 0.011387 Grad: 0.094395 Thermal: 0.000343 LR: 4.13e-06\n",
      "Epoch  22 [3750/10697 ( 35.1%)] Loss: 0.022653 L1: 0.012913 Grad: 0.097242 Thermal: 0.000320 LR: 4.13e-06\n",
      "Epoch  22 [3750/10697 ( 35.1%)] Loss: 0.022653 L1: 0.012913 Grad: 0.097242 Thermal: 0.000320 LR: 4.13e-06\n",
      "Epoch  22 [3800/10697 ( 35.5%)] Loss: 0.029391 L1: 0.017069 Grad: 0.122919 Thermal: 0.000612 LR: 4.13e-06\n",
      "Epoch  22 [3800/10697 ( 35.5%)] Loss: 0.029391 L1: 0.017069 Grad: 0.122919 Thermal: 0.000612 LR: 4.13e-06\n",
      "Epoch  22 [3850/10697 ( 36.0%)] Loss: 0.026187 L1: 0.015230 Grad: 0.109349 Thermal: 0.000440 LR: 4.13e-06\n",
      "Epoch  22 [3850/10697 ( 36.0%)] Loss: 0.026187 L1: 0.015230 Grad: 0.109349 Thermal: 0.000440 LR: 4.13e-06\n",
      "Epoch  22 [3900/10697 ( 36.5%)] Loss: 0.020380 L1: 0.011912 Grad: 0.084538 Thermal: 0.000292 LR: 4.13e-06\n",
      "Epoch  22 [3900/10697 ( 36.5%)] Loss: 0.020380 L1: 0.011912 Grad: 0.084538 Thermal: 0.000292 LR: 4.13e-06\n",
      "Epoch  22 [3950/10697 ( 36.9%)] Loss: 0.034702 L1: 0.019981 Grad: 0.146799 Thermal: 0.000830 LR: 4.13e-06\n",
      "Epoch  22 [3950/10697 ( 36.9%)] Loss: 0.034702 L1: 0.019981 Grad: 0.146799 Thermal: 0.000830 LR: 4.13e-06\n",
      "Epoch  22 [4000/10697 ( 37.4%)] Loss: 0.030774 L1: 0.017749 Grad: 0.129947 Thermal: 0.000616 LR: 4.13e-06\n",
      "Epoch  22 [4000/10697 ( 37.4%)] Loss: 0.030774 L1: 0.017749 Grad: 0.129947 Thermal: 0.000616 LR: 4.13e-06\n",
      "Epoch  22 [4050/10697 ( 37.9%)] Loss: 0.024471 L1: 0.014285 Grad: 0.101665 Thermal: 0.000405 LR: 4.13e-06\n",
      "Epoch  22 [4050/10697 ( 37.9%)] Loss: 0.024471 L1: 0.014285 Grad: 0.101665 Thermal: 0.000405 LR: 4.13e-06\n",
      "Epoch  22 [4100/10697 ( 38.3%)] Loss: 0.033203 L1: 0.018932 Grad: 0.142375 Thermal: 0.000678 LR: 4.13e-06\n",
      "Epoch  22 [4100/10697 ( 38.3%)] Loss: 0.033203 L1: 0.018932 Grad: 0.142375 Thermal: 0.000678 LR: 4.13e-06\n",
      "Epoch  22 [4150/10697 ( 38.8%)] Loss: 0.023031 L1: 0.012939 Grad: 0.100770 Thermal: 0.000301 LR: 4.13e-06\n",
      "Epoch  22 [4150/10697 ( 38.8%)] Loss: 0.023031 L1: 0.012939 Grad: 0.100770 Thermal: 0.000301 LR: 4.13e-06\n",
      "Epoch  22 [4200/10697 ( 39.3%)] Loss: 0.027494 L1: 0.016085 Grad: 0.113848 Thermal: 0.000470 LR: 4.13e-06\n",
      "Epoch  22 [4200/10697 ( 39.3%)] Loss: 0.027494 L1: 0.016085 Grad: 0.113848 Thermal: 0.000470 LR: 4.13e-06\n",
      "Epoch  22 [4250/10697 ( 39.7%)] Loss: 0.027326 L1: 0.015722 Grad: 0.115790 Thermal: 0.000503 LR: 4.13e-06\n",
      "Epoch  22 [4250/10697 ( 39.7%)] Loss: 0.027326 L1: 0.015722 Grad: 0.115790 Thermal: 0.000503 LR: 4.13e-06\n",
      "Epoch  22 [4300/10697 ( 40.2%)] Loss: 0.026771 L1: 0.015203 Grad: 0.115448 Thermal: 0.000466 LR: 4.13e-06\n",
      "Epoch  22 [4300/10697 ( 40.2%)] Loss: 0.026771 L1: 0.015203 Grad: 0.115448 Thermal: 0.000466 LR: 4.13e-06\n",
      "Epoch  22 [4350/10697 ( 40.7%)] Loss: 0.024101 L1: 0.014288 Grad: 0.097941 Thermal: 0.000373 LR: 4.13e-06\n",
      "Epoch  22 [4350/10697 ( 40.7%)] Loss: 0.024101 L1: 0.014288 Grad: 0.097941 Thermal: 0.000373 LR: 4.13e-06\n",
      "Epoch  22 [4400/10697 ( 41.1%)] Loss: 0.030868 L1: 0.017766 Grad: 0.130743 Thermal: 0.000548 LR: 4.13e-06\n",
      "Epoch  22 [4400/10697 ( 41.1%)] Loss: 0.030868 L1: 0.017766 Grad: 0.130743 Thermal: 0.000548 LR: 4.13e-06\n",
      "Epoch  22 [4450/10697 ( 41.6%)] Loss: 0.026340 L1: 0.015012 Grad: 0.113059 Thermal: 0.000443 LR: 4.13e-06\n",
      "Epoch  22 [4450/10697 ( 41.6%)] Loss: 0.026340 L1: 0.015012 Grad: 0.113059 Thermal: 0.000443 LR: 4.13e-06\n",
      "Epoch  22 [4500/10697 ( 42.1%)] Loss: 0.032950 L1: 0.019474 Grad: 0.134392 Thermal: 0.000725 LR: 4.13e-06\n",
      "Epoch  22 [4500/10697 ( 42.1%)] Loss: 0.032950 L1: 0.019474 Grad: 0.134392 Thermal: 0.000725 LR: 4.13e-06\n",
      "Epoch  22 [4550/10697 ( 42.5%)] Loss: 0.031621 L1: 0.018363 Grad: 0.132264 Thermal: 0.000629 LR: 4.13e-06\n",
      "Epoch  22 [4550/10697 ( 42.5%)] Loss: 0.031621 L1: 0.018363 Grad: 0.132264 Thermal: 0.000629 LR: 4.13e-06\n",
      "Epoch  22 [4600/10697 ( 43.0%)] Loss: 0.027810 L1: 0.015951 Grad: 0.118317 Thermal: 0.000546 LR: 4.13e-06\n",
      "Epoch  22 [4600/10697 ( 43.0%)] Loss: 0.027810 L1: 0.015951 Grad: 0.118317 Thermal: 0.000546 LR: 4.13e-06\n",
      "Epoch  22 [4650/10697 ( 43.5%)] Loss: 0.027739 L1: 0.016127 Grad: 0.115851 Thermal: 0.000538 LR: 4.13e-06\n",
      "Epoch  22 [4650/10697 ( 43.5%)] Loss: 0.027739 L1: 0.016127 Grad: 0.115851 Thermal: 0.000538 LR: 4.13e-06\n",
      "Epoch  22 [4700/10697 ( 43.9%)] Loss: 0.027200 L1: 0.015609 Grad: 0.115689 Thermal: 0.000448 LR: 4.13e-06\n",
      "Epoch  22 [4700/10697 ( 43.9%)] Loss: 0.027200 L1: 0.015609 Grad: 0.115689 Thermal: 0.000448 LR: 4.13e-06\n",
      "Epoch  22 [4750/10697 ( 44.4%)] Loss: 0.027241 L1: 0.016027 Grad: 0.111920 Thermal: 0.000443 LR: 4.13e-06\n",
      "Epoch  22 [4750/10697 ( 44.4%)] Loss: 0.027241 L1: 0.016027 Grad: 0.111920 Thermal: 0.000443 LR: 4.13e-06\n",
      "Epoch  22 [4800/10697 ( 44.9%)] Loss: 0.029557 L1: 0.017320 Grad: 0.122106 Thermal: 0.000524 LR: 4.13e-06\n",
      "Epoch  22 [4800/10697 ( 44.9%)] Loss: 0.029557 L1: 0.017320 Grad: 0.122106 Thermal: 0.000524 LR: 4.13e-06\n",
      "Epoch  22 [4850/10697 ( 45.3%)] Loss: 0.027431 L1: 0.015868 Grad: 0.115385 Thermal: 0.000489 LR: 4.13e-06\n",
      "Epoch  22 [4850/10697 ( 45.3%)] Loss: 0.027431 L1: 0.015868 Grad: 0.115385 Thermal: 0.000489 LR: 4.13e-06\n",
      "Epoch  22 [4900/10697 ( 45.8%)] Loss: 0.025862 L1: 0.014874 Grad: 0.109642 Thermal: 0.000467 LR: 4.13e-06\n",
      "Epoch  22 [4900/10697 ( 45.8%)] Loss: 0.025862 L1: 0.014874 Grad: 0.109642 Thermal: 0.000467 LR: 4.13e-06\n",
      "Epoch  22 [4950/10697 ( 46.3%)] Loss: 0.025326 L1: 0.014951 Grad: 0.103537 Thermal: 0.000415 LR: 4.13e-06\n",
      "Epoch  22 [4950/10697 ( 46.3%)] Loss: 0.025326 L1: 0.014951 Grad: 0.103537 Thermal: 0.000415 LR: 4.13e-06\n",
      "Epoch  22 [5000/10697 ( 46.7%)] Loss: 0.027853 L1: 0.015854 Grad: 0.119732 Thermal: 0.000515 LR: 4.13e-06\n",
      "Epoch  22 [5000/10697 ( 46.7%)] Loss: 0.027853 L1: 0.015854 Grad: 0.119732 Thermal: 0.000515 LR: 4.13e-06\n",
      "Epoch  22 [5050/10697 ( 47.2%)] Loss: 0.030870 L1: 0.018232 Grad: 0.126059 Thermal: 0.000634 LR: 4.13e-06\n",
      "Epoch  22 [5050/10697 ( 47.2%)] Loss: 0.030870 L1: 0.018232 Grad: 0.126059 Thermal: 0.000634 LR: 4.13e-06\n",
      "Epoch  22 [5100/10697 ( 47.7%)] Loss: 0.027336 L1: 0.015742 Grad: 0.115655 Thermal: 0.000586 LR: 4.13e-06\n",
      "Epoch  22 [5100/10697 ( 47.7%)] Loss: 0.027336 L1: 0.015742 Grad: 0.115655 Thermal: 0.000586 LR: 4.13e-06\n",
      "Epoch  22 [5150/10697 ( 48.1%)] Loss: 0.033394 L1: 0.019329 Grad: 0.140323 Thermal: 0.000665 LR: 4.13e-06\n",
      "Epoch  22 [5150/10697 ( 48.1%)] Loss: 0.033394 L1: 0.019329 Grad: 0.140323 Thermal: 0.000665 LR: 4.13e-06\n",
      "Epoch  22 [5200/10697 ( 48.6%)] Loss: 0.023307 L1: 0.013415 Grad: 0.098747 Thermal: 0.000356 LR: 4.13e-06\n",
      "Epoch  22 [5200/10697 ( 48.6%)] Loss: 0.023307 L1: 0.013415 Grad: 0.098747 Thermal: 0.000356 LR: 4.13e-06\n",
      "Epoch  22 [5250/10697 ( 49.1%)] Loss: 0.026005 L1: 0.015303 Grad: 0.106809 Thermal: 0.000427 LR: 4.13e-06\n",
      "Epoch  22 [5250/10697 ( 49.1%)] Loss: 0.026005 L1: 0.015303 Grad: 0.106809 Thermal: 0.000427 LR: 4.13e-06\n",
      "Epoch  22 [5300/10697 ( 49.5%)] Loss: 0.031770 L1: 0.017915 Grad: 0.138272 Thermal: 0.000555 LR: 4.13e-06\n",
      "Epoch  22 [5300/10697 ( 49.5%)] Loss: 0.031770 L1: 0.017915 Grad: 0.138272 Thermal: 0.000555 LR: 4.13e-06\n",
      "Epoch  22 [5350/10697 ( 50.0%)] Loss: 0.017047 L1: 0.009932 Grad: 0.071026 Thermal: 0.000240 LR: 4.13e-06\n",
      "Epoch  22 [5350/10697 ( 50.0%)] Loss: 0.017047 L1: 0.009932 Grad: 0.071026 Thermal: 0.000240 LR: 4.13e-06\n",
      "Epoch  22 [5400/10697 ( 50.5%)] Loss: 0.028224 L1: 0.016487 Grad: 0.117134 Thermal: 0.000474 LR: 4.13e-06\n",
      "Epoch  22 [5400/10697 ( 50.5%)] Loss: 0.028224 L1: 0.016487 Grad: 0.117134 Thermal: 0.000474 LR: 4.13e-06\n",
      "Epoch  22 [5450/10697 ( 50.9%)] Loss: 0.025925 L1: 0.015184 Grad: 0.107124 Thermal: 0.000583 LR: 4.13e-06\n",
      "Epoch  22 [5450/10697 ( 50.9%)] Loss: 0.025925 L1: 0.015184 Grad: 0.107124 Thermal: 0.000583 LR: 4.13e-06\n",
      "Epoch  22 [5500/10697 ( 51.4%)] Loss: 0.018872 L1: 0.011164 Grad: 0.076956 Thermal: 0.000264 LR: 4.13e-06\n",
      "Epoch  22 [5500/10697 ( 51.4%)] Loss: 0.018872 L1: 0.011164 Grad: 0.076956 Thermal: 0.000264 LR: 4.13e-06\n",
      "Epoch  22 [5550/10697 ( 51.9%)] Loss: 0.030177 L1: 0.017888 Grad: 0.122582 Thermal: 0.000618 LR: 4.13e-06\n",
      "Epoch  22 [5550/10697 ( 51.9%)] Loss: 0.030177 L1: 0.017888 Grad: 0.122582 Thermal: 0.000618 LR: 4.13e-06\n",
      "Epoch  22 [5600/10697 ( 52.4%)] Loss: 0.023880 L1: 0.013430 Grad: 0.104329 Thermal: 0.000343 LR: 4.13e-06\n",
      "Epoch  22 [5600/10697 ( 52.4%)] Loss: 0.023880 L1: 0.013430 Grad: 0.104329 Thermal: 0.000343 LR: 4.13e-06\n",
      "Epoch  22 [5650/10697 ( 52.8%)] Loss: 0.020781 L1: 0.011893 Grad: 0.088723 Thermal: 0.000329 LR: 4.13e-06\n",
      "Epoch  22 [5650/10697 ( 52.8%)] Loss: 0.020781 L1: 0.011893 Grad: 0.088723 Thermal: 0.000329 LR: 4.13e-06\n",
      "Epoch  22 [5700/10697 ( 53.3%)] Loss: 0.020832 L1: 0.012063 Grad: 0.087549 Thermal: 0.000285 LR: 4.13e-06\n",
      "Epoch  22 [5700/10697 ( 53.3%)] Loss: 0.020832 L1: 0.012063 Grad: 0.087549 Thermal: 0.000285 LR: 4.13e-06\n",
      "Epoch  22 [5750/10697 ( 53.8%)] Loss: 0.026320 L1: 0.015654 Grad: 0.106417 Thermal: 0.000500 LR: 4.13e-06\n",
      "Epoch  22 [5750/10697 ( 53.8%)] Loss: 0.026320 L1: 0.015654 Grad: 0.106417 Thermal: 0.000500 LR: 4.13e-06\n",
      "Epoch  22 [5800/10697 ( 54.2%)] Loss: 0.022660 L1: 0.012936 Grad: 0.097040 Thermal: 0.000389 LR: 4.13e-06\n",
      "Epoch  22 [5800/10697 ( 54.2%)] Loss: 0.022660 L1: 0.012936 Grad: 0.097040 Thermal: 0.000389 LR: 4.13e-06\n",
      "Epoch  22 [5850/10697 ( 54.7%)] Loss: 0.024809 L1: 0.014304 Grad: 0.104824 Thermal: 0.000448 LR: 4.13e-06\n",
      "Epoch  22 [5850/10697 ( 54.7%)] Loss: 0.024809 L1: 0.014304 Grad: 0.104824 Thermal: 0.000448 LR: 4.13e-06\n",
      "Epoch  22 [5900/10697 ( 55.2%)] Loss: 0.025745 L1: 0.014820 Grad: 0.109048 Thermal: 0.000409 LR: 4.13e-06\n",
      "Epoch  22 [5900/10697 ( 55.2%)] Loss: 0.025745 L1: 0.014820 Grad: 0.109048 Thermal: 0.000409 LR: 4.13e-06\n",
      "Epoch  22 [5950/10697 ( 55.6%)] Loss: 0.023288 L1: 0.013806 Grad: 0.094638 Thermal: 0.000376 LR: 4.13e-06\n",
      "Epoch  22 [5950/10697 ( 55.6%)] Loss: 0.023288 L1: 0.013806 Grad: 0.094638 Thermal: 0.000376 LR: 4.13e-06\n",
      "Epoch  22 [6000/10697 ( 56.1%)] Loss: 0.030731 L1: 0.017968 Grad: 0.127354 Thermal: 0.000561 LR: 4.13e-06\n",
      "Epoch  22 [6000/10697 ( 56.1%)] Loss: 0.030731 L1: 0.017968 Grad: 0.127354 Thermal: 0.000561 LR: 4.13e-06\n",
      "Epoch  22 [6050/10697 ( 56.6%)] Loss: 0.026491 L1: 0.015137 Grad: 0.113312 Thermal: 0.000461 LR: 4.13e-06\n",
      "Epoch  22 [6050/10697 ( 56.6%)] Loss: 0.026491 L1: 0.015137 Grad: 0.113312 Thermal: 0.000461 LR: 4.13e-06\n",
      "Epoch  22 [6100/10697 ( 57.0%)] Loss: 0.023863 L1: 0.014264 Grad: 0.095795 Thermal: 0.000389 LR: 4.13e-06\n",
      "Epoch  22 [6100/10697 ( 57.0%)] Loss: 0.023863 L1: 0.014264 Grad: 0.095795 Thermal: 0.000389 LR: 4.13e-06\n",
      "Epoch  22 [6150/10697 ( 57.5%)] Loss: 0.028644 L1: 0.016763 Grad: 0.118551 Thermal: 0.000512 LR: 4.13e-06\n",
      "Epoch  22 [6150/10697 ( 57.5%)] Loss: 0.028644 L1: 0.016763 Grad: 0.118551 Thermal: 0.000512 LR: 4.13e-06\n",
      "Epoch  22 [6200/10697 ( 58.0%)] Loss: 0.027057 L1: 0.015988 Grad: 0.110463 Thermal: 0.000459 LR: 4.13e-06\n",
      "Epoch  22 [6200/10697 ( 58.0%)] Loss: 0.027057 L1: 0.015988 Grad: 0.110463 Thermal: 0.000459 LR: 4.13e-06\n",
      "Epoch  22 [6250/10697 ( 58.4%)] Loss: 0.030638 L1: 0.017411 Grad: 0.131972 Thermal: 0.000583 LR: 4.13e-06\n",
      "Epoch  22 [6250/10697 ( 58.4%)] Loss: 0.030638 L1: 0.017411 Grad: 0.131972 Thermal: 0.000583 LR: 4.13e-06\n",
      "Epoch  22 [6300/10697 ( 58.9%)] Loss: 0.028454 L1: 0.016664 Grad: 0.117650 Thermal: 0.000504 LR: 4.13e-06\n",
      "Epoch  22 [6300/10697 ( 58.9%)] Loss: 0.028454 L1: 0.016664 Grad: 0.117650 Thermal: 0.000504 LR: 4.13e-06\n",
      "Epoch  22 [6350/10697 ( 59.4%)] Loss: 0.025605 L1: 0.015035 Grad: 0.105504 Thermal: 0.000397 LR: 4.13e-06\n",
      "Epoch  22 [6350/10697 ( 59.4%)] Loss: 0.025605 L1: 0.015035 Grad: 0.105504 Thermal: 0.000397 LR: 4.13e-06\n",
      "Epoch  22 [6400/10697 ( 59.8%)] Loss: 0.025003 L1: 0.014458 Grad: 0.105254 Thermal: 0.000386 LR: 4.13e-06\n",
      "Epoch  22 [6400/10697 ( 59.8%)] Loss: 0.025003 L1: 0.014458 Grad: 0.105254 Thermal: 0.000386 LR: 4.13e-06\n",
      "Epoch  22 [6450/10697 ( 60.3%)] Loss: 0.026992 L1: 0.015603 Grad: 0.113642 Thermal: 0.000493 LR: 4.13e-06\n",
      "Epoch  22 [6450/10697 ( 60.3%)] Loss: 0.026992 L1: 0.015603 Grad: 0.113642 Thermal: 0.000493 LR: 4.13e-06\n",
      "Epoch  22 [6500/10697 ( 60.8%)] Loss: 0.020704 L1: 0.012111 Grad: 0.085760 Thermal: 0.000339 LR: 4.13e-06\n",
      "Epoch  22 [6500/10697 ( 60.8%)] Loss: 0.020704 L1: 0.012111 Grad: 0.085760 Thermal: 0.000339 LR: 4.13e-06\n",
      "Epoch  22 [6550/10697 ( 61.2%)] Loss: 0.028101 L1: 0.016535 Grad: 0.115382 Thermal: 0.000553 LR: 4.13e-06\n",
      "Epoch  22 [6550/10697 ( 61.2%)] Loss: 0.028101 L1: 0.016535 Grad: 0.115382 Thermal: 0.000553 LR: 4.13e-06\n",
      "Epoch  22 [6600/10697 ( 61.7%)] Loss: 0.027200 L1: 0.015903 Grad: 0.112697 Thermal: 0.000561 LR: 4.13e-06\n",
      "Epoch  22 [6600/10697 ( 61.7%)] Loss: 0.027200 L1: 0.015903 Grad: 0.112697 Thermal: 0.000561 LR: 4.13e-06\n",
      "Epoch  22 [6650/10697 ( 62.2%)] Loss: 0.026058 L1: 0.015349 Grad: 0.106857 Thermal: 0.000452 LR: 4.13e-06\n",
      "Epoch  22 [6650/10697 ( 62.2%)] Loss: 0.026058 L1: 0.015349 Grad: 0.106857 Thermal: 0.000452 LR: 4.13e-06\n",
      "Epoch  22 [6700/10697 ( 62.6%)] Loss: 0.028295 L1: 0.015968 Grad: 0.123018 Thermal: 0.000500 LR: 4.13e-06\n",
      "Epoch  22 [6700/10697 ( 62.6%)] Loss: 0.028295 L1: 0.015968 Grad: 0.123018 Thermal: 0.000500 LR: 4.13e-06\n",
      "Epoch  22 [6750/10697 ( 63.1%)] Loss: 0.031482 L1: 0.018087 Grad: 0.133652 Thermal: 0.000603 LR: 4.13e-06\n",
      "Epoch  22 [6750/10697 ( 63.1%)] Loss: 0.031482 L1: 0.018087 Grad: 0.133652 Thermal: 0.000603 LR: 4.13e-06\n",
      "Epoch  22 [6800/10697 ( 63.6%)] Loss: 0.027039 L1: 0.016330 Grad: 0.106852 Thermal: 0.000464 LR: 4.13e-06\n",
      "Epoch  22 [6800/10697 ( 63.6%)] Loss: 0.027039 L1: 0.016330 Grad: 0.106852 Thermal: 0.000464 LR: 4.13e-06\n",
      "Epoch  22 [6850/10697 ( 64.0%)] Loss: 0.021542 L1: 0.012158 Grad: 0.093683 Thermal: 0.000310 LR: 4.13e-06\n",
      "Epoch  22 [6850/10697 ( 64.0%)] Loss: 0.021542 L1: 0.012158 Grad: 0.093683 Thermal: 0.000310 LR: 4.13e-06\n",
      "Epoch  22 [6900/10697 ( 64.5%)] Loss: 0.027489 L1: 0.015735 Grad: 0.117287 Thermal: 0.000502 LR: 4.13e-06\n",
      "Epoch  22 [6900/10697 ( 64.5%)] Loss: 0.027489 L1: 0.015735 Grad: 0.117287 Thermal: 0.000502 LR: 4.13e-06\n",
      "Epoch  22 [6950/10697 ( 65.0%)] Loss: 0.022862 L1: 0.013575 Grad: 0.092671 Thermal: 0.000406 LR: 4.13e-06\n",
      "Epoch  22 [6950/10697 ( 65.0%)] Loss: 0.022862 L1: 0.013575 Grad: 0.092671 Thermal: 0.000406 LR: 4.13e-06\n",
      "Epoch  22 [7000/10697 ( 65.4%)] Loss: 0.026974 L1: 0.015959 Grad: 0.109923 Thermal: 0.000467 LR: 4.13e-06\n",
      "Epoch  22 [7000/10697 ( 65.4%)] Loss: 0.026974 L1: 0.015959 Grad: 0.109923 Thermal: 0.000467 LR: 4.13e-06\n",
      "Epoch  22 [7050/10697 ( 65.9%)] Loss: 0.024240 L1: 0.013972 Grad: 0.102501 Thermal: 0.000372 LR: 4.13e-06\n",
      "Epoch  22 [7050/10697 ( 65.9%)] Loss: 0.024240 L1: 0.013972 Grad: 0.102501 Thermal: 0.000372 LR: 4.13e-06\n",
      "Epoch  22 [7100/10697 ( 66.4%)] Loss: 0.021604 L1: 0.012318 Grad: 0.092709 Thermal: 0.000298 LR: 4.13e-06\n",
      "Epoch  22 [7100/10697 ( 66.4%)] Loss: 0.021604 L1: 0.012318 Grad: 0.092709 Thermal: 0.000298 LR: 4.13e-06\n",
      "Epoch  22 [7150/10697 ( 66.8%)] Loss: 0.031730 L1: 0.018859 Grad: 0.128385 Thermal: 0.000656 LR: 4.13e-06\n",
      "Epoch  22 [7150/10697 ( 66.8%)] Loss: 0.031730 L1: 0.018859 Grad: 0.128385 Thermal: 0.000656 LR: 4.13e-06\n",
      "Epoch  22 [7200/10697 ( 67.3%)] Loss: 0.022939 L1: 0.012806 Grad: 0.101156 Thermal: 0.000354 LR: 4.13e-06\n",
      "Epoch  22 [7200/10697 ( 67.3%)] Loss: 0.022939 L1: 0.012806 Grad: 0.101156 Thermal: 0.000354 LR: 4.13e-06\n",
      "Epoch  22 [7250/10697 ( 67.8%)] Loss: 0.021572 L1: 0.012348 Grad: 0.092085 Thermal: 0.000298 LR: 4.13e-06\n",
      "Epoch  22 [7250/10697 ( 67.8%)] Loss: 0.021572 L1: 0.012348 Grad: 0.092085 Thermal: 0.000298 LR: 4.13e-06\n",
      "Epoch  22 [7300/10697 ( 68.2%)] Loss: 0.026595 L1: 0.015446 Grad: 0.111266 Thermal: 0.000439 LR: 4.13e-06\n",
      "Epoch  22 [7300/10697 ( 68.2%)] Loss: 0.026595 L1: 0.015446 Grad: 0.111266 Thermal: 0.000439 LR: 4.13e-06\n",
      "Epoch  22 [7350/10697 ( 68.7%)] Loss: 0.026886 L1: 0.015617 Grad: 0.112454 Thermal: 0.000473 LR: 4.13e-06\n",
      "Epoch  22 [7350/10697 ( 68.7%)] Loss: 0.026886 L1: 0.015617 Grad: 0.112454 Thermal: 0.000473 LR: 4.13e-06\n",
      "Epoch  22 [7400/10697 ( 69.2%)] Loss: 0.027604 L1: 0.015824 Grad: 0.117544 Thermal: 0.000503 LR: 4.13e-06\n",
      "Epoch  22 [7400/10697 ( 69.2%)] Loss: 0.027604 L1: 0.015824 Grad: 0.117544 Thermal: 0.000503 LR: 4.13e-06\n",
      "Epoch  22 [7450/10697 ( 69.6%)] Loss: 0.024836 L1: 0.014076 Grad: 0.107407 Thermal: 0.000390 LR: 4.13e-06\n",
      "Epoch  22 [7450/10697 ( 69.6%)] Loss: 0.024836 L1: 0.014076 Grad: 0.107407 Thermal: 0.000390 LR: 4.13e-06\n",
      "Epoch  22 [7500/10697 ( 70.1%)] Loss: 0.025120 L1: 0.014576 Grad: 0.105247 Thermal: 0.000388 LR: 4.13e-06\n",
      "Epoch  22 [7500/10697 ( 70.1%)] Loss: 0.025120 L1: 0.014576 Grad: 0.105247 Thermal: 0.000388 LR: 4.13e-06\n",
      "Epoch  22 [7550/10697 ( 70.6%)] Loss: 0.021591 L1: 0.012619 Grad: 0.089569 Thermal: 0.000304 LR: 4.13e-06\n",
      "Epoch  22 [7550/10697 ( 70.6%)] Loss: 0.021591 L1: 0.012619 Grad: 0.089569 Thermal: 0.000304 LR: 4.13e-06\n",
      "Epoch  22 [7600/10697 ( 71.0%)] Loss: 0.027509 L1: 0.015865 Grad: 0.116184 Thermal: 0.000507 LR: 4.13e-06\n",
      "Epoch  22 [7600/10697 ( 71.0%)] Loss: 0.027509 L1: 0.015865 Grad: 0.116184 Thermal: 0.000507 LR: 4.13e-06\n",
      "Epoch  22 [7650/10697 ( 71.5%)] Loss: 0.022552 L1: 0.013092 Grad: 0.094405 Thermal: 0.000382 LR: 4.13e-06\n",
      "Epoch  22 [7650/10697 ( 71.5%)] Loss: 0.022552 L1: 0.013092 Grad: 0.094405 Thermal: 0.000382 LR: 4.13e-06\n",
      "Epoch  22 [7700/10697 ( 72.0%)] Loss: 0.026455 L1: 0.015568 Grad: 0.108635 Thermal: 0.000463 LR: 4.13e-06\n",
      "Epoch  22 [7700/10697 ( 72.0%)] Loss: 0.026455 L1: 0.015568 Grad: 0.108635 Thermal: 0.000463 LR: 4.13e-06\n",
      "Epoch  22 [7750/10697 ( 72.5%)] Loss: 0.026362 L1: 0.015520 Grad: 0.108190 Thermal: 0.000470 LR: 4.13e-06\n",
      "Epoch  22 [7750/10697 ( 72.5%)] Loss: 0.026362 L1: 0.015520 Grad: 0.108190 Thermal: 0.000470 LR: 4.13e-06\n",
      "Epoch  22 [7800/10697 ( 72.9%)] Loss: 0.025102 L1: 0.014915 Grad: 0.101677 Thermal: 0.000384 LR: 4.13e-06\n",
      "Epoch  22 [7800/10697 ( 72.9%)] Loss: 0.025102 L1: 0.014915 Grad: 0.101677 Thermal: 0.000384 LR: 4.13e-06\n",
      "Epoch  22 [7850/10697 ( 73.4%)] Loss: 0.024212 L1: 0.014179 Grad: 0.100146 Thermal: 0.000357 LR: 4.13e-06\n",
      "Epoch  22 [7850/10697 ( 73.4%)] Loss: 0.024212 L1: 0.014179 Grad: 0.100146 Thermal: 0.000357 LR: 4.13e-06\n",
      "Epoch  22 [7900/10697 ( 73.9%)] Loss: 0.024179 L1: 0.014531 Grad: 0.096289 Thermal: 0.000393 LR: 4.13e-06\n",
      "Epoch  22 [7900/10697 ( 73.9%)] Loss: 0.024179 L1: 0.014531 Grad: 0.096289 Thermal: 0.000393 LR: 4.13e-06\n",
      "Epoch  22 [7950/10697 ( 74.3%)] Loss: 0.027459 L1: 0.015915 Grad: 0.115191 Thermal: 0.000508 LR: 4.13e-06\n",
      "Epoch  22 [7950/10697 ( 74.3%)] Loss: 0.027459 L1: 0.015915 Grad: 0.115191 Thermal: 0.000508 LR: 4.13e-06\n",
      "Epoch  22 [8000/10697 ( 74.8%)] Loss: 0.022349 L1: 0.013078 Grad: 0.092539 Thermal: 0.000342 LR: 4.13e-06\n",
      "Epoch  22 [8000/10697 ( 74.8%)] Loss: 0.022349 L1: 0.013078 Grad: 0.092539 Thermal: 0.000342 LR: 4.13e-06\n",
      "Epoch  22 [8050/10697 ( 75.3%)] Loss: 0.024081 L1: 0.014197 Grad: 0.098656 Thermal: 0.000368 LR: 4.13e-06\n",
      "Epoch  22 [8050/10697 ( 75.3%)] Loss: 0.024081 L1: 0.014197 Grad: 0.098656 Thermal: 0.000368 LR: 4.13e-06\n",
      "Epoch  22 [8100/10697 ( 75.7%)] Loss: 0.020741 L1: 0.012011 Grad: 0.087135 Thermal: 0.000331 LR: 4.13e-06\n",
      "Epoch  22 [8100/10697 ( 75.7%)] Loss: 0.020741 L1: 0.012011 Grad: 0.087135 Thermal: 0.000331 LR: 4.13e-06\n",
      "Epoch  22 [8150/10697 ( 76.2%)] Loss: 0.026597 L1: 0.015161 Grad: 0.114128 Thermal: 0.000454 LR: 4.13e-06\n",
      "Epoch  22 [8150/10697 ( 76.2%)] Loss: 0.026597 L1: 0.015161 Grad: 0.114128 Thermal: 0.000454 LR: 4.13e-06\n",
      "Epoch  22 [8200/10697 ( 76.7%)] Loss: 0.028898 L1: 0.016743 Grad: 0.121281 Thermal: 0.000526 LR: 4.13e-06\n",
      "Epoch  22 [8200/10697 ( 76.7%)] Loss: 0.028898 L1: 0.016743 Grad: 0.121281 Thermal: 0.000526 LR: 4.13e-06\n",
      "Epoch  22 [8250/10697 ( 77.1%)] Loss: 0.022285 L1: 0.012666 Grad: 0.096037 Thermal: 0.000317 LR: 4.13e-06\n",
      "Epoch  22 [8250/10697 ( 77.1%)] Loss: 0.022285 L1: 0.012666 Grad: 0.096037 Thermal: 0.000317 LR: 4.13e-06\n",
      "Epoch  22 [8300/10697 ( 77.6%)] Loss: 0.023417 L1: 0.013738 Grad: 0.096597 Thermal: 0.000378 LR: 4.13e-06\n",
      "Epoch  22 [8300/10697 ( 77.6%)] Loss: 0.023417 L1: 0.013738 Grad: 0.096597 Thermal: 0.000378 LR: 4.13e-06\n",
      "Epoch  22 [8350/10697 ( 78.1%)] Loss: 0.024062 L1: 0.014347 Grad: 0.096959 Thermal: 0.000384 LR: 4.13e-06\n",
      "Epoch  22 [8350/10697 ( 78.1%)] Loss: 0.024062 L1: 0.014347 Grad: 0.096959 Thermal: 0.000384 LR: 4.13e-06\n",
      "Epoch  22 [8400/10697 ( 78.5%)] Loss: 0.020009 L1: 0.011696 Grad: 0.082985 Thermal: 0.000280 LR: 4.13e-06\n",
      "Epoch  22 [8400/10697 ( 78.5%)] Loss: 0.020009 L1: 0.011696 Grad: 0.082985 Thermal: 0.000280 LR: 4.13e-06\n",
      "Epoch  22 [8450/10697 ( 79.0%)] Loss: 0.028280 L1: 0.016700 Grad: 0.115529 Thermal: 0.000532 LR: 4.13e-06\n",
      "Epoch  22 [8450/10697 ( 79.0%)] Loss: 0.028280 L1: 0.016700 Grad: 0.115529 Thermal: 0.000532 LR: 4.13e-06\n",
      "Epoch  22 [8500/10697 ( 79.5%)] Loss: 0.022897 L1: 0.013310 Grad: 0.095691 Thermal: 0.000357 LR: 4.13e-06\n",
      "Epoch  22 [8500/10697 ( 79.5%)] Loss: 0.022897 L1: 0.013310 Grad: 0.095691 Thermal: 0.000357 LR: 4.13e-06\n",
      "Epoch  22 [8550/10697 ( 79.9%)] Loss: 0.028877 L1: 0.017209 Grad: 0.116425 Thermal: 0.000509 LR: 4.13e-06\n",
      "Epoch  22 [8550/10697 ( 79.9%)] Loss: 0.028877 L1: 0.017209 Grad: 0.116425 Thermal: 0.000509 LR: 4.13e-06\n",
      "Epoch  22 [8600/10697 ( 80.4%)] Loss: 0.023282 L1: 0.013827 Grad: 0.094359 Thermal: 0.000371 LR: 4.13e-06\n",
      "Epoch  22 [8600/10697 ( 80.4%)] Loss: 0.023282 L1: 0.013827 Grad: 0.094359 Thermal: 0.000371 LR: 4.13e-06\n",
      "Epoch  22 [8650/10697 ( 80.9%)] Loss: 0.020240 L1: 0.011410 Grad: 0.088142 Thermal: 0.000299 LR: 4.13e-06\n",
      "Epoch  22 [8650/10697 ( 80.9%)] Loss: 0.020240 L1: 0.011410 Grad: 0.088142 Thermal: 0.000299 LR: 4.13e-06\n",
      "Epoch  22 [8700/10697 ( 81.3%)] Loss: 0.033399 L1: 0.019858 Grad: 0.135022 Thermal: 0.000786 LR: 4.13e-06\n",
      "Epoch  22 [8700/10697 ( 81.3%)] Loss: 0.033399 L1: 0.019858 Grad: 0.135022 Thermal: 0.000786 LR: 4.13e-06\n",
      "Epoch  22 [8750/10697 ( 81.8%)] Loss: 0.026827 L1: 0.015835 Grad: 0.109689 Thermal: 0.000461 LR: 4.13e-06\n",
      "Epoch  22 [8750/10697 ( 81.8%)] Loss: 0.026827 L1: 0.015835 Grad: 0.109689 Thermal: 0.000461 LR: 4.13e-06\n",
      "Epoch  22 [8800/10697 ( 82.3%)] Loss: 0.020585 L1: 0.011811 Grad: 0.087607 Thermal: 0.000283 LR: 4.13e-06\n",
      "Epoch  22 [8800/10697 ( 82.3%)] Loss: 0.020585 L1: 0.011811 Grad: 0.087607 Thermal: 0.000283 LR: 4.13e-06\n",
      "Epoch  22 [8850/10697 ( 82.7%)] Loss: 0.035037 L1: 0.020844 Grad: 0.141499 Thermal: 0.000861 LR: 4.13e-06\n",
      "Epoch  22 [8850/10697 ( 82.7%)] Loss: 0.035037 L1: 0.020844 Grad: 0.141499 Thermal: 0.000861 LR: 4.13e-06\n",
      "Epoch  22 [8900/10697 ( 83.2%)] Loss: 0.022223 L1: 0.012843 Grad: 0.093631 Thermal: 0.000327 LR: 4.13e-06\n",
      "Epoch  22 [8900/10697 ( 83.2%)] Loss: 0.022223 L1: 0.012843 Grad: 0.093631 Thermal: 0.000327 LR: 4.13e-06\n",
      "Epoch  22 [8950/10697 ( 83.7%)] Loss: 0.031234 L1: 0.018175 Grad: 0.130280 Thermal: 0.000615 LR: 4.13e-06\n",
      "Epoch  22 [8950/10697 ( 83.7%)] Loss: 0.031234 L1: 0.018175 Grad: 0.130280 Thermal: 0.000615 LR: 4.13e-06\n",
      "Epoch  22 [9000/10697 ( 84.1%)] Loss: 0.030230 L1: 0.018018 Grad: 0.121833 Thermal: 0.000562 LR: 4.13e-06\n",
      "Epoch  22 [9000/10697 ( 84.1%)] Loss: 0.030230 L1: 0.018018 Grad: 0.121833 Thermal: 0.000562 LR: 4.13e-06\n",
      "Epoch  22 [9050/10697 ( 84.6%)] Loss: 0.030702 L1: 0.017831 Grad: 0.128408 Thermal: 0.000590 LR: 4.13e-06\n",
      "Epoch  22 [9050/10697 ( 84.6%)] Loss: 0.030702 L1: 0.017831 Grad: 0.128408 Thermal: 0.000590 LR: 4.13e-06\n",
      "Epoch  22 [9100/10697 ( 85.1%)] Loss: 0.025985 L1: 0.015127 Grad: 0.108375 Thermal: 0.000426 LR: 4.13e-06\n",
      "Epoch  22 [9100/10697 ( 85.1%)] Loss: 0.025985 L1: 0.015127 Grad: 0.108375 Thermal: 0.000426 LR: 4.13e-06\n",
      "Epoch  22 [9150/10697 ( 85.5%)] Loss: 0.024968 L1: 0.014514 Grad: 0.104328 Thermal: 0.000424 LR: 4.13e-06\n",
      "Epoch  22 [9150/10697 ( 85.5%)] Loss: 0.024968 L1: 0.014514 Grad: 0.104328 Thermal: 0.000424 LR: 4.13e-06\n",
      "Epoch  22 [9200/10697 ( 86.0%)] Loss: 0.024609 L1: 0.014188 Grad: 0.104011 Thermal: 0.000386 LR: 4.13e-06\n",
      "Epoch  22 [9200/10697 ( 86.0%)] Loss: 0.024609 L1: 0.014188 Grad: 0.104011 Thermal: 0.000386 LR: 4.13e-06\n",
      "Epoch  22 [9250/10697 ( 86.5%)] Loss: 0.032555 L1: 0.018840 Grad: 0.136839 Thermal: 0.000628 LR: 4.13e-06\n",
      "Epoch  22 [9250/10697 ( 86.5%)] Loss: 0.032555 L1: 0.018840 Grad: 0.136839 Thermal: 0.000628 LR: 4.13e-06\n",
      "Epoch  22 [9300/10697 ( 86.9%)] Loss: 0.021752 L1: 0.012769 Grad: 0.089662 Thermal: 0.000328 LR: 4.13e-06\n",
      "Epoch  22 [9300/10697 ( 86.9%)] Loss: 0.021752 L1: 0.012769 Grad: 0.089662 Thermal: 0.000328 LR: 4.13e-06\n",
      "Epoch  22 [9350/10697 ( 87.4%)] Loss: 0.024394 L1: 0.014430 Grad: 0.099445 Thermal: 0.000387 LR: 4.13e-06\n",
      "Epoch  22 [9350/10697 ( 87.4%)] Loss: 0.024394 L1: 0.014430 Grad: 0.099445 Thermal: 0.000387 LR: 4.13e-06\n",
      "Epoch  22 [9400/10697 ( 87.9%)] Loss: 0.028374 L1: 0.016296 Grad: 0.120555 Thermal: 0.000465 LR: 4.13e-06\n",
      "Epoch  22 [9400/10697 ( 87.9%)] Loss: 0.028374 L1: 0.016296 Grad: 0.120555 Thermal: 0.000465 LR: 4.13e-06\n",
      "Epoch  22 [9450/10697 ( 88.3%)] Loss: 0.022531 L1: 0.012981 Grad: 0.095342 Thermal: 0.000329 LR: 4.13e-06\n",
      "Epoch  22 [9450/10697 ( 88.3%)] Loss: 0.022531 L1: 0.012981 Grad: 0.095342 Thermal: 0.000329 LR: 4.13e-06\n",
      "Epoch  22 [9500/10697 ( 88.8%)] Loss: 0.026943 L1: 0.015543 Grad: 0.113774 Thermal: 0.000453 LR: 4.13e-06\n",
      "Epoch  22 [9500/10697 ( 88.8%)] Loss: 0.026943 L1: 0.015543 Grad: 0.113774 Thermal: 0.000453 LR: 4.13e-06\n",
      "Epoch  22 [9550/10697 ( 89.3%)] Loss: 0.030525 L1: 0.017654 Grad: 0.128435 Thermal: 0.000558 LR: 4.13e-06\n",
      "Epoch  22 [9550/10697 ( 89.3%)] Loss: 0.030525 L1: 0.017654 Grad: 0.128435 Thermal: 0.000558 LR: 4.13e-06\n",
      "Epoch  22 [9600/10697 ( 89.7%)] Loss: 0.031198 L1: 0.018229 Grad: 0.129365 Thermal: 0.000642 LR: 4.13e-06\n",
      "Epoch  22 [9600/10697 ( 89.7%)] Loss: 0.031198 L1: 0.018229 Grad: 0.129365 Thermal: 0.000642 LR: 4.13e-06\n",
      "Epoch  22 [9650/10697 ( 90.2%)] Loss: 0.030462 L1: 0.017992 Grad: 0.124419 Thermal: 0.000568 LR: 4.13e-06\n",
      "Epoch  22 [9650/10697 ( 90.2%)] Loss: 0.030462 L1: 0.017992 Grad: 0.124419 Thermal: 0.000568 LR: 4.13e-06\n",
      "Epoch  22 [9700/10697 ( 90.7%)] Loss: 0.030539 L1: 0.017372 Grad: 0.131403 Thermal: 0.000550 LR: 4.13e-06\n",
      "Epoch  22 [9700/10697 ( 90.7%)] Loss: 0.030539 L1: 0.017372 Grad: 0.131403 Thermal: 0.000550 LR: 4.13e-06\n",
      "Epoch  22 [9750/10697 ( 91.1%)] Loss: 0.021774 L1: 0.012579 Grad: 0.091796 Thermal: 0.000312 LR: 4.13e-06\n",
      "Epoch  22 [9750/10697 ( 91.1%)] Loss: 0.021774 L1: 0.012579 Grad: 0.091796 Thermal: 0.000312 LR: 4.13e-06\n",
      "Epoch  22 [9800/10697 ( 91.6%)] Loss: 0.025965 L1: 0.014806 Grad: 0.111383 Thermal: 0.000427 LR: 4.13e-06\n",
      "Epoch  22 [9800/10697 ( 91.6%)] Loss: 0.025965 L1: 0.014806 Grad: 0.111383 Thermal: 0.000427 LR: 4.13e-06\n",
      "Epoch  22 [9850/10697 ( 92.1%)] Loss: 0.027266 L1: 0.016352 Grad: 0.108906 Thermal: 0.000485 LR: 4.13e-06\n",
      "Epoch  22 [9850/10697 ( 92.1%)] Loss: 0.027266 L1: 0.016352 Grad: 0.108906 Thermal: 0.000485 LR: 4.13e-06\n",
      "Epoch  22 [9900/10697 ( 92.5%)] Loss: 0.028624 L1: 0.016626 Grad: 0.119702 Thermal: 0.000545 LR: 4.13e-06\n",
      "Epoch  22 [9900/10697 ( 92.5%)] Loss: 0.028624 L1: 0.016626 Grad: 0.119702 Thermal: 0.000545 LR: 4.13e-06\n",
      "Epoch  22 [9950/10697 ( 93.0%)] Loss: 0.022675 L1: 0.013213 Grad: 0.094436 Thermal: 0.000358 LR: 4.13e-06\n",
      "Epoch  22 [9950/10697 ( 93.0%)] Loss: 0.022675 L1: 0.013213 Grad: 0.094436 Thermal: 0.000358 LR: 4.13e-06\n",
      "Epoch  22 [10000/10697 ( 93.5%)] Loss: 0.029371 L1: 0.017389 Grad: 0.119550 Thermal: 0.000549 LR: 4.13e-06\n",
      "Epoch  22 [10000/10697 ( 93.5%)] Loss: 0.029371 L1: 0.017389 Grad: 0.119550 Thermal: 0.000549 LR: 4.13e-06\n",
      "Epoch  22 [10050/10697 ( 94.0%)] Loss: 0.030027 L1: 0.017600 Grad: 0.123987 Thermal: 0.000569 LR: 4.13e-06\n",
      "Epoch  22 [10050/10697 ( 94.0%)] Loss: 0.030027 L1: 0.017600 Grad: 0.123987 Thermal: 0.000569 LR: 4.13e-06\n",
      "Epoch  22 [10100/10697 ( 94.4%)] Loss: 0.021222 L1: 0.012195 Grad: 0.090121 Thermal: 0.000296 LR: 4.13e-06\n",
      "Epoch  22 [10100/10697 ( 94.4%)] Loss: 0.021222 L1: 0.012195 Grad: 0.090121 Thermal: 0.000296 LR: 4.13e-06\n",
      "Epoch  22 [10150/10697 ( 94.9%)] Loss: 0.032152 L1: 0.017826 Grad: 0.142980 Thermal: 0.000560 LR: 4.13e-06\n",
      "Epoch  22 [10150/10697 ( 94.9%)] Loss: 0.032152 L1: 0.017826 Grad: 0.142980 Thermal: 0.000560 LR: 4.13e-06\n",
      "Epoch  22 [10200/10697 ( 95.4%)] Loss: 0.024969 L1: 0.014504 Grad: 0.104440 Thermal: 0.000416 LR: 4.13e-06\n",
      "Epoch  22 [10200/10697 ( 95.4%)] Loss: 0.024969 L1: 0.014504 Grad: 0.104440 Thermal: 0.000416 LR: 4.13e-06\n",
      "Epoch  22 [10250/10697 ( 95.8%)] Loss: 0.027073 L1: 0.015746 Grad: 0.113016 Thermal: 0.000496 LR: 4.13e-06\n",
      "Epoch  22 [10250/10697 ( 95.8%)] Loss: 0.027073 L1: 0.015746 Grad: 0.113016 Thermal: 0.000496 LR: 4.13e-06\n",
      "Epoch  22 [10300/10697 ( 96.3%)] Loss: 0.023263 L1: 0.013467 Grad: 0.097781 Thermal: 0.000356 LR: 4.13e-06\n",
      "Epoch  22 [10300/10697 ( 96.3%)] Loss: 0.023263 L1: 0.013467 Grad: 0.097781 Thermal: 0.000356 LR: 4.13e-06\n",
      "Epoch  22 [10350/10697 ( 96.8%)] Loss: 0.029886 L1: 0.017673 Grad: 0.121773 Thermal: 0.000707 LR: 4.13e-06\n",
      "Epoch  22 [10350/10697 ( 96.8%)] Loss: 0.029886 L1: 0.017673 Grad: 0.121773 Thermal: 0.000707 LR: 4.13e-06\n",
      "Epoch  22 [10400/10697 ( 97.2%)] Loss: 0.031060 L1: 0.018112 Grad: 0.129184 Thermal: 0.000590 LR: 4.13e-06\n",
      "Epoch  22 [10400/10697 ( 97.2%)] Loss: 0.031060 L1: 0.018112 Grad: 0.129184 Thermal: 0.000590 LR: 4.13e-06\n",
      "Epoch  22 [10450/10697 ( 97.7%)] Loss: 0.027808 L1: 0.016515 Grad: 0.112667 Thermal: 0.000519 LR: 4.13e-06\n",
      "Epoch  22 [10450/10697 ( 97.7%)] Loss: 0.027808 L1: 0.016515 Grad: 0.112667 Thermal: 0.000519 LR: 4.13e-06\n",
      "Epoch  22 [10500/10697 ( 98.2%)] Loss: 0.025143 L1: 0.014807 Grad: 0.103165 Thermal: 0.000394 LR: 4.13e-06\n",
      "Epoch  22 [10500/10697 ( 98.2%)] Loss: 0.025143 L1: 0.014807 Grad: 0.103165 Thermal: 0.000394 LR: 4.13e-06\n",
      "Epoch  22 [10550/10697 ( 98.6%)] Loss: 0.027412 L1: 0.016188 Grad: 0.111999 Thermal: 0.000488 LR: 4.13e-06\n",
      "Epoch  22 [10550/10697 ( 98.6%)] Loss: 0.027412 L1: 0.016188 Grad: 0.111999 Thermal: 0.000488 LR: 4.13e-06\n",
      "Epoch  22 [10600/10697 ( 99.1%)] Loss: 0.026969 L1: 0.015950 Grad: 0.109934 Thermal: 0.000501 LR: 4.13e-06\n",
      "Epoch  22 [10600/10697 ( 99.1%)] Loss: 0.026969 L1: 0.015950 Grad: 0.109934 Thermal: 0.000501 LR: 4.13e-06\n",
      "Epoch  22 [10650/10697 ( 99.6%)] Loss: 0.025407 L1: 0.015267 Grad: 0.101158 Thermal: 0.000471 LR: 4.13e-06\n",
      "Epoch  22 [10650/10697 ( 99.6%)] Loss: 0.025407 L1: 0.015267 Grad: 0.101158 Thermal: 0.000471 LR: 4.13e-06\n",
      "Epoch  22 Summary: Loss=0.026319 (L1:0.0154, Grad:0.1095, Thermal:0.0005) Val_PSNR=0.00dB Best=33.92dB Time=83.6min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  22 Summary: Loss=0.026319 (L1:0.0154, Grad:0.1095, Thermal:0.0005) Val_PSNR=0.00dB Best=33.92dB Time=83.6min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  23 [   0/10697 (  0.0%)] Loss: 0.026846 L1: 0.015798 Grad: 0.110253 Thermal: 0.000443 LR: 4.06e-06\n",
      "Epoch  23 [   0/10697 (  0.0%)] Loss: 0.026846 L1: 0.015798 Grad: 0.110253 Thermal: 0.000443 LR: 4.06e-06\n",
      "Epoch  23 [  50/10697 (  0.5%)] Loss: 0.028629 L1: 0.016470 Grad: 0.121295 Thermal: 0.000600 LR: 4.06e-06\n",
      "Epoch  23 [  50/10697 (  0.5%)] Loss: 0.028629 L1: 0.016470 Grad: 0.121295 Thermal: 0.000600 LR: 4.06e-06\n",
      "Epoch  23 [ 100/10697 (  0.9%)] Loss: 0.031593 L1: 0.019139 Grad: 0.124156 Thermal: 0.000766 LR: 4.06e-06\n",
      "Epoch  23 [ 100/10697 (  0.9%)] Loss: 0.031593 L1: 0.019139 Grad: 0.124156 Thermal: 0.000766 LR: 4.06e-06\n",
      "Epoch  23 [ 150/10697 (  1.4%)] Loss: 0.030909 L1: 0.017670 Grad: 0.132096 Thermal: 0.000600 LR: 4.06e-06\n",
      "Epoch  23 [ 150/10697 (  1.4%)] Loss: 0.030909 L1: 0.017670 Grad: 0.132096 Thermal: 0.000600 LR: 4.06e-06\n",
      "Epoch  23 [ 200/10697 (  1.9%)] Loss: 0.021169 L1: 0.012570 Grad: 0.085825 Thermal: 0.000324 LR: 4.06e-06\n",
      "Epoch  23 [ 200/10697 (  1.9%)] Loss: 0.021169 L1: 0.012570 Grad: 0.085825 Thermal: 0.000324 LR: 4.06e-06\n",
      "Epoch  23 [ 250/10697 (  2.3%)] Loss: 0.025785 L1: 0.015192 Grad: 0.105709 Thermal: 0.000451 LR: 4.06e-06\n",
      "Epoch  23 [ 250/10697 (  2.3%)] Loss: 0.025785 L1: 0.015192 Grad: 0.105709 Thermal: 0.000451 LR: 4.06e-06\n",
      "Epoch  23 [ 300/10697 (  2.8%)] Loss: 0.029341 L1: 0.017652 Grad: 0.116606 Thermal: 0.000568 LR: 4.06e-06\n",
      "Epoch  23 [ 300/10697 (  2.8%)] Loss: 0.029341 L1: 0.017652 Grad: 0.116606 Thermal: 0.000568 LR: 4.06e-06\n",
      "Epoch  23 [ 350/10697 (  3.3%)] Loss: 0.027853 L1: 0.016669 Grad: 0.111585 Thermal: 0.000507 LR: 4.06e-06\n",
      "Epoch  23 [ 350/10697 (  3.3%)] Loss: 0.027853 L1: 0.016669 Grad: 0.111585 Thermal: 0.000507 LR: 4.06e-06\n",
      "Epoch  23 [ 400/10697 (  3.7%)] Loss: 0.024824 L1: 0.014625 Grad: 0.101776 Thermal: 0.000421 LR: 4.06e-06\n",
      "Epoch  23 [ 400/10697 (  3.7%)] Loss: 0.024824 L1: 0.014625 Grad: 0.101776 Thermal: 0.000421 LR: 4.06e-06\n",
      "Epoch  23 [ 450/10697 (  4.2%)] Loss: 0.025238 L1: 0.015008 Grad: 0.102080 Thermal: 0.000432 LR: 4.06e-06\n",
      "Epoch  23 [ 450/10697 (  4.2%)] Loss: 0.025238 L1: 0.015008 Grad: 0.102080 Thermal: 0.000432 LR: 4.06e-06\n",
      "Epoch  23 [ 500/10697 (  4.7%)] Loss: 0.022535 L1: 0.013177 Grad: 0.093408 Thermal: 0.000351 LR: 4.06e-06\n",
      "Epoch  23 [ 500/10697 (  4.7%)] Loss: 0.022535 L1: 0.013177 Grad: 0.093408 Thermal: 0.000351 LR: 4.06e-06\n",
      "Epoch  23 [ 550/10697 (  5.1%)] Loss: 0.026139 L1: 0.015149 Grad: 0.109697 Thermal: 0.000413 LR: 4.06e-06\n",
      "Epoch  23 [ 550/10697 (  5.1%)] Loss: 0.026139 L1: 0.015149 Grad: 0.109697 Thermal: 0.000413 LR: 4.06e-06\n",
      "Epoch  23 [ 600/10697 (  5.6%)] Loss: 0.021569 L1: 0.012198 Grad: 0.093539 Thermal: 0.000341 LR: 4.06e-06\n",
      "Epoch  23 [ 600/10697 (  5.6%)] Loss: 0.021569 L1: 0.012198 Grad: 0.093539 Thermal: 0.000341 LR: 4.06e-06\n",
      "Epoch  23 [ 650/10697 (  6.1%)] Loss: 0.030359 L1: 0.016986 Grad: 0.133449 Thermal: 0.000565 LR: 4.06e-06\n",
      "Epoch  23 [ 650/10697 (  6.1%)] Loss: 0.030359 L1: 0.016986 Grad: 0.133449 Thermal: 0.000565 LR: 4.06e-06\n",
      "Epoch  23 [ 700/10697 (  6.5%)] Loss: 0.024496 L1: 0.014477 Grad: 0.100002 Thermal: 0.000386 LR: 4.06e-06\n",
      "Epoch  23 [ 700/10697 (  6.5%)] Loss: 0.024496 L1: 0.014477 Grad: 0.100002 Thermal: 0.000386 LR: 4.06e-06\n",
      "Epoch  23 [ 750/10697 (  7.0%)] Loss: 0.026966 L1: 0.015771 Grad: 0.111705 Thermal: 0.000477 LR: 4.06e-06\n",
      "Epoch  23 [ 750/10697 (  7.0%)] Loss: 0.026966 L1: 0.015771 Grad: 0.111705 Thermal: 0.000477 LR: 4.06e-06\n",
      "Epoch  23 [ 800/10697 (  7.5%)] Loss: 0.024902 L1: 0.014681 Grad: 0.102010 Thermal: 0.000399 LR: 4.06e-06\n",
      "Epoch  23 [ 800/10697 (  7.5%)] Loss: 0.024902 L1: 0.014681 Grad: 0.102010 Thermal: 0.000399 LR: 4.06e-06\n",
      "Epoch  23 [ 850/10697 (  7.9%)] Loss: 0.026136 L1: 0.015437 Grad: 0.106781 Thermal: 0.000425 LR: 4.06e-06\n",
      "Epoch  23 [ 850/10697 (  7.9%)] Loss: 0.026136 L1: 0.015437 Grad: 0.106781 Thermal: 0.000425 LR: 4.06e-06\n",
      "Epoch  23 [ 900/10697 (  8.4%)] Loss: 0.028524 L1: 0.017054 Grad: 0.114435 Thermal: 0.000533 LR: 4.06e-06\n",
      "Epoch  23 [ 900/10697 (  8.4%)] Loss: 0.028524 L1: 0.017054 Grad: 0.114435 Thermal: 0.000533 LR: 4.06e-06\n",
      "Epoch  23 [ 950/10697 (  8.9%)] Loss: 0.030578 L1: 0.017975 Grad: 0.125730 Thermal: 0.000604 LR: 4.06e-06\n",
      "Epoch  23 [ 950/10697 (  8.9%)] Loss: 0.030578 L1: 0.017975 Grad: 0.125730 Thermal: 0.000604 LR: 4.06e-06\n",
      "Epoch  23 [1000/10697 (  9.3%)] Loss: 0.029416 L1: 0.017107 Grad: 0.122830 Thermal: 0.000520 LR: 4.06e-06\n",
      "Epoch  23 [1000/10697 (  9.3%)] Loss: 0.029416 L1: 0.017107 Grad: 0.122830 Thermal: 0.000520 LR: 4.06e-06\n",
      "Epoch  23 [1050/10697 (  9.8%)] Loss: 0.029880 L1: 0.017497 Grad: 0.123553 Thermal: 0.000540 LR: 4.06e-06\n",
      "Epoch  23 [1050/10697 (  9.8%)] Loss: 0.029880 L1: 0.017497 Grad: 0.123553 Thermal: 0.000540 LR: 4.06e-06\n",
      "Epoch  23 [1100/10697 ( 10.3%)] Loss: 0.026871 L1: 0.015876 Grad: 0.109714 Thermal: 0.000485 LR: 4.06e-06\n",
      "Epoch  23 [1100/10697 ( 10.3%)] Loss: 0.026871 L1: 0.015876 Grad: 0.109714 Thermal: 0.000485 LR: 4.06e-06\n",
      "Epoch  23 [1150/10697 ( 10.8%)] Loss: 0.032652 L1: 0.019117 Grad: 0.135019 Thermal: 0.000657 LR: 4.06e-06\n",
      "Epoch  23 [1150/10697 ( 10.8%)] Loss: 0.032652 L1: 0.019117 Grad: 0.135019 Thermal: 0.000657 LR: 4.06e-06\n",
      "Epoch  23 [1200/10697 ( 11.2%)] Loss: 0.032378 L1: 0.018805 Grad: 0.135403 Thermal: 0.000652 LR: 4.06e-06\n",
      "Epoch  23 [1200/10697 ( 11.2%)] Loss: 0.032378 L1: 0.018805 Grad: 0.135403 Thermal: 0.000652 LR: 4.06e-06\n",
      "Epoch  23 [1250/10697 ( 11.7%)] Loss: 0.026088 L1: 0.014860 Grad: 0.112074 Thermal: 0.000411 LR: 4.06e-06\n",
      "Epoch  23 [1250/10697 ( 11.7%)] Loss: 0.026088 L1: 0.014860 Grad: 0.112074 Thermal: 0.000411 LR: 4.06e-06\n",
      "Epoch  23 [1300/10697 ( 12.2%)] Loss: 0.025626 L1: 0.015065 Grad: 0.105405 Thermal: 0.000421 LR: 4.06e-06\n",
      "Epoch  23 [1300/10697 ( 12.2%)] Loss: 0.025626 L1: 0.015065 Grad: 0.105405 Thermal: 0.000421 LR: 4.06e-06\n",
      "Epoch  23 [1350/10697 ( 12.6%)] Loss: 0.026077 L1: 0.014994 Grad: 0.110614 Thermal: 0.000423 LR: 4.06e-06\n",
      "Epoch  23 [1350/10697 ( 12.6%)] Loss: 0.026077 L1: 0.014994 Grad: 0.110614 Thermal: 0.000423 LR: 4.06e-06\n",
      "Epoch  23 [1400/10697 ( 13.1%)] Loss: 0.028022 L1: 0.016202 Grad: 0.117966 Thermal: 0.000473 LR: 4.06e-06\n",
      "Epoch  23 [1400/10697 ( 13.1%)] Loss: 0.028022 L1: 0.016202 Grad: 0.117966 Thermal: 0.000473 LR: 4.06e-06\n",
      "Epoch  23 [1450/10697 ( 13.6%)] Loss: 0.021209 L1: 0.012007 Grad: 0.091867 Thermal: 0.000309 LR: 4.06e-06\n",
      "Epoch  23 [1450/10697 ( 13.6%)] Loss: 0.021209 L1: 0.012007 Grad: 0.091867 Thermal: 0.000309 LR: 4.06e-06\n",
      "Epoch  23 [1500/10697 ( 14.0%)] Loss: 0.020645 L1: 0.011911 Grad: 0.087178 Thermal: 0.000312 LR: 4.06e-06\n",
      "Epoch  23 [1500/10697 ( 14.0%)] Loss: 0.020645 L1: 0.011911 Grad: 0.087178 Thermal: 0.000312 LR: 4.06e-06\n",
      "Epoch  23 [1550/10697 ( 14.5%)] Loss: 0.027104 L1: 0.016286 Grad: 0.107939 Thermal: 0.000484 LR: 4.06e-06\n",
      "Epoch  23 [1550/10697 ( 14.5%)] Loss: 0.027104 L1: 0.016286 Grad: 0.107939 Thermal: 0.000484 LR: 4.06e-06\n",
      "Epoch  23 [1600/10697 ( 15.0%)] Loss: 0.027089 L1: 0.015670 Grad: 0.113952 Thermal: 0.000465 LR: 4.06e-06\n",
      "Epoch  23 [1600/10697 ( 15.0%)] Loss: 0.027089 L1: 0.015670 Grad: 0.113952 Thermal: 0.000465 LR: 4.06e-06\n",
      "Epoch  23 [1650/10697 ( 15.4%)] Loss: 0.029916 L1: 0.017761 Grad: 0.121247 Thermal: 0.000609 LR: 4.06e-06\n",
      "Epoch  23 [1650/10697 ( 15.4%)] Loss: 0.029916 L1: 0.017761 Grad: 0.121247 Thermal: 0.000609 LR: 4.06e-06\n",
      "Epoch  23 [1700/10697 ( 15.9%)] Loss: 0.028501 L1: 0.016746 Grad: 0.117297 Thermal: 0.000509 LR: 4.06e-06\n",
      "Epoch  23 [1700/10697 ( 15.9%)] Loss: 0.028501 L1: 0.016746 Grad: 0.117297 Thermal: 0.000509 LR: 4.06e-06\n",
      "Epoch  23 [1750/10697 ( 16.4%)] Loss: 0.025602 L1: 0.015063 Grad: 0.105188 Thermal: 0.000417 LR: 4.06e-06\n",
      "Epoch  23 [1750/10697 ( 16.4%)] Loss: 0.025602 L1: 0.015063 Grad: 0.105188 Thermal: 0.000417 LR: 4.06e-06\n",
      "Epoch  23 [1800/10697 ( 16.8%)] Loss: 0.030075 L1: 0.017692 Grad: 0.123546 Thermal: 0.000572 LR: 4.06e-06\n",
      "Epoch  23 [1800/10697 ( 16.8%)] Loss: 0.030075 L1: 0.017692 Grad: 0.123546 Thermal: 0.000572 LR: 4.06e-06\n",
      "Epoch  23 [1850/10697 ( 17.3%)] Loss: 0.030372 L1: 0.017829 Grad: 0.125145 Thermal: 0.000567 LR: 4.06e-06\n",
      "Epoch  23 [1850/10697 ( 17.3%)] Loss: 0.030372 L1: 0.017829 Grad: 0.125145 Thermal: 0.000567 LR: 4.06e-06\n",
      "Epoch  23 [1900/10697 ( 17.8%)] Loss: 0.028737 L1: 0.016642 Grad: 0.120677 Thermal: 0.000550 LR: 4.06e-06\n",
      "Epoch  23 [1900/10697 ( 17.8%)] Loss: 0.028737 L1: 0.016642 Grad: 0.120677 Thermal: 0.000550 LR: 4.06e-06\n",
      "Epoch  23 [1950/10697 ( 18.2%)] Loss: 0.020337 L1: 0.011796 Grad: 0.085264 Thermal: 0.000292 LR: 4.06e-06\n",
      "Epoch  23 [1950/10697 ( 18.2%)] Loss: 0.020337 L1: 0.011796 Grad: 0.085264 Thermal: 0.000292 LR: 4.06e-06\n",
      "Epoch  23 [2000/10697 ( 18.7%)] Loss: 0.016514 L1: 0.009631 Grad: 0.068715 Thermal: 0.000215 LR: 4.06e-06\n",
      "Epoch  23 [2000/10697 ( 18.7%)] Loss: 0.016514 L1: 0.009631 Grad: 0.068715 Thermal: 0.000215 LR: 4.06e-06\n",
      "Epoch  23 [2050/10697 ( 19.2%)] Loss: 0.023508 L1: 0.013678 Grad: 0.098115 Thermal: 0.000354 LR: 4.06e-06\n",
      "Epoch  23 [2050/10697 ( 19.2%)] Loss: 0.023508 L1: 0.013678 Grad: 0.098115 Thermal: 0.000354 LR: 4.06e-06\n",
      "Epoch  23 [2100/10697 ( 19.6%)] Loss: 0.021242 L1: 0.012469 Grad: 0.087575 Thermal: 0.000315 LR: 4.06e-06\n",
      "Epoch  23 [2100/10697 ( 19.6%)] Loss: 0.021242 L1: 0.012469 Grad: 0.087575 Thermal: 0.000315 LR: 4.06e-06\n",
      "Epoch  23 [2150/10697 ( 20.1%)] Loss: 0.018406 L1: 0.010425 Grad: 0.079683 Thermal: 0.000255 LR: 4.06e-06\n",
      "Epoch  23 [2150/10697 ( 20.1%)] Loss: 0.018406 L1: 0.010425 Grad: 0.079683 Thermal: 0.000255 LR: 4.06e-06\n",
      "Epoch  23 [2200/10697 ( 20.6%)] Loss: 0.027301 L1: 0.015907 Grad: 0.113700 Thermal: 0.000476 LR: 4.06e-06\n",
      "Epoch  23 [2200/10697 ( 20.6%)] Loss: 0.027301 L1: 0.015907 Grad: 0.113700 Thermal: 0.000476 LR: 4.06e-06\n",
      "Epoch  23 [2250/10697 ( 21.0%)] Loss: 0.025516 L1: 0.014972 Grad: 0.105229 Thermal: 0.000434 LR: 4.06e-06\n",
      "Epoch  23 [2250/10697 ( 21.0%)] Loss: 0.025516 L1: 0.014972 Grad: 0.105229 Thermal: 0.000434 LR: 4.06e-06\n",
      "Epoch  23 [2300/10697 ( 21.5%)] Loss: 0.026391 L1: 0.015553 Grad: 0.108163 Thermal: 0.000432 LR: 4.06e-06\n",
      "Epoch  23 [2300/10697 ( 21.5%)] Loss: 0.026391 L1: 0.015553 Grad: 0.108163 Thermal: 0.000432 LR: 4.06e-06\n",
      "Epoch  23 [2350/10697 ( 22.0%)] Loss: 0.023774 L1: 0.013263 Grad: 0.104915 Thermal: 0.000378 LR: 4.06e-06\n",
      "Epoch  23 [2350/10697 ( 22.0%)] Loss: 0.023774 L1: 0.013263 Grad: 0.104915 Thermal: 0.000378 LR: 4.06e-06\n",
      "Epoch  23 [2400/10697 ( 22.4%)] Loss: 0.021814 L1: 0.012546 Grad: 0.092530 Thermal: 0.000310 LR: 4.06e-06\n",
      "Epoch  23 [2400/10697 ( 22.4%)] Loss: 0.021814 L1: 0.012546 Grad: 0.092530 Thermal: 0.000310 LR: 4.06e-06\n",
      "Epoch  23 [2450/10697 ( 22.9%)] Loss: 0.025910 L1: 0.015534 Grad: 0.103528 Thermal: 0.000461 LR: 4.06e-06\n",
      "Epoch  23 [2450/10697 ( 22.9%)] Loss: 0.025910 L1: 0.015534 Grad: 0.103528 Thermal: 0.000461 LR: 4.06e-06\n",
      "Epoch  23 [2500/10697 ( 23.4%)] Loss: 0.026428 L1: 0.015864 Grad: 0.105414 Thermal: 0.000446 LR: 4.06e-06\n",
      "Epoch  23 [2500/10697 ( 23.4%)] Loss: 0.026428 L1: 0.015864 Grad: 0.105414 Thermal: 0.000446 LR: 4.06e-06\n",
      "Epoch  23 [2550/10697 ( 23.8%)] Loss: 0.030436 L1: 0.017679 Grad: 0.127295 Thermal: 0.000562 LR: 4.06e-06\n",
      "Epoch  23 [2550/10697 ( 23.8%)] Loss: 0.030436 L1: 0.017679 Grad: 0.127295 Thermal: 0.000562 LR: 4.06e-06\n",
      "Epoch  23 [2600/10697 ( 24.3%)] Loss: 0.026189 L1: 0.015167 Grad: 0.109994 Thermal: 0.000444 LR: 4.06e-06\n",
      "Epoch  23 [2600/10697 ( 24.3%)] Loss: 0.026189 L1: 0.015167 Grad: 0.109994 Thermal: 0.000444 LR: 4.06e-06\n",
      "Epoch  23 [2650/10697 ( 24.8%)] Loss: 0.025130 L1: 0.014089 Grad: 0.110215 Thermal: 0.000386 LR: 4.06e-06\n",
      "Epoch  23 [2650/10697 ( 24.8%)] Loss: 0.025130 L1: 0.014089 Grad: 0.110215 Thermal: 0.000386 LR: 4.06e-06\n",
      "Epoch  23 [2700/10697 ( 25.2%)] Loss: 0.027776 L1: 0.016630 Grad: 0.111220 Thermal: 0.000474 LR: 4.06e-06\n",
      "Epoch  23 [2700/10697 ( 25.2%)] Loss: 0.027776 L1: 0.016630 Grad: 0.111220 Thermal: 0.000474 LR: 4.06e-06\n",
      "Epoch  23 [2750/10697 ( 25.7%)] Loss: 0.025167 L1: 0.014690 Grad: 0.104554 Thermal: 0.000442 LR: 4.06e-06\n",
      "Epoch  23 [2750/10697 ( 25.7%)] Loss: 0.025167 L1: 0.014690 Grad: 0.104554 Thermal: 0.000442 LR: 4.06e-06\n",
      "Epoch  23 [2800/10697 ( 26.2%)] Loss: 0.026796 L1: 0.015834 Grad: 0.109400 Thermal: 0.000452 LR: 4.06e-06\n",
      "Epoch  23 [2800/10697 ( 26.2%)] Loss: 0.026796 L1: 0.015834 Grad: 0.109400 Thermal: 0.000452 LR: 4.06e-06\n",
      "Epoch  23 [2850/10697 ( 26.6%)] Loss: 0.025467 L1: 0.014854 Grad: 0.105919 Thermal: 0.000424 LR: 4.06e-06\n",
      "Epoch  23 [2850/10697 ( 26.6%)] Loss: 0.025467 L1: 0.014854 Grad: 0.105919 Thermal: 0.000424 LR: 4.06e-06\n",
      "Epoch  23 [2900/10697 ( 27.1%)] Loss: 0.023265 L1: 0.013657 Grad: 0.095893 Thermal: 0.000377 LR: 4.06e-06\n",
      "Epoch  23 [2900/10697 ( 27.1%)] Loss: 0.023265 L1: 0.013657 Grad: 0.095893 Thermal: 0.000377 LR: 4.06e-06\n",
      "Epoch  23 [2950/10697 ( 27.6%)] Loss: 0.020074 L1: 0.011656 Grad: 0.084025 Thermal: 0.000299 LR: 4.06e-06\n",
      "Epoch  23 [2950/10697 ( 27.6%)] Loss: 0.020074 L1: 0.011656 Grad: 0.084025 Thermal: 0.000299 LR: 4.06e-06\n",
      "Epoch  23 [3000/10697 ( 28.0%)] Loss: 0.027794 L1: 0.016400 Grad: 0.113692 Thermal: 0.000495 LR: 4.06e-06\n",
      "Epoch  23 [3000/10697 ( 28.0%)] Loss: 0.027794 L1: 0.016400 Grad: 0.113692 Thermal: 0.000495 LR: 4.06e-06\n",
      "Epoch  23 [3050/10697 ( 28.5%)] Loss: 0.024931 L1: 0.014675 Grad: 0.102367 Thermal: 0.000388 LR: 4.06e-06\n",
      "Epoch  23 [3050/10697 ( 28.5%)] Loss: 0.024931 L1: 0.014675 Grad: 0.102367 Thermal: 0.000388 LR: 4.06e-06\n",
      "Epoch  23 [3100/10697 ( 29.0%)] Loss: 0.022488 L1: 0.012847 Grad: 0.096245 Thermal: 0.000335 LR: 4.06e-06\n",
      "Epoch  23 [3100/10697 ( 29.0%)] Loss: 0.022488 L1: 0.012847 Grad: 0.096245 Thermal: 0.000335 LR: 4.06e-06\n",
      "Epoch  23 [3150/10697 ( 29.4%)] Loss: 0.022514 L1: 0.013013 Grad: 0.094829 Thermal: 0.000355 LR: 4.06e-06\n",
      "Epoch  23 [3150/10697 ( 29.4%)] Loss: 0.022514 L1: 0.013013 Grad: 0.094829 Thermal: 0.000355 LR: 4.06e-06\n",
      "Epoch  23 [3200/10697 ( 29.9%)] Loss: 0.026952 L1: 0.015571 Grad: 0.113591 Thermal: 0.000441 LR: 4.06e-06\n",
      "Epoch  23 [3200/10697 ( 29.9%)] Loss: 0.026952 L1: 0.015571 Grad: 0.113591 Thermal: 0.000441 LR: 4.06e-06\n",
      "Epoch  23 [3250/10697 ( 30.4%)] Loss: 0.024520 L1: 0.014415 Grad: 0.100848 Thermal: 0.000403 LR: 4.06e-06\n",
      "Epoch  23 [3250/10697 ( 30.4%)] Loss: 0.024520 L1: 0.014415 Grad: 0.100848 Thermal: 0.000403 LR: 4.06e-06\n",
      "Epoch  23 [3300/10697 ( 30.8%)] Loss: 0.019055 L1: 0.010888 Grad: 0.081535 Thermal: 0.000266 LR: 4.06e-06\n",
      "Epoch  23 [3300/10697 ( 30.8%)] Loss: 0.019055 L1: 0.010888 Grad: 0.081535 Thermal: 0.000266 LR: 4.06e-06\n",
      "Epoch  23 [3350/10697 ( 31.3%)] Loss: 0.025919 L1: 0.014961 Grad: 0.109370 Thermal: 0.000415 LR: 4.06e-06\n",
      "Epoch  23 [3350/10697 ( 31.3%)] Loss: 0.025919 L1: 0.014961 Grad: 0.109370 Thermal: 0.000415 LR: 4.06e-06\n",
      "Epoch  23 [3400/10697 ( 31.8%)] Loss: 0.023234 L1: 0.013733 Grad: 0.094817 Thermal: 0.000381 LR: 4.06e-06\n",
      "Epoch  23 [3400/10697 ( 31.8%)] Loss: 0.023234 L1: 0.013733 Grad: 0.094817 Thermal: 0.000381 LR: 4.06e-06\n",
      "Epoch  23 [3450/10697 ( 32.3%)] Loss: 0.031566 L1: 0.018575 Grad: 0.129587 Thermal: 0.000632 LR: 4.06e-06\n",
      "Epoch  23 [3450/10697 ( 32.3%)] Loss: 0.031566 L1: 0.018575 Grad: 0.129587 Thermal: 0.000632 LR: 4.06e-06\n",
      "Epoch  23 [3500/10697 ( 32.7%)] Loss: 0.025034 L1: 0.014888 Grad: 0.101246 Thermal: 0.000424 LR: 4.06e-06\n",
      "Epoch  23 [3500/10697 ( 32.7%)] Loss: 0.025034 L1: 0.014888 Grad: 0.101246 Thermal: 0.000424 LR: 4.06e-06\n",
      "Epoch  23 [3550/10697 ( 33.2%)] Loss: 0.027982 L1: 0.015954 Grad: 0.120033 Thermal: 0.000489 LR: 4.06e-06\n",
      "Epoch  23 [3550/10697 ( 33.2%)] Loss: 0.027982 L1: 0.015954 Grad: 0.120033 Thermal: 0.000489 LR: 4.06e-06\n",
      "Epoch  23 [3600/10697 ( 33.7%)] Loss: 0.020906 L1: 0.012373 Grad: 0.085178 Thermal: 0.000304 LR: 4.06e-06\n",
      "Epoch  23 [3600/10697 ( 33.7%)] Loss: 0.020906 L1: 0.012373 Grad: 0.085178 Thermal: 0.000304 LR: 4.06e-06\n",
      "Epoch  23 [3650/10697 ( 34.1%)] Loss: 0.024524 L1: 0.014164 Grad: 0.103427 Thermal: 0.000352 LR: 4.06e-06\n",
      "Epoch  23 [3650/10697 ( 34.1%)] Loss: 0.024524 L1: 0.014164 Grad: 0.103427 Thermal: 0.000352 LR: 4.06e-06\n",
      "Epoch  23 [3700/10697 ( 34.6%)] Loss: 0.023137 L1: 0.013487 Grad: 0.096319 Thermal: 0.000354 LR: 4.06e-06\n",
      "Epoch  23 [3700/10697 ( 34.6%)] Loss: 0.023137 L1: 0.013487 Grad: 0.096319 Thermal: 0.000354 LR: 4.06e-06\n",
      "Epoch  23 [3750/10697 ( 35.1%)] Loss: 0.026899 L1: 0.016080 Grad: 0.107955 Thermal: 0.000461 LR: 4.06e-06\n",
      "Epoch  23 [3750/10697 ( 35.1%)] Loss: 0.026899 L1: 0.016080 Grad: 0.107955 Thermal: 0.000461 LR: 4.06e-06\n",
      "Epoch  23 [3800/10697 ( 35.5%)] Loss: 0.029276 L1: 0.017258 Grad: 0.119921 Thermal: 0.000518 LR: 4.06e-06\n",
      "Epoch  23 [3800/10697 ( 35.5%)] Loss: 0.029276 L1: 0.017258 Grad: 0.119921 Thermal: 0.000518 LR: 4.06e-06\n",
      "Epoch  23 [3850/10697 ( 36.0%)] Loss: 0.027344 L1: 0.015698 Grad: 0.116213 Thermal: 0.000486 LR: 4.06e-06\n",
      "Epoch  23 [3850/10697 ( 36.0%)] Loss: 0.027344 L1: 0.015698 Grad: 0.116213 Thermal: 0.000486 LR: 4.06e-06\n",
      "Epoch  23 [3900/10697 ( 36.5%)] Loss: 0.028145 L1: 0.016473 Grad: 0.116469 Thermal: 0.000497 LR: 4.06e-06\n",
      "Epoch  23 [3900/10697 ( 36.5%)] Loss: 0.028145 L1: 0.016473 Grad: 0.116469 Thermal: 0.000497 LR: 4.06e-06\n",
      "Epoch  23 [3950/10697 ( 36.9%)] Loss: 0.032831 L1: 0.018613 Grad: 0.141862 Thermal: 0.000652 LR: 4.06e-06\n",
      "Epoch  23 [3950/10697 ( 36.9%)] Loss: 0.032831 L1: 0.018613 Grad: 0.141862 Thermal: 0.000652 LR: 4.06e-06\n",
      "Epoch  23 [4000/10697 ( 37.4%)] Loss: 0.029837 L1: 0.017452 Grad: 0.123566 Thermal: 0.000561 LR: 4.06e-06\n",
      "Epoch  23 [4000/10697 ( 37.4%)] Loss: 0.029837 L1: 0.017452 Grad: 0.123566 Thermal: 0.000561 LR: 4.06e-06\n",
      "Epoch  23 [4050/10697 ( 37.9%)] Loss: 0.023811 L1: 0.014107 Grad: 0.096840 Thermal: 0.000418 LR: 4.06e-06\n",
      "Epoch  23 [4050/10697 ( 37.9%)] Loss: 0.023811 L1: 0.014107 Grad: 0.096840 Thermal: 0.000418 LR: 4.06e-06\n",
      "Epoch  23 [4100/10697 ( 38.3%)] Loss: 0.026398 L1: 0.015283 Grad: 0.110937 Thermal: 0.000424 LR: 4.06e-06\n",
      "Epoch  23 [4100/10697 ( 38.3%)] Loss: 0.026398 L1: 0.015283 Grad: 0.110937 Thermal: 0.000424 LR: 4.06e-06\n",
      "Epoch  23 [4150/10697 ( 38.8%)] Loss: 0.028492 L1: 0.016755 Grad: 0.117110 Thermal: 0.000502 LR: 4.06e-06\n",
      "Epoch  23 [4150/10697 ( 38.8%)] Loss: 0.028492 L1: 0.016755 Grad: 0.117110 Thermal: 0.000502 LR: 4.06e-06\n",
      "Epoch  23 [4200/10697 ( 39.3%)] Loss: 0.028771 L1: 0.016660 Grad: 0.120848 Thermal: 0.000518 LR: 4.06e-06\n",
      "Epoch  23 [4200/10697 ( 39.3%)] Loss: 0.028771 L1: 0.016660 Grad: 0.120848 Thermal: 0.000518 LR: 4.06e-06\n",
      "Epoch  23 [4250/10697 ( 39.7%)] Loss: 0.031348 L1: 0.017790 Grad: 0.135289 Thermal: 0.000586 LR: 4.06e-06\n",
      "Epoch  23 [4250/10697 ( 39.7%)] Loss: 0.031348 L1: 0.017790 Grad: 0.135289 Thermal: 0.000586 LR: 4.06e-06\n",
      "Epoch  23 [4300/10697 ( 40.2%)] Loss: 0.028329 L1: 0.016238 Grad: 0.120630 Thermal: 0.000565 LR: 4.06e-06\n",
      "Epoch  23 [4300/10697 ( 40.2%)] Loss: 0.028329 L1: 0.016238 Grad: 0.120630 Thermal: 0.000565 LR: 4.06e-06\n",
      "Epoch  23 [4350/10697 ( 40.7%)] Loss: 0.027690 L1: 0.016505 Grad: 0.111617 Thermal: 0.000470 LR: 4.06e-06\n",
      "Epoch  23 [4350/10697 ( 40.7%)] Loss: 0.027690 L1: 0.016505 Grad: 0.111617 Thermal: 0.000470 LR: 4.06e-06\n",
      "Epoch  23 [4400/10697 ( 41.1%)] Loss: 0.028478 L1: 0.016816 Grad: 0.116380 Thermal: 0.000485 LR: 4.06e-06\n",
      "Epoch  23 [4400/10697 ( 41.1%)] Loss: 0.028478 L1: 0.016816 Grad: 0.116380 Thermal: 0.000485 LR: 4.06e-06\n",
      "Epoch  23 [4450/10697 ( 41.6%)] Loss: 0.023828 L1: 0.013898 Grad: 0.099112 Thermal: 0.000367 LR: 4.06e-06\n",
      "Epoch  23 [4450/10697 ( 41.6%)] Loss: 0.023828 L1: 0.013898 Grad: 0.099112 Thermal: 0.000367 LR: 4.06e-06\n",
      "Epoch  23 [4500/10697 ( 42.1%)] Loss: 0.021391 L1: 0.012149 Grad: 0.092283 Thermal: 0.000284 LR: 4.06e-06\n",
      "Epoch  23 [4500/10697 ( 42.1%)] Loss: 0.021391 L1: 0.012149 Grad: 0.092283 Thermal: 0.000284 LR: 4.06e-06\n",
      "Epoch  23 [4550/10697 ( 42.5%)] Loss: 0.034134 L1: 0.019375 Grad: 0.147207 Thermal: 0.000757 LR: 4.06e-06\n",
      "Epoch  23 [4550/10697 ( 42.5%)] Loss: 0.034134 L1: 0.019375 Grad: 0.147207 Thermal: 0.000757 LR: 4.06e-06\n",
      "Epoch  23 [4600/10697 ( 43.0%)] Loss: 0.029615 L1: 0.017576 Grad: 0.120097 Thermal: 0.000602 LR: 4.06e-06\n",
      "Epoch  23 [4600/10697 ( 43.0%)] Loss: 0.029615 L1: 0.017576 Grad: 0.120097 Thermal: 0.000602 LR: 4.06e-06\n",
      "Epoch  23 [4650/10697 ( 43.5%)] Loss: 0.028511 L1: 0.017030 Grad: 0.114563 Thermal: 0.000505 LR: 4.06e-06\n",
      "Epoch  23 [4650/10697 ( 43.5%)] Loss: 0.028511 L1: 0.017030 Grad: 0.114563 Thermal: 0.000505 LR: 4.06e-06\n",
      "Epoch  23 [4700/10697 ( 43.9%)] Loss: 0.026744 L1: 0.015529 Grad: 0.111928 Thermal: 0.000441 LR: 4.06e-06\n",
      "Epoch  23 [4700/10697 ( 43.9%)] Loss: 0.026744 L1: 0.015529 Grad: 0.111928 Thermal: 0.000441 LR: 4.06e-06\n",
      "Epoch  23 [4750/10697 ( 44.4%)] Loss: 0.029315 L1: 0.016998 Grad: 0.122915 Thermal: 0.000524 LR: 4.06e-06\n",
      "Epoch  23 [4750/10697 ( 44.4%)] Loss: 0.029315 L1: 0.016998 Grad: 0.122915 Thermal: 0.000524 LR: 4.06e-06\n",
      "Epoch  23 [4800/10697 ( 44.9%)] Loss: 0.025635 L1: 0.014781 Grad: 0.108331 Thermal: 0.000422 LR: 4.06e-06\n",
      "Epoch  23 [4800/10697 ( 44.9%)] Loss: 0.025635 L1: 0.014781 Grad: 0.108331 Thermal: 0.000422 LR: 4.06e-06\n",
      "Epoch  23 [4850/10697 ( 45.3%)] Loss: 0.029645 L1: 0.017705 Grad: 0.119142 Thermal: 0.000527 LR: 4.06e-06\n",
      "Epoch  23 [4850/10697 ( 45.3%)] Loss: 0.029645 L1: 0.017705 Grad: 0.119142 Thermal: 0.000527 LR: 4.06e-06\n",
      "Epoch  23 [4900/10697 ( 45.8%)] Loss: 0.023671 L1: 0.013561 Grad: 0.100910 Thermal: 0.000384 LR: 4.06e-06\n",
      "Epoch  23 [4900/10697 ( 45.8%)] Loss: 0.023671 L1: 0.013561 Grad: 0.100910 Thermal: 0.000384 LR: 4.06e-06\n",
      "Epoch  23 [4950/10697 ( 46.3%)] Loss: 0.019022 L1: 0.010573 Grad: 0.084371 Thermal: 0.000237 LR: 4.06e-06\n",
      "Epoch  23 [4950/10697 ( 46.3%)] Loss: 0.019022 L1: 0.010573 Grad: 0.084371 Thermal: 0.000237 LR: 4.06e-06\n",
      "Epoch  23 [5000/10697 ( 46.7%)] Loss: 0.022940 L1: 0.013223 Grad: 0.096988 Thermal: 0.000379 LR: 4.06e-06\n",
      "Epoch  23 [5000/10697 ( 46.7%)] Loss: 0.022940 L1: 0.013223 Grad: 0.096988 Thermal: 0.000379 LR: 4.06e-06\n",
      "Epoch  23 [5050/10697 ( 47.2%)] Loss: 0.025214 L1: 0.015121 Grad: 0.100699 Thermal: 0.000469 LR: 4.06e-06\n",
      "Epoch  23 [5050/10697 ( 47.2%)] Loss: 0.025214 L1: 0.015121 Grad: 0.100699 Thermal: 0.000469 LR: 4.06e-06\n",
      "Epoch  23 [5100/10697 ( 47.7%)] Loss: 0.024643 L1: 0.014224 Grad: 0.104004 Thermal: 0.000384 LR: 4.06e-06\n",
      "Epoch  23 [5100/10697 ( 47.7%)] Loss: 0.024643 L1: 0.014224 Grad: 0.104004 Thermal: 0.000384 LR: 4.06e-06\n",
      "Epoch  23 [5150/10697 ( 48.1%)] Loss: 0.028496 L1: 0.016509 Grad: 0.119576 Thermal: 0.000593 LR: 4.06e-06\n",
      "Epoch  23 [5150/10697 ( 48.1%)] Loss: 0.028496 L1: 0.016509 Grad: 0.119576 Thermal: 0.000593 LR: 4.06e-06\n",
      "Epoch  23 [5200/10697 ( 48.6%)] Loss: 0.025485 L1: 0.014541 Grad: 0.109200 Thermal: 0.000492 LR: 4.06e-06\n",
      "Epoch  23 [5200/10697 ( 48.6%)] Loss: 0.025485 L1: 0.014541 Grad: 0.109200 Thermal: 0.000492 LR: 4.06e-06\n",
      "Epoch  23 [5250/10697 ( 49.1%)] Loss: 0.027549 L1: 0.016057 Grad: 0.114682 Thermal: 0.000468 LR: 4.06e-06\n",
      "Epoch  23 [5250/10697 ( 49.1%)] Loss: 0.027549 L1: 0.016057 Grad: 0.114682 Thermal: 0.000468 LR: 4.06e-06\n",
      "Epoch  23 [5300/10697 ( 49.5%)] Loss: 0.030143 L1: 0.017305 Grad: 0.128094 Thermal: 0.000559 LR: 4.06e-06\n",
      "Epoch  23 [5300/10697 ( 49.5%)] Loss: 0.030143 L1: 0.017305 Grad: 0.128094 Thermal: 0.000559 LR: 4.06e-06\n",
      "Epoch  23 [5350/10697 ( 50.0%)] Loss: 0.025636 L1: 0.015164 Grad: 0.104514 Thermal: 0.000421 LR: 4.06e-06\n",
      "Epoch  23 [5350/10697 ( 50.0%)] Loss: 0.025636 L1: 0.015164 Grad: 0.104514 Thermal: 0.000421 LR: 4.06e-06\n",
      "Epoch  23 [5400/10697 ( 50.5%)] Loss: 0.023959 L1: 0.014436 Grad: 0.095036 Thermal: 0.000395 LR: 4.06e-06\n",
      "Epoch  23 [5400/10697 ( 50.5%)] Loss: 0.023959 L1: 0.014436 Grad: 0.095036 Thermal: 0.000395 LR: 4.06e-06\n",
      "Epoch  23 [5450/10697 ( 50.9%)] Loss: 0.032642 L1: 0.018517 Grad: 0.140898 Thermal: 0.000704 LR: 4.06e-06\n",
      "Epoch  23 [5450/10697 ( 50.9%)] Loss: 0.032642 L1: 0.018517 Grad: 0.140898 Thermal: 0.000704 LR: 4.06e-06\n",
      "Epoch  23 [5500/10697 ( 51.4%)] Loss: 0.030558 L1: 0.017656 Grad: 0.128703 Thermal: 0.000634 LR: 4.06e-06\n",
      "Epoch  23 [5500/10697 ( 51.4%)] Loss: 0.030558 L1: 0.017656 Grad: 0.128703 Thermal: 0.000634 LR: 4.06e-06\n",
      "Epoch  23 [5550/10697 ( 51.9%)] Loss: 0.021690 L1: 0.012501 Grad: 0.091740 Thermal: 0.000301 LR: 4.06e-06\n",
      "Epoch  23 [5550/10697 ( 51.9%)] Loss: 0.021690 L1: 0.012501 Grad: 0.091740 Thermal: 0.000301 LR: 4.06e-06\n",
      "Epoch  23 [5600/10697 ( 52.4%)] Loss: 0.029041 L1: 0.016860 Grad: 0.121535 Thermal: 0.000553 LR: 4.06e-06\n",
      "Epoch  23 [5600/10697 ( 52.4%)] Loss: 0.029041 L1: 0.016860 Grad: 0.121535 Thermal: 0.000553 LR: 4.06e-06\n",
      "Epoch  23 [5650/10697 ( 52.8%)] Loss: 0.019280 L1: 0.011033 Grad: 0.082338 Thermal: 0.000265 LR: 4.06e-06\n",
      "Epoch  23 [5650/10697 ( 52.8%)] Loss: 0.019280 L1: 0.011033 Grad: 0.082338 Thermal: 0.000265 LR: 4.06e-06\n",
      "Epoch  23 [5700/10697 ( 53.3%)] Loss: 0.025367 L1: 0.014834 Grad: 0.105120 Thermal: 0.000417 LR: 4.06e-06\n",
      "Epoch  23 [5700/10697 ( 53.3%)] Loss: 0.025367 L1: 0.014834 Grad: 0.105120 Thermal: 0.000417 LR: 4.06e-06\n",
      "Epoch  23 [5750/10697 ( 53.8%)] Loss: 0.023523 L1: 0.014197 Grad: 0.093079 Thermal: 0.000368 LR: 4.06e-06\n",
      "Epoch  23 [5750/10697 ( 53.8%)] Loss: 0.023523 L1: 0.014197 Grad: 0.093079 Thermal: 0.000368 LR: 4.06e-06\n",
      "Epoch  23 [5800/10697 ( 54.2%)] Loss: 0.030852 L1: 0.018364 Grad: 0.124559 Thermal: 0.000637 LR: 4.06e-06\n",
      "Epoch  23 [5800/10697 ( 54.2%)] Loss: 0.030852 L1: 0.018364 Grad: 0.124559 Thermal: 0.000637 LR: 4.06e-06\n",
      "Epoch  23 [5850/10697 ( 54.7%)] Loss: 0.027442 L1: 0.015957 Grad: 0.114632 Thermal: 0.000436 LR: 4.06e-06\n",
      "Epoch  23 [5850/10697 ( 54.7%)] Loss: 0.027442 L1: 0.015957 Grad: 0.114632 Thermal: 0.000436 LR: 4.06e-06\n",
      "Epoch  23 [5900/10697 ( 55.2%)] Loss: 0.023223 L1: 0.013632 Grad: 0.095738 Thermal: 0.000352 LR: 4.06e-06\n",
      "Epoch  23 [5900/10697 ( 55.2%)] Loss: 0.023223 L1: 0.013632 Grad: 0.095738 Thermal: 0.000352 LR: 4.06e-06\n",
      "Epoch  23 [5950/10697 ( 55.6%)] Loss: 0.025152 L1: 0.014971 Grad: 0.101601 Thermal: 0.000416 LR: 4.06e-06\n",
      "Epoch  23 [5950/10697 ( 55.6%)] Loss: 0.025152 L1: 0.014971 Grad: 0.101601 Thermal: 0.000416 LR: 4.06e-06\n",
      "Epoch  23 [6000/10697 ( 56.1%)] Loss: 0.022138 L1: 0.012703 Grad: 0.094178 Thermal: 0.000343 LR: 4.06e-06\n",
      "Epoch  23 [6000/10697 ( 56.1%)] Loss: 0.022138 L1: 0.012703 Grad: 0.094178 Thermal: 0.000343 LR: 4.06e-06\n",
      "Epoch  23 [6050/10697 ( 56.6%)] Loss: 0.022773 L1: 0.013316 Grad: 0.094408 Thermal: 0.000318 LR: 4.06e-06\n",
      "Epoch  23 [6050/10697 ( 56.6%)] Loss: 0.022773 L1: 0.013316 Grad: 0.094408 Thermal: 0.000318 LR: 4.06e-06\n",
      "Epoch  23 [6100/10697 ( 57.0%)] Loss: 0.029162 L1: 0.017270 Grad: 0.118644 Thermal: 0.000546 LR: 4.06e-06\n",
      "Epoch  23 [6100/10697 ( 57.0%)] Loss: 0.029162 L1: 0.017270 Grad: 0.118644 Thermal: 0.000546 LR: 4.06e-06\n",
      "Epoch  23 [6150/10697 ( 57.5%)] Loss: 0.024932 L1: 0.014596 Grad: 0.103177 Thermal: 0.000376 LR: 4.06e-06\n",
      "Epoch  23 [6150/10697 ( 57.5%)] Loss: 0.024932 L1: 0.014596 Grad: 0.103177 Thermal: 0.000376 LR: 4.06e-06\n",
      "Epoch  23 [6200/10697 ( 58.0%)] Loss: 0.029888 L1: 0.017119 Grad: 0.127407 Thermal: 0.000567 LR: 4.06e-06\n",
      "Epoch  23 [6200/10697 ( 58.0%)] Loss: 0.029888 L1: 0.017119 Grad: 0.127407 Thermal: 0.000567 LR: 4.06e-06\n",
      "Epoch  23 [6250/10697 ( 58.4%)] Loss: 0.024660 L1: 0.014211 Grad: 0.104284 Thermal: 0.000412 LR: 4.06e-06\n",
      "Epoch  23 [6250/10697 ( 58.4%)] Loss: 0.024660 L1: 0.014211 Grad: 0.104284 Thermal: 0.000412 LR: 4.06e-06\n",
      "Epoch  23 [6300/10697 ( 58.9%)] Loss: 0.021726 L1: 0.012730 Grad: 0.089803 Thermal: 0.000323 LR: 4.06e-06\n",
      "Epoch  23 [6300/10697 ( 58.9%)] Loss: 0.021726 L1: 0.012730 Grad: 0.089803 Thermal: 0.000323 LR: 4.06e-06\n",
      "Epoch  23 [6350/10697 ( 59.4%)] Loss: 0.027565 L1: 0.016409 Grad: 0.111294 Thermal: 0.000526 LR: 4.06e-06\n",
      "Epoch  23 [6350/10697 ( 59.4%)] Loss: 0.027565 L1: 0.016409 Grad: 0.111294 Thermal: 0.000526 LR: 4.06e-06\n",
      "Epoch  23 [6400/10697 ( 59.8%)] Loss: 0.025828 L1: 0.015272 Grad: 0.105348 Thermal: 0.000442 LR: 4.06e-06\n",
      "Epoch  23 [6400/10697 ( 59.8%)] Loss: 0.025828 L1: 0.015272 Grad: 0.105348 Thermal: 0.000442 LR: 4.06e-06\n",
      "Epoch  23 [6450/10697 ( 60.3%)] Loss: 0.019624 L1: 0.011363 Grad: 0.082463 Thermal: 0.000284 LR: 4.06e-06\n",
      "Epoch  23 [6450/10697 ( 60.3%)] Loss: 0.019624 L1: 0.011363 Grad: 0.082463 Thermal: 0.000284 LR: 4.06e-06\n",
      "Epoch  23 [6500/10697 ( 60.8%)] Loss: 0.019555 L1: 0.011241 Grad: 0.083007 Thermal: 0.000268 LR: 4.06e-06\n",
      "Epoch  23 [6500/10697 ( 60.8%)] Loss: 0.019555 L1: 0.011241 Grad: 0.083007 Thermal: 0.000268 LR: 4.06e-06\n",
      "Epoch  23 [6550/10697 ( 61.2%)] Loss: 0.028572 L1: 0.016422 Grad: 0.121243 Thermal: 0.000504 LR: 4.06e-06\n",
      "Epoch  23 [6550/10697 ( 61.2%)] Loss: 0.028572 L1: 0.016422 Grad: 0.121243 Thermal: 0.000504 LR: 4.06e-06\n",
      "Epoch  23 [6600/10697 ( 61.7%)] Loss: 0.027591 L1: 0.016467 Grad: 0.111003 Thermal: 0.000467 LR: 4.06e-06\n",
      "Epoch  23 [6600/10697 ( 61.7%)] Loss: 0.027591 L1: 0.016467 Grad: 0.111003 Thermal: 0.000467 LR: 4.06e-06\n",
      "Epoch  23 [6650/10697 ( 62.2%)] Loss: 0.019691 L1: 0.011490 Grad: 0.081868 Thermal: 0.000281 LR: 4.06e-06\n",
      "Epoch  23 [6650/10697 ( 62.2%)] Loss: 0.019691 L1: 0.011490 Grad: 0.081868 Thermal: 0.000281 LR: 4.06e-06\n",
      "Epoch  23 [6700/10697 ( 62.6%)] Loss: 0.025929 L1: 0.015160 Grad: 0.107450 Thermal: 0.000480 LR: 4.06e-06\n",
      "Epoch  23 [6700/10697 ( 62.6%)] Loss: 0.025929 L1: 0.015160 Grad: 0.107450 Thermal: 0.000480 LR: 4.06e-06\n",
      "Epoch  23 [6750/10697 ( 63.1%)] Loss: 0.020932 L1: 0.011951 Grad: 0.089668 Thermal: 0.000276 LR: 4.06e-06\n",
      "Epoch  23 [6750/10697 ( 63.1%)] Loss: 0.020932 L1: 0.011951 Grad: 0.089668 Thermal: 0.000276 LR: 4.06e-06\n",
      "Epoch  23 [6800/10697 ( 63.6%)] Loss: 0.016535 L1: 0.009539 Grad: 0.069841 Thermal: 0.000256 LR: 4.06e-06\n",
      "Epoch  23 [6800/10697 ( 63.6%)] Loss: 0.016535 L1: 0.009539 Grad: 0.069841 Thermal: 0.000256 LR: 4.06e-06\n",
      "Epoch  23 [6850/10697 ( 64.0%)] Loss: 0.026265 L1: 0.015042 Grad: 0.112003 Thermal: 0.000455 LR: 4.06e-06\n",
      "Epoch  23 [6850/10697 ( 64.0%)] Loss: 0.026265 L1: 0.015042 Grad: 0.112003 Thermal: 0.000455 LR: 4.06e-06\n",
      "Epoch  23 [6900/10697 ( 64.5%)] Loss: 0.025798 L1: 0.015289 Grad: 0.104863 Thermal: 0.000447 LR: 4.06e-06\n",
      "Epoch  23 [6900/10697 ( 64.5%)] Loss: 0.025798 L1: 0.015289 Grad: 0.104863 Thermal: 0.000447 LR: 4.06e-06\n",
      "Epoch  23 [6950/10697 ( 65.0%)] Loss: 0.026622 L1: 0.016165 Grad: 0.104338 Thermal: 0.000465 LR: 4.06e-06\n",
      "Epoch  23 [6950/10697 ( 65.0%)] Loss: 0.026622 L1: 0.016165 Grad: 0.104338 Thermal: 0.000465 LR: 4.06e-06\n",
      "Epoch  23 [7000/10697 ( 65.4%)] Loss: 0.035640 L1: 0.020248 Grad: 0.153517 Thermal: 0.000802 LR: 4.06e-06\n",
      "Epoch  23 [7000/10697 ( 65.4%)] Loss: 0.035640 L1: 0.020248 Grad: 0.153517 Thermal: 0.000802 LR: 4.06e-06\n",
      "Epoch  23 [7050/10697 ( 65.9%)] Loss: 0.030126 L1: 0.017676 Grad: 0.124193 Thermal: 0.000631 LR: 4.06e-06\n",
      "Epoch  23 [7050/10697 ( 65.9%)] Loss: 0.030126 L1: 0.017676 Grad: 0.124193 Thermal: 0.000631 LR: 4.06e-06\n",
      "Epoch  23 [7100/10697 ( 66.4%)] Loss: 0.028821 L1: 0.016801 Grad: 0.119921 Thermal: 0.000554 LR: 4.06e-06\n",
      "Epoch  23 [7100/10697 ( 66.4%)] Loss: 0.028821 L1: 0.016801 Grad: 0.119921 Thermal: 0.000554 LR: 4.06e-06\n",
      "Epoch  23 [7150/10697 ( 66.8%)] Loss: 0.029393 L1: 0.017266 Grad: 0.120967 Thermal: 0.000610 LR: 4.06e-06\n",
      "Epoch  23 [7150/10697 ( 66.8%)] Loss: 0.029393 L1: 0.017266 Grad: 0.120967 Thermal: 0.000610 LR: 4.06e-06\n",
      "Epoch  23 [7200/10697 ( 67.3%)] Loss: 0.023551 L1: 0.013666 Grad: 0.098684 Thermal: 0.000338 LR: 4.06e-06\n",
      "Epoch  23 [7200/10697 ( 67.3%)] Loss: 0.023551 L1: 0.013666 Grad: 0.098684 Thermal: 0.000338 LR: 4.06e-06\n",
      "Epoch  23 [7250/10697 ( 67.8%)] Loss: 0.025752 L1: 0.015282 Grad: 0.104479 Thermal: 0.000440 LR: 4.06e-06\n",
      "Epoch  23 [7250/10697 ( 67.8%)] Loss: 0.025752 L1: 0.015282 Grad: 0.104479 Thermal: 0.000440 LR: 4.06e-06\n",
      "Epoch  23 [7300/10697 ( 68.2%)] Loss: 0.031992 L1: 0.018752 Grad: 0.132076 Thermal: 0.000636 LR: 4.06e-06\n",
      "Epoch  23 [7300/10697 ( 68.2%)] Loss: 0.031992 L1: 0.018752 Grad: 0.132076 Thermal: 0.000636 LR: 4.06e-06\n",
      "Epoch  23 [7350/10697 ( 68.7%)] Loss: 0.024236 L1: 0.014618 Grad: 0.095991 Thermal: 0.000395 LR: 4.06e-06\n",
      "Epoch  23 [7350/10697 ( 68.7%)] Loss: 0.024236 L1: 0.014618 Grad: 0.095991 Thermal: 0.000395 LR: 4.06e-06\n",
      "Epoch  23 [7400/10697 ( 69.2%)] Loss: 0.026610 L1: 0.015971 Grad: 0.106168 Thermal: 0.000441 LR: 4.06e-06\n",
      "Epoch  23 [7400/10697 ( 69.2%)] Loss: 0.026610 L1: 0.015971 Grad: 0.106168 Thermal: 0.000441 LR: 4.06e-06\n",
      "Epoch  23 [7450/10697 ( 69.6%)] Loss: 0.027435 L1: 0.016368 Grad: 0.110433 Thermal: 0.000482 LR: 4.06e-06\n",
      "Epoch  23 [7450/10697 ( 69.6%)] Loss: 0.027435 L1: 0.016368 Grad: 0.110433 Thermal: 0.000482 LR: 4.06e-06\n",
      "Epoch  23 [7500/10697 ( 70.1%)] Loss: 0.027750 L1: 0.016088 Grad: 0.116386 Thermal: 0.000469 LR: 4.06e-06\n",
      "Epoch  23 [7500/10697 ( 70.1%)] Loss: 0.027750 L1: 0.016088 Grad: 0.116386 Thermal: 0.000469 LR: 4.06e-06\n",
      "Epoch  23 [7550/10697 ( 70.6%)] Loss: 0.031427 L1: 0.018427 Grad: 0.129683 Thermal: 0.000634 LR: 4.06e-06\n",
      "Epoch  23 [7550/10697 ( 70.6%)] Loss: 0.031427 L1: 0.018427 Grad: 0.129683 Thermal: 0.000634 LR: 4.06e-06\n",
      "Epoch  23 [7600/10697 ( 71.0%)] Loss: 0.024624 L1: 0.014084 Grad: 0.105194 Thermal: 0.000422 LR: 4.06e-06\n",
      "Epoch  23 [7600/10697 ( 71.0%)] Loss: 0.024624 L1: 0.014084 Grad: 0.105194 Thermal: 0.000422 LR: 4.06e-06\n",
      "Epoch  23 [7650/10697 ( 71.5%)] Loss: 0.028367 L1: 0.016452 Grad: 0.118907 Thermal: 0.000499 LR: 4.06e-06\n",
      "Epoch  23 [7650/10697 ( 71.5%)] Loss: 0.028367 L1: 0.016452 Grad: 0.118907 Thermal: 0.000499 LR: 4.06e-06\n",
      "Epoch  23 [7700/10697 ( 72.0%)] Loss: 0.025675 L1: 0.015314 Grad: 0.103401 Thermal: 0.000424 LR: 4.06e-06\n",
      "Epoch  23 [7700/10697 ( 72.0%)] Loss: 0.025675 L1: 0.015314 Grad: 0.103401 Thermal: 0.000424 LR: 4.06e-06\n",
      "Epoch  23 [7750/10697 ( 72.5%)] Loss: 0.028810 L1: 0.016619 Grad: 0.121671 Thermal: 0.000478 LR: 4.06e-06\n",
      "Epoch  23 [7750/10697 ( 72.5%)] Loss: 0.028810 L1: 0.016619 Grad: 0.121671 Thermal: 0.000478 LR: 4.06e-06\n",
      "Epoch  23 [7800/10697 ( 72.9%)] Loss: 0.021147 L1: 0.012194 Grad: 0.089357 Thermal: 0.000352 LR: 4.06e-06\n",
      "Epoch  23 [7800/10697 ( 72.9%)] Loss: 0.021147 L1: 0.012194 Grad: 0.089357 Thermal: 0.000352 LR: 4.06e-06\n",
      "Epoch  23 [7850/10697 ( 73.4%)] Loss: 0.025888 L1: 0.015261 Grad: 0.106045 Thermal: 0.000439 LR: 4.06e-06\n",
      "Epoch  23 [7850/10697 ( 73.4%)] Loss: 0.025888 L1: 0.015261 Grad: 0.106045 Thermal: 0.000439 LR: 4.06e-06\n",
      "Epoch  23 [7900/10697 ( 73.9%)] Loss: 0.024151 L1: 0.014199 Grad: 0.099329 Thermal: 0.000393 LR: 4.06e-06\n",
      "Epoch  23 [7900/10697 ( 73.9%)] Loss: 0.024151 L1: 0.014199 Grad: 0.099329 Thermal: 0.000393 LR: 4.06e-06\n",
      "Epoch  23 [7950/10697 ( 74.3%)] Loss: 0.022365 L1: 0.012895 Grad: 0.094536 Thermal: 0.000343 LR: 4.06e-06\n",
      "Epoch  23 [7950/10697 ( 74.3%)] Loss: 0.022365 L1: 0.012895 Grad: 0.094536 Thermal: 0.000343 LR: 4.06e-06\n",
      "Epoch  23 [8000/10697 ( 74.8%)] Loss: 0.030356 L1: 0.017497 Grad: 0.128300 Thermal: 0.000583 LR: 4.06e-06\n",
      "Epoch  23 [8000/10697 ( 74.8%)] Loss: 0.030356 L1: 0.017497 Grad: 0.128300 Thermal: 0.000583 LR: 4.06e-06\n",
      "Epoch  23 [8050/10697 ( 75.3%)] Loss: 0.024927 L1: 0.014926 Grad: 0.099814 Thermal: 0.000399 LR: 4.06e-06\n",
      "Epoch  23 [8050/10697 ( 75.3%)] Loss: 0.024927 L1: 0.014926 Grad: 0.099814 Thermal: 0.000399 LR: 4.06e-06\n",
      "Epoch  23 [8100/10697 ( 75.7%)] Loss: 0.026604 L1: 0.015739 Grad: 0.108432 Thermal: 0.000440 LR: 4.06e-06\n",
      "Epoch  23 [8100/10697 ( 75.7%)] Loss: 0.026604 L1: 0.015739 Grad: 0.108432 Thermal: 0.000440 LR: 4.06e-06\n",
      "Epoch  23 [8150/10697 ( 76.2%)] Loss: 0.021430 L1: 0.012525 Grad: 0.088892 Thermal: 0.000311 LR: 4.06e-06\n",
      "Epoch  23 [8150/10697 ( 76.2%)] Loss: 0.021430 L1: 0.012525 Grad: 0.088892 Thermal: 0.000311 LR: 4.06e-06\n",
      "Epoch  23 [8200/10697 ( 76.7%)] Loss: 0.025877 L1: 0.015081 Grad: 0.107711 Thermal: 0.000479 LR: 4.06e-06\n",
      "Epoch  23 [8200/10697 ( 76.7%)] Loss: 0.025877 L1: 0.015081 Grad: 0.107711 Thermal: 0.000479 LR: 4.06e-06\n",
      "Epoch  23 [8250/10697 ( 77.1%)] Loss: 0.027926 L1: 0.016037 Grad: 0.118656 Thermal: 0.000467 LR: 4.06e-06\n",
      "Epoch  23 [8250/10697 ( 77.1%)] Loss: 0.027926 L1: 0.016037 Grad: 0.118656 Thermal: 0.000467 LR: 4.06e-06\n",
      "Epoch  23 [8300/10697 ( 77.6%)] Loss: 0.028648 L1: 0.016502 Grad: 0.121221 Thermal: 0.000493 LR: 4.06e-06\n",
      "Epoch  23 [8300/10697 ( 77.6%)] Loss: 0.028648 L1: 0.016502 Grad: 0.121221 Thermal: 0.000493 LR: 4.06e-06\n",
      "Epoch  23 [8350/10697 ( 78.1%)] Loss: 0.029321 L1: 0.017001 Grad: 0.122937 Thermal: 0.000521 LR: 4.06e-06\n",
      "Epoch  23 [8350/10697 ( 78.1%)] Loss: 0.029321 L1: 0.017001 Grad: 0.122937 Thermal: 0.000521 LR: 4.06e-06\n",
      "Epoch  23 [8400/10697 ( 78.5%)] Loss: 0.029422 L1: 0.016575 Grad: 0.128233 Thermal: 0.000475 LR: 4.06e-06\n",
      "Epoch  23 [8400/10697 ( 78.5%)] Loss: 0.029422 L1: 0.016575 Grad: 0.128233 Thermal: 0.000475 LR: 4.06e-06\n",
      "Epoch  23 [8450/10697 ( 79.0%)] Loss: 0.023099 L1: 0.013541 Grad: 0.095402 Thermal: 0.000354 LR: 4.06e-06\n",
      "Epoch  23 [8450/10697 ( 79.0%)] Loss: 0.023099 L1: 0.013541 Grad: 0.095402 Thermal: 0.000354 LR: 4.06e-06\n",
      "Epoch  23 [8500/10697 ( 79.5%)] Loss: 0.029457 L1: 0.016739 Grad: 0.126852 Thermal: 0.000641 LR: 4.06e-06\n",
      "Epoch  23 [8500/10697 ( 79.5%)] Loss: 0.029457 L1: 0.016739 Grad: 0.126852 Thermal: 0.000641 LR: 4.06e-06\n",
      "Epoch  23 [8550/10697 ( 79.9%)] Loss: 0.028250 L1: 0.016552 Grad: 0.116729 Thermal: 0.000507 LR: 4.06e-06\n",
      "Epoch  23 [8550/10697 ( 79.9%)] Loss: 0.028250 L1: 0.016552 Grad: 0.116729 Thermal: 0.000507 LR: 4.06e-06\n",
      "Epoch  23 [8600/10697 ( 80.4%)] Loss: 0.028951 L1: 0.016708 Grad: 0.122131 Thermal: 0.000597 LR: 4.06e-06\n",
      "Epoch  23 [8600/10697 ( 80.4%)] Loss: 0.028951 L1: 0.016708 Grad: 0.122131 Thermal: 0.000597 LR: 4.06e-06\n",
      "Epoch  23 [8650/10697 ( 80.9%)] Loss: 0.022823 L1: 0.013264 Grad: 0.095423 Thermal: 0.000334 LR: 4.06e-06\n",
      "Epoch  23 [8650/10697 ( 80.9%)] Loss: 0.022823 L1: 0.013264 Grad: 0.095423 Thermal: 0.000334 LR: 4.06e-06\n",
      "Epoch  23 [8700/10697 ( 81.3%)] Loss: 0.025998 L1: 0.015197 Grad: 0.107781 Thermal: 0.000462 LR: 4.06e-06\n",
      "Epoch  23 [8700/10697 ( 81.3%)] Loss: 0.025998 L1: 0.015197 Grad: 0.107781 Thermal: 0.000462 LR: 4.06e-06\n",
      "Epoch  23 [8750/10697 ( 81.8%)] Loss: 0.022582 L1: 0.013391 Grad: 0.091719 Thermal: 0.000384 LR: 4.06e-06\n",
      "Epoch  23 [8750/10697 ( 81.8%)] Loss: 0.022582 L1: 0.013391 Grad: 0.091719 Thermal: 0.000384 LR: 4.06e-06\n",
      "Epoch  23 [8800/10697 ( 82.3%)] Loss: 0.026473 L1: 0.015453 Grad: 0.109964 Thermal: 0.000460 LR: 4.06e-06\n",
      "Epoch  23 [8800/10697 ( 82.3%)] Loss: 0.026473 L1: 0.015453 Grad: 0.109964 Thermal: 0.000460 LR: 4.06e-06\n",
      "Epoch  23 [8850/10697 ( 82.7%)] Loss: 0.023511 L1: 0.013665 Grad: 0.098270 Thermal: 0.000371 LR: 4.06e-06\n",
      "Epoch  23 [8850/10697 ( 82.7%)] Loss: 0.023511 L1: 0.013665 Grad: 0.098270 Thermal: 0.000371 LR: 4.06e-06\n",
      "Epoch  23 [8900/10697 ( 83.2%)] Loss: 0.025989 L1: 0.015515 Grad: 0.104515 Thermal: 0.000451 LR: 4.06e-06\n",
      "Epoch  23 [8900/10697 ( 83.2%)] Loss: 0.025989 L1: 0.015515 Grad: 0.104515 Thermal: 0.000451 LR: 4.06e-06\n",
      "Epoch  23 [8950/10697 ( 83.7%)] Loss: 0.024815 L1: 0.014536 Grad: 0.102597 Thermal: 0.000385 LR: 4.06e-06\n",
      "Epoch  23 [8950/10697 ( 83.7%)] Loss: 0.024815 L1: 0.014536 Grad: 0.102597 Thermal: 0.000385 LR: 4.06e-06\n",
      "Epoch  23 [9000/10697 ( 84.1%)] Loss: 0.024419 L1: 0.014090 Grad: 0.103098 Thermal: 0.000379 LR: 4.06e-06\n",
      "Epoch  23 [9000/10697 ( 84.1%)] Loss: 0.024419 L1: 0.014090 Grad: 0.103098 Thermal: 0.000379 LR: 4.06e-06\n",
      "Epoch  23 [9050/10697 ( 84.6%)] Loss: 0.024702 L1: 0.014464 Grad: 0.102188 Thermal: 0.000401 LR: 4.06e-06\n",
      "Epoch  23 [9050/10697 ( 84.6%)] Loss: 0.024702 L1: 0.014464 Grad: 0.102188 Thermal: 0.000401 LR: 4.06e-06\n",
      "Epoch  23 [9100/10697 ( 85.1%)] Loss: 0.027185 L1: 0.016024 Grad: 0.111379 Thermal: 0.000452 LR: 4.06e-06\n",
      "Epoch  23 [9100/10697 ( 85.1%)] Loss: 0.027185 L1: 0.016024 Grad: 0.111379 Thermal: 0.000452 LR: 4.06e-06\n",
      "Epoch  23 [9150/10697 ( 85.5%)] Loss: 0.028412 L1: 0.016901 Grad: 0.114858 Thermal: 0.000506 LR: 4.06e-06\n",
      "Epoch  23 [9150/10697 ( 85.5%)] Loss: 0.028412 L1: 0.016901 Grad: 0.114858 Thermal: 0.000506 LR: 4.06e-06\n",
      "Epoch  23 [9200/10697 ( 86.0%)] Loss: 0.025942 L1: 0.015654 Grad: 0.102659 Thermal: 0.000444 LR: 4.06e-06\n",
      "Epoch  23 [9200/10697 ( 86.0%)] Loss: 0.025942 L1: 0.015654 Grad: 0.102659 Thermal: 0.000444 LR: 4.06e-06\n",
      "Epoch  23 [9250/10697 ( 86.5%)] Loss: 0.025863 L1: 0.014675 Grad: 0.111665 Thermal: 0.000422 LR: 4.06e-06\n",
      "Epoch  23 [9250/10697 ( 86.5%)] Loss: 0.025863 L1: 0.014675 Grad: 0.111665 Thermal: 0.000422 LR: 4.06e-06\n",
      "Epoch  23 [9300/10697 ( 86.9%)] Loss: 0.027470 L1: 0.016030 Grad: 0.114160 Thermal: 0.000489 LR: 4.06e-06\n",
      "Epoch  23 [9300/10697 ( 86.9%)] Loss: 0.027470 L1: 0.016030 Grad: 0.114160 Thermal: 0.000489 LR: 4.06e-06\n",
      "Epoch  23 [9350/10697 ( 87.4%)] Loss: 0.027500 L1: 0.016095 Grad: 0.113793 Thermal: 0.000515 LR: 4.06e-06\n",
      "Epoch  23 [9350/10697 ( 87.4%)] Loss: 0.027500 L1: 0.016095 Grad: 0.113793 Thermal: 0.000515 LR: 4.06e-06\n",
      "Epoch  23 [9400/10697 ( 87.9%)] Loss: 0.029939 L1: 0.017079 Grad: 0.128306 Thermal: 0.000593 LR: 4.06e-06\n",
      "Epoch  23 [9400/10697 ( 87.9%)] Loss: 0.029939 L1: 0.017079 Grad: 0.128306 Thermal: 0.000593 LR: 4.06e-06\n",
      "Epoch  23 [9450/10697 ( 88.3%)] Loss: 0.029291 L1: 0.016779 Grad: 0.124886 Thermal: 0.000476 LR: 4.06e-06\n",
      "Epoch  23 [9450/10697 ( 88.3%)] Loss: 0.029291 L1: 0.016779 Grad: 0.124886 Thermal: 0.000476 LR: 4.06e-06\n",
      "Epoch  23 [9500/10697 ( 88.8%)] Loss: 0.028998 L1: 0.016845 Grad: 0.121272 Thermal: 0.000522 LR: 4.06e-06\n",
      "Epoch  23 [9500/10697 ( 88.8%)] Loss: 0.028998 L1: 0.016845 Grad: 0.121272 Thermal: 0.000522 LR: 4.06e-06\n",
      "Epoch  23 [9550/10697 ( 89.3%)] Loss: 0.024926 L1: 0.015090 Grad: 0.098148 Thermal: 0.000420 LR: 4.06e-06\n",
      "Epoch  23 [9550/10697 ( 89.3%)] Loss: 0.024926 L1: 0.015090 Grad: 0.098148 Thermal: 0.000420 LR: 4.06e-06\n",
      "Epoch  23 [9600/10697 ( 89.7%)] Loss: 0.027532 L1: 0.015617 Grad: 0.118899 Thermal: 0.000496 LR: 4.06e-06\n",
      "Epoch  23 [9600/10697 ( 89.7%)] Loss: 0.027532 L1: 0.015617 Grad: 0.118899 Thermal: 0.000496 LR: 4.06e-06\n",
      "Epoch  23 [9650/10697 ( 90.2%)] Loss: 0.027577 L1: 0.016105 Grad: 0.114486 Thermal: 0.000481 LR: 4.06e-06\n",
      "Epoch  23 [9650/10697 ( 90.2%)] Loss: 0.027577 L1: 0.016105 Grad: 0.114486 Thermal: 0.000481 LR: 4.06e-06\n",
      "Epoch  23 [9700/10697 ( 90.7%)] Loss: 0.026031 L1: 0.015591 Grad: 0.104178 Thermal: 0.000440 LR: 4.06e-06\n",
      "Epoch  23 [9700/10697 ( 90.7%)] Loss: 0.026031 L1: 0.015591 Grad: 0.104178 Thermal: 0.000440 LR: 4.06e-06\n",
      "Epoch  23 [9750/10697 ( 91.1%)] Loss: 0.024558 L1: 0.014444 Grad: 0.100939 Thermal: 0.000386 LR: 4.06e-06\n",
      "Epoch  23 [9750/10697 ( 91.1%)] Loss: 0.024558 L1: 0.014444 Grad: 0.100939 Thermal: 0.000386 LR: 4.06e-06\n",
      "Epoch  23 [9800/10697 ( 91.6%)] Loss: 0.023786 L1: 0.013755 Grad: 0.100138 Thermal: 0.000355 LR: 4.06e-06\n",
      "Epoch  23 [9800/10697 ( 91.6%)] Loss: 0.023786 L1: 0.013755 Grad: 0.100138 Thermal: 0.000355 LR: 4.06e-06\n",
      "Epoch  23 [9850/10697 ( 92.1%)] Loss: 0.029199 L1: 0.017615 Grad: 0.115552 Thermal: 0.000568 LR: 4.06e-06\n",
      "Epoch  23 [9850/10697 ( 92.1%)] Loss: 0.029199 L1: 0.017615 Grad: 0.115552 Thermal: 0.000568 LR: 4.06e-06\n",
      "Epoch  23 [9900/10697 ( 92.5%)] Loss: 0.033042 L1: 0.019155 Grad: 0.138525 Thermal: 0.000679 LR: 4.06e-06\n",
      "Epoch  23 [9900/10697 ( 92.5%)] Loss: 0.033042 L1: 0.019155 Grad: 0.138525 Thermal: 0.000679 LR: 4.06e-06\n",
      "Epoch  23 [9950/10697 ( 93.0%)] Loss: 0.025278 L1: 0.014322 Grad: 0.109355 Thermal: 0.000411 LR: 4.06e-06\n",
      "Epoch  23 [9950/10697 ( 93.0%)] Loss: 0.025278 L1: 0.014322 Grad: 0.109355 Thermal: 0.000411 LR: 4.06e-06\n",
      "Epoch  23 [10000/10697 ( 93.5%)] Loss: 0.027648 L1: 0.015890 Grad: 0.117361 Thermal: 0.000454 LR: 4.06e-06\n",
      "Epoch  23 [10000/10697 ( 93.5%)] Loss: 0.027648 L1: 0.015890 Grad: 0.117361 Thermal: 0.000454 LR: 4.06e-06\n",
      "Epoch  23 [10050/10697 ( 94.0%)] Loss: 0.028048 L1: 0.016283 Grad: 0.117418 Thermal: 0.000464 LR: 4.06e-06\n",
      "Epoch  23 [10050/10697 ( 94.0%)] Loss: 0.028048 L1: 0.016283 Grad: 0.117418 Thermal: 0.000464 LR: 4.06e-06\n",
      "Epoch  23 [10100/10697 ( 94.4%)] Loss: 0.024427 L1: 0.014242 Grad: 0.101654 Thermal: 0.000381 LR: 4.06e-06\n",
      "Epoch  23 [10100/10697 ( 94.4%)] Loss: 0.024427 L1: 0.014242 Grad: 0.101654 Thermal: 0.000381 LR: 4.06e-06\n",
      "Epoch  23 [10150/10697 ( 94.9%)] Loss: 0.020471 L1: 0.011507 Grad: 0.089512 Thermal: 0.000256 LR: 4.06e-06\n",
      "Epoch  23 [10150/10697 ( 94.9%)] Loss: 0.020471 L1: 0.011507 Grad: 0.089512 Thermal: 0.000256 LR: 4.06e-06\n",
      "Epoch  23 [10200/10697 ( 95.4%)] Loss: 0.024001 L1: 0.014313 Grad: 0.096692 Thermal: 0.000365 LR: 4.06e-06\n",
      "Epoch  23 [10200/10697 ( 95.4%)] Loss: 0.024001 L1: 0.014313 Grad: 0.096692 Thermal: 0.000365 LR: 4.06e-06\n",
      "Epoch  23 [10250/10697 ( 95.8%)] Loss: 0.025391 L1: 0.014853 Grad: 0.105184 Thermal: 0.000404 LR: 4.06e-06\n",
      "Epoch  23 [10250/10697 ( 95.8%)] Loss: 0.025391 L1: 0.014853 Grad: 0.105184 Thermal: 0.000404 LR: 4.06e-06\n",
      "Epoch  23 [10300/10697 ( 96.3%)] Loss: 0.026333 L1: 0.015867 Grad: 0.104428 Thermal: 0.000460 LR: 4.06e-06\n",
      "Epoch  23 [10300/10697 ( 96.3%)] Loss: 0.026333 L1: 0.015867 Grad: 0.104428 Thermal: 0.000460 LR: 4.06e-06\n",
      "Epoch  23 [10350/10697 ( 96.8%)] Loss: 0.019201 L1: 0.011161 Grad: 0.080254 Thermal: 0.000285 LR: 4.06e-06\n",
      "Epoch  23 [10350/10697 ( 96.8%)] Loss: 0.019201 L1: 0.011161 Grad: 0.080254 Thermal: 0.000285 LR: 4.06e-06\n",
      "Epoch  23 [10400/10697 ( 97.2%)] Loss: 0.019591 L1: 0.011031 Grad: 0.085463 Thermal: 0.000266 LR: 4.06e-06\n",
      "Epoch  23 [10400/10697 ( 97.2%)] Loss: 0.019591 L1: 0.011031 Grad: 0.085463 Thermal: 0.000266 LR: 4.06e-06\n",
      "Epoch  23 [10450/10697 ( 97.7%)] Loss: 0.032530 L1: 0.019817 Grad: 0.126741 Thermal: 0.000772 LR: 4.06e-06\n",
      "Epoch  23 [10450/10697 ( 97.7%)] Loss: 0.032530 L1: 0.019817 Grad: 0.126741 Thermal: 0.000772 LR: 4.06e-06\n",
      "Epoch  23 [10500/10697 ( 98.2%)] Loss: 0.027777 L1: 0.016621 Grad: 0.111317 Thermal: 0.000495 LR: 4.06e-06\n",
      "Epoch  23 [10500/10697 ( 98.2%)] Loss: 0.027777 L1: 0.016621 Grad: 0.111317 Thermal: 0.000495 LR: 4.06e-06\n",
      "Epoch  23 [10550/10697 ( 98.6%)] Loss: 0.020916 L1: 0.012351 Grad: 0.085494 Thermal: 0.000310 LR: 4.06e-06\n",
      "Epoch  23 [10550/10697 ( 98.6%)] Loss: 0.020916 L1: 0.012351 Grad: 0.085494 Thermal: 0.000310 LR: 4.06e-06\n",
      "Epoch  23 [10600/10697 ( 99.1%)] Loss: 0.029873 L1: 0.017290 Grad: 0.125548 Thermal: 0.000578 LR: 4.06e-06\n",
      "Epoch  23 [10600/10697 ( 99.1%)] Loss: 0.029873 L1: 0.017290 Grad: 0.125548 Thermal: 0.000578 LR: 4.06e-06\n",
      "Epoch  23 [10650/10697 ( 99.6%)] Loss: 0.023558 L1: 0.013611 Grad: 0.099302 Thermal: 0.000350 LR: 4.06e-06\n",
      "Epoch  23 [10650/10697 ( 99.6%)] Loss: 0.023558 L1: 0.013611 Grad: 0.099302 Thermal: 0.000350 LR: 4.06e-06\n",
      "Epoch  23 Summary: Loss=0.026341 (L1:0.0154, Grad:0.1096, Thermal:0.0005) Val_PSNR=0.00dB Best=33.92dB Time=88.3min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  23 Summary: Loss=0.026341 (L1:0.0154, Grad:0.1096, Thermal:0.0005) Val_PSNR=0.00dB Best=33.92dB Time=88.3min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  24 [   0/10697 (  0.0%)] Loss: 0.023272 L1: 0.013531 Grad: 0.097239 Thermal: 0.000348 LR: 3.98e-06\n",
      "Epoch  24 [   0/10697 (  0.0%)] Loss: 0.023272 L1: 0.013531 Grad: 0.097239 Thermal: 0.000348 LR: 3.98e-06\n",
      "Epoch  24 [  50/10697 (  0.5%)] Loss: 0.021387 L1: 0.012360 Grad: 0.090116 Thermal: 0.000309 LR: 3.98e-06\n",
      "Epoch  24 [  50/10697 (  0.5%)] Loss: 0.021387 L1: 0.012360 Grad: 0.090116 Thermal: 0.000309 LR: 3.98e-06\n",
      "Epoch  24 [ 100/10697 (  0.9%)] Loss: 0.029422 L1: 0.016984 Grad: 0.124100 Thermal: 0.000557 LR: 3.98e-06\n",
      "Epoch  24 [ 100/10697 (  0.9%)] Loss: 0.029422 L1: 0.016984 Grad: 0.124100 Thermal: 0.000557 LR: 3.98e-06\n",
      "Epoch  24 [ 150/10697 (  1.4%)] Loss: 0.026630 L1: 0.015515 Grad: 0.110932 Thermal: 0.000437 LR: 3.98e-06\n",
      "Epoch  24 [ 150/10697 (  1.4%)] Loss: 0.026630 L1: 0.015515 Grad: 0.110932 Thermal: 0.000437 LR: 3.98e-06\n",
      "Epoch  24 [ 200/10697 (  1.9%)] Loss: 0.028297 L1: 0.016730 Grad: 0.115422 Thermal: 0.000494 LR: 3.98e-06\n",
      "Epoch  24 [ 200/10697 (  1.9%)] Loss: 0.028297 L1: 0.016730 Grad: 0.115422 Thermal: 0.000494 LR: 3.98e-06\n",
      "Epoch  24 [ 250/10697 (  2.3%)] Loss: 0.026385 L1: 0.015533 Grad: 0.108291 Thermal: 0.000447 LR: 3.98e-06\n",
      "Epoch  24 [ 250/10697 (  2.3%)] Loss: 0.026385 L1: 0.015533 Grad: 0.108291 Thermal: 0.000447 LR: 3.98e-06\n",
      "Epoch  24 [ 300/10697 (  2.8%)] Loss: 0.020820 L1: 0.011956 Grad: 0.088495 Thermal: 0.000290 LR: 3.98e-06\n",
      "Epoch  24 [ 300/10697 (  2.8%)] Loss: 0.020820 L1: 0.011956 Grad: 0.088495 Thermal: 0.000290 LR: 3.98e-06\n",
      "Epoch  24 [ 350/10697 (  3.3%)] Loss: 0.022399 L1: 0.013123 Grad: 0.092578 Thermal: 0.000351 LR: 3.98e-06\n",
      "Epoch  24 [ 350/10697 (  3.3%)] Loss: 0.022399 L1: 0.013123 Grad: 0.092578 Thermal: 0.000351 LR: 3.98e-06\n",
      "Epoch  24 [ 400/10697 (  3.7%)] Loss: 0.024338 L1: 0.014156 Grad: 0.101627 Thermal: 0.000381 LR: 3.98e-06\n",
      "Epoch  24 [ 400/10697 (  3.7%)] Loss: 0.024338 L1: 0.014156 Grad: 0.101627 Thermal: 0.000381 LR: 3.98e-06\n",
      "Epoch  24 [ 450/10697 (  4.2%)] Loss: 0.026392 L1: 0.015110 Grad: 0.112582 Thermal: 0.000463 LR: 3.98e-06\n",
      "Epoch  24 [ 450/10697 (  4.2%)] Loss: 0.026392 L1: 0.015110 Grad: 0.112582 Thermal: 0.000463 LR: 3.98e-06\n",
      "Epoch  24 [ 500/10697 (  4.7%)] Loss: 0.027084 L1: 0.015734 Grad: 0.113272 Thermal: 0.000462 LR: 3.98e-06\n",
      "Epoch  24 [ 500/10697 (  4.7%)] Loss: 0.027084 L1: 0.015734 Grad: 0.113272 Thermal: 0.000462 LR: 3.98e-06\n",
      "Epoch  24 [ 550/10697 (  5.1%)] Loss: 0.027487 L1: 0.016068 Grad: 0.113922 Thermal: 0.000528 LR: 3.98e-06\n",
      "Epoch  24 [ 550/10697 (  5.1%)] Loss: 0.027487 L1: 0.016068 Grad: 0.113922 Thermal: 0.000528 LR: 3.98e-06\n",
      "Epoch  24 [ 600/10697 (  5.6%)] Loss: 0.023103 L1: 0.013676 Grad: 0.094092 Thermal: 0.000368 LR: 3.98e-06\n",
      "Epoch  24 [ 600/10697 (  5.6%)] Loss: 0.023103 L1: 0.013676 Grad: 0.094092 Thermal: 0.000368 LR: 3.98e-06\n",
      "Epoch  24 [ 650/10697 (  6.1%)] Loss: 0.042464 L1: 0.024609 Grad: 0.177913 Thermal: 0.001273 LR: 3.98e-06\n",
      "Epoch  24 [ 650/10697 (  6.1%)] Loss: 0.042464 L1: 0.024609 Grad: 0.177913 Thermal: 0.001273 LR: 3.98e-06\n",
      "Epoch  24 [ 700/10697 (  6.5%)] Loss: 0.023678 L1: 0.013961 Grad: 0.096961 Thermal: 0.000407 LR: 3.98e-06\n",
      "Epoch  24 [ 700/10697 (  6.5%)] Loss: 0.023678 L1: 0.013961 Grad: 0.096961 Thermal: 0.000407 LR: 3.98e-06\n",
      "Epoch  24 [ 750/10697 (  7.0%)] Loss: 0.026577 L1: 0.015538 Grad: 0.110159 Thermal: 0.000458 LR: 3.98e-06\n",
      "Epoch  24 [ 750/10697 (  7.0%)] Loss: 0.026577 L1: 0.015538 Grad: 0.110159 Thermal: 0.000458 LR: 3.98e-06\n",
      "Epoch  24 [ 800/10697 (  7.5%)] Loss: 0.024028 L1: 0.013964 Grad: 0.100457 Thermal: 0.000370 LR: 3.98e-06\n",
      "Epoch  24 [ 800/10697 (  7.5%)] Loss: 0.024028 L1: 0.013964 Grad: 0.100457 Thermal: 0.000370 LR: 3.98e-06\n",
      "Epoch  24 [ 850/10697 (  7.9%)] Loss: 0.025124 L1: 0.015097 Grad: 0.100005 Thermal: 0.000525 LR: 3.98e-06\n",
      "Epoch  24 [ 850/10697 (  7.9%)] Loss: 0.025124 L1: 0.015097 Grad: 0.100005 Thermal: 0.000525 LR: 3.98e-06\n",
      "Epoch  24 [ 900/10697 (  8.4%)] Loss: 0.023596 L1: 0.013633 Grad: 0.099447 Thermal: 0.000376 LR: 3.98e-06\n",
      "Epoch  24 [ 900/10697 (  8.4%)] Loss: 0.023596 L1: 0.013633 Grad: 0.099447 Thermal: 0.000376 LR: 3.98e-06\n",
      "Epoch  24 [ 950/10697 (  8.9%)] Loss: 0.027029 L1: 0.015807 Grad: 0.111981 Thermal: 0.000474 LR: 3.98e-06\n",
      "Epoch  24 [ 950/10697 (  8.9%)] Loss: 0.027029 L1: 0.015807 Grad: 0.111981 Thermal: 0.000474 LR: 3.98e-06\n",
      "Epoch  24 [1000/10697 (  9.3%)] Loss: 0.027986 L1: 0.016475 Grad: 0.114876 Thermal: 0.000481 LR: 3.98e-06\n",
      "Epoch  24 [1000/10697 (  9.3%)] Loss: 0.027986 L1: 0.016475 Grad: 0.114876 Thermal: 0.000481 LR: 3.98e-06\n",
      "Epoch  24 [1050/10697 (  9.8%)] Loss: 0.022291 L1: 0.013119 Grad: 0.091544 Thermal: 0.000354 LR: 3.98e-06\n",
      "Epoch  24 [1050/10697 (  9.8%)] Loss: 0.022291 L1: 0.013119 Grad: 0.091544 Thermal: 0.000354 LR: 3.98e-06\n",
      "Epoch  24 [1100/10697 ( 10.3%)] Loss: 0.025675 L1: 0.015019 Grad: 0.106347 Thermal: 0.000407 LR: 3.98e-06\n",
      "Epoch  24 [1100/10697 ( 10.3%)] Loss: 0.025675 L1: 0.015019 Grad: 0.106347 Thermal: 0.000407 LR: 3.98e-06\n",
      "Epoch  24 [1150/10697 ( 10.8%)] Loss: 0.023756 L1: 0.013538 Grad: 0.101997 Thermal: 0.000372 LR: 3.98e-06\n",
      "Epoch  24 [1150/10697 ( 10.8%)] Loss: 0.023756 L1: 0.013538 Grad: 0.101997 Thermal: 0.000372 LR: 3.98e-06\n",
      "Epoch  24 [1200/10697 ( 11.2%)] Loss: 0.029442 L1: 0.017575 Grad: 0.118405 Thermal: 0.000529 LR: 3.98e-06\n",
      "Epoch  24 [1200/10697 ( 11.2%)] Loss: 0.029442 L1: 0.017575 Grad: 0.118405 Thermal: 0.000529 LR: 3.98e-06\n",
      "Epoch  24 [1250/10697 ( 11.7%)] Loss: 0.024736 L1: 0.014393 Grad: 0.103223 Thermal: 0.000398 LR: 3.98e-06\n",
      "Epoch  24 [1250/10697 ( 11.7%)] Loss: 0.024736 L1: 0.014393 Grad: 0.103223 Thermal: 0.000398 LR: 3.98e-06\n",
      "Epoch  24 [1300/10697 ( 12.2%)] Loss: 0.024071 L1: 0.014126 Grad: 0.099257 Thermal: 0.000385 LR: 3.98e-06\n",
      "Epoch  24 [1300/10697 ( 12.2%)] Loss: 0.024071 L1: 0.014126 Grad: 0.099257 Thermal: 0.000385 LR: 3.98e-06\n",
      "Epoch  24 [1350/10697 ( 12.6%)] Loss: 0.026649 L1: 0.015516 Grad: 0.111102 Thermal: 0.000457 LR: 3.98e-06\n",
      "Epoch  24 [1350/10697 ( 12.6%)] Loss: 0.026649 L1: 0.015516 Grad: 0.111102 Thermal: 0.000457 LR: 3.98e-06\n",
      "Epoch  24 [1400/10697 ( 13.1%)] Loss: 0.028508 L1: 0.016157 Grad: 0.123175 Thermal: 0.000679 LR: 3.98e-06\n",
      "Epoch  24 [1400/10697 ( 13.1%)] Loss: 0.028508 L1: 0.016157 Grad: 0.123175 Thermal: 0.000679 LR: 3.98e-06\n",
      "Epoch  24 [1450/10697 ( 13.6%)] Loss: 0.030334 L1: 0.017303 Grad: 0.129973 Thermal: 0.000678 LR: 3.98e-06\n",
      "Epoch  24 [1450/10697 ( 13.6%)] Loss: 0.030334 L1: 0.017303 Grad: 0.129973 Thermal: 0.000678 LR: 3.98e-06\n",
      "Epoch  24 [1500/10697 ( 14.0%)] Loss: 0.030591 L1: 0.017652 Grad: 0.129076 Thermal: 0.000633 LR: 3.98e-06\n",
      "Epoch  24 [1500/10697 ( 14.0%)] Loss: 0.030591 L1: 0.017652 Grad: 0.129076 Thermal: 0.000633 LR: 3.98e-06\n",
      "Epoch  24 [1550/10697 ( 14.5%)] Loss: 0.023740 L1: 0.013179 Grad: 0.105419 Thermal: 0.000387 LR: 3.98e-06\n",
      "Epoch  24 [1550/10697 ( 14.5%)] Loss: 0.023740 L1: 0.013179 Grad: 0.105419 Thermal: 0.000387 LR: 3.98e-06\n",
      "Epoch  24 [1600/10697 ( 15.0%)] Loss: 0.024745 L1: 0.014144 Grad: 0.105796 Thermal: 0.000426 LR: 3.98e-06\n",
      "Epoch  24 [1600/10697 ( 15.0%)] Loss: 0.024745 L1: 0.014144 Grad: 0.105796 Thermal: 0.000426 LR: 3.98e-06\n",
      "Epoch  24 [1650/10697 ( 15.4%)] Loss: 0.021065 L1: 0.012737 Grad: 0.083108 Thermal: 0.000342 LR: 3.98e-06\n",
      "Epoch  24 [1650/10697 ( 15.4%)] Loss: 0.021065 L1: 0.012737 Grad: 0.083108 Thermal: 0.000342 LR: 3.98e-06\n",
      "Epoch  24 [1700/10697 ( 15.9%)] Loss: 0.025371 L1: 0.014821 Grad: 0.105299 Thermal: 0.000398 LR: 3.98e-06\n",
      "Epoch  24 [1700/10697 ( 15.9%)] Loss: 0.025371 L1: 0.014821 Grad: 0.105299 Thermal: 0.000398 LR: 3.98e-06\n",
      "Epoch  24 [1750/10697 ( 16.4%)] Loss: 0.023332 L1: 0.013254 Grad: 0.100601 Thermal: 0.000341 LR: 3.98e-06\n",
      "Epoch  24 [1750/10697 ( 16.4%)] Loss: 0.023332 L1: 0.013254 Grad: 0.100601 Thermal: 0.000341 LR: 3.98e-06\n",
      "Epoch  24 [1800/10697 ( 16.8%)] Loss: 0.028818 L1: 0.017153 Grad: 0.116398 Thermal: 0.000508 LR: 3.98e-06\n",
      "Epoch  24 [1800/10697 ( 16.8%)] Loss: 0.028818 L1: 0.017153 Grad: 0.116398 Thermal: 0.000508 LR: 3.98e-06\n",
      "Epoch  24 [1850/10697 ( 17.3%)] Loss: 0.031520 L1: 0.017772 Grad: 0.137193 Thermal: 0.000572 LR: 3.98e-06\n",
      "Epoch  24 [1850/10697 ( 17.3%)] Loss: 0.031520 L1: 0.017772 Grad: 0.137193 Thermal: 0.000572 LR: 3.98e-06\n",
      "Epoch  24 [1900/10697 ( 17.8%)] Loss: 0.025416 L1: 0.015117 Grad: 0.102783 Thermal: 0.000420 LR: 3.98e-06\n",
      "Epoch  24 [1900/10697 ( 17.8%)] Loss: 0.025416 L1: 0.015117 Grad: 0.102783 Thermal: 0.000420 LR: 3.98e-06\n",
      "Epoch  24 [1950/10697 ( 18.2%)] Loss: 0.018978 L1: 0.010880 Grad: 0.080849 Thermal: 0.000253 LR: 3.98e-06\n",
      "Epoch  24 [1950/10697 ( 18.2%)] Loss: 0.018978 L1: 0.010880 Grad: 0.080849 Thermal: 0.000253 LR: 3.98e-06\n",
      "Epoch  24 [2000/10697 ( 18.7%)] Loss: 0.029014 L1: 0.017163 Grad: 0.118236 Thermal: 0.000551 LR: 3.98e-06\n",
      "Epoch  24 [2000/10697 ( 18.7%)] Loss: 0.029014 L1: 0.017163 Grad: 0.118236 Thermal: 0.000551 LR: 3.98e-06\n",
      "Epoch  24 [2050/10697 ( 19.2%)] Loss: 0.025763 L1: 0.015283 Grad: 0.104587 Thermal: 0.000439 LR: 3.98e-06\n",
      "Epoch  24 [2050/10697 ( 19.2%)] Loss: 0.025763 L1: 0.015283 Grad: 0.104587 Thermal: 0.000439 LR: 3.98e-06\n",
      "Epoch  24 [2100/10697 ( 19.6%)] Loss: 0.023326 L1: 0.013745 Grad: 0.095617 Thermal: 0.000379 LR: 3.98e-06\n",
      "Epoch  24 [2100/10697 ( 19.6%)] Loss: 0.023326 L1: 0.013745 Grad: 0.095617 Thermal: 0.000379 LR: 3.98e-06\n",
      "Epoch  24 [2150/10697 ( 20.1%)] Loss: 0.026517 L1: 0.015741 Grad: 0.107513 Thermal: 0.000502 LR: 3.98e-06\n",
      "Epoch  24 [2150/10697 ( 20.1%)] Loss: 0.026517 L1: 0.015741 Grad: 0.107513 Thermal: 0.000502 LR: 3.98e-06\n",
      "Epoch  24 [2200/10697 ( 20.6%)] Loss: 0.024162 L1: 0.013831 Grad: 0.103132 Thermal: 0.000360 LR: 3.98e-06\n",
      "Epoch  24 [2200/10697 ( 20.6%)] Loss: 0.024162 L1: 0.013831 Grad: 0.103132 Thermal: 0.000360 LR: 3.98e-06\n",
      "Epoch  24 [2250/10697 ( 21.0%)] Loss: 0.025012 L1: 0.014370 Grad: 0.106201 Thermal: 0.000434 LR: 3.98e-06\n",
      "Epoch  24 [2250/10697 ( 21.0%)] Loss: 0.025012 L1: 0.014370 Grad: 0.106201 Thermal: 0.000434 LR: 3.98e-06\n",
      "Epoch  24 [2300/10697 ( 21.5%)] Loss: 0.025462 L1: 0.014570 Grad: 0.108720 Thermal: 0.000403 LR: 3.98e-06\n",
      "Epoch  24 [2300/10697 ( 21.5%)] Loss: 0.025462 L1: 0.014570 Grad: 0.108720 Thermal: 0.000403 LR: 3.98e-06\n",
      "Epoch  24 [2350/10697 ( 22.0%)] Loss: 0.028665 L1: 0.016995 Grad: 0.116414 Thermal: 0.000563 LR: 3.98e-06\n",
      "Epoch  24 [2350/10697 ( 22.0%)] Loss: 0.028665 L1: 0.016995 Grad: 0.116414 Thermal: 0.000563 LR: 3.98e-06\n",
      "Epoch  24 [2400/10697 ( 22.4%)] Loss: 0.020162 L1: 0.011735 Grad: 0.084141 Thermal: 0.000264 LR: 3.98e-06\n",
      "Epoch  24 [2400/10697 ( 22.4%)] Loss: 0.020162 L1: 0.011735 Grad: 0.084141 Thermal: 0.000264 LR: 3.98e-06\n",
      "Epoch  24 [2450/10697 ( 22.9%)] Loss: 0.025379 L1: 0.015215 Grad: 0.101434 Thermal: 0.000414 LR: 3.98e-06\n",
      "Epoch  24 [2450/10697 ( 22.9%)] Loss: 0.025379 L1: 0.015215 Grad: 0.101434 Thermal: 0.000414 LR: 3.98e-06\n",
      "Epoch  24 [2500/10697 ( 23.4%)] Loss: 0.028269 L1: 0.016497 Grad: 0.117477 Thermal: 0.000496 LR: 3.98e-06\n",
      "Epoch  24 [2500/10697 ( 23.4%)] Loss: 0.028269 L1: 0.016497 Grad: 0.117477 Thermal: 0.000496 LR: 3.98e-06\n",
      "Epoch  24 [2550/10697 ( 23.8%)] Loss: 0.024100 L1: 0.014419 Grad: 0.096614 Thermal: 0.000391 LR: 3.98e-06\n",
      "Epoch  24 [2550/10697 ( 23.8%)] Loss: 0.024100 L1: 0.014419 Grad: 0.096614 Thermal: 0.000391 LR: 3.98e-06\n",
      "Epoch  24 [2600/10697 ( 24.3%)] Loss: 0.024824 L1: 0.014465 Grad: 0.103399 Thermal: 0.000388 LR: 3.98e-06\n",
      "Epoch  24 [2600/10697 ( 24.3%)] Loss: 0.024824 L1: 0.014465 Grad: 0.103399 Thermal: 0.000388 LR: 3.98e-06\n",
      "Epoch  24 [2650/10697 ( 24.8%)] Loss: 0.028759 L1: 0.016666 Grad: 0.120636 Thermal: 0.000585 LR: 3.98e-06\n",
      "Epoch  24 [2650/10697 ( 24.8%)] Loss: 0.028759 L1: 0.016666 Grad: 0.120636 Thermal: 0.000585 LR: 3.98e-06\n",
      "Epoch  24 [2700/10697 ( 25.2%)] Loss: 0.022523 L1: 0.012450 Grad: 0.100560 Thermal: 0.000334 LR: 3.98e-06\n",
      "Epoch  24 [2700/10697 ( 25.2%)] Loss: 0.022523 L1: 0.012450 Grad: 0.100560 Thermal: 0.000334 LR: 3.98e-06\n",
      "Epoch  24 [2750/10697 ( 25.7%)] Loss: 0.027595 L1: 0.016325 Grad: 0.112477 Thermal: 0.000444 LR: 3.98e-06\n",
      "Epoch  24 [2750/10697 ( 25.7%)] Loss: 0.027595 L1: 0.016325 Grad: 0.112477 Thermal: 0.000444 LR: 3.98e-06\n",
      "Epoch  24 [2800/10697 ( 26.2%)] Loss: 0.029735 L1: 0.017730 Grad: 0.119776 Thermal: 0.000563 LR: 3.98e-06\n",
      "Epoch  24 [2800/10697 ( 26.2%)] Loss: 0.029735 L1: 0.017730 Grad: 0.119776 Thermal: 0.000563 LR: 3.98e-06\n",
      "Epoch  24 [2850/10697 ( 26.6%)] Loss: 0.025964 L1: 0.015534 Grad: 0.104088 Thermal: 0.000429 LR: 3.98e-06\n",
      "Epoch  24 [2850/10697 ( 26.6%)] Loss: 0.025964 L1: 0.015534 Grad: 0.104088 Thermal: 0.000429 LR: 3.98e-06\n",
      "Epoch  24 [2900/10697 ( 27.1%)] Loss: 0.022407 L1: 0.013055 Grad: 0.093357 Thermal: 0.000335 LR: 3.98e-06\n",
      "Epoch  24 [2900/10697 ( 27.1%)] Loss: 0.022407 L1: 0.013055 Grad: 0.093357 Thermal: 0.000335 LR: 3.98e-06\n",
      "Epoch  24 [2950/10697 ( 27.6%)] Loss: 0.026374 L1: 0.015634 Grad: 0.107161 Thermal: 0.000478 LR: 3.98e-06\n",
      "Epoch  24 [2950/10697 ( 27.6%)] Loss: 0.026374 L1: 0.015634 Grad: 0.107161 Thermal: 0.000478 LR: 3.98e-06\n",
      "Epoch  24 [3000/10697 ( 28.0%)] Loss: 0.023434 L1: 0.013801 Grad: 0.096146 Thermal: 0.000377 LR: 3.98e-06\n",
      "Epoch  24 [3000/10697 ( 28.0%)] Loss: 0.023434 L1: 0.013801 Grad: 0.096146 Thermal: 0.000377 LR: 3.98e-06\n",
      "Epoch  24 [3050/10697 ( 28.5%)] Loss: 0.024736 L1: 0.014720 Grad: 0.099958 Thermal: 0.000405 LR: 3.98e-06\n",
      "Epoch  24 [3050/10697 ( 28.5%)] Loss: 0.024736 L1: 0.014720 Grad: 0.099958 Thermal: 0.000405 LR: 3.98e-06\n",
      "Epoch  24 [3100/10697 ( 29.0%)] Loss: 0.022969 L1: 0.013716 Grad: 0.092352 Thermal: 0.000353 LR: 3.98e-06\n",
      "Epoch  24 [3100/10697 ( 29.0%)] Loss: 0.022969 L1: 0.013716 Grad: 0.092352 Thermal: 0.000353 LR: 3.98e-06\n",
      "Epoch  24 [3150/10697 ( 29.4%)] Loss: 0.027258 L1: 0.016057 Grad: 0.111767 Thermal: 0.000482 LR: 3.98e-06\n",
      "Epoch  24 [3150/10697 ( 29.4%)] Loss: 0.027258 L1: 0.016057 Grad: 0.111767 Thermal: 0.000482 LR: 3.98e-06\n",
      "Epoch  24 [3200/10697 ( 29.9%)] Loss: 0.028968 L1: 0.016837 Grad: 0.121061 Thermal: 0.000499 LR: 3.98e-06\n",
      "Epoch  24 [3200/10697 ( 29.9%)] Loss: 0.028968 L1: 0.016837 Grad: 0.121061 Thermal: 0.000499 LR: 3.98e-06\n",
      "Epoch  24 [3250/10697 ( 30.4%)] Loss: 0.023159 L1: 0.013714 Grad: 0.094257 Thermal: 0.000385 LR: 3.98e-06\n",
      "Epoch  24 [3250/10697 ( 30.4%)] Loss: 0.023159 L1: 0.013714 Grad: 0.094257 Thermal: 0.000385 LR: 3.98e-06\n",
      "Epoch  24 [3300/10697 ( 30.8%)] Loss: 0.027645 L1: 0.016365 Grad: 0.112554 Thermal: 0.000494 LR: 3.98e-06\n",
      "Epoch  24 [3300/10697 ( 30.8%)] Loss: 0.027645 L1: 0.016365 Grad: 0.112554 Thermal: 0.000494 LR: 3.98e-06\n",
      "Epoch  24 [3350/10697 ( 31.3%)] Loss: 0.027923 L1: 0.016817 Grad: 0.110813 Thermal: 0.000503 LR: 3.98e-06\n",
      "Epoch  24 [3350/10697 ( 31.3%)] Loss: 0.027923 L1: 0.016817 Grad: 0.110813 Thermal: 0.000503 LR: 3.98e-06\n",
      "Epoch  24 [3400/10697 ( 31.8%)] Loss: 0.021821 L1: 0.012462 Grad: 0.093427 Thermal: 0.000330 LR: 3.98e-06\n",
      "Epoch  24 [3400/10697 ( 31.8%)] Loss: 0.021821 L1: 0.012462 Grad: 0.093427 Thermal: 0.000330 LR: 3.98e-06\n",
      "Epoch  24 [3450/10697 ( 32.3%)] Loss: 0.027324 L1: 0.015937 Grad: 0.113627 Thermal: 0.000483 LR: 3.98e-06\n",
      "Epoch  24 [3450/10697 ( 32.3%)] Loss: 0.027324 L1: 0.015937 Grad: 0.113627 Thermal: 0.000483 LR: 3.98e-06\n",
      "Epoch  24 [3500/10697 ( 32.7%)] Loss: 0.031718 L1: 0.018390 Grad: 0.132978 Thermal: 0.000605 LR: 3.98e-06\n",
      "Epoch  24 [3500/10697 ( 32.7%)] Loss: 0.031718 L1: 0.018390 Grad: 0.132978 Thermal: 0.000605 LR: 3.98e-06\n",
      "Epoch  24 [3550/10697 ( 33.2%)] Loss: 0.022294 L1: 0.012993 Grad: 0.092849 Thermal: 0.000329 LR: 3.98e-06\n",
      "Epoch  24 [3550/10697 ( 33.2%)] Loss: 0.022294 L1: 0.012993 Grad: 0.092849 Thermal: 0.000329 LR: 3.98e-06\n",
      "Epoch  24 [3600/10697 ( 33.7%)] Loss: 0.023231 L1: 0.013475 Grad: 0.097372 Thermal: 0.000383 LR: 3.98e-06\n",
      "Epoch  24 [3600/10697 ( 33.7%)] Loss: 0.023231 L1: 0.013475 Grad: 0.097372 Thermal: 0.000383 LR: 3.98e-06\n",
      "Epoch  24 [3650/10697 ( 34.1%)] Loss: 0.028188 L1: 0.016277 Grad: 0.118871 Thermal: 0.000476 LR: 3.98e-06\n",
      "Epoch  24 [3650/10697 ( 34.1%)] Loss: 0.028188 L1: 0.016277 Grad: 0.118871 Thermal: 0.000476 LR: 3.98e-06\n",
      "Epoch  24 [3700/10697 ( 34.6%)] Loss: 0.029072 L1: 0.016826 Grad: 0.122159 Thermal: 0.000606 LR: 3.98e-06\n",
      "Epoch  24 [3700/10697 ( 34.6%)] Loss: 0.029072 L1: 0.016826 Grad: 0.122159 Thermal: 0.000606 LR: 3.98e-06\n",
      "Epoch  24 [3750/10697 ( 35.1%)] Loss: 0.029753 L1: 0.017570 Grad: 0.121548 Thermal: 0.000564 LR: 3.98e-06\n",
      "Epoch  24 [3750/10697 ( 35.1%)] Loss: 0.029753 L1: 0.017570 Grad: 0.121548 Thermal: 0.000564 LR: 3.98e-06\n",
      "Epoch  24 [3800/10697 ( 35.5%)] Loss: 0.028038 L1: 0.016233 Grad: 0.117811 Thermal: 0.000484 LR: 3.98e-06\n",
      "Epoch  24 [3800/10697 ( 35.5%)] Loss: 0.028038 L1: 0.016233 Grad: 0.117811 Thermal: 0.000484 LR: 3.98e-06\n",
      "Epoch  24 [3850/10697 ( 36.0%)] Loss: 0.018622 L1: 0.010652 Grad: 0.079568 Thermal: 0.000268 LR: 3.98e-06\n",
      "Epoch  24 [3850/10697 ( 36.0%)] Loss: 0.018622 L1: 0.010652 Grad: 0.079568 Thermal: 0.000268 LR: 3.98e-06\n",
      "Epoch  24 [3900/10697 ( 36.5%)] Loss: 0.027435 L1: 0.015958 Grad: 0.114533 Thermal: 0.000458 LR: 3.98e-06\n",
      "Epoch  24 [3900/10697 ( 36.5%)] Loss: 0.027435 L1: 0.015958 Grad: 0.114533 Thermal: 0.000458 LR: 3.98e-06\n",
      "Epoch  24 [3950/10697 ( 36.9%)] Loss: 0.026577 L1: 0.016061 Grad: 0.104937 Thermal: 0.000454 LR: 3.98e-06\n",
      "Epoch  24 [3950/10697 ( 36.9%)] Loss: 0.026577 L1: 0.016061 Grad: 0.104937 Thermal: 0.000454 LR: 3.98e-06\n",
      "Epoch  24 [4000/10697 ( 37.4%)] Loss: 0.027035 L1: 0.015685 Grad: 0.113284 Thermal: 0.000443 LR: 3.98e-06\n",
      "Epoch  24 [4000/10697 ( 37.4%)] Loss: 0.027035 L1: 0.015685 Grad: 0.113284 Thermal: 0.000443 LR: 3.98e-06\n",
      "Epoch  24 [4050/10697 ( 37.9%)] Loss: 0.027331 L1: 0.016128 Grad: 0.111794 Thermal: 0.000473 LR: 3.98e-06\n",
      "Epoch  24 [4050/10697 ( 37.9%)] Loss: 0.027331 L1: 0.016128 Grad: 0.111794 Thermal: 0.000473 LR: 3.98e-06\n",
      "Epoch  24 [4100/10697 ( 38.3%)] Loss: 0.028261 L1: 0.016693 Grad: 0.115436 Thermal: 0.000495 LR: 3.98e-06\n",
      "Epoch  24 [4100/10697 ( 38.3%)] Loss: 0.028261 L1: 0.016693 Grad: 0.115436 Thermal: 0.000495 LR: 3.98e-06\n",
      "Epoch  24 [4150/10697 ( 38.8%)] Loss: 0.031715 L1: 0.018171 Grad: 0.135145 Thermal: 0.000589 LR: 3.98e-06\n",
      "Epoch  24 [4150/10697 ( 38.8%)] Loss: 0.031715 L1: 0.018171 Grad: 0.135145 Thermal: 0.000589 LR: 3.98e-06\n",
      "Epoch  24 [4200/10697 ( 39.3%)] Loss: 0.030021 L1: 0.017680 Grad: 0.123132 Thermal: 0.000559 LR: 3.98e-06\n",
      "Epoch  24 [4200/10697 ( 39.3%)] Loss: 0.030021 L1: 0.017680 Grad: 0.123132 Thermal: 0.000559 LR: 3.98e-06\n",
      "Epoch  24 [4250/10697 ( 39.7%)] Loss: 0.025439 L1: 0.014601 Grad: 0.108155 Thermal: 0.000454 LR: 3.98e-06\n",
      "Epoch  24 [4250/10697 ( 39.7%)] Loss: 0.025439 L1: 0.014601 Grad: 0.108155 Thermal: 0.000454 LR: 3.98e-06\n",
      "Epoch  24 [4300/10697 ( 40.2%)] Loss: 0.026257 L1: 0.015812 Grad: 0.104226 Thermal: 0.000442 LR: 3.98e-06\n",
      "Epoch  24 [4300/10697 ( 40.2%)] Loss: 0.026257 L1: 0.015812 Grad: 0.104226 Thermal: 0.000442 LR: 3.98e-06\n",
      "Epoch  24 [4350/10697 ( 40.7%)] Loss: 0.022451 L1: 0.013200 Grad: 0.092336 Thermal: 0.000352 LR: 3.98e-06\n",
      "Epoch  24 [4350/10697 ( 40.7%)] Loss: 0.022451 L1: 0.013200 Grad: 0.092336 Thermal: 0.000352 LR: 3.98e-06\n",
      "Epoch  24 [4400/10697 ( 41.1%)] Loss: 0.026729 L1: 0.015553 Grad: 0.111549 Thermal: 0.000429 LR: 3.98e-06\n",
      "Epoch  24 [4400/10697 ( 41.1%)] Loss: 0.026729 L1: 0.015553 Grad: 0.111549 Thermal: 0.000429 LR: 3.98e-06\n",
      "Epoch  24 [4450/10697 ( 41.6%)] Loss: 0.026552 L1: 0.015240 Grad: 0.112897 Thermal: 0.000446 LR: 3.98e-06\n",
      "Epoch  24 [4450/10697 ( 41.6%)] Loss: 0.026552 L1: 0.015240 Grad: 0.112897 Thermal: 0.000446 LR: 3.98e-06\n",
      "Epoch  24 [4500/10697 ( 42.1%)] Loss: 0.030884 L1: 0.017852 Grad: 0.130022 Thermal: 0.000586 LR: 3.98e-06\n",
      "Epoch  24 [4500/10697 ( 42.1%)] Loss: 0.030884 L1: 0.017852 Grad: 0.130022 Thermal: 0.000586 LR: 3.98e-06\n",
      "Epoch  24 [4550/10697 ( 42.5%)] Loss: 0.033950 L1: 0.019430 Grad: 0.144841 Thermal: 0.000734 LR: 3.98e-06\n",
      "Epoch  24 [4550/10697 ( 42.5%)] Loss: 0.033950 L1: 0.019430 Grad: 0.144841 Thermal: 0.000734 LR: 3.98e-06\n",
      "Epoch  24 [4600/10697 ( 43.0%)] Loss: 0.020583 L1: 0.012315 Grad: 0.082519 Thermal: 0.000328 LR: 3.98e-06\n",
      "Epoch  24 [4600/10697 ( 43.0%)] Loss: 0.020583 L1: 0.012315 Grad: 0.082519 Thermal: 0.000328 LR: 3.98e-06\n",
      "Epoch  24 [4650/10697 ( 43.5%)] Loss: 0.026052 L1: 0.015233 Grad: 0.107977 Thermal: 0.000418 LR: 3.98e-06\n",
      "Epoch  24 [4650/10697 ( 43.5%)] Loss: 0.026052 L1: 0.015233 Grad: 0.107977 Thermal: 0.000418 LR: 3.98e-06\n",
      "Epoch  24 [4700/10697 ( 43.9%)] Loss: 0.025754 L1: 0.014866 Grad: 0.108673 Thermal: 0.000407 LR: 3.98e-06\n",
      "Epoch  24 [4700/10697 ( 43.9%)] Loss: 0.025754 L1: 0.014866 Grad: 0.108673 Thermal: 0.000407 LR: 3.98e-06\n",
      "Epoch  24 [4750/10697 ( 44.4%)] Loss: 0.026700 L1: 0.015508 Grad: 0.111697 Thermal: 0.000446 LR: 3.98e-06\n",
      "Epoch  24 [4750/10697 ( 44.4%)] Loss: 0.026700 L1: 0.015508 Grad: 0.111697 Thermal: 0.000446 LR: 3.98e-06\n",
      "Epoch  24 [4800/10697 ( 44.9%)] Loss: 0.031901 L1: 0.017893 Grad: 0.139748 Thermal: 0.000678 LR: 3.98e-06\n",
      "Epoch  24 [4800/10697 ( 44.9%)] Loss: 0.031901 L1: 0.017893 Grad: 0.139748 Thermal: 0.000678 LR: 3.98e-06\n",
      "Epoch  24 [4850/10697 ( 45.3%)] Loss: 0.022078 L1: 0.013029 Grad: 0.090349 Thermal: 0.000296 LR: 3.98e-06\n",
      "Epoch  24 [4850/10697 ( 45.3%)] Loss: 0.022078 L1: 0.013029 Grad: 0.090349 Thermal: 0.000296 LR: 3.98e-06\n",
      "Epoch  24 [4900/10697 ( 45.8%)] Loss: 0.023117 L1: 0.013451 Grad: 0.096477 Thermal: 0.000361 LR: 3.98e-06\n",
      "Epoch  24 [4900/10697 ( 45.8%)] Loss: 0.023117 L1: 0.013451 Grad: 0.096477 Thermal: 0.000361 LR: 3.98e-06\n",
      "Epoch  24 [4950/10697 ( 46.3%)] Loss: 0.024089 L1: 0.014274 Grad: 0.097942 Thermal: 0.000403 LR: 3.98e-06\n",
      "Epoch  24 [4950/10697 ( 46.3%)] Loss: 0.024089 L1: 0.014274 Grad: 0.097942 Thermal: 0.000403 LR: 3.98e-06\n",
      "Epoch  24 [5000/10697 ( 46.7%)] Loss: 0.026822 L1: 0.015520 Grad: 0.112786 Thermal: 0.000470 LR: 3.98e-06\n",
      "Epoch  24 [5000/10697 ( 46.7%)] Loss: 0.026822 L1: 0.015520 Grad: 0.112786 Thermal: 0.000470 LR: 3.98e-06\n",
      "Epoch  24 [5050/10697 ( 47.2%)] Loss: 0.024967 L1: 0.014567 Grad: 0.103801 Thermal: 0.000382 LR: 3.98e-06\n",
      "Epoch  24 [5050/10697 ( 47.2%)] Loss: 0.024967 L1: 0.014567 Grad: 0.103801 Thermal: 0.000382 LR: 3.98e-06\n",
      "Epoch  24 [5100/10697 ( 47.7%)] Loss: 0.024748 L1: 0.013950 Grad: 0.107769 Thermal: 0.000408 LR: 3.98e-06\n",
      "Epoch  24 [5100/10697 ( 47.7%)] Loss: 0.024748 L1: 0.013950 Grad: 0.107769 Thermal: 0.000408 LR: 3.98e-06\n",
      "Epoch  24 [5150/10697 ( 48.1%)] Loss: 0.031208 L1: 0.017574 Grad: 0.136022 Thermal: 0.000632 LR: 3.98e-06\n",
      "Epoch  24 [5150/10697 ( 48.1%)] Loss: 0.031208 L1: 0.017574 Grad: 0.136022 Thermal: 0.000632 LR: 3.98e-06\n",
      "Epoch  24 [5200/10697 ( 48.6%)] Loss: 0.020583 L1: 0.012021 Grad: 0.085468 Thermal: 0.000299 LR: 3.98e-06\n",
      "Epoch  24 [5200/10697 ( 48.6%)] Loss: 0.020583 L1: 0.012021 Grad: 0.085468 Thermal: 0.000299 LR: 3.98e-06\n",
      "Epoch  24 [5250/10697 ( 49.1%)] Loss: 0.023069 L1: 0.013095 Grad: 0.099559 Thermal: 0.000375 LR: 3.98e-06\n",
      "Epoch  24 [5250/10697 ( 49.1%)] Loss: 0.023069 L1: 0.013095 Grad: 0.099559 Thermal: 0.000375 LR: 3.98e-06\n",
      "Epoch  24 [5300/10697 ( 49.5%)] Loss: 0.021577 L1: 0.012197 Grad: 0.093641 Thermal: 0.000306 LR: 3.98e-06\n",
      "Epoch  24 [5300/10697 ( 49.5%)] Loss: 0.021577 L1: 0.012197 Grad: 0.093641 Thermal: 0.000306 LR: 3.98e-06\n",
      "Epoch  24 [5350/10697 ( 50.0%)] Loss: 0.026381 L1: 0.015060 Grad: 0.112985 Thermal: 0.000455 LR: 3.98e-06\n",
      "Epoch  24 [5350/10697 ( 50.0%)] Loss: 0.026381 L1: 0.015060 Grad: 0.112985 Thermal: 0.000455 LR: 3.98e-06\n",
      "Epoch  24 [5400/10697 ( 50.5%)] Loss: 0.025533 L1: 0.014720 Grad: 0.107925 Thermal: 0.000416 LR: 3.98e-06\n",
      "Epoch  24 [5400/10697 ( 50.5%)] Loss: 0.025533 L1: 0.014720 Grad: 0.107925 Thermal: 0.000416 LR: 3.98e-06\n",
      "Epoch  24 [5450/10697 ( 50.9%)] Loss: 0.022090 L1: 0.012728 Grad: 0.093467 Thermal: 0.000295 LR: 3.98e-06\n",
      "Epoch  24 [5450/10697 ( 50.9%)] Loss: 0.022090 L1: 0.012728 Grad: 0.093467 Thermal: 0.000295 LR: 3.98e-06\n",
      "Epoch  24 [5500/10697 ( 51.4%)] Loss: 0.027335 L1: 0.015931 Grad: 0.113786 Thermal: 0.000507 LR: 3.98e-06\n",
      "Epoch  24 [5500/10697 ( 51.4%)] Loss: 0.027335 L1: 0.015931 Grad: 0.113786 Thermal: 0.000507 LR: 3.98e-06\n",
      "Epoch  24 [5550/10697 ( 51.9%)] Loss: 0.020115 L1: 0.011641 Grad: 0.084585 Thermal: 0.000305 LR: 3.98e-06\n",
      "Epoch  24 [5550/10697 ( 51.9%)] Loss: 0.020115 L1: 0.011641 Grad: 0.084585 Thermal: 0.000305 LR: 3.98e-06\n",
      "Epoch  24 [5600/10697 ( 52.4%)] Loss: 0.025245 L1: 0.014771 Grad: 0.104523 Thermal: 0.000431 LR: 3.98e-06\n",
      "Epoch  24 [5600/10697 ( 52.4%)] Loss: 0.025245 L1: 0.014771 Grad: 0.104523 Thermal: 0.000431 LR: 3.98e-06\n",
      "Epoch  24 [5650/10697 ( 52.8%)] Loss: 0.030017 L1: 0.017837 Grad: 0.121530 Thermal: 0.000551 LR: 3.98e-06\n",
      "Epoch  24 [5650/10697 ( 52.8%)] Loss: 0.030017 L1: 0.017837 Grad: 0.121530 Thermal: 0.000551 LR: 3.98e-06\n",
      "Epoch  24 [5700/10697 ( 53.3%)] Loss: 0.035764 L1: 0.020828 Grad: 0.148928 Thermal: 0.000861 LR: 3.98e-06\n",
      "Epoch  24 [5700/10697 ( 53.3%)] Loss: 0.035764 L1: 0.020828 Grad: 0.148928 Thermal: 0.000861 LR: 3.98e-06\n",
      "Epoch  24 [5750/10697 ( 53.8%)] Loss: 0.030292 L1: 0.017917 Grad: 0.123472 Thermal: 0.000548 LR: 3.98e-06\n",
      "Epoch  24 [5750/10697 ( 53.8%)] Loss: 0.030292 L1: 0.017917 Grad: 0.123472 Thermal: 0.000548 LR: 3.98e-06\n",
      "Epoch  24 [5800/10697 ( 54.2%)] Loss: 0.020538 L1: 0.011780 Grad: 0.087427 Thermal: 0.000298 LR: 3.98e-06\n",
      "Epoch  24 [5800/10697 ( 54.2%)] Loss: 0.020538 L1: 0.011780 Grad: 0.087427 Thermal: 0.000298 LR: 3.98e-06\n",
      "Epoch  24 [5850/10697 ( 54.7%)] Loss: 0.027955 L1: 0.016578 Grad: 0.113532 Thermal: 0.000480 LR: 3.98e-06\n",
      "Epoch  24 [5850/10697 ( 54.7%)] Loss: 0.027955 L1: 0.016578 Grad: 0.113532 Thermal: 0.000480 LR: 3.98e-06\n",
      "Epoch  24 [5900/10697 ( 55.2%)] Loss: 0.024503 L1: 0.013925 Grad: 0.105597 Thermal: 0.000365 LR: 3.98e-06\n",
      "Epoch  24 [5900/10697 ( 55.2%)] Loss: 0.024503 L1: 0.013925 Grad: 0.105597 Thermal: 0.000365 LR: 3.98e-06\n",
      "Epoch  24 [5950/10697 ( 55.6%)] Loss: 0.026525 L1: 0.015554 Grad: 0.109499 Thermal: 0.000430 LR: 3.98e-06\n",
      "Epoch  24 [5950/10697 ( 55.6%)] Loss: 0.026525 L1: 0.015554 Grad: 0.109499 Thermal: 0.000430 LR: 3.98e-06\n",
      "Epoch  24 [6000/10697 ( 56.1%)] Loss: 0.021866 L1: 0.012817 Grad: 0.090334 Thermal: 0.000307 LR: 3.98e-06\n",
      "Epoch  24 [6000/10697 ( 56.1%)] Loss: 0.021866 L1: 0.012817 Grad: 0.090334 Thermal: 0.000307 LR: 3.98e-06\n",
      "Epoch  24 [6050/10697 ( 56.6%)] Loss: 0.029225 L1: 0.017135 Grad: 0.120596 Thermal: 0.000613 LR: 3.98e-06\n",
      "Epoch  24 [6050/10697 ( 56.6%)] Loss: 0.029225 L1: 0.017135 Grad: 0.120596 Thermal: 0.000613 LR: 3.98e-06\n",
      "Epoch  24 [6100/10697 ( 57.0%)] Loss: 0.027346 L1: 0.015773 Grad: 0.115487 Thermal: 0.000485 LR: 3.98e-06\n",
      "Epoch  24 [6100/10697 ( 57.0%)] Loss: 0.027346 L1: 0.015773 Grad: 0.115487 Thermal: 0.000485 LR: 3.98e-06\n",
      "Epoch  24 [6150/10697 ( 57.5%)] Loss: 0.025678 L1: 0.014998 Grad: 0.106560 Thermal: 0.000486 LR: 3.98e-06\n",
      "Epoch  24 [6150/10697 ( 57.5%)] Loss: 0.025678 L1: 0.014998 Grad: 0.106560 Thermal: 0.000486 LR: 3.98e-06\n",
      "Epoch  24 [6200/10697 ( 58.0%)] Loss: 0.022727 L1: 0.013094 Grad: 0.096175 Thermal: 0.000308 LR: 3.98e-06\n",
      "Epoch  24 [6200/10697 ( 58.0%)] Loss: 0.022727 L1: 0.013094 Grad: 0.096175 Thermal: 0.000308 LR: 3.98e-06\n",
      "Epoch  24 [6250/10697 ( 58.4%)] Loss: 0.026995 L1: 0.015564 Grad: 0.114082 Thermal: 0.000450 LR: 3.98e-06\n",
      "Epoch  24 [6250/10697 ( 58.4%)] Loss: 0.026995 L1: 0.015564 Grad: 0.114082 Thermal: 0.000450 LR: 3.98e-06\n",
      "Epoch  24 [6300/10697 ( 58.9%)] Loss: 0.028100 L1: 0.016267 Grad: 0.118077 Thermal: 0.000500 LR: 3.98e-06\n",
      "Epoch  24 [6300/10697 ( 58.9%)] Loss: 0.028100 L1: 0.016267 Grad: 0.118077 Thermal: 0.000500 LR: 3.98e-06\n",
      "Epoch  24 [6350/10697 ( 59.4%)] Loss: 0.025908 L1: 0.015165 Grad: 0.107215 Thermal: 0.000432 LR: 3.98e-06\n",
      "Epoch  24 [6350/10697 ( 59.4%)] Loss: 0.025908 L1: 0.015165 Grad: 0.107215 Thermal: 0.000432 LR: 3.98e-06\n",
      "Epoch  24 [6400/10697 ( 59.8%)] Loss: 0.026713 L1: 0.015646 Grad: 0.110440 Thermal: 0.000470 LR: 3.98e-06\n",
      "Epoch  24 [6400/10697 ( 59.8%)] Loss: 0.026713 L1: 0.015646 Grad: 0.110440 Thermal: 0.000470 LR: 3.98e-06\n",
      "Epoch  24 [6450/10697 ( 60.3%)] Loss: 0.021482 L1: 0.012900 Grad: 0.085645 Thermal: 0.000337 LR: 3.98e-06\n",
      "Epoch  24 [6450/10697 ( 60.3%)] Loss: 0.021482 L1: 0.012900 Grad: 0.085645 Thermal: 0.000337 LR: 3.98e-06\n",
      "Epoch  24 [6500/10697 ( 60.8%)] Loss: 0.028461 L1: 0.016702 Grad: 0.117337 Thermal: 0.000512 LR: 3.98e-06\n",
      "Epoch  24 [6500/10697 ( 60.8%)] Loss: 0.028461 L1: 0.016702 Grad: 0.117337 Thermal: 0.000512 LR: 3.98e-06\n",
      "Epoch  24 [6550/10697 ( 61.2%)] Loss: 0.025800 L1: 0.015185 Grad: 0.105920 Thermal: 0.000463 LR: 3.98e-06\n",
      "Epoch  24 [6550/10697 ( 61.2%)] Loss: 0.025800 L1: 0.015185 Grad: 0.105920 Thermal: 0.000463 LR: 3.98e-06\n",
      "Epoch  24 [6600/10697 ( 61.7%)] Loss: 0.030348 L1: 0.017611 Grad: 0.127052 Thermal: 0.000623 LR: 3.98e-06\n",
      "Epoch  24 [6600/10697 ( 61.7%)] Loss: 0.030348 L1: 0.017611 Grad: 0.127052 Thermal: 0.000623 LR: 3.98e-06\n",
      "Epoch  24 [6650/10697 ( 62.2%)] Loss: 0.024051 L1: 0.014188 Grad: 0.098393 Thermal: 0.000459 LR: 3.98e-06\n",
      "Epoch  24 [6650/10697 ( 62.2%)] Loss: 0.024051 L1: 0.014188 Grad: 0.098393 Thermal: 0.000459 LR: 3.98e-06\n",
      "Epoch  24 [6700/10697 ( 62.6%)] Loss: 0.024860 L1: 0.014633 Grad: 0.102066 Thermal: 0.000409 LR: 3.98e-06\n",
      "Epoch  24 [6700/10697 ( 62.6%)] Loss: 0.024860 L1: 0.014633 Grad: 0.102066 Thermal: 0.000409 LR: 3.98e-06\n",
      "Epoch  24 [6750/10697 ( 63.1%)] Loss: 0.025796 L1: 0.015045 Grad: 0.107293 Thermal: 0.000433 LR: 3.98e-06\n",
      "Epoch  24 [6750/10697 ( 63.1%)] Loss: 0.025796 L1: 0.015045 Grad: 0.107293 Thermal: 0.000433 LR: 3.98e-06\n",
      "Epoch  24 [6800/10697 ( 63.6%)] Loss: 0.026841 L1: 0.016215 Grad: 0.106020 Thermal: 0.000470 LR: 3.98e-06\n",
      "Epoch  24 [6800/10697 ( 63.6%)] Loss: 0.026841 L1: 0.016215 Grad: 0.106020 Thermal: 0.000470 LR: 3.98e-06\n",
      "Epoch  24 [6850/10697 ( 64.0%)] Loss: 0.020793 L1: 0.012160 Grad: 0.086168 Thermal: 0.000314 LR: 3.98e-06\n",
      "Epoch  24 [6850/10697 ( 64.0%)] Loss: 0.020793 L1: 0.012160 Grad: 0.086168 Thermal: 0.000314 LR: 3.98e-06\n",
      "Epoch  24 [6900/10697 ( 64.5%)] Loss: 0.021176 L1: 0.012256 Grad: 0.089033 Thermal: 0.000329 LR: 3.98e-06\n",
      "Epoch  24 [6900/10697 ( 64.5%)] Loss: 0.021176 L1: 0.012256 Grad: 0.089033 Thermal: 0.000329 LR: 3.98e-06\n",
      "Epoch  24 [6950/10697 ( 65.0%)] Loss: 0.024423 L1: 0.014332 Grad: 0.100704 Thermal: 0.000395 LR: 3.98e-06\n",
      "Epoch  24 [6950/10697 ( 65.0%)] Loss: 0.024423 L1: 0.014332 Grad: 0.100704 Thermal: 0.000395 LR: 3.98e-06\n",
      "Epoch  24 [7000/10697 ( 65.4%)] Loss: 0.029025 L1: 0.016970 Grad: 0.120273 Thermal: 0.000546 LR: 3.98e-06\n",
      "Epoch  24 [7000/10697 ( 65.4%)] Loss: 0.029025 L1: 0.016970 Grad: 0.120273 Thermal: 0.000546 LR: 3.98e-06\n",
      "Epoch  24 [7050/10697 ( 65.9%)] Loss: 0.026775 L1: 0.015642 Grad: 0.111107 Thermal: 0.000441 LR: 3.98e-06\n",
      "Epoch  24 [7050/10697 ( 65.9%)] Loss: 0.026775 L1: 0.015642 Grad: 0.111107 Thermal: 0.000441 LR: 3.98e-06\n",
      "Epoch  24 [7100/10697 ( 66.4%)] Loss: 0.025418 L1: 0.015035 Grad: 0.103628 Thermal: 0.000404 LR: 3.98e-06\n",
      "Epoch  24 [7100/10697 ( 66.4%)] Loss: 0.025418 L1: 0.015035 Grad: 0.103628 Thermal: 0.000404 LR: 3.98e-06\n",
      "Epoch  24 [7150/10697 ( 66.8%)] Loss: 0.028435 L1: 0.015846 Grad: 0.125633 Thermal: 0.000509 LR: 3.98e-06\n",
      "Epoch  24 [7150/10697 ( 66.8%)] Loss: 0.028435 L1: 0.015846 Grad: 0.125633 Thermal: 0.000509 LR: 3.98e-06\n",
      "Epoch  24 [7200/10697 ( 67.3%)] Loss: 0.026853 L1: 0.015252 Grad: 0.115751 Thermal: 0.000521 LR: 3.98e-06\n",
      "Epoch  24 [7200/10697 ( 67.3%)] Loss: 0.026853 L1: 0.015252 Grad: 0.115751 Thermal: 0.000521 LR: 3.98e-06\n",
      "Epoch  24 [7250/10697 ( 67.8%)] Loss: 0.023762 L1: 0.013787 Grad: 0.099569 Thermal: 0.000360 LR: 3.98e-06\n",
      "Epoch  24 [7250/10697 ( 67.8%)] Loss: 0.023762 L1: 0.013787 Grad: 0.099569 Thermal: 0.000360 LR: 3.98e-06\n",
      "Epoch  24 [7300/10697 ( 68.2%)] Loss: 0.030514 L1: 0.017851 Grad: 0.126329 Thermal: 0.000609 LR: 3.98e-06\n",
      "Epoch  24 [7300/10697 ( 68.2%)] Loss: 0.030514 L1: 0.017851 Grad: 0.126329 Thermal: 0.000609 LR: 3.98e-06\n",
      "Epoch  24 [7350/10697 ( 68.7%)] Loss: 0.025609 L1: 0.014881 Grad: 0.107076 Thermal: 0.000408 LR: 3.98e-06\n",
      "Epoch  24 [7350/10697 ( 68.7%)] Loss: 0.025609 L1: 0.014881 Grad: 0.107076 Thermal: 0.000408 LR: 3.98e-06\n",
      "Epoch  24 [7400/10697 ( 69.2%)] Loss: 0.025754 L1: 0.015442 Grad: 0.102904 Thermal: 0.000435 LR: 3.98e-06\n",
      "Epoch  24 [7400/10697 ( 69.2%)] Loss: 0.025754 L1: 0.015442 Grad: 0.102904 Thermal: 0.000435 LR: 3.98e-06\n",
      "Epoch  24 [7450/10697 ( 69.6%)] Loss: 0.026506 L1: 0.015391 Grad: 0.110943 Thermal: 0.000429 LR: 3.98e-06\n",
      "Epoch  24 [7450/10697 ( 69.6%)] Loss: 0.026506 L1: 0.015391 Grad: 0.110943 Thermal: 0.000429 LR: 3.98e-06\n",
      "Epoch  24 [7500/10697 ( 70.1%)] Loss: 0.024385 L1: 0.014305 Grad: 0.100603 Thermal: 0.000396 LR: 3.98e-06\n",
      "Epoch  24 [7500/10697 ( 70.1%)] Loss: 0.024385 L1: 0.014305 Grad: 0.100603 Thermal: 0.000396 LR: 3.98e-06\n",
      "Epoch  24 [7550/10697 ( 70.6%)] Loss: 0.027213 L1: 0.015941 Grad: 0.112480 Thermal: 0.000477 LR: 3.98e-06\n",
      "Epoch  24 [7550/10697 ( 70.6%)] Loss: 0.027213 L1: 0.015941 Grad: 0.112480 Thermal: 0.000477 LR: 3.98e-06\n",
      "Epoch  24 [7600/10697 ( 71.0%)] Loss: 0.030668 L1: 0.017899 Grad: 0.127395 Thermal: 0.000602 LR: 3.98e-06\n",
      "Epoch  24 [7600/10697 ( 71.0%)] Loss: 0.030668 L1: 0.017899 Grad: 0.127395 Thermal: 0.000602 LR: 3.98e-06\n",
      "Epoch  24 [7650/10697 ( 71.5%)] Loss: 0.026598 L1: 0.015816 Grad: 0.107598 Thermal: 0.000440 LR: 3.98e-06\n",
      "Epoch  24 [7650/10697 ( 71.5%)] Loss: 0.026598 L1: 0.015816 Grad: 0.107598 Thermal: 0.000440 LR: 3.98e-06\n",
      "Epoch  24 [7700/10697 ( 72.0%)] Loss: 0.025156 L1: 0.014527 Grad: 0.106100 Thermal: 0.000392 LR: 3.98e-06\n",
      "Epoch  24 [7700/10697 ( 72.0%)] Loss: 0.025156 L1: 0.014527 Grad: 0.106100 Thermal: 0.000392 LR: 3.98e-06\n",
      "Epoch  24 [7750/10697 ( 72.5%)] Loss: 0.029684 L1: 0.017442 Grad: 0.122153 Thermal: 0.000530 LR: 3.98e-06\n",
      "Epoch  24 [7750/10697 ( 72.5%)] Loss: 0.029684 L1: 0.017442 Grad: 0.122153 Thermal: 0.000530 LR: 3.98e-06\n",
      "Epoch  24 [7800/10697 ( 72.9%)] Loss: 0.024569 L1: 0.014154 Grad: 0.103953 Thermal: 0.000401 LR: 3.98e-06\n",
      "Epoch  24 [7800/10697 ( 72.9%)] Loss: 0.024569 L1: 0.014154 Grad: 0.103953 Thermal: 0.000401 LR: 3.98e-06\n",
      "Epoch  24 [7850/10697 ( 73.4%)] Loss: 0.021383 L1: 0.012398 Grad: 0.089680 Thermal: 0.000323 LR: 3.98e-06\n",
      "Epoch  24 [7850/10697 ( 73.4%)] Loss: 0.021383 L1: 0.012398 Grad: 0.089680 Thermal: 0.000323 LR: 3.98e-06\n",
      "Epoch  24 [7900/10697 ( 73.9%)] Loss: 0.030326 L1: 0.017698 Grad: 0.126008 Thermal: 0.000546 LR: 3.98e-06\n",
      "Epoch  24 [7900/10697 ( 73.9%)] Loss: 0.030326 L1: 0.017698 Grad: 0.126008 Thermal: 0.000546 LR: 3.98e-06\n",
      "Epoch  24 [7950/10697 ( 74.3%)] Loss: 0.024506 L1: 0.014557 Grad: 0.099291 Thermal: 0.000398 LR: 3.98e-06\n",
      "Epoch  24 [7950/10697 ( 74.3%)] Loss: 0.024506 L1: 0.014557 Grad: 0.099291 Thermal: 0.000398 LR: 3.98e-06\n",
      "Epoch  24 [8000/10697 ( 74.8%)] Loss: 0.025642 L1: 0.014838 Grad: 0.107812 Thermal: 0.000442 LR: 3.98e-06\n",
      "Epoch  24 [8000/10697 ( 74.8%)] Loss: 0.025642 L1: 0.014838 Grad: 0.107812 Thermal: 0.000442 LR: 3.98e-06\n",
      "Epoch  24 [8050/10697 ( 75.3%)] Loss: 0.020475 L1: 0.011606 Grad: 0.088549 Thermal: 0.000275 LR: 3.98e-06\n",
      "Epoch  24 [8050/10697 ( 75.3%)] Loss: 0.020475 L1: 0.011606 Grad: 0.088549 Thermal: 0.000275 LR: 3.98e-06\n",
      "Epoch  24 [8100/10697 ( 75.7%)] Loss: 0.032050 L1: 0.018773 Grad: 0.132449 Thermal: 0.000629 LR: 3.98e-06\n",
      "Epoch  24 [8100/10697 ( 75.7%)] Loss: 0.032050 L1: 0.018773 Grad: 0.132449 Thermal: 0.000629 LR: 3.98e-06\n",
      "Epoch  24 [8150/10697 ( 76.2%)] Loss: 0.026590 L1: 0.015429 Grad: 0.111348 Thermal: 0.000514 LR: 3.98e-06\n",
      "Epoch  24 [8150/10697 ( 76.2%)] Loss: 0.026590 L1: 0.015429 Grad: 0.111348 Thermal: 0.000514 LR: 3.98e-06\n",
      "Epoch  24 [8200/10697 ( 76.7%)] Loss: 0.026856 L1: 0.015847 Grad: 0.109840 Thermal: 0.000489 LR: 3.98e-06\n",
      "Epoch  24 [8200/10697 ( 76.7%)] Loss: 0.026856 L1: 0.015847 Grad: 0.109840 Thermal: 0.000489 LR: 3.98e-06\n",
      "Epoch  24 [8250/10697 ( 77.1%)] Loss: 0.030481 L1: 0.017697 Grad: 0.127542 Thermal: 0.000599 LR: 3.98e-06\n",
      "Epoch  24 [8250/10697 ( 77.1%)] Loss: 0.030481 L1: 0.017697 Grad: 0.127542 Thermal: 0.000599 LR: 3.98e-06\n",
      "Epoch  24 [8300/10697 ( 77.6%)] Loss: 0.032080 L1: 0.018861 Grad: 0.131844 Thermal: 0.000684 LR: 3.98e-06\n",
      "Epoch  24 [8300/10697 ( 77.6%)] Loss: 0.032080 L1: 0.018861 Grad: 0.131844 Thermal: 0.000684 LR: 3.98e-06\n",
      "Epoch  24 [8350/10697 ( 78.1%)] Loss: 0.026964 L1: 0.015975 Grad: 0.109670 Thermal: 0.000453 LR: 3.98e-06\n",
      "Epoch  24 [8350/10697 ( 78.1%)] Loss: 0.026964 L1: 0.015975 Grad: 0.109670 Thermal: 0.000453 LR: 3.98e-06\n",
      "Epoch  24 [8400/10697 ( 78.5%)] Loss: 0.025576 L1: 0.014441 Grad: 0.111144 Thermal: 0.000422 LR: 3.98e-06\n",
      "Epoch  24 [8400/10697 ( 78.5%)] Loss: 0.025576 L1: 0.014441 Grad: 0.111144 Thermal: 0.000422 LR: 3.98e-06\n",
      "Epoch  24 [8450/10697 ( 79.0%)] Loss: 0.027015 L1: 0.015865 Grad: 0.111272 Thermal: 0.000461 LR: 3.98e-06\n",
      "Epoch  24 [8450/10697 ( 79.0%)] Loss: 0.027015 L1: 0.015865 Grad: 0.111272 Thermal: 0.000461 LR: 3.98e-06\n",
      "Epoch  24 [8500/10697 ( 79.5%)] Loss: 0.026570 L1: 0.015564 Grad: 0.109831 Thermal: 0.000463 LR: 3.98e-06\n",
      "Epoch  24 [8500/10697 ( 79.5%)] Loss: 0.026570 L1: 0.015564 Grad: 0.109831 Thermal: 0.000463 LR: 3.98e-06\n",
      "Epoch  24 [8550/10697 ( 79.9%)] Loss: 0.025793 L1: 0.015124 Grad: 0.106477 Thermal: 0.000417 LR: 3.98e-06\n",
      "Epoch  24 [8550/10697 ( 79.9%)] Loss: 0.025793 L1: 0.015124 Grad: 0.106477 Thermal: 0.000417 LR: 3.98e-06\n",
      "Epoch  24 [8600/10697 ( 80.4%)] Loss: 0.027894 L1: 0.016209 Grad: 0.116613 Thermal: 0.000472 LR: 3.98e-06\n",
      "Epoch  24 [8600/10697 ( 80.4%)] Loss: 0.027894 L1: 0.016209 Grad: 0.116613 Thermal: 0.000472 LR: 3.98e-06\n",
      "Epoch  24 [8650/10697 ( 80.9%)] Loss: 0.033087 L1: 0.018771 Grad: 0.142788 Thermal: 0.000750 LR: 3.98e-06\n",
      "Epoch  24 [8650/10697 ( 80.9%)] Loss: 0.033087 L1: 0.018771 Grad: 0.142788 Thermal: 0.000750 LR: 3.98e-06\n",
      "Epoch  24 [8700/10697 ( 81.3%)] Loss: 0.024008 L1: 0.013871 Grad: 0.101186 Thermal: 0.000350 LR: 3.98e-06\n",
      "Epoch  24 [8700/10697 ( 81.3%)] Loss: 0.024008 L1: 0.013871 Grad: 0.101186 Thermal: 0.000350 LR: 3.98e-06\n",
      "Epoch  24 [8750/10697 ( 81.8%)] Loss: 0.027049 L1: 0.016188 Grad: 0.108374 Thermal: 0.000474 LR: 3.98e-06\n",
      "Epoch  24 [8750/10697 ( 81.8%)] Loss: 0.027049 L1: 0.016188 Grad: 0.108374 Thermal: 0.000474 LR: 3.98e-06\n",
      "Epoch  24 [8800/10697 ( 82.3%)] Loss: 0.031289 L1: 0.018104 Grad: 0.131513 Thermal: 0.000685 LR: 3.98e-06\n",
      "Epoch  24 [8800/10697 ( 82.3%)] Loss: 0.031289 L1: 0.018104 Grad: 0.131513 Thermal: 0.000685 LR: 3.98e-06\n",
      "Epoch  24 [8850/10697 ( 82.7%)] Loss: 0.026978 L1: 0.015755 Grad: 0.112014 Thermal: 0.000435 LR: 3.98e-06\n",
      "Epoch  24 [8850/10697 ( 82.7%)] Loss: 0.026978 L1: 0.015755 Grad: 0.112014 Thermal: 0.000435 LR: 3.98e-06\n",
      "Epoch  24 [8900/10697 ( 83.2%)] Loss: 0.024993 L1: 0.014644 Grad: 0.103294 Thermal: 0.000399 LR: 3.98e-06\n",
      "Epoch  24 [8900/10697 ( 83.2%)] Loss: 0.024993 L1: 0.014644 Grad: 0.103294 Thermal: 0.000399 LR: 3.98e-06\n",
      "Epoch  24 [8950/10697 ( 83.7%)] Loss: 0.026771 L1: 0.015915 Grad: 0.108340 Thermal: 0.000448 LR: 3.98e-06\n",
      "Epoch  24 [8950/10697 ( 83.7%)] Loss: 0.026771 L1: 0.015915 Grad: 0.108340 Thermal: 0.000448 LR: 3.98e-06\n",
      "Epoch  24 [9000/10697 ( 84.1%)] Loss: 0.028948 L1: 0.017174 Grad: 0.117473 Thermal: 0.000537 LR: 3.98e-06\n",
      "Epoch  24 [9000/10697 ( 84.1%)] Loss: 0.028948 L1: 0.017174 Grad: 0.117473 Thermal: 0.000537 LR: 3.98e-06\n",
      "Epoch  24 [9050/10697 ( 84.6%)] Loss: 0.026858 L1: 0.015463 Grad: 0.113751 Thermal: 0.000410 LR: 3.98e-06\n",
      "Epoch  24 [9050/10697 ( 84.6%)] Loss: 0.026858 L1: 0.015463 Grad: 0.113751 Thermal: 0.000410 LR: 3.98e-06\n",
      "Epoch  24 [9100/10697 ( 85.1%)] Loss: 0.031077 L1: 0.018089 Grad: 0.129573 Thermal: 0.000606 LR: 3.98e-06\n",
      "Epoch  24 [9100/10697 ( 85.1%)] Loss: 0.031077 L1: 0.018089 Grad: 0.129573 Thermal: 0.000606 LR: 3.98e-06\n",
      "Epoch  24 [9150/10697 ( 85.5%)] Loss: 0.025781 L1: 0.014710 Grad: 0.110501 Thermal: 0.000436 LR: 3.98e-06\n",
      "Epoch  24 [9150/10697 ( 85.5%)] Loss: 0.025781 L1: 0.014710 Grad: 0.110501 Thermal: 0.000436 LR: 3.98e-06\n",
      "Epoch  24 [9200/10697 ( 86.0%)] Loss: 0.028615 L1: 0.016482 Grad: 0.121081 Thermal: 0.000505 LR: 3.98e-06\n",
      "Epoch  24 [9200/10697 ( 86.0%)] Loss: 0.028615 L1: 0.016482 Grad: 0.121081 Thermal: 0.000505 LR: 3.98e-06\n",
      "Epoch  24 [9250/10697 ( 86.5%)] Loss: 0.026942 L1: 0.016212 Grad: 0.107068 Thermal: 0.000468 LR: 3.98e-06\n",
      "Epoch  24 [9250/10697 ( 86.5%)] Loss: 0.026942 L1: 0.016212 Grad: 0.107068 Thermal: 0.000468 LR: 3.98e-06\n",
      "Epoch  24 [9300/10697 ( 86.9%)] Loss: 0.033655 L1: 0.019376 Grad: 0.142453 Thermal: 0.000673 LR: 3.98e-06\n",
      "Epoch  24 [9300/10697 ( 86.9%)] Loss: 0.033655 L1: 0.019376 Grad: 0.142453 Thermal: 0.000673 LR: 3.98e-06\n",
      "Epoch  24 [9350/10697 ( 87.4%)] Loss: 0.027841 L1: 0.016265 Grad: 0.115522 Thermal: 0.000477 LR: 3.98e-06\n",
      "Epoch  24 [9350/10697 ( 87.4%)] Loss: 0.027841 L1: 0.016265 Grad: 0.115522 Thermal: 0.000477 LR: 3.98e-06\n",
      "Epoch  24 [9400/10697 ( 87.9%)] Loss: 0.024069 L1: 0.013854 Grad: 0.101962 Thermal: 0.000385 LR: 3.98e-06\n",
      "Epoch  24 [9400/10697 ( 87.9%)] Loss: 0.024069 L1: 0.013854 Grad: 0.101962 Thermal: 0.000385 LR: 3.98e-06\n",
      "Epoch  24 [9450/10697 ( 88.3%)] Loss: 0.028568 L1: 0.015960 Grad: 0.125831 Thermal: 0.000491 LR: 3.98e-06\n",
      "Epoch  24 [9450/10697 ( 88.3%)] Loss: 0.028568 L1: 0.015960 Grad: 0.125831 Thermal: 0.000491 LR: 3.98e-06\n",
      "Epoch  24 [9500/10697 ( 88.8%)] Loss: 0.023200 L1: 0.013610 Grad: 0.095732 Thermal: 0.000350 LR: 3.98e-06\n",
      "Epoch  24 [9500/10697 ( 88.8%)] Loss: 0.023200 L1: 0.013610 Grad: 0.095732 Thermal: 0.000350 LR: 3.98e-06\n",
      "Epoch  24 [9550/10697 ( 89.3%)] Loss: 0.021211 L1: 0.012455 Grad: 0.087386 Thermal: 0.000349 LR: 3.98e-06\n",
      "Epoch  24 [9550/10697 ( 89.3%)] Loss: 0.021211 L1: 0.012455 Grad: 0.087386 Thermal: 0.000349 LR: 3.98e-06\n",
      "Epoch  24 [9600/10697 ( 89.7%)] Loss: 0.024301 L1: 0.014578 Grad: 0.097027 Thermal: 0.000408 LR: 3.98e-06\n",
      "Epoch  24 [9600/10697 ( 89.7%)] Loss: 0.024301 L1: 0.014578 Grad: 0.097027 Thermal: 0.000408 LR: 3.98e-06\n",
      "Epoch  24 [9650/10697 ( 90.2%)] Loss: 0.028201 L1: 0.016657 Grad: 0.115191 Thermal: 0.000496 LR: 3.98e-06\n",
      "Epoch  24 [9650/10697 ( 90.2%)] Loss: 0.028201 L1: 0.016657 Grad: 0.115191 Thermal: 0.000496 LR: 3.98e-06\n",
      "Epoch  24 [9700/10697 ( 90.7%)] Loss: 0.027482 L1: 0.015949 Grad: 0.115097 Thermal: 0.000461 LR: 3.98e-06\n",
      "Epoch  24 [9700/10697 ( 90.7%)] Loss: 0.027482 L1: 0.015949 Grad: 0.115097 Thermal: 0.000461 LR: 3.98e-06\n",
      "Epoch  24 [9750/10697 ( 91.1%)] Loss: 0.028517 L1: 0.016286 Grad: 0.122039 Thermal: 0.000545 LR: 3.98e-06\n",
      "Epoch  24 [9750/10697 ( 91.1%)] Loss: 0.028517 L1: 0.016286 Grad: 0.122039 Thermal: 0.000545 LR: 3.98e-06\n",
      "Epoch  24 [9800/10697 ( 91.6%)] Loss: 0.030795 L1: 0.018070 Grad: 0.126969 Thermal: 0.000576 LR: 3.98e-06\n",
      "Epoch  24 [9800/10697 ( 91.6%)] Loss: 0.030795 L1: 0.018070 Grad: 0.126969 Thermal: 0.000576 LR: 3.98e-06\n",
      "Epoch  24 [9850/10697 ( 92.1%)] Loss: 0.030000 L1: 0.016989 Grad: 0.129846 Thermal: 0.000521 LR: 3.98e-06\n",
      "Epoch  24 [9850/10697 ( 92.1%)] Loss: 0.030000 L1: 0.016989 Grad: 0.129846 Thermal: 0.000521 LR: 3.98e-06\n",
      "Epoch  24 [9900/10697 ( 92.5%)] Loss: 0.023773 L1: 0.014079 Grad: 0.096747 Thermal: 0.000385 LR: 3.98e-06\n",
      "Epoch  24 [9900/10697 ( 92.5%)] Loss: 0.023773 L1: 0.014079 Grad: 0.096747 Thermal: 0.000385 LR: 3.98e-06\n",
      "Epoch  24 [9950/10697 ( 93.0%)] Loss: 0.029896 L1: 0.017513 Grad: 0.123503 Thermal: 0.000638 LR: 3.98e-06\n",
      "Epoch  24 [9950/10697 ( 93.0%)] Loss: 0.029896 L1: 0.017513 Grad: 0.123503 Thermal: 0.000638 LR: 3.98e-06\n",
      "Epoch  24 [10000/10697 ( 93.5%)] Loss: 0.023907 L1: 0.013975 Grad: 0.099089 Thermal: 0.000467 LR: 3.98e-06\n",
      "Epoch  24 [10000/10697 ( 93.5%)] Loss: 0.023907 L1: 0.013975 Grad: 0.099089 Thermal: 0.000467 LR: 3.98e-06\n",
      "Epoch  24 [10050/10697 ( 94.0%)] Loss: 0.027857 L1: 0.016161 Grad: 0.116711 Thermal: 0.000498 LR: 3.98e-06\n",
      "Epoch  24 [10050/10697 ( 94.0%)] Loss: 0.027857 L1: 0.016161 Grad: 0.116711 Thermal: 0.000498 LR: 3.98e-06\n",
      "Epoch  24 [10100/10697 ( 94.4%)] Loss: 0.030543 L1: 0.017988 Grad: 0.125246 Thermal: 0.000616 LR: 3.98e-06\n",
      "Epoch  24 [10100/10697 ( 94.4%)] Loss: 0.030543 L1: 0.017988 Grad: 0.125246 Thermal: 0.000616 LR: 3.98e-06\n",
      "Epoch  24 [10150/10697 ( 94.9%)] Loss: 0.020748 L1: 0.011656 Grad: 0.090764 Thermal: 0.000314 LR: 3.98e-06\n",
      "Epoch  24 [10150/10697 ( 94.9%)] Loss: 0.020748 L1: 0.011656 Grad: 0.090764 Thermal: 0.000314 LR: 3.98e-06\n",
      "Epoch  24 [10200/10697 ( 95.4%)] Loss: 0.025931 L1: 0.015274 Grad: 0.106356 Thermal: 0.000436 LR: 3.98e-06\n",
      "Epoch  24 [10200/10697 ( 95.4%)] Loss: 0.025931 L1: 0.015274 Grad: 0.106356 Thermal: 0.000436 LR: 3.98e-06\n",
      "Epoch  24 [10250/10697 ( 95.8%)] Loss: 0.033588 L1: 0.019348 Grad: 0.142078 Thermal: 0.000657 LR: 3.98e-06\n",
      "Epoch  24 [10250/10697 ( 95.8%)] Loss: 0.033588 L1: 0.019348 Grad: 0.142078 Thermal: 0.000657 LR: 3.98e-06\n",
      "Epoch  24 [10300/10697 ( 96.3%)] Loss: 0.030968 L1: 0.018099 Grad: 0.128405 Thermal: 0.000579 LR: 3.98e-06\n",
      "Epoch  24 [10300/10697 ( 96.3%)] Loss: 0.030968 L1: 0.018099 Grad: 0.128405 Thermal: 0.000579 LR: 3.98e-06\n",
      "Epoch  24 [10350/10697 ( 96.8%)] Loss: 0.024760 L1: 0.014381 Grad: 0.103609 Thermal: 0.000378 LR: 3.98e-06\n",
      "Epoch  24 [10350/10697 ( 96.8%)] Loss: 0.024760 L1: 0.014381 Grad: 0.103609 Thermal: 0.000378 LR: 3.98e-06\n",
      "Epoch  24 [10400/10697 ( 97.2%)] Loss: 0.025053 L1: 0.014536 Grad: 0.104933 Thermal: 0.000469 LR: 3.98e-06\n",
      "Epoch  24 [10400/10697 ( 97.2%)] Loss: 0.025053 L1: 0.014536 Grad: 0.104933 Thermal: 0.000469 LR: 3.98e-06\n",
      "Epoch  24 [10450/10697 ( 97.7%)] Loss: 0.033176 L1: 0.019400 Grad: 0.137420 Thermal: 0.000672 LR: 3.98e-06\n",
      "Epoch  24 [10450/10697 ( 97.7%)] Loss: 0.033176 L1: 0.019400 Grad: 0.137420 Thermal: 0.000672 LR: 3.98e-06\n",
      "Epoch  24 [10500/10697 ( 98.2%)] Loss: 0.021807 L1: 0.012895 Grad: 0.088952 Thermal: 0.000331 LR: 3.98e-06\n",
      "Epoch  24 [10500/10697 ( 98.2%)] Loss: 0.021807 L1: 0.012895 Grad: 0.088952 Thermal: 0.000331 LR: 3.98e-06\n",
      "Epoch  24 [10550/10697 ( 98.6%)] Loss: 0.022383 L1: 0.012941 Grad: 0.094258 Thermal: 0.000333 LR: 3.98e-06\n",
      "Epoch  24 [10550/10697 ( 98.6%)] Loss: 0.022383 L1: 0.012941 Grad: 0.094258 Thermal: 0.000333 LR: 3.98e-06\n",
      "Epoch  24 [10600/10697 ( 99.1%)] Loss: 0.027313 L1: 0.016393 Grad: 0.108955 Thermal: 0.000473 LR: 3.98e-06\n",
      "Epoch  24 [10600/10697 ( 99.1%)] Loss: 0.027313 L1: 0.016393 Grad: 0.108955 Thermal: 0.000473 LR: 3.98e-06\n",
      "Epoch  24 [10650/10697 ( 99.6%)] Loss: 0.029093 L1: 0.017143 Grad: 0.119239 Thermal: 0.000524 LR: 3.98e-06\n",
      "Epoch  24 [10650/10697 ( 99.6%)] Loss: 0.029093 L1: 0.017143 Grad: 0.119239 Thermal: 0.000524 LR: 3.98e-06\n",
      "Epoch  24 Summary: Loss=0.026308 (L1:0.0153, Grad:0.1094, Thermal:0.0005) Val_PSNR=0.00dB Best=33.92dB Time=92.7min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  24 Summary: Loss=0.026308 (L1:0.0153, Grad:0.1094, Thermal:0.0005) Val_PSNR=0.00dB Best=33.92dB Time=92.7min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  25 [   0/10697 (  0.0%)] Loss: 0.022741 L1: 0.013511 Grad: 0.092123 Thermal: 0.000352 LR: 3.90e-06\n",
      "Epoch  25 [   0/10697 (  0.0%)] Loss: 0.022741 L1: 0.013511 Grad: 0.092123 Thermal: 0.000352 LR: 3.90e-06\n",
      "Epoch  25 [  50/10697 (  0.5%)] Loss: 0.025729 L1: 0.014847 Grad: 0.108518 Thermal: 0.000606 LR: 3.90e-06\n",
      "Epoch  25 [  50/10697 (  0.5%)] Loss: 0.025729 L1: 0.014847 Grad: 0.108518 Thermal: 0.000606 LR: 3.90e-06\n",
      "Epoch  25 [ 100/10697 (  0.9%)] Loss: 0.027152 L1: 0.015873 Grad: 0.112566 Thermal: 0.000446 LR: 3.90e-06\n",
      "Epoch  25 [ 100/10697 (  0.9%)] Loss: 0.027152 L1: 0.015873 Grad: 0.112566 Thermal: 0.000446 LR: 3.90e-06\n",
      "Epoch  25 [ 150/10697 (  1.4%)] Loss: 0.029933 L1: 0.016725 Grad: 0.131810 Thermal: 0.000540 LR: 3.90e-06\n",
      "Epoch  25 [ 150/10697 (  1.4%)] Loss: 0.029933 L1: 0.016725 Grad: 0.131810 Thermal: 0.000540 LR: 3.90e-06\n",
      "Epoch  25 [ 200/10697 (  1.9%)] Loss: 0.028670 L1: 0.017034 Grad: 0.116098 Thermal: 0.000515 LR: 3.90e-06\n",
      "Epoch  25 [ 200/10697 (  1.9%)] Loss: 0.028670 L1: 0.017034 Grad: 0.116098 Thermal: 0.000515 LR: 3.90e-06\n",
      "Epoch  25 [ 250/10697 (  2.3%)] Loss: 0.026961 L1: 0.016246 Grad: 0.106909 Thermal: 0.000476 LR: 3.90e-06\n",
      "Epoch  25 [ 250/10697 (  2.3%)] Loss: 0.026961 L1: 0.016246 Grad: 0.106909 Thermal: 0.000476 LR: 3.90e-06\n",
      "Epoch  25 [ 300/10697 (  2.8%)] Loss: 0.025055 L1: 0.014714 Grad: 0.103204 Thermal: 0.000397 LR: 3.90e-06\n",
      "Epoch  25 [ 300/10697 (  2.8%)] Loss: 0.025055 L1: 0.014714 Grad: 0.103204 Thermal: 0.000397 LR: 3.90e-06\n",
      "Epoch  25 [ 350/10697 (  3.3%)] Loss: 0.024906 L1: 0.014908 Grad: 0.099757 Thermal: 0.000444 LR: 3.90e-06\n",
      "Epoch  25 [ 350/10697 (  3.3%)] Loss: 0.024906 L1: 0.014908 Grad: 0.099757 Thermal: 0.000444 LR: 3.90e-06\n",
      "Epoch  25 [ 400/10697 (  3.7%)] Loss: 0.029054 L1: 0.016827 Grad: 0.122006 Thermal: 0.000531 LR: 3.90e-06\n",
      "Epoch  25 [ 400/10697 (  3.7%)] Loss: 0.029054 L1: 0.016827 Grad: 0.122006 Thermal: 0.000531 LR: 3.90e-06\n",
      "Epoch  25 [ 450/10697 (  4.2%)] Loss: 0.027837 L1: 0.016468 Grad: 0.113434 Thermal: 0.000517 LR: 3.90e-06\n",
      "Epoch  25 [ 450/10697 (  4.2%)] Loss: 0.027837 L1: 0.016468 Grad: 0.113434 Thermal: 0.000517 LR: 3.90e-06\n",
      "Epoch  25 [ 500/10697 (  4.7%)] Loss: 0.031988 L1: 0.018340 Grad: 0.136111 Thermal: 0.000736 LR: 3.90e-06\n",
      "Epoch  25 [ 500/10697 (  4.7%)] Loss: 0.031988 L1: 0.018340 Grad: 0.136111 Thermal: 0.000736 LR: 3.90e-06\n",
      "Epoch  25 [ 550/10697 (  5.1%)] Loss: 0.026816 L1: 0.015618 Grad: 0.111778 Thermal: 0.000402 LR: 3.90e-06\n",
      "Epoch  25 [ 550/10697 (  5.1%)] Loss: 0.026816 L1: 0.015618 Grad: 0.111778 Thermal: 0.000402 LR: 3.90e-06\n",
      "Epoch  25 [ 600/10697 (  5.6%)] Loss: 0.030591 L1: 0.017516 Grad: 0.130397 Thermal: 0.000695 LR: 3.90e-06\n",
      "Epoch  25 [ 600/10697 (  5.6%)] Loss: 0.030591 L1: 0.017516 Grad: 0.130397 Thermal: 0.000695 LR: 3.90e-06\n",
      "Epoch  25 [ 650/10697 (  6.1%)] Loss: 0.021239 L1: 0.012724 Grad: 0.084986 Thermal: 0.000332 LR: 3.90e-06\n",
      "Epoch  25 [ 650/10697 (  6.1%)] Loss: 0.021239 L1: 0.012724 Grad: 0.084986 Thermal: 0.000332 LR: 3.90e-06\n",
      "Epoch  25 [ 700/10697 (  6.5%)] Loss: 0.026487 L1: 0.014999 Grad: 0.114658 Thermal: 0.000438 LR: 3.90e-06\n",
      "Epoch  25 [ 700/10697 (  6.5%)] Loss: 0.026487 L1: 0.014999 Grad: 0.114658 Thermal: 0.000438 LR: 3.90e-06\n",
      "Epoch  25 [ 750/10697 (  7.0%)] Loss: 0.024892 L1: 0.014545 Grad: 0.103250 Thermal: 0.000432 LR: 3.90e-06\n",
      "Epoch  25 [ 750/10697 (  7.0%)] Loss: 0.024892 L1: 0.014545 Grad: 0.103250 Thermal: 0.000432 LR: 3.90e-06\n",
      "Epoch  25 [ 800/10697 (  7.5%)] Loss: 0.018626 L1: 0.010721 Grad: 0.078882 Thermal: 0.000328 LR: 3.90e-06\n",
      "Epoch  25 [ 800/10697 (  7.5%)] Loss: 0.018626 L1: 0.010721 Grad: 0.078882 Thermal: 0.000328 LR: 3.90e-06\n",
      "Epoch  25 [ 850/10697 (  7.9%)] Loss: 0.022001 L1: 0.012954 Grad: 0.090298 Thermal: 0.000332 LR: 3.90e-06\n",
      "Epoch  25 [ 850/10697 (  7.9%)] Loss: 0.022001 L1: 0.012954 Grad: 0.090298 Thermal: 0.000332 LR: 3.90e-06\n",
      "Epoch  25 [ 900/10697 (  8.4%)] Loss: 0.026847 L1: 0.015841 Grad: 0.109835 Thermal: 0.000458 LR: 3.90e-06\n",
      "Epoch  25 [ 900/10697 (  8.4%)] Loss: 0.026847 L1: 0.015841 Grad: 0.109835 Thermal: 0.000458 LR: 3.90e-06\n",
      "Epoch  25 [ 950/10697 (  8.9%)] Loss: 0.025912 L1: 0.015564 Grad: 0.103261 Thermal: 0.000431 LR: 3.90e-06\n",
      "Epoch  25 [ 950/10697 (  8.9%)] Loss: 0.025912 L1: 0.015564 Grad: 0.103261 Thermal: 0.000431 LR: 3.90e-06\n",
      "Epoch  25 [1000/10697 (  9.3%)] Loss: 0.029712 L1: 0.017677 Grad: 0.120081 Thermal: 0.000546 LR: 3.90e-06\n",
      "Epoch  25 [1000/10697 (  9.3%)] Loss: 0.029712 L1: 0.017677 Grad: 0.120081 Thermal: 0.000546 LR: 3.90e-06\n",
      "Epoch  25 [1050/10697 (  9.8%)] Loss: 0.030578 L1: 0.017835 Grad: 0.127160 Thermal: 0.000543 LR: 3.90e-06\n",
      "Epoch  25 [1050/10697 (  9.8%)] Loss: 0.030578 L1: 0.017835 Grad: 0.127160 Thermal: 0.000543 LR: 3.90e-06\n",
      "Epoch  25 [1100/10697 ( 10.3%)] Loss: 0.026965 L1: 0.016070 Grad: 0.108731 Thermal: 0.000455 LR: 3.90e-06\n",
      "Epoch  25 [1100/10697 ( 10.3%)] Loss: 0.026965 L1: 0.016070 Grad: 0.108731 Thermal: 0.000455 LR: 3.90e-06\n",
      "Epoch  25 [1150/10697 ( 10.8%)] Loss: 0.023046 L1: 0.013492 Grad: 0.095364 Thermal: 0.000350 LR: 3.90e-06\n",
      "Epoch  25 [1150/10697 ( 10.8%)] Loss: 0.023046 L1: 0.013492 Grad: 0.095364 Thermal: 0.000350 LR: 3.90e-06\n",
      "Epoch  25 [1200/10697 ( 11.2%)] Loss: 0.036639 L1: 0.020972 Grad: 0.156252 Thermal: 0.000850 LR: 3.90e-06\n",
      "Epoch  25 [1200/10697 ( 11.2%)] Loss: 0.036639 L1: 0.020972 Grad: 0.156252 Thermal: 0.000850 LR: 3.90e-06\n",
      "Epoch  25 [1250/10697 ( 11.7%)] Loss: 0.028950 L1: 0.017159 Grad: 0.117663 Thermal: 0.000499 LR: 3.90e-06\n",
      "Epoch  25 [1250/10697 ( 11.7%)] Loss: 0.028950 L1: 0.017159 Grad: 0.117663 Thermal: 0.000499 LR: 3.90e-06\n",
      "Epoch  25 [1300/10697 ( 12.2%)] Loss: 0.024540 L1: 0.014217 Grad: 0.103028 Thermal: 0.000405 LR: 3.90e-06\n",
      "Epoch  25 [1300/10697 ( 12.2%)] Loss: 0.024540 L1: 0.014217 Grad: 0.103028 Thermal: 0.000405 LR: 3.90e-06\n",
      "Epoch  25 [1350/10697 ( 12.6%)] Loss: 0.027243 L1: 0.015537 Grad: 0.116786 Thermal: 0.000544 LR: 3.90e-06\n",
      "Epoch  25 [1350/10697 ( 12.6%)] Loss: 0.027243 L1: 0.015537 Grad: 0.116786 Thermal: 0.000544 LR: 3.90e-06\n",
      "Epoch  25 [1400/10697 ( 13.1%)] Loss: 0.025138 L1: 0.014463 Grad: 0.106543 Thermal: 0.000415 LR: 3.90e-06\n",
      "Epoch  25 [1400/10697 ( 13.1%)] Loss: 0.025138 L1: 0.014463 Grad: 0.106543 Thermal: 0.000415 LR: 3.90e-06\n",
      "Epoch  25 [1450/10697 ( 13.6%)] Loss: 0.026917 L1: 0.015682 Grad: 0.112126 Thermal: 0.000447 LR: 3.90e-06\n",
      "Epoch  25 [1450/10697 ( 13.6%)] Loss: 0.026917 L1: 0.015682 Grad: 0.112126 Thermal: 0.000447 LR: 3.90e-06\n",
      "Epoch  25 [1500/10697 ( 14.0%)] Loss: 0.027568 L1: 0.016233 Grad: 0.113122 Thermal: 0.000461 LR: 3.90e-06\n",
      "Epoch  25 [1500/10697 ( 14.0%)] Loss: 0.027568 L1: 0.016233 Grad: 0.113122 Thermal: 0.000461 LR: 3.90e-06\n",
      "Epoch  25 [1550/10697 ( 14.5%)] Loss: 0.026446 L1: 0.015244 Grad: 0.111788 Thermal: 0.000451 LR: 3.90e-06\n",
      "Epoch  25 [1550/10697 ( 14.5%)] Loss: 0.026446 L1: 0.015244 Grad: 0.111788 Thermal: 0.000451 LR: 3.90e-06\n",
      "Epoch  25 [1600/10697 ( 15.0%)] Loss: 0.031209 L1: 0.018298 Grad: 0.128803 Thermal: 0.000619 LR: 3.90e-06\n",
      "Epoch  25 [1600/10697 ( 15.0%)] Loss: 0.031209 L1: 0.018298 Grad: 0.128803 Thermal: 0.000619 LR: 3.90e-06\n",
      "Epoch  25 [1650/10697 ( 15.4%)] Loss: 0.025802 L1: 0.014804 Grad: 0.109742 Thermal: 0.000479 LR: 3.90e-06\n",
      "Epoch  25 [1650/10697 ( 15.4%)] Loss: 0.025802 L1: 0.014804 Grad: 0.109742 Thermal: 0.000479 LR: 3.90e-06\n",
      "Epoch  25 [1700/10697 ( 15.9%)] Loss: 0.027514 L1: 0.016185 Grad: 0.113042 Thermal: 0.000503 LR: 3.90e-06\n",
      "Epoch  25 [1700/10697 ( 15.9%)] Loss: 0.027514 L1: 0.016185 Grad: 0.113042 Thermal: 0.000503 LR: 3.90e-06\n",
      "Epoch  25 [1750/10697 ( 16.4%)] Loss: 0.022561 L1: 0.013428 Grad: 0.091154 Thermal: 0.000350 LR: 3.90e-06\n",
      "Epoch  25 [1750/10697 ( 16.4%)] Loss: 0.022561 L1: 0.013428 Grad: 0.091154 Thermal: 0.000350 LR: 3.90e-06\n",
      "Epoch  25 [1800/10697 ( 16.8%)] Loss: 0.029720 L1: 0.017453 Grad: 0.122372 Thermal: 0.000604 LR: 3.90e-06\n",
      "Epoch  25 [1800/10697 ( 16.8%)] Loss: 0.029720 L1: 0.017453 Grad: 0.122372 Thermal: 0.000604 LR: 3.90e-06\n",
      "Epoch  25 [1850/10697 ( 17.3%)] Loss: 0.030294 L1: 0.017230 Grad: 0.130281 Thermal: 0.000723 LR: 3.90e-06\n",
      "Epoch  25 [1850/10697 ( 17.3%)] Loss: 0.030294 L1: 0.017230 Grad: 0.130281 Thermal: 0.000723 LR: 3.90e-06\n",
      "Epoch  25 [1900/10697 ( 17.8%)] Loss: 0.024773 L1: 0.014705 Grad: 0.100469 Thermal: 0.000425 LR: 3.90e-06\n",
      "Epoch  25 [1900/10697 ( 17.8%)] Loss: 0.024773 L1: 0.014705 Grad: 0.100469 Thermal: 0.000425 LR: 3.90e-06\n",
      "Epoch  25 [1950/10697 ( 18.2%)] Loss: 0.020909 L1: 0.012287 Grad: 0.086073 Thermal: 0.000298 LR: 3.90e-06\n",
      "Epoch  25 [1950/10697 ( 18.2%)] Loss: 0.020909 L1: 0.012287 Grad: 0.086073 Thermal: 0.000298 LR: 3.90e-06\n",
      "Epoch  25 [2000/10697 ( 18.7%)] Loss: 0.022821 L1: 0.013352 Grad: 0.094494 Thermal: 0.000387 LR: 3.90e-06\n",
      "Epoch  25 [2000/10697 ( 18.7%)] Loss: 0.022821 L1: 0.013352 Grad: 0.094494 Thermal: 0.000387 LR: 3.90e-06\n",
      "Epoch  25 [2050/10697 ( 19.2%)] Loss: 0.025034 L1: 0.014681 Grad: 0.103315 Thermal: 0.000415 LR: 3.90e-06\n",
      "Epoch  25 [2050/10697 ( 19.2%)] Loss: 0.025034 L1: 0.014681 Grad: 0.103315 Thermal: 0.000415 LR: 3.90e-06\n",
      "Epoch  25 [2100/10697 ( 19.6%)] Loss: 0.024508 L1: 0.014351 Grad: 0.101355 Thermal: 0.000423 LR: 3.90e-06\n",
      "Epoch  25 [2100/10697 ( 19.6%)] Loss: 0.024508 L1: 0.014351 Grad: 0.101355 Thermal: 0.000423 LR: 3.90e-06\n",
      "Epoch  25 [2150/10697 ( 20.1%)] Loss: 0.020619 L1: 0.012049 Grad: 0.085534 Thermal: 0.000323 LR: 3.90e-06\n",
      "Epoch  25 [2150/10697 ( 20.1%)] Loss: 0.020619 L1: 0.012049 Grad: 0.085534 Thermal: 0.000323 LR: 3.90e-06\n",
      "Epoch  25 [2200/10697 ( 20.6%)] Loss: 0.022928 L1: 0.013293 Grad: 0.096152 Thermal: 0.000401 LR: 3.90e-06\n",
      "Epoch  25 [2200/10697 ( 20.6%)] Loss: 0.022928 L1: 0.013293 Grad: 0.096152 Thermal: 0.000401 LR: 3.90e-06\n",
      "Epoch  25 [2250/10697 ( 21.0%)] Loss: 0.026885 L1: 0.015526 Grad: 0.113380 Thermal: 0.000422 LR: 3.90e-06\n",
      "Epoch  25 [2250/10697 ( 21.0%)] Loss: 0.026885 L1: 0.015526 Grad: 0.113380 Thermal: 0.000422 LR: 3.90e-06\n",
      "Epoch  25 [2300/10697 ( 21.5%)] Loss: 0.026461 L1: 0.015190 Grad: 0.112462 Thermal: 0.000500 LR: 3.90e-06\n",
      "Epoch  25 [2300/10697 ( 21.5%)] Loss: 0.026461 L1: 0.015190 Grad: 0.112462 Thermal: 0.000500 LR: 3.90e-06\n",
      "Epoch  25 [2350/10697 ( 22.0%)] Loss: 0.024774 L1: 0.014677 Grad: 0.100774 Thermal: 0.000395 LR: 3.90e-06\n",
      "Epoch  25 [2350/10697 ( 22.0%)] Loss: 0.024774 L1: 0.014677 Grad: 0.100774 Thermal: 0.000395 LR: 3.90e-06\n",
      "Epoch  25 [2400/10697 ( 22.4%)] Loss: 0.019916 L1: 0.011543 Grad: 0.083584 Thermal: 0.000283 LR: 3.90e-06\n",
      "Epoch  25 [2400/10697 ( 22.4%)] Loss: 0.019916 L1: 0.011543 Grad: 0.083584 Thermal: 0.000283 LR: 3.90e-06\n",
      "Epoch  25 [2450/10697 ( 22.9%)] Loss: 0.028523 L1: 0.016393 Grad: 0.121045 Thermal: 0.000496 LR: 3.90e-06\n",
      "Epoch  25 [2450/10697 ( 22.9%)] Loss: 0.028523 L1: 0.016393 Grad: 0.121045 Thermal: 0.000496 LR: 3.90e-06\n",
      "Epoch  25 [2500/10697 ( 23.4%)] Loss: 0.025656 L1: 0.014354 Grad: 0.112820 Thermal: 0.000396 LR: 3.90e-06\n",
      "Epoch  25 [2500/10697 ( 23.4%)] Loss: 0.025656 L1: 0.014354 Grad: 0.112820 Thermal: 0.000396 LR: 3.90e-06\n",
      "Epoch  25 [2550/10697 ( 23.8%)] Loss: 0.026905 L1: 0.016015 Grad: 0.108671 Thermal: 0.000474 LR: 3.90e-06\n",
      "Epoch  25 [2550/10697 ( 23.8%)] Loss: 0.026905 L1: 0.016015 Grad: 0.108671 Thermal: 0.000474 LR: 3.90e-06\n",
      "Epoch  25 [2600/10697 ( 24.3%)] Loss: 0.020957 L1: 0.012164 Grad: 0.087786 Thermal: 0.000291 LR: 3.90e-06\n",
      "Epoch  25 [2600/10697 ( 24.3%)] Loss: 0.020957 L1: 0.012164 Grad: 0.087786 Thermal: 0.000291 LR: 3.90e-06\n",
      "Epoch  25 [2650/10697 ( 24.8%)] Loss: 0.024143 L1: 0.013805 Grad: 0.103192 Thermal: 0.000370 LR: 3.90e-06\n",
      "Epoch  25 [2650/10697 ( 24.8%)] Loss: 0.024143 L1: 0.013805 Grad: 0.103192 Thermal: 0.000370 LR: 3.90e-06\n",
      "Epoch  25 [2700/10697 ( 25.2%)] Loss: 0.023294 L1: 0.013415 Grad: 0.098602 Thermal: 0.000372 LR: 3.90e-06\n",
      "Epoch  25 [2700/10697 ( 25.2%)] Loss: 0.023294 L1: 0.013415 Grad: 0.098602 Thermal: 0.000372 LR: 3.90e-06\n",
      "Epoch  25 [2750/10697 ( 25.7%)] Loss: 0.028375 L1: 0.016799 Grad: 0.115529 Thermal: 0.000481 LR: 3.90e-06\n",
      "Epoch  25 [2750/10697 ( 25.7%)] Loss: 0.028375 L1: 0.016799 Grad: 0.115529 Thermal: 0.000481 LR: 3.90e-06\n",
      "Epoch  25 [2800/10697 ( 26.2%)] Loss: 0.029101 L1: 0.017074 Grad: 0.119986 Thermal: 0.000563 LR: 3.90e-06\n",
      "Epoch  25 [2800/10697 ( 26.2%)] Loss: 0.029101 L1: 0.017074 Grad: 0.119986 Thermal: 0.000563 LR: 3.90e-06\n",
      "Epoch  25 [2850/10697 ( 26.6%)] Loss: 0.023085 L1: 0.013701 Grad: 0.093655 Thermal: 0.000369 LR: 3.90e-06\n",
      "Epoch  25 [2850/10697 ( 26.6%)] Loss: 0.023085 L1: 0.013701 Grad: 0.093655 Thermal: 0.000369 LR: 3.90e-06\n",
      "Epoch  25 [2900/10697 ( 27.1%)] Loss: 0.031461 L1: 0.018453 Grad: 0.129689 Thermal: 0.000772 LR: 3.90e-06\n",
      "Epoch  25 [2900/10697 ( 27.1%)] Loss: 0.031461 L1: 0.018453 Grad: 0.129689 Thermal: 0.000772 LR: 3.90e-06\n",
      "Epoch  25 [2950/10697 ( 27.6%)] Loss: 0.024829 L1: 0.014963 Grad: 0.098454 Thermal: 0.000407 LR: 3.90e-06\n",
      "Epoch  25 [2950/10697 ( 27.6%)] Loss: 0.024829 L1: 0.014963 Grad: 0.098454 Thermal: 0.000407 LR: 3.90e-06\n",
      "Epoch  25 [3000/10697 ( 28.0%)] Loss: 0.023867 L1: 0.014110 Grad: 0.097387 Thermal: 0.000357 LR: 3.90e-06\n",
      "Epoch  25 [3000/10697 ( 28.0%)] Loss: 0.023867 L1: 0.014110 Grad: 0.097387 Thermal: 0.000357 LR: 3.90e-06\n",
      "Epoch  25 [3050/10697 ( 28.5%)] Loss: 0.025530 L1: 0.015040 Grad: 0.104693 Thermal: 0.000410 LR: 3.90e-06\n",
      "Epoch  25 [3050/10697 ( 28.5%)] Loss: 0.025530 L1: 0.015040 Grad: 0.104693 Thermal: 0.000410 LR: 3.90e-06\n",
      "Epoch  25 [3100/10697 ( 29.0%)] Loss: 0.030314 L1: 0.017823 Grad: 0.124569 Thermal: 0.000680 LR: 3.90e-06\n",
      "Epoch  25 [3100/10697 ( 29.0%)] Loss: 0.030314 L1: 0.017823 Grad: 0.124569 Thermal: 0.000680 LR: 3.90e-06\n",
      "Epoch  25 [3150/10697 ( 29.4%)] Loss: 0.023458 L1: 0.013599 Grad: 0.098399 Thermal: 0.000382 LR: 3.90e-06\n",
      "Epoch  25 [3150/10697 ( 29.4%)] Loss: 0.023458 L1: 0.013599 Grad: 0.098399 Thermal: 0.000382 LR: 3.90e-06\n",
      "Epoch  25 [3200/10697 ( 29.9%)] Loss: 0.026967 L1: 0.015319 Grad: 0.116245 Thermal: 0.000465 LR: 3.90e-06\n",
      "Epoch  25 [3200/10697 ( 29.9%)] Loss: 0.026967 L1: 0.015319 Grad: 0.116245 Thermal: 0.000465 LR: 3.90e-06\n",
      "Epoch  25 [3250/10697 ( 30.4%)] Loss: 0.025017 L1: 0.014648 Grad: 0.103493 Thermal: 0.000400 LR: 3.90e-06\n",
      "Epoch  25 [3250/10697 ( 30.4%)] Loss: 0.025017 L1: 0.014648 Grad: 0.103493 Thermal: 0.000400 LR: 3.90e-06\n",
      "Epoch  25 [3300/10697 ( 30.8%)] Loss: 0.029984 L1: 0.017656 Grad: 0.122998 Thermal: 0.000562 LR: 3.90e-06\n",
      "Epoch  25 [3300/10697 ( 30.8%)] Loss: 0.029984 L1: 0.017656 Grad: 0.122998 Thermal: 0.000562 LR: 3.90e-06\n",
      "Epoch  25 [3350/10697 ( 31.3%)] Loss: 0.030067 L1: 0.017163 Grad: 0.128763 Thermal: 0.000555 LR: 3.90e-06\n",
      "Epoch  25 [3350/10697 ( 31.3%)] Loss: 0.030067 L1: 0.017163 Grad: 0.128763 Thermal: 0.000555 LR: 3.90e-06\n",
      "Epoch  25 [3400/10697 ( 31.8%)] Loss: 0.023320 L1: 0.013692 Grad: 0.096110 Thermal: 0.000338 LR: 3.90e-06\n",
      "Epoch  25 [3400/10697 ( 31.8%)] Loss: 0.023320 L1: 0.013692 Grad: 0.096110 Thermal: 0.000338 LR: 3.90e-06\n",
      "Epoch  25 [3450/10697 ( 32.3%)] Loss: 0.024266 L1: 0.013959 Grad: 0.102877 Thermal: 0.000386 LR: 3.90e-06\n",
      "Epoch  25 [3450/10697 ( 32.3%)] Loss: 0.024266 L1: 0.013959 Grad: 0.102877 Thermal: 0.000386 LR: 3.90e-06\n",
      "Epoch  25 [3500/10697 ( 32.7%)] Loss: 0.028439 L1: 0.016339 Grad: 0.120719 Thermal: 0.000560 LR: 3.90e-06\n",
      "Epoch  25 [3500/10697 ( 32.7%)] Loss: 0.028439 L1: 0.016339 Grad: 0.120719 Thermal: 0.000560 LR: 3.90e-06\n",
      "Epoch  25 [3550/10697 ( 33.2%)] Loss: 0.024317 L1: 0.014188 Grad: 0.101100 Thermal: 0.000363 LR: 3.90e-06\n",
      "Epoch  25 [3550/10697 ( 33.2%)] Loss: 0.024317 L1: 0.014188 Grad: 0.101100 Thermal: 0.000363 LR: 3.90e-06\n",
      "Epoch  25 [3600/10697 ( 33.7%)] Loss: 0.024288 L1: 0.014271 Grad: 0.099977 Thermal: 0.000377 LR: 3.90e-06\n",
      "Epoch  25 [3600/10697 ( 33.7%)] Loss: 0.024288 L1: 0.014271 Grad: 0.099977 Thermal: 0.000377 LR: 3.90e-06\n",
      "Epoch  25 [3650/10697 ( 34.1%)] Loss: 0.026068 L1: 0.015247 Grad: 0.107997 Thermal: 0.000417 LR: 3.90e-06\n",
      "Epoch  25 [3650/10697 ( 34.1%)] Loss: 0.026068 L1: 0.015247 Grad: 0.107997 Thermal: 0.000417 LR: 3.90e-06\n",
      "Epoch  25 [3700/10697 ( 34.6%)] Loss: 0.030238 L1: 0.017647 Grad: 0.125633 Thermal: 0.000550 LR: 3.90e-06\n",
      "Epoch  25 [3700/10697 ( 34.6%)] Loss: 0.030238 L1: 0.017647 Grad: 0.125633 Thermal: 0.000550 LR: 3.90e-06\n",
      "Epoch  25 [3750/10697 ( 35.1%)] Loss: 0.029959 L1: 0.017480 Grad: 0.124483 Thermal: 0.000601 LR: 3.90e-06\n",
      "Epoch  25 [3750/10697 ( 35.1%)] Loss: 0.029959 L1: 0.017480 Grad: 0.124483 Thermal: 0.000601 LR: 3.90e-06\n",
      "Epoch  25 [3800/10697 ( 35.5%)] Loss: 0.027486 L1: 0.015977 Grad: 0.114848 Thermal: 0.000500 LR: 3.90e-06\n",
      "Epoch  25 [3800/10697 ( 35.5%)] Loss: 0.027486 L1: 0.015977 Grad: 0.114848 Thermal: 0.000500 LR: 3.90e-06\n",
      "Epoch  25 [3850/10697 ( 36.0%)] Loss: 0.030480 L1: 0.017813 Grad: 0.126382 Thermal: 0.000565 LR: 3.90e-06\n",
      "Epoch  25 [3850/10697 ( 36.0%)] Loss: 0.030480 L1: 0.017813 Grad: 0.126382 Thermal: 0.000565 LR: 3.90e-06\n",
      "Epoch  25 [3900/10697 ( 36.5%)] Loss: 0.022148 L1: 0.012617 Grad: 0.095148 Thermal: 0.000329 LR: 3.90e-06\n",
      "Epoch  25 [3900/10697 ( 36.5%)] Loss: 0.022148 L1: 0.012617 Grad: 0.095148 Thermal: 0.000329 LR: 3.90e-06\n",
      "Epoch  25 [3950/10697 ( 36.9%)] Loss: 0.021088 L1: 0.012246 Grad: 0.088270 Thermal: 0.000297 LR: 3.90e-06\n",
      "Epoch  25 [3950/10697 ( 36.9%)] Loss: 0.021088 L1: 0.012246 Grad: 0.088270 Thermal: 0.000297 LR: 3.90e-06\n",
      "Epoch  25 [4000/10697 ( 37.4%)] Loss: 0.024369 L1: 0.013935 Grad: 0.104160 Thermal: 0.000358 LR: 3.90e-06\n",
      "Epoch  25 [4000/10697 ( 37.4%)] Loss: 0.024369 L1: 0.013935 Grad: 0.104160 Thermal: 0.000358 LR: 3.90e-06\n",
      "Epoch  25 [4050/10697 ( 37.9%)] Loss: 0.030902 L1: 0.017779 Grad: 0.130942 Thermal: 0.000590 LR: 3.90e-06\n",
      "Epoch  25 [4050/10697 ( 37.9%)] Loss: 0.030902 L1: 0.017779 Grad: 0.130942 Thermal: 0.000590 LR: 3.90e-06\n",
      "Epoch  25 [4100/10697 ( 38.3%)] Loss: 0.026646 L1: 0.015780 Grad: 0.108432 Thermal: 0.000452 LR: 3.90e-06\n",
      "Epoch  25 [4100/10697 ( 38.3%)] Loss: 0.026646 L1: 0.015780 Grad: 0.108432 Thermal: 0.000452 LR: 3.90e-06\n",
      "Epoch  25 [4150/10697 ( 38.8%)] Loss: 0.023143 L1: 0.013631 Grad: 0.094946 Thermal: 0.000365 LR: 3.90e-06\n",
      "Epoch  25 [4150/10697 ( 38.8%)] Loss: 0.023143 L1: 0.013631 Grad: 0.094946 Thermal: 0.000365 LR: 3.90e-06\n",
      "Epoch  25 [4200/10697 ( 39.3%)] Loss: 0.023607 L1: 0.013433 Grad: 0.101554 Thermal: 0.000369 LR: 3.90e-06\n",
      "Epoch  25 [4200/10697 ( 39.3%)] Loss: 0.023607 L1: 0.013433 Grad: 0.101554 Thermal: 0.000369 LR: 3.90e-06\n",
      "Epoch  25 [4250/10697 ( 39.7%)] Loss: 0.023798 L1: 0.013851 Grad: 0.099275 Thermal: 0.000388 LR: 3.90e-06\n",
      "Epoch  25 [4250/10697 ( 39.7%)] Loss: 0.023798 L1: 0.013851 Grad: 0.099275 Thermal: 0.000388 LR: 3.90e-06\n",
      "Epoch  25 [4300/10697 ( 40.2%)] Loss: 0.026817 L1: 0.016201 Grad: 0.105940 Thermal: 0.000453 LR: 3.90e-06\n",
      "Epoch  25 [4300/10697 ( 40.2%)] Loss: 0.026817 L1: 0.016201 Grad: 0.105940 Thermal: 0.000453 LR: 3.90e-06\n",
      "Epoch  25 [4350/10697 ( 40.7%)] Loss: 0.028498 L1: 0.016103 Grad: 0.123701 Thermal: 0.000499 LR: 3.90e-06\n",
      "Epoch  25 [4350/10697 ( 40.7%)] Loss: 0.028498 L1: 0.016103 Grad: 0.123701 Thermal: 0.000499 LR: 3.90e-06\n",
      "Epoch  25 [4400/10697 ( 41.1%)] Loss: 0.030708 L1: 0.017768 Grad: 0.129129 Thermal: 0.000560 LR: 3.90e-06\n",
      "Epoch  25 [4400/10697 ( 41.1%)] Loss: 0.030708 L1: 0.017768 Grad: 0.129129 Thermal: 0.000560 LR: 3.90e-06\n",
      "Epoch  25 [4450/10697 ( 41.6%)] Loss: 0.028482 L1: 0.016809 Grad: 0.116461 Thermal: 0.000539 LR: 3.90e-06\n",
      "Epoch  25 [4450/10697 ( 41.6%)] Loss: 0.028482 L1: 0.016809 Grad: 0.116461 Thermal: 0.000539 LR: 3.90e-06\n",
      "Epoch  25 [4500/10697 ( 42.1%)] Loss: 0.025075 L1: 0.015068 Grad: 0.099857 Thermal: 0.000426 LR: 3.90e-06\n",
      "Epoch  25 [4500/10697 ( 42.1%)] Loss: 0.025075 L1: 0.015068 Grad: 0.099857 Thermal: 0.000426 LR: 3.90e-06\n",
      "Epoch  25 [4550/10697 ( 42.5%)] Loss: 0.022899 L1: 0.013593 Grad: 0.092875 Thermal: 0.000369 LR: 3.90e-06\n",
      "Epoch  25 [4550/10697 ( 42.5%)] Loss: 0.022899 L1: 0.013593 Grad: 0.092875 Thermal: 0.000369 LR: 3.90e-06\n",
      "Epoch  25 [4600/10697 ( 43.0%)] Loss: 0.027238 L1: 0.015593 Grad: 0.116179 Thermal: 0.000527 LR: 3.90e-06\n",
      "Epoch  25 [4600/10697 ( 43.0%)] Loss: 0.027238 L1: 0.015593 Grad: 0.116179 Thermal: 0.000527 LR: 3.90e-06\n",
      "Epoch  25 [4650/10697 ( 43.5%)] Loss: 0.025161 L1: 0.014840 Grad: 0.102987 Thermal: 0.000441 LR: 3.90e-06\n",
      "Epoch  25 [4650/10697 ( 43.5%)] Loss: 0.025161 L1: 0.014840 Grad: 0.102987 Thermal: 0.000441 LR: 3.90e-06\n",
      "Epoch  25 [4700/10697 ( 43.9%)] Loss: 0.022677 L1: 0.013112 Grad: 0.095471 Thermal: 0.000362 LR: 3.90e-06\n",
      "Epoch  25 [4700/10697 ( 43.9%)] Loss: 0.022677 L1: 0.013112 Grad: 0.095471 Thermal: 0.000362 LR: 3.90e-06\n",
      "Epoch  25 [4750/10697 ( 44.4%)] Loss: 0.027232 L1: 0.016216 Grad: 0.109931 Thermal: 0.000461 LR: 3.90e-06\n",
      "Epoch  25 [4750/10697 ( 44.4%)] Loss: 0.027232 L1: 0.016216 Grad: 0.109931 Thermal: 0.000461 LR: 3.90e-06\n",
      "Epoch  25 [4800/10697 ( 44.9%)] Loss: 0.029083 L1: 0.017531 Grad: 0.115251 Thermal: 0.000538 LR: 3.90e-06\n",
      "Epoch  25 [4800/10697 ( 44.9%)] Loss: 0.029083 L1: 0.017531 Grad: 0.115251 Thermal: 0.000538 LR: 3.90e-06\n",
      "Epoch  25 [4850/10697 ( 45.3%)] Loss: 0.023604 L1: 0.013768 Grad: 0.098182 Thermal: 0.000343 LR: 3.90e-06\n",
      "Epoch  25 [4850/10697 ( 45.3%)] Loss: 0.023604 L1: 0.013768 Grad: 0.098182 Thermal: 0.000343 LR: 3.90e-06\n",
      "Epoch  25 [4900/10697 ( 45.8%)] Loss: 0.028590 L1: 0.016972 Grad: 0.115917 Thermal: 0.000524 LR: 3.90e-06\n",
      "Epoch  25 [4900/10697 ( 45.8%)] Loss: 0.028590 L1: 0.016972 Grad: 0.115917 Thermal: 0.000524 LR: 3.90e-06\n",
      "Epoch  25 [4950/10697 ( 46.3%)] Loss: 0.023055 L1: 0.013266 Grad: 0.097708 Thermal: 0.000377 LR: 3.90e-06\n",
      "Epoch  25 [4950/10697 ( 46.3%)] Loss: 0.023055 L1: 0.013266 Grad: 0.097708 Thermal: 0.000377 LR: 3.90e-06\n",
      "Epoch  25 [5000/10697 ( 46.7%)] Loss: 0.029599 L1: 0.017329 Grad: 0.122435 Thermal: 0.000535 LR: 3.90e-06\n",
      "Epoch  25 [5000/10697 ( 46.7%)] Loss: 0.029599 L1: 0.017329 Grad: 0.122435 Thermal: 0.000535 LR: 3.90e-06\n",
      "Epoch  25 [5050/10697 ( 47.2%)] Loss: 0.023030 L1: 0.013621 Grad: 0.093919 Thermal: 0.000343 LR: 3.90e-06\n",
      "Epoch  25 [5050/10697 ( 47.2%)] Loss: 0.023030 L1: 0.013621 Grad: 0.093919 Thermal: 0.000343 LR: 3.90e-06\n",
      "Epoch  25 [5100/10697 ( 47.7%)] Loss: 0.025642 L1: 0.015110 Grad: 0.105099 Thermal: 0.000424 LR: 3.90e-06\n",
      "Epoch  25 [5100/10697 ( 47.7%)] Loss: 0.025642 L1: 0.015110 Grad: 0.105099 Thermal: 0.000424 LR: 3.90e-06\n",
      "Epoch  25 [5150/10697 ( 48.1%)] Loss: 0.021615 L1: 0.012759 Grad: 0.088393 Thermal: 0.000336 LR: 3.90e-06\n",
      "Epoch  25 [5150/10697 ( 48.1%)] Loss: 0.021615 L1: 0.012759 Grad: 0.088393 Thermal: 0.000336 LR: 3.90e-06\n",
      "Epoch  25 [5200/10697 ( 48.6%)] Loss: 0.025557 L1: 0.014788 Grad: 0.107493 Thermal: 0.000398 LR: 3.90e-06\n",
      "Epoch  25 [5200/10697 ( 48.6%)] Loss: 0.025557 L1: 0.014788 Grad: 0.107493 Thermal: 0.000398 LR: 3.90e-06\n",
      "Epoch  25 [5250/10697 ( 49.1%)] Loss: 0.026624 L1: 0.015563 Grad: 0.110377 Thermal: 0.000472 LR: 3.90e-06\n",
      "Epoch  25 [5250/10697 ( 49.1%)] Loss: 0.026624 L1: 0.015563 Grad: 0.110377 Thermal: 0.000472 LR: 3.90e-06\n",
      "Epoch  25 [5300/10697 ( 49.5%)] Loss: 0.025615 L1: 0.014385 Grad: 0.112088 Thermal: 0.000424 LR: 3.90e-06\n",
      "Epoch  25 [5300/10697 ( 49.5%)] Loss: 0.025615 L1: 0.014385 Grad: 0.112088 Thermal: 0.000424 LR: 3.90e-06\n",
      "Epoch  25 [5350/10697 ( 50.0%)] Loss: 0.025161 L1: 0.014400 Grad: 0.107409 Thermal: 0.000402 LR: 3.90e-06\n",
      "Epoch  25 [5350/10697 ( 50.0%)] Loss: 0.025161 L1: 0.014400 Grad: 0.107409 Thermal: 0.000402 LR: 3.90e-06\n",
      "Epoch  25 [5400/10697 ( 50.5%)] Loss: 0.025208 L1: 0.014288 Grad: 0.108991 Thermal: 0.000423 LR: 3.90e-06\n",
      "Epoch  25 [5400/10697 ( 50.5%)] Loss: 0.025208 L1: 0.014288 Grad: 0.108991 Thermal: 0.000423 LR: 3.90e-06\n",
      "Epoch  25 [5450/10697 ( 50.9%)] Loss: 0.026019 L1: 0.015204 Grad: 0.107932 Thermal: 0.000438 LR: 3.90e-06\n",
      "Epoch  25 [5450/10697 ( 50.9%)] Loss: 0.026019 L1: 0.015204 Grad: 0.107932 Thermal: 0.000438 LR: 3.90e-06\n",
      "Epoch  25 [5500/10697 ( 51.4%)] Loss: 0.023963 L1: 0.014041 Grad: 0.099035 Thermal: 0.000370 LR: 3.90e-06\n",
      "Epoch  25 [5500/10697 ( 51.4%)] Loss: 0.023963 L1: 0.014041 Grad: 0.099035 Thermal: 0.000370 LR: 3.90e-06\n",
      "Epoch  25 [5550/10697 ( 51.9%)] Loss: 0.028401 L1: 0.016604 Grad: 0.117734 Thermal: 0.000473 LR: 3.90e-06\n",
      "Epoch  25 [5550/10697 ( 51.9%)] Loss: 0.028401 L1: 0.016604 Grad: 0.117734 Thermal: 0.000473 LR: 3.90e-06\n",
      "Epoch  25 [5600/10697 ( 52.4%)] Loss: 0.030008 L1: 0.017763 Grad: 0.122142 Thermal: 0.000599 LR: 3.90e-06\n",
      "Epoch  25 [5600/10697 ( 52.4%)] Loss: 0.030008 L1: 0.017763 Grad: 0.122142 Thermal: 0.000599 LR: 3.90e-06\n",
      "Epoch  25 [5650/10697 ( 52.8%)] Loss: 0.024919 L1: 0.014416 Grad: 0.104825 Thermal: 0.000407 LR: 3.90e-06\n",
      "Epoch  25 [5650/10697 ( 52.8%)] Loss: 0.024919 L1: 0.014416 Grad: 0.104825 Thermal: 0.000407 LR: 3.90e-06\n",
      "Epoch  25 [5700/10697 ( 53.3%)] Loss: 0.028995 L1: 0.017066 Grad: 0.119011 Thermal: 0.000552 LR: 3.90e-06\n",
      "Epoch  25 [5700/10697 ( 53.3%)] Loss: 0.028995 L1: 0.017066 Grad: 0.119011 Thermal: 0.000552 LR: 3.90e-06\n",
      "Epoch  25 [5750/10697 ( 53.8%)] Loss: 0.027147 L1: 0.016141 Grad: 0.109836 Thermal: 0.000451 LR: 3.90e-06\n",
      "Epoch  25 [5750/10697 ( 53.8%)] Loss: 0.027147 L1: 0.016141 Grad: 0.109836 Thermal: 0.000451 LR: 3.90e-06\n",
      "Epoch  25 [5800/10697 ( 54.2%)] Loss: 0.021900 L1: 0.012681 Grad: 0.092020 Thermal: 0.000326 LR: 3.90e-06\n",
      "Epoch  25 [5800/10697 ( 54.2%)] Loss: 0.021900 L1: 0.012681 Grad: 0.092020 Thermal: 0.000326 LR: 3.90e-06\n",
      "Epoch  25 [5850/10697 ( 54.7%)] Loss: 0.014085 L1: 0.008049 Grad: 0.060276 Thermal: 0.000154 LR: 3.90e-06\n",
      "Epoch  25 [5850/10697 ( 54.7%)] Loss: 0.014085 L1: 0.008049 Grad: 0.060276 Thermal: 0.000154 LR: 3.90e-06\n",
      "Epoch  25 [5900/10697 ( 55.2%)] Loss: 0.028442 L1: 0.016637 Grad: 0.117797 Thermal: 0.000504 LR: 3.90e-06\n",
      "Epoch  25 [5900/10697 ( 55.2%)] Loss: 0.028442 L1: 0.016637 Grad: 0.117797 Thermal: 0.000504 LR: 3.90e-06\n",
      "Epoch  25 [5950/10697 ( 55.6%)] Loss: 0.027993 L1: 0.016832 Grad: 0.111352 Thermal: 0.000517 LR: 3.90e-06\n",
      "Epoch  25 [5950/10697 ( 55.6%)] Loss: 0.027993 L1: 0.016832 Grad: 0.111352 Thermal: 0.000517 LR: 3.90e-06\n",
      "Epoch  25 [6000/10697 ( 56.1%)] Loss: 0.027440 L1: 0.015510 Grad: 0.119052 Thermal: 0.000506 LR: 3.90e-06\n",
      "Epoch  25 [6000/10697 ( 56.1%)] Loss: 0.027440 L1: 0.015510 Grad: 0.119052 Thermal: 0.000506 LR: 3.90e-06\n",
      "Epoch  25 [6050/10697 ( 56.6%)] Loss: 0.028973 L1: 0.017371 Grad: 0.115759 Thermal: 0.000524 LR: 3.90e-06\n",
      "Epoch  25 [6050/10697 ( 56.6%)] Loss: 0.028973 L1: 0.017371 Grad: 0.115759 Thermal: 0.000524 LR: 3.90e-06\n",
      "Epoch  25 [6100/10697 ( 57.0%)] Loss: 0.026661 L1: 0.015417 Grad: 0.112219 Thermal: 0.000438 LR: 3.90e-06\n",
      "Epoch  25 [6100/10697 ( 57.0%)] Loss: 0.026661 L1: 0.015417 Grad: 0.112219 Thermal: 0.000438 LR: 3.90e-06\n",
      "Epoch  25 [6150/10697 ( 57.5%)] Loss: 0.029006 L1: 0.017123 Grad: 0.118562 Thermal: 0.000553 LR: 3.90e-06\n",
      "Epoch  25 [6150/10697 ( 57.5%)] Loss: 0.029006 L1: 0.017123 Grad: 0.118562 Thermal: 0.000553 LR: 3.90e-06\n",
      "Epoch  25 [6200/10697 ( 58.0%)] Loss: 0.024407 L1: 0.014094 Grad: 0.102938 Thermal: 0.000377 LR: 3.90e-06\n",
      "Epoch  25 [6200/10697 ( 58.0%)] Loss: 0.024407 L1: 0.014094 Grad: 0.102938 Thermal: 0.000377 LR: 3.90e-06\n",
      "Epoch  25 [6250/10697 ( 58.4%)] Loss: 0.023907 L1: 0.014069 Grad: 0.098171 Thermal: 0.000418 LR: 3.90e-06\n",
      "Epoch  25 [6250/10697 ( 58.4%)] Loss: 0.023907 L1: 0.014069 Grad: 0.098171 Thermal: 0.000418 LR: 3.90e-06\n",
      "Epoch  25 [6300/10697 ( 58.9%)] Loss: 0.023921 L1: 0.014325 Grad: 0.095749 Thermal: 0.000422 LR: 3.90e-06\n",
      "Epoch  25 [6300/10697 ( 58.9%)] Loss: 0.023921 L1: 0.014325 Grad: 0.095749 Thermal: 0.000422 LR: 3.90e-06\n",
      "Epoch  25 [6350/10697 ( 59.4%)] Loss: 0.031017 L1: 0.018169 Grad: 0.128192 Thermal: 0.000577 LR: 3.90e-06\n",
      "Epoch  25 [6350/10697 ( 59.4%)] Loss: 0.031017 L1: 0.018169 Grad: 0.128192 Thermal: 0.000577 LR: 3.90e-06\n",
      "Epoch  25 [6400/10697 ( 59.8%)] Loss: 0.031427 L1: 0.018127 Grad: 0.132707 Thermal: 0.000577 LR: 3.90e-06\n",
      "Epoch  25 [6400/10697 ( 59.8%)] Loss: 0.031427 L1: 0.018127 Grad: 0.132707 Thermal: 0.000577 LR: 3.90e-06\n",
      "Epoch  25 [6450/10697 ( 60.3%)] Loss: 0.032260 L1: 0.018581 Grad: 0.136457 Thermal: 0.000666 LR: 3.90e-06\n",
      "Epoch  25 [6450/10697 ( 60.3%)] Loss: 0.032260 L1: 0.018581 Grad: 0.136457 Thermal: 0.000666 LR: 3.90e-06\n",
      "Epoch  25 [6500/10697 ( 60.8%)] Loss: 0.027222 L1: 0.015593 Grad: 0.116060 Thermal: 0.000453 LR: 3.90e-06\n",
      "Epoch  25 [6500/10697 ( 60.8%)] Loss: 0.027222 L1: 0.015593 Grad: 0.116060 Thermal: 0.000453 LR: 3.90e-06\n",
      "Epoch  25 [6550/10697 ( 61.2%)] Loss: 0.022973 L1: 0.013490 Grad: 0.094659 Thermal: 0.000358 LR: 3.90e-06\n",
      "Epoch  25 [6550/10697 ( 61.2%)] Loss: 0.022973 L1: 0.013490 Grad: 0.094659 Thermal: 0.000358 LR: 3.90e-06\n",
      "Epoch  25 [6600/10697 ( 61.7%)] Loss: 0.024672 L1: 0.014759 Grad: 0.098935 Thermal: 0.000395 LR: 3.90e-06\n",
      "Epoch  25 [6600/10697 ( 61.7%)] Loss: 0.024672 L1: 0.014759 Grad: 0.098935 Thermal: 0.000395 LR: 3.90e-06\n",
      "Epoch  25 [6650/10697 ( 62.2%)] Loss: 0.027961 L1: 0.016185 Grad: 0.117526 Thermal: 0.000480 LR: 3.90e-06\n",
      "Epoch  25 [6650/10697 ( 62.2%)] Loss: 0.027961 L1: 0.016185 Grad: 0.117526 Thermal: 0.000480 LR: 3.90e-06\n",
      "Epoch  25 [6700/10697 ( 62.6%)] Loss: 0.025012 L1: 0.014535 Grad: 0.104574 Thermal: 0.000395 LR: 3.90e-06\n",
      "Epoch  25 [6700/10697 ( 62.6%)] Loss: 0.025012 L1: 0.014535 Grad: 0.104574 Thermal: 0.000395 LR: 3.90e-06\n",
      "Epoch  25 [6750/10697 ( 63.1%)] Loss: 0.026964 L1: 0.016075 Grad: 0.108668 Thermal: 0.000448 LR: 3.90e-06\n",
      "Epoch  25 [6750/10697 ( 63.1%)] Loss: 0.026964 L1: 0.016075 Grad: 0.108668 Thermal: 0.000448 LR: 3.90e-06\n",
      "Epoch  25 [6800/10697 ( 63.6%)] Loss: 0.027616 L1: 0.015776 Grad: 0.118170 Thermal: 0.000456 LR: 3.90e-06\n",
      "Epoch  25 [6800/10697 ( 63.6%)] Loss: 0.027616 L1: 0.015776 Grad: 0.118170 Thermal: 0.000456 LR: 3.90e-06\n",
      "Epoch  25 [6850/10697 ( 64.0%)] Loss: 0.027332 L1: 0.015887 Grad: 0.114225 Thermal: 0.000448 LR: 3.90e-06\n",
      "Epoch  25 [6850/10697 ( 64.0%)] Loss: 0.027332 L1: 0.015887 Grad: 0.114225 Thermal: 0.000448 LR: 3.90e-06\n",
      "Epoch  25 [6900/10697 ( 64.5%)] Loss: 0.025655 L1: 0.015080 Grad: 0.105523 Thermal: 0.000470 LR: 3.90e-06\n",
      "Epoch  25 [6900/10697 ( 64.5%)] Loss: 0.025655 L1: 0.015080 Grad: 0.105523 Thermal: 0.000470 LR: 3.90e-06\n",
      "Epoch  25 [6950/10697 ( 65.0%)] Loss: 0.025399 L1: 0.015214 Grad: 0.101636 Thermal: 0.000415 LR: 3.90e-06\n",
      "Epoch  25 [6950/10697 ( 65.0%)] Loss: 0.025399 L1: 0.015214 Grad: 0.101636 Thermal: 0.000415 LR: 3.90e-06\n",
      "Epoch  25 [7000/10697 ( 65.4%)] Loss: 0.020293 L1: 0.011690 Grad: 0.085882 Thermal: 0.000295 LR: 3.90e-06\n",
      "Epoch  25 [7000/10697 ( 65.4%)] Loss: 0.020293 L1: 0.011690 Grad: 0.085882 Thermal: 0.000295 LR: 3.90e-06\n",
      "Epoch  25 [7050/10697 ( 65.9%)] Loss: 0.027053 L1: 0.016132 Grad: 0.108977 Thermal: 0.000465 LR: 3.90e-06\n",
      "Epoch  25 [7050/10697 ( 65.9%)] Loss: 0.027053 L1: 0.016132 Grad: 0.108977 Thermal: 0.000465 LR: 3.90e-06\n",
      "Epoch  25 [7100/10697 ( 66.4%)] Loss: 0.024769 L1: 0.014366 Grad: 0.103836 Thermal: 0.000383 LR: 3.90e-06\n",
      "Epoch  25 [7100/10697 ( 66.4%)] Loss: 0.024769 L1: 0.014366 Grad: 0.103836 Thermal: 0.000383 LR: 3.90e-06\n",
      "Epoch  25 [7150/10697 ( 66.8%)] Loss: 0.027630 L1: 0.016093 Grad: 0.115111 Thermal: 0.000524 LR: 3.90e-06\n",
      "Epoch  25 [7150/10697 ( 66.8%)] Loss: 0.027630 L1: 0.016093 Grad: 0.115111 Thermal: 0.000524 LR: 3.90e-06\n",
      "Epoch  25 [7200/10697 ( 67.3%)] Loss: 0.025207 L1: 0.014672 Grad: 0.105136 Thermal: 0.000421 LR: 3.90e-06\n",
      "Epoch  25 [7200/10697 ( 67.3%)] Loss: 0.025207 L1: 0.014672 Grad: 0.105136 Thermal: 0.000421 LR: 3.90e-06\n",
      "Epoch  25 [7250/10697 ( 67.8%)] Loss: 0.025994 L1: 0.015733 Grad: 0.102398 Thermal: 0.000422 LR: 3.90e-06\n",
      "Epoch  25 [7250/10697 ( 67.8%)] Loss: 0.025994 L1: 0.015733 Grad: 0.102398 Thermal: 0.000422 LR: 3.90e-06\n",
      "Epoch  25 [7300/10697 ( 68.2%)] Loss: 0.021550 L1: 0.012523 Grad: 0.090121 Thermal: 0.000305 LR: 3.90e-06\n",
      "Epoch  25 [7300/10697 ( 68.2%)] Loss: 0.021550 L1: 0.012523 Grad: 0.090121 Thermal: 0.000305 LR: 3.90e-06\n",
      "Epoch  25 [7350/10697 ( 68.7%)] Loss: 0.025001 L1: 0.014577 Grad: 0.104032 Thermal: 0.000413 LR: 3.90e-06\n",
      "Epoch  25 [7350/10697 ( 68.7%)] Loss: 0.025001 L1: 0.014577 Grad: 0.104032 Thermal: 0.000413 LR: 3.90e-06\n",
      "Epoch  25 [7400/10697 ( 69.2%)] Loss: 0.026972 L1: 0.016189 Grad: 0.107596 Thermal: 0.000465 LR: 3.90e-06\n",
      "Epoch  25 [7400/10697 ( 69.2%)] Loss: 0.026972 L1: 0.016189 Grad: 0.107596 Thermal: 0.000465 LR: 3.90e-06\n",
      "Epoch  25 [7450/10697 ( 69.6%)] Loss: 0.026586 L1: 0.015529 Grad: 0.110354 Thermal: 0.000432 LR: 3.90e-06\n",
      "Epoch  25 [7450/10697 ( 69.6%)] Loss: 0.026586 L1: 0.015529 Grad: 0.110354 Thermal: 0.000432 LR: 3.90e-06\n",
      "Epoch  25 [7500/10697 ( 70.1%)] Loss: 0.020041 L1: 0.011788 Grad: 0.082384 Thermal: 0.000292 LR: 3.90e-06\n",
      "Epoch  25 [7500/10697 ( 70.1%)] Loss: 0.020041 L1: 0.011788 Grad: 0.082384 Thermal: 0.000292 LR: 3.90e-06\n",
      "Epoch  25 [7550/10697 ( 70.6%)] Loss: 0.027558 L1: 0.016129 Grad: 0.114051 Thermal: 0.000477 LR: 3.90e-06\n",
      "Epoch  25 [7550/10697 ( 70.6%)] Loss: 0.027558 L1: 0.016129 Grad: 0.114051 Thermal: 0.000477 LR: 3.90e-06\n",
      "Epoch  25 [7600/10697 ( 71.0%)] Loss: 0.028787 L1: 0.016791 Grad: 0.119711 Thermal: 0.000503 LR: 3.90e-06\n",
      "Epoch  25 [7600/10697 ( 71.0%)] Loss: 0.028787 L1: 0.016791 Grad: 0.119711 Thermal: 0.000503 LR: 3.90e-06\n",
      "Epoch  25 [7650/10697 ( 71.5%)] Loss: 0.027592 L1: 0.016001 Grad: 0.115679 Thermal: 0.000451 LR: 3.90e-06\n",
      "Epoch  25 [7650/10697 ( 71.5%)] Loss: 0.027592 L1: 0.016001 Grad: 0.115679 Thermal: 0.000451 LR: 3.90e-06\n",
      "Epoch  25 [7700/10697 ( 72.0%)] Loss: 0.026123 L1: 0.015718 Grad: 0.103825 Thermal: 0.000444 LR: 3.90e-06\n",
      "Epoch  25 [7700/10697 ( 72.0%)] Loss: 0.026123 L1: 0.015718 Grad: 0.103825 Thermal: 0.000444 LR: 3.90e-06\n",
      "Epoch  25 [7750/10697 ( 72.5%)] Loss: 0.024734 L1: 0.014275 Grad: 0.104391 Thermal: 0.000402 LR: 3.90e-06\n",
      "Epoch  25 [7750/10697 ( 72.5%)] Loss: 0.024734 L1: 0.014275 Grad: 0.104391 Thermal: 0.000402 LR: 3.90e-06\n",
      "Epoch  25 [7800/10697 ( 72.9%)] Loss: 0.030924 L1: 0.017886 Grad: 0.130092 Thermal: 0.000560 LR: 3.90e-06\n",
      "Epoch  25 [7800/10697 ( 72.9%)] Loss: 0.030924 L1: 0.017886 Grad: 0.130092 Thermal: 0.000560 LR: 3.90e-06\n",
      "Epoch  25 [7850/10697 ( 73.4%)] Loss: 0.024007 L1: 0.014208 Grad: 0.097796 Thermal: 0.000381 LR: 3.90e-06\n",
      "Epoch  25 [7850/10697 ( 73.4%)] Loss: 0.024007 L1: 0.014208 Grad: 0.097796 Thermal: 0.000381 LR: 3.90e-06\n",
      "Epoch  25 [7900/10697 ( 73.9%)] Loss: 0.024343 L1: 0.014396 Grad: 0.099259 Thermal: 0.000419 LR: 3.90e-06\n",
      "Epoch  25 [7900/10697 ( 73.9%)] Loss: 0.024343 L1: 0.014396 Grad: 0.099259 Thermal: 0.000419 LR: 3.90e-06\n",
      "Epoch  25 [7950/10697 ( 74.3%)] Loss: 0.033177 L1: 0.019110 Grad: 0.140338 Thermal: 0.000658 LR: 3.90e-06\n",
      "Epoch  25 [7950/10697 ( 74.3%)] Loss: 0.033177 L1: 0.019110 Grad: 0.140338 Thermal: 0.000658 LR: 3.90e-06\n",
      "Epoch  25 [8000/10697 ( 74.8%)] Loss: 0.024474 L1: 0.014013 Grad: 0.104398 Thermal: 0.000415 LR: 3.90e-06\n",
      "Epoch  25 [8000/10697 ( 74.8%)] Loss: 0.024474 L1: 0.014013 Grad: 0.104398 Thermal: 0.000415 LR: 3.90e-06\n",
      "Epoch  25 [8050/10697 ( 75.3%)] Loss: 0.028595 L1: 0.016757 Grad: 0.118117 Thermal: 0.000528 LR: 3.90e-06\n",
      "Epoch  25 [8050/10697 ( 75.3%)] Loss: 0.028595 L1: 0.016757 Grad: 0.118117 Thermal: 0.000528 LR: 3.90e-06\n",
      "Epoch  25 [8100/10697 ( 75.7%)] Loss: 0.024181 L1: 0.014428 Grad: 0.097344 Thermal: 0.000375 LR: 3.90e-06\n",
      "Epoch  25 [8100/10697 ( 75.7%)] Loss: 0.024181 L1: 0.014428 Grad: 0.097344 Thermal: 0.000375 LR: 3.90e-06\n",
      "Epoch  25 [8150/10697 ( 76.2%)] Loss: 0.026221 L1: 0.015795 Grad: 0.104023 Thermal: 0.000474 LR: 3.90e-06\n",
      "Epoch  25 [8150/10697 ( 76.2%)] Loss: 0.026221 L1: 0.015795 Grad: 0.104023 Thermal: 0.000474 LR: 3.90e-06\n",
      "Epoch  25 [8200/10697 ( 76.7%)] Loss: 0.029446 L1: 0.016929 Grad: 0.124917 Thermal: 0.000495 LR: 3.90e-06\n",
      "Epoch  25 [8200/10697 ( 76.7%)] Loss: 0.029446 L1: 0.016929 Grad: 0.124917 Thermal: 0.000495 LR: 3.90e-06\n",
      "Epoch  25 [8250/10697 ( 77.1%)] Loss: 0.024904 L1: 0.014809 Grad: 0.100749 Thermal: 0.000401 LR: 3.90e-06\n",
      "Epoch  25 [8250/10697 ( 77.1%)] Loss: 0.024904 L1: 0.014809 Grad: 0.100749 Thermal: 0.000401 LR: 3.90e-06\n",
      "Epoch  25 [8300/10697 ( 77.6%)] Loss: 0.029596 L1: 0.016989 Grad: 0.125807 Thermal: 0.000541 LR: 3.90e-06\n",
      "Epoch  25 [8300/10697 ( 77.6%)] Loss: 0.029596 L1: 0.016989 Grad: 0.125807 Thermal: 0.000541 LR: 3.90e-06\n",
      "Epoch  25 [8350/10697 ( 78.1%)] Loss: 0.024267 L1: 0.013952 Grad: 0.102949 Thermal: 0.000410 LR: 3.90e-06\n",
      "Epoch  25 [8350/10697 ( 78.1%)] Loss: 0.024267 L1: 0.013952 Grad: 0.102949 Thermal: 0.000410 LR: 3.90e-06\n",
      "Epoch  25 [8400/10697 ( 78.5%)] Loss: 0.021970 L1: 0.012829 Grad: 0.091229 Thermal: 0.000351 LR: 3.90e-06\n",
      "Epoch  25 [8400/10697 ( 78.5%)] Loss: 0.021970 L1: 0.012829 Grad: 0.091229 Thermal: 0.000351 LR: 3.90e-06\n",
      "Epoch  25 [8450/10697 ( 79.0%)] Loss: 0.025950 L1: 0.015146 Grad: 0.107819 Thermal: 0.000448 LR: 3.90e-06\n",
      "Epoch  25 [8450/10697 ( 79.0%)] Loss: 0.025950 L1: 0.015146 Grad: 0.107819 Thermal: 0.000448 LR: 3.90e-06\n",
      "Epoch  25 [8500/10697 ( 79.5%)] Loss: 0.027197 L1: 0.016127 Grad: 0.110465 Thermal: 0.000470 LR: 3.90e-06\n",
      "Epoch  25 [8500/10697 ( 79.5%)] Loss: 0.027197 L1: 0.016127 Grad: 0.110465 Thermal: 0.000470 LR: 3.90e-06\n",
      "Epoch  25 [8550/10697 ( 79.9%)] Loss: 0.034949 L1: 0.020243 Grad: 0.146678 Thermal: 0.000775 LR: 3.90e-06\n",
      "Epoch  25 [8550/10697 ( 79.9%)] Loss: 0.034949 L1: 0.020243 Grad: 0.146678 Thermal: 0.000775 LR: 3.90e-06\n",
      "Epoch  25 [8600/10697 ( 80.4%)] Loss: 0.023267 L1: 0.013372 Grad: 0.098761 Thermal: 0.000368 LR: 3.90e-06\n",
      "Epoch  25 [8600/10697 ( 80.4%)] Loss: 0.023267 L1: 0.013372 Grad: 0.098761 Thermal: 0.000368 LR: 3.90e-06\n",
      "Epoch  25 [8650/10697 ( 80.9%)] Loss: 0.029070 L1: 0.017291 Grad: 0.117486 Thermal: 0.000607 LR: 3.90e-06\n",
      "Epoch  25 [8650/10697 ( 80.9%)] Loss: 0.029070 L1: 0.017291 Grad: 0.117486 Thermal: 0.000607 LR: 3.90e-06\n",
      "Epoch  25 [8700/10697 ( 81.3%)] Loss: 0.027546 L1: 0.016134 Grad: 0.113890 Thermal: 0.000455 LR: 3.90e-06\n",
      "Epoch  25 [8700/10697 ( 81.3%)] Loss: 0.027546 L1: 0.016134 Grad: 0.113890 Thermal: 0.000455 LR: 3.90e-06\n",
      "Epoch  25 [8750/10697 ( 81.8%)] Loss: 0.028196 L1: 0.016277 Grad: 0.118973 Thermal: 0.000450 LR: 3.90e-06\n",
      "Epoch  25 [8750/10697 ( 81.8%)] Loss: 0.028196 L1: 0.016277 Grad: 0.118973 Thermal: 0.000450 LR: 3.90e-06\n",
      "Epoch  25 [8800/10697 ( 82.3%)] Loss: 0.026940 L1: 0.016007 Grad: 0.109097 Thermal: 0.000456 LR: 3.90e-06\n",
      "Epoch  25 [8800/10697 ( 82.3%)] Loss: 0.026940 L1: 0.016007 Grad: 0.109097 Thermal: 0.000456 LR: 3.90e-06\n",
      "Epoch  25 [8850/10697 ( 82.7%)] Loss: 0.026098 L1: 0.014738 Grad: 0.113372 Thermal: 0.000460 LR: 3.90e-06\n",
      "Epoch  25 [8850/10697 ( 82.7%)] Loss: 0.026098 L1: 0.014738 Grad: 0.113372 Thermal: 0.000460 LR: 3.90e-06\n",
      "Epoch  25 [8900/10697 ( 83.2%)] Loss: 0.021166 L1: 0.012381 Grad: 0.087687 Thermal: 0.000310 LR: 3.90e-06\n",
      "Epoch  25 [8900/10697 ( 83.2%)] Loss: 0.021166 L1: 0.012381 Grad: 0.087687 Thermal: 0.000310 LR: 3.90e-06\n",
      "Epoch  25 [8950/10697 ( 83.7%)] Loss: 0.022638 L1: 0.013055 Grad: 0.095646 Thermal: 0.000361 LR: 3.90e-06\n",
      "Epoch  25 [8950/10697 ( 83.7%)] Loss: 0.022638 L1: 0.013055 Grad: 0.095646 Thermal: 0.000361 LR: 3.90e-06\n",
      "Epoch  25 [9000/10697 ( 84.1%)] Loss: 0.027304 L1: 0.015977 Grad: 0.113029 Thermal: 0.000479 LR: 3.90e-06\n",
      "Epoch  25 [9000/10697 ( 84.1%)] Loss: 0.027304 L1: 0.015977 Grad: 0.113029 Thermal: 0.000479 LR: 3.90e-06\n",
      "Epoch  25 [9050/10697 ( 84.6%)] Loss: 0.023221 L1: 0.013501 Grad: 0.097013 Thermal: 0.000363 LR: 3.90e-06\n",
      "Epoch  25 [9050/10697 ( 84.6%)] Loss: 0.023221 L1: 0.013501 Grad: 0.097013 Thermal: 0.000363 LR: 3.90e-06\n",
      "Epoch  25 [9100/10697 ( 85.1%)] Loss: 0.026122 L1: 0.015782 Grad: 0.103185 Thermal: 0.000428 LR: 3.90e-06\n",
      "Epoch  25 [9100/10697 ( 85.1%)] Loss: 0.026122 L1: 0.015782 Grad: 0.103185 Thermal: 0.000428 LR: 3.90e-06\n",
      "Epoch  25 [9150/10697 ( 85.5%)] Loss: 0.031379 L1: 0.018655 Grad: 0.126921 Thermal: 0.000643 LR: 3.90e-06\n",
      "Epoch  25 [9150/10697 ( 85.5%)] Loss: 0.031379 L1: 0.018655 Grad: 0.126921 Thermal: 0.000643 LR: 3.90e-06\n",
      "Epoch  25 [9200/10697 ( 86.0%)] Loss: 0.024029 L1: 0.014269 Grad: 0.097405 Thermal: 0.000398 LR: 3.90e-06\n",
      "Epoch  25 [9200/10697 ( 86.0%)] Loss: 0.024029 L1: 0.014269 Grad: 0.097405 Thermal: 0.000398 LR: 3.90e-06\n",
      "Epoch  25 [9250/10697 ( 86.5%)] Loss: 0.030205 L1: 0.017546 Grad: 0.126273 Thermal: 0.000619 LR: 3.90e-06\n",
      "Epoch  25 [9250/10697 ( 86.5%)] Loss: 0.030205 L1: 0.017546 Grad: 0.126273 Thermal: 0.000619 LR: 3.90e-06\n",
      "Epoch  25 [9300/10697 ( 86.9%)] Loss: 0.026536 L1: 0.015167 Grad: 0.113459 Thermal: 0.000452 LR: 3.90e-06\n",
      "Epoch  25 [9300/10697 ( 86.9%)] Loss: 0.026536 L1: 0.015167 Grad: 0.113459 Thermal: 0.000452 LR: 3.90e-06\n",
      "Epoch  25 [9350/10697 ( 87.4%)] Loss: 0.022196 L1: 0.012852 Grad: 0.093276 Thermal: 0.000328 LR: 3.90e-06\n",
      "Epoch  25 [9350/10697 ( 87.4%)] Loss: 0.022196 L1: 0.012852 Grad: 0.093276 Thermal: 0.000328 LR: 3.90e-06\n",
      "Epoch  25 [9400/10697 ( 87.9%)] Loss: 0.026060 L1: 0.015162 Grad: 0.108755 Thermal: 0.000458 LR: 3.90e-06\n",
      "Epoch  25 [9400/10697 ( 87.9%)] Loss: 0.026060 L1: 0.015162 Grad: 0.108755 Thermal: 0.000458 LR: 3.90e-06\n",
      "Epoch  25 [9450/10697 ( 88.3%)] Loss: 0.024735 L1: 0.014997 Grad: 0.097170 Thermal: 0.000419 LR: 3.90e-06\n",
      "Epoch  25 [9450/10697 ( 88.3%)] Loss: 0.024735 L1: 0.014997 Grad: 0.097170 Thermal: 0.000419 LR: 3.90e-06\n",
      "Epoch  25 [9500/10697 ( 88.8%)] Loss: 0.023197 L1: 0.013693 Grad: 0.094871 Thermal: 0.000347 LR: 3.90e-06\n",
      "Epoch  25 [9500/10697 ( 88.8%)] Loss: 0.023197 L1: 0.013693 Grad: 0.094871 Thermal: 0.000347 LR: 3.90e-06\n",
      "Epoch  25 [9550/10697 ( 89.3%)] Loss: 0.025751 L1: 0.015074 Grad: 0.106566 Thermal: 0.000422 LR: 3.90e-06\n",
      "Epoch  25 [9550/10697 ( 89.3%)] Loss: 0.025751 L1: 0.015074 Grad: 0.106566 Thermal: 0.000422 LR: 3.90e-06\n",
      "Epoch  25 [9600/10697 ( 89.7%)] Loss: 0.025431 L1: 0.014988 Grad: 0.104230 Thermal: 0.000406 LR: 3.90e-06\n",
      "Epoch  25 [9600/10697 ( 89.7%)] Loss: 0.025431 L1: 0.014988 Grad: 0.104230 Thermal: 0.000406 LR: 3.90e-06\n",
      "Epoch  25 [9650/10697 ( 90.2%)] Loss: 0.027011 L1: 0.016115 Grad: 0.108731 Thermal: 0.000461 LR: 3.90e-06\n",
      "Epoch  25 [9650/10697 ( 90.2%)] Loss: 0.027011 L1: 0.016115 Grad: 0.108731 Thermal: 0.000461 LR: 3.90e-06\n",
      "Epoch  25 [9700/10697 ( 90.7%)] Loss: 0.028485 L1: 0.016907 Grad: 0.115526 Thermal: 0.000502 LR: 3.90e-06\n",
      "Epoch  25 [9700/10697 ( 90.7%)] Loss: 0.028485 L1: 0.016907 Grad: 0.115526 Thermal: 0.000502 LR: 3.90e-06\n",
      "Epoch  25 [9750/10697 ( 91.1%)] Loss: 0.031225 L1: 0.018021 Grad: 0.131704 Thermal: 0.000663 LR: 3.90e-06\n",
      "Epoch  25 [9750/10697 ( 91.1%)] Loss: 0.031225 L1: 0.018021 Grad: 0.131704 Thermal: 0.000663 LR: 3.90e-06\n",
      "Epoch  25 [9800/10697 ( 91.6%)] Loss: 0.025223 L1: 0.014781 Grad: 0.104204 Thermal: 0.000430 LR: 3.90e-06\n",
      "Epoch  25 [9800/10697 ( 91.6%)] Loss: 0.025223 L1: 0.014781 Grad: 0.104204 Thermal: 0.000430 LR: 3.90e-06\n",
      "Epoch  25 [9850/10697 ( 92.1%)] Loss: 0.022779 L1: 0.013171 Grad: 0.095895 Thermal: 0.000360 LR: 3.90e-06\n",
      "Epoch  25 [9850/10697 ( 92.1%)] Loss: 0.022779 L1: 0.013171 Grad: 0.095895 Thermal: 0.000360 LR: 3.90e-06\n",
      "Epoch  25 [9900/10697 ( 92.5%)] Loss: 0.033737 L1: 0.019206 Grad: 0.144916 Thermal: 0.000787 LR: 3.90e-06\n",
      "Epoch  25 [9900/10697 ( 92.5%)] Loss: 0.033737 L1: 0.019206 Grad: 0.144916 Thermal: 0.000787 LR: 3.90e-06\n",
      "Epoch  25 [9950/10697 ( 93.0%)] Loss: 0.027485 L1: 0.016684 Grad: 0.107773 Thermal: 0.000478 LR: 3.90e-06\n",
      "Epoch  25 [9950/10697 ( 93.0%)] Loss: 0.027485 L1: 0.016684 Grad: 0.107773 Thermal: 0.000478 LR: 3.90e-06\n",
      "Epoch  25 [10000/10697 ( 93.5%)] Loss: 0.030293 L1: 0.017735 Grad: 0.125300 Thermal: 0.000565 LR: 3.90e-06\n",
      "Epoch  25 [10000/10697 ( 93.5%)] Loss: 0.030293 L1: 0.017735 Grad: 0.125300 Thermal: 0.000565 LR: 3.90e-06\n",
      "Epoch  25 [10050/10697 ( 94.0%)] Loss: 0.026569 L1: 0.015942 Grad: 0.106042 Thermal: 0.000460 LR: 3.90e-06\n",
      "Epoch  25 [10050/10697 ( 94.0%)] Loss: 0.026569 L1: 0.015942 Grad: 0.106042 Thermal: 0.000460 LR: 3.90e-06\n",
      "Epoch  25 [10100/10697 ( 94.4%)] Loss: 0.023946 L1: 0.013764 Grad: 0.101629 Thermal: 0.000392 LR: 3.90e-06\n",
      "Epoch  25 [10100/10697 ( 94.4%)] Loss: 0.023946 L1: 0.013764 Grad: 0.101629 Thermal: 0.000392 LR: 3.90e-06\n",
      "Epoch  25 [10150/10697 ( 94.9%)] Loss: 0.023291 L1: 0.013102 Grad: 0.101721 Thermal: 0.000335 LR: 3.90e-06\n",
      "Epoch  25 [10150/10697 ( 94.9%)] Loss: 0.023291 L1: 0.013102 Grad: 0.101721 Thermal: 0.000335 LR: 3.90e-06\n",
      "Epoch  25 [10200/10697 ( 95.4%)] Loss: 0.023541 L1: 0.013685 Grad: 0.098368 Thermal: 0.000383 LR: 3.90e-06\n",
      "Epoch  25 [10200/10697 ( 95.4%)] Loss: 0.023541 L1: 0.013685 Grad: 0.098368 Thermal: 0.000383 LR: 3.90e-06\n",
      "Epoch  25 [10250/10697 ( 95.8%)] Loss: 0.024411 L1: 0.014067 Grad: 0.103243 Thermal: 0.000397 LR: 3.90e-06\n",
      "Epoch  25 [10250/10697 ( 95.8%)] Loss: 0.024411 L1: 0.014067 Grad: 0.103243 Thermal: 0.000397 LR: 3.90e-06\n",
      "Epoch  25 [10300/10697 ( 96.3%)] Loss: 0.029713 L1: 0.016612 Grad: 0.130713 Thermal: 0.000593 LR: 3.90e-06\n",
      "Epoch  25 [10300/10697 ( 96.3%)] Loss: 0.029713 L1: 0.016612 Grad: 0.130713 Thermal: 0.000593 LR: 3.90e-06\n",
      "Epoch  25 [10350/10697 ( 96.8%)] Loss: 0.021638 L1: 0.012390 Grad: 0.092310 Thermal: 0.000340 LR: 3.90e-06\n",
      "Epoch  25 [10350/10697 ( 96.8%)] Loss: 0.021638 L1: 0.012390 Grad: 0.092310 Thermal: 0.000340 LR: 3.90e-06\n",
      "Epoch  25 [10400/10697 ( 97.2%)] Loss: 0.023457 L1: 0.013905 Grad: 0.095332 Thermal: 0.000373 LR: 3.90e-06\n",
      "Epoch  25 [10400/10697 ( 97.2%)] Loss: 0.023457 L1: 0.013905 Grad: 0.095332 Thermal: 0.000373 LR: 3.90e-06\n",
      "Epoch  25 [10450/10697 ( 97.7%)] Loss: 0.026221 L1: 0.015914 Grad: 0.102842 Thermal: 0.000461 LR: 3.90e-06\n",
      "Epoch  25 [10450/10697 ( 97.7%)] Loss: 0.026221 L1: 0.015914 Grad: 0.102842 Thermal: 0.000461 LR: 3.90e-06\n",
      "Epoch  25 [10500/10697 ( 98.2%)] Loss: 0.025109 L1: 0.014607 Grad: 0.104820 Thermal: 0.000398 LR: 3.90e-06\n",
      "Epoch  25 [10500/10697 ( 98.2%)] Loss: 0.025109 L1: 0.014607 Grad: 0.104820 Thermal: 0.000398 LR: 3.90e-06\n",
      "Epoch  25 [10550/10697 ( 98.6%)] Loss: 0.022385 L1: 0.013179 Grad: 0.091874 Thermal: 0.000388 LR: 3.90e-06\n",
      "Epoch  25 [10550/10697 ( 98.6%)] Loss: 0.022385 L1: 0.013179 Grad: 0.091874 Thermal: 0.000388 LR: 3.90e-06\n",
      "Epoch  25 [10600/10697 ( 99.1%)] Loss: 0.028992 L1: 0.017057 Grad: 0.119094 Thermal: 0.000499 LR: 3.90e-06\n",
      "Epoch  25 [10600/10697 ( 99.1%)] Loss: 0.028992 L1: 0.017057 Grad: 0.119094 Thermal: 0.000499 LR: 3.90e-06\n",
      "Epoch  25 [10650/10697 ( 99.6%)] Loss: 0.030432 L1: 0.017745 Grad: 0.126597 Thermal: 0.000559 LR: 3.90e-06\n",
      "Epoch  25 [10650/10697 ( 99.6%)] Loss: 0.030432 L1: 0.017745 Grad: 0.126597 Thermal: 0.000559 LR: 3.90e-06\n",
      "üí´ New best model saved! PSNR: 33.95\n",
      "Epoch  25 Summary: Loss=0.026285 (L1:0.0153, Grad:0.1093, Thermal:0.0005) Val_PSNR=33.95dB Best=33.95dB Time=96.5min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "üí´ New best model saved! PSNR: 33.95\n",
      "Epoch  25 Summary: Loss=0.026285 (L1:0.0153, Grad:0.1093, Thermal:0.0005) Val_PSNR=33.95dB Best=33.95dB Time=96.5min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  26 [   0/10697 (  0.0%)] Loss: 0.029235 L1: 0.016867 Grad: 0.123409 Thermal: 0.000527 LR: 3.82e-06\n",
      "Epoch  26 [   0/10697 (  0.0%)] Loss: 0.029235 L1: 0.016867 Grad: 0.123409 Thermal: 0.000527 LR: 3.82e-06\n",
      "Epoch  26 [  50/10697 (  0.5%)] Loss: 0.035747 L1: 0.021304 Grad: 0.143976 Thermal: 0.000917 LR: 3.82e-06\n",
      "Epoch  26 [  50/10697 (  0.5%)] Loss: 0.035747 L1: 0.021304 Grad: 0.143976 Thermal: 0.000917 LR: 3.82e-06\n",
      "Epoch  26 [ 100/10697 (  0.9%)] Loss: 0.023238 L1: 0.013703 Grad: 0.095173 Thermal: 0.000366 LR: 3.82e-06\n",
      "Epoch  26 [ 100/10697 (  0.9%)] Loss: 0.023238 L1: 0.013703 Grad: 0.095173 Thermal: 0.000366 LR: 3.82e-06\n",
      "Epoch  26 [ 150/10697 (  1.4%)] Loss: 0.024311 L1: 0.014345 Grad: 0.099447 Thermal: 0.000422 LR: 3.82e-06\n",
      "Epoch  26 [ 150/10697 (  1.4%)] Loss: 0.024311 L1: 0.014345 Grad: 0.099447 Thermal: 0.000422 LR: 3.82e-06\n",
      "Epoch  26 [ 200/10697 (  1.9%)] Loss: 0.031690 L1: 0.018694 Grad: 0.129642 Thermal: 0.000654 LR: 3.82e-06\n",
      "Epoch  26 [ 200/10697 (  1.9%)] Loss: 0.031690 L1: 0.018694 Grad: 0.129642 Thermal: 0.000654 LR: 3.82e-06\n",
      "Epoch  26 [ 250/10697 (  2.3%)] Loss: 0.030654 L1: 0.017968 Grad: 0.126590 Thermal: 0.000550 LR: 3.82e-06\n",
      "Epoch  26 [ 250/10697 (  2.3%)] Loss: 0.030654 L1: 0.017968 Grad: 0.126590 Thermal: 0.000550 LR: 3.82e-06\n",
      "Epoch  26 [ 300/10697 (  2.8%)] Loss: 0.025400 L1: 0.014724 Grad: 0.106538 Thermal: 0.000444 LR: 3.82e-06\n",
      "Epoch  26 [ 300/10697 (  2.8%)] Loss: 0.025400 L1: 0.014724 Grad: 0.106538 Thermal: 0.000444 LR: 3.82e-06\n",
      "Epoch  26 [ 350/10697 (  3.3%)] Loss: 0.024062 L1: 0.013601 Grad: 0.104430 Thermal: 0.000365 LR: 3.82e-06\n",
      "Epoch  26 [ 350/10697 (  3.3%)] Loss: 0.024062 L1: 0.013601 Grad: 0.104430 Thermal: 0.000365 LR: 3.82e-06\n",
      "Epoch  26 [ 400/10697 (  3.7%)] Loss: 0.027566 L1: 0.016682 Grad: 0.108596 Thermal: 0.000484 LR: 3.82e-06\n",
      "Epoch  26 [ 400/10697 (  3.7%)] Loss: 0.027566 L1: 0.016682 Grad: 0.108596 Thermal: 0.000484 LR: 3.82e-06\n",
      "Epoch  26 [ 450/10697 (  4.2%)] Loss: 0.022368 L1: 0.012905 Grad: 0.094456 Thermal: 0.000347 LR: 3.82e-06\n",
      "Epoch  26 [ 450/10697 (  4.2%)] Loss: 0.022368 L1: 0.012905 Grad: 0.094456 Thermal: 0.000347 LR: 3.82e-06\n",
      "Epoch  26 [ 500/10697 (  4.7%)] Loss: 0.027631 L1: 0.015905 Grad: 0.117028 Thermal: 0.000478 LR: 3.82e-06\n",
      "Epoch  26 [ 500/10697 (  4.7%)] Loss: 0.027631 L1: 0.015905 Grad: 0.117028 Thermal: 0.000478 LR: 3.82e-06\n",
      "Epoch  26 [ 550/10697 (  5.1%)] Loss: 0.025158 L1: 0.014948 Grad: 0.101884 Thermal: 0.000435 LR: 3.82e-06\n",
      "Epoch  26 [ 550/10697 (  5.1%)] Loss: 0.025158 L1: 0.014948 Grad: 0.101884 Thermal: 0.000435 LR: 3.82e-06\n",
      "Epoch  26 [ 600/10697 (  5.6%)] Loss: 0.024935 L1: 0.014627 Grad: 0.102861 Thermal: 0.000434 LR: 3.82e-06\n",
      "Epoch  26 [ 600/10697 (  5.6%)] Loss: 0.024935 L1: 0.014627 Grad: 0.102861 Thermal: 0.000434 LR: 3.82e-06\n",
      "Epoch  26 [ 650/10697 (  6.1%)] Loss: 0.022300 L1: 0.013195 Grad: 0.090878 Thermal: 0.000347 LR: 3.82e-06\n",
      "Epoch  26 [ 650/10697 (  6.1%)] Loss: 0.022300 L1: 0.013195 Grad: 0.090878 Thermal: 0.000347 LR: 3.82e-06\n",
      "Epoch  26 [ 700/10697 (  6.5%)] Loss: 0.019168 L1: 0.011261 Grad: 0.078922 Thermal: 0.000289 LR: 3.82e-06\n",
      "Epoch  26 [ 700/10697 (  6.5%)] Loss: 0.019168 L1: 0.011261 Grad: 0.078922 Thermal: 0.000289 LR: 3.82e-06\n",
      "Epoch  26 [ 750/10697 (  7.0%)] Loss: 0.026794 L1: 0.015636 Grad: 0.111352 Thermal: 0.000455 LR: 3.82e-06\n",
      "Epoch  26 [ 750/10697 (  7.0%)] Loss: 0.026794 L1: 0.015636 Grad: 0.111352 Thermal: 0.000455 LR: 3.82e-06\n",
      "Epoch  26 [ 800/10697 (  7.5%)] Loss: 0.021639 L1: 0.012451 Grad: 0.091720 Thermal: 0.000323 LR: 3.82e-06\n",
      "Epoch  26 [ 800/10697 (  7.5%)] Loss: 0.021639 L1: 0.012451 Grad: 0.091720 Thermal: 0.000323 LR: 3.82e-06\n",
      "Epoch  26 [ 850/10697 (  7.9%)] Loss: 0.029098 L1: 0.016446 Grad: 0.126264 Thermal: 0.000495 LR: 3.82e-06\n",
      "Epoch  26 [ 850/10697 (  7.9%)] Loss: 0.029098 L1: 0.016446 Grad: 0.126264 Thermal: 0.000495 LR: 3.82e-06\n",
      "Epoch  26 [ 900/10697 (  8.4%)] Loss: 0.030359 L1: 0.017804 Grad: 0.125256 Thermal: 0.000599 LR: 3.82e-06\n",
      "Epoch  26 [ 900/10697 (  8.4%)] Loss: 0.030359 L1: 0.017804 Grad: 0.125256 Thermal: 0.000599 LR: 3.82e-06\n",
      "Epoch  26 [ 950/10697 (  8.9%)] Loss: 0.027614 L1: 0.016073 Grad: 0.115149 Thermal: 0.000530 LR: 3.82e-06\n",
      "Epoch  26 [ 950/10697 (  8.9%)] Loss: 0.027614 L1: 0.016073 Grad: 0.115149 Thermal: 0.000530 LR: 3.82e-06\n",
      "Epoch  26 [1000/10697 (  9.3%)] Loss: 0.029760 L1: 0.017112 Grad: 0.126186 Thermal: 0.000584 LR: 3.82e-06\n",
      "Epoch  26 [1000/10697 (  9.3%)] Loss: 0.029760 L1: 0.017112 Grad: 0.126186 Thermal: 0.000584 LR: 3.82e-06\n",
      "Epoch  26 [1050/10697 (  9.8%)] Loss: 0.021153 L1: 0.012153 Grad: 0.089836 Thermal: 0.000327 LR: 3.82e-06\n",
      "Epoch  26 [1050/10697 (  9.8%)] Loss: 0.021153 L1: 0.012153 Grad: 0.089836 Thermal: 0.000327 LR: 3.82e-06\n",
      "Epoch  26 [1100/10697 ( 10.3%)] Loss: 0.028939 L1: 0.016498 Grad: 0.124168 Thermal: 0.000493 LR: 3.82e-06\n",
      "Epoch  26 [1100/10697 ( 10.3%)] Loss: 0.028939 L1: 0.016498 Grad: 0.124168 Thermal: 0.000493 LR: 3.82e-06\n",
      "Epoch  26 [1150/10697 ( 10.8%)] Loss: 0.020573 L1: 0.011803 Grad: 0.087559 Thermal: 0.000302 LR: 3.82e-06\n",
      "Epoch  26 [1150/10697 ( 10.8%)] Loss: 0.020573 L1: 0.011803 Grad: 0.087559 Thermal: 0.000302 LR: 3.82e-06\n",
      "Epoch  26 [1200/10697 ( 11.2%)] Loss: 0.023128 L1: 0.013292 Grad: 0.098193 Thermal: 0.000334 LR: 3.82e-06\n",
      "Epoch  26 [1200/10697 ( 11.2%)] Loss: 0.023128 L1: 0.013292 Grad: 0.098193 Thermal: 0.000334 LR: 3.82e-06\n",
      "Epoch  26 [1250/10697 ( 11.7%)] Loss: 0.034225 L1: 0.019384 Grad: 0.148039 Thermal: 0.000734 LR: 3.82e-06\n",
      "Epoch  26 [1250/10697 ( 11.7%)] Loss: 0.034225 L1: 0.019384 Grad: 0.148039 Thermal: 0.000734 LR: 3.82e-06\n",
      "Epoch  26 [1300/10697 ( 12.2%)] Loss: 0.021440 L1: 0.012150 Grad: 0.092726 Thermal: 0.000362 LR: 3.82e-06\n",
      "Epoch  26 [1300/10697 ( 12.2%)] Loss: 0.021440 L1: 0.012150 Grad: 0.092726 Thermal: 0.000362 LR: 3.82e-06\n",
      "Epoch  26 [1350/10697 ( 12.6%)] Loss: 0.028347 L1: 0.016661 Grad: 0.116578 Thermal: 0.000553 LR: 3.82e-06\n",
      "Epoch  26 [1350/10697 ( 12.6%)] Loss: 0.028347 L1: 0.016661 Grad: 0.116578 Thermal: 0.000553 LR: 3.82e-06\n",
      "Epoch  26 [1400/10697 ( 13.1%)] Loss: 0.028777 L1: 0.017007 Grad: 0.117411 Thermal: 0.000570 LR: 3.82e-06\n",
      "Epoch  26 [1400/10697 ( 13.1%)] Loss: 0.028777 L1: 0.017007 Grad: 0.117411 Thermal: 0.000570 LR: 3.82e-06\n",
      "Epoch  26 [1450/10697 ( 13.6%)] Loss: 0.027308 L1: 0.015624 Grad: 0.116621 Thermal: 0.000437 LR: 3.82e-06\n",
      "Epoch  26 [1450/10697 ( 13.6%)] Loss: 0.027308 L1: 0.015624 Grad: 0.116621 Thermal: 0.000437 LR: 3.82e-06\n",
      "Epoch  26 [1500/10697 ( 14.0%)] Loss: 0.026123 L1: 0.014991 Grad: 0.111111 Thermal: 0.000405 LR: 3.82e-06\n",
      "Epoch  26 [1500/10697 ( 14.0%)] Loss: 0.026123 L1: 0.014991 Grad: 0.111111 Thermal: 0.000405 LR: 3.82e-06\n",
      "Epoch  26 [1550/10697 ( 14.5%)] Loss: 0.026126 L1: 0.015469 Grad: 0.106366 Thermal: 0.000424 LR: 3.82e-06\n",
      "Epoch  26 [1550/10697 ( 14.5%)] Loss: 0.026126 L1: 0.015469 Grad: 0.106366 Thermal: 0.000424 LR: 3.82e-06\n",
      "Epoch  26 [1600/10697 ( 15.0%)] Loss: 0.028032 L1: 0.016518 Grad: 0.114877 Thermal: 0.000516 LR: 3.82e-06\n",
      "Epoch  26 [1600/10697 ( 15.0%)] Loss: 0.028032 L1: 0.016518 Grad: 0.114877 Thermal: 0.000516 LR: 3.82e-06\n",
      "Epoch  26 [1650/10697 ( 15.4%)] Loss: 0.022623 L1: 0.013005 Grad: 0.096025 Thermal: 0.000328 LR: 3.82e-06\n",
      "Epoch  26 [1650/10697 ( 15.4%)] Loss: 0.022623 L1: 0.013005 Grad: 0.096025 Thermal: 0.000328 LR: 3.82e-06\n",
      "Epoch  26 [1700/10697 ( 15.9%)] Loss: 0.025110 L1: 0.014842 Grad: 0.102472 Thermal: 0.000412 LR: 3.82e-06\n",
      "Epoch  26 [1700/10697 ( 15.9%)] Loss: 0.025110 L1: 0.014842 Grad: 0.102472 Thermal: 0.000412 LR: 3.82e-06\n",
      "Epoch  26 [1750/10697 ( 16.4%)] Loss: 0.027972 L1: 0.016673 Grad: 0.112737 Thermal: 0.000505 LR: 3.82e-06\n",
      "Epoch  26 [1750/10697 ( 16.4%)] Loss: 0.027972 L1: 0.016673 Grad: 0.112737 Thermal: 0.000505 LR: 3.82e-06\n",
      "Epoch  26 [1800/10697 ( 16.8%)] Loss: 0.021223 L1: 0.011933 Grad: 0.092737 Thermal: 0.000317 LR: 3.82e-06\n",
      "Epoch  26 [1800/10697 ( 16.8%)] Loss: 0.021223 L1: 0.011933 Grad: 0.092737 Thermal: 0.000317 LR: 3.82e-06\n",
      "Epoch  26 [1850/10697 ( 17.3%)] Loss: 0.026215 L1: 0.015290 Grad: 0.109000 Thermal: 0.000513 LR: 3.82e-06\n",
      "Epoch  26 [1850/10697 ( 17.3%)] Loss: 0.026215 L1: 0.015290 Grad: 0.109000 Thermal: 0.000513 LR: 3.82e-06\n",
      "Epoch  26 [1900/10697 ( 17.8%)] Loss: 0.026589 L1: 0.015479 Grad: 0.110873 Thermal: 0.000444 LR: 3.82e-06\n",
      "Epoch  26 [1900/10697 ( 17.8%)] Loss: 0.026589 L1: 0.015479 Grad: 0.110873 Thermal: 0.000444 LR: 3.82e-06\n",
      "Epoch  26 [1950/10697 ( 18.2%)] Loss: 0.027917 L1: 0.015877 Grad: 0.120162 Thermal: 0.000475 LR: 3.82e-06\n",
      "Epoch  26 [1950/10697 ( 18.2%)] Loss: 0.027917 L1: 0.015877 Grad: 0.120162 Thermal: 0.000475 LR: 3.82e-06\n",
      "Epoch  26 [2000/10697 ( 18.7%)] Loss: 0.027804 L1: 0.016421 Grad: 0.113558 Thermal: 0.000540 LR: 3.82e-06\n",
      "Epoch  26 [2000/10697 ( 18.7%)] Loss: 0.027804 L1: 0.016421 Grad: 0.113558 Thermal: 0.000540 LR: 3.82e-06\n",
      "Epoch  26 [2050/10697 ( 19.2%)] Loss: 0.025404 L1: 0.014848 Grad: 0.105343 Thermal: 0.000433 LR: 3.82e-06\n",
      "Epoch  26 [2050/10697 ( 19.2%)] Loss: 0.025404 L1: 0.014848 Grad: 0.105343 Thermal: 0.000433 LR: 3.82e-06\n",
      "Epoch  26 [2100/10697 ( 19.6%)] Loss: 0.029222 L1: 0.017592 Grad: 0.116024 Thermal: 0.000539 LR: 3.82e-06\n",
      "Epoch  26 [2100/10697 ( 19.6%)] Loss: 0.029222 L1: 0.017592 Grad: 0.116024 Thermal: 0.000539 LR: 3.82e-06\n",
      "Epoch  26 [2150/10697 ( 20.1%)] Loss: 0.026976 L1: 0.015790 Grad: 0.111640 Thermal: 0.000452 LR: 3.82e-06\n",
      "Epoch  26 [2150/10697 ( 20.1%)] Loss: 0.026976 L1: 0.015790 Grad: 0.111640 Thermal: 0.000452 LR: 3.82e-06\n",
      "Epoch  26 [2200/10697 ( 20.6%)] Loss: 0.031515 L1: 0.018438 Grad: 0.130445 Thermal: 0.000657 LR: 3.82e-06\n",
      "Epoch  26 [2200/10697 ( 20.6%)] Loss: 0.031515 L1: 0.018438 Grad: 0.130445 Thermal: 0.000657 LR: 3.82e-06\n",
      "Epoch  26 [2250/10697 ( 21.0%)] Loss: 0.023058 L1: 0.013390 Grad: 0.096504 Thermal: 0.000355 LR: 3.82e-06\n",
      "Epoch  26 [2250/10697 ( 21.0%)] Loss: 0.023058 L1: 0.013390 Grad: 0.096504 Thermal: 0.000355 LR: 3.82e-06\n",
      "Epoch  26 [2300/10697 ( 21.5%)] Loss: 0.027502 L1: 0.015740 Grad: 0.117362 Thermal: 0.000506 LR: 3.82e-06\n",
      "Epoch  26 [2300/10697 ( 21.5%)] Loss: 0.027502 L1: 0.015740 Grad: 0.117362 Thermal: 0.000506 LR: 3.82e-06\n",
      "Epoch  26 [2350/10697 ( 22.0%)] Loss: 0.025114 L1: 0.014546 Grad: 0.105486 Thermal: 0.000386 LR: 3.82e-06\n",
      "Epoch  26 [2350/10697 ( 22.0%)] Loss: 0.025114 L1: 0.014546 Grad: 0.105486 Thermal: 0.000386 LR: 3.82e-06\n",
      "Epoch  26 [2400/10697 ( 22.4%)] Loss: 0.020769 L1: 0.012029 Grad: 0.087242 Thermal: 0.000312 LR: 3.82e-06\n",
      "Epoch  26 [2400/10697 ( 22.4%)] Loss: 0.020769 L1: 0.012029 Grad: 0.087242 Thermal: 0.000312 LR: 3.82e-06\n",
      "Epoch  26 [2450/10697 ( 22.9%)] Loss: 0.021519 L1: 0.012606 Grad: 0.088964 Thermal: 0.000320 LR: 3.82e-06\n",
      "Epoch  26 [2450/10697 ( 22.9%)] Loss: 0.021519 L1: 0.012606 Grad: 0.088964 Thermal: 0.000320 LR: 3.82e-06\n",
      "Epoch  26 [2500/10697 ( 23.4%)] Loss: 0.023213 L1: 0.013691 Grad: 0.095036 Thermal: 0.000365 LR: 3.82e-06\n",
      "Epoch  26 [2500/10697 ( 23.4%)] Loss: 0.023213 L1: 0.013691 Grad: 0.095036 Thermal: 0.000365 LR: 3.82e-06\n",
      "Epoch  26 [2550/10697 ( 23.8%)] Loss: 0.028267 L1: 0.016476 Grad: 0.117676 Thermal: 0.000474 LR: 3.82e-06\n",
      "Epoch  26 [2550/10697 ( 23.8%)] Loss: 0.028267 L1: 0.016476 Grad: 0.117676 Thermal: 0.000474 LR: 3.82e-06\n",
      "Epoch  26 [2600/10697 ( 24.3%)] Loss: 0.025203 L1: 0.014461 Grad: 0.107232 Thermal: 0.000370 LR: 3.82e-06\n",
      "Epoch  26 [2600/10697 ( 24.3%)] Loss: 0.025203 L1: 0.014461 Grad: 0.107232 Thermal: 0.000370 LR: 3.82e-06\n",
      "Epoch  26 [2650/10697 ( 24.8%)] Loss: 0.027815 L1: 0.016289 Grad: 0.115018 Thermal: 0.000469 LR: 3.82e-06\n",
      "Epoch  26 [2650/10697 ( 24.8%)] Loss: 0.027815 L1: 0.016289 Grad: 0.115018 Thermal: 0.000469 LR: 3.82e-06\n",
      "Epoch  26 [2700/10697 ( 25.2%)] Loss: 0.024055 L1: 0.013864 Grad: 0.101671 Thermal: 0.000483 LR: 3.82e-06\n",
      "Epoch  26 [2700/10697 ( 25.2%)] Loss: 0.024055 L1: 0.013864 Grad: 0.101671 Thermal: 0.000483 LR: 3.82e-06\n",
      "Epoch  26 [2750/10697 ( 25.7%)] Loss: 0.018145 L1: 0.010232 Grad: 0.078990 Thermal: 0.000274 LR: 3.82e-06\n",
      "Epoch  26 [2750/10697 ( 25.7%)] Loss: 0.018145 L1: 0.010232 Grad: 0.078990 Thermal: 0.000274 LR: 3.82e-06\n",
      "Epoch  26 [2800/10697 ( 26.2%)] Loss: 0.026806 L1: 0.016070 Grad: 0.107133 Thermal: 0.000464 LR: 3.82e-06\n",
      "Epoch  26 [2800/10697 ( 26.2%)] Loss: 0.026806 L1: 0.016070 Grad: 0.107133 Thermal: 0.000464 LR: 3.82e-06\n",
      "Epoch  26 [2850/10697 ( 26.6%)] Loss: 0.033556 L1: 0.019602 Grad: 0.139171 Thermal: 0.000739 LR: 3.82e-06\n",
      "Epoch  26 [2850/10697 ( 26.6%)] Loss: 0.033556 L1: 0.019602 Grad: 0.139171 Thermal: 0.000739 LR: 3.82e-06\n",
      "Epoch  26 [2900/10697 ( 27.1%)] Loss: 0.024586 L1: 0.014292 Grad: 0.102737 Thermal: 0.000401 LR: 3.82e-06\n",
      "Epoch  26 [2900/10697 ( 27.1%)] Loss: 0.024586 L1: 0.014292 Grad: 0.102737 Thermal: 0.000401 LR: 3.82e-06\n",
      "Epoch  26 [2950/10697 ( 27.6%)] Loss: 0.024969 L1: 0.015035 Grad: 0.099136 Thermal: 0.000407 LR: 3.82e-06\n",
      "Epoch  26 [2950/10697 ( 27.6%)] Loss: 0.024969 L1: 0.015035 Grad: 0.099136 Thermal: 0.000407 LR: 3.82e-06\n",
      "Epoch  26 [3000/10697 ( 28.0%)] Loss: 0.027837 L1: 0.016306 Grad: 0.115057 Thermal: 0.000501 LR: 3.82e-06\n",
      "Epoch  26 [3000/10697 ( 28.0%)] Loss: 0.027837 L1: 0.016306 Grad: 0.115057 Thermal: 0.000501 LR: 3.82e-06\n",
      "Epoch  26 [3050/10697 ( 28.5%)] Loss: 0.034317 L1: 0.019791 Grad: 0.144898 Thermal: 0.000732 LR: 3.82e-06\n",
      "Epoch  26 [3050/10697 ( 28.5%)] Loss: 0.034317 L1: 0.019791 Grad: 0.144898 Thermal: 0.000732 LR: 3.82e-06\n",
      "Epoch  26 [3100/10697 ( 29.0%)] Loss: 0.021384 L1: 0.012255 Grad: 0.091131 Thermal: 0.000307 LR: 3.82e-06\n",
      "Epoch  26 [3100/10697 ( 29.0%)] Loss: 0.021384 L1: 0.012255 Grad: 0.091131 Thermal: 0.000307 LR: 3.82e-06\n",
      "Epoch  26 [3150/10697 ( 29.4%)] Loss: 0.021146 L1: 0.012441 Grad: 0.086900 Thermal: 0.000317 LR: 3.82e-06\n",
      "Epoch  26 [3150/10697 ( 29.4%)] Loss: 0.021146 L1: 0.012441 Grad: 0.086900 Thermal: 0.000317 LR: 3.82e-06\n",
      "Epoch  26 [3200/10697 ( 29.9%)] Loss: 0.026434 L1: 0.015585 Grad: 0.108254 Thermal: 0.000468 LR: 3.82e-06\n",
      "Epoch  26 [3200/10697 ( 29.9%)] Loss: 0.026434 L1: 0.015585 Grad: 0.108254 Thermal: 0.000468 LR: 3.82e-06\n",
      "Epoch  26 [3250/10697 ( 30.4%)] Loss: 0.030694 L1: 0.018625 Grad: 0.120341 Thermal: 0.000703 LR: 3.82e-06\n",
      "Epoch  26 [3250/10697 ( 30.4%)] Loss: 0.030694 L1: 0.018625 Grad: 0.120341 Thermal: 0.000703 LR: 3.82e-06\n",
      "Epoch  26 [3300/10697 ( 30.8%)] Loss: 0.026025 L1: 0.015466 Grad: 0.105345 Thermal: 0.000486 LR: 3.82e-06\n",
      "Epoch  26 [3300/10697 ( 30.8%)] Loss: 0.026025 L1: 0.015466 Grad: 0.105345 Thermal: 0.000486 LR: 3.82e-06\n",
      "Epoch  26 [3350/10697 ( 31.3%)] Loss: 0.033175 L1: 0.018967 Grad: 0.141766 Thermal: 0.000629 LR: 3.82e-06\n",
      "Epoch  26 [3350/10697 ( 31.3%)] Loss: 0.033175 L1: 0.018967 Grad: 0.141766 Thermal: 0.000629 LR: 3.82e-06\n",
      "Epoch  26 [3400/10697 ( 31.8%)] Loss: 0.024136 L1: 0.013679 Grad: 0.104393 Thermal: 0.000354 LR: 3.82e-06\n",
      "Epoch  26 [3400/10697 ( 31.8%)] Loss: 0.024136 L1: 0.013679 Grad: 0.104393 Thermal: 0.000354 LR: 3.82e-06\n",
      "Epoch  26 [3450/10697 ( 32.3%)] Loss: 0.022489 L1: 0.012934 Grad: 0.095396 Thermal: 0.000326 LR: 3.82e-06\n",
      "Epoch  26 [3450/10697 ( 32.3%)] Loss: 0.022489 L1: 0.012934 Grad: 0.095396 Thermal: 0.000326 LR: 3.82e-06\n",
      "Epoch  26 [3500/10697 ( 32.7%)] Loss: 0.027879 L1: 0.016290 Grad: 0.115636 Thermal: 0.000515 LR: 3.82e-06\n",
      "Epoch  26 [3500/10697 ( 32.7%)] Loss: 0.027879 L1: 0.016290 Grad: 0.115636 Thermal: 0.000515 LR: 3.82e-06\n",
      "Epoch  26 [3550/10697 ( 33.2%)] Loss: 0.033739 L1: 0.019272 Grad: 0.144310 Thermal: 0.000720 LR: 3.82e-06\n",
      "Epoch  26 [3550/10697 ( 33.2%)] Loss: 0.033739 L1: 0.019272 Grad: 0.144310 Thermal: 0.000720 LR: 3.82e-06\n",
      "Epoch  26 [3600/10697 ( 33.7%)] Loss: 0.024893 L1: 0.014788 Grad: 0.100850 Thermal: 0.000391 LR: 3.82e-06\n",
      "Epoch  26 [3600/10697 ( 33.7%)] Loss: 0.024893 L1: 0.014788 Grad: 0.100850 Thermal: 0.000391 LR: 3.82e-06\n",
      "Epoch  26 [3650/10697 ( 34.1%)] Loss: 0.027601 L1: 0.015876 Grad: 0.116986 Thermal: 0.000522 LR: 3.82e-06\n",
      "Epoch  26 [3650/10697 ( 34.1%)] Loss: 0.027601 L1: 0.015876 Grad: 0.116986 Thermal: 0.000522 LR: 3.82e-06\n",
      "Epoch  26 [3700/10697 ( 34.6%)] Loss: 0.031403 L1: 0.017912 Grad: 0.134610 Thermal: 0.000589 LR: 3.82e-06\n",
      "Epoch  26 [3700/10697 ( 34.6%)] Loss: 0.031403 L1: 0.017912 Grad: 0.134610 Thermal: 0.000589 LR: 3.82e-06\n",
      "Epoch  26 [3750/10697 ( 35.1%)] Loss: 0.025310 L1: 0.014878 Grad: 0.104105 Thermal: 0.000431 LR: 3.82e-06\n",
      "Epoch  26 [3750/10697 ( 35.1%)] Loss: 0.025310 L1: 0.014878 Grad: 0.104105 Thermal: 0.000431 LR: 3.82e-06\n",
      "Epoch  26 [3800/10697 ( 35.5%)] Loss: 0.032117 L1: 0.018656 Grad: 0.134276 Thermal: 0.000677 LR: 3.82e-06\n",
      "Epoch  26 [3800/10697 ( 35.5%)] Loss: 0.032117 L1: 0.018656 Grad: 0.134276 Thermal: 0.000677 LR: 3.82e-06\n",
      "Epoch  26 [3850/10697 ( 36.0%)] Loss: 0.026902 L1: 0.015602 Grad: 0.112773 Thermal: 0.000457 LR: 3.82e-06\n",
      "Epoch  26 [3850/10697 ( 36.0%)] Loss: 0.026902 L1: 0.015602 Grad: 0.112773 Thermal: 0.000457 LR: 3.82e-06\n",
      "Epoch  26 [3900/10697 ( 36.5%)] Loss: 0.033644 L1: 0.019944 Grad: 0.136611 Thermal: 0.000788 LR: 3.82e-06\n",
      "Epoch  26 [3900/10697 ( 36.5%)] Loss: 0.033644 L1: 0.019944 Grad: 0.136611 Thermal: 0.000788 LR: 3.82e-06\n",
      "Epoch  26 [3950/10697 ( 36.9%)] Loss: 0.020261 L1: 0.011502 Grad: 0.087456 Thermal: 0.000272 LR: 3.82e-06\n",
      "Epoch  26 [3950/10697 ( 36.9%)] Loss: 0.020261 L1: 0.011502 Grad: 0.087456 Thermal: 0.000272 LR: 3.82e-06\n",
      "Epoch  26 [4000/10697 ( 37.4%)] Loss: 0.028316 L1: 0.016523 Grad: 0.117697 Thermal: 0.000477 LR: 3.82e-06\n",
      "Epoch  26 [4000/10697 ( 37.4%)] Loss: 0.028316 L1: 0.016523 Grad: 0.117697 Thermal: 0.000477 LR: 3.82e-06\n",
      "Epoch  26 [4050/10697 ( 37.9%)] Loss: 0.026576 L1: 0.015925 Grad: 0.106279 Thermal: 0.000468 LR: 3.82e-06\n",
      "Epoch  26 [4050/10697 ( 37.9%)] Loss: 0.026576 L1: 0.015925 Grad: 0.106279 Thermal: 0.000468 LR: 3.82e-06\n",
      "Epoch  26 [4100/10697 ( 38.3%)] Loss: 0.030997 L1: 0.017671 Grad: 0.132908 Thermal: 0.000714 LR: 3.82e-06\n",
      "Epoch  26 [4100/10697 ( 38.3%)] Loss: 0.030997 L1: 0.017671 Grad: 0.132908 Thermal: 0.000714 LR: 3.82e-06\n",
      "Epoch  26 [4150/10697 ( 38.8%)] Loss: 0.028173 L1: 0.016656 Grad: 0.114937 Thermal: 0.000476 LR: 3.82e-06\n",
      "Epoch  26 [4150/10697 ( 38.8%)] Loss: 0.028173 L1: 0.016656 Grad: 0.114937 Thermal: 0.000476 LR: 3.82e-06\n",
      "Epoch  26 [4200/10697 ( 39.3%)] Loss: 0.027648 L1: 0.016321 Grad: 0.113015 Thermal: 0.000512 LR: 3.82e-06\n",
      "Epoch  26 [4200/10697 ( 39.3%)] Loss: 0.027648 L1: 0.016321 Grad: 0.113015 Thermal: 0.000512 LR: 3.82e-06\n",
      "Epoch  26 [4250/10697 ( 39.7%)] Loss: 0.027168 L1: 0.015970 Grad: 0.111751 Thermal: 0.000467 LR: 3.82e-06\n",
      "Epoch  26 [4250/10697 ( 39.7%)] Loss: 0.027168 L1: 0.015970 Grad: 0.111751 Thermal: 0.000467 LR: 3.82e-06\n",
      "Epoch  26 [4300/10697 ( 40.2%)] Loss: 0.030826 L1: 0.017842 Grad: 0.129529 Thermal: 0.000618 LR: 3.82e-06\n",
      "Epoch  26 [4300/10697 ( 40.2%)] Loss: 0.030826 L1: 0.017842 Grad: 0.129529 Thermal: 0.000618 LR: 3.82e-06\n",
      "Epoch  26 [4350/10697 ( 40.7%)] Loss: 0.020470 L1: 0.011879 Grad: 0.085759 Thermal: 0.000302 LR: 3.82e-06\n",
      "Epoch  26 [4350/10697 ( 40.7%)] Loss: 0.020470 L1: 0.011879 Grad: 0.085759 Thermal: 0.000302 LR: 3.82e-06\n",
      "Epoch  26 [4400/10697 ( 41.1%)] Loss: 0.022917 L1: 0.013160 Grad: 0.097380 Thermal: 0.000386 LR: 3.82e-06\n",
      "Epoch  26 [4400/10697 ( 41.1%)] Loss: 0.022917 L1: 0.013160 Grad: 0.097380 Thermal: 0.000386 LR: 3.82e-06\n",
      "Epoch  26 [4450/10697 ( 41.6%)] Loss: 0.031268 L1: 0.018266 Grad: 0.129716 Thermal: 0.000611 LR: 3.82e-06\n",
      "Epoch  26 [4450/10697 ( 41.6%)] Loss: 0.031268 L1: 0.018266 Grad: 0.129716 Thermal: 0.000611 LR: 3.82e-06\n",
      "Epoch  26 [4500/10697 ( 42.1%)] Loss: 0.027234 L1: 0.015565 Grad: 0.116465 Thermal: 0.000462 LR: 3.82e-06\n",
      "Epoch  26 [4500/10697 ( 42.1%)] Loss: 0.027234 L1: 0.015565 Grad: 0.116465 Thermal: 0.000462 LR: 3.82e-06\n",
      "Epoch  26 [4550/10697 ( 42.5%)] Loss: 0.029994 L1: 0.017487 Grad: 0.124789 Thermal: 0.000555 LR: 3.82e-06\n",
      "Epoch  26 [4550/10697 ( 42.5%)] Loss: 0.029994 L1: 0.017487 Grad: 0.124789 Thermal: 0.000555 LR: 3.82e-06\n",
      "Epoch  26 [4600/10697 ( 43.0%)] Loss: 0.029264 L1: 0.017170 Grad: 0.120656 Thermal: 0.000568 LR: 3.82e-06\n",
      "Epoch  26 [4600/10697 ( 43.0%)] Loss: 0.029264 L1: 0.017170 Grad: 0.120656 Thermal: 0.000568 LR: 3.82e-06\n",
      "Epoch  26 [4650/10697 ( 43.5%)] Loss: 0.028264 L1: 0.016577 Grad: 0.116618 Thermal: 0.000503 LR: 3.82e-06\n",
      "Epoch  26 [4650/10697 ( 43.5%)] Loss: 0.028264 L1: 0.016577 Grad: 0.116618 Thermal: 0.000503 LR: 3.82e-06\n",
      "Epoch  26 [4700/10697 ( 43.9%)] Loss: 0.025012 L1: 0.014522 Grad: 0.104662 Thermal: 0.000465 LR: 3.82e-06\n",
      "Epoch  26 [4700/10697 ( 43.9%)] Loss: 0.025012 L1: 0.014522 Grad: 0.104662 Thermal: 0.000465 LR: 3.82e-06\n",
      "Epoch  26 [4750/10697 ( 44.4%)] Loss: 0.023467 L1: 0.013654 Grad: 0.097934 Thermal: 0.000388 LR: 3.82e-06\n",
      "Epoch  26 [4750/10697 ( 44.4%)] Loss: 0.023467 L1: 0.013654 Grad: 0.097934 Thermal: 0.000388 LR: 3.82e-06\n",
      "Epoch  26 [4800/10697 ( 44.9%)] Loss: 0.031485 L1: 0.018357 Grad: 0.130973 Thermal: 0.000625 LR: 3.82e-06\n",
      "Epoch  26 [4800/10697 ( 44.9%)] Loss: 0.031485 L1: 0.018357 Grad: 0.130973 Thermal: 0.000625 LR: 3.82e-06\n",
      "Epoch  26 [4850/10697 ( 45.3%)] Loss: 0.026519 L1: 0.015254 Grad: 0.112403 Thermal: 0.000501 LR: 3.82e-06\n",
      "Epoch  26 [4850/10697 ( 45.3%)] Loss: 0.026519 L1: 0.015254 Grad: 0.112403 Thermal: 0.000501 LR: 3.82e-06\n",
      "Epoch  26 [4900/10697 ( 45.8%)] Loss: 0.024082 L1: 0.014037 Grad: 0.100239 Thermal: 0.000415 LR: 3.82e-06\n",
      "Epoch  26 [4900/10697 ( 45.8%)] Loss: 0.024082 L1: 0.014037 Grad: 0.100239 Thermal: 0.000415 LR: 3.82e-06\n",
      "Epoch  26 [4950/10697 ( 46.3%)] Loss: 0.020212 L1: 0.011688 Grad: 0.085096 Thermal: 0.000303 LR: 3.82e-06\n",
      "Epoch  26 [4950/10697 ( 46.3%)] Loss: 0.020212 L1: 0.011688 Grad: 0.085096 Thermal: 0.000303 LR: 3.82e-06\n",
      "Epoch  26 [5000/10697 ( 46.7%)] Loss: 0.029589 L1: 0.017272 Grad: 0.122894 Thermal: 0.000567 LR: 3.82e-06\n",
      "Epoch  26 [5000/10697 ( 46.7%)] Loss: 0.029589 L1: 0.017272 Grad: 0.122894 Thermal: 0.000567 LR: 3.82e-06\n",
      "Epoch  26 [5050/10697 ( 47.2%)] Loss: 0.023415 L1: 0.013786 Grad: 0.096106 Thermal: 0.000373 LR: 3.82e-06\n",
      "Epoch  26 [5050/10697 ( 47.2%)] Loss: 0.023415 L1: 0.013786 Grad: 0.096106 Thermal: 0.000373 LR: 3.82e-06\n",
      "Epoch  26 [5100/10697 ( 47.7%)] Loss: 0.022075 L1: 0.012499 Grad: 0.095562 Thermal: 0.000397 LR: 3.82e-06\n",
      "Epoch  26 [5100/10697 ( 47.7%)] Loss: 0.022075 L1: 0.012499 Grad: 0.095562 Thermal: 0.000397 LR: 3.82e-06\n",
      "Epoch  26 [5150/10697 ( 48.1%)] Loss: 0.021771 L1: 0.012297 Grad: 0.094591 Thermal: 0.000294 LR: 3.82e-06\n",
      "Epoch  26 [5150/10697 ( 48.1%)] Loss: 0.021771 L1: 0.012297 Grad: 0.094591 Thermal: 0.000294 LR: 3.82e-06\n",
      "Epoch  26 [5200/10697 ( 48.6%)] Loss: 0.026900 L1: 0.015997 Grad: 0.108781 Thermal: 0.000478 LR: 3.82e-06\n",
      "Epoch  26 [5200/10697 ( 48.6%)] Loss: 0.026900 L1: 0.015997 Grad: 0.108781 Thermal: 0.000478 LR: 3.82e-06\n",
      "Epoch  26 [5250/10697 ( 49.1%)] Loss: 0.030980 L1: 0.017676 Grad: 0.132722 Thermal: 0.000634 LR: 3.82e-06\n",
      "Epoch  26 [5250/10697 ( 49.1%)] Loss: 0.030980 L1: 0.017676 Grad: 0.132722 Thermal: 0.000634 LR: 3.82e-06\n",
      "Epoch  26 [5300/10697 ( 49.5%)] Loss: 0.027141 L1: 0.016122 Grad: 0.109955 Thermal: 0.000470 LR: 3.82e-06\n",
      "Epoch  26 [5300/10697 ( 49.5%)] Loss: 0.027141 L1: 0.016122 Grad: 0.109955 Thermal: 0.000470 LR: 3.82e-06\n",
      "Epoch  26 [5350/10697 ( 50.0%)] Loss: 0.028161 L1: 0.016774 Grad: 0.113632 Thermal: 0.000476 LR: 3.82e-06\n",
      "Epoch  26 [5350/10697 ( 50.0%)] Loss: 0.028161 L1: 0.016774 Grad: 0.113632 Thermal: 0.000476 LR: 3.82e-06\n",
      "Epoch  26 [5400/10697 ( 50.5%)] Loss: 0.024269 L1: 0.013998 Grad: 0.102484 Thermal: 0.000446 LR: 3.82e-06\n",
      "Epoch  26 [5400/10697 ( 50.5%)] Loss: 0.024269 L1: 0.013998 Grad: 0.102484 Thermal: 0.000446 LR: 3.82e-06\n",
      "Epoch  26 [5450/10697 ( 50.9%)] Loss: 0.028531 L1: 0.016339 Grad: 0.121669 Thermal: 0.000512 LR: 3.82e-06\n",
      "Epoch  26 [5450/10697 ( 50.9%)] Loss: 0.028531 L1: 0.016339 Grad: 0.121669 Thermal: 0.000512 LR: 3.82e-06\n",
      "Epoch  26 [5500/10697 ( 51.4%)] Loss: 0.023926 L1: 0.013912 Grad: 0.099944 Thermal: 0.000381 LR: 3.82e-06\n",
      "Epoch  26 [5500/10697 ( 51.4%)] Loss: 0.023926 L1: 0.013912 Grad: 0.099944 Thermal: 0.000381 LR: 3.82e-06\n",
      "Epoch  26 [5550/10697 ( 51.9%)] Loss: 0.023946 L1: 0.013681 Grad: 0.102452 Thermal: 0.000401 LR: 3.82e-06\n",
      "Epoch  26 [5550/10697 ( 51.9%)] Loss: 0.023946 L1: 0.013681 Grad: 0.102452 Thermal: 0.000401 LR: 3.82e-06\n",
      "Epoch  26 [5600/10697 ( 52.4%)] Loss: 0.026052 L1: 0.015468 Grad: 0.105611 Thermal: 0.000456 LR: 3.82e-06\n",
      "Epoch  26 [5600/10697 ( 52.4%)] Loss: 0.026052 L1: 0.015468 Grad: 0.105611 Thermal: 0.000456 LR: 3.82e-06\n",
      "Epoch  26 [5650/10697 ( 52.8%)] Loss: 0.029669 L1: 0.017550 Grad: 0.120900 Thermal: 0.000576 LR: 3.82e-06\n",
      "Epoch  26 [5650/10697 ( 52.8%)] Loss: 0.029669 L1: 0.017550 Grad: 0.120900 Thermal: 0.000576 LR: 3.82e-06\n",
      "Epoch  26 [5700/10697 ( 53.3%)] Loss: 0.031088 L1: 0.018067 Grad: 0.129858 Thermal: 0.000694 LR: 3.82e-06\n",
      "Epoch  26 [5700/10697 ( 53.3%)] Loss: 0.031088 L1: 0.018067 Grad: 0.129858 Thermal: 0.000694 LR: 3.82e-06\n",
      "Epoch  26 [5750/10697 ( 53.8%)] Loss: 0.029944 L1: 0.017730 Grad: 0.121853 Thermal: 0.000593 LR: 3.82e-06\n",
      "Epoch  26 [5750/10697 ( 53.8%)] Loss: 0.029944 L1: 0.017730 Grad: 0.121853 Thermal: 0.000593 LR: 3.82e-06\n",
      "Epoch  26 [5800/10697 ( 54.2%)] Loss: 0.022764 L1: 0.013487 Grad: 0.092592 Thermal: 0.000363 LR: 3.82e-06\n",
      "Epoch  26 [5800/10697 ( 54.2%)] Loss: 0.022764 L1: 0.013487 Grad: 0.092592 Thermal: 0.000363 LR: 3.82e-06\n",
      "Epoch  26 [5850/10697 ( 54.7%)] Loss: 0.022248 L1: 0.012945 Grad: 0.092857 Thermal: 0.000339 LR: 3.82e-06\n",
      "Epoch  26 [5850/10697 ( 54.7%)] Loss: 0.022248 L1: 0.012945 Grad: 0.092857 Thermal: 0.000339 LR: 3.82e-06\n",
      "Epoch  26 [5900/10697 ( 55.2%)] Loss: 0.028783 L1: 0.016659 Grad: 0.120919 Thermal: 0.000650 LR: 3.82e-06\n",
      "Epoch  26 [5900/10697 ( 55.2%)] Loss: 0.028783 L1: 0.016659 Grad: 0.120919 Thermal: 0.000650 LR: 3.82e-06\n",
      "Epoch  26 [5950/10697 ( 55.6%)] Loss: 0.022828 L1: 0.012987 Grad: 0.098256 Thermal: 0.000293 LR: 3.82e-06\n",
      "Epoch  26 [5950/10697 ( 55.6%)] Loss: 0.022828 L1: 0.012987 Grad: 0.098256 Thermal: 0.000293 LR: 3.82e-06\n",
      "Epoch  26 [6000/10697 ( 56.1%)] Loss: 0.021223 L1: 0.012188 Grad: 0.090201 Thermal: 0.000307 LR: 3.82e-06\n",
      "Epoch  26 [6000/10697 ( 56.1%)] Loss: 0.021223 L1: 0.012188 Grad: 0.090201 Thermal: 0.000307 LR: 3.82e-06\n",
      "Epoch  26 [6050/10697 ( 56.6%)] Loss: 0.023175 L1: 0.013427 Grad: 0.097304 Thermal: 0.000354 LR: 3.82e-06\n",
      "Epoch  26 [6050/10697 ( 56.6%)] Loss: 0.023175 L1: 0.013427 Grad: 0.097304 Thermal: 0.000354 LR: 3.82e-06\n",
      "Epoch  26 [6100/10697 ( 57.0%)] Loss: 0.027172 L1: 0.015741 Grad: 0.114075 Thermal: 0.000488 LR: 3.82e-06\n",
      "Epoch  26 [6100/10697 ( 57.0%)] Loss: 0.027172 L1: 0.015741 Grad: 0.114075 Thermal: 0.000488 LR: 3.82e-06\n",
      "Epoch  26 [6150/10697 ( 57.5%)] Loss: 0.025187 L1: 0.014560 Grad: 0.106076 Thermal: 0.000390 LR: 3.82e-06\n",
      "Epoch  26 [6150/10697 ( 57.5%)] Loss: 0.025187 L1: 0.014560 Grad: 0.106076 Thermal: 0.000390 LR: 3.82e-06\n",
      "Epoch  26 [6200/10697 ( 58.0%)] Loss: 0.025069 L1: 0.014270 Grad: 0.107806 Thermal: 0.000369 LR: 3.82e-06\n",
      "Epoch  26 [6200/10697 ( 58.0%)] Loss: 0.025069 L1: 0.014270 Grad: 0.107806 Thermal: 0.000369 LR: 3.82e-06\n",
      "Epoch  26 [6250/10697 ( 58.4%)] Loss: 0.027195 L1: 0.016218 Grad: 0.109543 Thermal: 0.000462 LR: 3.82e-06\n",
      "Epoch  26 [6250/10697 ( 58.4%)] Loss: 0.027195 L1: 0.016218 Grad: 0.109543 Thermal: 0.000462 LR: 3.82e-06\n",
      "Epoch  26 [6300/10697 ( 58.9%)] Loss: 0.019310 L1: 0.011298 Grad: 0.079987 Thermal: 0.000266 LR: 3.82e-06\n",
      "Epoch  26 [6300/10697 ( 58.9%)] Loss: 0.019310 L1: 0.011298 Grad: 0.079987 Thermal: 0.000266 LR: 3.82e-06\n",
      "Epoch  26 [6350/10697 ( 59.4%)] Loss: 0.022842 L1: 0.013235 Grad: 0.095869 Thermal: 0.000409 LR: 3.82e-06\n",
      "Epoch  26 [6350/10697 ( 59.4%)] Loss: 0.022842 L1: 0.013235 Grad: 0.095869 Thermal: 0.000409 LR: 3.82e-06\n",
      "Epoch  26 [6400/10697 ( 59.8%)] Loss: 0.027372 L1: 0.016367 Grad: 0.109814 Thermal: 0.000466 LR: 3.82e-06\n",
      "Epoch  26 [6400/10697 ( 59.8%)] Loss: 0.027372 L1: 0.016367 Grad: 0.109814 Thermal: 0.000466 LR: 3.82e-06\n",
      "Epoch  26 [6450/10697 ( 60.3%)] Loss: 0.026512 L1: 0.015799 Grad: 0.106912 Thermal: 0.000432 LR: 3.82e-06\n",
      "Epoch  26 [6450/10697 ( 60.3%)] Loss: 0.026512 L1: 0.015799 Grad: 0.106912 Thermal: 0.000432 LR: 3.82e-06\n",
      "Epoch  26 [6500/10697 ( 60.8%)] Loss: 0.025674 L1: 0.014714 Grad: 0.109384 Thermal: 0.000425 LR: 3.82e-06\n",
      "Epoch  26 [6500/10697 ( 60.8%)] Loss: 0.025674 L1: 0.014714 Grad: 0.109384 Thermal: 0.000425 LR: 3.82e-06\n",
      "Epoch  26 [6550/10697 ( 61.2%)] Loss: 0.023412 L1: 0.013495 Grad: 0.098998 Thermal: 0.000351 LR: 3.82e-06\n",
      "Epoch  26 [6550/10697 ( 61.2%)] Loss: 0.023412 L1: 0.013495 Grad: 0.098998 Thermal: 0.000351 LR: 3.82e-06\n",
      "Epoch  26 [6600/10697 ( 61.7%)] Loss: 0.023266 L1: 0.013441 Grad: 0.098087 Thermal: 0.000339 LR: 3.82e-06\n",
      "Epoch  26 [6600/10697 ( 61.7%)] Loss: 0.023266 L1: 0.013441 Grad: 0.098087 Thermal: 0.000339 LR: 3.82e-06\n",
      "Epoch  26 [6650/10697 ( 62.2%)] Loss: 0.024136 L1: 0.014293 Grad: 0.098227 Thermal: 0.000403 LR: 3.82e-06\n",
      "Epoch  26 [6650/10697 ( 62.2%)] Loss: 0.024136 L1: 0.014293 Grad: 0.098227 Thermal: 0.000403 LR: 3.82e-06\n",
      "Epoch  26 [6700/10697 ( 62.6%)] Loss: 0.024381 L1: 0.013994 Grad: 0.103678 Thermal: 0.000388 LR: 3.82e-06\n",
      "Epoch  26 [6700/10697 ( 62.6%)] Loss: 0.024381 L1: 0.013994 Grad: 0.103678 Thermal: 0.000388 LR: 3.82e-06\n",
      "Epoch  26 [6750/10697 ( 63.1%)] Loss: 0.026343 L1: 0.015274 Grad: 0.110489 Thermal: 0.000409 LR: 3.82e-06\n",
      "Epoch  26 [6750/10697 ( 63.1%)] Loss: 0.026343 L1: 0.015274 Grad: 0.110489 Thermal: 0.000409 LR: 3.82e-06\n",
      "Epoch  26 [6800/10697 ( 63.6%)] Loss: 0.023855 L1: 0.014132 Grad: 0.097039 Thermal: 0.000379 LR: 3.82e-06\n",
      "Epoch  26 [6800/10697 ( 63.6%)] Loss: 0.023855 L1: 0.014132 Grad: 0.097039 Thermal: 0.000379 LR: 3.82e-06\n",
      "Epoch  26 [6850/10697 ( 64.0%)] Loss: 0.030651 L1: 0.017898 Grad: 0.127238 Thermal: 0.000581 LR: 3.82e-06\n",
      "Epoch  26 [6850/10697 ( 64.0%)] Loss: 0.030651 L1: 0.017898 Grad: 0.127238 Thermal: 0.000581 LR: 3.82e-06\n",
      "Epoch  26 [6900/10697 ( 64.5%)] Loss: 0.025540 L1: 0.014798 Grad: 0.107200 Thermal: 0.000434 LR: 3.82e-06\n",
      "Epoch  26 [6900/10697 ( 64.5%)] Loss: 0.025540 L1: 0.014798 Grad: 0.107200 Thermal: 0.000434 LR: 3.82e-06\n",
      "Epoch  26 [6950/10697 ( 65.0%)] Loss: 0.027553 L1: 0.016182 Grad: 0.113463 Thermal: 0.000499 LR: 3.82e-06\n",
      "Epoch  26 [6950/10697 ( 65.0%)] Loss: 0.027553 L1: 0.016182 Grad: 0.113463 Thermal: 0.000499 LR: 3.82e-06\n",
      "Epoch  26 [7000/10697 ( 65.4%)] Loss: 0.023212 L1: 0.012776 Grad: 0.104183 Thermal: 0.000369 LR: 3.82e-06\n",
      "Epoch  26 [7000/10697 ( 65.4%)] Loss: 0.023212 L1: 0.012776 Grad: 0.104183 Thermal: 0.000369 LR: 3.82e-06\n",
      "Epoch  26 [7050/10697 ( 65.9%)] Loss: 0.030646 L1: 0.017790 Grad: 0.128274 Thermal: 0.000588 LR: 3.82e-06\n",
      "Epoch  26 [7050/10697 ( 65.9%)] Loss: 0.030646 L1: 0.017790 Grad: 0.128274 Thermal: 0.000588 LR: 3.82e-06\n",
      "Epoch  26 [7100/10697 ( 66.4%)] Loss: 0.024176 L1: 0.014305 Grad: 0.098528 Thermal: 0.000373 LR: 3.82e-06\n",
      "Epoch  26 [7100/10697 ( 66.4%)] Loss: 0.024176 L1: 0.014305 Grad: 0.098528 Thermal: 0.000373 LR: 3.82e-06\n",
      "Epoch  26 [7150/10697 ( 66.8%)] Loss: 0.026475 L1: 0.016030 Grad: 0.104219 Thermal: 0.000460 LR: 3.82e-06\n",
      "Epoch  26 [7150/10697 ( 66.8%)] Loss: 0.026475 L1: 0.016030 Grad: 0.104219 Thermal: 0.000460 LR: 3.82e-06\n",
      "Epoch  26 [7200/10697 ( 67.3%)] Loss: 0.018567 L1: 0.010681 Grad: 0.078740 Thermal: 0.000249 LR: 3.82e-06\n",
      "Epoch  26 [7200/10697 ( 67.3%)] Loss: 0.018567 L1: 0.010681 Grad: 0.078740 Thermal: 0.000249 LR: 3.82e-06\n",
      "Epoch  26 [7250/10697 ( 67.8%)] Loss: 0.026708 L1: 0.015780 Grad: 0.109064 Thermal: 0.000439 LR: 3.82e-06\n",
      "Epoch  26 [7250/10697 ( 67.8%)] Loss: 0.026708 L1: 0.015780 Grad: 0.109064 Thermal: 0.000439 LR: 3.82e-06\n",
      "Epoch  26 [7300/10697 ( 68.2%)] Loss: 0.031460 L1: 0.017831 Grad: 0.136003 Thermal: 0.000573 LR: 3.82e-06\n",
      "Epoch  26 [7300/10697 ( 68.2%)] Loss: 0.031460 L1: 0.017831 Grad: 0.136003 Thermal: 0.000573 LR: 3.82e-06\n",
      "Epoch  26 [7350/10697 ( 68.7%)] Loss: 0.024197 L1: 0.014298 Grad: 0.098792 Thermal: 0.000391 LR: 3.82e-06\n",
      "Epoch  26 [7350/10697 ( 68.7%)] Loss: 0.024197 L1: 0.014298 Grad: 0.098792 Thermal: 0.000391 LR: 3.82e-06\n",
      "Epoch  26 [7400/10697 ( 69.2%)] Loss: 0.029355 L1: 0.016843 Grad: 0.124836 Thermal: 0.000578 LR: 3.82e-06\n",
      "Epoch  26 [7400/10697 ( 69.2%)] Loss: 0.029355 L1: 0.016843 Grad: 0.124836 Thermal: 0.000578 LR: 3.82e-06\n",
      "Epoch  26 [7450/10697 ( 69.6%)] Loss: 0.026427 L1: 0.015091 Grad: 0.113138 Thermal: 0.000433 LR: 3.82e-06\n",
      "Epoch  26 [7450/10697 ( 69.6%)] Loss: 0.026427 L1: 0.015091 Grad: 0.113138 Thermal: 0.000433 LR: 3.82e-06\n",
      "Epoch  26 [7500/10697 ( 70.1%)] Loss: 0.027981 L1: 0.016380 Grad: 0.115779 Thermal: 0.000469 LR: 3.82e-06\n",
      "Epoch  26 [7500/10697 ( 70.1%)] Loss: 0.027981 L1: 0.016380 Grad: 0.115779 Thermal: 0.000469 LR: 3.82e-06\n",
      "Epoch  26 [7550/10697 ( 70.6%)] Loss: 0.029674 L1: 0.017382 Grad: 0.122639 Thermal: 0.000564 LR: 3.82e-06\n",
      "Epoch  26 [7550/10697 ( 70.6%)] Loss: 0.029674 L1: 0.017382 Grad: 0.122639 Thermal: 0.000564 LR: 3.82e-06\n",
      "Epoch  26 [7600/10697 ( 71.0%)] Loss: 0.031231 L1: 0.018166 Grad: 0.130340 Thermal: 0.000615 LR: 3.82e-06\n",
      "Epoch  26 [7600/10697 ( 71.0%)] Loss: 0.031231 L1: 0.018166 Grad: 0.130340 Thermal: 0.000615 LR: 3.82e-06\n",
      "Epoch  26 [7650/10697 ( 71.5%)] Loss: 0.025658 L1: 0.015091 Grad: 0.105460 Thermal: 0.000411 LR: 3.82e-06\n",
      "Epoch  26 [7650/10697 ( 71.5%)] Loss: 0.025658 L1: 0.015091 Grad: 0.105460 Thermal: 0.000411 LR: 3.82e-06\n",
      "Epoch  26 [7700/10697 ( 72.0%)] Loss: 0.030815 L1: 0.017762 Grad: 0.130228 Thermal: 0.000596 LR: 3.82e-06\n",
      "Epoch  26 [7700/10697 ( 72.0%)] Loss: 0.030815 L1: 0.017762 Grad: 0.130228 Thermal: 0.000596 LR: 3.82e-06\n",
      "Epoch  26 [7750/10697 ( 72.5%)] Loss: 0.031792 L1: 0.018211 Grad: 0.135508 Thermal: 0.000611 LR: 3.82e-06\n",
      "Epoch  26 [7750/10697 ( 72.5%)] Loss: 0.031792 L1: 0.018211 Grad: 0.135508 Thermal: 0.000611 LR: 3.82e-06\n",
      "Epoch  26 [7800/10697 ( 72.9%)] Loss: 0.024010 L1: 0.014101 Grad: 0.098902 Thermal: 0.000383 LR: 3.82e-06\n",
      "Epoch  26 [7800/10697 ( 72.9%)] Loss: 0.024010 L1: 0.014101 Grad: 0.098902 Thermal: 0.000383 LR: 3.82e-06\n",
      "Epoch  26 [7850/10697 ( 73.4%)] Loss: 0.024570 L1: 0.014111 Grad: 0.104406 Thermal: 0.000368 LR: 3.82e-06\n",
      "Epoch  26 [7850/10697 ( 73.4%)] Loss: 0.024570 L1: 0.014111 Grad: 0.104406 Thermal: 0.000368 LR: 3.82e-06\n",
      "Epoch  26 [7900/10697 ( 73.9%)] Loss: 0.023839 L1: 0.014105 Grad: 0.097172 Thermal: 0.000346 LR: 3.82e-06\n",
      "Epoch  26 [7900/10697 ( 73.9%)] Loss: 0.023839 L1: 0.014105 Grad: 0.097172 Thermal: 0.000346 LR: 3.82e-06\n",
      "Epoch  26 [7950/10697 ( 74.3%)] Loss: 0.025329 L1: 0.014904 Grad: 0.104055 Thermal: 0.000393 LR: 3.82e-06\n",
      "Epoch  26 [7950/10697 ( 74.3%)] Loss: 0.025329 L1: 0.014904 Grad: 0.104055 Thermal: 0.000393 LR: 3.82e-06\n",
      "Epoch  26 [8000/10697 ( 74.8%)] Loss: 0.029405 L1: 0.017168 Grad: 0.122123 Thermal: 0.000493 LR: 3.82e-06\n",
      "Epoch  26 [8000/10697 ( 74.8%)] Loss: 0.029405 L1: 0.017168 Grad: 0.122123 Thermal: 0.000493 LR: 3.82e-06\n",
      "Epoch  26 [8050/10697 ( 75.3%)] Loss: 0.022240 L1: 0.013123 Grad: 0.090986 Thermal: 0.000369 LR: 3.82e-06\n",
      "Epoch  26 [8050/10697 ( 75.3%)] Loss: 0.022240 L1: 0.013123 Grad: 0.090986 Thermal: 0.000369 LR: 3.82e-06\n",
      "Epoch  26 [8100/10697 ( 75.7%)] Loss: 0.025829 L1: 0.015086 Grad: 0.107213 Thermal: 0.000436 LR: 3.82e-06\n",
      "Epoch  26 [8100/10697 ( 75.7%)] Loss: 0.025829 L1: 0.015086 Grad: 0.107213 Thermal: 0.000436 LR: 3.82e-06\n",
      "Epoch  26 [8150/10697 ( 76.2%)] Loss: 0.023488 L1: 0.013995 Grad: 0.094737 Thermal: 0.000375 LR: 3.82e-06\n",
      "Epoch  26 [8150/10697 ( 76.2%)] Loss: 0.023488 L1: 0.013995 Grad: 0.094737 Thermal: 0.000375 LR: 3.82e-06\n",
      "Epoch  26 [8200/10697 ( 76.7%)] Loss: 0.030659 L1: 0.017909 Grad: 0.127177 Thermal: 0.000662 LR: 3.82e-06\n",
      "Epoch  26 [8200/10697 ( 76.7%)] Loss: 0.030659 L1: 0.017909 Grad: 0.127177 Thermal: 0.000662 LR: 3.82e-06\n",
      "Epoch  26 [8250/10697 ( 77.1%)] Loss: 0.029791 L1: 0.017435 Grad: 0.123286 Thermal: 0.000551 LR: 3.82e-06\n",
      "Epoch  26 [8250/10697 ( 77.1%)] Loss: 0.029791 L1: 0.017435 Grad: 0.123286 Thermal: 0.000551 LR: 3.82e-06\n",
      "Epoch  26 [8300/10697 ( 77.6%)] Loss: 0.022197 L1: 0.012829 Grad: 0.093505 Thermal: 0.000343 LR: 3.82e-06\n",
      "Epoch  26 [8300/10697 ( 77.6%)] Loss: 0.022197 L1: 0.012829 Grad: 0.093505 Thermal: 0.000343 LR: 3.82e-06\n",
      "Epoch  26 [8350/10697 ( 78.1%)] Loss: 0.032000 L1: 0.018511 Grad: 0.134549 Thermal: 0.000678 LR: 3.82e-06\n",
      "Epoch  26 [8350/10697 ( 78.1%)] Loss: 0.032000 L1: 0.018511 Grad: 0.134549 Thermal: 0.000678 LR: 3.82e-06\n",
      "Epoch  26 [8400/10697 ( 78.5%)] Loss: 0.023452 L1: 0.013853 Grad: 0.095804 Thermal: 0.000377 LR: 3.82e-06\n",
      "Epoch  26 [8400/10697 ( 78.5%)] Loss: 0.023452 L1: 0.013853 Grad: 0.095804 Thermal: 0.000377 LR: 3.82e-06\n",
      "Epoch  26 [8450/10697 ( 79.0%)] Loss: 0.022082 L1: 0.013025 Grad: 0.090399 Thermal: 0.000334 LR: 3.82e-06\n",
      "Epoch  26 [8450/10697 ( 79.0%)] Loss: 0.022082 L1: 0.013025 Grad: 0.090399 Thermal: 0.000334 LR: 3.82e-06\n",
      "Epoch  26 [8500/10697 ( 79.5%)] Loss: 0.024962 L1: 0.014390 Grad: 0.105527 Thermal: 0.000370 LR: 3.82e-06\n",
      "Epoch  26 [8500/10697 ( 79.5%)] Loss: 0.024962 L1: 0.014390 Grad: 0.105527 Thermal: 0.000370 LR: 3.82e-06\n",
      "Epoch  26 [8550/10697 ( 79.9%)] Loss: 0.020079 L1: 0.011778 Grad: 0.082868 Thermal: 0.000295 LR: 3.82e-06\n",
      "Epoch  26 [8550/10697 ( 79.9%)] Loss: 0.020079 L1: 0.011778 Grad: 0.082868 Thermal: 0.000295 LR: 3.82e-06\n",
      "Epoch  26 [8600/10697 ( 80.4%)] Loss: 0.026794 L1: 0.015352 Grad: 0.114200 Thermal: 0.000447 LR: 3.82e-06\n",
      "Epoch  26 [8600/10697 ( 80.4%)] Loss: 0.026794 L1: 0.015352 Grad: 0.114200 Thermal: 0.000447 LR: 3.82e-06\n",
      "Epoch  26 [8650/10697 ( 80.9%)] Loss: 0.023513 L1: 0.013840 Grad: 0.096520 Thermal: 0.000402 LR: 3.82e-06\n",
      "Epoch  26 [8650/10697 ( 80.9%)] Loss: 0.023513 L1: 0.013840 Grad: 0.096520 Thermal: 0.000402 LR: 3.82e-06\n",
      "Epoch  26 [8700/10697 ( 81.3%)] Loss: 0.024088 L1: 0.013974 Grad: 0.100952 Thermal: 0.000383 LR: 3.82e-06\n",
      "Epoch  26 [8700/10697 ( 81.3%)] Loss: 0.024088 L1: 0.013974 Grad: 0.100952 Thermal: 0.000383 LR: 3.82e-06\n",
      "Epoch  26 [8750/10697 ( 81.8%)] Loss: 0.031120 L1: 0.018057 Grad: 0.130312 Thermal: 0.000629 LR: 3.82e-06\n",
      "Epoch  26 [8750/10697 ( 81.8%)] Loss: 0.031120 L1: 0.018057 Grad: 0.130312 Thermal: 0.000629 LR: 3.82e-06\n",
      "Epoch  26 [8800/10697 ( 82.3%)] Loss: 0.024717 L1: 0.014978 Grad: 0.097197 Thermal: 0.000396 LR: 3.82e-06\n",
      "Epoch  26 [8800/10697 ( 82.3%)] Loss: 0.024717 L1: 0.014978 Grad: 0.097197 Thermal: 0.000396 LR: 3.82e-06\n",
      "Epoch  26 [8850/10697 ( 82.7%)] Loss: 0.026165 L1: 0.015606 Grad: 0.105374 Thermal: 0.000436 LR: 3.82e-06\n",
      "Epoch  26 [8850/10697 ( 82.7%)] Loss: 0.026165 L1: 0.015606 Grad: 0.105374 Thermal: 0.000436 LR: 3.82e-06\n",
      "Epoch  26 [8900/10697 ( 83.2%)] Loss: 0.024505 L1: 0.014162 Grad: 0.103224 Thermal: 0.000402 LR: 3.82e-06\n",
      "Epoch  26 [8900/10697 ( 83.2%)] Loss: 0.024505 L1: 0.014162 Grad: 0.103224 Thermal: 0.000402 LR: 3.82e-06\n",
      "Epoch  26 [8950/10697 ( 83.7%)] Loss: 0.021710 L1: 0.012806 Grad: 0.088874 Thermal: 0.000336 LR: 3.82e-06\n",
      "Epoch  26 [8950/10697 ( 83.7%)] Loss: 0.021710 L1: 0.012806 Grad: 0.088874 Thermal: 0.000336 LR: 3.82e-06\n",
      "Epoch  26 [9000/10697 ( 84.1%)] Loss: 0.021244 L1: 0.012286 Grad: 0.089429 Thermal: 0.000301 LR: 3.82e-06\n",
      "Epoch  26 [9000/10697 ( 84.1%)] Loss: 0.021244 L1: 0.012286 Grad: 0.089429 Thermal: 0.000301 LR: 3.82e-06\n",
      "Epoch  26 [9050/10697 ( 84.6%)] Loss: 0.023097 L1: 0.013669 Grad: 0.094085 Thermal: 0.000382 LR: 3.82e-06\n",
      "Epoch  26 [9050/10697 ( 84.6%)] Loss: 0.023097 L1: 0.013669 Grad: 0.094085 Thermal: 0.000382 LR: 3.82e-06\n",
      "Epoch  26 [9100/10697 ( 85.1%)] Loss: 0.020521 L1: 0.011914 Grad: 0.085925 Thermal: 0.000287 LR: 3.82e-06\n",
      "Epoch  26 [9100/10697 ( 85.1%)] Loss: 0.020521 L1: 0.011914 Grad: 0.085925 Thermal: 0.000287 LR: 3.82e-06\n",
      "Epoch  26 [9150/10697 ( 85.5%)] Loss: 0.024434 L1: 0.014222 Grad: 0.101921 Thermal: 0.000416 LR: 3.82e-06\n",
      "Epoch  26 [9150/10697 ( 85.5%)] Loss: 0.024434 L1: 0.014222 Grad: 0.101921 Thermal: 0.000416 LR: 3.82e-06\n",
      "Epoch  26 [9200/10697 ( 86.0%)] Loss: 0.022046 L1: 0.012807 Grad: 0.092229 Thermal: 0.000325 LR: 3.82e-06\n",
      "Epoch  26 [9200/10697 ( 86.0%)] Loss: 0.022046 L1: 0.012807 Grad: 0.092229 Thermal: 0.000325 LR: 3.82e-06\n",
      "Epoch  26 [9250/10697 ( 86.5%)] Loss: 0.029882 L1: 0.017318 Grad: 0.125373 Thermal: 0.000531 LR: 3.82e-06\n",
      "Epoch  26 [9250/10697 ( 86.5%)] Loss: 0.029882 L1: 0.017318 Grad: 0.125373 Thermal: 0.000531 LR: 3.82e-06\n",
      "Epoch  26 [9300/10697 ( 86.9%)] Loss: 0.026353 L1: 0.014982 Grad: 0.113473 Thermal: 0.000470 LR: 3.82e-06\n",
      "Epoch  26 [9300/10697 ( 86.9%)] Loss: 0.026353 L1: 0.014982 Grad: 0.113473 Thermal: 0.000470 LR: 3.82e-06\n",
      "Epoch  26 [9350/10697 ( 87.4%)] Loss: 0.023228 L1: 0.013507 Grad: 0.097035 Thermal: 0.000357 LR: 3.82e-06\n",
      "Epoch  26 [9350/10697 ( 87.4%)] Loss: 0.023228 L1: 0.013507 Grad: 0.097035 Thermal: 0.000357 LR: 3.82e-06\n",
      "Epoch  26 [9400/10697 ( 87.9%)] Loss: 0.026810 L1: 0.015914 Grad: 0.108734 Thermal: 0.000443 LR: 3.82e-06\n",
      "Epoch  26 [9400/10697 ( 87.9%)] Loss: 0.026810 L1: 0.015914 Grad: 0.108734 Thermal: 0.000443 LR: 3.82e-06\n",
      "Epoch  26 [9450/10697 ( 88.3%)] Loss: 0.031725 L1: 0.018812 Grad: 0.128815 Thermal: 0.000628 LR: 3.82e-06\n",
      "Epoch  26 [9450/10697 ( 88.3%)] Loss: 0.031725 L1: 0.018812 Grad: 0.128815 Thermal: 0.000628 LR: 3.82e-06\n",
      "Epoch  26 [9500/10697 ( 88.8%)] Loss: 0.027223 L1: 0.016009 Grad: 0.111914 Thermal: 0.000456 LR: 3.82e-06\n",
      "Epoch  26 [9500/10697 ( 88.8%)] Loss: 0.027223 L1: 0.016009 Grad: 0.111914 Thermal: 0.000456 LR: 3.82e-06\n",
      "Epoch  26 [9550/10697 ( 89.3%)] Loss: 0.019497 L1: 0.010972 Grad: 0.085131 Thermal: 0.000246 LR: 3.82e-06\n",
      "Epoch  26 [9550/10697 ( 89.3%)] Loss: 0.019497 L1: 0.010972 Grad: 0.085131 Thermal: 0.000246 LR: 3.82e-06\n",
      "Epoch  26 [9600/10697 ( 89.7%)] Loss: 0.023283 L1: 0.013634 Grad: 0.096327 Thermal: 0.000331 LR: 3.82e-06\n",
      "Epoch  26 [9600/10697 ( 89.7%)] Loss: 0.023283 L1: 0.013634 Grad: 0.096327 Thermal: 0.000331 LR: 3.82e-06\n",
      "Epoch  26 [9650/10697 ( 90.2%)] Loss: 0.025693 L1: 0.015128 Grad: 0.105438 Thermal: 0.000413 LR: 3.82e-06\n",
      "Epoch  26 [9650/10697 ( 90.2%)] Loss: 0.025693 L1: 0.015128 Grad: 0.105438 Thermal: 0.000413 LR: 3.82e-06\n",
      "Epoch  26 [9700/10697 ( 90.7%)] Loss: 0.022919 L1: 0.013559 Grad: 0.093435 Thermal: 0.000346 LR: 3.82e-06\n",
      "Epoch  26 [9700/10697 ( 90.7%)] Loss: 0.022919 L1: 0.013559 Grad: 0.093435 Thermal: 0.000346 LR: 3.82e-06\n",
      "Epoch  26 [9750/10697 ( 91.1%)] Loss: 0.029704 L1: 0.017032 Grad: 0.126420 Thermal: 0.000587 LR: 3.82e-06\n",
      "Epoch  26 [9750/10697 ( 91.1%)] Loss: 0.029704 L1: 0.017032 Grad: 0.126420 Thermal: 0.000587 LR: 3.82e-06\n",
      "Epoch  26 [9800/10697 ( 91.6%)] Loss: 0.025810 L1: 0.014901 Grad: 0.108858 Thermal: 0.000473 LR: 3.82e-06\n",
      "Epoch  26 [9800/10697 ( 91.6%)] Loss: 0.025810 L1: 0.014901 Grad: 0.108858 Thermal: 0.000473 LR: 3.82e-06\n",
      "Epoch  26 [9850/10697 ( 92.1%)] Loss: 0.028645 L1: 0.016613 Grad: 0.120067 Thermal: 0.000498 LR: 3.82e-06\n",
      "Epoch  26 [9850/10697 ( 92.1%)] Loss: 0.028645 L1: 0.016613 Grad: 0.120067 Thermal: 0.000498 LR: 3.82e-06\n",
      "Epoch  26 [9900/10697 ( 92.5%)] Loss: 0.023492 L1: 0.014105 Grad: 0.093690 Thermal: 0.000370 LR: 3.82e-06\n",
      "Epoch  26 [9900/10697 ( 92.5%)] Loss: 0.023492 L1: 0.014105 Grad: 0.093690 Thermal: 0.000370 LR: 3.82e-06\n",
      "Epoch  26 [9950/10697 ( 93.0%)] Loss: 0.034072 L1: 0.019532 Grad: 0.145002 Thermal: 0.000795 LR: 3.82e-06\n",
      "Epoch  26 [9950/10697 ( 93.0%)] Loss: 0.034072 L1: 0.019532 Grad: 0.145002 Thermal: 0.000795 LR: 3.82e-06\n",
      "Epoch  26 [10000/10697 ( 93.5%)] Loss: 0.026830 L1: 0.015990 Grad: 0.108171 Thermal: 0.000469 LR: 3.82e-06\n",
      "Epoch  26 [10000/10697 ( 93.5%)] Loss: 0.026830 L1: 0.015990 Grad: 0.108171 Thermal: 0.000469 LR: 3.82e-06\n",
      "Epoch  26 [10050/10697 ( 94.0%)] Loss: 0.026981 L1: 0.015451 Grad: 0.115062 Thermal: 0.000471 LR: 3.82e-06\n",
      "Epoch  26 [10050/10697 ( 94.0%)] Loss: 0.026981 L1: 0.015451 Grad: 0.115062 Thermal: 0.000471 LR: 3.82e-06\n",
      "Epoch  26 [10100/10697 ( 94.4%)] Loss: 0.032079 L1: 0.018644 Grad: 0.134013 Thermal: 0.000669 LR: 3.82e-06\n",
      "Epoch  26 [10100/10697 ( 94.4%)] Loss: 0.032079 L1: 0.018644 Grad: 0.134013 Thermal: 0.000669 LR: 3.82e-06\n",
      "Epoch  26 [10150/10697 ( 94.9%)] Loss: 0.026680 L1: 0.015999 Grad: 0.106579 Thermal: 0.000465 LR: 3.82e-06\n",
      "Epoch  26 [10150/10697 ( 94.9%)] Loss: 0.026680 L1: 0.015999 Grad: 0.106579 Thermal: 0.000465 LR: 3.82e-06\n",
      "Epoch  26 [10200/10697 ( 95.4%)] Loss: 0.024990 L1: 0.014719 Grad: 0.102508 Thermal: 0.000412 LR: 3.82e-06\n",
      "Epoch  26 [10200/10697 ( 95.4%)] Loss: 0.024990 L1: 0.014719 Grad: 0.102508 Thermal: 0.000412 LR: 3.82e-06\n",
      "Epoch  26 [10250/10697 ( 95.8%)] Loss: 0.022000 L1: 0.012650 Grad: 0.093327 Thermal: 0.000331 LR: 3.82e-06\n",
      "Epoch  26 [10250/10697 ( 95.8%)] Loss: 0.022000 L1: 0.012650 Grad: 0.093327 Thermal: 0.000331 LR: 3.82e-06\n",
      "Epoch  26 [10300/10697 ( 96.3%)] Loss: 0.020281 L1: 0.011264 Grad: 0.090042 Thermal: 0.000265 LR: 3.82e-06\n",
      "Epoch  26 [10300/10697 ( 96.3%)] Loss: 0.020281 L1: 0.011264 Grad: 0.090042 Thermal: 0.000265 LR: 3.82e-06\n",
      "Epoch  26 [10350/10697 ( 96.8%)] Loss: 0.027014 L1: 0.016119 Grad: 0.108732 Thermal: 0.000433 LR: 3.82e-06\n",
      "Epoch  26 [10350/10697 ( 96.8%)] Loss: 0.027014 L1: 0.016119 Grad: 0.108732 Thermal: 0.000433 LR: 3.82e-06\n",
      "Epoch  26 [10400/10697 ( 97.2%)] Loss: 0.022395 L1: 0.012815 Grad: 0.095620 Thermal: 0.000358 LR: 3.82e-06\n",
      "Epoch  26 [10400/10697 ( 97.2%)] Loss: 0.022395 L1: 0.012815 Grad: 0.095620 Thermal: 0.000358 LR: 3.82e-06\n",
      "Epoch  26 [10450/10697 ( 97.7%)] Loss: 0.027291 L1: 0.016015 Grad: 0.112513 Thermal: 0.000502 LR: 3.82e-06\n",
      "Epoch  26 [10450/10697 ( 97.7%)] Loss: 0.027291 L1: 0.016015 Grad: 0.112513 Thermal: 0.000502 LR: 3.82e-06\n",
      "Epoch  26 [10500/10697 ( 98.2%)] Loss: 0.020290 L1: 0.011898 Grad: 0.083780 Thermal: 0.000281 LR: 3.82e-06\n",
      "Epoch  26 [10500/10697 ( 98.2%)] Loss: 0.020290 L1: 0.011898 Grad: 0.083780 Thermal: 0.000281 LR: 3.82e-06\n",
      "Epoch  26 [10550/10697 ( 98.6%)] Loss: 0.026797 L1: 0.015403 Grad: 0.113699 Thermal: 0.000486 LR: 3.82e-06\n",
      "Epoch  26 [10550/10697 ( 98.6%)] Loss: 0.026797 L1: 0.015403 Grad: 0.113699 Thermal: 0.000486 LR: 3.82e-06\n",
      "Epoch  26 [10600/10697 ( 99.1%)] Loss: 0.027269 L1: 0.015355 Grad: 0.118920 Thermal: 0.000446 LR: 3.82e-06\n",
      "Epoch  26 [10600/10697 ( 99.1%)] Loss: 0.027269 L1: 0.015355 Grad: 0.118920 Thermal: 0.000446 LR: 3.82e-06\n",
      "Epoch  26 [10650/10697 ( 99.6%)] Loss: 0.037214 L1: 0.021289 Grad: 0.158825 Thermal: 0.000847 LR: 3.82e-06\n",
      "Epoch  26 [10650/10697 ( 99.6%)] Loss: 0.037214 L1: 0.021289 Grad: 0.158825 Thermal: 0.000847 LR: 3.82e-06\n",
      "Epoch  26 Summary: Loss=0.026297 (L1:0.0153, Grad:0.1094, Thermal:0.0005) Val_PSNR=0.00dB Best=33.95dB Time=100.2min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  26 Summary: Loss=0.026297 (L1:0.0153, Grad:0.1094, Thermal:0.0005) Val_PSNR=0.00dB Best=33.95dB Time=100.2min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  27 [   0/10697 (  0.0%)] Loss: 0.026787 L1: 0.016033 Grad: 0.107314 Thermal: 0.000458 LR: 3.74e-06\n",
      "Epoch  27 [   0/10697 (  0.0%)] Loss: 0.026787 L1: 0.016033 Grad: 0.107314 Thermal: 0.000458 LR: 3.74e-06\n",
      "Epoch  27 [  50/10697 (  0.5%)] Loss: 0.026734 L1: 0.015852 Grad: 0.108578 Thermal: 0.000494 LR: 3.74e-06\n",
      "Epoch  27 [  50/10697 (  0.5%)] Loss: 0.026734 L1: 0.015852 Grad: 0.108578 Thermal: 0.000494 LR: 3.74e-06\n",
      "Epoch  27 [ 100/10697 (  0.9%)] Loss: 0.026907 L1: 0.016082 Grad: 0.108031 Thermal: 0.000451 LR: 3.74e-06\n",
      "Epoch  27 [ 100/10697 (  0.9%)] Loss: 0.026907 L1: 0.016082 Grad: 0.108031 Thermal: 0.000451 LR: 3.74e-06\n",
      "Epoch  27 [ 150/10697 (  1.4%)] Loss: 0.024939 L1: 0.014692 Grad: 0.102269 Thermal: 0.000412 LR: 3.74e-06\n",
      "Epoch  27 [ 150/10697 (  1.4%)] Loss: 0.024939 L1: 0.014692 Grad: 0.102269 Thermal: 0.000412 LR: 3.74e-06\n",
      "Epoch  27 [ 200/10697 (  1.9%)] Loss: 0.028242 L1: 0.016327 Grad: 0.118878 Thermal: 0.000538 LR: 3.74e-06\n",
      "Epoch  27 [ 200/10697 (  1.9%)] Loss: 0.028242 L1: 0.016327 Grad: 0.118878 Thermal: 0.000538 LR: 3.74e-06\n",
      "Epoch  27 [ 250/10697 (  2.3%)] Loss: 0.029096 L1: 0.016592 Grad: 0.124761 Thermal: 0.000550 LR: 3.74e-06\n",
      "Epoch  27 [ 250/10697 (  2.3%)] Loss: 0.029096 L1: 0.016592 Grad: 0.124761 Thermal: 0.000550 LR: 3.74e-06\n",
      "Epoch  27 [ 300/10697 (  2.8%)] Loss: 0.025282 L1: 0.014647 Grad: 0.106136 Thermal: 0.000435 LR: 3.74e-06\n",
      "Epoch  27 [ 300/10697 (  2.8%)] Loss: 0.025282 L1: 0.014647 Grad: 0.106136 Thermal: 0.000435 LR: 3.74e-06\n",
      "Epoch  27 [ 350/10697 (  3.3%)] Loss: 0.030592 L1: 0.017659 Grad: 0.129061 Thermal: 0.000538 LR: 3.74e-06\n",
      "Epoch  27 [ 350/10697 (  3.3%)] Loss: 0.030592 L1: 0.017659 Grad: 0.129061 Thermal: 0.000538 LR: 3.74e-06\n",
      "Epoch  27 [ 400/10697 (  3.7%)] Loss: 0.030518 L1: 0.017839 Grad: 0.126487 Thermal: 0.000623 LR: 3.74e-06\n",
      "Epoch  27 [ 400/10697 (  3.7%)] Loss: 0.030518 L1: 0.017839 Grad: 0.126487 Thermal: 0.000623 LR: 3.74e-06\n",
      "Epoch  27 [ 450/10697 (  4.2%)] Loss: 0.027796 L1: 0.016548 Grad: 0.112227 Thermal: 0.000502 LR: 3.74e-06\n",
      "Epoch  27 [ 450/10697 (  4.2%)] Loss: 0.027796 L1: 0.016548 Grad: 0.112227 Thermal: 0.000502 LR: 3.74e-06\n",
      "Epoch  27 [ 500/10697 (  4.7%)] Loss: 0.027178 L1: 0.015921 Grad: 0.112329 Thermal: 0.000469 LR: 3.74e-06\n",
      "Epoch  27 [ 500/10697 (  4.7%)] Loss: 0.027178 L1: 0.015921 Grad: 0.112329 Thermal: 0.000469 LR: 3.74e-06\n",
      "Epoch  27 [ 550/10697 (  5.1%)] Loss: 0.018844 L1: 0.011047 Grad: 0.077837 Thermal: 0.000266 LR: 3.74e-06\n",
      "Epoch  27 [ 550/10697 (  5.1%)] Loss: 0.018844 L1: 0.011047 Grad: 0.077837 Thermal: 0.000266 LR: 3.74e-06\n",
      "Epoch  27 [ 600/10697 (  5.6%)] Loss: 0.036131 L1: 0.020374 Grad: 0.157169 Thermal: 0.000795 LR: 3.74e-06\n",
      "Epoch  27 [ 600/10697 (  5.6%)] Loss: 0.036131 L1: 0.020374 Grad: 0.157169 Thermal: 0.000795 LR: 3.74e-06\n",
      "Epoch  27 [ 650/10697 (  6.1%)] Loss: 0.027098 L1: 0.016132 Grad: 0.109423 Thermal: 0.000464 LR: 3.74e-06\n",
      "Epoch  27 [ 650/10697 (  6.1%)] Loss: 0.027098 L1: 0.016132 Grad: 0.109423 Thermal: 0.000464 LR: 3.74e-06\n",
      "Epoch  27 [ 700/10697 (  6.5%)] Loss: 0.020863 L1: 0.012169 Grad: 0.086774 Thermal: 0.000333 LR: 3.74e-06\n",
      "Epoch  27 [ 700/10697 (  6.5%)] Loss: 0.020863 L1: 0.012169 Grad: 0.086774 Thermal: 0.000333 LR: 3.74e-06\n",
      "Epoch  27 [ 750/10697 (  7.0%)] Loss: 0.025619 L1: 0.014658 Grad: 0.109382 Thermal: 0.000452 LR: 3.74e-06\n",
      "Epoch  27 [ 750/10697 (  7.0%)] Loss: 0.025619 L1: 0.014658 Grad: 0.109382 Thermal: 0.000452 LR: 3.74e-06\n",
      "Epoch  27 [ 800/10697 (  7.5%)] Loss: 0.025653 L1: 0.015480 Grad: 0.101509 Thermal: 0.000450 LR: 3.74e-06\n",
      "Epoch  27 [ 800/10697 (  7.5%)] Loss: 0.025653 L1: 0.015480 Grad: 0.101509 Thermal: 0.000450 LR: 3.74e-06\n",
      "Epoch  27 [ 850/10697 (  7.9%)] Loss: 0.024154 L1: 0.014036 Grad: 0.100968 Thermal: 0.000415 LR: 3.74e-06\n",
      "Epoch  27 [ 850/10697 (  7.9%)] Loss: 0.024154 L1: 0.014036 Grad: 0.100968 Thermal: 0.000415 LR: 3.74e-06\n",
      "Epoch  27 [ 900/10697 (  8.4%)] Loss: 0.025353 L1: 0.014929 Grad: 0.104045 Thermal: 0.000390 LR: 3.74e-06\n",
      "Epoch  27 [ 900/10697 (  8.4%)] Loss: 0.025353 L1: 0.014929 Grad: 0.104045 Thermal: 0.000390 LR: 3.74e-06\n",
      "Epoch  27 [ 950/10697 (  8.9%)] Loss: 0.028132 L1: 0.016557 Grad: 0.115496 Thermal: 0.000515 LR: 3.74e-06\n",
      "Epoch  27 [ 950/10697 (  8.9%)] Loss: 0.028132 L1: 0.016557 Grad: 0.115496 Thermal: 0.000515 LR: 3.74e-06\n",
      "Epoch  27 [1000/10697 (  9.3%)] Loss: 0.033791 L1: 0.019255 Grad: 0.144988 Thermal: 0.000734 LR: 3.74e-06\n",
      "Epoch  27 [1000/10697 (  9.3%)] Loss: 0.033791 L1: 0.019255 Grad: 0.144988 Thermal: 0.000734 LR: 3.74e-06\n",
      "Epoch  27 [1050/10697 (  9.8%)] Loss: 0.024588 L1: 0.014607 Grad: 0.099606 Thermal: 0.000409 LR: 3.74e-06\n",
      "Epoch  27 [1050/10697 (  9.8%)] Loss: 0.024588 L1: 0.014607 Grad: 0.099606 Thermal: 0.000409 LR: 3.74e-06\n",
      "Epoch  27 [1100/10697 ( 10.3%)] Loss: 0.024636 L1: 0.014889 Grad: 0.097276 Thermal: 0.000399 LR: 3.74e-06\n",
      "Epoch  27 [1100/10697 ( 10.3%)] Loss: 0.024636 L1: 0.014889 Grad: 0.097276 Thermal: 0.000399 LR: 3.74e-06\n",
      "Epoch  27 [1150/10697 ( 10.8%)] Loss: 0.024923 L1: 0.014411 Grad: 0.104937 Thermal: 0.000378 LR: 3.74e-06\n",
      "Epoch  27 [1150/10697 ( 10.8%)] Loss: 0.024923 L1: 0.014411 Grad: 0.104937 Thermal: 0.000378 LR: 3.74e-06\n",
      "Epoch  27 [1200/10697 ( 11.2%)] Loss: 0.025128 L1: 0.014328 Grad: 0.107797 Thermal: 0.000407 LR: 3.74e-06\n",
      "Epoch  27 [1200/10697 ( 11.2%)] Loss: 0.025128 L1: 0.014328 Grad: 0.107797 Thermal: 0.000407 LR: 3.74e-06\n",
      "Epoch  27 [1250/10697 ( 11.7%)] Loss: 0.022221 L1: 0.013155 Grad: 0.090484 Thermal: 0.000354 LR: 3.74e-06\n",
      "Epoch  27 [1250/10697 ( 11.7%)] Loss: 0.022221 L1: 0.013155 Grad: 0.090484 Thermal: 0.000354 LR: 3.74e-06\n",
      "Epoch  27 [1300/10697 ( 12.2%)] Loss: 0.033107 L1: 0.019005 Grad: 0.140664 Thermal: 0.000716 LR: 3.74e-06\n",
      "Epoch  27 [1300/10697 ( 12.2%)] Loss: 0.033107 L1: 0.019005 Grad: 0.140664 Thermal: 0.000716 LR: 3.74e-06\n",
      "Epoch  27 [1350/10697 ( 12.6%)] Loss: 0.017989 L1: 0.010213 Grad: 0.077642 Thermal: 0.000240 LR: 3.74e-06\n",
      "Epoch  27 [1350/10697 ( 12.6%)] Loss: 0.017989 L1: 0.010213 Grad: 0.077642 Thermal: 0.000240 LR: 3.74e-06\n",
      "Epoch  27 [1400/10697 ( 13.1%)] Loss: 0.027018 L1: 0.016350 Grad: 0.106432 Thermal: 0.000480 LR: 3.74e-06\n",
      "Epoch  27 [1400/10697 ( 13.1%)] Loss: 0.027018 L1: 0.016350 Grad: 0.106432 Thermal: 0.000480 LR: 3.74e-06\n",
      "Epoch  27 [1450/10697 ( 13.6%)] Loss: 0.025651 L1: 0.014835 Grad: 0.107952 Thermal: 0.000410 LR: 3.74e-06\n",
      "Epoch  27 [1450/10697 ( 13.6%)] Loss: 0.025651 L1: 0.014835 Grad: 0.107952 Thermal: 0.000410 LR: 3.74e-06\n",
      "Epoch  27 [1500/10697 ( 14.0%)] Loss: 0.027806 L1: 0.016438 Grad: 0.113410 Thermal: 0.000543 LR: 3.74e-06\n",
      "Epoch  27 [1500/10697 ( 14.0%)] Loss: 0.027806 L1: 0.016438 Grad: 0.113410 Thermal: 0.000543 LR: 3.74e-06\n",
      "Epoch  27 [1550/10697 ( 14.5%)] Loss: 0.027744 L1: 0.016266 Grad: 0.114497 Thermal: 0.000552 LR: 3.74e-06\n",
      "Epoch  27 [1550/10697 ( 14.5%)] Loss: 0.027744 L1: 0.016266 Grad: 0.114497 Thermal: 0.000552 LR: 3.74e-06\n",
      "Epoch  27 [1600/10697 ( 15.0%)] Loss: 0.027114 L1: 0.015957 Grad: 0.111346 Thermal: 0.000457 LR: 3.74e-06\n",
      "Epoch  27 [1600/10697 ( 15.0%)] Loss: 0.027114 L1: 0.015957 Grad: 0.111346 Thermal: 0.000457 LR: 3.74e-06\n",
      "Epoch  27 [1650/10697 ( 15.4%)] Loss: 0.023454 L1: 0.013986 Grad: 0.094468 Thermal: 0.000410 LR: 3.74e-06\n",
      "Epoch  27 [1650/10697 ( 15.4%)] Loss: 0.023454 L1: 0.013986 Grad: 0.094468 Thermal: 0.000410 LR: 3.74e-06\n",
      "Epoch  27 [1700/10697 ( 15.9%)] Loss: 0.026984 L1: 0.016061 Grad: 0.109014 Thermal: 0.000449 LR: 3.74e-06\n",
      "Epoch  27 [1700/10697 ( 15.9%)] Loss: 0.026984 L1: 0.016061 Grad: 0.109014 Thermal: 0.000449 LR: 3.74e-06\n",
      "Epoch  27 [1750/10697 ( 16.4%)] Loss: 0.031216 L1: 0.018171 Grad: 0.130147 Thermal: 0.000615 LR: 3.74e-06\n",
      "Epoch  27 [1750/10697 ( 16.4%)] Loss: 0.031216 L1: 0.018171 Grad: 0.130147 Thermal: 0.000615 LR: 3.74e-06\n",
      "Epoch  27 [1800/10697 ( 16.8%)] Loss: 0.023561 L1: 0.013729 Grad: 0.098146 Thermal: 0.000336 LR: 3.74e-06\n",
      "Epoch  27 [1800/10697 ( 16.8%)] Loss: 0.023561 L1: 0.013729 Grad: 0.098146 Thermal: 0.000336 LR: 3.74e-06\n",
      "Epoch  27 [1850/10697 ( 17.3%)] Loss: 0.029904 L1: 0.017367 Grad: 0.125083 Thermal: 0.000568 LR: 3.74e-06\n",
      "Epoch  27 [1850/10697 ( 17.3%)] Loss: 0.029904 L1: 0.017367 Grad: 0.125083 Thermal: 0.000568 LR: 3.74e-06\n",
      "Epoch  27 [1900/10697 ( 17.8%)] Loss: 0.019427 L1: 0.011185 Grad: 0.082284 Thermal: 0.000283 LR: 3.74e-06\n",
      "Epoch  27 [1900/10697 ( 17.8%)] Loss: 0.019427 L1: 0.011185 Grad: 0.082284 Thermal: 0.000283 LR: 3.74e-06\n",
      "Epoch  27 [1950/10697 ( 18.2%)] Loss: 0.022573 L1: 0.012771 Grad: 0.097849 Thermal: 0.000325 LR: 3.74e-06\n",
      "Epoch  27 [1950/10697 ( 18.2%)] Loss: 0.022573 L1: 0.012771 Grad: 0.097849 Thermal: 0.000325 LR: 3.74e-06\n",
      "Epoch  27 [2000/10697 ( 18.7%)] Loss: 0.028230 L1: 0.016509 Grad: 0.116915 Thermal: 0.000582 LR: 3.74e-06\n",
      "Epoch  27 [2000/10697 ( 18.7%)] Loss: 0.028230 L1: 0.016509 Grad: 0.116915 Thermal: 0.000582 LR: 3.74e-06\n",
      "Epoch  27 [2050/10697 ( 19.2%)] Loss: 0.029124 L1: 0.016882 Grad: 0.122163 Thermal: 0.000518 LR: 3.74e-06\n",
      "Epoch  27 [2050/10697 ( 19.2%)] Loss: 0.029124 L1: 0.016882 Grad: 0.122163 Thermal: 0.000518 LR: 3.74e-06\n",
      "Epoch  27 [2100/10697 ( 19.6%)] Loss: 0.029095 L1: 0.016817 Grad: 0.122474 Thermal: 0.000610 LR: 3.74e-06\n",
      "Epoch  27 [2100/10697 ( 19.6%)] Loss: 0.029095 L1: 0.016817 Grad: 0.122474 Thermal: 0.000610 LR: 3.74e-06\n",
      "Epoch  27 [2150/10697 ( 20.1%)] Loss: 0.021560 L1: 0.012183 Grad: 0.093610 Thermal: 0.000324 LR: 3.74e-06\n",
      "Epoch  27 [2150/10697 ( 20.1%)] Loss: 0.021560 L1: 0.012183 Grad: 0.093610 Thermal: 0.000324 LR: 3.74e-06\n",
      "Epoch  27 [2200/10697 ( 20.6%)] Loss: 0.026985 L1: 0.015605 Grad: 0.113574 Thermal: 0.000454 LR: 3.74e-06\n",
      "Epoch  27 [2200/10697 ( 20.6%)] Loss: 0.026985 L1: 0.015605 Grad: 0.113574 Thermal: 0.000454 LR: 3.74e-06\n",
      "Epoch  27 [2250/10697 ( 21.0%)] Loss: 0.026509 L1: 0.015574 Grad: 0.109107 Thermal: 0.000469 LR: 3.74e-06\n",
      "Epoch  27 [2250/10697 ( 21.0%)] Loss: 0.026509 L1: 0.015574 Grad: 0.109107 Thermal: 0.000469 LR: 3.74e-06\n",
      "Epoch  27 [2300/10697 ( 21.5%)] Loss: 0.031179 L1: 0.018045 Grad: 0.131030 Thermal: 0.000625 LR: 3.74e-06\n",
      "Epoch  27 [2300/10697 ( 21.5%)] Loss: 0.031179 L1: 0.018045 Grad: 0.131030 Thermal: 0.000625 LR: 3.74e-06\n",
      "Epoch  27 [2350/10697 ( 22.0%)] Loss: 0.028112 L1: 0.016690 Grad: 0.113963 Thermal: 0.000503 LR: 3.74e-06\n",
      "Epoch  27 [2350/10697 ( 22.0%)] Loss: 0.028112 L1: 0.016690 Grad: 0.113963 Thermal: 0.000503 LR: 3.74e-06\n",
      "Epoch  27 [2400/10697 ( 22.4%)] Loss: 0.027967 L1: 0.016226 Grad: 0.117140 Thermal: 0.000549 LR: 3.74e-06\n",
      "Epoch  27 [2400/10697 ( 22.4%)] Loss: 0.027967 L1: 0.016226 Grad: 0.117140 Thermal: 0.000549 LR: 3.74e-06\n",
      "Epoch  27 [2450/10697 ( 22.9%)] Loss: 0.032883 L1: 0.019248 Grad: 0.135983 Thermal: 0.000728 LR: 3.74e-06\n",
      "Epoch  27 [2450/10697 ( 22.9%)] Loss: 0.032883 L1: 0.019248 Grad: 0.135983 Thermal: 0.000728 LR: 3.74e-06\n",
      "Epoch  27 [2500/10697 ( 23.4%)] Loss: 0.025302 L1: 0.015089 Grad: 0.101936 Thermal: 0.000388 LR: 3.74e-06\n",
      "Epoch  27 [2500/10697 ( 23.4%)] Loss: 0.025302 L1: 0.015089 Grad: 0.101936 Thermal: 0.000388 LR: 3.74e-06\n",
      "Epoch  27 [2550/10697 ( 23.8%)] Loss: 0.031960 L1: 0.018424 Grad: 0.134924 Thermal: 0.000882 LR: 3.74e-06\n",
      "Epoch  27 [2550/10697 ( 23.8%)] Loss: 0.031960 L1: 0.018424 Grad: 0.134924 Thermal: 0.000882 LR: 3.74e-06\n",
      "Epoch  27 [2600/10697 ( 24.3%)] Loss: 0.028834 L1: 0.016194 Grad: 0.126165 Thermal: 0.000485 LR: 3.74e-06\n",
      "Epoch  27 [2600/10697 ( 24.3%)] Loss: 0.028834 L1: 0.016194 Grad: 0.126165 Thermal: 0.000485 LR: 3.74e-06\n",
      "Epoch  27 [2650/10697 ( 24.8%)] Loss: 0.030286 L1: 0.017903 Grad: 0.123491 Thermal: 0.000674 LR: 3.74e-06\n",
      "Epoch  27 [2650/10697 ( 24.8%)] Loss: 0.030286 L1: 0.017903 Grad: 0.123491 Thermal: 0.000674 LR: 3.74e-06\n",
      "Epoch  27 [2700/10697 ( 25.2%)] Loss: 0.025555 L1: 0.015165 Grad: 0.103701 Thermal: 0.000409 LR: 3.74e-06\n",
      "Epoch  27 [2700/10697 ( 25.2%)] Loss: 0.025555 L1: 0.015165 Grad: 0.103701 Thermal: 0.000409 LR: 3.74e-06\n",
      "Epoch  27 [2750/10697 ( 25.7%)] Loss: 0.029786 L1: 0.017282 Grad: 0.124767 Thermal: 0.000545 LR: 3.74e-06\n",
      "Epoch  27 [2750/10697 ( 25.7%)] Loss: 0.029786 L1: 0.017282 Grad: 0.124767 Thermal: 0.000545 LR: 3.74e-06\n",
      "Epoch  27 [2800/10697 ( 26.2%)] Loss: 0.025584 L1: 0.014964 Grad: 0.105987 Thermal: 0.000423 LR: 3.74e-06\n",
      "Epoch  27 [2800/10697 ( 26.2%)] Loss: 0.025584 L1: 0.014964 Grad: 0.105987 Thermal: 0.000423 LR: 3.74e-06\n",
      "Epoch  27 [2850/10697 ( 26.6%)] Loss: 0.025064 L1: 0.014210 Grad: 0.108352 Thermal: 0.000387 LR: 3.74e-06\n",
      "Epoch  27 [2850/10697 ( 26.6%)] Loss: 0.025064 L1: 0.014210 Grad: 0.108352 Thermal: 0.000387 LR: 3.74e-06\n",
      "Epoch  27 [2900/10697 ( 27.1%)] Loss: 0.026190 L1: 0.015580 Grad: 0.105870 Thermal: 0.000448 LR: 3.74e-06\n",
      "Epoch  27 [2900/10697 ( 27.1%)] Loss: 0.026190 L1: 0.015580 Grad: 0.105870 Thermal: 0.000448 LR: 3.74e-06\n",
      "Epoch  27 [2950/10697 ( 27.6%)] Loss: 0.030605 L1: 0.018076 Grad: 0.124991 Thermal: 0.000581 LR: 3.74e-06\n",
      "Epoch  27 [2950/10697 ( 27.6%)] Loss: 0.030605 L1: 0.018076 Grad: 0.124991 Thermal: 0.000581 LR: 3.74e-06\n",
      "Epoch  27 [3000/10697 ( 28.0%)] Loss: 0.023825 L1: 0.013822 Grad: 0.099845 Thermal: 0.000360 LR: 3.74e-06\n",
      "Epoch  27 [3000/10697 ( 28.0%)] Loss: 0.023825 L1: 0.013822 Grad: 0.099845 Thermal: 0.000360 LR: 3.74e-06\n",
      "Epoch  27 [3050/10697 ( 28.5%)] Loss: 0.024379 L1: 0.013764 Grad: 0.105967 Thermal: 0.000364 LR: 3.74e-06\n",
      "Epoch  27 [3050/10697 ( 28.5%)] Loss: 0.024379 L1: 0.013764 Grad: 0.105967 Thermal: 0.000364 LR: 3.74e-06\n",
      "Epoch  27 [3100/10697 ( 29.0%)] Loss: 0.027594 L1: 0.016167 Grad: 0.114020 Thermal: 0.000492 LR: 3.74e-06\n",
      "Epoch  27 [3100/10697 ( 29.0%)] Loss: 0.027594 L1: 0.016167 Grad: 0.114020 Thermal: 0.000492 LR: 3.74e-06\n",
      "Epoch  27 [3150/10697 ( 29.4%)] Loss: 0.021574 L1: 0.012560 Grad: 0.089974 Thermal: 0.000327 LR: 3.74e-06\n",
      "Epoch  27 [3150/10697 ( 29.4%)] Loss: 0.021574 L1: 0.012560 Grad: 0.089974 Thermal: 0.000327 LR: 3.74e-06\n",
      "Epoch  27 [3200/10697 ( 29.9%)] Loss: 0.032791 L1: 0.019056 Grad: 0.137028 Thermal: 0.000644 LR: 3.74e-06\n",
      "Epoch  27 [3200/10697 ( 29.9%)] Loss: 0.032791 L1: 0.019056 Grad: 0.137028 Thermal: 0.000644 LR: 3.74e-06\n",
      "Epoch  27 [3250/10697 ( 30.4%)] Loss: 0.017904 L1: 0.009951 Grad: 0.079415 Thermal: 0.000234 LR: 3.74e-06\n",
      "Epoch  27 [3250/10697 ( 30.4%)] Loss: 0.017904 L1: 0.009951 Grad: 0.079415 Thermal: 0.000234 LR: 3.74e-06\n",
      "Epoch  27 [3300/10697 ( 30.8%)] Loss: 0.021378 L1: 0.012654 Grad: 0.087075 Thermal: 0.000340 LR: 3.74e-06\n",
      "Epoch  27 [3300/10697 ( 30.8%)] Loss: 0.021378 L1: 0.012654 Grad: 0.087075 Thermal: 0.000340 LR: 3.74e-06\n",
      "Epoch  27 [3350/10697 ( 31.3%)] Loss: 0.024173 L1: 0.014569 Grad: 0.095854 Thermal: 0.000371 LR: 3.74e-06\n",
      "Epoch  27 [3350/10697 ( 31.3%)] Loss: 0.024173 L1: 0.014569 Grad: 0.095854 Thermal: 0.000371 LR: 3.74e-06\n",
      "Epoch  27 [3400/10697 ( 31.8%)] Loss: 0.026896 L1: 0.016036 Grad: 0.108361 Thermal: 0.000473 LR: 3.74e-06\n",
      "Epoch  27 [3400/10697 ( 31.8%)] Loss: 0.026896 L1: 0.016036 Grad: 0.108361 Thermal: 0.000473 LR: 3.74e-06\n",
      "Epoch  27 [3450/10697 ( 32.3%)] Loss: 0.028493 L1: 0.016933 Grad: 0.115315 Thermal: 0.000562 LR: 3.74e-06\n",
      "Epoch  27 [3450/10697 ( 32.3%)] Loss: 0.028493 L1: 0.016933 Grad: 0.115315 Thermal: 0.000562 LR: 3.74e-06\n",
      "Epoch  27 [3500/10697 ( 32.7%)] Loss: 0.026590 L1: 0.015197 Grad: 0.113716 Thermal: 0.000427 LR: 3.74e-06\n",
      "Epoch  27 [3500/10697 ( 32.7%)] Loss: 0.026590 L1: 0.015197 Grad: 0.113716 Thermal: 0.000427 LR: 3.74e-06\n",
      "Epoch  27 [3550/10697 ( 33.2%)] Loss: 0.025931 L1: 0.015425 Grad: 0.104834 Thermal: 0.000457 LR: 3.74e-06\n",
      "Epoch  27 [3550/10697 ( 33.2%)] Loss: 0.025931 L1: 0.015425 Grad: 0.104834 Thermal: 0.000457 LR: 3.74e-06\n",
      "Epoch  27 [3600/10697 ( 33.7%)] Loss: 0.026878 L1: 0.016002 Grad: 0.108522 Thermal: 0.000493 LR: 3.74e-06\n",
      "Epoch  27 [3600/10697 ( 33.7%)] Loss: 0.026878 L1: 0.016002 Grad: 0.108522 Thermal: 0.000493 LR: 3.74e-06\n",
      "Epoch  27 [3650/10697 ( 34.1%)] Loss: 0.028194 L1: 0.016394 Grad: 0.117740 Thermal: 0.000517 LR: 3.74e-06\n",
      "Epoch  27 [3650/10697 ( 34.1%)] Loss: 0.028194 L1: 0.016394 Grad: 0.117740 Thermal: 0.000517 LR: 3.74e-06\n",
      "Epoch  27 [3700/10697 ( 34.6%)] Loss: 0.032138 L1: 0.018389 Grad: 0.137148 Thermal: 0.000678 LR: 3.74e-06\n",
      "Epoch  27 [3700/10697 ( 34.6%)] Loss: 0.032138 L1: 0.018389 Grad: 0.137148 Thermal: 0.000678 LR: 3.74e-06\n",
      "Epoch  27 [3750/10697 ( 35.1%)] Loss: 0.026659 L1: 0.015555 Grad: 0.110814 Thermal: 0.000456 LR: 3.74e-06\n",
      "Epoch  27 [3750/10697 ( 35.1%)] Loss: 0.026659 L1: 0.015555 Grad: 0.110814 Thermal: 0.000456 LR: 3.74e-06\n",
      "Epoch  27 [3800/10697 ( 35.5%)] Loss: 0.029331 L1: 0.017150 Grad: 0.121544 Thermal: 0.000522 LR: 3.74e-06\n",
      "Epoch  27 [3800/10697 ( 35.5%)] Loss: 0.029331 L1: 0.017150 Grad: 0.121544 Thermal: 0.000522 LR: 3.74e-06\n",
      "Epoch  27 [3850/10697 ( 36.0%)] Loss: 0.021391 L1: 0.012149 Grad: 0.092272 Thermal: 0.000302 LR: 3.74e-06\n",
      "Epoch  27 [3850/10697 ( 36.0%)] Loss: 0.021391 L1: 0.012149 Grad: 0.092272 Thermal: 0.000302 LR: 3.74e-06\n",
      "Epoch  27 [3900/10697 ( 36.5%)] Loss: 0.030920 L1: 0.017690 Grad: 0.132006 Thermal: 0.000601 LR: 3.74e-06\n",
      "Epoch  27 [3900/10697 ( 36.5%)] Loss: 0.030920 L1: 0.017690 Grad: 0.132006 Thermal: 0.000601 LR: 3.74e-06\n",
      "Epoch  27 [3950/10697 ( 36.9%)] Loss: 0.023434 L1: 0.013868 Grad: 0.095475 Thermal: 0.000376 LR: 3.74e-06\n",
      "Epoch  27 [3950/10697 ( 36.9%)] Loss: 0.023434 L1: 0.013868 Grad: 0.095475 Thermal: 0.000376 LR: 3.74e-06\n",
      "Epoch  27 [4000/10697 ( 37.4%)] Loss: 0.026259 L1: 0.015220 Grad: 0.110173 Thermal: 0.000443 LR: 3.74e-06\n",
      "Epoch  27 [4000/10697 ( 37.4%)] Loss: 0.026259 L1: 0.015220 Grad: 0.110173 Thermal: 0.000443 LR: 3.74e-06\n",
      "Epoch  27 [4050/10697 ( 37.9%)] Loss: 0.027325 L1: 0.015937 Grad: 0.113641 Thermal: 0.000483 LR: 3.74e-06\n",
      "Epoch  27 [4050/10697 ( 37.9%)] Loss: 0.027325 L1: 0.015937 Grad: 0.113641 Thermal: 0.000483 LR: 3.74e-06\n",
      "Epoch  27 [4100/10697 ( 38.3%)] Loss: 0.023058 L1: 0.013205 Grad: 0.098340 Thermal: 0.000384 LR: 3.74e-06\n",
      "Epoch  27 [4100/10697 ( 38.3%)] Loss: 0.023058 L1: 0.013205 Grad: 0.098340 Thermal: 0.000384 LR: 3.74e-06\n",
      "Epoch  27 [4150/10697 ( 38.8%)] Loss: 0.020345 L1: 0.011977 Grad: 0.083532 Thermal: 0.000292 LR: 3.74e-06\n",
      "Epoch  27 [4150/10697 ( 38.8%)] Loss: 0.020345 L1: 0.011977 Grad: 0.083532 Thermal: 0.000292 LR: 3.74e-06\n",
      "Epoch  27 [4200/10697 ( 39.3%)] Loss: 0.027892 L1: 0.016538 Grad: 0.113301 Thermal: 0.000496 LR: 3.74e-06\n",
      "Epoch  27 [4200/10697 ( 39.3%)] Loss: 0.027892 L1: 0.016538 Grad: 0.113301 Thermal: 0.000496 LR: 3.74e-06\n",
      "Epoch  27 [4250/10697 ( 39.7%)] Loss: 0.026355 L1: 0.015244 Grad: 0.110895 Thermal: 0.000444 LR: 3.74e-06\n",
      "Epoch  27 [4250/10697 ( 39.7%)] Loss: 0.026355 L1: 0.015244 Grad: 0.110895 Thermal: 0.000444 LR: 3.74e-06\n",
      "Epoch  27 [4300/10697 ( 40.2%)] Loss: 0.023255 L1: 0.013491 Grad: 0.097475 Thermal: 0.000345 LR: 3.74e-06\n",
      "Epoch  27 [4300/10697 ( 40.2%)] Loss: 0.023255 L1: 0.013491 Grad: 0.097475 Thermal: 0.000345 LR: 3.74e-06\n",
      "Epoch  27 [4350/10697 ( 40.7%)] Loss: 0.027578 L1: 0.016356 Grad: 0.111931 Thermal: 0.000571 LR: 3.74e-06\n",
      "Epoch  27 [4350/10697 ( 40.7%)] Loss: 0.027578 L1: 0.016356 Grad: 0.111931 Thermal: 0.000571 LR: 3.74e-06\n",
      "Epoch  27 [4400/10697 ( 41.1%)] Loss: 0.022480 L1: 0.012796 Grad: 0.096655 Thermal: 0.000384 LR: 3.74e-06\n",
      "Epoch  27 [4400/10697 ( 41.1%)] Loss: 0.022480 L1: 0.012796 Grad: 0.096655 Thermal: 0.000384 LR: 3.74e-06\n",
      "Epoch  27 [4450/10697 ( 41.6%)] Loss: 0.025415 L1: 0.014916 Grad: 0.104783 Thermal: 0.000414 LR: 3.74e-06\n",
      "Epoch  27 [4450/10697 ( 41.6%)] Loss: 0.025415 L1: 0.014916 Grad: 0.104783 Thermal: 0.000414 LR: 3.74e-06\n",
      "Epoch  27 [4500/10697 ( 42.1%)] Loss: 0.021263 L1: 0.012168 Grad: 0.090788 Thermal: 0.000326 LR: 3.74e-06\n",
      "Epoch  27 [4500/10697 ( 42.1%)] Loss: 0.021263 L1: 0.012168 Grad: 0.090788 Thermal: 0.000326 LR: 3.74e-06\n",
      "Epoch  27 [4550/10697 ( 42.5%)] Loss: 0.023000 L1: 0.013560 Grad: 0.094238 Thermal: 0.000336 LR: 3.74e-06\n",
      "Epoch  27 [4550/10697 ( 42.5%)] Loss: 0.023000 L1: 0.013560 Grad: 0.094238 Thermal: 0.000336 LR: 3.74e-06\n",
      "Epoch  27 [4600/10697 ( 43.0%)] Loss: 0.025437 L1: 0.015078 Grad: 0.103381 Thermal: 0.000422 LR: 3.74e-06\n",
      "Epoch  27 [4600/10697 ( 43.0%)] Loss: 0.025437 L1: 0.015078 Grad: 0.103381 Thermal: 0.000422 LR: 3.74e-06\n",
      "Epoch  27 [4650/10697 ( 43.5%)] Loss: 0.030270 L1: 0.017768 Grad: 0.124745 Thermal: 0.000547 LR: 3.74e-06\n",
      "Epoch  27 [4650/10697 ( 43.5%)] Loss: 0.030270 L1: 0.017768 Grad: 0.124745 Thermal: 0.000547 LR: 3.74e-06\n",
      "Epoch  27 [4700/10697 ( 43.9%)] Loss: 0.025774 L1: 0.015428 Grad: 0.103250 Thermal: 0.000416 LR: 3.74e-06\n",
      "Epoch  27 [4700/10697 ( 43.9%)] Loss: 0.025774 L1: 0.015428 Grad: 0.103250 Thermal: 0.000416 LR: 3.74e-06\n",
      "Epoch  27 [4750/10697 ( 44.4%)] Loss: 0.024461 L1: 0.014250 Grad: 0.101921 Thermal: 0.000389 LR: 3.74e-06\n",
      "Epoch  27 [4750/10697 ( 44.4%)] Loss: 0.024461 L1: 0.014250 Grad: 0.101921 Thermal: 0.000389 LR: 3.74e-06\n",
      "Epoch  27 [4800/10697 ( 44.9%)] Loss: 0.024359 L1: 0.014068 Grad: 0.102688 Thermal: 0.000441 LR: 3.74e-06\n",
      "Epoch  27 [4800/10697 ( 44.9%)] Loss: 0.024359 L1: 0.014068 Grad: 0.102688 Thermal: 0.000441 LR: 3.74e-06\n",
      "Epoch  27 [4850/10697 ( 45.3%)] Loss: 0.027253 L1: 0.016070 Grad: 0.111614 Thermal: 0.000447 LR: 3.74e-06\n",
      "Epoch  27 [4850/10697 ( 45.3%)] Loss: 0.027253 L1: 0.016070 Grad: 0.111614 Thermal: 0.000447 LR: 3.74e-06\n",
      "Epoch  27 [4900/10697 ( 45.8%)] Loss: 0.023328 L1: 0.013664 Grad: 0.096454 Thermal: 0.000376 LR: 3.74e-06\n",
      "Epoch  27 [4900/10697 ( 45.8%)] Loss: 0.023328 L1: 0.013664 Grad: 0.096454 Thermal: 0.000376 LR: 3.74e-06\n",
      "Epoch  27 [4950/10697 ( 46.3%)] Loss: 0.027277 L1: 0.015529 Grad: 0.117238 Thermal: 0.000475 LR: 3.74e-06\n",
      "Epoch  27 [4950/10697 ( 46.3%)] Loss: 0.027277 L1: 0.015529 Grad: 0.117238 Thermal: 0.000475 LR: 3.74e-06\n",
      "Epoch  27 [5000/10697 ( 46.7%)] Loss: 0.020584 L1: 0.012053 Grad: 0.085169 Thermal: 0.000300 LR: 3.74e-06\n",
      "Epoch  27 [5000/10697 ( 46.7%)] Loss: 0.020584 L1: 0.012053 Grad: 0.085169 Thermal: 0.000300 LR: 3.74e-06\n",
      "Epoch  27 [5050/10697 ( 47.2%)] Loss: 0.028112 L1: 0.016370 Grad: 0.117181 Thermal: 0.000482 LR: 3.74e-06\n",
      "Epoch  27 [5050/10697 ( 47.2%)] Loss: 0.028112 L1: 0.016370 Grad: 0.117181 Thermal: 0.000482 LR: 3.74e-06\n",
      "Epoch  27 [5100/10697 ( 47.7%)] Loss: 0.031684 L1: 0.017975 Grad: 0.136729 Thermal: 0.000713 LR: 3.74e-06\n",
      "Epoch  27 [5100/10697 ( 47.7%)] Loss: 0.031684 L1: 0.017975 Grad: 0.136729 Thermal: 0.000713 LR: 3.74e-06\n",
      "Epoch  27 [5150/10697 ( 48.1%)] Loss: 0.028487 L1: 0.016815 Grad: 0.116473 Thermal: 0.000486 LR: 3.74e-06\n",
      "Epoch  27 [5150/10697 ( 48.1%)] Loss: 0.028487 L1: 0.016815 Grad: 0.116473 Thermal: 0.000486 LR: 3.74e-06\n",
      "Epoch  27 [5200/10697 ( 48.6%)] Loss: 0.023241 L1: 0.013748 Grad: 0.094750 Thermal: 0.000365 LR: 3.74e-06\n",
      "Epoch  27 [5200/10697 ( 48.6%)] Loss: 0.023241 L1: 0.013748 Grad: 0.094750 Thermal: 0.000365 LR: 3.74e-06\n",
      "Epoch  27 [5250/10697 ( 49.1%)] Loss: 0.030659 L1: 0.017518 Grad: 0.131132 Thermal: 0.000562 LR: 3.74e-06\n",
      "Epoch  27 [5250/10697 ( 49.1%)] Loss: 0.030659 L1: 0.017518 Grad: 0.131132 Thermal: 0.000562 LR: 3.74e-06\n",
      "Epoch  27 [5300/10697 ( 49.5%)] Loss: 0.021805 L1: 0.012928 Grad: 0.088608 Thermal: 0.000327 LR: 3.74e-06\n",
      "Epoch  27 [5300/10697 ( 49.5%)] Loss: 0.021805 L1: 0.012928 Grad: 0.088608 Thermal: 0.000327 LR: 3.74e-06\n",
      "Epoch  27 [5350/10697 ( 50.0%)] Loss: 0.031793 L1: 0.018380 Grad: 0.133819 Thermal: 0.000623 LR: 3.74e-06\n",
      "Epoch  27 [5350/10697 ( 50.0%)] Loss: 0.031793 L1: 0.018380 Grad: 0.133819 Thermal: 0.000623 LR: 3.74e-06\n",
      "Epoch  27 [5400/10697 ( 50.5%)] Loss: 0.029509 L1: 0.017250 Grad: 0.122314 Thermal: 0.000545 LR: 3.74e-06\n",
      "Epoch  27 [5400/10697 ( 50.5%)] Loss: 0.029509 L1: 0.017250 Grad: 0.122314 Thermal: 0.000545 LR: 3.74e-06\n",
      "Epoch  27 [5450/10697 ( 50.9%)] Loss: 0.027137 L1: 0.016129 Grad: 0.109852 Thermal: 0.000460 LR: 3.74e-06\n",
      "Epoch  27 [5450/10697 ( 50.9%)] Loss: 0.027137 L1: 0.016129 Grad: 0.109852 Thermal: 0.000460 LR: 3.74e-06\n",
      "Epoch  27 [5500/10697 ( 51.4%)] Loss: 0.021894 L1: 0.012604 Grad: 0.092734 Thermal: 0.000343 LR: 3.74e-06\n",
      "Epoch  27 [5500/10697 ( 51.4%)] Loss: 0.021894 L1: 0.012604 Grad: 0.092734 Thermal: 0.000343 LR: 3.74e-06\n",
      "Epoch  27 [5550/10697 ( 51.9%)] Loss: 0.026295 L1: 0.014844 Grad: 0.114296 Thermal: 0.000430 LR: 3.74e-06\n",
      "Epoch  27 [5550/10697 ( 51.9%)] Loss: 0.026295 L1: 0.014844 Grad: 0.114296 Thermal: 0.000430 LR: 3.74e-06\n",
      "Epoch  27 [5600/10697 ( 52.4%)] Loss: 0.027244 L1: 0.016360 Grad: 0.108598 Thermal: 0.000470 LR: 3.74e-06\n",
      "Epoch  27 [5600/10697 ( 52.4%)] Loss: 0.027244 L1: 0.016360 Grad: 0.108598 Thermal: 0.000470 LR: 3.74e-06\n",
      "Epoch  27 [5650/10697 ( 52.8%)] Loss: 0.027754 L1: 0.016226 Grad: 0.115030 Thermal: 0.000497 LR: 3.74e-06\n",
      "Epoch  27 [5650/10697 ( 52.8%)] Loss: 0.027754 L1: 0.016226 Grad: 0.115030 Thermal: 0.000497 LR: 3.74e-06\n",
      "Epoch  27 [5700/10697 ( 53.3%)] Loss: 0.026079 L1: 0.015404 Grad: 0.106532 Thermal: 0.000427 LR: 3.74e-06\n",
      "Epoch  27 [5700/10697 ( 53.3%)] Loss: 0.026079 L1: 0.015404 Grad: 0.106532 Thermal: 0.000427 LR: 3.74e-06\n",
      "Epoch  27 [5750/10697 ( 53.8%)] Loss: 0.022569 L1: 0.013314 Grad: 0.092372 Thermal: 0.000354 LR: 3.74e-06\n",
      "Epoch  27 [5750/10697 ( 53.8%)] Loss: 0.022569 L1: 0.013314 Grad: 0.092372 Thermal: 0.000354 LR: 3.74e-06\n",
      "Epoch  27 [5800/10697 ( 54.2%)] Loss: 0.023041 L1: 0.013479 Grad: 0.095432 Thermal: 0.000363 LR: 3.74e-06\n",
      "Epoch  27 [5800/10697 ( 54.2%)] Loss: 0.023041 L1: 0.013479 Grad: 0.095432 Thermal: 0.000363 LR: 3.74e-06\n",
      "Epoch  27 [5850/10697 ( 54.7%)] Loss: 0.027484 L1: 0.016294 Grad: 0.111675 Thermal: 0.000465 LR: 3.74e-06\n",
      "Epoch  27 [5850/10697 ( 54.7%)] Loss: 0.027484 L1: 0.016294 Grad: 0.111675 Thermal: 0.000465 LR: 3.74e-06\n",
      "Epoch  27 [5900/10697 ( 55.2%)] Loss: 0.026011 L1: 0.015264 Grad: 0.107252 Thermal: 0.000436 LR: 3.74e-06\n",
      "Epoch  27 [5900/10697 ( 55.2%)] Loss: 0.026011 L1: 0.015264 Grad: 0.107252 Thermal: 0.000436 LR: 3.74e-06\n",
      "Epoch  27 [5950/10697 ( 55.6%)] Loss: 0.021542 L1: 0.012630 Grad: 0.088961 Thermal: 0.000309 LR: 3.74e-06\n",
      "Epoch  27 [5950/10697 ( 55.6%)] Loss: 0.021542 L1: 0.012630 Grad: 0.088961 Thermal: 0.000309 LR: 3.74e-06\n",
      "Epoch  27 [6000/10697 ( 56.1%)] Loss: 0.021400 L1: 0.012547 Grad: 0.088382 Thermal: 0.000295 LR: 3.74e-06\n",
      "Epoch  27 [6000/10697 ( 56.1%)] Loss: 0.021400 L1: 0.012547 Grad: 0.088382 Thermal: 0.000295 LR: 3.74e-06\n",
      "Epoch  27 [6050/10697 ( 56.6%)] Loss: 0.021106 L1: 0.011978 Grad: 0.091126 Thermal: 0.000294 LR: 3.74e-06\n",
      "Epoch  27 [6050/10697 ( 56.6%)] Loss: 0.021106 L1: 0.011978 Grad: 0.091126 Thermal: 0.000294 LR: 3.74e-06\n",
      "Epoch  27 [6100/10697 ( 57.0%)] Loss: 0.025211 L1: 0.014361 Grad: 0.108261 Thermal: 0.000470 LR: 3.74e-06\n",
      "Epoch  27 [6100/10697 ( 57.0%)] Loss: 0.025211 L1: 0.014361 Grad: 0.108261 Thermal: 0.000470 LR: 3.74e-06\n",
      "Epoch  27 [6150/10697 ( 57.5%)] Loss: 0.024696 L1: 0.014484 Grad: 0.101928 Thermal: 0.000379 LR: 3.74e-06\n",
      "Epoch  27 [6150/10697 ( 57.5%)] Loss: 0.024696 L1: 0.014484 Grad: 0.101928 Thermal: 0.000379 LR: 3.74e-06\n",
      "Epoch  27 [6200/10697 ( 58.0%)] Loss: 0.031009 L1: 0.018195 Grad: 0.127816 Thermal: 0.000649 LR: 3.74e-06\n",
      "Epoch  27 [6200/10697 ( 58.0%)] Loss: 0.031009 L1: 0.018195 Grad: 0.127816 Thermal: 0.000649 LR: 3.74e-06\n",
      "Epoch  27 [6250/10697 ( 58.4%)] Loss: 0.026924 L1: 0.015859 Grad: 0.110413 Thermal: 0.000468 LR: 3.74e-06\n",
      "Epoch  27 [6250/10697 ( 58.4%)] Loss: 0.026924 L1: 0.015859 Grad: 0.110413 Thermal: 0.000468 LR: 3.74e-06\n",
      "Epoch  27 [6300/10697 ( 58.9%)] Loss: 0.026408 L1: 0.015516 Grad: 0.108698 Thermal: 0.000444 LR: 3.74e-06\n",
      "Epoch  27 [6300/10697 ( 58.9%)] Loss: 0.026408 L1: 0.015516 Grad: 0.108698 Thermal: 0.000444 LR: 3.74e-06\n",
      "Epoch  27 [6350/10697 ( 59.4%)] Loss: 0.024342 L1: 0.014001 Grad: 0.103201 Thermal: 0.000416 LR: 3.74e-06\n",
      "Epoch  27 [6350/10697 ( 59.4%)] Loss: 0.024342 L1: 0.014001 Grad: 0.103201 Thermal: 0.000416 LR: 3.74e-06\n",
      "Epoch  27 [6400/10697 ( 59.8%)] Loss: 0.028372 L1: 0.016473 Grad: 0.118630 Thermal: 0.000728 LR: 3.74e-06\n",
      "Epoch  27 [6400/10697 ( 59.8%)] Loss: 0.028372 L1: 0.016473 Grad: 0.118630 Thermal: 0.000728 LR: 3.74e-06\n",
      "Epoch  27 [6450/10697 ( 60.3%)] Loss: 0.022960 L1: 0.013649 Grad: 0.092930 Thermal: 0.000374 LR: 3.74e-06\n",
      "Epoch  27 [6450/10697 ( 60.3%)] Loss: 0.022960 L1: 0.013649 Grad: 0.092930 Thermal: 0.000374 LR: 3.74e-06\n",
      "Epoch  27 [6500/10697 ( 60.8%)] Loss: 0.026077 L1: 0.015488 Grad: 0.105664 Thermal: 0.000448 LR: 3.74e-06\n",
      "Epoch  27 [6500/10697 ( 60.8%)] Loss: 0.026077 L1: 0.015488 Grad: 0.105664 Thermal: 0.000448 LR: 3.74e-06\n",
      "Epoch  27 [6550/10697 ( 61.2%)] Loss: 0.026632 L1: 0.015171 Grad: 0.114385 Thermal: 0.000463 LR: 3.74e-06\n",
      "Epoch  27 [6550/10697 ( 61.2%)] Loss: 0.026632 L1: 0.015171 Grad: 0.114385 Thermal: 0.000463 LR: 3.74e-06\n",
      "Epoch  27 [6600/10697 ( 61.7%)] Loss: 0.025878 L1: 0.015378 Grad: 0.104777 Thermal: 0.000431 LR: 3.74e-06\n",
      "Epoch  27 [6600/10697 ( 61.7%)] Loss: 0.025878 L1: 0.015378 Grad: 0.104777 Thermal: 0.000431 LR: 3.74e-06\n",
      "Epoch  27 [6650/10697 ( 62.2%)] Loss: 0.027806 L1: 0.016209 Grad: 0.115707 Thermal: 0.000524 LR: 3.74e-06\n",
      "Epoch  27 [6650/10697 ( 62.2%)] Loss: 0.027806 L1: 0.016209 Grad: 0.115707 Thermal: 0.000524 LR: 3.74e-06\n",
      "Epoch  27 [6700/10697 ( 62.6%)] Loss: 0.025481 L1: 0.015197 Grad: 0.102621 Thermal: 0.000433 LR: 3.74e-06\n",
      "Epoch  27 [6700/10697 ( 62.6%)] Loss: 0.025481 L1: 0.015197 Grad: 0.102621 Thermal: 0.000433 LR: 3.74e-06\n",
      "Epoch  27 [6750/10697 ( 63.1%)] Loss: 0.023935 L1: 0.013639 Grad: 0.102778 Thermal: 0.000369 LR: 3.74e-06\n",
      "Epoch  27 [6750/10697 ( 63.1%)] Loss: 0.023935 L1: 0.013639 Grad: 0.102778 Thermal: 0.000369 LR: 3.74e-06\n",
      "Epoch  27 [6800/10697 ( 63.6%)] Loss: 0.026031 L1: 0.015894 Grad: 0.101144 Thermal: 0.000447 LR: 3.74e-06\n",
      "Epoch  27 [6800/10697 ( 63.6%)] Loss: 0.026031 L1: 0.015894 Grad: 0.101144 Thermal: 0.000447 LR: 3.74e-06\n",
      "Epoch  27 [6850/10697 ( 64.0%)] Loss: 0.024656 L1: 0.014089 Grad: 0.105435 Thermal: 0.000466 LR: 3.74e-06\n",
      "Epoch  27 [6850/10697 ( 64.0%)] Loss: 0.024656 L1: 0.014089 Grad: 0.105435 Thermal: 0.000466 LR: 3.74e-06\n",
      "Epoch  27 [6900/10697 ( 64.5%)] Loss: 0.030532 L1: 0.017280 Grad: 0.132243 Thermal: 0.000551 LR: 3.74e-06\n",
      "Epoch  27 [6900/10697 ( 64.5%)] Loss: 0.030532 L1: 0.017280 Grad: 0.132243 Thermal: 0.000551 LR: 3.74e-06\n",
      "Epoch  27 [6950/10697 ( 65.0%)] Loss: 0.029681 L1: 0.017327 Grad: 0.123269 Thermal: 0.000530 LR: 3.74e-06\n",
      "Epoch  27 [6950/10697 ( 65.0%)] Loss: 0.029681 L1: 0.017327 Grad: 0.123269 Thermal: 0.000530 LR: 3.74e-06\n",
      "Epoch  27 [7000/10697 ( 65.4%)] Loss: 0.029630 L1: 0.017288 Grad: 0.123134 Thermal: 0.000581 LR: 3.74e-06\n",
      "Epoch  27 [7000/10697 ( 65.4%)] Loss: 0.029630 L1: 0.017288 Grad: 0.123134 Thermal: 0.000581 LR: 3.74e-06\n",
      "Epoch  27 [7050/10697 ( 65.9%)] Loss: 0.028854 L1: 0.016526 Grad: 0.123021 Thermal: 0.000525 LR: 3.74e-06\n",
      "Epoch  27 [7050/10697 ( 65.9%)] Loss: 0.028854 L1: 0.016526 Grad: 0.123021 Thermal: 0.000525 LR: 3.74e-06\n",
      "Epoch  27 [7100/10697 ( 66.4%)] Loss: 0.025737 L1: 0.015298 Grad: 0.104176 Thermal: 0.000417 LR: 3.74e-06\n",
      "Epoch  27 [7100/10697 ( 66.4%)] Loss: 0.025737 L1: 0.015298 Grad: 0.104176 Thermal: 0.000417 LR: 3.74e-06\n",
      "Epoch  27 [7150/10697 ( 66.8%)] Loss: 0.028723 L1: 0.016577 Grad: 0.121215 Thermal: 0.000485 LR: 3.74e-06\n",
      "Epoch  27 [7150/10697 ( 66.8%)] Loss: 0.028723 L1: 0.016577 Grad: 0.121215 Thermal: 0.000485 LR: 3.74e-06\n",
      "Epoch  27 [7200/10697 ( 67.3%)] Loss: 0.032890 L1: 0.018741 Grad: 0.141122 Thermal: 0.000744 LR: 3.74e-06\n",
      "Epoch  27 [7200/10697 ( 67.3%)] Loss: 0.032890 L1: 0.018741 Grad: 0.141122 Thermal: 0.000744 LR: 3.74e-06\n",
      "Epoch  27 [7250/10697 ( 67.8%)] Loss: 0.024630 L1: 0.014657 Grad: 0.099528 Thermal: 0.000417 LR: 3.74e-06\n",
      "Epoch  27 [7250/10697 ( 67.8%)] Loss: 0.024630 L1: 0.014657 Grad: 0.099528 Thermal: 0.000417 LR: 3.74e-06\n",
      "Epoch  27 [7300/10697 ( 68.2%)] Loss: 0.023502 L1: 0.013782 Grad: 0.097008 Thermal: 0.000379 LR: 3.74e-06\n",
      "Epoch  27 [7300/10697 ( 68.2%)] Loss: 0.023502 L1: 0.013782 Grad: 0.097008 Thermal: 0.000379 LR: 3.74e-06\n",
      "Epoch  27 [7350/10697 ( 68.7%)] Loss: 0.025092 L1: 0.014769 Grad: 0.103019 Thermal: 0.000423 LR: 3.74e-06\n",
      "Epoch  27 [7350/10697 ( 68.7%)] Loss: 0.025092 L1: 0.014769 Grad: 0.103019 Thermal: 0.000423 LR: 3.74e-06\n",
      "Epoch  27 [7400/10697 ( 69.2%)] Loss: 0.025852 L1: 0.015711 Grad: 0.101180 Thermal: 0.000450 LR: 3.74e-06\n",
      "Epoch  27 [7400/10697 ( 69.2%)] Loss: 0.025852 L1: 0.015711 Grad: 0.101180 Thermal: 0.000450 LR: 3.74e-06\n",
      "Epoch  27 [7450/10697 ( 69.6%)] Loss: 0.026142 L1: 0.015280 Grad: 0.108391 Thermal: 0.000465 LR: 3.74e-06\n",
      "Epoch  27 [7450/10697 ( 69.6%)] Loss: 0.026142 L1: 0.015280 Grad: 0.108391 Thermal: 0.000465 LR: 3.74e-06\n",
      "Epoch  27 [7500/10697 ( 70.1%)] Loss: 0.025952 L1: 0.015406 Grad: 0.105240 Thermal: 0.000443 LR: 3.74e-06\n",
      "Epoch  27 [7500/10697 ( 70.1%)] Loss: 0.025952 L1: 0.015406 Grad: 0.105240 Thermal: 0.000443 LR: 3.74e-06\n",
      "Epoch  27 [7550/10697 ( 70.6%)] Loss: 0.026629 L1: 0.015830 Grad: 0.107768 Thermal: 0.000445 LR: 3.74e-06\n",
      "Epoch  27 [7550/10697 ( 70.6%)] Loss: 0.026629 L1: 0.015830 Grad: 0.107768 Thermal: 0.000445 LR: 3.74e-06\n",
      "Epoch  27 [7600/10697 ( 71.0%)] Loss: 0.025269 L1: 0.014686 Grad: 0.105614 Thermal: 0.000421 LR: 3.74e-06\n",
      "Epoch  27 [7600/10697 ( 71.0%)] Loss: 0.025269 L1: 0.014686 Grad: 0.105614 Thermal: 0.000421 LR: 3.74e-06\n",
      "Epoch  27 [7650/10697 ( 71.5%)] Loss: 0.024018 L1: 0.013821 Grad: 0.101793 Thermal: 0.000349 LR: 3.74e-06\n",
      "Epoch  27 [7650/10697 ( 71.5%)] Loss: 0.024018 L1: 0.013821 Grad: 0.101793 Thermal: 0.000349 LR: 3.74e-06\n",
      "Epoch  27 [7700/10697 ( 72.0%)] Loss: 0.031794 L1: 0.018184 Grad: 0.135792 Thermal: 0.000629 LR: 3.74e-06\n",
      "Epoch  27 [7700/10697 ( 72.0%)] Loss: 0.031794 L1: 0.018184 Grad: 0.135792 Thermal: 0.000629 LR: 3.74e-06\n",
      "Epoch  27 [7750/10697 ( 72.5%)] Loss: 0.029991 L1: 0.017683 Grad: 0.122801 Thermal: 0.000569 LR: 3.74e-06\n",
      "Epoch  27 [7750/10697 ( 72.5%)] Loss: 0.029991 L1: 0.017683 Grad: 0.122801 Thermal: 0.000569 LR: 3.74e-06\n",
      "Epoch  27 [7800/10697 ( 72.9%)] Loss: 0.025763 L1: 0.015051 Grad: 0.106888 Thermal: 0.000463 LR: 3.74e-06\n",
      "Epoch  27 [7800/10697 ( 72.9%)] Loss: 0.025763 L1: 0.015051 Grad: 0.106888 Thermal: 0.000463 LR: 3.74e-06\n",
      "Epoch  27 [7850/10697 ( 73.4%)] Loss: 0.026995 L1: 0.015397 Grad: 0.115732 Thermal: 0.000495 LR: 3.74e-06\n",
      "Epoch  27 [7850/10697 ( 73.4%)] Loss: 0.026995 L1: 0.015397 Grad: 0.115732 Thermal: 0.000495 LR: 3.74e-06\n",
      "Epoch  27 [7900/10697 ( 73.9%)] Loss: 0.025269 L1: 0.015051 Grad: 0.101974 Thermal: 0.000420 LR: 3.74e-06\n",
      "Epoch  27 [7900/10697 ( 73.9%)] Loss: 0.025269 L1: 0.015051 Grad: 0.101974 Thermal: 0.000420 LR: 3.74e-06\n",
      "Epoch  27 [7950/10697 ( 74.3%)] Loss: 0.026613 L1: 0.015863 Grad: 0.107253 Thermal: 0.000493 LR: 3.74e-06\n",
      "Epoch  27 [7950/10697 ( 74.3%)] Loss: 0.026613 L1: 0.015863 Grad: 0.107253 Thermal: 0.000493 LR: 3.74e-06\n",
      "Epoch  27 [8000/10697 ( 74.8%)] Loss: 0.029533 L1: 0.017002 Grad: 0.125040 Thermal: 0.000542 LR: 3.74e-06\n",
      "Epoch  27 [8000/10697 ( 74.8%)] Loss: 0.029533 L1: 0.017002 Grad: 0.125040 Thermal: 0.000542 LR: 3.74e-06\n",
      "Epoch  27 [8050/10697 ( 75.3%)] Loss: 0.028447 L1: 0.016669 Grad: 0.117542 Thermal: 0.000478 LR: 3.74e-06\n",
      "Epoch  27 [8050/10697 ( 75.3%)] Loss: 0.028447 L1: 0.016669 Grad: 0.117542 Thermal: 0.000478 LR: 3.74e-06\n",
      "Epoch  27 [8100/10697 ( 75.7%)] Loss: 0.025283 L1: 0.015126 Grad: 0.101359 Thermal: 0.000418 LR: 3.74e-06\n",
      "Epoch  27 [8100/10697 ( 75.7%)] Loss: 0.025283 L1: 0.015126 Grad: 0.101359 Thermal: 0.000418 LR: 3.74e-06\n",
      "Epoch  27 [8150/10697 ( 76.2%)] Loss: 0.027522 L1: 0.016250 Grad: 0.112465 Thermal: 0.000502 LR: 3.74e-06\n",
      "Epoch  27 [8150/10697 ( 76.2%)] Loss: 0.027522 L1: 0.016250 Grad: 0.112465 Thermal: 0.000502 LR: 3.74e-06\n",
      "Epoch  27 [8200/10697 ( 76.7%)] Loss: 0.033836 L1: 0.019235 Grad: 0.145653 Thermal: 0.000731 LR: 3.74e-06\n",
      "Epoch  27 [8200/10697 ( 76.7%)] Loss: 0.033836 L1: 0.019235 Grad: 0.145653 Thermal: 0.000731 LR: 3.74e-06\n",
      "Epoch  27 [8250/10697 ( 77.1%)] Loss: 0.025428 L1: 0.014996 Grad: 0.104109 Thermal: 0.000427 LR: 3.74e-06\n",
      "Epoch  27 [8250/10697 ( 77.1%)] Loss: 0.025428 L1: 0.014996 Grad: 0.104109 Thermal: 0.000427 LR: 3.74e-06\n",
      "Epoch  27 [8300/10697 ( 77.6%)] Loss: 0.026688 L1: 0.015829 Grad: 0.108374 Thermal: 0.000439 LR: 3.74e-06\n",
      "Epoch  27 [8300/10697 ( 77.6%)] Loss: 0.026688 L1: 0.015829 Grad: 0.108374 Thermal: 0.000439 LR: 3.74e-06\n",
      "Epoch  27 [8350/10697 ( 78.1%)] Loss: 0.029870 L1: 0.017412 Grad: 0.124314 Thermal: 0.000529 LR: 3.74e-06\n",
      "Epoch  27 [8350/10697 ( 78.1%)] Loss: 0.029870 L1: 0.017412 Grad: 0.124314 Thermal: 0.000529 LR: 3.74e-06\n",
      "Epoch  27 [8400/10697 ( 78.5%)] Loss: 0.025882 L1: 0.015544 Grad: 0.103162 Thermal: 0.000440 LR: 3.74e-06\n",
      "Epoch  27 [8400/10697 ( 78.5%)] Loss: 0.025882 L1: 0.015544 Grad: 0.103162 Thermal: 0.000440 LR: 3.74e-06\n",
      "Epoch  27 [8450/10697 ( 79.0%)] Loss: 0.035081 L1: 0.020627 Grad: 0.144093 Thermal: 0.000895 LR: 3.74e-06\n",
      "Epoch  27 [8450/10697 ( 79.0%)] Loss: 0.035081 L1: 0.020627 Grad: 0.144093 Thermal: 0.000895 LR: 3.74e-06\n",
      "Epoch  27 [8500/10697 ( 79.5%)] Loss: 0.027257 L1: 0.015864 Grad: 0.113686 Thermal: 0.000478 LR: 3.74e-06\n",
      "Epoch  27 [8500/10697 ( 79.5%)] Loss: 0.027257 L1: 0.015864 Grad: 0.113686 Thermal: 0.000478 LR: 3.74e-06\n",
      "Epoch  27 [8550/10697 ( 79.9%)] Loss: 0.025205 L1: 0.014913 Grad: 0.102715 Thermal: 0.000417 LR: 3.74e-06\n",
      "Epoch  27 [8550/10697 ( 79.9%)] Loss: 0.025205 L1: 0.014913 Grad: 0.102715 Thermal: 0.000417 LR: 3.74e-06\n",
      "Epoch  27 [8600/10697 ( 80.4%)] Loss: 0.027597 L1: 0.016329 Grad: 0.112439 Thermal: 0.000479 LR: 3.74e-06\n",
      "Epoch  27 [8600/10697 ( 80.4%)] Loss: 0.027597 L1: 0.016329 Grad: 0.112439 Thermal: 0.000479 LR: 3.74e-06\n",
      "Epoch  27 [8650/10697 ( 80.9%)] Loss: 0.029149 L1: 0.017069 Grad: 0.120475 Thermal: 0.000655 LR: 3.74e-06\n",
      "Epoch  27 [8650/10697 ( 80.9%)] Loss: 0.029149 L1: 0.017069 Grad: 0.120475 Thermal: 0.000655 LR: 3.74e-06\n",
      "Epoch  27 [8700/10697 ( 81.3%)] Loss: 0.029909 L1: 0.017774 Grad: 0.121060 Thermal: 0.000575 LR: 3.74e-06\n",
      "Epoch  27 [8700/10697 ( 81.3%)] Loss: 0.029909 L1: 0.017774 Grad: 0.121060 Thermal: 0.000575 LR: 3.74e-06\n",
      "Epoch  27 [8750/10697 ( 81.8%)] Loss: 0.028926 L1: 0.017375 Grad: 0.115250 Thermal: 0.000525 LR: 3.74e-06\n",
      "Epoch  27 [8750/10697 ( 81.8%)] Loss: 0.028926 L1: 0.017375 Grad: 0.115250 Thermal: 0.000525 LR: 3.74e-06\n",
      "Epoch  27 [8800/10697 ( 82.3%)] Loss: 0.026270 L1: 0.015197 Grad: 0.110500 Thermal: 0.000460 LR: 3.74e-06\n",
      "Epoch  27 [8800/10697 ( 82.3%)] Loss: 0.026270 L1: 0.015197 Grad: 0.110500 Thermal: 0.000460 LR: 3.74e-06\n",
      "Epoch  27 [8850/10697 ( 82.7%)] Loss: 0.024912 L1: 0.014601 Grad: 0.102901 Thermal: 0.000402 LR: 3.74e-06\n",
      "Epoch  27 [8850/10697 ( 82.7%)] Loss: 0.024912 L1: 0.014601 Grad: 0.102901 Thermal: 0.000402 LR: 3.74e-06\n",
      "Epoch  27 [8900/10697 ( 83.2%)] Loss: 0.023950 L1: 0.013697 Grad: 0.102339 Thermal: 0.000375 LR: 3.74e-06\n",
      "Epoch  27 [8900/10697 ( 83.2%)] Loss: 0.023950 L1: 0.013697 Grad: 0.102339 Thermal: 0.000375 LR: 3.74e-06\n",
      "Epoch  27 [8950/10697 ( 83.7%)] Loss: 0.030253 L1: 0.017749 Grad: 0.124753 Thermal: 0.000585 LR: 3.74e-06\n",
      "Epoch  27 [8950/10697 ( 83.7%)] Loss: 0.030253 L1: 0.017749 Grad: 0.124753 Thermal: 0.000585 LR: 3.74e-06\n",
      "Epoch  27 [9000/10697 ( 84.1%)] Loss: 0.025061 L1: 0.014295 Grad: 0.107451 Thermal: 0.000422 LR: 3.74e-06\n",
      "Epoch  27 [9000/10697 ( 84.1%)] Loss: 0.025061 L1: 0.014295 Grad: 0.107451 Thermal: 0.000422 LR: 3.74e-06\n",
      "Epoch  27 [9050/10697 ( 84.6%)] Loss: 0.027781 L1: 0.016486 Grad: 0.112694 Thermal: 0.000494 LR: 3.74e-06\n",
      "Epoch  27 [9050/10697 ( 84.6%)] Loss: 0.027781 L1: 0.016486 Grad: 0.112694 Thermal: 0.000494 LR: 3.74e-06\n",
      "Epoch  27 [9100/10697 ( 85.1%)] Loss: 0.027203 L1: 0.016132 Grad: 0.110458 Thermal: 0.000503 LR: 3.74e-06\n",
      "Epoch  27 [9100/10697 ( 85.1%)] Loss: 0.027203 L1: 0.016132 Grad: 0.110458 Thermal: 0.000503 LR: 3.74e-06\n",
      "Epoch  27 [9150/10697 ( 85.5%)] Loss: 0.032053 L1: 0.018476 Grad: 0.135476 Thermal: 0.000596 LR: 3.74e-06\n",
      "Epoch  27 [9150/10697 ( 85.5%)] Loss: 0.032053 L1: 0.018476 Grad: 0.135476 Thermal: 0.000596 LR: 3.74e-06\n",
      "Epoch  27 [9200/10697 ( 86.0%)] Loss: 0.026440 L1: 0.015671 Grad: 0.107473 Thermal: 0.000423 LR: 3.74e-06\n",
      "Epoch  27 [9200/10697 ( 86.0%)] Loss: 0.026440 L1: 0.015671 Grad: 0.107473 Thermal: 0.000423 LR: 3.74e-06\n",
      "Epoch  27 [9250/10697 ( 86.5%)] Loss: 0.026023 L1: 0.015345 Grad: 0.106567 Thermal: 0.000422 LR: 3.74e-06\n",
      "Epoch  27 [9250/10697 ( 86.5%)] Loss: 0.026023 L1: 0.015345 Grad: 0.106567 Thermal: 0.000422 LR: 3.74e-06\n",
      "Epoch  27 [9300/10697 ( 86.9%)] Loss: 0.023460 L1: 0.013269 Grad: 0.101740 Thermal: 0.000351 LR: 3.74e-06\n",
      "Epoch  27 [9300/10697 ( 86.9%)] Loss: 0.023460 L1: 0.013269 Grad: 0.101740 Thermal: 0.000351 LR: 3.74e-06\n",
      "Epoch  27 [9350/10697 ( 87.4%)] Loss: 0.028369 L1: 0.016292 Grad: 0.120526 Thermal: 0.000480 LR: 3.74e-06\n",
      "Epoch  27 [9350/10697 ( 87.4%)] Loss: 0.028369 L1: 0.016292 Grad: 0.120526 Thermal: 0.000480 LR: 3.74e-06\n",
      "Epoch  27 [9400/10697 ( 87.9%)] Loss: 0.026607 L1: 0.015693 Grad: 0.108911 Thermal: 0.000462 LR: 3.74e-06\n",
      "Epoch  27 [9400/10697 ( 87.9%)] Loss: 0.026607 L1: 0.015693 Grad: 0.108911 Thermal: 0.000462 LR: 3.74e-06\n",
      "Epoch  27 [9450/10697 ( 88.3%)] Loss: 0.027282 L1: 0.016301 Grad: 0.109594 Thermal: 0.000441 LR: 3.74e-06\n",
      "Epoch  27 [9450/10697 ( 88.3%)] Loss: 0.027282 L1: 0.016301 Grad: 0.109594 Thermal: 0.000441 LR: 3.74e-06\n",
      "Epoch  27 [9500/10697 ( 88.8%)] Loss: 0.021196 L1: 0.012148 Grad: 0.090341 Thermal: 0.000277 LR: 3.74e-06\n",
      "Epoch  27 [9500/10697 ( 88.8%)] Loss: 0.021196 L1: 0.012148 Grad: 0.090341 Thermal: 0.000277 LR: 3.74e-06\n",
      "Epoch  27 [9550/10697 ( 89.3%)] Loss: 0.029077 L1: 0.016696 Grad: 0.123490 Thermal: 0.000633 LR: 3.74e-06\n",
      "Epoch  27 [9550/10697 ( 89.3%)] Loss: 0.029077 L1: 0.016696 Grad: 0.123490 Thermal: 0.000633 LR: 3.74e-06\n",
      "Epoch  27 [9600/10697 ( 89.7%)] Loss: 0.029377 L1: 0.017191 Grad: 0.121591 Thermal: 0.000539 LR: 3.74e-06\n",
      "Epoch  27 [9600/10697 ( 89.7%)] Loss: 0.029377 L1: 0.017191 Grad: 0.121591 Thermal: 0.000539 LR: 3.74e-06\n",
      "Epoch  27 [9650/10697 ( 90.2%)] Loss: 0.020647 L1: 0.012367 Grad: 0.082645 Thermal: 0.000300 LR: 3.74e-06\n",
      "Epoch  27 [9650/10697 ( 90.2%)] Loss: 0.020647 L1: 0.012367 Grad: 0.082645 Thermal: 0.000300 LR: 3.74e-06\n",
      "Epoch  27 [9700/10697 ( 90.7%)] Loss: 0.037084 L1: 0.021427 Grad: 0.156107 Thermal: 0.000929 LR: 3.74e-06\n",
      "Epoch  27 [9700/10697 ( 90.7%)] Loss: 0.037084 L1: 0.021427 Grad: 0.156107 Thermal: 0.000929 LR: 3.74e-06\n",
      "Epoch  27 [9750/10697 ( 91.1%)] Loss: 0.031091 L1: 0.018149 Grad: 0.129124 Thermal: 0.000588 LR: 3.74e-06\n",
      "Epoch  27 [9750/10697 ( 91.1%)] Loss: 0.031091 L1: 0.018149 Grad: 0.129124 Thermal: 0.000588 LR: 3.74e-06\n",
      "Epoch  27 [9800/10697 ( 91.6%)] Loss: 0.025963 L1: 0.015452 Grad: 0.104887 Thermal: 0.000446 LR: 3.74e-06\n",
      "Epoch  27 [9800/10697 ( 91.6%)] Loss: 0.025963 L1: 0.015452 Grad: 0.104887 Thermal: 0.000446 LR: 3.74e-06\n",
      "Epoch  27 [9850/10697 ( 92.1%)] Loss: 0.024850 L1: 0.014373 Grad: 0.104579 Thermal: 0.000380 LR: 3.74e-06\n",
      "Epoch  27 [9850/10697 ( 92.1%)] Loss: 0.024850 L1: 0.014373 Grad: 0.104579 Thermal: 0.000380 LR: 3.74e-06\n",
      "Epoch  27 [9900/10697 ( 92.5%)] Loss: 0.020625 L1: 0.011980 Grad: 0.086285 Thermal: 0.000330 LR: 3.74e-06\n",
      "Epoch  27 [9900/10697 ( 92.5%)] Loss: 0.020625 L1: 0.011980 Grad: 0.086285 Thermal: 0.000330 LR: 3.74e-06\n",
      "Epoch  27 [9950/10697 ( 93.0%)] Loss: 0.026435 L1: 0.015657 Grad: 0.107559 Thermal: 0.000454 LR: 3.74e-06\n",
      "Epoch  27 [9950/10697 ( 93.0%)] Loss: 0.026435 L1: 0.015657 Grad: 0.107559 Thermal: 0.000454 LR: 3.74e-06\n",
      "Epoch  27 [10000/10697 ( 93.5%)] Loss: 0.024194 L1: 0.014180 Grad: 0.099964 Thermal: 0.000361 LR: 3.74e-06\n",
      "Epoch  27 [10000/10697 ( 93.5%)] Loss: 0.024194 L1: 0.014180 Grad: 0.099964 Thermal: 0.000361 LR: 3.74e-06\n",
      "Epoch  27 [10050/10697 ( 94.0%)] Loss: 0.022658 L1: 0.013241 Grad: 0.094003 Thermal: 0.000332 LR: 3.74e-06\n",
      "Epoch  27 [10050/10697 ( 94.0%)] Loss: 0.022658 L1: 0.013241 Grad: 0.094003 Thermal: 0.000332 LR: 3.74e-06\n",
      "Epoch  27 [10100/10697 ( 94.4%)] Loss: 0.031321 L1: 0.017924 Grad: 0.133670 Thermal: 0.000595 LR: 3.74e-06\n",
      "Epoch  27 [10100/10697 ( 94.4%)] Loss: 0.031321 L1: 0.017924 Grad: 0.133670 Thermal: 0.000595 LR: 3.74e-06\n",
      "Epoch  27 [10150/10697 ( 94.9%)] Loss: 0.026771 L1: 0.015896 Grad: 0.108526 Thermal: 0.000462 LR: 3.74e-06\n",
      "Epoch  27 [10150/10697 ( 94.9%)] Loss: 0.026771 L1: 0.015896 Grad: 0.108526 Thermal: 0.000462 LR: 3.74e-06\n",
      "Epoch  27 [10200/10697 ( 95.4%)] Loss: 0.024249 L1: 0.013811 Grad: 0.104195 Thermal: 0.000366 LR: 3.74e-06\n",
      "Epoch  27 [10200/10697 ( 95.4%)] Loss: 0.024249 L1: 0.013811 Grad: 0.104195 Thermal: 0.000366 LR: 3.74e-06\n",
      "Epoch  27 [10250/10697 ( 95.8%)] Loss: 0.020804 L1: 0.012155 Grad: 0.086333 Thermal: 0.000306 LR: 3.74e-06\n",
      "Epoch  27 [10250/10697 ( 95.8%)] Loss: 0.020804 L1: 0.012155 Grad: 0.086333 Thermal: 0.000306 LR: 3.74e-06\n",
      "Epoch  27 [10300/10697 ( 96.3%)] Loss: 0.032566 L1: 0.018727 Grad: 0.138055 Thermal: 0.000681 LR: 3.74e-06\n",
      "Epoch  27 [10300/10697 ( 96.3%)] Loss: 0.032566 L1: 0.018727 Grad: 0.138055 Thermal: 0.000681 LR: 3.74e-06\n",
      "Epoch  27 [10350/10697 ( 96.8%)] Loss: 0.021887 L1: 0.012905 Grad: 0.089647 Thermal: 0.000337 LR: 3.74e-06\n",
      "Epoch  27 [10350/10697 ( 96.8%)] Loss: 0.021887 L1: 0.012905 Grad: 0.089647 Thermal: 0.000337 LR: 3.74e-06\n",
      "Epoch  27 [10400/10697 ( 97.2%)] Loss: 0.022738 L1: 0.013123 Grad: 0.095992 Thermal: 0.000321 LR: 3.74e-06\n",
      "Epoch  27 [10400/10697 ( 97.2%)] Loss: 0.022738 L1: 0.013123 Grad: 0.095992 Thermal: 0.000321 LR: 3.74e-06\n",
      "Epoch  27 [10450/10697 ( 97.7%)] Loss: 0.021101 L1: 0.012213 Grad: 0.088728 Thermal: 0.000308 LR: 3.74e-06\n",
      "Epoch  27 [10450/10697 ( 97.7%)] Loss: 0.021101 L1: 0.012213 Grad: 0.088728 Thermal: 0.000308 LR: 3.74e-06\n",
      "Epoch  27 [10500/10697 ( 98.2%)] Loss: 0.026609 L1: 0.015767 Grad: 0.108199 Thermal: 0.000451 LR: 3.74e-06\n",
      "Epoch  27 [10500/10697 ( 98.2%)] Loss: 0.026609 L1: 0.015767 Grad: 0.108199 Thermal: 0.000451 LR: 3.74e-06\n",
      "Epoch  27 [10550/10697 ( 98.6%)] Loss: 0.025856 L1: 0.014791 Grad: 0.110432 Thermal: 0.000427 LR: 3.74e-06\n",
      "Epoch  27 [10550/10697 ( 98.6%)] Loss: 0.025856 L1: 0.014791 Grad: 0.110432 Thermal: 0.000427 LR: 3.74e-06\n",
      "Epoch  27 [10600/10697 ( 99.1%)] Loss: 0.024187 L1: 0.014033 Grad: 0.101353 Thermal: 0.000372 LR: 3.74e-06\n",
      "Epoch  27 [10600/10697 ( 99.1%)] Loss: 0.024187 L1: 0.014033 Grad: 0.101353 Thermal: 0.000372 LR: 3.74e-06\n",
      "Epoch  27 [10650/10697 ( 99.6%)] Loss: 0.028784 L1: 0.016989 Grad: 0.117694 Thermal: 0.000502 LR: 3.74e-06\n",
      "Epoch  27 [10650/10697 ( 99.6%)] Loss: 0.028784 L1: 0.016989 Grad: 0.117694 Thermal: 0.000502 LR: 3.74e-06\n",
      "Epoch  27 Summary: Loss=0.026265 (L1:0.0153, Grad:0.1092, Thermal:0.0005) Val_PSNR=0.00dB Best=33.95dB Time=103.9min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  27 Summary: Loss=0.026265 (L1:0.0153, Grad:0.1092, Thermal:0.0005) Val_PSNR=0.00dB Best=33.95dB Time=103.9min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  28 [   0/10697 (  0.0%)] Loss: 0.022944 L1: 0.012947 Grad: 0.099794 Thermal: 0.000363 LR: 3.66e-06\n",
      "Epoch  28 [   0/10697 (  0.0%)] Loss: 0.022944 L1: 0.012947 Grad: 0.099794 Thermal: 0.000363 LR: 3.66e-06\n",
      "Epoch  28 [  50/10697 (  0.5%)] Loss: 0.025075 L1: 0.014931 Grad: 0.101242 Thermal: 0.000399 LR: 3.66e-06\n",
      "Epoch  28 [  50/10697 (  0.5%)] Loss: 0.025075 L1: 0.014931 Grad: 0.101242 Thermal: 0.000399 LR: 3.66e-06\n",
      "Epoch  28 [ 100/10697 (  0.9%)] Loss: 0.026376 L1: 0.015642 Grad: 0.107119 Thermal: 0.000452 LR: 3.66e-06\n",
      "Epoch  28 [ 100/10697 (  0.9%)] Loss: 0.026376 L1: 0.015642 Grad: 0.107119 Thermal: 0.000452 LR: 3.66e-06\n",
      "Epoch  28 [ 150/10697 (  1.4%)] Loss: 0.024389 L1: 0.013915 Grad: 0.104538 Thermal: 0.000412 LR: 3.66e-06\n",
      "Epoch  28 [ 150/10697 (  1.4%)] Loss: 0.024389 L1: 0.013915 Grad: 0.104538 Thermal: 0.000412 LR: 3.66e-06\n",
      "Epoch  28 [ 200/10697 (  1.9%)] Loss: 0.028172 L1: 0.016466 Grad: 0.116809 Thermal: 0.000502 LR: 3.66e-06\n",
      "Epoch  28 [ 200/10697 (  1.9%)] Loss: 0.028172 L1: 0.016466 Grad: 0.116809 Thermal: 0.000502 LR: 3.66e-06\n",
      "Epoch  28 [ 250/10697 (  2.3%)] Loss: 0.025570 L1: 0.015134 Grad: 0.104145 Thermal: 0.000438 LR: 3.66e-06\n",
      "Epoch  28 [ 250/10697 (  2.3%)] Loss: 0.025570 L1: 0.015134 Grad: 0.104145 Thermal: 0.000438 LR: 3.66e-06\n",
      "Epoch  28 [ 300/10697 (  2.8%)] Loss: 0.023301 L1: 0.013326 Grad: 0.099576 Thermal: 0.000356 LR: 3.66e-06\n",
      "Epoch  28 [ 300/10697 (  2.8%)] Loss: 0.023301 L1: 0.013326 Grad: 0.099576 Thermal: 0.000356 LR: 3.66e-06\n",
      "Epoch  28 [ 350/10697 (  3.3%)] Loss: 0.027791 L1: 0.016050 Grad: 0.117171 Thermal: 0.000479 LR: 3.66e-06\n",
      "Epoch  28 [ 350/10697 (  3.3%)] Loss: 0.027791 L1: 0.016050 Grad: 0.117171 Thermal: 0.000479 LR: 3.66e-06\n",
      "Epoch  28 [ 400/10697 (  3.7%)] Loss: 0.025430 L1: 0.015302 Grad: 0.101058 Thermal: 0.000428 LR: 3.66e-06\n",
      "Epoch  28 [ 400/10697 (  3.7%)] Loss: 0.025430 L1: 0.015302 Grad: 0.101058 Thermal: 0.000428 LR: 3.66e-06\n",
      "Epoch  28 [ 450/10697 (  4.2%)] Loss: 0.028904 L1: 0.017040 Grad: 0.118369 Thermal: 0.000550 LR: 3.66e-06\n",
      "Epoch  28 [ 450/10697 (  4.2%)] Loss: 0.028904 L1: 0.017040 Grad: 0.118369 Thermal: 0.000550 LR: 3.66e-06\n",
      "Epoch  28 [ 500/10697 (  4.7%)] Loss: 0.025463 L1: 0.015253 Grad: 0.101890 Thermal: 0.000413 LR: 3.66e-06\n",
      "Epoch  28 [ 500/10697 (  4.7%)] Loss: 0.025463 L1: 0.015253 Grad: 0.101890 Thermal: 0.000413 LR: 3.66e-06\n",
      "Epoch  28 [ 550/10697 (  5.1%)] Loss: 0.026672 L1: 0.015629 Grad: 0.110182 Thermal: 0.000476 LR: 3.66e-06\n",
      "Epoch  28 [ 550/10697 (  5.1%)] Loss: 0.026672 L1: 0.015629 Grad: 0.110182 Thermal: 0.000476 LR: 3.66e-06\n",
      "Epoch  28 [ 600/10697 (  5.6%)] Loss: 0.023054 L1: 0.013268 Grad: 0.097676 Thermal: 0.000378 LR: 3.66e-06\n",
      "Epoch  28 [ 600/10697 (  5.6%)] Loss: 0.023054 L1: 0.013268 Grad: 0.097676 Thermal: 0.000378 LR: 3.66e-06\n",
      "Epoch  28 [ 650/10697 (  6.1%)] Loss: 0.028371 L1: 0.016345 Grad: 0.119961 Thermal: 0.000599 LR: 3.66e-06\n",
      "Epoch  28 [ 650/10697 (  6.1%)] Loss: 0.028371 L1: 0.016345 Grad: 0.119961 Thermal: 0.000599 LR: 3.66e-06\n",
      "Epoch  28 [ 700/10697 (  6.5%)] Loss: 0.031883 L1: 0.018658 Grad: 0.131951 Thermal: 0.000603 LR: 3.66e-06\n",
      "Epoch  28 [ 700/10697 (  6.5%)] Loss: 0.031883 L1: 0.018658 Grad: 0.131951 Thermal: 0.000603 LR: 3.66e-06\n",
      "Epoch  28 [ 750/10697 (  7.0%)] Loss: 0.027824 L1: 0.016418 Grad: 0.113803 Thermal: 0.000522 LR: 3.66e-06\n",
      "Epoch  28 [ 750/10697 (  7.0%)] Loss: 0.027824 L1: 0.016418 Grad: 0.113803 Thermal: 0.000522 LR: 3.66e-06\n",
      "Epoch  28 [ 800/10697 (  7.5%)] Loss: 0.028347 L1: 0.016281 Grad: 0.120403 Thermal: 0.000520 LR: 3.66e-06\n",
      "Epoch  28 [ 800/10697 (  7.5%)] Loss: 0.028347 L1: 0.016281 Grad: 0.120403 Thermal: 0.000520 LR: 3.66e-06\n",
      "Epoch  28 [ 850/10697 (  7.9%)] Loss: 0.021042 L1: 0.011953 Grad: 0.090733 Thermal: 0.000313 LR: 3.66e-06\n",
      "Epoch  28 [ 850/10697 (  7.9%)] Loss: 0.021042 L1: 0.011953 Grad: 0.090733 Thermal: 0.000313 LR: 3.66e-06\n",
      "Epoch  28 [ 900/10697 (  8.4%)] Loss: 0.029321 L1: 0.016964 Grad: 0.123296 Thermal: 0.000554 LR: 3.66e-06\n",
      "Epoch  28 [ 900/10697 (  8.4%)] Loss: 0.029321 L1: 0.016964 Grad: 0.123296 Thermal: 0.000554 LR: 3.66e-06\n",
      "Epoch  28 [ 950/10697 (  8.9%)] Loss: 0.027982 L1: 0.016706 Grad: 0.112496 Thermal: 0.000512 LR: 3.66e-06\n",
      "Epoch  28 [ 950/10697 (  8.9%)] Loss: 0.027982 L1: 0.016706 Grad: 0.112496 Thermal: 0.000512 LR: 3.66e-06\n",
      "Epoch  28 [1000/10697 (  9.3%)] Loss: 0.029413 L1: 0.016837 Grad: 0.125525 Thermal: 0.000482 LR: 3.66e-06\n",
      "Epoch  28 [1000/10697 (  9.3%)] Loss: 0.029413 L1: 0.016837 Grad: 0.125525 Thermal: 0.000482 LR: 3.66e-06\n",
      "Epoch  28 [1050/10697 (  9.8%)] Loss: 0.029795 L1: 0.017693 Grad: 0.120733 Thermal: 0.000565 LR: 3.66e-06\n",
      "Epoch  28 [1050/10697 (  9.8%)] Loss: 0.029795 L1: 0.017693 Grad: 0.120733 Thermal: 0.000565 LR: 3.66e-06\n",
      "Epoch  28 [1100/10697 ( 10.3%)] Loss: 0.021853 L1: 0.012706 Grad: 0.091323 Thermal: 0.000312 LR: 3.66e-06\n",
      "Epoch  28 [1100/10697 ( 10.3%)] Loss: 0.021853 L1: 0.012706 Grad: 0.091323 Thermal: 0.000312 LR: 3.66e-06\n",
      "Epoch  28 [1150/10697 ( 10.8%)] Loss: 0.025500 L1: 0.014642 Grad: 0.108375 Thermal: 0.000412 LR: 3.66e-06\n",
      "Epoch  28 [1150/10697 ( 10.8%)] Loss: 0.025500 L1: 0.014642 Grad: 0.108375 Thermal: 0.000412 LR: 3.66e-06\n",
      "Epoch  28 [1200/10697 ( 11.2%)] Loss: 0.018489 L1: 0.010403 Grad: 0.080738 Thermal: 0.000243 LR: 3.66e-06\n",
      "Epoch  28 [1200/10697 ( 11.2%)] Loss: 0.018489 L1: 0.010403 Grad: 0.080738 Thermal: 0.000243 LR: 3.66e-06\n",
      "Epoch  28 [1250/10697 ( 11.7%)] Loss: 0.028590 L1: 0.016487 Grad: 0.120760 Thermal: 0.000526 LR: 3.66e-06\n",
      "Epoch  28 [1250/10697 ( 11.7%)] Loss: 0.028590 L1: 0.016487 Grad: 0.120760 Thermal: 0.000526 LR: 3.66e-06\n",
      "Epoch  28 [1300/10697 ( 12.2%)] Loss: 0.028751 L1: 0.016984 Grad: 0.117410 Thermal: 0.000536 LR: 3.66e-06\n",
      "Epoch  28 [1300/10697 ( 12.2%)] Loss: 0.028751 L1: 0.016984 Grad: 0.117410 Thermal: 0.000536 LR: 3.66e-06\n",
      "Epoch  28 [1350/10697 ( 12.6%)] Loss: 0.023252 L1: 0.013626 Grad: 0.096078 Thermal: 0.000369 LR: 3.66e-06\n",
      "Epoch  28 [1350/10697 ( 12.6%)] Loss: 0.023252 L1: 0.013626 Grad: 0.096078 Thermal: 0.000369 LR: 3.66e-06\n",
      "Epoch  28 [1400/10697 ( 13.1%)] Loss: 0.023097 L1: 0.013316 Grad: 0.097639 Thermal: 0.000350 LR: 3.66e-06\n",
      "Epoch  28 [1400/10697 ( 13.1%)] Loss: 0.023097 L1: 0.013316 Grad: 0.097639 Thermal: 0.000350 LR: 3.66e-06\n",
      "Epoch  28 [1450/10697 ( 13.6%)] Loss: 0.024235 L1: 0.014088 Grad: 0.101251 Thermal: 0.000435 LR: 3.66e-06\n",
      "Epoch  28 [1450/10697 ( 13.6%)] Loss: 0.024235 L1: 0.014088 Grad: 0.101251 Thermal: 0.000435 LR: 3.66e-06\n",
      "Epoch  28 [1500/10697 ( 14.0%)] Loss: 0.028515 L1: 0.016624 Grad: 0.118666 Thermal: 0.000487 LR: 3.66e-06\n",
      "Epoch  28 [1500/10697 ( 14.0%)] Loss: 0.028515 L1: 0.016624 Grad: 0.118666 Thermal: 0.000487 LR: 3.66e-06\n",
      "Epoch  28 [1550/10697 ( 14.5%)] Loss: 0.023895 L1: 0.013870 Grad: 0.100055 Thermal: 0.000379 LR: 3.66e-06\n",
      "Epoch  28 [1550/10697 ( 14.5%)] Loss: 0.023895 L1: 0.013870 Grad: 0.100055 Thermal: 0.000379 LR: 3.66e-06\n",
      "Epoch  28 [1600/10697 ( 15.0%)] Loss: 0.027631 L1: 0.016149 Grad: 0.114561 Thermal: 0.000510 LR: 3.66e-06\n",
      "Epoch  28 [1600/10697 ( 15.0%)] Loss: 0.027631 L1: 0.016149 Grad: 0.114561 Thermal: 0.000510 LR: 3.66e-06\n",
      "Epoch  28 [1650/10697 ( 15.4%)] Loss: 0.025522 L1: 0.015066 Grad: 0.104353 Thermal: 0.000421 LR: 3.66e-06\n",
      "Epoch  28 [1650/10697 ( 15.4%)] Loss: 0.025522 L1: 0.015066 Grad: 0.104353 Thermal: 0.000421 LR: 3.66e-06\n",
      "Epoch  28 [1700/10697 ( 15.9%)] Loss: 0.026517 L1: 0.015786 Grad: 0.107103 Thermal: 0.000419 LR: 3.66e-06\n",
      "Epoch  28 [1700/10697 ( 15.9%)] Loss: 0.026517 L1: 0.015786 Grad: 0.107103 Thermal: 0.000419 LR: 3.66e-06\n",
      "Epoch  28 [1750/10697 ( 16.4%)] Loss: 0.024357 L1: 0.014483 Grad: 0.098544 Thermal: 0.000385 LR: 3.66e-06\n",
      "Epoch  28 [1750/10697 ( 16.4%)] Loss: 0.024357 L1: 0.014483 Grad: 0.098544 Thermal: 0.000385 LR: 3.66e-06\n",
      "Epoch  28 [1800/10697 ( 16.8%)] Loss: 0.027738 L1: 0.015961 Grad: 0.117508 Thermal: 0.000531 LR: 3.66e-06\n",
      "Epoch  28 [1800/10697 ( 16.8%)] Loss: 0.027738 L1: 0.015961 Grad: 0.117508 Thermal: 0.000531 LR: 3.66e-06\n",
      "Epoch  28 [1850/10697 ( 17.3%)] Loss: 0.024634 L1: 0.014343 Grad: 0.102717 Thermal: 0.000383 LR: 3.66e-06\n",
      "Epoch  28 [1850/10697 ( 17.3%)] Loss: 0.024634 L1: 0.014343 Grad: 0.102717 Thermal: 0.000383 LR: 3.66e-06\n",
      "Epoch  28 [1900/10697 ( 17.8%)] Loss: 0.031143 L1: 0.017842 Grad: 0.132677 Thermal: 0.000663 LR: 3.66e-06\n",
      "Epoch  28 [1900/10697 ( 17.8%)] Loss: 0.031143 L1: 0.017842 Grad: 0.132677 Thermal: 0.000663 LR: 3.66e-06\n",
      "Epoch  28 [1950/10697 ( 18.2%)] Loss: 0.027084 L1: 0.015573 Grad: 0.114893 Thermal: 0.000439 LR: 3.66e-06\n",
      "Epoch  28 [1950/10697 ( 18.2%)] Loss: 0.027084 L1: 0.015573 Grad: 0.114893 Thermal: 0.000439 LR: 3.66e-06\n",
      "Epoch  28 [2000/10697 ( 18.7%)] Loss: 0.030555 L1: 0.017697 Grad: 0.128257 Thermal: 0.000643 LR: 3.66e-06\n",
      "Epoch  28 [2000/10697 ( 18.7%)] Loss: 0.030555 L1: 0.017697 Grad: 0.128257 Thermal: 0.000643 LR: 3.66e-06\n",
      "Epoch  28 [2050/10697 ( 19.2%)] Loss: 0.032913 L1: 0.018931 Grad: 0.139454 Thermal: 0.000724 LR: 3.66e-06\n",
      "Epoch  28 [2050/10697 ( 19.2%)] Loss: 0.032913 L1: 0.018931 Grad: 0.139454 Thermal: 0.000724 LR: 3.66e-06\n",
      "Epoch  28 [2100/10697 ( 19.6%)] Loss: 0.022680 L1: 0.012969 Grad: 0.096939 Thermal: 0.000335 LR: 3.66e-06\n",
      "Epoch  28 [2100/10697 ( 19.6%)] Loss: 0.022680 L1: 0.012969 Grad: 0.096939 Thermal: 0.000335 LR: 3.66e-06\n",
      "Epoch  28 [2150/10697 ( 20.1%)] Loss: 0.028904 L1: 0.017161 Grad: 0.117177 Thermal: 0.000508 LR: 3.66e-06\n",
      "Epoch  28 [2150/10697 ( 20.1%)] Loss: 0.028904 L1: 0.017161 Grad: 0.117177 Thermal: 0.000508 LR: 3.66e-06\n",
      "Epoch  28 [2200/10697 ( 20.6%)] Loss: 0.028908 L1: 0.016426 Grad: 0.124559 Thermal: 0.000516 LR: 3.66e-06\n",
      "Epoch  28 [2200/10697 ( 20.6%)] Loss: 0.028908 L1: 0.016426 Grad: 0.124559 Thermal: 0.000516 LR: 3.66e-06\n",
      "Epoch  28 [2250/10697 ( 21.0%)] Loss: 0.024266 L1: 0.014453 Grad: 0.097942 Thermal: 0.000380 LR: 3.66e-06\n",
      "Epoch  28 [2250/10697 ( 21.0%)] Loss: 0.024266 L1: 0.014453 Grad: 0.097942 Thermal: 0.000380 LR: 3.66e-06\n",
      "Epoch  28 [2300/10697 ( 21.5%)] Loss: 0.029295 L1: 0.017005 Grad: 0.122632 Thermal: 0.000527 LR: 3.66e-06\n",
      "Epoch  28 [2300/10697 ( 21.5%)] Loss: 0.029295 L1: 0.017005 Grad: 0.122632 Thermal: 0.000527 LR: 3.66e-06\n",
      "Epoch  28 [2350/10697 ( 22.0%)] Loss: 0.024471 L1: 0.014255 Grad: 0.101946 Thermal: 0.000433 LR: 3.66e-06\n",
      "Epoch  28 [2350/10697 ( 22.0%)] Loss: 0.024471 L1: 0.014255 Grad: 0.101946 Thermal: 0.000433 LR: 3.66e-06\n",
      "Epoch  28 [2400/10697 ( 22.4%)] Loss: 0.032797 L1: 0.019704 Grad: 0.130553 Thermal: 0.000763 LR: 3.66e-06\n",
      "Epoch  28 [2400/10697 ( 22.4%)] Loss: 0.032797 L1: 0.019704 Grad: 0.130553 Thermal: 0.000763 LR: 3.66e-06\n",
      "Epoch  28 [2450/10697 ( 22.9%)] Loss: 0.024793 L1: 0.013965 Grad: 0.108077 Thermal: 0.000404 LR: 3.66e-06\n",
      "Epoch  28 [2450/10697 ( 22.9%)] Loss: 0.024793 L1: 0.013965 Grad: 0.108077 Thermal: 0.000404 LR: 3.66e-06\n",
      "Epoch  28 [2500/10697 ( 23.4%)] Loss: 0.022715 L1: 0.013048 Grad: 0.096494 Thermal: 0.000354 LR: 3.66e-06\n",
      "Epoch  28 [2500/10697 ( 23.4%)] Loss: 0.022715 L1: 0.013048 Grad: 0.096494 Thermal: 0.000354 LR: 3.66e-06\n",
      "Epoch  28 [2550/10697 ( 23.8%)] Loss: 0.026350 L1: 0.015596 Grad: 0.107310 Thermal: 0.000449 LR: 3.66e-06\n",
      "Epoch  28 [2550/10697 ( 23.8%)] Loss: 0.026350 L1: 0.015596 Grad: 0.107310 Thermal: 0.000449 LR: 3.66e-06\n",
      "Epoch  28 [2600/10697 ( 24.3%)] Loss: 0.024123 L1: 0.014248 Grad: 0.098567 Thermal: 0.000368 LR: 3.66e-06\n",
      "Epoch  28 [2600/10697 ( 24.3%)] Loss: 0.024123 L1: 0.014248 Grad: 0.098567 Thermal: 0.000368 LR: 3.66e-06\n",
      "Epoch  28 [2650/10697 ( 24.8%)] Loss: 0.030721 L1: 0.017625 Grad: 0.130692 Thermal: 0.000539 LR: 3.66e-06\n",
      "Epoch  28 [2650/10697 ( 24.8%)] Loss: 0.030721 L1: 0.017625 Grad: 0.130692 Thermal: 0.000539 LR: 3.66e-06\n",
      "Epoch  28 [2700/10697 ( 25.2%)] Loss: 0.022163 L1: 0.012691 Grad: 0.094558 Thermal: 0.000323 LR: 3.66e-06\n",
      "Epoch  28 [2700/10697 ( 25.2%)] Loss: 0.022163 L1: 0.012691 Grad: 0.094558 Thermal: 0.000323 LR: 3.66e-06\n",
      "Epoch  28 [2750/10697 ( 25.7%)] Loss: 0.026856 L1: 0.015571 Grad: 0.112602 Thermal: 0.000482 LR: 3.66e-06\n",
      "Epoch  28 [2750/10697 ( 25.7%)] Loss: 0.026856 L1: 0.015571 Grad: 0.112602 Thermal: 0.000482 LR: 3.66e-06\n",
      "Epoch  28 [2800/10697 ( 26.2%)] Loss: 0.032443 L1: 0.018947 Grad: 0.134499 Thermal: 0.000929 LR: 3.66e-06\n",
      "Epoch  28 [2800/10697 ( 26.2%)] Loss: 0.032443 L1: 0.018947 Grad: 0.134499 Thermal: 0.000929 LR: 3.66e-06\n",
      "Epoch  28 [2850/10697 ( 26.6%)] Loss: 0.031476 L1: 0.018030 Grad: 0.134133 Thermal: 0.000650 LR: 3.66e-06\n",
      "Epoch  28 [2850/10697 ( 26.6%)] Loss: 0.031476 L1: 0.018030 Grad: 0.134133 Thermal: 0.000650 LR: 3.66e-06\n",
      "Epoch  28 [2900/10697 ( 27.1%)] Loss: 0.021163 L1: 0.012253 Grad: 0.088947 Thermal: 0.000303 LR: 3.66e-06\n",
      "Epoch  28 [2900/10697 ( 27.1%)] Loss: 0.021163 L1: 0.012253 Grad: 0.088947 Thermal: 0.000303 LR: 3.66e-06\n",
      "Epoch  28 [2950/10697 ( 27.6%)] Loss: 0.027725 L1: 0.016212 Grad: 0.114897 Thermal: 0.000463 LR: 3.66e-06\n",
      "Epoch  28 [2950/10697 ( 27.6%)] Loss: 0.027725 L1: 0.016212 Grad: 0.114897 Thermal: 0.000463 LR: 3.66e-06\n",
      "Epoch  28 [3000/10697 ( 28.0%)] Loss: 0.027441 L1: 0.016190 Grad: 0.112272 Thermal: 0.000482 LR: 3.66e-06\n",
      "Epoch  28 [3000/10697 ( 28.0%)] Loss: 0.027441 L1: 0.016190 Grad: 0.112272 Thermal: 0.000482 LR: 3.66e-06\n",
      "Epoch  28 [3050/10697 ( 28.5%)] Loss: 0.023499 L1: 0.013760 Grad: 0.097206 Thermal: 0.000374 LR: 3.66e-06\n",
      "Epoch  28 [3050/10697 ( 28.5%)] Loss: 0.023499 L1: 0.013760 Grad: 0.097206 Thermal: 0.000374 LR: 3.66e-06\n",
      "Epoch  28 [3100/10697 ( 29.0%)] Loss: 0.031423 L1: 0.017823 Grad: 0.135670 Thermal: 0.000664 LR: 3.66e-06\n",
      "Epoch  28 [3100/10697 ( 29.0%)] Loss: 0.031423 L1: 0.017823 Grad: 0.135670 Thermal: 0.000664 LR: 3.66e-06\n",
      "Epoch  28 [3150/10697 ( 29.4%)] Loss: 0.033820 L1: 0.019228 Grad: 0.145537 Thermal: 0.000757 LR: 3.66e-06\n",
      "Epoch  28 [3150/10697 ( 29.4%)] Loss: 0.033820 L1: 0.019228 Grad: 0.145537 Thermal: 0.000757 LR: 3.66e-06\n",
      "Epoch  28 [3200/10697 ( 29.9%)] Loss: 0.026605 L1: 0.015535 Grad: 0.110483 Thermal: 0.000441 LR: 3.66e-06\n",
      "Epoch  28 [3200/10697 ( 29.9%)] Loss: 0.026605 L1: 0.015535 Grad: 0.110483 Thermal: 0.000441 LR: 3.66e-06\n",
      "Epoch  28 [3250/10697 ( 30.4%)] Loss: 0.028510 L1: 0.016367 Grad: 0.121156 Thermal: 0.000534 LR: 3.66e-06\n",
      "Epoch  28 [3250/10697 ( 30.4%)] Loss: 0.028510 L1: 0.016367 Grad: 0.121156 Thermal: 0.000534 LR: 3.66e-06\n",
      "Epoch  28 [3300/10697 ( 30.8%)] Loss: 0.022249 L1: 0.012982 Grad: 0.092506 Thermal: 0.000334 LR: 3.66e-06\n",
      "Epoch  28 [3300/10697 ( 30.8%)] Loss: 0.022249 L1: 0.012982 Grad: 0.092506 Thermal: 0.000334 LR: 3.66e-06\n",
      "Epoch  28 [3350/10697 ( 31.3%)] Loss: 0.025167 L1: 0.014544 Grad: 0.105983 Thermal: 0.000487 LR: 3.66e-06\n",
      "Epoch  28 [3350/10697 ( 31.3%)] Loss: 0.025167 L1: 0.014544 Grad: 0.105983 Thermal: 0.000487 LR: 3.66e-06\n",
      "Epoch  28 [3400/10697 ( 31.8%)] Loss: 0.026738 L1: 0.015438 Grad: 0.112781 Thermal: 0.000436 LR: 3.66e-06\n",
      "Epoch  28 [3400/10697 ( 31.8%)] Loss: 0.026738 L1: 0.015438 Grad: 0.112781 Thermal: 0.000436 LR: 3.66e-06\n",
      "Epoch  28 [3450/10697 ( 32.3%)] Loss: 0.027118 L1: 0.015716 Grad: 0.113793 Thermal: 0.000438 LR: 3.66e-06\n",
      "Epoch  28 [3450/10697 ( 32.3%)] Loss: 0.027118 L1: 0.015716 Grad: 0.113793 Thermal: 0.000438 LR: 3.66e-06\n",
      "Epoch  28 [3500/10697 ( 32.7%)] Loss: 0.021778 L1: 0.012979 Grad: 0.087820 Thermal: 0.000343 LR: 3.66e-06\n",
      "Epoch  28 [3500/10697 ( 32.7%)] Loss: 0.021778 L1: 0.012979 Grad: 0.087820 Thermal: 0.000343 LR: 3.66e-06\n",
      "Epoch  28 [3550/10697 ( 33.2%)] Loss: 0.026944 L1: 0.015972 Grad: 0.109497 Thermal: 0.000441 LR: 3.66e-06\n",
      "Epoch  28 [3550/10697 ( 33.2%)] Loss: 0.026944 L1: 0.015972 Grad: 0.109497 Thermal: 0.000441 LR: 3.66e-06\n",
      "Epoch  28 [3600/10697 ( 33.7%)] Loss: 0.024772 L1: 0.014098 Grad: 0.106535 Thermal: 0.000416 LR: 3.66e-06\n",
      "Epoch  28 [3600/10697 ( 33.7%)] Loss: 0.024772 L1: 0.014098 Grad: 0.106535 Thermal: 0.000416 LR: 3.66e-06\n",
      "Epoch  28 [3650/10697 ( 34.1%)] Loss: 0.025216 L1: 0.014696 Grad: 0.104994 Thermal: 0.000405 LR: 3.66e-06\n",
      "Epoch  28 [3650/10697 ( 34.1%)] Loss: 0.025216 L1: 0.014696 Grad: 0.104994 Thermal: 0.000405 LR: 3.66e-06\n",
      "Epoch  28 [3700/10697 ( 34.6%)] Loss: 0.019031 L1: 0.010972 Grad: 0.080466 Thermal: 0.000249 LR: 3.66e-06\n",
      "Epoch  28 [3700/10697 ( 34.6%)] Loss: 0.019031 L1: 0.010972 Grad: 0.080466 Thermal: 0.000249 LR: 3.66e-06\n",
      "Epoch  28 [3750/10697 ( 35.1%)] Loss: 0.027951 L1: 0.016131 Grad: 0.117961 Thermal: 0.000483 LR: 3.66e-06\n",
      "Epoch  28 [3750/10697 ( 35.1%)] Loss: 0.027951 L1: 0.016131 Grad: 0.117961 Thermal: 0.000483 LR: 3.66e-06\n",
      "Epoch  28 [3800/10697 ( 35.5%)] Loss: 0.027712 L1: 0.016339 Grad: 0.113477 Thermal: 0.000496 LR: 3.66e-06\n",
      "Epoch  28 [3800/10697 ( 35.5%)] Loss: 0.027712 L1: 0.016339 Grad: 0.113477 Thermal: 0.000496 LR: 3.66e-06\n",
      "Epoch  28 [3850/10697 ( 36.0%)] Loss: 0.025737 L1: 0.015126 Grad: 0.105902 Thermal: 0.000425 LR: 3.66e-06\n",
      "Epoch  28 [3850/10697 ( 36.0%)] Loss: 0.025737 L1: 0.015126 Grad: 0.105902 Thermal: 0.000425 LR: 3.66e-06\n",
      "Epoch  28 [3900/10697 ( 36.5%)] Loss: 0.026721 L1: 0.015480 Grad: 0.112179 Thermal: 0.000449 LR: 3.66e-06\n",
      "Epoch  28 [3900/10697 ( 36.5%)] Loss: 0.026721 L1: 0.015480 Grad: 0.112179 Thermal: 0.000449 LR: 3.66e-06\n",
      "Epoch  28 [3950/10697 ( 36.9%)] Loss: 0.024970 L1: 0.014900 Grad: 0.100478 Thermal: 0.000444 LR: 3.66e-06\n",
      "Epoch  28 [3950/10697 ( 36.9%)] Loss: 0.024970 L1: 0.014900 Grad: 0.100478 Thermal: 0.000444 LR: 3.66e-06\n",
      "Epoch  28 [4000/10697 ( 37.4%)] Loss: 0.029631 L1: 0.016965 Grad: 0.126406 Thermal: 0.000515 LR: 3.66e-06\n",
      "Epoch  28 [4000/10697 ( 37.4%)] Loss: 0.029631 L1: 0.016965 Grad: 0.126406 Thermal: 0.000515 LR: 3.66e-06\n",
      "Epoch  28 [4050/10697 ( 37.9%)] Loss: 0.025442 L1: 0.014605 Grad: 0.108134 Thermal: 0.000481 LR: 3.66e-06\n",
      "Epoch  28 [4050/10697 ( 37.9%)] Loss: 0.025442 L1: 0.014605 Grad: 0.108134 Thermal: 0.000481 LR: 3.66e-06\n",
      "Epoch  28 [4100/10697 ( 38.3%)] Loss: 0.026357 L1: 0.015486 Grad: 0.108489 Thermal: 0.000436 LR: 3.66e-06\n",
      "Epoch  28 [4100/10697 ( 38.3%)] Loss: 0.026357 L1: 0.015486 Grad: 0.108489 Thermal: 0.000436 LR: 3.66e-06\n",
      "Epoch  28 [4150/10697 ( 38.8%)] Loss: 0.029402 L1: 0.017421 Grad: 0.119541 Thermal: 0.000553 LR: 3.66e-06\n",
      "Epoch  28 [4150/10697 ( 38.8%)] Loss: 0.029402 L1: 0.017421 Grad: 0.119541 Thermal: 0.000553 LR: 3.66e-06\n",
      "Epoch  28 [4200/10697 ( 39.3%)] Loss: 0.026943 L1: 0.015460 Grad: 0.114579 Thermal: 0.000497 LR: 3.66e-06\n",
      "Epoch  28 [4200/10697 ( 39.3%)] Loss: 0.026943 L1: 0.015460 Grad: 0.114579 Thermal: 0.000497 LR: 3.66e-06\n",
      "Epoch  28 [4250/10697 ( 39.7%)] Loss: 0.027388 L1: 0.015795 Grad: 0.115689 Thermal: 0.000485 LR: 3.66e-06\n",
      "Epoch  28 [4250/10697 ( 39.7%)] Loss: 0.027388 L1: 0.015795 Grad: 0.115689 Thermal: 0.000485 LR: 3.66e-06\n",
      "Epoch  28 [4300/10697 ( 40.2%)] Loss: 0.027435 L1: 0.016163 Grad: 0.112473 Thermal: 0.000505 LR: 3.66e-06\n",
      "Epoch  28 [4300/10697 ( 40.2%)] Loss: 0.027435 L1: 0.016163 Grad: 0.112473 Thermal: 0.000505 LR: 3.66e-06\n",
      "Epoch  28 [4350/10697 ( 40.7%)] Loss: 0.026689 L1: 0.014799 Grad: 0.118689 Thermal: 0.000428 LR: 3.66e-06\n",
      "Epoch  28 [4350/10697 ( 40.7%)] Loss: 0.026689 L1: 0.014799 Grad: 0.118689 Thermal: 0.000428 LR: 3.66e-06\n",
      "Epoch  28 [4400/10697 ( 41.1%)] Loss: 0.024254 L1: 0.014371 Grad: 0.098636 Thermal: 0.000395 LR: 3.66e-06\n",
      "Epoch  28 [4400/10697 ( 41.1%)] Loss: 0.024254 L1: 0.014371 Grad: 0.098636 Thermal: 0.000395 LR: 3.66e-06\n",
      "Epoch  28 [4450/10697 ( 41.6%)] Loss: 0.025363 L1: 0.014856 Grad: 0.104869 Thermal: 0.000401 LR: 3.66e-06\n",
      "Epoch  28 [4450/10697 ( 41.6%)] Loss: 0.025363 L1: 0.014856 Grad: 0.104869 Thermal: 0.000401 LR: 3.66e-06\n",
      "Epoch  28 [4500/10697 ( 42.1%)] Loss: 0.026645 L1: 0.015528 Grad: 0.110945 Thermal: 0.000454 LR: 3.66e-06\n",
      "Epoch  28 [4500/10697 ( 42.1%)] Loss: 0.026645 L1: 0.015528 Grad: 0.110945 Thermal: 0.000454 LR: 3.66e-06\n",
      "Epoch  28 [4550/10697 ( 42.5%)] Loss: 0.025530 L1: 0.014783 Grad: 0.107248 Thermal: 0.000443 LR: 3.66e-06\n",
      "Epoch  28 [4550/10697 ( 42.5%)] Loss: 0.025530 L1: 0.014783 Grad: 0.107248 Thermal: 0.000443 LR: 3.66e-06\n",
      "Epoch  28 [4600/10697 ( 43.0%)] Loss: 0.031412 L1: 0.018534 Grad: 0.128450 Thermal: 0.000672 LR: 3.66e-06\n",
      "Epoch  28 [4600/10697 ( 43.0%)] Loss: 0.031412 L1: 0.018534 Grad: 0.128450 Thermal: 0.000672 LR: 3.66e-06\n",
      "Epoch  28 [4650/10697 ( 43.5%)] Loss: 0.027408 L1: 0.016089 Grad: 0.112947 Thermal: 0.000472 LR: 3.66e-06\n",
      "Epoch  28 [4650/10697 ( 43.5%)] Loss: 0.027408 L1: 0.016089 Grad: 0.112947 Thermal: 0.000472 LR: 3.66e-06\n",
      "Epoch  28 [4700/10697 ( 43.9%)] Loss: 0.026178 L1: 0.015103 Grad: 0.110510 Thermal: 0.000487 LR: 3.66e-06\n",
      "Epoch  28 [4700/10697 ( 43.9%)] Loss: 0.026178 L1: 0.015103 Grad: 0.110510 Thermal: 0.000487 LR: 3.66e-06\n",
      "Epoch  28 [4750/10697 ( 44.4%)] Loss: 0.025989 L1: 0.015294 Grad: 0.106741 Thermal: 0.000420 LR: 3.66e-06\n",
      "Epoch  28 [4750/10697 ( 44.4%)] Loss: 0.025989 L1: 0.015294 Grad: 0.106741 Thermal: 0.000420 LR: 3.66e-06\n",
      "Epoch  28 [4800/10697 ( 44.9%)] Loss: 0.026083 L1: 0.014991 Grad: 0.110692 Thermal: 0.000468 LR: 3.66e-06\n",
      "Epoch  28 [4800/10697 ( 44.9%)] Loss: 0.026083 L1: 0.014991 Grad: 0.110692 Thermal: 0.000468 LR: 3.66e-06\n",
      "Epoch  28 [4850/10697 ( 45.3%)] Loss: 0.028183 L1: 0.016337 Grad: 0.118225 Thermal: 0.000483 LR: 3.66e-06\n",
      "Epoch  28 [4850/10697 ( 45.3%)] Loss: 0.028183 L1: 0.016337 Grad: 0.118225 Thermal: 0.000483 LR: 3.66e-06\n",
      "Epoch  28 [4900/10697 ( 45.8%)] Loss: 0.029187 L1: 0.017000 Grad: 0.121583 Thermal: 0.000571 LR: 3.66e-06\n",
      "Epoch  28 [4900/10697 ( 45.8%)] Loss: 0.029187 L1: 0.017000 Grad: 0.121583 Thermal: 0.000571 LR: 3.66e-06\n",
      "Epoch  28 [4950/10697 ( 46.3%)] Loss: 0.022866 L1: 0.013641 Grad: 0.092055 Thermal: 0.000375 LR: 3.66e-06\n",
      "Epoch  28 [4950/10697 ( 46.3%)] Loss: 0.022866 L1: 0.013641 Grad: 0.092055 Thermal: 0.000375 LR: 3.66e-06\n",
      "Epoch  28 [5000/10697 ( 46.7%)] Loss: 0.030889 L1: 0.018410 Grad: 0.124503 Thermal: 0.000587 LR: 3.66e-06\n",
      "Epoch  28 [5000/10697 ( 46.7%)] Loss: 0.030889 L1: 0.018410 Grad: 0.124503 Thermal: 0.000587 LR: 3.66e-06\n",
      "Epoch  28 [5050/10697 ( 47.2%)] Loss: 0.028946 L1: 0.016324 Grad: 0.125959 Thermal: 0.000514 LR: 3.66e-06\n",
      "Epoch  28 [5050/10697 ( 47.2%)] Loss: 0.028946 L1: 0.016324 Grad: 0.125959 Thermal: 0.000514 LR: 3.66e-06\n",
      "Epoch  28 [5100/10697 ( 47.7%)] Loss: 0.025572 L1: 0.014995 Grad: 0.105551 Thermal: 0.000436 LR: 3.66e-06\n",
      "Epoch  28 [5100/10697 ( 47.7%)] Loss: 0.025572 L1: 0.014995 Grad: 0.105551 Thermal: 0.000436 LR: 3.66e-06\n",
      "Epoch  28 [5150/10697 ( 48.1%)] Loss: 0.026163 L1: 0.015413 Grad: 0.107276 Thermal: 0.000434 LR: 3.66e-06\n",
      "Epoch  28 [5150/10697 ( 48.1%)] Loss: 0.026163 L1: 0.015413 Grad: 0.107276 Thermal: 0.000434 LR: 3.66e-06\n",
      "Epoch  28 [5200/10697 ( 48.6%)] Loss: 0.020323 L1: 0.011739 Grad: 0.085707 Thermal: 0.000281 LR: 3.66e-06\n",
      "Epoch  28 [5200/10697 ( 48.6%)] Loss: 0.020323 L1: 0.011739 Grad: 0.085707 Thermal: 0.000281 LR: 3.66e-06\n",
      "Epoch  28 [5250/10697 ( 49.1%)] Loss: 0.027963 L1: 0.017028 Grad: 0.109088 Thermal: 0.000519 LR: 3.66e-06\n",
      "Epoch  28 [5250/10697 ( 49.1%)] Loss: 0.027963 L1: 0.017028 Grad: 0.109088 Thermal: 0.000519 LR: 3.66e-06\n",
      "Epoch  28 [5300/10697 ( 49.5%)] Loss: 0.032449 L1: 0.018858 Grad: 0.135532 Thermal: 0.000774 LR: 3.66e-06\n",
      "Epoch  28 [5300/10697 ( 49.5%)] Loss: 0.032449 L1: 0.018858 Grad: 0.135532 Thermal: 0.000774 LR: 3.66e-06\n",
      "Epoch  28 [5350/10697 ( 50.0%)] Loss: 0.025687 L1: 0.015091 Grad: 0.105731 Thermal: 0.000456 LR: 3.66e-06\n",
      "Epoch  28 [5350/10697 ( 50.0%)] Loss: 0.025687 L1: 0.015091 Grad: 0.105731 Thermal: 0.000456 LR: 3.66e-06\n",
      "Epoch  28 [5400/10697 ( 50.5%)] Loss: 0.024863 L1: 0.014399 Grad: 0.104423 Thermal: 0.000433 LR: 3.66e-06\n",
      "Epoch  28 [5400/10697 ( 50.5%)] Loss: 0.024863 L1: 0.014399 Grad: 0.104423 Thermal: 0.000433 LR: 3.66e-06\n",
      "Epoch  28 [5450/10697 ( 50.9%)] Loss: 0.025332 L1: 0.015336 Grad: 0.099752 Thermal: 0.000418 LR: 3.66e-06\n",
      "Epoch  28 [5450/10697 ( 50.9%)] Loss: 0.025332 L1: 0.015336 Grad: 0.099752 Thermal: 0.000418 LR: 3.66e-06\n",
      "Epoch  28 [5500/10697 ( 51.4%)] Loss: 0.022857 L1: 0.013707 Grad: 0.091318 Thermal: 0.000365 LR: 3.66e-06\n",
      "Epoch  28 [5500/10697 ( 51.4%)] Loss: 0.022857 L1: 0.013707 Grad: 0.091318 Thermal: 0.000365 LR: 3.66e-06\n",
      "Epoch  28 [5550/10697 ( 51.9%)] Loss: 0.025385 L1: 0.015314 Grad: 0.100507 Thermal: 0.000415 LR: 3.66e-06\n",
      "Epoch  28 [5550/10697 ( 51.9%)] Loss: 0.025385 L1: 0.015314 Grad: 0.100507 Thermal: 0.000415 LR: 3.66e-06\n",
      "Epoch  28 [5600/10697 ( 52.4%)] Loss: 0.026424 L1: 0.015982 Grad: 0.104196 Thermal: 0.000447 LR: 3.66e-06\n",
      "Epoch  28 [5600/10697 ( 52.4%)] Loss: 0.026424 L1: 0.015982 Grad: 0.104196 Thermal: 0.000447 LR: 3.66e-06\n",
      "Epoch  28 [5650/10697 ( 52.8%)] Loss: 0.022480 L1: 0.013244 Grad: 0.092170 Thermal: 0.000379 LR: 3.66e-06\n",
      "Epoch  28 [5650/10697 ( 52.8%)] Loss: 0.022480 L1: 0.013244 Grad: 0.092170 Thermal: 0.000379 LR: 3.66e-06\n",
      "Epoch  28 [5700/10697 ( 53.3%)] Loss: 0.024012 L1: 0.013799 Grad: 0.101952 Thermal: 0.000348 LR: 3.66e-06\n",
      "Epoch  28 [5700/10697 ( 53.3%)] Loss: 0.024012 L1: 0.013799 Grad: 0.101952 Thermal: 0.000348 LR: 3.66e-06\n",
      "Epoch  28 [5750/10697 ( 53.8%)] Loss: 0.025468 L1: 0.014856 Grad: 0.105883 Thermal: 0.000463 LR: 3.66e-06\n",
      "Epoch  28 [5750/10697 ( 53.8%)] Loss: 0.025468 L1: 0.014856 Grad: 0.105883 Thermal: 0.000463 LR: 3.66e-06\n",
      "Epoch  28 [5800/10697 ( 54.2%)] Loss: 0.029493 L1: 0.017316 Grad: 0.121496 Thermal: 0.000534 LR: 3.66e-06\n",
      "Epoch  28 [5800/10697 ( 54.2%)] Loss: 0.029493 L1: 0.017316 Grad: 0.121496 Thermal: 0.000534 LR: 3.66e-06\n",
      "Epoch  28 [5850/10697 ( 54.7%)] Loss: 0.024110 L1: 0.014148 Grad: 0.099432 Thermal: 0.000375 LR: 3.66e-06\n",
      "Epoch  28 [5850/10697 ( 54.7%)] Loss: 0.024110 L1: 0.014148 Grad: 0.099432 Thermal: 0.000375 LR: 3.66e-06\n",
      "Epoch  28 [5900/10697 ( 55.2%)] Loss: 0.026771 L1: 0.016047 Grad: 0.107014 Thermal: 0.000451 LR: 3.66e-06\n",
      "Epoch  28 [5900/10697 ( 55.2%)] Loss: 0.026771 L1: 0.016047 Grad: 0.107014 Thermal: 0.000451 LR: 3.66e-06\n",
      "Epoch  28 [5950/10697 ( 55.6%)] Loss: 0.025437 L1: 0.014785 Grad: 0.106281 Thermal: 0.000468 LR: 3.66e-06\n",
      "Epoch  28 [5950/10697 ( 55.6%)] Loss: 0.025437 L1: 0.014785 Grad: 0.106281 Thermal: 0.000468 LR: 3.66e-06\n",
      "Epoch  28 [6000/10697 ( 56.1%)] Loss: 0.021660 L1: 0.012628 Grad: 0.090159 Thermal: 0.000318 LR: 3.66e-06\n",
      "Epoch  28 [6000/10697 ( 56.1%)] Loss: 0.021660 L1: 0.012628 Grad: 0.090159 Thermal: 0.000318 LR: 3.66e-06\n",
      "Epoch  28 [6050/10697 ( 56.6%)] Loss: 0.027147 L1: 0.015671 Grad: 0.114529 Thermal: 0.000460 LR: 3.66e-06\n",
      "Epoch  28 [6050/10697 ( 56.6%)] Loss: 0.027147 L1: 0.015671 Grad: 0.114529 Thermal: 0.000460 LR: 3.66e-06\n",
      "Epoch  28 [6100/10697 ( 57.0%)] Loss: 0.022048 L1: 0.012705 Grad: 0.093281 Thermal: 0.000305 LR: 3.66e-06\n",
      "Epoch  28 [6100/10697 ( 57.0%)] Loss: 0.022048 L1: 0.012705 Grad: 0.093281 Thermal: 0.000305 LR: 3.66e-06\n",
      "Epoch  28 [6150/10697 ( 57.5%)] Loss: 0.028447 L1: 0.016639 Grad: 0.117828 Thermal: 0.000516 LR: 3.66e-06\n",
      "Epoch  28 [6150/10697 ( 57.5%)] Loss: 0.028447 L1: 0.016639 Grad: 0.117828 Thermal: 0.000516 LR: 3.66e-06\n",
      "Epoch  28 [6200/10697 ( 58.0%)] Loss: 0.033429 L1: 0.019187 Grad: 0.142048 Thermal: 0.000737 LR: 3.66e-06\n",
      "Epoch  28 [6200/10697 ( 58.0%)] Loss: 0.033429 L1: 0.019187 Grad: 0.142048 Thermal: 0.000737 LR: 3.66e-06\n",
      "Epoch  28 [6250/10697 ( 58.4%)] Loss: 0.021101 L1: 0.012058 Grad: 0.090301 Thermal: 0.000261 LR: 3.66e-06\n",
      "Epoch  28 [6250/10697 ( 58.4%)] Loss: 0.021101 L1: 0.012058 Grad: 0.090301 Thermal: 0.000261 LR: 3.66e-06\n",
      "Epoch  28 [6300/10697 ( 58.9%)] Loss: 0.025890 L1: 0.015037 Grad: 0.108302 Thermal: 0.000467 LR: 3.66e-06\n",
      "Epoch  28 [6300/10697 ( 58.9%)] Loss: 0.025890 L1: 0.015037 Grad: 0.108302 Thermal: 0.000467 LR: 3.66e-06\n",
      "Epoch  28 [6350/10697 ( 59.4%)] Loss: 0.025520 L1: 0.015268 Grad: 0.102307 Thermal: 0.000426 LR: 3.66e-06\n",
      "Epoch  28 [6350/10697 ( 59.4%)] Loss: 0.025520 L1: 0.015268 Grad: 0.102307 Thermal: 0.000426 LR: 3.66e-06\n",
      "Epoch  28 [6400/10697 ( 59.8%)] Loss: 0.026691 L1: 0.015104 Grad: 0.115584 Thermal: 0.000578 LR: 3.66e-06\n",
      "Epoch  28 [6400/10697 ( 59.8%)] Loss: 0.026691 L1: 0.015104 Grad: 0.115584 Thermal: 0.000578 LR: 3.66e-06\n",
      "Epoch  28 [6450/10697 ( 60.3%)] Loss: 0.023984 L1: 0.014116 Grad: 0.098494 Thermal: 0.000377 LR: 3.66e-06\n",
      "Epoch  28 [6450/10697 ( 60.3%)] Loss: 0.023984 L1: 0.014116 Grad: 0.098494 Thermal: 0.000377 LR: 3.66e-06\n",
      "Epoch  28 [6500/10697 ( 60.8%)] Loss: 0.025162 L1: 0.014808 Grad: 0.103319 Thermal: 0.000443 LR: 3.66e-06\n",
      "Epoch  28 [6500/10697 ( 60.8%)] Loss: 0.025162 L1: 0.014808 Grad: 0.103319 Thermal: 0.000443 LR: 3.66e-06\n",
      "Epoch  28 [6550/10697 ( 61.2%)] Loss: 0.022721 L1: 0.013456 Grad: 0.092463 Thermal: 0.000382 LR: 3.66e-06\n",
      "Epoch  28 [6550/10697 ( 61.2%)] Loss: 0.022721 L1: 0.013456 Grad: 0.092463 Thermal: 0.000382 LR: 3.66e-06\n",
      "Epoch  28 [6600/10697 ( 61.7%)] Loss: 0.026252 L1: 0.014870 Grad: 0.113510 Thermal: 0.000617 LR: 3.66e-06\n",
      "Epoch  28 [6600/10697 ( 61.7%)] Loss: 0.026252 L1: 0.014870 Grad: 0.113510 Thermal: 0.000617 LR: 3.66e-06\n",
      "Epoch  28 [6650/10697 ( 62.2%)] Loss: 0.027146 L1: 0.016034 Grad: 0.110903 Thermal: 0.000437 LR: 3.66e-06\n",
      "Epoch  28 [6650/10697 ( 62.2%)] Loss: 0.027146 L1: 0.016034 Grad: 0.110903 Thermal: 0.000437 LR: 3.66e-06\n",
      "Epoch  28 [6700/10697 ( 62.6%)] Loss: 0.025386 L1: 0.014754 Grad: 0.106111 Thermal: 0.000435 LR: 3.66e-06\n",
      "Epoch  28 [6700/10697 ( 62.6%)] Loss: 0.025386 L1: 0.014754 Grad: 0.106111 Thermal: 0.000435 LR: 3.66e-06\n",
      "Epoch  28 [6750/10697 ( 63.1%)] Loss: 0.025425 L1: 0.014806 Grad: 0.105971 Thermal: 0.000447 LR: 3.66e-06\n",
      "Epoch  28 [6750/10697 ( 63.1%)] Loss: 0.025425 L1: 0.014806 Grad: 0.105971 Thermal: 0.000447 LR: 3.66e-06\n",
      "Epoch  28 [6800/10697 ( 63.6%)] Loss: 0.017936 L1: 0.010487 Grad: 0.074353 Thermal: 0.000267 LR: 3.66e-06\n",
      "Epoch  28 [6800/10697 ( 63.6%)] Loss: 0.017936 L1: 0.010487 Grad: 0.074353 Thermal: 0.000267 LR: 3.66e-06\n",
      "Epoch  28 [6850/10697 ( 64.0%)] Loss: 0.026725 L1: 0.015835 Grad: 0.108660 Thermal: 0.000472 LR: 3.66e-06\n",
      "Epoch  28 [6850/10697 ( 64.0%)] Loss: 0.026725 L1: 0.015835 Grad: 0.108660 Thermal: 0.000472 LR: 3.66e-06\n",
      "Epoch  28 [6900/10697 ( 64.5%)] Loss: 0.025883 L1: 0.015378 Grad: 0.104839 Thermal: 0.000436 LR: 3.66e-06\n",
      "Epoch  28 [6900/10697 ( 64.5%)] Loss: 0.025883 L1: 0.015378 Grad: 0.104839 Thermal: 0.000436 LR: 3.66e-06\n",
      "Epoch  28 [6950/10697 ( 65.0%)] Loss: 0.027640 L1: 0.015882 Grad: 0.117282 Thermal: 0.000590 LR: 3.66e-06\n",
      "Epoch  28 [6950/10697 ( 65.0%)] Loss: 0.027640 L1: 0.015882 Grad: 0.117282 Thermal: 0.000590 LR: 3.66e-06\n",
      "Epoch  28 [7000/10697 ( 65.4%)] Loss: 0.025728 L1: 0.014964 Grad: 0.107432 Thermal: 0.000406 LR: 3.66e-06\n",
      "Epoch  28 [7000/10697 ( 65.4%)] Loss: 0.025728 L1: 0.014964 Grad: 0.107432 Thermal: 0.000406 LR: 3.66e-06\n",
      "Epoch  28 [7050/10697 ( 65.9%)] Loss: 0.025268 L1: 0.015091 Grad: 0.101563 Thermal: 0.000414 LR: 3.66e-06\n",
      "Epoch  28 [7050/10697 ( 65.9%)] Loss: 0.025268 L1: 0.015091 Grad: 0.101563 Thermal: 0.000414 LR: 3.66e-06\n",
      "Epoch  28 [7100/10697 ( 66.4%)] Loss: 0.027322 L1: 0.015650 Grad: 0.116485 Thermal: 0.000477 LR: 3.66e-06\n",
      "Epoch  28 [7100/10697 ( 66.4%)] Loss: 0.027322 L1: 0.015650 Grad: 0.116485 Thermal: 0.000477 LR: 3.66e-06\n",
      "Epoch  28 [7150/10697 ( 66.8%)] Loss: 0.024742 L1: 0.014472 Grad: 0.102496 Thermal: 0.000403 LR: 3.66e-06\n",
      "Epoch  28 [7150/10697 ( 66.8%)] Loss: 0.024742 L1: 0.014472 Grad: 0.102496 Thermal: 0.000403 LR: 3.66e-06\n",
      "Epoch  28 [7200/10697 ( 67.3%)] Loss: 0.026644 L1: 0.015914 Grad: 0.107070 Thermal: 0.000464 LR: 3.66e-06\n",
      "Epoch  28 [7200/10697 ( 67.3%)] Loss: 0.026644 L1: 0.015914 Grad: 0.107070 Thermal: 0.000464 LR: 3.66e-06\n",
      "Epoch  28 [7250/10697 ( 67.8%)] Loss: 0.024811 L1: 0.014919 Grad: 0.098728 Thermal: 0.000394 LR: 3.66e-06\n",
      "Epoch  28 [7250/10697 ( 67.8%)] Loss: 0.024811 L1: 0.014919 Grad: 0.098728 Thermal: 0.000394 LR: 3.66e-06\n",
      "Epoch  28 [7300/10697 ( 68.2%)] Loss: 0.020138 L1: 0.011874 Grad: 0.082488 Thermal: 0.000306 LR: 3.66e-06\n",
      "Epoch  28 [7300/10697 ( 68.2%)] Loss: 0.020138 L1: 0.011874 Grad: 0.082488 Thermal: 0.000306 LR: 3.66e-06\n",
      "Epoch  28 [7350/10697 ( 68.7%)] Loss: 0.025926 L1: 0.014910 Grad: 0.109957 Thermal: 0.000403 LR: 3.66e-06\n",
      "Epoch  28 [7350/10697 ( 68.7%)] Loss: 0.025926 L1: 0.014910 Grad: 0.109957 Thermal: 0.000403 LR: 3.66e-06\n",
      "Epoch  28 [7400/10697 ( 69.2%)] Loss: 0.019096 L1: 0.011165 Grad: 0.079182 Thermal: 0.000246 LR: 3.66e-06\n",
      "Epoch  28 [7400/10697 ( 69.2%)] Loss: 0.019096 L1: 0.011165 Grad: 0.079182 Thermal: 0.000246 LR: 3.66e-06\n",
      "Epoch  28 [7450/10697 ( 69.6%)] Loss: 0.020160 L1: 0.011845 Grad: 0.082985 Thermal: 0.000317 LR: 3.66e-06\n",
      "Epoch  28 [7450/10697 ( 69.6%)] Loss: 0.020160 L1: 0.011845 Grad: 0.082985 Thermal: 0.000317 LR: 3.66e-06\n",
      "Epoch  28 [7500/10697 ( 70.1%)] Loss: 0.041810 L1: 0.023654 Grad: 0.181042 Thermal: 0.001034 LR: 3.66e-06\n",
      "Epoch  28 [7500/10697 ( 70.1%)] Loss: 0.041810 L1: 0.023654 Grad: 0.181042 Thermal: 0.001034 LR: 3.66e-06\n",
      "Epoch  28 [7550/10697 ( 70.6%)] Loss: 0.026582 L1: 0.015436 Grad: 0.111226 Thermal: 0.000470 LR: 3.66e-06\n",
      "Epoch  28 [7550/10697 ( 70.6%)] Loss: 0.026582 L1: 0.015436 Grad: 0.111226 Thermal: 0.000470 LR: 3.66e-06\n",
      "Epoch  28 [7600/10697 ( 71.0%)] Loss: 0.025426 L1: 0.014864 Grad: 0.105406 Thermal: 0.000428 LR: 3.66e-06\n",
      "Epoch  28 [7600/10697 ( 71.0%)] Loss: 0.025426 L1: 0.014864 Grad: 0.105406 Thermal: 0.000428 LR: 3.66e-06\n",
      "Epoch  28 [7650/10697 ( 71.5%)] Loss: 0.025710 L1: 0.015091 Grad: 0.105984 Thermal: 0.000415 LR: 3.66e-06\n",
      "Epoch  28 [7650/10697 ( 71.5%)] Loss: 0.025710 L1: 0.015091 Grad: 0.105984 Thermal: 0.000415 LR: 3.66e-06\n",
      "Epoch  28 [7700/10697 ( 72.0%)] Loss: 0.021833 L1: 0.012547 Grad: 0.092705 Thermal: 0.000306 LR: 3.66e-06\n",
      "Epoch  28 [7700/10697 ( 72.0%)] Loss: 0.021833 L1: 0.012547 Grad: 0.092705 Thermal: 0.000306 LR: 3.66e-06\n",
      "Epoch  28 [7750/10697 ( 72.5%)] Loss: 0.032309 L1: 0.018807 Grad: 0.134692 Thermal: 0.000645 LR: 3.66e-06\n",
      "Epoch  28 [7750/10697 ( 72.5%)] Loss: 0.032309 L1: 0.018807 Grad: 0.134692 Thermal: 0.000645 LR: 3.66e-06\n",
      "Epoch  28 [7800/10697 ( 72.9%)] Loss: 0.027543 L1: 0.016048 Grad: 0.114703 Thermal: 0.000486 LR: 3.66e-06\n",
      "Epoch  28 [7800/10697 ( 72.9%)] Loss: 0.027543 L1: 0.016048 Grad: 0.114703 Thermal: 0.000486 LR: 3.66e-06\n",
      "Epoch  28 [7850/10697 ( 73.4%)] Loss: 0.023208 L1: 0.013643 Grad: 0.095464 Thermal: 0.000366 LR: 3.66e-06\n",
      "Epoch  28 [7850/10697 ( 73.4%)] Loss: 0.023208 L1: 0.013643 Grad: 0.095464 Thermal: 0.000366 LR: 3.66e-06\n",
      "Epoch  28 [7900/10697 ( 73.9%)] Loss: 0.018946 L1: 0.010936 Grad: 0.079963 Thermal: 0.000283 LR: 3.66e-06\n",
      "Epoch  28 [7900/10697 ( 73.9%)] Loss: 0.018946 L1: 0.010936 Grad: 0.079963 Thermal: 0.000283 LR: 3.66e-06\n",
      "Epoch  28 [7950/10697 ( 74.3%)] Loss: 0.039625 L1: 0.022949 Grad: 0.166254 Thermal: 0.001022 LR: 3.66e-06\n",
      "Epoch  28 [7950/10697 ( 74.3%)] Loss: 0.039625 L1: 0.022949 Grad: 0.166254 Thermal: 0.001022 LR: 3.66e-06\n",
      "Epoch  28 [8000/10697 ( 74.8%)] Loss: 0.029240 L1: 0.016892 Grad: 0.123209 Thermal: 0.000544 LR: 3.66e-06\n",
      "Epoch  28 [8000/10697 ( 74.8%)] Loss: 0.029240 L1: 0.016892 Grad: 0.123209 Thermal: 0.000544 LR: 3.66e-06\n",
      "Epoch  28 [8050/10697 ( 75.3%)] Loss: 0.024574 L1: 0.014497 Grad: 0.100566 Thermal: 0.000393 LR: 3.66e-06\n",
      "Epoch  28 [8050/10697 ( 75.3%)] Loss: 0.024574 L1: 0.014497 Grad: 0.100566 Thermal: 0.000393 LR: 3.66e-06\n",
      "Epoch  28 [8100/10697 ( 75.7%)] Loss: 0.031203 L1: 0.018399 Grad: 0.127661 Thermal: 0.000770 LR: 3.66e-06\n",
      "Epoch  28 [8100/10697 ( 75.7%)] Loss: 0.031203 L1: 0.018399 Grad: 0.127661 Thermal: 0.000770 LR: 3.66e-06\n",
      "Epoch  28 [8150/10697 ( 76.2%)] Loss: 0.030409 L1: 0.017400 Grad: 0.129792 Thermal: 0.000601 LR: 3.66e-06\n",
      "Epoch  28 [8150/10697 ( 76.2%)] Loss: 0.030409 L1: 0.017400 Grad: 0.129792 Thermal: 0.000601 LR: 3.66e-06\n",
      "Epoch  28 [8200/10697 ( 76.7%)] Loss: 0.027680 L1: 0.015987 Grad: 0.116691 Thermal: 0.000483 LR: 3.66e-06\n",
      "Epoch  28 [8200/10697 ( 76.7%)] Loss: 0.027680 L1: 0.015987 Grad: 0.116691 Thermal: 0.000483 LR: 3.66e-06\n",
      "Epoch  28 [8250/10697 ( 77.1%)] Loss: 0.027176 L1: 0.016417 Grad: 0.107356 Thermal: 0.000476 LR: 3.66e-06\n",
      "Epoch  28 [8250/10697 ( 77.1%)] Loss: 0.027176 L1: 0.016417 Grad: 0.107356 Thermal: 0.000476 LR: 3.66e-06\n",
      "Epoch  28 [8300/10697 ( 77.6%)] Loss: 0.028296 L1: 0.016803 Grad: 0.114656 Thermal: 0.000543 LR: 3.66e-06\n",
      "Epoch  28 [8300/10697 ( 77.6%)] Loss: 0.028296 L1: 0.016803 Grad: 0.114656 Thermal: 0.000543 LR: 3.66e-06\n",
      "Epoch  28 [8350/10697 ( 78.1%)] Loss: 0.022307 L1: 0.013080 Grad: 0.092097 Thermal: 0.000330 LR: 3.66e-06\n",
      "Epoch  28 [8350/10697 ( 78.1%)] Loss: 0.022307 L1: 0.013080 Grad: 0.092097 Thermal: 0.000330 LR: 3.66e-06\n",
      "Epoch  28 [8400/10697 ( 78.5%)] Loss: 0.021651 L1: 0.012942 Grad: 0.086924 Thermal: 0.000331 LR: 3.66e-06\n",
      "Epoch  28 [8400/10697 ( 78.5%)] Loss: 0.021651 L1: 0.012942 Grad: 0.086924 Thermal: 0.000331 LR: 3.66e-06\n",
      "Epoch  28 [8450/10697 ( 79.0%)] Loss: 0.026373 L1: 0.015560 Grad: 0.107914 Thermal: 0.000432 LR: 3.66e-06\n",
      "Epoch  28 [8450/10697 ( 79.0%)] Loss: 0.026373 L1: 0.015560 Grad: 0.107914 Thermal: 0.000432 LR: 3.66e-06\n",
      "Epoch  28 [8500/10697 ( 79.5%)] Loss: 0.025867 L1: 0.015229 Grad: 0.106180 Thermal: 0.000402 LR: 3.66e-06\n",
      "Epoch  28 [8500/10697 ( 79.5%)] Loss: 0.025867 L1: 0.015229 Grad: 0.106180 Thermal: 0.000402 LR: 3.66e-06\n",
      "Epoch  28 [8550/10697 ( 79.9%)] Loss: 0.025450 L1: 0.015077 Grad: 0.103535 Thermal: 0.000398 LR: 3.66e-06\n",
      "Epoch  28 [8550/10697 ( 79.9%)] Loss: 0.025450 L1: 0.015077 Grad: 0.103535 Thermal: 0.000398 LR: 3.66e-06\n",
      "Epoch  28 [8600/10697 ( 80.4%)] Loss: 0.027223 L1: 0.015637 Grad: 0.115630 Thermal: 0.000460 LR: 3.66e-06\n",
      "Epoch  28 [8600/10697 ( 80.4%)] Loss: 0.027223 L1: 0.015637 Grad: 0.115630 Thermal: 0.000460 LR: 3.66e-06\n",
      "Epoch  28 [8650/10697 ( 80.9%)] Loss: 0.022562 L1: 0.013566 Grad: 0.089783 Thermal: 0.000359 LR: 3.66e-06\n",
      "Epoch  28 [8650/10697 ( 80.9%)] Loss: 0.022562 L1: 0.013566 Grad: 0.089783 Thermal: 0.000359 LR: 3.66e-06\n",
      "Epoch  28 [8700/10697 ( 81.3%)] Loss: 0.025309 L1: 0.014661 Grad: 0.106269 Thermal: 0.000426 LR: 3.66e-06\n",
      "Epoch  28 [8700/10697 ( 81.3%)] Loss: 0.025309 L1: 0.014661 Grad: 0.106269 Thermal: 0.000426 LR: 3.66e-06\n",
      "Epoch  28 [8750/10697 ( 81.8%)] Loss: 0.031962 L1: 0.018431 Grad: 0.134998 Thermal: 0.000627 LR: 3.66e-06\n",
      "Epoch  28 [8750/10697 ( 81.8%)] Loss: 0.031962 L1: 0.018431 Grad: 0.134998 Thermal: 0.000627 LR: 3.66e-06\n",
      "Epoch  28 [8800/10697 ( 82.3%)] Loss: 0.023214 L1: 0.012734 Grad: 0.104641 Thermal: 0.000321 LR: 3.66e-06\n",
      "Epoch  28 [8800/10697 ( 82.3%)] Loss: 0.023214 L1: 0.012734 Grad: 0.104641 Thermal: 0.000321 LR: 3.66e-06\n",
      "Epoch  28 [8850/10697 ( 82.7%)] Loss: 0.022973 L1: 0.013665 Grad: 0.092897 Thermal: 0.000378 LR: 3.66e-06\n",
      "Epoch  28 [8850/10697 ( 82.7%)] Loss: 0.022973 L1: 0.013665 Grad: 0.092897 Thermal: 0.000378 LR: 3.66e-06\n",
      "Epoch  28 [8900/10697 ( 83.2%)] Loss: 0.026272 L1: 0.014889 Grad: 0.113602 Thermal: 0.000442 LR: 3.66e-06\n",
      "Epoch  28 [8900/10697 ( 83.2%)] Loss: 0.026272 L1: 0.014889 Grad: 0.113602 Thermal: 0.000442 LR: 3.66e-06\n",
      "Epoch  28 [8950/10697 ( 83.7%)] Loss: 0.028328 L1: 0.016864 Grad: 0.114389 Thermal: 0.000508 LR: 3.66e-06\n",
      "Epoch  28 [8950/10697 ( 83.7%)] Loss: 0.028328 L1: 0.016864 Grad: 0.114389 Thermal: 0.000508 LR: 3.66e-06\n",
      "Epoch  28 [9000/10697 ( 84.1%)] Loss: 0.026356 L1: 0.014823 Grad: 0.115104 Thermal: 0.000462 LR: 3.66e-06\n",
      "Epoch  28 [9000/10697 ( 84.1%)] Loss: 0.026356 L1: 0.014823 Grad: 0.115104 Thermal: 0.000462 LR: 3.66e-06\n",
      "Epoch  28 [9050/10697 ( 84.6%)] Loss: 0.024863 L1: 0.015108 Grad: 0.097351 Thermal: 0.000404 LR: 3.66e-06\n",
      "Epoch  28 [9050/10697 ( 84.6%)] Loss: 0.024863 L1: 0.015108 Grad: 0.097351 Thermal: 0.000404 LR: 3.66e-06\n",
      "Epoch  28 [9100/10697 ( 85.1%)] Loss: 0.023272 L1: 0.013669 Grad: 0.095858 Thermal: 0.000348 LR: 3.66e-06\n",
      "Epoch  28 [9100/10697 ( 85.1%)] Loss: 0.023272 L1: 0.013669 Grad: 0.095858 Thermal: 0.000348 LR: 3.66e-06\n",
      "Epoch  28 [9150/10697 ( 85.5%)] Loss: 0.028731 L1: 0.016962 Grad: 0.117428 Thermal: 0.000531 LR: 3.66e-06\n",
      "Epoch  28 [9150/10697 ( 85.5%)] Loss: 0.028731 L1: 0.016962 Grad: 0.117428 Thermal: 0.000531 LR: 3.66e-06\n",
      "Epoch  28 [9200/10697 ( 86.0%)] Loss: 0.030424 L1: 0.017607 Grad: 0.127878 Thermal: 0.000585 LR: 3.66e-06\n",
      "Epoch  28 [9200/10697 ( 86.0%)] Loss: 0.030424 L1: 0.017607 Grad: 0.127878 Thermal: 0.000585 LR: 3.66e-06\n",
      "Epoch  28 [9250/10697 ( 86.5%)] Loss: 0.027517 L1: 0.016351 Grad: 0.111428 Thermal: 0.000465 LR: 3.66e-06\n",
      "Epoch  28 [9250/10697 ( 86.5%)] Loss: 0.027517 L1: 0.016351 Grad: 0.111428 Thermal: 0.000465 LR: 3.66e-06\n",
      "Epoch  28 [9300/10697 ( 86.9%)] Loss: 0.019629 L1: 0.011005 Grad: 0.086105 Thermal: 0.000268 LR: 3.66e-06\n",
      "Epoch  28 [9300/10697 ( 86.9%)] Loss: 0.019629 L1: 0.011005 Grad: 0.086105 Thermal: 0.000268 LR: 3.66e-06\n",
      "Epoch  28 [9350/10697 ( 87.4%)] Loss: 0.025504 L1: 0.015260 Grad: 0.102234 Thermal: 0.000402 LR: 3.66e-06\n",
      "Epoch  28 [9350/10697 ( 87.4%)] Loss: 0.025504 L1: 0.015260 Grad: 0.102234 Thermal: 0.000402 LR: 3.66e-06\n",
      "Epoch  28 [9400/10697 ( 87.9%)] Loss: 0.026973 L1: 0.016307 Grad: 0.106419 Thermal: 0.000491 LR: 3.66e-06\n",
      "Epoch  28 [9400/10697 ( 87.9%)] Loss: 0.026973 L1: 0.016307 Grad: 0.106419 Thermal: 0.000491 LR: 3.66e-06\n",
      "Epoch  28 [9450/10697 ( 88.3%)] Loss: 0.030150 L1: 0.017542 Grad: 0.125797 Thermal: 0.000563 LR: 3.66e-06\n",
      "Epoch  28 [9450/10697 ( 88.3%)] Loss: 0.030150 L1: 0.017542 Grad: 0.125797 Thermal: 0.000563 LR: 3.66e-06\n",
      "Epoch  28 [9500/10697 ( 88.8%)] Loss: 0.025995 L1: 0.015193 Grad: 0.107769 Thermal: 0.000493 LR: 3.66e-06\n",
      "Epoch  28 [9500/10697 ( 88.8%)] Loss: 0.025995 L1: 0.015193 Grad: 0.107769 Thermal: 0.000493 LR: 3.66e-06\n",
      "Epoch  28 [9550/10697 ( 89.3%)] Loss: 0.021587 L1: 0.012926 Grad: 0.086435 Thermal: 0.000342 LR: 3.66e-06\n",
      "Epoch  28 [9550/10697 ( 89.3%)] Loss: 0.021587 L1: 0.012926 Grad: 0.086435 Thermal: 0.000342 LR: 3.66e-06\n",
      "Epoch  28 [9600/10697 ( 89.7%)] Loss: 0.026723 L1: 0.015741 Grad: 0.109581 Thermal: 0.000469 LR: 3.66e-06\n",
      "Epoch  28 [9600/10697 ( 89.7%)] Loss: 0.026723 L1: 0.015741 Grad: 0.109581 Thermal: 0.000469 LR: 3.66e-06\n",
      "Epoch  28 [9650/10697 ( 90.2%)] Loss: 0.027608 L1: 0.016072 Grad: 0.115103 Thermal: 0.000517 LR: 3.66e-06\n",
      "Epoch  28 [9650/10697 ( 90.2%)] Loss: 0.027608 L1: 0.016072 Grad: 0.115103 Thermal: 0.000517 LR: 3.66e-06\n",
      "Epoch  28 [9700/10697 ( 90.7%)] Loss: 0.023331 L1: 0.013522 Grad: 0.097912 Thermal: 0.000356 LR: 3.66e-06\n",
      "Epoch  28 [9700/10697 ( 90.7%)] Loss: 0.023331 L1: 0.013522 Grad: 0.097912 Thermal: 0.000356 LR: 3.66e-06\n",
      "Epoch  28 [9750/10697 ( 91.1%)] Loss: 0.023994 L1: 0.014230 Grad: 0.097446 Thermal: 0.000377 LR: 3.66e-06\n",
      "Epoch  28 [9750/10697 ( 91.1%)] Loss: 0.023994 L1: 0.014230 Grad: 0.097446 Thermal: 0.000377 LR: 3.66e-06\n",
      "Epoch  28 [9800/10697 ( 91.6%)] Loss: 0.030964 L1: 0.018381 Grad: 0.125512 Thermal: 0.000638 LR: 3.66e-06\n",
      "Epoch  28 [9800/10697 ( 91.6%)] Loss: 0.030964 L1: 0.018381 Grad: 0.125512 Thermal: 0.000638 LR: 3.66e-06\n",
      "Epoch  28 [9850/10697 ( 92.1%)] Loss: 0.028217 L1: 0.016545 Grad: 0.116460 Thermal: 0.000531 LR: 3.66e-06\n",
      "Epoch  28 [9850/10697 ( 92.1%)] Loss: 0.028217 L1: 0.016545 Grad: 0.116460 Thermal: 0.000531 LR: 3.66e-06\n",
      "Epoch  28 [9900/10697 ( 92.5%)] Loss: 0.019895 L1: 0.011727 Grad: 0.081520 Thermal: 0.000318 LR: 3.66e-06\n",
      "Epoch  28 [9900/10697 ( 92.5%)] Loss: 0.019895 L1: 0.011727 Grad: 0.081520 Thermal: 0.000318 LR: 3.66e-06\n",
      "Epoch  28 [9950/10697 ( 93.0%)] Loss: 0.027422 L1: 0.016437 Grad: 0.109612 Thermal: 0.000485 LR: 3.66e-06\n",
      "Epoch  28 [9950/10697 ( 93.0%)] Loss: 0.027422 L1: 0.016437 Grad: 0.109612 Thermal: 0.000485 LR: 3.66e-06\n",
      "Epoch  28 [10000/10697 ( 93.5%)] Loss: 0.029880 L1: 0.017313 Grad: 0.125352 Thermal: 0.000638 LR: 3.66e-06\n",
      "Epoch  28 [10000/10697 ( 93.5%)] Loss: 0.029880 L1: 0.017313 Grad: 0.125352 Thermal: 0.000638 LR: 3.66e-06\n",
      "Epoch  28 [10050/10697 ( 94.0%)] Loss: 0.031305 L1: 0.018232 Grad: 0.130406 Thermal: 0.000653 LR: 3.66e-06\n",
      "Epoch  28 [10050/10697 ( 94.0%)] Loss: 0.031305 L1: 0.018232 Grad: 0.130406 Thermal: 0.000653 LR: 3.66e-06\n",
      "Epoch  28 [10100/10697 ( 94.4%)] Loss: 0.024131 L1: 0.014423 Grad: 0.096868 Thermal: 0.000425 LR: 3.66e-06\n",
      "Epoch  28 [10100/10697 ( 94.4%)] Loss: 0.024131 L1: 0.014423 Grad: 0.096868 Thermal: 0.000425 LR: 3.66e-06\n",
      "Epoch  28 [10150/10697 ( 94.9%)] Loss: 0.025102 L1: 0.014840 Grad: 0.102405 Thermal: 0.000434 LR: 3.66e-06\n",
      "Epoch  28 [10150/10697 ( 94.9%)] Loss: 0.025102 L1: 0.014840 Grad: 0.102405 Thermal: 0.000434 LR: 3.66e-06\n",
      "Epoch  28 [10200/10697 ( 95.4%)] Loss: 0.027029 L1: 0.016011 Grad: 0.109943 Thermal: 0.000476 LR: 3.66e-06\n",
      "Epoch  28 [10200/10697 ( 95.4%)] Loss: 0.027029 L1: 0.016011 Grad: 0.109943 Thermal: 0.000476 LR: 3.66e-06\n",
      "Epoch  28 [10250/10697 ( 95.8%)] Loss: 0.024418 L1: 0.013889 Grad: 0.105098 Thermal: 0.000401 LR: 3.66e-06\n",
      "Epoch  28 [10250/10697 ( 95.8%)] Loss: 0.024418 L1: 0.013889 Grad: 0.105098 Thermal: 0.000401 LR: 3.66e-06\n",
      "Epoch  28 [10300/10697 ( 96.3%)] Loss: 0.025546 L1: 0.015180 Grad: 0.103448 Thermal: 0.000426 LR: 3.66e-06\n",
      "Epoch  28 [10300/10697 ( 96.3%)] Loss: 0.025546 L1: 0.015180 Grad: 0.103448 Thermal: 0.000426 LR: 3.66e-06\n",
      "Epoch  28 [10350/10697 ( 96.8%)] Loss: 0.022400 L1: 0.012666 Grad: 0.097175 Thermal: 0.000335 LR: 3.66e-06\n",
      "Epoch  28 [10350/10697 ( 96.8%)] Loss: 0.022400 L1: 0.012666 Grad: 0.097175 Thermal: 0.000335 LR: 3.66e-06\n",
      "Epoch  28 [10400/10697 ( 97.2%)] Loss: 0.033124 L1: 0.019238 Grad: 0.138524 Thermal: 0.000683 LR: 3.66e-06\n",
      "Epoch  28 [10400/10697 ( 97.2%)] Loss: 0.033124 L1: 0.019238 Grad: 0.138524 Thermal: 0.000683 LR: 3.66e-06\n",
      "Epoch  28 [10450/10697 ( 97.7%)] Loss: 0.028148 L1: 0.016328 Grad: 0.117958 Thermal: 0.000477 LR: 3.66e-06\n",
      "Epoch  28 [10450/10697 ( 97.7%)] Loss: 0.028148 L1: 0.016328 Grad: 0.117958 Thermal: 0.000477 LR: 3.66e-06\n",
      "Epoch  28 [10500/10697 ( 98.2%)] Loss: 0.024065 L1: 0.014106 Grad: 0.099399 Thermal: 0.000385 LR: 3.66e-06\n",
      "Epoch  28 [10500/10697 ( 98.2%)] Loss: 0.024065 L1: 0.014106 Grad: 0.099399 Thermal: 0.000385 LR: 3.66e-06\n",
      "Epoch  28 [10550/10697 ( 98.6%)] Loss: 0.024527 L1: 0.014583 Grad: 0.099241 Thermal: 0.000393 LR: 3.66e-06\n",
      "Epoch  28 [10550/10697 ( 98.6%)] Loss: 0.024527 L1: 0.014583 Grad: 0.099241 Thermal: 0.000393 LR: 3.66e-06\n",
      "Epoch  28 [10600/10697 ( 99.1%)] Loss: 0.021193 L1: 0.012593 Grad: 0.085845 Thermal: 0.000307 LR: 3.66e-06\n",
      "Epoch  28 [10600/10697 ( 99.1%)] Loss: 0.021193 L1: 0.012593 Grad: 0.085845 Thermal: 0.000307 LR: 3.66e-06\n",
      "Epoch  28 [10650/10697 ( 99.6%)] Loss: 0.023076 L1: 0.013685 Grad: 0.093725 Thermal: 0.000375 LR: 3.66e-06\n",
      "Epoch  28 [10650/10697 ( 99.6%)] Loss: 0.023076 L1: 0.013685 Grad: 0.093725 Thermal: 0.000375 LR: 3.66e-06\n",
      "Epoch  28 Summary: Loss=0.026300 (L1:0.0153, Grad:0.1094, Thermal:0.0005) Val_PSNR=0.00dB Best=33.95dB Time=107.7min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  28 Summary: Loss=0.026300 (L1:0.0153, Grad:0.1094, Thermal:0.0005) Val_PSNR=0.00dB Best=33.95dB Time=107.7min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  29 [   0/10697 (  0.0%)] Loss: 0.027292 L1: 0.015993 Grad: 0.112766 Thermal: 0.000448 LR: 3.57e-06\n",
      "Epoch  29 [   0/10697 (  0.0%)] Loss: 0.027292 L1: 0.015993 Grad: 0.112766 Thermal: 0.000448 LR: 3.57e-06\n",
      "Epoch  29 [  50/10697 (  0.5%)] Loss: 0.020821 L1: 0.011804 Grad: 0.090032 Thermal: 0.000288 LR: 3.57e-06\n",
      "Epoch  29 [  50/10697 (  0.5%)] Loss: 0.020821 L1: 0.011804 Grad: 0.090032 Thermal: 0.000288 LR: 3.57e-06\n",
      "Epoch  29 [ 100/10697 (  0.9%)] Loss: 0.026601 L1: 0.015696 Grad: 0.108821 Thermal: 0.000458 LR: 3.57e-06\n",
      "Epoch  29 [ 100/10697 (  0.9%)] Loss: 0.026601 L1: 0.015696 Grad: 0.108821 Thermal: 0.000458 LR: 3.57e-06\n",
      "Epoch  29 [ 150/10697 (  1.4%)] Loss: 0.026048 L1: 0.015462 Grad: 0.105635 Thermal: 0.000445 LR: 3.57e-06\n",
      "Epoch  29 [ 150/10697 (  1.4%)] Loss: 0.026048 L1: 0.015462 Grad: 0.105635 Thermal: 0.000445 LR: 3.57e-06\n",
      "Epoch  29 [ 200/10697 (  1.9%)] Loss: 0.022094 L1: 0.013191 Grad: 0.088854 Thermal: 0.000351 LR: 3.57e-06\n",
      "Epoch  29 [ 200/10697 (  1.9%)] Loss: 0.022094 L1: 0.013191 Grad: 0.088854 Thermal: 0.000351 LR: 3.57e-06\n",
      "Epoch  29 [ 250/10697 (  2.3%)] Loss: 0.030301 L1: 0.017570 Grad: 0.126997 Thermal: 0.000620 LR: 3.57e-06\n",
      "Epoch  29 [ 250/10697 (  2.3%)] Loss: 0.030301 L1: 0.017570 Grad: 0.126997 Thermal: 0.000620 LR: 3.57e-06\n",
      "Epoch  29 [ 300/10697 (  2.8%)] Loss: 0.025009 L1: 0.014976 Grad: 0.100114 Thermal: 0.000430 LR: 3.57e-06\n",
      "Epoch  29 [ 300/10697 (  2.8%)] Loss: 0.025009 L1: 0.014976 Grad: 0.100114 Thermal: 0.000430 LR: 3.57e-06\n",
      "Epoch  29 [ 350/10697 (  3.3%)] Loss: 0.026176 L1: 0.015447 Grad: 0.107053 Thermal: 0.000462 LR: 3.57e-06\n",
      "Epoch  29 [ 350/10697 (  3.3%)] Loss: 0.026176 L1: 0.015447 Grad: 0.107053 Thermal: 0.000462 LR: 3.57e-06\n",
      "Epoch  29 [ 400/10697 (  3.7%)] Loss: 0.032628 L1: 0.018655 Grad: 0.139381 Thermal: 0.000699 LR: 3.57e-06\n",
      "Epoch  29 [ 400/10697 (  3.7%)] Loss: 0.032628 L1: 0.018655 Grad: 0.139381 Thermal: 0.000699 LR: 3.57e-06\n",
      "Epoch  29 [ 450/10697 (  4.2%)] Loss: 0.032222 L1: 0.018089 Grad: 0.140990 Thermal: 0.000671 LR: 3.57e-06\n",
      "Epoch  29 [ 450/10697 (  4.2%)] Loss: 0.032222 L1: 0.018089 Grad: 0.140990 Thermal: 0.000671 LR: 3.57e-06\n",
      "Epoch  29 [ 500/10697 (  4.7%)] Loss: 0.028448 L1: 0.016451 Grad: 0.119718 Thermal: 0.000506 LR: 3.57e-06\n",
      "Epoch  29 [ 500/10697 (  4.7%)] Loss: 0.028448 L1: 0.016451 Grad: 0.119718 Thermal: 0.000506 LR: 3.57e-06\n",
      "Epoch  29 [ 550/10697 (  5.1%)] Loss: 0.024756 L1: 0.014058 Grad: 0.106770 Thermal: 0.000414 LR: 3.57e-06\n",
      "Epoch  29 [ 550/10697 (  5.1%)] Loss: 0.024756 L1: 0.014058 Grad: 0.106770 Thermal: 0.000414 LR: 3.57e-06\n",
      "Epoch  29 [ 600/10697 (  5.6%)] Loss: 0.028547 L1: 0.017356 Grad: 0.111656 Thermal: 0.000503 LR: 3.57e-06\n",
      "Epoch  29 [ 600/10697 (  5.6%)] Loss: 0.028547 L1: 0.017356 Grad: 0.111656 Thermal: 0.000503 LR: 3.57e-06\n",
      "Epoch  29 [ 650/10697 (  6.1%)] Loss: 0.029154 L1: 0.017450 Grad: 0.116766 Thermal: 0.000543 LR: 3.57e-06\n",
      "Epoch  29 [ 650/10697 (  6.1%)] Loss: 0.029154 L1: 0.017450 Grad: 0.116766 Thermal: 0.000543 LR: 3.57e-06\n",
      "Epoch  29 [ 700/10697 (  6.5%)] Loss: 0.027348 L1: 0.015946 Grad: 0.113794 Thermal: 0.000452 LR: 3.57e-06\n",
      "Epoch  29 [ 700/10697 (  6.5%)] Loss: 0.027348 L1: 0.015946 Grad: 0.113794 Thermal: 0.000452 LR: 3.57e-06\n",
      "Epoch  29 [ 750/10697 (  7.0%)] Loss: 0.025206 L1: 0.014559 Grad: 0.106265 Thermal: 0.000412 LR: 3.57e-06\n",
      "Epoch  29 [ 750/10697 (  7.0%)] Loss: 0.025206 L1: 0.014559 Grad: 0.106265 Thermal: 0.000412 LR: 3.57e-06\n",
      "Epoch  29 [ 800/10697 (  7.5%)] Loss: 0.029131 L1: 0.016955 Grad: 0.121484 Thermal: 0.000557 LR: 3.57e-06\n",
      "Epoch  29 [ 800/10697 (  7.5%)] Loss: 0.029131 L1: 0.016955 Grad: 0.121484 Thermal: 0.000557 LR: 3.57e-06\n",
      "Epoch  29 [ 850/10697 (  7.9%)] Loss: 0.028322 L1: 0.016761 Grad: 0.115359 Thermal: 0.000493 LR: 3.57e-06\n",
      "Epoch  29 [ 850/10697 (  7.9%)] Loss: 0.028322 L1: 0.016761 Grad: 0.115359 Thermal: 0.000493 LR: 3.57e-06\n",
      "Epoch  29 [ 900/10697 (  8.4%)] Loss: 0.024959 L1: 0.014259 Grad: 0.106810 Thermal: 0.000382 LR: 3.57e-06\n",
      "Epoch  29 [ 900/10697 (  8.4%)] Loss: 0.024959 L1: 0.014259 Grad: 0.106810 Thermal: 0.000382 LR: 3.57e-06\n",
      "Epoch  29 [ 950/10697 (  8.9%)] Loss: 0.025414 L1: 0.014757 Grad: 0.106370 Thermal: 0.000409 LR: 3.57e-06\n",
      "Epoch  29 [ 950/10697 (  8.9%)] Loss: 0.025414 L1: 0.014757 Grad: 0.106370 Thermal: 0.000409 LR: 3.57e-06\n",
      "Epoch  29 [1000/10697 (  9.3%)] Loss: 0.028439 L1: 0.016610 Grad: 0.118042 Thermal: 0.000503 LR: 3.57e-06\n",
      "Epoch  29 [1000/10697 (  9.3%)] Loss: 0.028439 L1: 0.016610 Grad: 0.118042 Thermal: 0.000503 LR: 3.57e-06\n",
      "Epoch  29 [1050/10697 (  9.8%)] Loss: 0.024772 L1: 0.014428 Grad: 0.103236 Thermal: 0.000390 LR: 3.57e-06\n",
      "Epoch  29 [1050/10697 (  9.8%)] Loss: 0.024772 L1: 0.014428 Grad: 0.103236 Thermal: 0.000390 LR: 3.57e-06\n",
      "Epoch  29 [1100/10697 ( 10.3%)] Loss: 0.022852 L1: 0.013533 Grad: 0.093011 Thermal: 0.000362 LR: 3.57e-06\n",
      "Epoch  29 [1100/10697 ( 10.3%)] Loss: 0.022852 L1: 0.013533 Grad: 0.093011 Thermal: 0.000362 LR: 3.57e-06\n",
      "Epoch  29 [1150/10697 ( 10.8%)] Loss: 0.027308 L1: 0.016288 Grad: 0.109955 Thermal: 0.000480 LR: 3.57e-06\n",
      "Epoch  29 [1150/10697 ( 10.8%)] Loss: 0.027308 L1: 0.016288 Grad: 0.109955 Thermal: 0.000480 LR: 3.57e-06\n",
      "Epoch  29 [1200/10697 ( 11.2%)] Loss: 0.024340 L1: 0.014577 Grad: 0.097429 Thermal: 0.000408 LR: 3.57e-06\n",
      "Epoch  29 [1200/10697 ( 11.2%)] Loss: 0.024340 L1: 0.014577 Grad: 0.097429 Thermal: 0.000408 LR: 3.57e-06\n",
      "Epoch  29 [1250/10697 ( 11.7%)] Loss: 0.027482 L1: 0.016080 Grad: 0.113756 Thermal: 0.000537 LR: 3.57e-06\n",
      "Epoch  29 [1250/10697 ( 11.7%)] Loss: 0.027482 L1: 0.016080 Grad: 0.113756 Thermal: 0.000537 LR: 3.57e-06\n",
      "Epoch  29 [1300/10697 ( 12.2%)] Loss: 0.026603 L1: 0.015848 Grad: 0.107335 Thermal: 0.000441 LR: 3.57e-06\n",
      "Epoch  29 [1300/10697 ( 12.2%)] Loss: 0.026603 L1: 0.015848 Grad: 0.107335 Thermal: 0.000441 LR: 3.57e-06\n",
      "Epoch  29 [1350/10697 ( 12.6%)] Loss: 0.029980 L1: 0.017626 Grad: 0.123263 Thermal: 0.000545 LR: 3.57e-06\n",
      "Epoch  29 [1350/10697 ( 12.6%)] Loss: 0.029980 L1: 0.017626 Grad: 0.123263 Thermal: 0.000545 LR: 3.57e-06\n",
      "Epoch  29 [1400/10697 ( 13.1%)] Loss: 0.027590 L1: 0.016072 Grad: 0.114936 Thermal: 0.000486 LR: 3.57e-06\n",
      "Epoch  29 [1400/10697 ( 13.1%)] Loss: 0.027590 L1: 0.016072 Grad: 0.114936 Thermal: 0.000486 LR: 3.57e-06\n",
      "Epoch  29 [1450/10697 ( 13.6%)] Loss: 0.026472 L1: 0.015446 Grad: 0.110048 Thermal: 0.000435 LR: 3.57e-06\n",
      "Epoch  29 [1450/10697 ( 13.6%)] Loss: 0.026472 L1: 0.015446 Grad: 0.110048 Thermal: 0.000435 LR: 3.57e-06\n",
      "Epoch  29 [1500/10697 ( 14.0%)] Loss: 0.030074 L1: 0.017712 Grad: 0.123351 Thermal: 0.000549 LR: 3.57e-06\n",
      "Epoch  29 [1500/10697 ( 14.0%)] Loss: 0.030074 L1: 0.017712 Grad: 0.123351 Thermal: 0.000549 LR: 3.57e-06\n",
      "Epoch  29 [1550/10697 ( 14.5%)] Loss: 0.023715 L1: 0.013972 Grad: 0.097238 Thermal: 0.000372 LR: 3.57e-06\n",
      "Epoch  29 [1550/10697 ( 14.5%)] Loss: 0.023715 L1: 0.013972 Grad: 0.097238 Thermal: 0.000372 LR: 3.57e-06\n",
      "Epoch  29 [1600/10697 ( 15.0%)] Loss: 0.029846 L1: 0.017042 Grad: 0.127729 Thermal: 0.000616 LR: 3.57e-06\n",
      "Epoch  29 [1600/10697 ( 15.0%)] Loss: 0.029846 L1: 0.017042 Grad: 0.127729 Thermal: 0.000616 LR: 3.57e-06\n",
      "Epoch  29 [1650/10697 ( 15.4%)] Loss: 0.031604 L1: 0.018432 Grad: 0.131374 Thermal: 0.000684 LR: 3.57e-06\n",
      "Epoch  29 [1650/10697 ( 15.4%)] Loss: 0.031604 L1: 0.018432 Grad: 0.131374 Thermal: 0.000684 LR: 3.57e-06\n",
      "Epoch  29 [1700/10697 ( 15.9%)] Loss: 0.019756 L1: 0.011319 Grad: 0.084227 Thermal: 0.000284 LR: 3.57e-06\n",
      "Epoch  29 [1700/10697 ( 15.9%)] Loss: 0.019756 L1: 0.011319 Grad: 0.084227 Thermal: 0.000284 LR: 3.57e-06\n",
      "Epoch  29 [1750/10697 ( 16.4%)] Loss: 0.029015 L1: 0.017102 Grad: 0.118884 Thermal: 0.000493 LR: 3.57e-06\n",
      "Epoch  29 [1750/10697 ( 16.4%)] Loss: 0.029015 L1: 0.017102 Grad: 0.118884 Thermal: 0.000493 LR: 3.57e-06\n",
      "Epoch  29 [1800/10697 ( 16.8%)] Loss: 0.027565 L1: 0.016392 Grad: 0.111496 Thermal: 0.000480 LR: 3.57e-06\n",
      "Epoch  29 [1800/10697 ( 16.8%)] Loss: 0.027565 L1: 0.016392 Grad: 0.111496 Thermal: 0.000480 LR: 3.57e-06\n",
      "Epoch  29 [1850/10697 ( 17.3%)] Loss: 0.028028 L1: 0.016756 Grad: 0.112468 Thermal: 0.000501 LR: 3.57e-06\n",
      "Epoch  29 [1850/10697 ( 17.3%)] Loss: 0.028028 L1: 0.016756 Grad: 0.112468 Thermal: 0.000501 LR: 3.57e-06\n",
      "Epoch  29 [1900/10697 ( 17.8%)] Loss: 0.027015 L1: 0.016271 Grad: 0.107208 Thermal: 0.000461 LR: 3.57e-06\n",
      "Epoch  29 [1900/10697 ( 17.8%)] Loss: 0.027015 L1: 0.016271 Grad: 0.107208 Thermal: 0.000461 LR: 3.57e-06\n",
      "Epoch  29 [1950/10697 ( 18.2%)] Loss: 0.026858 L1: 0.016126 Grad: 0.107097 Thermal: 0.000455 LR: 3.57e-06\n",
      "Epoch  29 [1950/10697 ( 18.2%)] Loss: 0.026858 L1: 0.016126 Grad: 0.107097 Thermal: 0.000455 LR: 3.57e-06\n",
      "Epoch  29 [2000/10697 ( 18.7%)] Loss: 0.030782 L1: 0.017654 Grad: 0.131013 Thermal: 0.000537 LR: 3.57e-06\n",
      "Epoch  29 [2000/10697 ( 18.7%)] Loss: 0.030782 L1: 0.017654 Grad: 0.131013 Thermal: 0.000537 LR: 3.57e-06\n",
      "Epoch  29 [2050/10697 ( 19.2%)] Loss: 0.024993 L1: 0.014433 Grad: 0.105383 Thermal: 0.000422 LR: 3.57e-06\n",
      "Epoch  29 [2050/10697 ( 19.2%)] Loss: 0.024993 L1: 0.014433 Grad: 0.105383 Thermal: 0.000422 LR: 3.57e-06\n",
      "Epoch  29 [2100/10697 ( 19.6%)] Loss: 0.023497 L1: 0.013785 Grad: 0.096947 Thermal: 0.000360 LR: 3.57e-06\n",
      "Epoch  29 [2100/10697 ( 19.6%)] Loss: 0.023497 L1: 0.013785 Grad: 0.096947 Thermal: 0.000360 LR: 3.57e-06\n",
      "Epoch  29 [2150/10697 ( 20.1%)] Loss: 0.025488 L1: 0.015335 Grad: 0.101319 Thermal: 0.000427 LR: 3.57e-06\n",
      "Epoch  29 [2150/10697 ( 20.1%)] Loss: 0.025488 L1: 0.015335 Grad: 0.101319 Thermal: 0.000427 LR: 3.57e-06\n",
      "Epoch  29 [2200/10697 ( 20.6%)] Loss: 0.024355 L1: 0.014070 Grad: 0.102641 Thermal: 0.000436 LR: 3.57e-06\n",
      "Epoch  29 [2200/10697 ( 20.6%)] Loss: 0.024355 L1: 0.014070 Grad: 0.102641 Thermal: 0.000436 LR: 3.57e-06\n",
      "Epoch  29 [2250/10697 ( 21.0%)] Loss: 0.025836 L1: 0.014974 Grad: 0.108399 Thermal: 0.000433 LR: 3.57e-06\n",
      "Epoch  29 [2250/10697 ( 21.0%)] Loss: 0.025836 L1: 0.014974 Grad: 0.108399 Thermal: 0.000433 LR: 3.57e-06\n",
      "Epoch  29 [2300/10697 ( 21.5%)] Loss: 0.028009 L1: 0.016509 Grad: 0.114765 Thermal: 0.000479 LR: 3.57e-06\n",
      "Epoch  29 [2300/10697 ( 21.5%)] Loss: 0.028009 L1: 0.016509 Grad: 0.114765 Thermal: 0.000479 LR: 3.57e-06\n",
      "Epoch  29 [2350/10697 ( 22.0%)] Loss: 0.033655 L1: 0.019702 Grad: 0.139142 Thermal: 0.000763 LR: 3.57e-06\n",
      "Epoch  29 [2350/10697 ( 22.0%)] Loss: 0.033655 L1: 0.019702 Grad: 0.139142 Thermal: 0.000763 LR: 3.57e-06\n",
      "Epoch  29 [2400/10697 ( 22.4%)] Loss: 0.026673 L1: 0.015267 Grad: 0.113848 Thermal: 0.000428 LR: 3.57e-06\n",
      "Epoch  29 [2400/10697 ( 22.4%)] Loss: 0.026673 L1: 0.015267 Grad: 0.113848 Thermal: 0.000428 LR: 3.57e-06\n",
      "Epoch  29 [2450/10697 ( 22.9%)] Loss: 0.021887 L1: 0.012682 Grad: 0.091879 Thermal: 0.000343 LR: 3.57e-06\n",
      "Epoch  29 [2450/10697 ( 22.9%)] Loss: 0.021887 L1: 0.012682 Grad: 0.091879 Thermal: 0.000343 LR: 3.57e-06\n",
      "Epoch  29 [2500/10697 ( 23.4%)] Loss: 0.027271 L1: 0.015427 Grad: 0.118196 Thermal: 0.000492 LR: 3.57e-06\n",
      "Epoch  29 [2500/10697 ( 23.4%)] Loss: 0.027271 L1: 0.015427 Grad: 0.118196 Thermal: 0.000492 LR: 3.57e-06\n",
      "Epoch  29 [2550/10697 ( 23.8%)] Loss: 0.026420 L1: 0.015978 Grad: 0.104185 Thermal: 0.000459 LR: 3.57e-06\n",
      "Epoch  29 [2550/10697 ( 23.8%)] Loss: 0.026420 L1: 0.015978 Grad: 0.104185 Thermal: 0.000459 LR: 3.57e-06\n",
      "Epoch  29 [2600/10697 ( 24.3%)] Loss: 0.027983 L1: 0.016275 Grad: 0.116791 Thermal: 0.000580 LR: 3.57e-06\n",
      "Epoch  29 [2600/10697 ( 24.3%)] Loss: 0.027983 L1: 0.016275 Grad: 0.116791 Thermal: 0.000580 LR: 3.57e-06\n",
      "Epoch  29 [2650/10697 ( 24.8%)] Loss: 0.030565 L1: 0.017579 Grad: 0.129559 Thermal: 0.000612 LR: 3.57e-06\n",
      "Epoch  29 [2650/10697 ( 24.8%)] Loss: 0.030565 L1: 0.017579 Grad: 0.129559 Thermal: 0.000612 LR: 3.57e-06\n",
      "Epoch  29 [2700/10697 ( 25.2%)] Loss: 0.022218 L1: 0.012606 Grad: 0.095958 Thermal: 0.000314 LR: 3.57e-06\n",
      "Epoch  29 [2700/10697 ( 25.2%)] Loss: 0.022218 L1: 0.012606 Grad: 0.095958 Thermal: 0.000314 LR: 3.57e-06\n",
      "Epoch  29 [2750/10697 ( 25.7%)] Loss: 0.027848 L1: 0.016200 Grad: 0.116244 Thermal: 0.000475 LR: 3.57e-06\n",
      "Epoch  29 [2750/10697 ( 25.7%)] Loss: 0.027848 L1: 0.016200 Grad: 0.116244 Thermal: 0.000475 LR: 3.57e-06\n",
      "Epoch  29 [2800/10697 ( 26.2%)] Loss: 0.027056 L1: 0.015584 Grad: 0.114481 Thermal: 0.000470 LR: 3.57e-06\n",
      "Epoch  29 [2800/10697 ( 26.2%)] Loss: 0.027056 L1: 0.015584 Grad: 0.114481 Thermal: 0.000470 LR: 3.57e-06\n",
      "Epoch  29 [2850/10697 ( 26.6%)] Loss: 0.026969 L1: 0.015577 Grad: 0.113651 Thermal: 0.000533 LR: 3.57e-06\n",
      "Epoch  29 [2850/10697 ( 26.6%)] Loss: 0.026969 L1: 0.015577 Grad: 0.113651 Thermal: 0.000533 LR: 3.57e-06\n",
      "Epoch  29 [2900/10697 ( 27.1%)] Loss: 0.025803 L1: 0.014661 Grad: 0.111212 Thermal: 0.000424 LR: 3.57e-06\n",
      "Epoch  29 [2900/10697 ( 27.1%)] Loss: 0.025803 L1: 0.014661 Grad: 0.111212 Thermal: 0.000424 LR: 3.57e-06\n",
      "Epoch  29 [2950/10697 ( 27.6%)] Loss: 0.028406 L1: 0.016380 Grad: 0.119997 Thermal: 0.000536 LR: 3.57e-06\n",
      "Epoch  29 [2950/10697 ( 27.6%)] Loss: 0.028406 L1: 0.016380 Grad: 0.119997 Thermal: 0.000536 LR: 3.57e-06\n",
      "Epoch  29 [3000/10697 ( 28.0%)] Loss: 0.026142 L1: 0.015798 Grad: 0.103223 Thermal: 0.000431 LR: 3.57e-06\n",
      "Epoch  29 [3000/10697 ( 28.0%)] Loss: 0.026142 L1: 0.015798 Grad: 0.103223 Thermal: 0.000431 LR: 3.57e-06\n",
      "Epoch  29 [3050/10697 ( 28.5%)] Loss: 0.030040 L1: 0.017586 Grad: 0.124264 Thermal: 0.000550 LR: 3.57e-06\n",
      "Epoch  29 [3050/10697 ( 28.5%)] Loss: 0.030040 L1: 0.017586 Grad: 0.124264 Thermal: 0.000550 LR: 3.57e-06\n",
      "Epoch  29 [3100/10697 ( 29.0%)] Loss: 0.032126 L1: 0.018116 Grad: 0.139699 Thermal: 0.000787 LR: 3.57e-06\n",
      "Epoch  29 [3100/10697 ( 29.0%)] Loss: 0.032126 L1: 0.018116 Grad: 0.139699 Thermal: 0.000787 LR: 3.57e-06\n",
      "Epoch  29 [3150/10697 ( 29.4%)] Loss: 0.023238 L1: 0.013455 Grad: 0.097648 Thermal: 0.000362 LR: 3.57e-06\n",
      "Epoch  29 [3150/10697 ( 29.4%)] Loss: 0.023238 L1: 0.013455 Grad: 0.097648 Thermal: 0.000362 LR: 3.57e-06\n",
      "Epoch  29 [3200/10697 ( 29.9%)] Loss: 0.029847 L1: 0.017592 Grad: 0.122262 Thermal: 0.000570 LR: 3.57e-06\n",
      "Epoch  29 [3200/10697 ( 29.9%)] Loss: 0.029847 L1: 0.017592 Grad: 0.122262 Thermal: 0.000570 LR: 3.57e-06\n",
      "Epoch  29 [3250/10697 ( 30.4%)] Loss: 0.023550 L1: 0.013787 Grad: 0.097441 Thermal: 0.000371 LR: 3.57e-06\n",
      "Epoch  29 [3250/10697 ( 30.4%)] Loss: 0.023550 L1: 0.013787 Grad: 0.097441 Thermal: 0.000371 LR: 3.57e-06\n",
      "Epoch  29 [3300/10697 ( 30.8%)] Loss: 0.025656 L1: 0.015186 Grad: 0.104482 Thermal: 0.000427 LR: 3.57e-06\n",
      "Epoch  29 [3300/10697 ( 30.8%)] Loss: 0.025656 L1: 0.015186 Grad: 0.104482 Thermal: 0.000427 LR: 3.57e-06\n",
      "Epoch  29 [3350/10697 ( 31.3%)] Loss: 0.023462 L1: 0.014035 Grad: 0.094084 Thermal: 0.000367 LR: 3.57e-06\n",
      "Epoch  29 [3350/10697 ( 31.3%)] Loss: 0.023462 L1: 0.014035 Grad: 0.094084 Thermal: 0.000367 LR: 3.57e-06\n",
      "Epoch  29 [3400/10697 ( 31.8%)] Loss: 0.027922 L1: 0.016429 Grad: 0.114698 Thermal: 0.000471 LR: 3.57e-06\n",
      "Epoch  29 [3400/10697 ( 31.8%)] Loss: 0.027922 L1: 0.016429 Grad: 0.114698 Thermal: 0.000471 LR: 3.57e-06\n",
      "Epoch  29 [3450/10697 ( 32.3%)] Loss: 0.027877 L1: 0.016494 Grad: 0.113594 Thermal: 0.000470 LR: 3.57e-06\n",
      "Epoch  29 [3450/10697 ( 32.3%)] Loss: 0.027877 L1: 0.016494 Grad: 0.113594 Thermal: 0.000470 LR: 3.57e-06\n",
      "Epoch  29 [3500/10697 ( 32.7%)] Loss: 0.025160 L1: 0.015095 Grad: 0.100430 Thermal: 0.000435 LR: 3.57e-06\n",
      "Epoch  29 [3500/10697 ( 32.7%)] Loss: 0.025160 L1: 0.015095 Grad: 0.100430 Thermal: 0.000435 LR: 3.57e-06\n",
      "Epoch  29 [3550/10697 ( 33.2%)] Loss: 0.027985 L1: 0.016114 Grad: 0.118462 Thermal: 0.000501 LR: 3.57e-06\n",
      "Epoch  29 [3550/10697 ( 33.2%)] Loss: 0.027985 L1: 0.016114 Grad: 0.118462 Thermal: 0.000501 LR: 3.57e-06\n",
      "Epoch  29 [3600/10697 ( 33.7%)] Loss: 0.028688 L1: 0.016445 Grad: 0.122179 Thermal: 0.000504 LR: 3.57e-06\n",
      "Epoch  29 [3600/10697 ( 33.7%)] Loss: 0.028688 L1: 0.016445 Grad: 0.122179 Thermal: 0.000504 LR: 3.57e-06\n",
      "Epoch  29 [3650/10697 ( 34.1%)] Loss: 0.026046 L1: 0.015338 Grad: 0.106855 Thermal: 0.000440 LR: 3.57e-06\n",
      "Epoch  29 [3650/10697 ( 34.1%)] Loss: 0.026046 L1: 0.015338 Grad: 0.106855 Thermal: 0.000440 LR: 3.57e-06\n",
      "Epoch  29 [3700/10697 ( 34.6%)] Loss: 0.030953 L1: 0.018093 Grad: 0.128307 Thermal: 0.000571 LR: 3.57e-06\n",
      "Epoch  29 [3700/10697 ( 34.6%)] Loss: 0.030953 L1: 0.018093 Grad: 0.128307 Thermal: 0.000571 LR: 3.57e-06\n",
      "Epoch  29 [3750/10697 ( 35.1%)] Loss: 0.032866 L1: 0.018729 Grad: 0.141044 Thermal: 0.000653 LR: 3.57e-06\n",
      "Epoch  29 [3750/10697 ( 35.1%)] Loss: 0.032866 L1: 0.018729 Grad: 0.141044 Thermal: 0.000653 LR: 3.57e-06\n",
      "Epoch  29 [3800/10697 ( 35.5%)] Loss: 0.026825 L1: 0.016045 Grad: 0.107554 Thermal: 0.000489 LR: 3.57e-06\n",
      "Epoch  29 [3800/10697 ( 35.5%)] Loss: 0.026825 L1: 0.016045 Grad: 0.107554 Thermal: 0.000489 LR: 3.57e-06\n",
      "Epoch  29 [3850/10697 ( 36.0%)] Loss: 0.023927 L1: 0.014319 Grad: 0.095863 Thermal: 0.000432 LR: 3.57e-06\n",
      "Epoch  29 [3850/10697 ( 36.0%)] Loss: 0.023927 L1: 0.014319 Grad: 0.095863 Thermal: 0.000432 LR: 3.57e-06\n",
      "Epoch  29 [3900/10697 ( 36.5%)] Loss: 0.025743 L1: 0.014987 Grad: 0.107339 Thermal: 0.000424 LR: 3.57e-06\n",
      "Epoch  29 [3900/10697 ( 36.5%)] Loss: 0.025743 L1: 0.014987 Grad: 0.107339 Thermal: 0.000424 LR: 3.57e-06\n",
      "Epoch  29 [3950/10697 ( 36.9%)] Loss: 0.029478 L1: 0.017426 Grad: 0.120245 Thermal: 0.000550 LR: 3.57e-06\n",
      "Epoch  29 [3950/10697 ( 36.9%)] Loss: 0.029478 L1: 0.017426 Grad: 0.120245 Thermal: 0.000550 LR: 3.57e-06\n",
      "Epoch  29 [4000/10697 ( 37.4%)] Loss: 0.026040 L1: 0.015594 Grad: 0.104230 Thermal: 0.000442 LR: 3.57e-06\n",
      "Epoch  29 [4000/10697 ( 37.4%)] Loss: 0.026040 L1: 0.015594 Grad: 0.104230 Thermal: 0.000442 LR: 3.57e-06\n",
      "Epoch  29 [4050/10697 ( 37.9%)] Loss: 0.029208 L1: 0.017054 Grad: 0.121255 Thermal: 0.000567 LR: 3.57e-06\n",
      "Epoch  29 [4050/10697 ( 37.9%)] Loss: 0.029208 L1: 0.017054 Grad: 0.121255 Thermal: 0.000567 LR: 3.57e-06\n",
      "Epoch  29 [4100/10697 ( 38.3%)] Loss: 0.025419 L1: 0.014763 Grad: 0.106367 Thermal: 0.000377 LR: 3.57e-06\n",
      "Epoch  29 [4100/10697 ( 38.3%)] Loss: 0.025419 L1: 0.014763 Grad: 0.106367 Thermal: 0.000377 LR: 3.57e-06\n",
      "Epoch  29 [4150/10697 ( 38.8%)] Loss: 0.022358 L1: 0.012612 Grad: 0.097292 Thermal: 0.000343 LR: 3.57e-06\n",
      "Epoch  29 [4150/10697 ( 38.8%)] Loss: 0.022358 L1: 0.012612 Grad: 0.097292 Thermal: 0.000343 LR: 3.57e-06\n",
      "Epoch  29 [4200/10697 ( 39.3%)] Loss: 0.023964 L1: 0.013682 Grad: 0.102636 Thermal: 0.000375 LR: 3.57e-06\n",
      "Epoch  29 [4200/10697 ( 39.3%)] Loss: 0.023964 L1: 0.013682 Grad: 0.102636 Thermal: 0.000375 LR: 3.57e-06\n",
      "Epoch  29 [4250/10697 ( 39.7%)] Loss: 0.020807 L1: 0.012206 Grad: 0.085854 Thermal: 0.000311 LR: 3.57e-06\n",
      "Epoch  29 [4250/10697 ( 39.7%)] Loss: 0.020807 L1: 0.012206 Grad: 0.085854 Thermal: 0.000311 LR: 3.57e-06\n",
      "Epoch  29 [4300/10697 ( 40.2%)] Loss: 0.027985 L1: 0.016080 Grad: 0.118786 Thermal: 0.000527 LR: 3.57e-06\n",
      "Epoch  29 [4300/10697 ( 40.2%)] Loss: 0.027985 L1: 0.016080 Grad: 0.118786 Thermal: 0.000527 LR: 3.57e-06\n",
      "Epoch  29 [4350/10697 ( 40.7%)] Loss: 0.025963 L1: 0.015392 Grad: 0.105496 Thermal: 0.000427 LR: 3.57e-06\n",
      "Epoch  29 [4350/10697 ( 40.7%)] Loss: 0.025963 L1: 0.015392 Grad: 0.105496 Thermal: 0.000427 LR: 3.57e-06\n",
      "Epoch  29 [4400/10697 ( 41.1%)] Loss: 0.028092 L1: 0.016129 Grad: 0.119387 Thermal: 0.000486 LR: 3.57e-06\n",
      "Epoch  29 [4400/10697 ( 41.1%)] Loss: 0.028092 L1: 0.016129 Grad: 0.119387 Thermal: 0.000486 LR: 3.57e-06\n",
      "Epoch  29 [4450/10697 ( 41.6%)] Loss: 0.024246 L1: 0.014113 Grad: 0.101139 Thermal: 0.000381 LR: 3.57e-06\n",
      "Epoch  29 [4450/10697 ( 41.6%)] Loss: 0.024246 L1: 0.014113 Grad: 0.101139 Thermal: 0.000381 LR: 3.57e-06\n",
      "Epoch  29 [4500/10697 ( 42.1%)] Loss: 0.029833 L1: 0.017509 Grad: 0.122969 Thermal: 0.000548 LR: 3.57e-06\n",
      "Epoch  29 [4500/10697 ( 42.1%)] Loss: 0.029833 L1: 0.017509 Grad: 0.122969 Thermal: 0.000548 LR: 3.57e-06\n",
      "Epoch  29 [4550/10697 ( 42.5%)] Loss: 0.027318 L1: 0.015282 Grad: 0.120139 Thermal: 0.000452 LR: 3.57e-06\n",
      "Epoch  29 [4550/10697 ( 42.5%)] Loss: 0.027318 L1: 0.015282 Grad: 0.120139 Thermal: 0.000452 LR: 3.57e-06\n",
      "Epoch  29 [4600/10697 ( 43.0%)] Loss: 0.024730 L1: 0.014466 Grad: 0.102419 Thermal: 0.000441 LR: 3.57e-06\n",
      "Epoch  29 [4600/10697 ( 43.0%)] Loss: 0.024730 L1: 0.014466 Grad: 0.102419 Thermal: 0.000441 LR: 3.57e-06\n",
      "Epoch  29 [4650/10697 ( 43.5%)] Loss: 0.032336 L1: 0.018642 Grad: 0.136588 Thermal: 0.000700 LR: 3.57e-06\n",
      "Epoch  29 [4650/10697 ( 43.5%)] Loss: 0.032336 L1: 0.018642 Grad: 0.136588 Thermal: 0.000700 LR: 3.57e-06\n",
      "Epoch  29 [4700/10697 ( 43.9%)] Loss: 0.023286 L1: 0.013334 Grad: 0.099365 Thermal: 0.000323 LR: 3.57e-06\n",
      "Epoch  29 [4700/10697 ( 43.9%)] Loss: 0.023286 L1: 0.013334 Grad: 0.099365 Thermal: 0.000323 LR: 3.57e-06\n",
      "Epoch  29 [4750/10697 ( 44.4%)] Loss: 0.023089 L1: 0.013501 Grad: 0.095709 Thermal: 0.000343 LR: 3.57e-06\n",
      "Epoch  29 [4750/10697 ( 44.4%)] Loss: 0.023089 L1: 0.013501 Grad: 0.095709 Thermal: 0.000343 LR: 3.57e-06\n",
      "Epoch  29 [4800/10697 ( 44.9%)] Loss: 0.031227 L1: 0.018065 Grad: 0.131298 Thermal: 0.000641 LR: 3.57e-06\n",
      "Epoch  29 [4800/10697 ( 44.9%)] Loss: 0.031227 L1: 0.018065 Grad: 0.131298 Thermal: 0.000641 LR: 3.57e-06\n",
      "Epoch  29 [4850/10697 ( 45.3%)] Loss: 0.031633 L1: 0.018759 Grad: 0.128433 Thermal: 0.000629 LR: 3.57e-06\n",
      "Epoch  29 [4850/10697 ( 45.3%)] Loss: 0.031633 L1: 0.018759 Grad: 0.128433 Thermal: 0.000629 LR: 3.57e-06\n",
      "Epoch  29 [4900/10697 ( 45.8%)] Loss: 0.027690 L1: 0.016573 Grad: 0.110941 Thermal: 0.000462 LR: 3.57e-06\n",
      "Epoch  29 [4900/10697 ( 45.8%)] Loss: 0.027690 L1: 0.016573 Grad: 0.110941 Thermal: 0.000462 LR: 3.57e-06\n",
      "Epoch  29 [4950/10697 ( 46.3%)] Loss: 0.018727 L1: 0.010482 Grad: 0.082299 Thermal: 0.000303 LR: 3.57e-06\n",
      "Epoch  29 [4950/10697 ( 46.3%)] Loss: 0.018727 L1: 0.010482 Grad: 0.082299 Thermal: 0.000303 LR: 3.57e-06\n",
      "Epoch  29 [5000/10697 ( 46.7%)] Loss: 0.030763 L1: 0.017607 Grad: 0.131278 Thermal: 0.000567 LR: 3.57e-06\n",
      "Epoch  29 [5000/10697 ( 46.7%)] Loss: 0.030763 L1: 0.017607 Grad: 0.131278 Thermal: 0.000567 LR: 3.57e-06\n",
      "Epoch  29 [5050/10697 ( 47.2%)] Loss: 0.029986 L1: 0.017508 Grad: 0.124489 Thermal: 0.000586 LR: 3.57e-06\n",
      "Epoch  29 [5050/10697 ( 47.2%)] Loss: 0.029986 L1: 0.017508 Grad: 0.124489 Thermal: 0.000586 LR: 3.57e-06\n",
      "Epoch  29 [5100/10697 ( 47.7%)] Loss: 0.022327 L1: 0.013329 Grad: 0.089798 Thermal: 0.000362 LR: 3.57e-06\n",
      "Epoch  29 [5100/10697 ( 47.7%)] Loss: 0.022327 L1: 0.013329 Grad: 0.089798 Thermal: 0.000362 LR: 3.57e-06\n",
      "Epoch  29 [5150/10697 ( 48.1%)] Loss: 0.029982 L1: 0.017095 Grad: 0.128573 Thermal: 0.000598 LR: 3.57e-06\n",
      "Epoch  29 [5150/10697 ( 48.1%)] Loss: 0.029982 L1: 0.017095 Grad: 0.128573 Thermal: 0.000598 LR: 3.57e-06\n",
      "Epoch  29 [5200/10697 ( 48.6%)] Loss: 0.026964 L1: 0.015846 Grad: 0.110950 Thermal: 0.000451 LR: 3.57e-06\n",
      "Epoch  29 [5200/10697 ( 48.6%)] Loss: 0.026964 L1: 0.015846 Grad: 0.110950 Thermal: 0.000451 LR: 3.57e-06\n",
      "Epoch  29 [5250/10697 ( 49.1%)] Loss: 0.024587 L1: 0.014727 Grad: 0.098403 Thermal: 0.000387 LR: 3.57e-06\n",
      "Epoch  29 [5250/10697 ( 49.1%)] Loss: 0.024587 L1: 0.014727 Grad: 0.098403 Thermal: 0.000387 LR: 3.57e-06\n",
      "Epoch  29 [5300/10697 ( 49.5%)] Loss: 0.020144 L1: 0.011759 Grad: 0.083710 Thermal: 0.000284 LR: 3.57e-06\n",
      "Epoch  29 [5300/10697 ( 49.5%)] Loss: 0.020144 L1: 0.011759 Grad: 0.083710 Thermal: 0.000284 LR: 3.57e-06\n",
      "Epoch  29 [5350/10697 ( 50.0%)] Loss: 0.033600 L1: 0.019957 Grad: 0.136064 Thermal: 0.000752 LR: 3.57e-06\n",
      "Epoch  29 [5350/10697 ( 50.0%)] Loss: 0.033600 L1: 0.019957 Grad: 0.136064 Thermal: 0.000752 LR: 3.57e-06\n",
      "Epoch  29 [5400/10697 ( 50.5%)] Loss: 0.026062 L1: 0.015164 Grad: 0.108773 Thermal: 0.000416 LR: 3.57e-06\n",
      "Epoch  29 [5400/10697 ( 50.5%)] Loss: 0.026062 L1: 0.015164 Grad: 0.108773 Thermal: 0.000416 LR: 3.57e-06\n",
      "Epoch  29 [5450/10697 ( 50.9%)] Loss: 0.026281 L1: 0.015617 Grad: 0.106379 Thermal: 0.000509 LR: 3.57e-06\n",
      "Epoch  29 [5450/10697 ( 50.9%)] Loss: 0.026281 L1: 0.015617 Grad: 0.106379 Thermal: 0.000509 LR: 3.57e-06\n",
      "Epoch  29 [5500/10697 ( 51.4%)] Loss: 0.033519 L1: 0.019686 Grad: 0.137973 Thermal: 0.000711 LR: 3.57e-06\n",
      "Epoch  29 [5500/10697 ( 51.4%)] Loss: 0.033519 L1: 0.019686 Grad: 0.137973 Thermal: 0.000711 LR: 3.57e-06\n",
      "Epoch  29 [5550/10697 ( 51.9%)] Loss: 0.028248 L1: 0.016594 Grad: 0.116287 Thermal: 0.000495 LR: 3.57e-06\n",
      "Epoch  29 [5550/10697 ( 51.9%)] Loss: 0.028248 L1: 0.016594 Grad: 0.116287 Thermal: 0.000495 LR: 3.57e-06\n",
      "Epoch  29 [5600/10697 ( 52.4%)] Loss: 0.025171 L1: 0.014698 Grad: 0.104534 Thermal: 0.000409 LR: 3.57e-06\n",
      "Epoch  29 [5600/10697 ( 52.4%)] Loss: 0.025171 L1: 0.014698 Grad: 0.104534 Thermal: 0.000409 LR: 3.57e-06\n",
      "Epoch  29 [5650/10697 ( 52.8%)] Loss: 0.022981 L1: 0.013726 Grad: 0.092365 Thermal: 0.000357 LR: 3.57e-06\n",
      "Epoch  29 [5650/10697 ( 52.8%)] Loss: 0.022981 L1: 0.013726 Grad: 0.092365 Thermal: 0.000357 LR: 3.57e-06\n",
      "Epoch  29 [5700/10697 ( 53.3%)] Loss: 0.023158 L1: 0.013494 Grad: 0.096455 Thermal: 0.000362 LR: 3.57e-06\n",
      "Epoch  29 [5700/10697 ( 53.3%)] Loss: 0.023158 L1: 0.013494 Grad: 0.096455 Thermal: 0.000362 LR: 3.57e-06\n",
      "Epoch  29 [5750/10697 ( 53.8%)] Loss: 0.027333 L1: 0.016300 Grad: 0.110076 Thermal: 0.000504 LR: 3.57e-06\n",
      "Epoch  29 [5750/10697 ( 53.8%)] Loss: 0.027333 L1: 0.016300 Grad: 0.110076 Thermal: 0.000504 LR: 3.57e-06\n",
      "Epoch  29 [5800/10697 ( 54.2%)] Loss: 0.026706 L1: 0.015162 Grad: 0.115228 Thermal: 0.000432 LR: 3.57e-06\n",
      "Epoch  29 [5800/10697 ( 54.2%)] Loss: 0.026706 L1: 0.015162 Grad: 0.115228 Thermal: 0.000432 LR: 3.57e-06\n",
      "Epoch  29 [5850/10697 ( 54.7%)] Loss: 0.029195 L1: 0.017170 Grad: 0.119983 Thermal: 0.000527 LR: 3.57e-06\n",
      "Epoch  29 [5850/10697 ( 54.7%)] Loss: 0.029195 L1: 0.017170 Grad: 0.119983 Thermal: 0.000527 LR: 3.57e-06\n",
      "Epoch  29 [5900/10697 ( 55.2%)] Loss: 0.025575 L1: 0.014735 Grad: 0.108191 Thermal: 0.000412 LR: 3.57e-06\n",
      "Epoch  29 [5900/10697 ( 55.2%)] Loss: 0.025575 L1: 0.014735 Grad: 0.108191 Thermal: 0.000412 LR: 3.57e-06\n",
      "Epoch  29 [5950/10697 ( 55.6%)] Loss: 0.027263 L1: 0.016112 Grad: 0.111271 Thermal: 0.000496 LR: 3.57e-06\n",
      "Epoch  29 [5950/10697 ( 55.6%)] Loss: 0.027263 L1: 0.016112 Grad: 0.111271 Thermal: 0.000496 LR: 3.57e-06\n",
      "Epoch  29 [6000/10697 ( 56.1%)] Loss: 0.027027 L1: 0.015379 Grad: 0.116241 Thermal: 0.000484 LR: 3.57e-06\n",
      "Epoch  29 [6000/10697 ( 56.1%)] Loss: 0.027027 L1: 0.015379 Grad: 0.116241 Thermal: 0.000484 LR: 3.57e-06\n",
      "Epoch  29 [6050/10697 ( 56.6%)] Loss: 0.025971 L1: 0.014647 Grad: 0.113019 Thermal: 0.000443 LR: 3.57e-06\n",
      "Epoch  29 [6050/10697 ( 56.6%)] Loss: 0.025971 L1: 0.014647 Grad: 0.113019 Thermal: 0.000443 LR: 3.57e-06\n",
      "Epoch  29 [6100/10697 ( 57.0%)] Loss: 0.019284 L1: 0.010911 Grad: 0.083605 Thermal: 0.000242 LR: 3.57e-06\n",
      "Epoch  29 [6100/10697 ( 57.0%)] Loss: 0.019284 L1: 0.010911 Grad: 0.083605 Thermal: 0.000242 LR: 3.57e-06\n",
      "Epoch  29 [6150/10697 ( 57.5%)] Loss: 0.034643 L1: 0.020526 Grad: 0.140765 Thermal: 0.000810 LR: 3.57e-06\n",
      "Epoch  29 [6150/10697 ( 57.5%)] Loss: 0.034643 L1: 0.020526 Grad: 0.140765 Thermal: 0.000810 LR: 3.57e-06\n",
      "Epoch  29 [6200/10697 ( 58.0%)] Loss: 0.034026 L1: 0.019391 Grad: 0.145979 Thermal: 0.000732 LR: 3.57e-06\n",
      "Epoch  29 [6200/10697 ( 58.0%)] Loss: 0.034026 L1: 0.019391 Grad: 0.145979 Thermal: 0.000732 LR: 3.57e-06\n",
      "Epoch  29 [6250/10697 ( 58.4%)] Loss: 0.024931 L1: 0.014642 Grad: 0.102680 Thermal: 0.000434 LR: 3.57e-06\n",
      "Epoch  29 [6250/10697 ( 58.4%)] Loss: 0.024931 L1: 0.014642 Grad: 0.102680 Thermal: 0.000434 LR: 3.57e-06\n",
      "Epoch  29 [6300/10697 ( 58.9%)] Loss: 0.025926 L1: 0.015290 Grad: 0.106135 Thermal: 0.000442 LR: 3.57e-06\n",
      "Epoch  29 [6300/10697 ( 58.9%)] Loss: 0.025926 L1: 0.015290 Grad: 0.106135 Thermal: 0.000442 LR: 3.57e-06\n",
      "Epoch  29 [6350/10697 ( 59.4%)] Loss: 0.028391 L1: 0.016347 Grad: 0.120214 Thermal: 0.000455 LR: 3.57e-06\n",
      "Epoch  29 [6350/10697 ( 59.4%)] Loss: 0.028391 L1: 0.016347 Grad: 0.120214 Thermal: 0.000455 LR: 3.57e-06\n",
      "Epoch  29 [6400/10697 ( 59.8%)] Loss: 0.025502 L1: 0.015215 Grad: 0.102657 Thermal: 0.000428 LR: 3.57e-06\n",
      "Epoch  29 [6400/10697 ( 59.8%)] Loss: 0.025502 L1: 0.015215 Grad: 0.102657 Thermal: 0.000428 LR: 3.57e-06\n",
      "Epoch  29 [6450/10697 ( 60.3%)] Loss: 0.023946 L1: 0.013964 Grad: 0.099631 Thermal: 0.000374 LR: 3.57e-06\n",
      "Epoch  29 [6450/10697 ( 60.3%)] Loss: 0.023946 L1: 0.013964 Grad: 0.099631 Thermal: 0.000374 LR: 3.57e-06\n",
      "Epoch  29 [6500/10697 ( 60.8%)] Loss: 0.022234 L1: 0.012989 Grad: 0.092270 Thermal: 0.000365 LR: 3.57e-06\n",
      "Epoch  29 [6500/10697 ( 60.8%)] Loss: 0.022234 L1: 0.012989 Grad: 0.092270 Thermal: 0.000365 LR: 3.57e-06\n",
      "Epoch  29 [6550/10697 ( 61.2%)] Loss: 0.026575 L1: 0.015629 Grad: 0.109235 Thermal: 0.000450 LR: 3.57e-06\n",
      "Epoch  29 [6550/10697 ( 61.2%)] Loss: 0.026575 L1: 0.015629 Grad: 0.109235 Thermal: 0.000450 LR: 3.57e-06\n",
      "Epoch  29 [6600/10697 ( 61.7%)] Loss: 0.030118 L1: 0.017743 Grad: 0.123478 Thermal: 0.000554 LR: 3.57e-06\n",
      "Epoch  29 [6600/10697 ( 61.7%)] Loss: 0.030118 L1: 0.017743 Grad: 0.123478 Thermal: 0.000554 LR: 3.57e-06\n",
      "Epoch  29 [6650/10697 ( 62.2%)] Loss: 0.023705 L1: 0.013876 Grad: 0.098104 Thermal: 0.000367 LR: 3.57e-06\n",
      "Epoch  29 [6650/10697 ( 62.2%)] Loss: 0.023705 L1: 0.013876 Grad: 0.098104 Thermal: 0.000367 LR: 3.57e-06\n",
      "Epoch  29 [6700/10697 ( 62.6%)] Loss: 0.027484 L1: 0.016237 Grad: 0.112224 Thermal: 0.000474 LR: 3.57e-06\n",
      "Epoch  29 [6700/10697 ( 62.6%)] Loss: 0.027484 L1: 0.016237 Grad: 0.112224 Thermal: 0.000474 LR: 3.57e-06\n",
      "Epoch  29 [6750/10697 ( 63.1%)] Loss: 0.024418 L1: 0.014145 Grad: 0.102532 Thermal: 0.000390 LR: 3.57e-06\n",
      "Epoch  29 [6750/10697 ( 63.1%)] Loss: 0.024418 L1: 0.014145 Grad: 0.102532 Thermal: 0.000390 LR: 3.57e-06\n",
      "Epoch  29 [6800/10697 ( 63.6%)] Loss: 0.022711 L1: 0.013493 Grad: 0.092003 Thermal: 0.000358 LR: 3.57e-06\n",
      "Epoch  29 [6800/10697 ( 63.6%)] Loss: 0.022711 L1: 0.013493 Grad: 0.092003 Thermal: 0.000358 LR: 3.57e-06\n",
      "Epoch  29 [6850/10697 ( 64.0%)] Loss: 0.024091 L1: 0.014446 Grad: 0.096259 Thermal: 0.000374 LR: 3.57e-06\n",
      "Epoch  29 [6850/10697 ( 64.0%)] Loss: 0.024091 L1: 0.014446 Grad: 0.096259 Thermal: 0.000374 LR: 3.57e-06\n",
      "Epoch  29 [6900/10697 ( 64.5%)] Loss: 0.026162 L1: 0.015929 Grad: 0.102101 Thermal: 0.000471 LR: 3.57e-06\n",
      "Epoch  29 [6900/10697 ( 64.5%)] Loss: 0.026162 L1: 0.015929 Grad: 0.102101 Thermal: 0.000471 LR: 3.57e-06\n",
      "Epoch  29 [6950/10697 ( 65.0%)] Loss: 0.031891 L1: 0.018032 Grad: 0.138259 Thermal: 0.000655 LR: 3.57e-06\n",
      "Epoch  29 [6950/10697 ( 65.0%)] Loss: 0.031891 L1: 0.018032 Grad: 0.138259 Thermal: 0.000655 LR: 3.57e-06\n",
      "Epoch  29 [7000/10697 ( 65.4%)] Loss: 0.026471 L1: 0.016054 Grad: 0.103940 Thermal: 0.000457 LR: 3.57e-06\n",
      "Epoch  29 [7000/10697 ( 65.4%)] Loss: 0.026471 L1: 0.016054 Grad: 0.103940 Thermal: 0.000457 LR: 3.57e-06\n",
      "Epoch  29 [7050/10697 ( 65.9%)] Loss: 0.026809 L1: 0.015331 Grad: 0.114552 Thermal: 0.000454 LR: 3.57e-06\n",
      "Epoch  29 [7050/10697 ( 65.9%)] Loss: 0.026809 L1: 0.015331 Grad: 0.114552 Thermal: 0.000454 LR: 3.57e-06\n",
      "Epoch  29 [7100/10697 ( 66.4%)] Loss: 0.025582 L1: 0.014960 Grad: 0.106008 Thermal: 0.000422 LR: 3.57e-06\n",
      "Epoch  29 [7100/10697 ( 66.4%)] Loss: 0.025582 L1: 0.014960 Grad: 0.106008 Thermal: 0.000422 LR: 3.57e-06\n",
      "Epoch  29 [7150/10697 ( 66.8%)] Loss: 0.028326 L1: 0.016993 Grad: 0.113075 Thermal: 0.000503 LR: 3.57e-06\n",
      "Epoch  29 [7150/10697 ( 66.8%)] Loss: 0.028326 L1: 0.016993 Grad: 0.113075 Thermal: 0.000503 LR: 3.57e-06\n",
      "Epoch  29 [7200/10697 ( 67.3%)] Loss: 0.024858 L1: 0.014552 Grad: 0.102878 Thermal: 0.000363 LR: 3.57e-06\n",
      "Epoch  29 [7200/10697 ( 67.3%)] Loss: 0.024858 L1: 0.014552 Grad: 0.102878 Thermal: 0.000363 LR: 3.57e-06\n",
      "Epoch  29 [7250/10697 ( 67.8%)] Loss: 0.025890 L1: 0.015528 Grad: 0.103397 Thermal: 0.000433 LR: 3.57e-06\n",
      "Epoch  29 [7250/10697 ( 67.8%)] Loss: 0.025890 L1: 0.015528 Grad: 0.103397 Thermal: 0.000433 LR: 3.57e-06\n",
      "Epoch  29 [7300/10697 ( 68.2%)] Loss: 0.026105 L1: 0.015192 Grad: 0.108896 Thermal: 0.000463 LR: 3.57e-06\n",
      "Epoch  29 [7300/10697 ( 68.2%)] Loss: 0.026105 L1: 0.015192 Grad: 0.108896 Thermal: 0.000463 LR: 3.57e-06\n",
      "Epoch  29 [7350/10697 ( 68.7%)] Loss: 0.035623 L1: 0.020511 Grad: 0.150691 Thermal: 0.000850 LR: 3.57e-06\n",
      "Epoch  29 [7350/10697 ( 68.7%)] Loss: 0.035623 L1: 0.020511 Grad: 0.150691 Thermal: 0.000850 LR: 3.57e-06\n",
      "Epoch  29 [7400/10697 ( 69.2%)] Loss: 0.027593 L1: 0.016273 Grad: 0.112981 Thermal: 0.000450 LR: 3.57e-06\n",
      "Epoch  29 [7400/10697 ( 69.2%)] Loss: 0.027593 L1: 0.016273 Grad: 0.112981 Thermal: 0.000450 LR: 3.57e-06\n",
      "Epoch  29 [7450/10697 ( 69.6%)] Loss: 0.024597 L1: 0.014431 Grad: 0.101433 Thermal: 0.000454 LR: 3.57e-06\n",
      "Epoch  29 [7450/10697 ( 69.6%)] Loss: 0.024597 L1: 0.014431 Grad: 0.101433 Thermal: 0.000454 LR: 3.57e-06\n",
      "Epoch  29 [7500/10697 ( 70.1%)] Loss: 0.030255 L1: 0.018114 Grad: 0.121117 Thermal: 0.000584 LR: 3.57e-06\n",
      "Epoch  29 [7500/10697 ( 70.1%)] Loss: 0.030255 L1: 0.018114 Grad: 0.121117 Thermal: 0.000584 LR: 3.57e-06\n",
      "Epoch  29 [7550/10697 ( 70.6%)] Loss: 0.026646 L1: 0.015581 Grad: 0.110417 Thermal: 0.000468 LR: 3.57e-06\n",
      "Epoch  29 [7550/10697 ( 70.6%)] Loss: 0.026646 L1: 0.015581 Grad: 0.110417 Thermal: 0.000468 LR: 3.57e-06\n",
      "Epoch  29 [7600/10697 ( 71.0%)] Loss: 0.026826 L1: 0.015852 Grad: 0.109499 Thermal: 0.000467 LR: 3.57e-06\n",
      "Epoch  29 [7600/10697 ( 71.0%)] Loss: 0.026826 L1: 0.015852 Grad: 0.109499 Thermal: 0.000467 LR: 3.57e-06\n",
      "Epoch  29 [7650/10697 ( 71.5%)] Loss: 0.022721 L1: 0.013470 Grad: 0.092341 Thermal: 0.000346 LR: 3.57e-06\n",
      "Epoch  29 [7650/10697 ( 71.5%)] Loss: 0.022721 L1: 0.013470 Grad: 0.092341 Thermal: 0.000346 LR: 3.57e-06\n",
      "Epoch  29 [7700/10697 ( 72.0%)] Loss: 0.028995 L1: 0.016762 Grad: 0.122087 Thermal: 0.000481 LR: 3.57e-06\n",
      "Epoch  29 [7700/10697 ( 72.0%)] Loss: 0.028995 L1: 0.016762 Grad: 0.122087 Thermal: 0.000481 LR: 3.57e-06\n",
      "Epoch  29 [7750/10697 ( 72.5%)] Loss: 0.024031 L1: 0.014199 Grad: 0.098133 Thermal: 0.000364 LR: 3.57e-06\n",
      "Epoch  29 [7750/10697 ( 72.5%)] Loss: 0.024031 L1: 0.014199 Grad: 0.098133 Thermal: 0.000364 LR: 3.57e-06\n",
      "Epoch  29 [7800/10697 ( 72.9%)] Loss: 0.031157 L1: 0.017805 Grad: 0.133189 Thermal: 0.000650 LR: 3.57e-06\n",
      "Epoch  29 [7800/10697 ( 72.9%)] Loss: 0.031157 L1: 0.017805 Grad: 0.133189 Thermal: 0.000650 LR: 3.57e-06\n",
      "Epoch  29 [7850/10697 ( 73.4%)] Loss: 0.025219 L1: 0.014948 Grad: 0.102496 Thermal: 0.000434 LR: 3.57e-06\n",
      "Epoch  29 [7850/10697 ( 73.4%)] Loss: 0.025219 L1: 0.014948 Grad: 0.102496 Thermal: 0.000434 LR: 3.57e-06\n",
      "Epoch  29 [7900/10697 ( 73.9%)] Loss: 0.025379 L1: 0.015196 Grad: 0.101616 Thermal: 0.000434 LR: 3.57e-06\n",
      "Epoch  29 [7900/10697 ( 73.9%)] Loss: 0.025379 L1: 0.015196 Grad: 0.101616 Thermal: 0.000434 LR: 3.57e-06\n",
      "Epoch  29 [7950/10697 ( 74.3%)] Loss: 0.025898 L1: 0.014811 Grad: 0.110669 Thermal: 0.000406 LR: 3.57e-06\n",
      "Epoch  29 [7950/10697 ( 74.3%)] Loss: 0.025898 L1: 0.014811 Grad: 0.110669 Thermal: 0.000406 LR: 3.57e-06\n",
      "Epoch  29 [8000/10697 ( 74.8%)] Loss: 0.027231 L1: 0.015953 Grad: 0.112544 Thermal: 0.000470 LR: 3.57e-06\n",
      "Epoch  29 [8000/10697 ( 74.8%)] Loss: 0.027231 L1: 0.015953 Grad: 0.112544 Thermal: 0.000470 LR: 3.57e-06\n",
      "Epoch  29 [8050/10697 ( 75.3%)] Loss: 0.026535 L1: 0.015452 Grad: 0.110616 Thermal: 0.000424 LR: 3.57e-06\n",
      "Epoch  29 [8050/10697 ( 75.3%)] Loss: 0.026535 L1: 0.015452 Grad: 0.110616 Thermal: 0.000424 LR: 3.57e-06\n",
      "Epoch  29 [8100/10697 ( 75.7%)] Loss: 0.027436 L1: 0.016113 Grad: 0.112987 Thermal: 0.000488 LR: 3.57e-06\n",
      "Epoch  29 [8100/10697 ( 75.7%)] Loss: 0.027436 L1: 0.016113 Grad: 0.112987 Thermal: 0.000488 LR: 3.57e-06\n",
      "Epoch  29 [8150/10697 ( 76.2%)] Loss: 0.027197 L1: 0.015657 Grad: 0.115155 Thermal: 0.000487 LR: 3.57e-06\n",
      "Epoch  29 [8150/10697 ( 76.2%)] Loss: 0.027197 L1: 0.015657 Grad: 0.115155 Thermal: 0.000487 LR: 3.57e-06\n",
      "Epoch  29 [8200/10697 ( 76.7%)] Loss: 0.020257 L1: 0.011898 Grad: 0.083436 Thermal: 0.000300 LR: 3.57e-06\n",
      "Epoch  29 [8200/10697 ( 76.7%)] Loss: 0.020257 L1: 0.011898 Grad: 0.083436 Thermal: 0.000300 LR: 3.57e-06\n",
      "Epoch  29 [8250/10697 ( 77.1%)] Loss: 0.026562 L1: 0.015350 Grad: 0.111917 Thermal: 0.000420 LR: 3.57e-06\n",
      "Epoch  29 [8250/10697 ( 77.1%)] Loss: 0.026562 L1: 0.015350 Grad: 0.111917 Thermal: 0.000420 LR: 3.57e-06\n",
      "Epoch  29 [8300/10697 ( 77.6%)] Loss: 0.033459 L1: 0.019648 Grad: 0.137724 Thermal: 0.000789 LR: 3.57e-06\n",
      "Epoch  29 [8300/10697 ( 77.6%)] Loss: 0.033459 L1: 0.019648 Grad: 0.137724 Thermal: 0.000789 LR: 3.57e-06\n",
      "Epoch  29 [8350/10697 ( 78.1%)] Loss: 0.023151 L1: 0.013661 Grad: 0.094719 Thermal: 0.000374 LR: 3.57e-06\n",
      "Epoch  29 [8350/10697 ( 78.1%)] Loss: 0.023151 L1: 0.013661 Grad: 0.094719 Thermal: 0.000374 LR: 3.57e-06\n",
      "Epoch  29 [8400/10697 ( 78.5%)] Loss: 0.024316 L1: 0.014539 Grad: 0.097571 Thermal: 0.000400 LR: 3.57e-06\n",
      "Epoch  29 [8400/10697 ( 78.5%)] Loss: 0.024316 L1: 0.014539 Grad: 0.097571 Thermal: 0.000400 LR: 3.57e-06\n",
      "Epoch  29 [8450/10697 ( 79.0%)] Loss: 0.019493 L1: 0.011353 Grad: 0.081247 Thermal: 0.000303 LR: 3.57e-06\n",
      "Epoch  29 [8450/10697 ( 79.0%)] Loss: 0.019493 L1: 0.011353 Grad: 0.081247 Thermal: 0.000303 LR: 3.57e-06\n",
      "Epoch  29 [8500/10697 ( 79.5%)] Loss: 0.024958 L1: 0.014677 Grad: 0.102601 Thermal: 0.000405 LR: 3.57e-06\n",
      "Epoch  29 [8500/10697 ( 79.5%)] Loss: 0.024958 L1: 0.014677 Grad: 0.102601 Thermal: 0.000405 LR: 3.57e-06\n",
      "Epoch  29 [8550/10697 ( 79.9%)] Loss: 0.028097 L1: 0.016396 Grad: 0.116768 Thermal: 0.000472 LR: 3.57e-06\n",
      "Epoch  29 [8550/10697 ( 79.9%)] Loss: 0.028097 L1: 0.016396 Grad: 0.116768 Thermal: 0.000472 LR: 3.57e-06\n",
      "Epoch  29 [8600/10697 ( 80.4%)] Loss: 0.024398 L1: 0.014119 Grad: 0.102595 Thermal: 0.000397 LR: 3.57e-06\n",
      "Epoch  29 [8600/10697 ( 80.4%)] Loss: 0.024398 L1: 0.014119 Grad: 0.102595 Thermal: 0.000397 LR: 3.57e-06\n",
      "Epoch  29 [8650/10697 ( 80.9%)] Loss: 0.018201 L1: 0.010734 Grad: 0.074538 Thermal: 0.000258 LR: 3.57e-06\n",
      "Epoch  29 [8650/10697 ( 80.9%)] Loss: 0.018201 L1: 0.010734 Grad: 0.074538 Thermal: 0.000258 LR: 3.57e-06\n",
      "Epoch  29 [8700/10697 ( 81.3%)] Loss: 0.028518 L1: 0.016593 Grad: 0.118987 Thermal: 0.000534 LR: 3.57e-06\n",
      "Epoch  29 [8700/10697 ( 81.3%)] Loss: 0.028518 L1: 0.016593 Grad: 0.118987 Thermal: 0.000534 LR: 3.57e-06\n",
      "Epoch  29 [8750/10697 ( 81.8%)] Loss: 0.025269 L1: 0.014656 Grad: 0.105910 Thermal: 0.000438 LR: 3.57e-06\n",
      "Epoch  29 [8750/10697 ( 81.8%)] Loss: 0.025269 L1: 0.014656 Grad: 0.105910 Thermal: 0.000438 LR: 3.57e-06\n",
      "Epoch  29 [8800/10697 ( 82.3%)] Loss: 0.021950 L1: 0.012589 Grad: 0.093439 Thermal: 0.000344 LR: 3.57e-06\n",
      "Epoch  29 [8800/10697 ( 82.3%)] Loss: 0.021950 L1: 0.012589 Grad: 0.093439 Thermal: 0.000344 LR: 3.57e-06\n",
      "Epoch  29 [8850/10697 ( 82.7%)] Loss: 0.028279 L1: 0.016454 Grad: 0.118013 Thermal: 0.000484 LR: 3.57e-06\n",
      "Epoch  29 [8850/10697 ( 82.7%)] Loss: 0.028279 L1: 0.016454 Grad: 0.118013 Thermal: 0.000484 LR: 3.57e-06\n",
      "Epoch  29 [8900/10697 ( 83.2%)] Loss: 0.025050 L1: 0.014197 Grad: 0.108339 Thermal: 0.000388 LR: 3.57e-06\n",
      "Epoch  29 [8900/10697 ( 83.2%)] Loss: 0.025050 L1: 0.014197 Grad: 0.108339 Thermal: 0.000388 LR: 3.57e-06\n",
      "Epoch  29 [8950/10697 ( 83.7%)] Loss: 0.028334 L1: 0.016428 Grad: 0.118810 Thermal: 0.000517 LR: 3.57e-06\n",
      "Epoch  29 [8950/10697 ( 83.7%)] Loss: 0.028334 L1: 0.016428 Grad: 0.118810 Thermal: 0.000517 LR: 3.57e-06\n",
      "Epoch  29 [9000/10697 ( 84.1%)] Loss: 0.026956 L1: 0.015476 Grad: 0.114548 Thermal: 0.000485 LR: 3.57e-06\n",
      "Epoch  29 [9000/10697 ( 84.1%)] Loss: 0.026956 L1: 0.015476 Grad: 0.114548 Thermal: 0.000485 LR: 3.57e-06\n",
      "Epoch  29 [9050/10697 ( 84.6%)] Loss: 0.026751 L1: 0.016010 Grad: 0.107181 Thermal: 0.000457 LR: 3.57e-06\n",
      "Epoch  29 [9050/10697 ( 84.6%)] Loss: 0.026751 L1: 0.016010 Grad: 0.107181 Thermal: 0.000457 LR: 3.57e-06\n",
      "Epoch  29 [9100/10697 ( 85.1%)] Loss: 0.024113 L1: 0.014189 Grad: 0.099050 Thermal: 0.000380 LR: 3.57e-06\n",
      "Epoch  29 [9100/10697 ( 85.1%)] Loss: 0.024113 L1: 0.014189 Grad: 0.099050 Thermal: 0.000380 LR: 3.57e-06\n",
      "Epoch  29 [9150/10697 ( 85.5%)] Loss: 0.028934 L1: 0.016644 Grad: 0.122592 Thermal: 0.000601 LR: 3.57e-06\n",
      "Epoch  29 [9150/10697 ( 85.5%)] Loss: 0.028934 L1: 0.016644 Grad: 0.122592 Thermal: 0.000601 LR: 3.57e-06\n",
      "Epoch  29 [9200/10697 ( 86.0%)] Loss: 0.026705 L1: 0.015147 Grad: 0.115342 Thermal: 0.000473 LR: 3.57e-06\n",
      "Epoch  29 [9200/10697 ( 86.0%)] Loss: 0.026705 L1: 0.015147 Grad: 0.115342 Thermal: 0.000473 LR: 3.57e-06\n",
      "Epoch  29 [9250/10697 ( 86.5%)] Loss: 0.025904 L1: 0.014859 Grad: 0.110233 Thermal: 0.000422 LR: 3.57e-06\n",
      "Epoch  29 [9250/10697 ( 86.5%)] Loss: 0.025904 L1: 0.014859 Grad: 0.110233 Thermal: 0.000422 LR: 3.57e-06\n",
      "Epoch  29 [9300/10697 ( 86.9%)] Loss: 0.021783 L1: 0.012566 Grad: 0.092013 Thermal: 0.000329 LR: 3.57e-06\n",
      "Epoch  29 [9300/10697 ( 86.9%)] Loss: 0.021783 L1: 0.012566 Grad: 0.092013 Thermal: 0.000329 LR: 3.57e-06\n",
      "Epoch  29 [9350/10697 ( 87.4%)] Loss: 0.027874 L1: 0.016545 Grad: 0.113056 Thermal: 0.000468 LR: 3.57e-06\n",
      "Epoch  29 [9350/10697 ( 87.4%)] Loss: 0.027874 L1: 0.016545 Grad: 0.113056 Thermal: 0.000468 LR: 3.57e-06\n",
      "Epoch  29 [9400/10697 ( 87.9%)] Loss: 0.028858 L1: 0.016850 Grad: 0.119835 Thermal: 0.000509 LR: 3.57e-06\n",
      "Epoch  29 [9400/10697 ( 87.9%)] Loss: 0.028858 L1: 0.016850 Grad: 0.119835 Thermal: 0.000509 LR: 3.57e-06\n",
      "Epoch  29 [9450/10697 ( 88.3%)] Loss: 0.027946 L1: 0.016387 Grad: 0.115362 Thermal: 0.000461 LR: 3.57e-06\n",
      "Epoch  29 [9450/10697 ( 88.3%)] Loss: 0.027946 L1: 0.016387 Grad: 0.115362 Thermal: 0.000461 LR: 3.57e-06\n",
      "Epoch  29 [9500/10697 ( 88.8%)] Loss: 0.020831 L1: 0.012271 Grad: 0.085459 Thermal: 0.000297 LR: 3.57e-06\n",
      "Epoch  29 [9500/10697 ( 88.8%)] Loss: 0.020831 L1: 0.012271 Grad: 0.085459 Thermal: 0.000297 LR: 3.57e-06\n",
      "Epoch  29 [9550/10697 ( 89.3%)] Loss: 0.029402 L1: 0.016736 Grad: 0.126402 Thermal: 0.000512 LR: 3.57e-06\n",
      "Epoch  29 [9550/10697 ( 89.3%)] Loss: 0.029402 L1: 0.016736 Grad: 0.126402 Thermal: 0.000512 LR: 3.57e-06\n",
      "Epoch  29 [9600/10697 ( 89.7%)] Loss: 0.023095 L1: 0.013574 Grad: 0.095042 Thermal: 0.000330 LR: 3.57e-06\n",
      "Epoch  29 [9600/10697 ( 89.7%)] Loss: 0.023095 L1: 0.013574 Grad: 0.095042 Thermal: 0.000330 LR: 3.57e-06\n",
      "Epoch  29 [9650/10697 ( 90.2%)] Loss: 0.026632 L1: 0.015701 Grad: 0.109091 Thermal: 0.000435 LR: 3.57e-06\n",
      "Epoch  29 [9650/10697 ( 90.2%)] Loss: 0.026632 L1: 0.015701 Grad: 0.109091 Thermal: 0.000435 LR: 3.57e-06\n",
      "Epoch  29 [9700/10697 ( 90.7%)] Loss: 0.032617 L1: 0.019501 Grad: 0.130785 Thermal: 0.000750 LR: 3.57e-06\n",
      "Epoch  29 [9700/10697 ( 90.7%)] Loss: 0.032617 L1: 0.019501 Grad: 0.130785 Thermal: 0.000750 LR: 3.57e-06\n",
      "Epoch  29 [9750/10697 ( 91.1%)] Loss: 0.027696 L1: 0.016069 Grad: 0.116040 Thermal: 0.000461 LR: 3.57e-06\n",
      "Epoch  29 [9750/10697 ( 91.1%)] Loss: 0.027696 L1: 0.016069 Grad: 0.116040 Thermal: 0.000461 LR: 3.57e-06\n",
      "Epoch  29 [9800/10697 ( 91.6%)] Loss: 0.020053 L1: 0.011752 Grad: 0.082875 Thermal: 0.000286 LR: 3.57e-06\n",
      "Epoch  29 [9800/10697 ( 91.6%)] Loss: 0.020053 L1: 0.011752 Grad: 0.082875 Thermal: 0.000286 LR: 3.57e-06\n",
      "Epoch  29 [9850/10697 ( 92.1%)] Loss: 0.025179 L1: 0.014793 Grad: 0.103636 Thermal: 0.000440 LR: 3.57e-06\n",
      "Epoch  29 [9850/10697 ( 92.1%)] Loss: 0.025179 L1: 0.014793 Grad: 0.103636 Thermal: 0.000440 LR: 3.57e-06\n",
      "Epoch  29 [9900/10697 ( 92.5%)] Loss: 0.023156 L1: 0.013326 Grad: 0.098119 Thermal: 0.000364 LR: 3.57e-06\n",
      "Epoch  29 [9900/10697 ( 92.5%)] Loss: 0.023156 L1: 0.013326 Grad: 0.098119 Thermal: 0.000364 LR: 3.57e-06\n",
      "Epoch  29 [9950/10697 ( 93.0%)] Loss: 0.024273 L1: 0.014293 Grad: 0.099586 Thermal: 0.000439 LR: 3.57e-06\n",
      "Epoch  29 [9950/10697 ( 93.0%)] Loss: 0.024273 L1: 0.014293 Grad: 0.099586 Thermal: 0.000439 LR: 3.57e-06\n",
      "Epoch  29 [10000/10697 ( 93.5%)] Loss: 0.024902 L1: 0.014497 Grad: 0.103843 Thermal: 0.000406 LR: 3.57e-06\n",
      "Epoch  29 [10000/10697 ( 93.5%)] Loss: 0.024902 L1: 0.014497 Grad: 0.103843 Thermal: 0.000406 LR: 3.57e-06\n",
      "Epoch  29 [10050/10697 ( 94.0%)] Loss: 0.025219 L1: 0.014455 Grad: 0.107451 Thermal: 0.000375 LR: 3.57e-06\n",
      "Epoch  29 [10050/10697 ( 94.0%)] Loss: 0.025219 L1: 0.014455 Grad: 0.107451 Thermal: 0.000375 LR: 3.57e-06\n",
      "Epoch  29 [10100/10697 ( 94.4%)] Loss: 0.025058 L1: 0.014216 Grad: 0.108192 Thermal: 0.000454 LR: 3.57e-06\n",
      "Epoch  29 [10100/10697 ( 94.4%)] Loss: 0.025058 L1: 0.014216 Grad: 0.108192 Thermal: 0.000454 LR: 3.57e-06\n",
      "Epoch  29 [10150/10697 ( 94.9%)] Loss: 0.029223 L1: 0.017019 Grad: 0.121737 Thermal: 0.000601 LR: 3.57e-06\n",
      "Epoch  29 [10150/10697 ( 94.9%)] Loss: 0.029223 L1: 0.017019 Grad: 0.121737 Thermal: 0.000601 LR: 3.57e-06\n",
      "Epoch  29 [10200/10697 ( 95.4%)] Loss: 0.024284 L1: 0.014093 Grad: 0.101709 Thermal: 0.000406 LR: 3.57e-06\n",
      "Epoch  29 [10200/10697 ( 95.4%)] Loss: 0.024284 L1: 0.014093 Grad: 0.101709 Thermal: 0.000406 LR: 3.57e-06\n",
      "Epoch  29 [10250/10697 ( 95.8%)] Loss: 0.028031 L1: 0.016878 Grad: 0.111287 Thermal: 0.000490 LR: 3.57e-06\n",
      "Epoch  29 [10250/10697 ( 95.8%)] Loss: 0.028031 L1: 0.016878 Grad: 0.111287 Thermal: 0.000490 LR: 3.57e-06\n",
      "Epoch  29 [10300/10697 ( 96.3%)] Loss: 0.028288 L1: 0.016547 Grad: 0.117164 Thermal: 0.000500 LR: 3.57e-06\n",
      "Epoch  29 [10300/10697 ( 96.3%)] Loss: 0.028288 L1: 0.016547 Grad: 0.117164 Thermal: 0.000500 LR: 3.57e-06\n",
      "Epoch  29 [10350/10697 ( 96.8%)] Loss: 0.024696 L1: 0.014692 Grad: 0.099833 Thermal: 0.000420 LR: 3.57e-06\n",
      "Epoch  29 [10350/10697 ( 96.8%)] Loss: 0.024696 L1: 0.014692 Grad: 0.099833 Thermal: 0.000420 LR: 3.57e-06\n",
      "Epoch  29 [10400/10697 ( 97.2%)] Loss: 0.032973 L1: 0.019049 Grad: 0.138917 Thermal: 0.000658 LR: 3.57e-06\n",
      "Epoch  29 [10400/10697 ( 97.2%)] Loss: 0.032973 L1: 0.019049 Grad: 0.138917 Thermal: 0.000658 LR: 3.57e-06\n",
      "Epoch  29 [10450/10697 ( 97.7%)] Loss: 0.023466 L1: 0.013527 Grad: 0.099210 Thermal: 0.000353 LR: 3.57e-06\n",
      "Epoch  29 [10450/10697 ( 97.7%)] Loss: 0.023466 L1: 0.013527 Grad: 0.099210 Thermal: 0.000353 LR: 3.57e-06\n",
      "Epoch  29 [10500/10697 ( 98.2%)] Loss: 0.025902 L1: 0.015066 Grad: 0.108141 Thermal: 0.000435 LR: 3.57e-06\n",
      "Epoch  29 [10500/10697 ( 98.2%)] Loss: 0.025902 L1: 0.015066 Grad: 0.108141 Thermal: 0.000435 LR: 3.57e-06\n",
      "Epoch  29 [10550/10697 ( 98.6%)] Loss: 0.025997 L1: 0.014885 Grad: 0.110876 Thermal: 0.000502 LR: 3.57e-06\n",
      "Epoch  29 [10550/10697 ( 98.6%)] Loss: 0.025997 L1: 0.014885 Grad: 0.110876 Thermal: 0.000502 LR: 3.57e-06\n",
      "Epoch  29 [10600/10697 ( 99.1%)] Loss: 0.030633 L1: 0.017980 Grad: 0.126245 Thermal: 0.000575 LR: 3.57e-06\n",
      "Epoch  29 [10600/10697 ( 99.1%)] Loss: 0.030633 L1: 0.017980 Grad: 0.126245 Thermal: 0.000575 LR: 3.57e-06\n",
      "Epoch  29 [10650/10697 ( 99.6%)] Loss: 0.031400 L1: 0.018327 Grad: 0.130420 Thermal: 0.000614 LR: 3.57e-06\n",
      "Epoch  29 [10650/10697 ( 99.6%)] Loss: 0.031400 L1: 0.018327 Grad: 0.130420 Thermal: 0.000614 LR: 3.57e-06\n",
      "Epoch  29 Summary: Loss=0.026302 (L1:0.0153, Grad:0.1094, Thermal:0.0005) Val_PSNR=0.00dB Best=33.95dB Time=111.4min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  29 Summary: Loss=0.026302 (L1:0.0153, Grad:0.1094, Thermal:0.0005) Val_PSNR=0.00dB Best=33.95dB Time=111.4min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  30 [   0/10697 (  0.0%)] Loss: 0.027916 L1: 0.016186 Grad: 0.117037 Thermal: 0.000519 LR: 3.48e-06\n",
      "Epoch  30 [   0/10697 (  0.0%)] Loss: 0.027916 L1: 0.016186 Grad: 0.117037 Thermal: 0.000519 LR: 3.48e-06\n",
      "Epoch  30 [  50/10697 (  0.5%)] Loss: 0.027971 L1: 0.016431 Grad: 0.115158 Thermal: 0.000487 LR: 3.48e-06\n",
      "Epoch  30 [  50/10697 (  0.5%)] Loss: 0.027971 L1: 0.016431 Grad: 0.115158 Thermal: 0.000487 LR: 3.48e-06\n",
      "Epoch  30 [ 100/10697 (  0.9%)] Loss: 0.023225 L1: 0.013510 Grad: 0.096982 Thermal: 0.000339 LR: 3.48e-06\n",
      "Epoch  30 [ 100/10697 (  0.9%)] Loss: 0.023225 L1: 0.013510 Grad: 0.096982 Thermal: 0.000339 LR: 3.48e-06\n",
      "Epoch  30 [ 150/10697 (  1.4%)] Loss: 0.019354 L1: 0.011127 Grad: 0.082136 Thermal: 0.000281 LR: 3.48e-06\n",
      "Epoch  30 [ 150/10697 (  1.4%)] Loss: 0.019354 L1: 0.011127 Grad: 0.082136 Thermal: 0.000281 LR: 3.48e-06\n",
      "Epoch  30 [ 200/10697 (  1.9%)] Loss: 0.027767 L1: 0.015874 Grad: 0.118727 Thermal: 0.000413 LR: 3.48e-06\n",
      "Epoch  30 [ 200/10697 (  1.9%)] Loss: 0.027767 L1: 0.015874 Grad: 0.118727 Thermal: 0.000413 LR: 3.48e-06\n",
      "Epoch  30 [ 250/10697 (  2.3%)] Loss: 0.024363 L1: 0.013681 Grad: 0.106644 Thermal: 0.000361 LR: 3.48e-06\n",
      "Epoch  30 [ 250/10697 (  2.3%)] Loss: 0.024363 L1: 0.013681 Grad: 0.106644 Thermal: 0.000361 LR: 3.48e-06\n",
      "Epoch  30 [ 300/10697 (  2.8%)] Loss: 0.023890 L1: 0.014149 Grad: 0.097222 Thermal: 0.000375 LR: 3.48e-06\n",
      "Epoch  30 [ 300/10697 (  2.8%)] Loss: 0.023890 L1: 0.014149 Grad: 0.097222 Thermal: 0.000375 LR: 3.48e-06\n",
      "Epoch  30 [ 350/10697 (  3.3%)] Loss: 0.028251 L1: 0.016639 Grad: 0.115869 Thermal: 0.000510 LR: 3.48e-06\n",
      "Epoch  30 [ 350/10697 (  3.3%)] Loss: 0.028251 L1: 0.016639 Grad: 0.115869 Thermal: 0.000510 LR: 3.48e-06\n",
      "Epoch  30 [ 400/10697 (  3.7%)] Loss: 0.026189 L1: 0.014870 Grad: 0.112958 Thermal: 0.000462 LR: 3.48e-06\n",
      "Epoch  30 [ 400/10697 (  3.7%)] Loss: 0.026189 L1: 0.014870 Grad: 0.112958 Thermal: 0.000462 LR: 3.48e-06\n",
      "Epoch  30 [ 450/10697 (  4.2%)] Loss: 0.027587 L1: 0.016267 Grad: 0.112968 Thermal: 0.000472 LR: 3.48e-06\n",
      "Epoch  30 [ 450/10697 (  4.2%)] Loss: 0.027587 L1: 0.016267 Grad: 0.112968 Thermal: 0.000472 LR: 3.48e-06\n",
      "Epoch  30 [ 500/10697 (  4.7%)] Loss: 0.022616 L1: 0.013584 Grad: 0.090135 Thermal: 0.000369 LR: 3.48e-06\n",
      "Epoch  30 [ 500/10697 (  4.7%)] Loss: 0.022616 L1: 0.013584 Grad: 0.090135 Thermal: 0.000369 LR: 3.48e-06\n",
      "Epoch  30 [ 550/10697 (  5.1%)] Loss: 0.029491 L1: 0.017203 Grad: 0.122571 Thermal: 0.000616 LR: 3.48e-06\n",
      "Epoch  30 [ 550/10697 (  5.1%)] Loss: 0.029491 L1: 0.017203 Grad: 0.122571 Thermal: 0.000616 LR: 3.48e-06\n",
      "Epoch  30 [ 600/10697 (  5.6%)] Loss: 0.038148 L1: 0.022067 Grad: 0.160288 Thermal: 0.001039 LR: 3.48e-06\n",
      "Epoch  30 [ 600/10697 (  5.6%)] Loss: 0.038148 L1: 0.022067 Grad: 0.160288 Thermal: 0.001039 LR: 3.48e-06\n",
      "Epoch  30 [ 650/10697 (  6.1%)] Loss: 0.030632 L1: 0.017739 Grad: 0.128637 Thermal: 0.000585 LR: 3.48e-06\n",
      "Epoch  30 [ 650/10697 (  6.1%)] Loss: 0.030632 L1: 0.017739 Grad: 0.128637 Thermal: 0.000585 LR: 3.48e-06\n",
      "Epoch  30 [ 700/10697 (  6.5%)] Loss: 0.019906 L1: 0.011548 Grad: 0.083433 Thermal: 0.000299 LR: 3.48e-06\n",
      "Epoch  30 [ 700/10697 (  6.5%)] Loss: 0.019906 L1: 0.011548 Grad: 0.083433 Thermal: 0.000299 LR: 3.48e-06\n",
      "Epoch  30 [ 750/10697 (  7.0%)] Loss: 0.027483 L1: 0.016557 Grad: 0.109015 Thermal: 0.000477 LR: 3.48e-06\n",
      "Epoch  30 [ 750/10697 (  7.0%)] Loss: 0.027483 L1: 0.016557 Grad: 0.109015 Thermal: 0.000477 LR: 3.48e-06\n",
      "Epoch  30 [ 800/10697 (  7.5%)] Loss: 0.027220 L1: 0.015896 Grad: 0.113018 Thermal: 0.000441 LR: 3.48e-06\n",
      "Epoch  30 [ 800/10697 (  7.5%)] Loss: 0.027220 L1: 0.015896 Grad: 0.113018 Thermal: 0.000441 LR: 3.48e-06\n",
      "Epoch  30 [ 850/10697 (  7.9%)] Loss: 0.023075 L1: 0.013332 Grad: 0.097246 Thermal: 0.000369 LR: 3.48e-06\n",
      "Epoch  30 [ 850/10697 (  7.9%)] Loss: 0.023075 L1: 0.013332 Grad: 0.097246 Thermal: 0.000369 LR: 3.48e-06\n",
      "Epoch  30 [ 900/10697 (  8.4%)] Loss: 0.019933 L1: 0.011318 Grad: 0.085958 Thermal: 0.000392 LR: 3.48e-06\n",
      "Epoch  30 [ 900/10697 (  8.4%)] Loss: 0.019933 L1: 0.011318 Grad: 0.085958 Thermal: 0.000392 LR: 3.48e-06\n",
      "Epoch  30 [ 950/10697 (  8.9%)] Loss: 0.027696 L1: 0.016239 Grad: 0.114310 Thermal: 0.000509 LR: 3.48e-06\n",
      "Epoch  30 [ 950/10697 (  8.9%)] Loss: 0.027696 L1: 0.016239 Grad: 0.114310 Thermal: 0.000509 LR: 3.48e-06\n",
      "Epoch  30 [1000/10697 (  9.3%)] Loss: 0.025132 L1: 0.015029 Grad: 0.100833 Thermal: 0.000401 LR: 3.48e-06\n",
      "Epoch  30 [1000/10697 (  9.3%)] Loss: 0.025132 L1: 0.015029 Grad: 0.100833 Thermal: 0.000401 LR: 3.48e-06\n",
      "Epoch  30 [1050/10697 (  9.8%)] Loss: 0.027336 L1: 0.015991 Grad: 0.113236 Thermal: 0.000434 LR: 3.48e-06\n",
      "Epoch  30 [1050/10697 (  9.8%)] Loss: 0.027336 L1: 0.015991 Grad: 0.113236 Thermal: 0.000434 LR: 3.48e-06\n",
      "Epoch  30 [1100/10697 ( 10.3%)] Loss: 0.031144 L1: 0.018165 Grad: 0.129476 Thermal: 0.000612 LR: 3.48e-06\n",
      "Epoch  30 [1100/10697 ( 10.3%)] Loss: 0.031144 L1: 0.018165 Grad: 0.129476 Thermal: 0.000612 LR: 3.48e-06\n",
      "Epoch  30 [1150/10697 ( 10.8%)] Loss: 0.021401 L1: 0.011796 Grad: 0.095918 Thermal: 0.000262 LR: 3.48e-06\n",
      "Epoch  30 [1150/10697 ( 10.8%)] Loss: 0.021401 L1: 0.011796 Grad: 0.095918 Thermal: 0.000262 LR: 3.48e-06\n",
      "Epoch  30 [1200/10697 ( 11.2%)] Loss: 0.028943 L1: 0.016768 Grad: 0.121486 Thermal: 0.000536 LR: 3.48e-06\n",
      "Epoch  30 [1200/10697 ( 11.2%)] Loss: 0.028943 L1: 0.016768 Grad: 0.121486 Thermal: 0.000536 LR: 3.48e-06\n",
      "Epoch  30 [1250/10697 ( 11.7%)] Loss: 0.022159 L1: 0.012775 Grad: 0.093674 Thermal: 0.000347 LR: 3.48e-06\n",
      "Epoch  30 [1250/10697 ( 11.7%)] Loss: 0.022159 L1: 0.012775 Grad: 0.093674 Thermal: 0.000347 LR: 3.48e-06\n",
      "Epoch  30 [1300/10697 ( 12.2%)] Loss: 0.024423 L1: 0.014238 Grad: 0.101658 Thermal: 0.000386 LR: 3.48e-06\n",
      "Epoch  30 [1300/10697 ( 12.2%)] Loss: 0.024423 L1: 0.014238 Grad: 0.101658 Thermal: 0.000386 LR: 3.48e-06\n",
      "Epoch  30 [1350/10697 ( 12.6%)] Loss: 0.024551 L1: 0.014503 Grad: 0.100292 Thermal: 0.000370 LR: 3.48e-06\n",
      "Epoch  30 [1350/10697 ( 12.6%)] Loss: 0.024551 L1: 0.014503 Grad: 0.100292 Thermal: 0.000370 LR: 3.48e-06\n",
      "Epoch  30 [1400/10697 ( 13.1%)] Loss: 0.027476 L1: 0.016322 Grad: 0.111319 Thermal: 0.000441 LR: 3.48e-06\n",
      "Epoch  30 [1400/10697 ( 13.1%)] Loss: 0.027476 L1: 0.016322 Grad: 0.111319 Thermal: 0.000441 LR: 3.48e-06\n",
      "Epoch  30 [1450/10697 ( 13.6%)] Loss: 0.024713 L1: 0.014329 Grad: 0.103631 Thermal: 0.000420 LR: 3.48e-06\n",
      "Epoch  30 [1450/10697 ( 13.6%)] Loss: 0.024713 L1: 0.014329 Grad: 0.103631 Thermal: 0.000420 LR: 3.48e-06\n",
      "Epoch  30 [1500/10697 ( 14.0%)] Loss: 0.024388 L1: 0.013973 Grad: 0.103952 Thermal: 0.000401 LR: 3.48e-06\n",
      "Epoch  30 [1500/10697 ( 14.0%)] Loss: 0.024388 L1: 0.013973 Grad: 0.103952 Thermal: 0.000401 LR: 3.48e-06\n",
      "Epoch  30 [1550/10697 ( 14.5%)] Loss: 0.025661 L1: 0.015092 Grad: 0.105485 Thermal: 0.000426 LR: 3.48e-06\n",
      "Epoch  30 [1550/10697 ( 14.5%)] Loss: 0.025661 L1: 0.015092 Grad: 0.105485 Thermal: 0.000426 LR: 3.48e-06\n",
      "Epoch  30 [1600/10697 ( 15.0%)] Loss: 0.026947 L1: 0.015927 Grad: 0.109974 Thermal: 0.000452 LR: 3.48e-06\n",
      "Epoch  30 [1600/10697 ( 15.0%)] Loss: 0.026947 L1: 0.015927 Grad: 0.109974 Thermal: 0.000452 LR: 3.48e-06\n",
      "Epoch  30 [1650/10697 ( 15.4%)] Loss: 0.022945 L1: 0.013328 Grad: 0.096001 Thermal: 0.000339 LR: 3.48e-06\n",
      "Epoch  30 [1650/10697 ( 15.4%)] Loss: 0.022945 L1: 0.013328 Grad: 0.096001 Thermal: 0.000339 LR: 3.48e-06\n",
      "Epoch  30 [1700/10697 ( 15.9%)] Loss: 0.030275 L1: 0.018201 Grad: 0.120462 Thermal: 0.000571 LR: 3.48e-06\n",
      "Epoch  30 [1700/10697 ( 15.9%)] Loss: 0.030275 L1: 0.018201 Grad: 0.120462 Thermal: 0.000571 LR: 3.48e-06\n",
      "Epoch  30 [1750/10697 ( 16.4%)] Loss: 0.024624 L1: 0.014168 Grad: 0.104371 Thermal: 0.000381 LR: 3.48e-06\n",
      "Epoch  30 [1750/10697 ( 16.4%)] Loss: 0.024624 L1: 0.014168 Grad: 0.104371 Thermal: 0.000381 LR: 3.48e-06\n",
      "Epoch  30 [1800/10697 ( 16.8%)] Loss: 0.025563 L1: 0.014863 Grad: 0.106802 Thermal: 0.000400 LR: 3.48e-06\n",
      "Epoch  30 [1800/10697 ( 16.8%)] Loss: 0.025563 L1: 0.014863 Grad: 0.106802 Thermal: 0.000400 LR: 3.48e-06\n",
      "Epoch  30 [1850/10697 ( 17.3%)] Loss: 0.023555 L1: 0.013521 Grad: 0.100167 Thermal: 0.000343 LR: 3.48e-06\n",
      "Epoch  30 [1850/10697 ( 17.3%)] Loss: 0.023555 L1: 0.013521 Grad: 0.100167 Thermal: 0.000343 LR: 3.48e-06\n",
      "Epoch  30 [1900/10697 ( 17.8%)] Loss: 0.024255 L1: 0.013991 Grad: 0.102452 Thermal: 0.000373 LR: 3.48e-06\n",
      "Epoch  30 [1900/10697 ( 17.8%)] Loss: 0.024255 L1: 0.013991 Grad: 0.102452 Thermal: 0.000373 LR: 3.48e-06\n",
      "Epoch  30 [1950/10697 ( 18.2%)] Loss: 0.025609 L1: 0.015217 Grad: 0.103705 Thermal: 0.000431 LR: 3.48e-06\n",
      "Epoch  30 [1950/10697 ( 18.2%)] Loss: 0.025609 L1: 0.015217 Grad: 0.103705 Thermal: 0.000431 LR: 3.48e-06\n",
      "Epoch  30 [2000/10697 ( 18.7%)] Loss: 0.029089 L1: 0.017065 Grad: 0.119988 Thermal: 0.000503 LR: 3.48e-06\n",
      "Epoch  30 [2000/10697 ( 18.7%)] Loss: 0.029089 L1: 0.017065 Grad: 0.119988 Thermal: 0.000503 LR: 3.48e-06\n",
      "Epoch  30 [2050/10697 ( 19.2%)] Loss: 0.024262 L1: 0.014343 Grad: 0.099007 Thermal: 0.000368 LR: 3.48e-06\n",
      "Epoch  30 [2050/10697 ( 19.2%)] Loss: 0.024262 L1: 0.014343 Grad: 0.099007 Thermal: 0.000368 LR: 3.48e-06\n",
      "Epoch  30 [2100/10697 ( 19.6%)] Loss: 0.031791 L1: 0.018082 Grad: 0.136745 Thermal: 0.000677 LR: 3.48e-06\n",
      "Epoch  30 [2100/10697 ( 19.6%)] Loss: 0.031791 L1: 0.018082 Grad: 0.136745 Thermal: 0.000677 LR: 3.48e-06\n",
      "Epoch  30 [2150/10697 ( 20.1%)] Loss: 0.022150 L1: 0.013035 Grad: 0.090999 Thermal: 0.000321 LR: 3.48e-06\n",
      "Epoch  30 [2150/10697 ( 20.1%)] Loss: 0.022150 L1: 0.013035 Grad: 0.090999 Thermal: 0.000321 LR: 3.48e-06\n",
      "Epoch  30 [2200/10697 ( 20.6%)] Loss: 0.027931 L1: 0.016151 Grad: 0.117551 Thermal: 0.000507 LR: 3.48e-06\n",
      "Epoch  30 [2200/10697 ( 20.6%)] Loss: 0.027931 L1: 0.016151 Grad: 0.117551 Thermal: 0.000507 LR: 3.48e-06\n",
      "Epoch  30 [2250/10697 ( 21.0%)] Loss: 0.022830 L1: 0.012937 Grad: 0.098753 Thermal: 0.000359 LR: 3.48e-06\n",
      "Epoch  30 [2250/10697 ( 21.0%)] Loss: 0.022830 L1: 0.012937 Grad: 0.098753 Thermal: 0.000359 LR: 3.48e-06\n",
      "Epoch  30 [2300/10697 ( 21.5%)] Loss: 0.025919 L1: 0.015152 Grad: 0.107458 Thermal: 0.000437 LR: 3.48e-06\n",
      "Epoch  30 [2300/10697 ( 21.5%)] Loss: 0.025919 L1: 0.015152 Grad: 0.107458 Thermal: 0.000437 LR: 3.48e-06\n",
      "Epoch  30 [2350/10697 ( 22.0%)] Loss: 0.027080 L1: 0.015583 Grad: 0.114715 Thermal: 0.000516 LR: 3.48e-06\n",
      "Epoch  30 [2350/10697 ( 22.0%)] Loss: 0.027080 L1: 0.015583 Grad: 0.114715 Thermal: 0.000516 LR: 3.48e-06\n",
      "Epoch  30 [2400/10697 ( 22.4%)] Loss: 0.029347 L1: 0.017308 Grad: 0.120110 Thermal: 0.000561 LR: 3.48e-06\n",
      "Epoch  30 [2400/10697 ( 22.4%)] Loss: 0.029347 L1: 0.017308 Grad: 0.120110 Thermal: 0.000561 LR: 3.48e-06\n",
      "Epoch  30 [2450/10697 ( 22.9%)] Loss: 0.025782 L1: 0.014804 Grad: 0.109584 Thermal: 0.000399 LR: 3.48e-06\n",
      "Epoch  30 [2450/10697 ( 22.9%)] Loss: 0.025782 L1: 0.014804 Grad: 0.109584 Thermal: 0.000399 LR: 3.48e-06\n",
      "Epoch  30 [2500/10697 ( 23.4%)] Loss: 0.029934 L1: 0.017530 Grad: 0.123767 Thermal: 0.000545 LR: 3.48e-06\n",
      "Epoch  30 [2500/10697 ( 23.4%)] Loss: 0.029934 L1: 0.017530 Grad: 0.123767 Thermal: 0.000545 LR: 3.48e-06\n",
      "Epoch  30 [2550/10697 ( 23.8%)] Loss: 0.024993 L1: 0.014466 Grad: 0.105070 Thermal: 0.000396 LR: 3.48e-06\n",
      "Epoch  30 [2550/10697 ( 23.8%)] Loss: 0.024993 L1: 0.014466 Grad: 0.105070 Thermal: 0.000396 LR: 3.48e-06\n",
      "Epoch  30 [2600/10697 ( 24.3%)] Loss: 0.025938 L1: 0.015430 Grad: 0.104860 Thermal: 0.000433 LR: 3.48e-06\n",
      "Epoch  30 [2600/10697 ( 24.3%)] Loss: 0.025938 L1: 0.015430 Grad: 0.104860 Thermal: 0.000433 LR: 3.48e-06\n",
      "Epoch  30 [2650/10697 ( 24.8%)] Loss: 0.018734 L1: 0.010844 Grad: 0.078763 Thermal: 0.000267 LR: 3.48e-06\n",
      "Epoch  30 [2650/10697 ( 24.8%)] Loss: 0.018734 L1: 0.010844 Grad: 0.078763 Thermal: 0.000267 LR: 3.48e-06\n",
      "Epoch  30 [2700/10697 ( 25.2%)] Loss: 0.028152 L1: 0.016004 Grad: 0.121260 Thermal: 0.000434 LR: 3.48e-06\n",
      "Epoch  30 [2700/10697 ( 25.2%)] Loss: 0.028152 L1: 0.016004 Grad: 0.121260 Thermal: 0.000434 LR: 3.48e-06\n",
      "Epoch  30 [2750/10697 ( 25.7%)] Loss: 0.029579 L1: 0.017437 Grad: 0.121137 Thermal: 0.000576 LR: 3.48e-06\n",
      "Epoch  30 [2750/10697 ( 25.7%)] Loss: 0.029579 L1: 0.017437 Grad: 0.121137 Thermal: 0.000576 LR: 3.48e-06\n",
      "Epoch  30 [2800/10697 ( 26.2%)] Loss: 0.027051 L1: 0.015922 Grad: 0.111068 Thermal: 0.000446 LR: 3.48e-06\n",
      "Epoch  30 [2800/10697 ( 26.2%)] Loss: 0.027051 L1: 0.015922 Grad: 0.111068 Thermal: 0.000446 LR: 3.48e-06\n",
      "Epoch  30 [2850/10697 ( 26.6%)] Loss: 0.028309 L1: 0.016299 Grad: 0.119823 Thermal: 0.000558 LR: 3.48e-06\n",
      "Epoch  30 [2850/10697 ( 26.6%)] Loss: 0.028309 L1: 0.016299 Grad: 0.119823 Thermal: 0.000558 LR: 3.48e-06\n",
      "Epoch  30 [2900/10697 ( 27.1%)] Loss: 0.026017 L1: 0.015247 Grad: 0.107489 Thermal: 0.000427 LR: 3.48e-06\n",
      "Epoch  30 [2900/10697 ( 27.1%)] Loss: 0.026017 L1: 0.015247 Grad: 0.107489 Thermal: 0.000427 LR: 3.48e-06\n",
      "Epoch  30 [2950/10697 ( 27.6%)] Loss: 0.025432 L1: 0.014855 Grad: 0.105547 Thermal: 0.000447 LR: 3.48e-06\n",
      "Epoch  30 [2950/10697 ( 27.6%)] Loss: 0.025432 L1: 0.014855 Grad: 0.105547 Thermal: 0.000447 LR: 3.48e-06\n",
      "Epoch  30 [3000/10697 ( 28.0%)] Loss: 0.026518 L1: 0.014918 Grad: 0.115790 Thermal: 0.000413 LR: 3.48e-06\n",
      "Epoch  30 [3000/10697 ( 28.0%)] Loss: 0.026518 L1: 0.014918 Grad: 0.115790 Thermal: 0.000413 LR: 3.48e-06\n",
      "Epoch  30 [3050/10697 ( 28.5%)] Loss: 0.026645 L1: 0.015968 Grad: 0.106548 Thermal: 0.000449 LR: 3.48e-06\n",
      "Epoch  30 [3050/10697 ( 28.5%)] Loss: 0.026645 L1: 0.015968 Grad: 0.106548 Thermal: 0.000449 LR: 3.48e-06\n",
      "Epoch  30 [3100/10697 ( 29.0%)] Loss: 0.030099 L1: 0.017467 Grad: 0.126027 Thermal: 0.000584 LR: 3.48e-06\n",
      "Epoch  30 [3100/10697 ( 29.0%)] Loss: 0.030099 L1: 0.017467 Grad: 0.126027 Thermal: 0.000584 LR: 3.48e-06\n",
      "Epoch  30 [3150/10697 ( 29.4%)] Loss: 0.023929 L1: 0.014090 Grad: 0.098209 Thermal: 0.000361 LR: 3.48e-06\n",
      "Epoch  30 [3150/10697 ( 29.4%)] Loss: 0.023929 L1: 0.014090 Grad: 0.098209 Thermal: 0.000361 LR: 3.48e-06\n",
      "Epoch  30 [3200/10697 ( 29.9%)] Loss: 0.024991 L1: 0.014691 Grad: 0.102802 Thermal: 0.000391 LR: 3.48e-06\n",
      "Epoch  30 [3200/10697 ( 29.9%)] Loss: 0.024991 L1: 0.014691 Grad: 0.102802 Thermal: 0.000391 LR: 3.48e-06\n",
      "Epoch  30 [3250/10697 ( 30.4%)] Loss: 0.023503 L1: 0.013803 Grad: 0.096823 Thermal: 0.000365 LR: 3.48e-06\n",
      "Epoch  30 [3250/10697 ( 30.4%)] Loss: 0.023503 L1: 0.013803 Grad: 0.096823 Thermal: 0.000365 LR: 3.48e-06\n",
      "Epoch  30 [3300/10697 ( 30.8%)] Loss: 0.032585 L1: 0.019542 Grad: 0.130083 Thermal: 0.000695 LR: 3.48e-06\n",
      "Epoch  30 [3300/10697 ( 30.8%)] Loss: 0.032585 L1: 0.019542 Grad: 0.130083 Thermal: 0.000695 LR: 3.48e-06\n",
      "Epoch  30 [3350/10697 ( 31.3%)] Loss: 0.023100 L1: 0.013631 Grad: 0.094510 Thermal: 0.000357 LR: 3.48e-06\n",
      "Epoch  30 [3350/10697 ( 31.3%)] Loss: 0.023100 L1: 0.013631 Grad: 0.094510 Thermal: 0.000357 LR: 3.48e-06\n",
      "Epoch  30 [3400/10697 ( 31.8%)] Loss: 0.023981 L1: 0.014066 Grad: 0.098956 Thermal: 0.000384 LR: 3.48e-06\n",
      "Epoch  30 [3400/10697 ( 31.8%)] Loss: 0.023981 L1: 0.014066 Grad: 0.098956 Thermal: 0.000384 LR: 3.48e-06\n",
      "Epoch  30 [3450/10697 ( 32.3%)] Loss: 0.026503 L1: 0.015498 Grad: 0.109820 Thermal: 0.000464 LR: 3.48e-06\n",
      "Epoch  30 [3450/10697 ( 32.3%)] Loss: 0.026503 L1: 0.015498 Grad: 0.109820 Thermal: 0.000464 LR: 3.48e-06\n",
      "Epoch  30 [3500/10697 ( 32.7%)] Loss: 0.023312 L1: 0.013852 Grad: 0.094418 Thermal: 0.000355 LR: 3.48e-06\n",
      "Epoch  30 [3500/10697 ( 32.7%)] Loss: 0.023312 L1: 0.013852 Grad: 0.094418 Thermal: 0.000355 LR: 3.48e-06\n",
      "Epoch  30 [3550/10697 ( 33.2%)] Loss: 0.024203 L1: 0.013923 Grad: 0.102617 Thermal: 0.000371 LR: 3.48e-06\n",
      "Epoch  30 [3550/10697 ( 33.2%)] Loss: 0.024203 L1: 0.013923 Grad: 0.102617 Thermal: 0.000371 LR: 3.48e-06\n",
      "Epoch  30 [3600/10697 ( 33.7%)] Loss: 0.025162 L1: 0.014825 Grad: 0.103174 Thermal: 0.000401 LR: 3.48e-06\n",
      "Epoch  30 [3600/10697 ( 33.7%)] Loss: 0.025162 L1: 0.014825 Grad: 0.103174 Thermal: 0.000401 LR: 3.48e-06\n",
      "Epoch  30 [3650/10697 ( 34.1%)] Loss: 0.022418 L1: 0.012994 Grad: 0.094075 Thermal: 0.000322 LR: 3.48e-06\n",
      "Epoch  30 [3650/10697 ( 34.1%)] Loss: 0.022418 L1: 0.012994 Grad: 0.094075 Thermal: 0.000322 LR: 3.48e-06\n",
      "Epoch  30 [3700/10697 ( 34.6%)] Loss: 0.029664 L1: 0.017267 Grad: 0.123702 Thermal: 0.000538 LR: 3.48e-06\n",
      "Epoch  30 [3700/10697 ( 34.6%)] Loss: 0.029664 L1: 0.017267 Grad: 0.123702 Thermal: 0.000538 LR: 3.48e-06\n",
      "Epoch  30 [3750/10697 ( 35.1%)] Loss: 0.029277 L1: 0.017343 Grad: 0.119064 Thermal: 0.000549 LR: 3.48e-06\n",
      "Epoch  30 [3750/10697 ( 35.1%)] Loss: 0.029277 L1: 0.017343 Grad: 0.119064 Thermal: 0.000549 LR: 3.48e-06\n",
      "Epoch  30 [3800/10697 ( 35.5%)] Loss: 0.028640 L1: 0.016774 Grad: 0.118425 Thermal: 0.000470 LR: 3.48e-06\n",
      "Epoch  30 [3800/10697 ( 35.5%)] Loss: 0.028640 L1: 0.016774 Grad: 0.118425 Thermal: 0.000470 LR: 3.48e-06\n",
      "Epoch  30 [3850/10697 ( 36.0%)] Loss: 0.028674 L1: 0.017161 Grad: 0.114868 Thermal: 0.000530 LR: 3.48e-06\n",
      "Epoch  30 [3850/10697 ( 36.0%)] Loss: 0.028674 L1: 0.017161 Grad: 0.114868 Thermal: 0.000530 LR: 3.48e-06\n",
      "Epoch  30 [3900/10697 ( 36.5%)] Loss: 0.025491 L1: 0.015326 Grad: 0.101444 Thermal: 0.000426 LR: 3.48e-06\n",
      "Epoch  30 [3900/10697 ( 36.5%)] Loss: 0.025491 L1: 0.015326 Grad: 0.101444 Thermal: 0.000426 LR: 3.48e-06\n",
      "Epoch  30 [3950/10697 ( 36.9%)] Loss: 0.024255 L1: 0.014293 Grad: 0.099417 Thermal: 0.000395 LR: 3.48e-06\n",
      "Epoch  30 [3950/10697 ( 36.9%)] Loss: 0.024255 L1: 0.014293 Grad: 0.099417 Thermal: 0.000395 LR: 3.48e-06\n",
      "Epoch  30 [4000/10697 ( 37.4%)] Loss: 0.025172 L1: 0.014786 Grad: 0.103649 Thermal: 0.000414 LR: 3.48e-06\n",
      "Epoch  30 [4000/10697 ( 37.4%)] Loss: 0.025172 L1: 0.014786 Grad: 0.103649 Thermal: 0.000414 LR: 3.48e-06\n",
      "Epoch  30 [4050/10697 ( 37.9%)] Loss: 0.023976 L1: 0.013412 Grad: 0.105467 Thermal: 0.000365 LR: 3.48e-06\n",
      "Epoch  30 [4050/10697 ( 37.9%)] Loss: 0.023976 L1: 0.013412 Grad: 0.105467 Thermal: 0.000365 LR: 3.48e-06\n",
      "Epoch  30 [4100/10697 ( 38.3%)] Loss: 0.027310 L1: 0.016032 Grad: 0.112552 Thermal: 0.000461 LR: 3.48e-06\n",
      "Epoch  30 [4100/10697 ( 38.3%)] Loss: 0.027310 L1: 0.016032 Grad: 0.112552 Thermal: 0.000461 LR: 3.48e-06\n",
      "Epoch  30 [4150/10697 ( 38.8%)] Loss: 0.025662 L1: 0.014843 Grad: 0.107970 Thermal: 0.000438 LR: 3.48e-06\n",
      "Epoch  30 [4150/10697 ( 38.8%)] Loss: 0.025662 L1: 0.014843 Grad: 0.107970 Thermal: 0.000438 LR: 3.48e-06\n",
      "Epoch  30 [4200/10697 ( 39.3%)] Loss: 0.026180 L1: 0.015526 Grad: 0.106328 Thermal: 0.000422 LR: 3.48e-06\n",
      "Epoch  30 [4200/10697 ( 39.3%)] Loss: 0.026180 L1: 0.015526 Grad: 0.106328 Thermal: 0.000422 LR: 3.48e-06\n",
      "Epoch  30 [4250/10697 ( 39.7%)] Loss: 0.024423 L1: 0.014160 Grad: 0.102433 Thermal: 0.000389 LR: 3.48e-06\n",
      "Epoch  30 [4250/10697 ( 39.7%)] Loss: 0.024423 L1: 0.014160 Grad: 0.102433 Thermal: 0.000389 LR: 3.48e-06\n",
      "Epoch  30 [4300/10697 ( 40.2%)] Loss: 0.023524 L1: 0.013201 Grad: 0.103026 Thermal: 0.000394 LR: 3.48e-06\n",
      "Epoch  30 [4300/10697 ( 40.2%)] Loss: 0.023524 L1: 0.013201 Grad: 0.103026 Thermal: 0.000394 LR: 3.48e-06\n",
      "Epoch  30 [4350/10697 ( 40.7%)] Loss: 0.027950 L1: 0.016775 Grad: 0.111505 Thermal: 0.000498 LR: 3.48e-06\n",
      "Epoch  30 [4350/10697 ( 40.7%)] Loss: 0.027950 L1: 0.016775 Grad: 0.111505 Thermal: 0.000498 LR: 3.48e-06\n",
      "Epoch  30 [4400/10697 ( 41.1%)] Loss: 0.030956 L1: 0.017927 Grad: 0.130009 Thermal: 0.000571 LR: 3.48e-06\n",
      "Epoch  30 [4400/10697 ( 41.1%)] Loss: 0.030956 L1: 0.017927 Grad: 0.130009 Thermal: 0.000571 LR: 3.48e-06\n",
      "Epoch  30 [4450/10697 ( 41.6%)] Loss: 0.022524 L1: 0.013383 Grad: 0.091237 Thermal: 0.000351 LR: 3.48e-06\n",
      "Epoch  30 [4450/10697 ( 41.6%)] Loss: 0.022524 L1: 0.013383 Grad: 0.091237 Thermal: 0.000351 LR: 3.48e-06\n",
      "Epoch  30 [4500/10697 ( 42.1%)] Loss: 0.030999 L1: 0.017844 Grad: 0.131259 Thermal: 0.000576 LR: 3.48e-06\n",
      "Epoch  30 [4500/10697 ( 42.1%)] Loss: 0.030999 L1: 0.017844 Grad: 0.131259 Thermal: 0.000576 LR: 3.48e-06\n",
      "Epoch  30 [4550/10697 ( 42.5%)] Loss: 0.020167 L1: 0.011403 Grad: 0.087491 Thermal: 0.000287 LR: 3.48e-06\n",
      "Epoch  30 [4550/10697 ( 42.5%)] Loss: 0.020167 L1: 0.011403 Grad: 0.087491 Thermal: 0.000287 LR: 3.48e-06\n",
      "Epoch  30 [4600/10697 ( 43.0%)] Loss: 0.028276 L1: 0.016485 Grad: 0.117662 Thermal: 0.000500 LR: 3.48e-06\n",
      "Epoch  30 [4600/10697 ( 43.0%)] Loss: 0.028276 L1: 0.016485 Grad: 0.117662 Thermal: 0.000500 LR: 3.48e-06\n",
      "Epoch  30 [4650/10697 ( 43.5%)] Loss: 0.024382 L1: 0.014340 Grad: 0.100238 Thermal: 0.000364 LR: 3.48e-06\n",
      "Epoch  30 [4650/10697 ( 43.5%)] Loss: 0.024382 L1: 0.014340 Grad: 0.100238 Thermal: 0.000364 LR: 3.48e-06\n",
      "Epoch  30 [4700/10697 ( 43.9%)] Loss: 0.026334 L1: 0.015441 Grad: 0.108706 Thermal: 0.000452 LR: 3.48e-06\n",
      "Epoch  30 [4700/10697 ( 43.9%)] Loss: 0.026334 L1: 0.015441 Grad: 0.108706 Thermal: 0.000452 LR: 3.48e-06\n",
      "Epoch  30 [4750/10697 ( 44.4%)] Loss: 0.032508 L1: 0.019075 Grad: 0.133989 Thermal: 0.000689 LR: 3.48e-06\n",
      "Epoch  30 [4750/10697 ( 44.4%)] Loss: 0.032508 L1: 0.019075 Grad: 0.133989 Thermal: 0.000689 LR: 3.48e-06\n",
      "Epoch  30 [4800/10697 ( 44.9%)] Loss: 0.026642 L1: 0.015658 Grad: 0.109626 Thermal: 0.000436 LR: 3.48e-06\n",
      "Epoch  30 [4800/10697 ( 44.9%)] Loss: 0.026642 L1: 0.015658 Grad: 0.109626 Thermal: 0.000436 LR: 3.48e-06\n",
      "Epoch  30 [4850/10697 ( 45.3%)] Loss: 0.028010 L1: 0.016265 Grad: 0.117208 Thermal: 0.000475 LR: 3.48e-06\n",
      "Epoch  30 [4850/10697 ( 45.3%)] Loss: 0.028010 L1: 0.016265 Grad: 0.117208 Thermal: 0.000475 LR: 3.48e-06\n",
      "Epoch  30 [4900/10697 ( 45.8%)] Loss: 0.028377 L1: 0.016423 Grad: 0.119263 Thermal: 0.000553 LR: 3.48e-06\n",
      "Epoch  30 [4900/10697 ( 45.8%)] Loss: 0.028377 L1: 0.016423 Grad: 0.119263 Thermal: 0.000553 LR: 3.48e-06\n",
      "Epoch  30 [4950/10697 ( 46.3%)] Loss: 0.028280 L1: 0.016402 Grad: 0.118520 Thermal: 0.000529 LR: 3.48e-06\n",
      "Epoch  30 [4950/10697 ( 46.3%)] Loss: 0.028280 L1: 0.016402 Grad: 0.118520 Thermal: 0.000529 LR: 3.48e-06\n",
      "Epoch  30 [5000/10697 ( 46.7%)] Loss: 0.027748 L1: 0.016057 Grad: 0.116647 Thermal: 0.000526 LR: 3.48e-06\n",
      "Epoch  30 [5000/10697 ( 46.7%)] Loss: 0.027748 L1: 0.016057 Grad: 0.116647 Thermal: 0.000526 LR: 3.48e-06\n",
      "Epoch  30 [5050/10697 ( 47.2%)] Loss: 0.024843 L1: 0.014632 Grad: 0.101914 Thermal: 0.000401 LR: 3.48e-06\n",
      "Epoch  30 [5050/10697 ( 47.2%)] Loss: 0.024843 L1: 0.014632 Grad: 0.101914 Thermal: 0.000401 LR: 3.48e-06\n",
      "Epoch  30 [5100/10697 ( 47.7%)] Loss: 0.032431 L1: 0.019012 Grad: 0.133802 Thermal: 0.000777 LR: 3.48e-06\n",
      "Epoch  30 [5100/10697 ( 47.7%)] Loss: 0.032431 L1: 0.019012 Grad: 0.133802 Thermal: 0.000777 LR: 3.48e-06\n",
      "Epoch  30 [5150/10697 ( 48.1%)] Loss: 0.026484 L1: 0.015375 Grad: 0.110876 Thermal: 0.000421 LR: 3.48e-06\n",
      "Epoch  30 [5150/10697 ( 48.1%)] Loss: 0.026484 L1: 0.015375 Grad: 0.110876 Thermal: 0.000421 LR: 3.48e-06\n",
      "Epoch  30 [5200/10697 ( 48.6%)] Loss: 0.019382 L1: 0.011209 Grad: 0.081590 Thermal: 0.000268 LR: 3.48e-06\n",
      "Epoch  30 [5200/10697 ( 48.6%)] Loss: 0.019382 L1: 0.011209 Grad: 0.081590 Thermal: 0.000268 LR: 3.48e-06\n",
      "Epoch  30 [5250/10697 ( 49.1%)] Loss: 0.023770 L1: 0.014200 Grad: 0.095508 Thermal: 0.000387 LR: 3.48e-06\n",
      "Epoch  30 [5250/10697 ( 49.1%)] Loss: 0.023770 L1: 0.014200 Grad: 0.095508 Thermal: 0.000387 LR: 3.48e-06\n",
      "Epoch  30 [5300/10697 ( 49.5%)] Loss: 0.023934 L1: 0.014122 Grad: 0.097917 Thermal: 0.000403 LR: 3.48e-06\n",
      "Epoch  30 [5300/10697 ( 49.5%)] Loss: 0.023934 L1: 0.014122 Grad: 0.097917 Thermal: 0.000403 LR: 3.48e-06\n",
      "Epoch  30 [5350/10697 ( 50.0%)] Loss: 0.030726 L1: 0.017979 Grad: 0.127143 Thermal: 0.000652 LR: 3.48e-06\n",
      "Epoch  30 [5350/10697 ( 50.0%)] Loss: 0.030726 L1: 0.017979 Grad: 0.127143 Thermal: 0.000652 LR: 3.48e-06\n",
      "Epoch  30 [5400/10697 ( 50.5%)] Loss: 0.025283 L1: 0.015098 Grad: 0.101649 Thermal: 0.000405 LR: 3.48e-06\n",
      "Epoch  30 [5400/10697 ( 50.5%)] Loss: 0.025283 L1: 0.015098 Grad: 0.101649 Thermal: 0.000405 LR: 3.48e-06\n",
      "Epoch  30 [5450/10697 ( 50.9%)] Loss: 0.029297 L1: 0.017291 Grad: 0.119792 Thermal: 0.000538 LR: 3.48e-06\n",
      "Epoch  30 [5450/10697 ( 50.9%)] Loss: 0.029297 L1: 0.017291 Grad: 0.119792 Thermal: 0.000538 LR: 3.48e-06\n",
      "Epoch  30 [5500/10697 ( 51.4%)] Loss: 0.024126 L1: 0.014223 Grad: 0.098811 Thermal: 0.000441 LR: 3.48e-06\n",
      "Epoch  30 [5500/10697 ( 51.4%)] Loss: 0.024126 L1: 0.014223 Grad: 0.098811 Thermal: 0.000441 LR: 3.48e-06\n",
      "Epoch  30 [5550/10697 ( 51.9%)] Loss: 0.028499 L1: 0.016577 Grad: 0.118945 Thermal: 0.000546 LR: 3.48e-06\n",
      "Epoch  30 [5550/10697 ( 51.9%)] Loss: 0.028499 L1: 0.016577 Grad: 0.118945 Thermal: 0.000546 LR: 3.48e-06\n",
      "Epoch  30 [5600/10697 ( 52.4%)] Loss: 0.023779 L1: 0.013893 Grad: 0.098660 Thermal: 0.000397 LR: 3.48e-06\n",
      "Epoch  30 [5600/10697 ( 52.4%)] Loss: 0.023779 L1: 0.013893 Grad: 0.098660 Thermal: 0.000397 LR: 3.48e-06\n",
      "Epoch  30 [5650/10697 ( 52.8%)] Loss: 0.022656 L1: 0.013148 Grad: 0.094897 Thermal: 0.000354 LR: 3.48e-06\n",
      "Epoch  30 [5650/10697 ( 52.8%)] Loss: 0.022656 L1: 0.013148 Grad: 0.094897 Thermal: 0.000354 LR: 3.48e-06\n",
      "Epoch  30 [5700/10697 ( 53.3%)] Loss: 0.033829 L1: 0.019180 Grad: 0.146112 Thermal: 0.000741 LR: 3.48e-06\n",
      "Epoch  30 [5700/10697 ( 53.3%)] Loss: 0.033829 L1: 0.019180 Grad: 0.146112 Thermal: 0.000741 LR: 3.48e-06\n",
      "Epoch  30 [5750/10697 ( 53.8%)] Loss: 0.029881 L1: 0.017390 Grad: 0.124625 Thermal: 0.000562 LR: 3.48e-06\n",
      "Epoch  30 [5750/10697 ( 53.8%)] Loss: 0.029881 L1: 0.017390 Grad: 0.124625 Thermal: 0.000562 LR: 3.48e-06\n",
      "Epoch  30 [5800/10697 ( 54.2%)] Loss: 0.022548 L1: 0.013066 Grad: 0.094631 Thermal: 0.000387 LR: 3.48e-06\n",
      "Epoch  30 [5800/10697 ( 54.2%)] Loss: 0.022548 L1: 0.013066 Grad: 0.094631 Thermal: 0.000387 LR: 3.48e-06\n",
      "Epoch  30 [5850/10697 ( 54.7%)] Loss: 0.025699 L1: 0.015041 Grad: 0.106362 Thermal: 0.000435 LR: 3.48e-06\n",
      "Epoch  30 [5850/10697 ( 54.7%)] Loss: 0.025699 L1: 0.015041 Grad: 0.106362 Thermal: 0.000435 LR: 3.48e-06\n",
      "Epoch  30 [5900/10697 ( 55.2%)] Loss: 0.021779 L1: 0.012917 Grad: 0.088449 Thermal: 0.000355 LR: 3.48e-06\n",
      "Epoch  30 [5900/10697 ( 55.2%)] Loss: 0.021779 L1: 0.012917 Grad: 0.088449 Thermal: 0.000355 LR: 3.48e-06\n",
      "Epoch  30 [5950/10697 ( 55.6%)] Loss: 0.025209 L1: 0.014347 Grad: 0.108443 Thermal: 0.000357 LR: 3.48e-06\n",
      "Epoch  30 [5950/10697 ( 55.6%)] Loss: 0.025209 L1: 0.014347 Grad: 0.108443 Thermal: 0.000357 LR: 3.48e-06\n",
      "Epoch  30 [6000/10697 ( 56.1%)] Loss: 0.023686 L1: 0.014053 Grad: 0.096133 Thermal: 0.000390 LR: 3.48e-06\n",
      "Epoch  30 [6000/10697 ( 56.1%)] Loss: 0.023686 L1: 0.014053 Grad: 0.096133 Thermal: 0.000390 LR: 3.48e-06\n",
      "Epoch  30 [6050/10697 ( 56.6%)] Loss: 0.021832 L1: 0.012435 Grad: 0.093818 Thermal: 0.000306 LR: 3.48e-06\n",
      "Epoch  30 [6050/10697 ( 56.6%)] Loss: 0.021832 L1: 0.012435 Grad: 0.093818 Thermal: 0.000306 LR: 3.48e-06\n",
      "Epoch  30 [6100/10697 ( 57.0%)] Loss: 0.025846 L1: 0.015473 Grad: 0.103523 Thermal: 0.000425 LR: 3.48e-06\n",
      "Epoch  30 [6100/10697 ( 57.0%)] Loss: 0.025846 L1: 0.015473 Grad: 0.103523 Thermal: 0.000425 LR: 3.48e-06\n",
      "Epoch  30 [6150/10697 ( 57.5%)] Loss: 0.021581 L1: 0.012744 Grad: 0.088204 Thermal: 0.000319 LR: 3.48e-06\n",
      "Epoch  30 [6150/10697 ( 57.5%)] Loss: 0.021581 L1: 0.012744 Grad: 0.088204 Thermal: 0.000319 LR: 3.48e-06\n",
      "Epoch  30 [6200/10697 ( 58.0%)] Loss: 0.026378 L1: 0.015544 Grad: 0.108047 Thermal: 0.000584 LR: 3.48e-06\n",
      "Epoch  30 [6200/10697 ( 58.0%)] Loss: 0.026378 L1: 0.015544 Grad: 0.108047 Thermal: 0.000584 LR: 3.48e-06\n",
      "Epoch  30 [6250/10697 ( 58.4%)] Loss: 0.022777 L1: 0.013366 Grad: 0.093928 Thermal: 0.000365 LR: 3.48e-06\n",
      "Epoch  30 [6250/10697 ( 58.4%)] Loss: 0.022777 L1: 0.013366 Grad: 0.093928 Thermal: 0.000365 LR: 3.48e-06\n",
      "Epoch  30 [6300/10697 ( 58.9%)] Loss: 0.026591 L1: 0.015253 Grad: 0.113133 Thermal: 0.000504 LR: 3.48e-06\n",
      "Epoch  30 [6300/10697 ( 58.9%)] Loss: 0.026591 L1: 0.015253 Grad: 0.113133 Thermal: 0.000504 LR: 3.48e-06\n",
      "Epoch  30 [6350/10697 ( 59.4%)] Loss: 0.034219 L1: 0.020006 Grad: 0.141784 Thermal: 0.000695 LR: 3.48e-06\n",
      "Epoch  30 [6350/10697 ( 59.4%)] Loss: 0.034219 L1: 0.020006 Grad: 0.141784 Thermal: 0.000695 LR: 3.48e-06\n",
      "Epoch  30 [6400/10697 ( 59.8%)] Loss: 0.021082 L1: 0.012393 Grad: 0.086746 Thermal: 0.000292 LR: 3.48e-06\n",
      "Epoch  30 [6400/10697 ( 59.8%)] Loss: 0.021082 L1: 0.012393 Grad: 0.086746 Thermal: 0.000292 LR: 3.48e-06\n",
      "Epoch  30 [6450/10697 ( 60.3%)] Loss: 0.025515 L1: 0.014991 Grad: 0.105014 Thermal: 0.000444 LR: 3.48e-06\n",
      "Epoch  30 [6450/10697 ( 60.3%)] Loss: 0.025515 L1: 0.014991 Grad: 0.105014 Thermal: 0.000444 LR: 3.48e-06\n",
      "Epoch  30 [6500/10697 ( 60.8%)] Loss: 0.022126 L1: 0.012700 Grad: 0.094079 Thermal: 0.000354 LR: 3.48e-06\n",
      "Epoch  30 [6500/10697 ( 60.8%)] Loss: 0.022126 L1: 0.012700 Grad: 0.094079 Thermal: 0.000354 LR: 3.48e-06\n",
      "Epoch  30 [6550/10697 ( 61.2%)] Loss: 0.029992 L1: 0.017592 Grad: 0.123721 Thermal: 0.000566 LR: 3.48e-06\n",
      "Epoch  30 [6550/10697 ( 61.2%)] Loss: 0.029992 L1: 0.017592 Grad: 0.123721 Thermal: 0.000566 LR: 3.48e-06\n",
      "Epoch  30 [6600/10697 ( 61.7%)] Loss: 0.036028 L1: 0.020788 Grad: 0.151982 Thermal: 0.000837 LR: 3.48e-06\n",
      "Epoch  30 [6600/10697 ( 61.7%)] Loss: 0.036028 L1: 0.020788 Grad: 0.151982 Thermal: 0.000837 LR: 3.48e-06\n",
      "Epoch  30 [6650/10697 ( 62.2%)] Loss: 0.032422 L1: 0.018757 Grad: 0.136332 Thermal: 0.000649 LR: 3.48e-06\n",
      "Epoch  30 [6650/10697 ( 62.2%)] Loss: 0.032422 L1: 0.018757 Grad: 0.136332 Thermal: 0.000649 LR: 3.48e-06\n",
      "Epoch  30 [6700/10697 ( 62.6%)] Loss: 0.026188 L1: 0.015759 Grad: 0.104067 Thermal: 0.000438 LR: 3.48e-06\n",
      "Epoch  30 [6700/10697 ( 62.6%)] Loss: 0.026188 L1: 0.015759 Grad: 0.104067 Thermal: 0.000438 LR: 3.48e-06\n",
      "Epoch  30 [6750/10697 ( 63.1%)] Loss: 0.027512 L1: 0.016373 Grad: 0.111163 Thermal: 0.000454 LR: 3.48e-06\n",
      "Epoch  30 [6750/10697 ( 63.1%)] Loss: 0.027512 L1: 0.016373 Grad: 0.111163 Thermal: 0.000454 LR: 3.48e-06\n",
      "Epoch  30 [6800/10697 ( 63.6%)] Loss: 0.025065 L1: 0.014591 Grad: 0.104533 Thermal: 0.000401 LR: 3.48e-06\n",
      "Epoch  30 [6800/10697 ( 63.6%)] Loss: 0.025065 L1: 0.014591 Grad: 0.104533 Thermal: 0.000401 LR: 3.48e-06\n",
      "Epoch  30 [6850/10697 ( 64.0%)] Loss: 0.024582 L1: 0.014810 Grad: 0.097518 Thermal: 0.000387 LR: 3.48e-06\n",
      "Epoch  30 [6850/10697 ( 64.0%)] Loss: 0.024582 L1: 0.014810 Grad: 0.097518 Thermal: 0.000387 LR: 3.48e-06\n",
      "Epoch  30 [6900/10697 ( 64.5%)] Loss: 0.026560 L1: 0.015346 Grad: 0.111918 Thermal: 0.000438 LR: 3.48e-06\n",
      "Epoch  30 [6900/10697 ( 64.5%)] Loss: 0.026560 L1: 0.015346 Grad: 0.111918 Thermal: 0.000438 LR: 3.48e-06\n",
      "Epoch  30 [6950/10697 ( 65.0%)] Loss: 0.028516 L1: 0.016793 Grad: 0.116970 Thermal: 0.000533 LR: 3.48e-06\n",
      "Epoch  30 [6950/10697 ( 65.0%)] Loss: 0.028516 L1: 0.016793 Grad: 0.116970 Thermal: 0.000533 LR: 3.48e-06\n",
      "Epoch  30 [7000/10697 ( 65.4%)] Loss: 0.025020 L1: 0.014629 Grad: 0.103700 Thermal: 0.000423 LR: 3.48e-06\n",
      "Epoch  30 [7000/10697 ( 65.4%)] Loss: 0.025020 L1: 0.014629 Grad: 0.103700 Thermal: 0.000423 LR: 3.48e-06\n",
      "Epoch  30 [7050/10697 ( 65.9%)] Loss: 0.029681 L1: 0.017531 Grad: 0.121218 Thermal: 0.000575 LR: 3.48e-06\n",
      "Epoch  30 [7050/10697 ( 65.9%)] Loss: 0.029681 L1: 0.017531 Grad: 0.121218 Thermal: 0.000575 LR: 3.48e-06\n",
      "Epoch  30 [7100/10697 ( 66.4%)] Loss: 0.026025 L1: 0.015369 Grad: 0.106331 Thermal: 0.000451 LR: 3.48e-06\n",
      "Epoch  30 [7100/10697 ( 66.4%)] Loss: 0.026025 L1: 0.015369 Grad: 0.106331 Thermal: 0.000451 LR: 3.48e-06\n",
      "Epoch  30 [7150/10697 ( 66.8%)] Loss: 0.022822 L1: 0.013110 Grad: 0.096945 Thermal: 0.000349 LR: 3.48e-06\n",
      "Epoch  30 [7150/10697 ( 66.8%)] Loss: 0.022822 L1: 0.013110 Grad: 0.096945 Thermal: 0.000349 LR: 3.48e-06\n",
      "Epoch  30 [7200/10697 ( 67.3%)] Loss: 0.024434 L1: 0.014588 Grad: 0.098267 Thermal: 0.000393 LR: 3.48e-06\n",
      "Epoch  30 [7200/10697 ( 67.3%)] Loss: 0.024434 L1: 0.014588 Grad: 0.098267 Thermal: 0.000393 LR: 3.48e-06\n",
      "Epoch  30 [7250/10697 ( 67.8%)] Loss: 0.024804 L1: 0.014427 Grad: 0.103571 Thermal: 0.000403 LR: 3.48e-06\n",
      "Epoch  30 [7250/10697 ( 67.8%)] Loss: 0.024804 L1: 0.014427 Grad: 0.103571 Thermal: 0.000403 LR: 3.48e-06\n",
      "Epoch  30 [7300/10697 ( 68.2%)] Loss: 0.023505 L1: 0.014086 Grad: 0.094002 Thermal: 0.000375 LR: 3.48e-06\n",
      "Epoch  30 [7300/10697 ( 68.2%)] Loss: 0.023505 L1: 0.014086 Grad: 0.094002 Thermal: 0.000375 LR: 3.48e-06\n",
      "Epoch  30 [7350/10697 ( 68.7%)] Loss: 0.026894 L1: 0.015740 Grad: 0.111315 Thermal: 0.000456 LR: 3.48e-06\n",
      "Epoch  30 [7350/10697 ( 68.7%)] Loss: 0.026894 L1: 0.015740 Grad: 0.111315 Thermal: 0.000456 LR: 3.48e-06\n",
      "Epoch  30 [7400/10697 ( 69.2%)] Loss: 0.031202 L1: 0.018169 Grad: 0.130024 Thermal: 0.000611 LR: 3.48e-06\n",
      "Epoch  30 [7400/10697 ( 69.2%)] Loss: 0.031202 L1: 0.018169 Grad: 0.130024 Thermal: 0.000611 LR: 3.48e-06\n",
      "Epoch  30 [7450/10697 ( 69.6%)] Loss: 0.022855 L1: 0.013207 Grad: 0.096298 Thermal: 0.000350 LR: 3.48e-06\n",
      "Epoch  30 [7450/10697 ( 69.6%)] Loss: 0.022855 L1: 0.013207 Grad: 0.096298 Thermal: 0.000350 LR: 3.48e-06\n",
      "Epoch  30 [7500/10697 ( 70.1%)] Loss: 0.019757 L1: 0.011702 Grad: 0.080402 Thermal: 0.000290 LR: 3.48e-06\n",
      "Epoch  30 [7500/10697 ( 70.1%)] Loss: 0.019757 L1: 0.011702 Grad: 0.080402 Thermal: 0.000290 LR: 3.48e-06\n",
      "Epoch  30 [7550/10697 ( 70.6%)] Loss: 0.025694 L1: 0.015320 Grad: 0.103534 Thermal: 0.000413 LR: 3.48e-06\n",
      "Epoch  30 [7550/10697 ( 70.6%)] Loss: 0.025694 L1: 0.015320 Grad: 0.103534 Thermal: 0.000413 LR: 3.48e-06\n",
      "Epoch  30 [7600/10697 ( 71.0%)] Loss: 0.027507 L1: 0.016053 Grad: 0.114314 Thermal: 0.000466 LR: 3.48e-06\n",
      "Epoch  30 [7600/10697 ( 71.0%)] Loss: 0.027507 L1: 0.016053 Grad: 0.114314 Thermal: 0.000466 LR: 3.48e-06\n",
      "Epoch  30 [7650/10697 ( 71.5%)] Loss: 0.029799 L1: 0.017158 Grad: 0.126112 Thermal: 0.000584 LR: 3.48e-06\n",
      "Epoch  30 [7650/10697 ( 71.5%)] Loss: 0.029799 L1: 0.017158 Grad: 0.126112 Thermal: 0.000584 LR: 3.48e-06\n",
      "Epoch  30 [7700/10697 ( 72.0%)] Loss: 0.022570 L1: 0.013479 Grad: 0.090737 Thermal: 0.000346 LR: 3.48e-06\n",
      "Epoch  30 [7700/10697 ( 72.0%)] Loss: 0.022570 L1: 0.013479 Grad: 0.090737 Thermal: 0.000346 LR: 3.48e-06\n",
      "Epoch  30 [7750/10697 ( 72.5%)] Loss: 0.030941 L1: 0.018141 Grad: 0.127699 Thermal: 0.000607 LR: 3.48e-06\n",
      "Epoch  30 [7750/10697 ( 72.5%)] Loss: 0.030941 L1: 0.018141 Grad: 0.127699 Thermal: 0.000607 LR: 3.48e-06\n",
      "Epoch  30 [7800/10697 ( 72.9%)] Loss: 0.027401 L1: 0.016082 Grad: 0.112953 Thermal: 0.000471 LR: 3.48e-06\n",
      "Epoch  30 [7800/10697 ( 72.9%)] Loss: 0.027401 L1: 0.016082 Grad: 0.112953 Thermal: 0.000471 LR: 3.48e-06\n",
      "Epoch  30 [7850/10697 ( 73.4%)] Loss: 0.028207 L1: 0.016499 Grad: 0.116827 Thermal: 0.000513 LR: 3.48e-06\n",
      "Epoch  30 [7850/10697 ( 73.4%)] Loss: 0.028207 L1: 0.016499 Grad: 0.116827 Thermal: 0.000513 LR: 3.48e-06\n",
      "Epoch  30 [7900/10697 ( 73.9%)] Loss: 0.027569 L1: 0.016059 Grad: 0.114865 Thermal: 0.000469 LR: 3.48e-06\n",
      "Epoch  30 [7900/10697 ( 73.9%)] Loss: 0.027569 L1: 0.016059 Grad: 0.114865 Thermal: 0.000469 LR: 3.48e-06\n",
      "Epoch  30 [7950/10697 ( 74.3%)] Loss: 0.026863 L1: 0.015656 Grad: 0.111848 Thermal: 0.000454 LR: 3.48e-06\n",
      "Epoch  30 [7950/10697 ( 74.3%)] Loss: 0.026863 L1: 0.015656 Grad: 0.111848 Thermal: 0.000454 LR: 3.48e-06\n",
      "Epoch  30 [8000/10697 ( 74.8%)] Loss: 0.028259 L1: 0.016434 Grad: 0.117992 Thermal: 0.000512 LR: 3.48e-06\n",
      "Epoch  30 [8000/10697 ( 74.8%)] Loss: 0.028259 L1: 0.016434 Grad: 0.117992 Thermal: 0.000512 LR: 3.48e-06\n",
      "Epoch  30 [8050/10697 ( 75.3%)] Loss: 0.026843 L1: 0.016097 Grad: 0.107223 Thermal: 0.000474 LR: 3.48e-06\n",
      "Epoch  30 [8050/10697 ( 75.3%)] Loss: 0.026843 L1: 0.016097 Grad: 0.107223 Thermal: 0.000474 LR: 3.48e-06\n",
      "Epoch  30 [8100/10697 ( 75.7%)] Loss: 0.032174 L1: 0.018254 Grad: 0.138906 Thermal: 0.000589 LR: 3.48e-06\n",
      "Epoch  30 [8100/10697 ( 75.7%)] Loss: 0.032174 L1: 0.018254 Grad: 0.138906 Thermal: 0.000589 LR: 3.48e-06\n",
      "Epoch  30 [8150/10697 ( 76.2%)] Loss: 0.029793 L1: 0.017071 Grad: 0.126953 Thermal: 0.000526 LR: 3.48e-06\n",
      "Epoch  30 [8150/10697 ( 76.2%)] Loss: 0.029793 L1: 0.017071 Grad: 0.126953 Thermal: 0.000526 LR: 3.48e-06\n",
      "Epoch  30 [8200/10697 ( 76.7%)] Loss: 0.027103 L1: 0.015962 Grad: 0.111148 Thermal: 0.000516 LR: 3.48e-06\n",
      "Epoch  30 [8200/10697 ( 76.7%)] Loss: 0.027103 L1: 0.015962 Grad: 0.111148 Thermal: 0.000516 LR: 3.48e-06\n",
      "Epoch  30 [8250/10697 ( 77.1%)] Loss: 0.026315 L1: 0.015825 Grad: 0.104676 Thermal: 0.000440 LR: 3.48e-06\n",
      "Epoch  30 [8250/10697 ( 77.1%)] Loss: 0.026315 L1: 0.015825 Grad: 0.104676 Thermal: 0.000440 LR: 3.48e-06\n",
      "Epoch  30 [8300/10697 ( 77.6%)] Loss: 0.025528 L1: 0.014600 Grad: 0.109077 Thermal: 0.000415 LR: 3.48e-06\n",
      "Epoch  30 [8300/10697 ( 77.6%)] Loss: 0.025528 L1: 0.014600 Grad: 0.109077 Thermal: 0.000415 LR: 3.48e-06\n",
      "Epoch  30 [8350/10697 ( 78.1%)] Loss: 0.024147 L1: 0.014205 Grad: 0.099230 Thermal: 0.000370 LR: 3.48e-06\n",
      "Epoch  30 [8350/10697 ( 78.1%)] Loss: 0.024147 L1: 0.014205 Grad: 0.099230 Thermal: 0.000370 LR: 3.48e-06\n",
      "Epoch  30 [8400/10697 ( 78.5%)] Loss: 0.022673 L1: 0.013165 Grad: 0.094909 Thermal: 0.000333 LR: 3.48e-06\n",
      "Epoch  30 [8400/10697 ( 78.5%)] Loss: 0.022673 L1: 0.013165 Grad: 0.094909 Thermal: 0.000333 LR: 3.48e-06\n",
      "Epoch  30 [8450/10697 ( 79.0%)] Loss: 0.026678 L1: 0.015588 Grad: 0.110677 Thermal: 0.000446 LR: 3.48e-06\n",
      "Epoch  30 [8450/10697 ( 79.0%)] Loss: 0.026678 L1: 0.015588 Grad: 0.110677 Thermal: 0.000446 LR: 3.48e-06\n",
      "Epoch  30 [8500/10697 ( 79.5%)] Loss: 0.031614 L1: 0.018553 Grad: 0.130294 Thermal: 0.000637 LR: 3.48e-06\n",
      "Epoch  30 [8500/10697 ( 79.5%)] Loss: 0.031614 L1: 0.018553 Grad: 0.130294 Thermal: 0.000637 LR: 3.48e-06\n",
      "Epoch  30 [8550/10697 ( 79.9%)] Loss: 0.026497 L1: 0.015394 Grad: 0.110765 Thermal: 0.000537 LR: 3.48e-06\n",
      "Epoch  30 [8550/10697 ( 79.9%)] Loss: 0.026497 L1: 0.015394 Grad: 0.110765 Thermal: 0.000537 LR: 3.48e-06\n",
      "Epoch  30 [8600/10697 ( 80.4%)] Loss: 0.027439 L1: 0.015392 Grad: 0.120235 Thermal: 0.000477 LR: 3.48e-06\n",
      "Epoch  30 [8600/10697 ( 80.4%)] Loss: 0.027439 L1: 0.015392 Grad: 0.120235 Thermal: 0.000477 LR: 3.48e-06\n",
      "Epoch  30 [8650/10697 ( 80.9%)] Loss: 0.028632 L1: 0.016133 Grad: 0.124744 Thermal: 0.000501 LR: 3.48e-06\n",
      "Epoch  30 [8650/10697 ( 80.9%)] Loss: 0.028632 L1: 0.016133 Grad: 0.124744 Thermal: 0.000501 LR: 3.48e-06\n",
      "Epoch  30 [8700/10697 ( 81.3%)] Loss: 0.025279 L1: 0.014988 Grad: 0.102677 Thermal: 0.000465 LR: 3.48e-06\n",
      "Epoch  30 [8700/10697 ( 81.3%)] Loss: 0.025279 L1: 0.014988 Grad: 0.102677 Thermal: 0.000465 LR: 3.48e-06\n",
      "Epoch  30 [8750/10697 ( 81.8%)] Loss: 0.021933 L1: 0.012480 Grad: 0.094364 Thermal: 0.000338 LR: 3.48e-06\n",
      "Epoch  30 [8750/10697 ( 81.8%)] Loss: 0.021933 L1: 0.012480 Grad: 0.094364 Thermal: 0.000338 LR: 3.48e-06\n",
      "Epoch  30 [8800/10697 ( 82.3%)] Loss: 0.026275 L1: 0.015486 Grad: 0.107673 Thermal: 0.000432 LR: 3.48e-06\n",
      "Epoch  30 [8800/10697 ( 82.3%)] Loss: 0.026275 L1: 0.015486 Grad: 0.107673 Thermal: 0.000432 LR: 3.48e-06\n",
      "Epoch  30 [8850/10697 ( 82.7%)] Loss: 0.026711 L1: 0.015969 Grad: 0.107200 Thermal: 0.000441 LR: 3.48e-06\n",
      "Epoch  30 [8850/10697 ( 82.7%)] Loss: 0.026711 L1: 0.015969 Grad: 0.107200 Thermal: 0.000441 LR: 3.48e-06\n",
      "Epoch  30 [8900/10697 ( 83.2%)] Loss: 0.019691 L1: 0.011300 Grad: 0.083774 Thermal: 0.000267 LR: 3.48e-06\n",
      "Epoch  30 [8900/10697 ( 83.2%)] Loss: 0.019691 L1: 0.011300 Grad: 0.083774 Thermal: 0.000267 LR: 3.48e-06\n",
      "Epoch  30 [8950/10697 ( 83.7%)] Loss: 0.022848 L1: 0.013029 Grad: 0.098024 Thermal: 0.000333 LR: 3.48e-06\n",
      "Epoch  30 [8950/10697 ( 83.7%)] Loss: 0.022848 L1: 0.013029 Grad: 0.098024 Thermal: 0.000333 LR: 3.48e-06\n",
      "Epoch  30 [9000/10697 ( 84.1%)] Loss: 0.031262 L1: 0.017920 Grad: 0.133113 Thermal: 0.000610 LR: 3.48e-06\n",
      "Epoch  30 [9000/10697 ( 84.1%)] Loss: 0.031262 L1: 0.017920 Grad: 0.133113 Thermal: 0.000610 LR: 3.48e-06\n",
      "Epoch  30 [9050/10697 ( 84.6%)] Loss: 0.018686 L1: 0.011038 Grad: 0.076324 Thermal: 0.000297 LR: 3.48e-06\n",
      "Epoch  30 [9050/10697 ( 84.6%)] Loss: 0.018686 L1: 0.011038 Grad: 0.076324 Thermal: 0.000297 LR: 3.48e-06\n",
      "Epoch  30 [9100/10697 ( 85.1%)] Loss: 0.026436 L1: 0.015298 Grad: 0.111160 Thermal: 0.000423 LR: 3.48e-06\n",
      "Epoch  30 [9100/10697 ( 85.1%)] Loss: 0.026436 L1: 0.015298 Grad: 0.111160 Thermal: 0.000423 LR: 3.48e-06\n",
      "Epoch  30 [9150/10697 ( 85.5%)] Loss: 0.024902 L1: 0.014625 Grad: 0.102567 Thermal: 0.000407 LR: 3.48e-06\n",
      "Epoch  30 [9150/10697 ( 85.5%)] Loss: 0.024902 L1: 0.014625 Grad: 0.102567 Thermal: 0.000407 LR: 3.48e-06\n",
      "Epoch  30 [9200/10697 ( 86.0%)] Loss: 0.029399 L1: 0.017290 Grad: 0.120821 Thermal: 0.000537 LR: 3.48e-06\n",
      "Epoch  30 [9200/10697 ( 86.0%)] Loss: 0.029399 L1: 0.017290 Grad: 0.120821 Thermal: 0.000537 LR: 3.48e-06\n",
      "Epoch  30 [9250/10697 ( 86.5%)] Loss: 0.023394 L1: 0.013574 Grad: 0.098016 Thermal: 0.000375 LR: 3.48e-06\n",
      "Epoch  30 [9250/10697 ( 86.5%)] Loss: 0.023394 L1: 0.013574 Grad: 0.098016 Thermal: 0.000375 LR: 3.48e-06\n",
      "Epoch  30 [9300/10697 ( 86.9%)] Loss: 0.029057 L1: 0.016614 Grad: 0.124177 Thermal: 0.000501 LR: 3.48e-06\n",
      "Epoch  30 [9300/10697 ( 86.9%)] Loss: 0.029057 L1: 0.016614 Grad: 0.124177 Thermal: 0.000501 LR: 3.48e-06\n",
      "Epoch  30 [9350/10697 ( 87.4%)] Loss: 0.026603 L1: 0.015396 Grad: 0.111860 Thermal: 0.000432 LR: 3.48e-06\n",
      "Epoch  30 [9350/10697 ( 87.4%)] Loss: 0.026603 L1: 0.015396 Grad: 0.111860 Thermal: 0.000432 LR: 3.48e-06\n",
      "Epoch  30 [9400/10697 ( 87.9%)] Loss: 0.025977 L1: 0.015156 Grad: 0.108000 Thermal: 0.000426 LR: 3.48e-06\n",
      "Epoch  30 [9400/10697 ( 87.9%)] Loss: 0.025977 L1: 0.015156 Grad: 0.108000 Thermal: 0.000426 LR: 3.48e-06\n",
      "Epoch  30 [9450/10697 ( 88.3%)] Loss: 0.025869 L1: 0.015267 Grad: 0.105774 Thermal: 0.000504 LR: 3.48e-06\n",
      "Epoch  30 [9450/10697 ( 88.3%)] Loss: 0.025869 L1: 0.015267 Grad: 0.105774 Thermal: 0.000504 LR: 3.48e-06\n",
      "Epoch  30 [9500/10697 ( 88.8%)] Loss: 0.024858 L1: 0.014419 Grad: 0.104195 Thermal: 0.000402 LR: 3.48e-06\n",
      "Epoch  30 [9500/10697 ( 88.8%)] Loss: 0.024858 L1: 0.014419 Grad: 0.104195 Thermal: 0.000402 LR: 3.48e-06\n",
      "Epoch  30 [9550/10697 ( 89.3%)] Loss: 0.027436 L1: 0.016448 Grad: 0.109648 Thermal: 0.000475 LR: 3.48e-06\n",
      "Epoch  30 [9550/10697 ( 89.3%)] Loss: 0.027436 L1: 0.016448 Grad: 0.109648 Thermal: 0.000475 LR: 3.48e-06\n",
      "Epoch  30 [9600/10697 ( 89.7%)] Loss: 0.022834 L1: 0.013445 Grad: 0.093720 Thermal: 0.000345 LR: 3.48e-06\n",
      "Epoch  30 [9600/10697 ( 89.7%)] Loss: 0.022834 L1: 0.013445 Grad: 0.093720 Thermal: 0.000345 LR: 3.48e-06\n",
      "Epoch  30 [9650/10697 ( 90.2%)] Loss: 0.023063 L1: 0.013608 Grad: 0.094374 Thermal: 0.000353 LR: 3.48e-06\n",
      "Epoch  30 [9650/10697 ( 90.2%)] Loss: 0.023063 L1: 0.013608 Grad: 0.094374 Thermal: 0.000353 LR: 3.48e-06\n",
      "Epoch  30 [9700/10697 ( 90.7%)] Loss: 0.030310 L1: 0.017449 Grad: 0.128340 Thermal: 0.000529 LR: 3.48e-06\n",
      "Epoch  30 [9700/10697 ( 90.7%)] Loss: 0.030310 L1: 0.017449 Grad: 0.128340 Thermal: 0.000529 LR: 3.48e-06\n",
      "Epoch  30 [9750/10697 ( 91.1%)] Loss: 0.023139 L1: 0.013136 Grad: 0.099857 Thermal: 0.000341 LR: 3.48e-06\n",
      "Epoch  30 [9750/10697 ( 91.1%)] Loss: 0.023139 L1: 0.013136 Grad: 0.099857 Thermal: 0.000341 LR: 3.48e-06\n",
      "Epoch  30 [9800/10697 ( 91.6%)] Loss: 0.024749 L1: 0.013955 Grad: 0.107722 Thermal: 0.000417 LR: 3.48e-06\n",
      "Epoch  30 [9800/10697 ( 91.6%)] Loss: 0.024749 L1: 0.013955 Grad: 0.107722 Thermal: 0.000417 LR: 3.48e-06\n",
      "Epoch  30 [9850/10697 ( 92.1%)] Loss: 0.025162 L1: 0.015156 Grad: 0.099837 Thermal: 0.000439 LR: 3.48e-06\n",
      "Epoch  30 [9850/10697 ( 92.1%)] Loss: 0.025162 L1: 0.015156 Grad: 0.099837 Thermal: 0.000439 LR: 3.48e-06\n",
      "Epoch  30 [9900/10697 ( 92.5%)] Loss: 0.030233 L1: 0.017592 Grad: 0.126093 Thermal: 0.000636 LR: 3.48e-06\n",
      "Epoch  30 [9900/10697 ( 92.5%)] Loss: 0.030233 L1: 0.017592 Grad: 0.126093 Thermal: 0.000636 LR: 3.48e-06\n",
      "Epoch  30 [9950/10697 ( 93.0%)] Loss: 0.028588 L1: 0.016634 Grad: 0.119293 Thermal: 0.000500 LR: 3.48e-06\n",
      "Epoch  30 [9950/10697 ( 93.0%)] Loss: 0.028588 L1: 0.016634 Grad: 0.119293 Thermal: 0.000500 LR: 3.48e-06\n",
      "Epoch  30 [10000/10697 ( 93.5%)] Loss: 0.028356 L1: 0.016812 Grad: 0.115188 Thermal: 0.000494 LR: 3.48e-06\n",
      "Epoch  30 [10000/10697 ( 93.5%)] Loss: 0.028356 L1: 0.016812 Grad: 0.115188 Thermal: 0.000494 LR: 3.48e-06\n",
      "Epoch  30 [10050/10697 ( 94.0%)] Loss: 0.021550 L1: 0.012575 Grad: 0.089569 Thermal: 0.000354 LR: 3.48e-06\n",
      "Epoch  30 [10050/10697 ( 94.0%)] Loss: 0.021550 L1: 0.012575 Grad: 0.089569 Thermal: 0.000354 LR: 3.48e-06\n",
      "Epoch  30 [10100/10697 ( 94.4%)] Loss: 0.028605 L1: 0.016540 Grad: 0.120402 Thermal: 0.000491 LR: 3.48e-06\n",
      "Epoch  30 [10100/10697 ( 94.4%)] Loss: 0.028605 L1: 0.016540 Grad: 0.120402 Thermal: 0.000491 LR: 3.48e-06\n",
      "Epoch  30 [10150/10697 ( 94.9%)] Loss: 0.023651 L1: 0.014136 Grad: 0.094958 Thermal: 0.000373 LR: 3.48e-06\n",
      "Epoch  30 [10150/10697 ( 94.9%)] Loss: 0.023651 L1: 0.014136 Grad: 0.094958 Thermal: 0.000373 LR: 3.48e-06\n",
      "Epoch  30 [10200/10697 ( 95.4%)] Loss: 0.029017 L1: 0.016838 Grad: 0.121477 Thermal: 0.000615 LR: 3.48e-06\n",
      "Epoch  30 [10200/10697 ( 95.4%)] Loss: 0.029017 L1: 0.016838 Grad: 0.121477 Thermal: 0.000615 LR: 3.48e-06\n",
      "Epoch  30 [10250/10697 ( 95.8%)] Loss: 0.023164 L1: 0.013516 Grad: 0.096308 Thermal: 0.000342 LR: 3.48e-06\n",
      "Epoch  30 [10250/10697 ( 95.8%)] Loss: 0.023164 L1: 0.013516 Grad: 0.096308 Thermal: 0.000342 LR: 3.48e-06\n",
      "Epoch  30 [10300/10697 ( 96.3%)] Loss: 0.026462 L1: 0.015288 Grad: 0.111503 Thermal: 0.000474 LR: 3.48e-06\n",
      "Epoch  30 [10300/10697 ( 96.3%)] Loss: 0.026462 L1: 0.015288 Grad: 0.111503 Thermal: 0.000474 LR: 3.48e-06\n",
      "Epoch  30 [10350/10697 ( 96.8%)] Loss: 0.027583 L1: 0.015984 Grad: 0.115756 Thermal: 0.000469 LR: 3.48e-06\n",
      "Epoch  30 [10350/10697 ( 96.8%)] Loss: 0.027583 L1: 0.015984 Grad: 0.115756 Thermal: 0.000469 LR: 3.48e-06\n",
      "Epoch  30 [10400/10697 ( 97.2%)] Loss: 0.029911 L1: 0.017068 Grad: 0.128153 Thermal: 0.000552 LR: 3.48e-06\n",
      "Epoch  30 [10400/10697 ( 97.2%)] Loss: 0.029911 L1: 0.017068 Grad: 0.128153 Thermal: 0.000552 LR: 3.48e-06\n",
      "Epoch  30 [10450/10697 ( 97.7%)] Loss: 0.025705 L1: 0.015121 Grad: 0.105622 Thermal: 0.000426 LR: 3.48e-06\n",
      "Epoch  30 [10450/10697 ( 97.7%)] Loss: 0.025705 L1: 0.015121 Grad: 0.105622 Thermal: 0.000426 LR: 3.48e-06\n",
      "Epoch  30 [10500/10697 ( 98.2%)] Loss: 0.027263 L1: 0.016112 Grad: 0.111271 Thermal: 0.000474 LR: 3.48e-06\n",
      "Epoch  30 [10500/10697 ( 98.2%)] Loss: 0.027263 L1: 0.016112 Grad: 0.111271 Thermal: 0.000474 LR: 3.48e-06\n",
      "Epoch  30 [10550/10697 ( 98.6%)] Loss: 0.026818 L1: 0.016041 Grad: 0.107547 Thermal: 0.000448 LR: 3.48e-06\n",
      "Epoch  30 [10550/10697 ( 98.6%)] Loss: 0.026818 L1: 0.016041 Grad: 0.107547 Thermal: 0.000448 LR: 3.48e-06\n",
      "Epoch  30 [10600/10697 ( 99.1%)] Loss: 0.025713 L1: 0.015209 Grad: 0.104816 Thermal: 0.000446 LR: 3.48e-06\n",
      "Epoch  30 [10600/10697 ( 99.1%)] Loss: 0.025713 L1: 0.015209 Grad: 0.104816 Thermal: 0.000446 LR: 3.48e-06\n",
      "Epoch  30 [10650/10697 ( 99.6%)] Loss: 0.023240 L1: 0.013602 Grad: 0.096198 Thermal: 0.000373 LR: 3.48e-06\n",
      "Epoch  30 [10650/10697 ( 99.6%)] Loss: 0.023240 L1: 0.013602 Grad: 0.096198 Thermal: 0.000373 LR: 3.48e-06\n",
      "üí´ New best model saved! PSNR: 33.96\n",
      "Epoch  30 Summary: Loss=0.026282 (L1:0.0153, Grad:0.1093, Thermal:0.0005) Val_PSNR=33.96dB Best=33.96dB Time=115.3min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "üí´ New best model saved! PSNR: 33.96\n",
      "Epoch  30 Summary: Loss=0.026282 (L1:0.0153, Grad:0.1093, Thermal:0.0005) Val_PSNR=33.96dB Best=33.96dB Time=115.3min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  31 [   0/10697 (  0.0%)] Loss: 0.026581 L1: 0.015332 Grad: 0.112266 Thermal: 0.000448 LR: 3.39e-06\n",
      "Epoch  31 [   0/10697 (  0.0%)] Loss: 0.026581 L1: 0.015332 Grad: 0.112266 Thermal: 0.000448 LR: 3.39e-06\n",
      "Epoch  31 [  50/10697 (  0.5%)] Loss: 0.028562 L1: 0.016806 Grad: 0.117322 Thermal: 0.000483 LR: 3.39e-06\n",
      "Epoch  31 [  50/10697 (  0.5%)] Loss: 0.028562 L1: 0.016806 Grad: 0.117322 Thermal: 0.000483 LR: 3.39e-06\n",
      "Epoch  31 [ 100/10697 (  0.9%)] Loss: 0.027047 L1: 0.016185 Grad: 0.108396 Thermal: 0.000461 LR: 3.39e-06\n",
      "Epoch  31 [ 100/10697 (  0.9%)] Loss: 0.027047 L1: 0.016185 Grad: 0.108396 Thermal: 0.000461 LR: 3.39e-06\n",
      "Epoch  31 [ 150/10697 (  1.4%)] Loss: 0.020948 L1: 0.012005 Grad: 0.089281 Thermal: 0.000295 LR: 3.39e-06\n",
      "Epoch  31 [ 150/10697 (  1.4%)] Loss: 0.020948 L1: 0.012005 Grad: 0.089281 Thermal: 0.000295 LR: 3.39e-06\n",
      "Epoch  31 [ 200/10697 (  1.9%)] Loss: 0.026130 L1: 0.015225 Grad: 0.108820 Thermal: 0.000458 LR: 3.39e-06\n",
      "Epoch  31 [ 200/10697 (  1.9%)] Loss: 0.026130 L1: 0.015225 Grad: 0.108820 Thermal: 0.000458 LR: 3.39e-06\n",
      "Epoch  31 [ 250/10697 (  2.3%)] Loss: 0.024940 L1: 0.014843 Grad: 0.100767 Thermal: 0.000407 LR: 3.39e-06\n",
      "Epoch  31 [ 250/10697 (  2.3%)] Loss: 0.024940 L1: 0.014843 Grad: 0.100767 Thermal: 0.000407 LR: 3.39e-06\n",
      "Epoch  31 [ 300/10697 (  2.8%)] Loss: 0.028914 L1: 0.016977 Grad: 0.119109 Thermal: 0.000505 LR: 3.39e-06\n",
      "Epoch  31 [ 300/10697 (  2.8%)] Loss: 0.028914 L1: 0.016977 Grad: 0.119109 Thermal: 0.000505 LR: 3.39e-06\n",
      "Epoch  31 [ 350/10697 (  3.3%)] Loss: 0.029652 L1: 0.016779 Grad: 0.128431 Thermal: 0.000585 LR: 3.39e-06\n",
      "Epoch  31 [ 350/10697 (  3.3%)] Loss: 0.029652 L1: 0.016779 Grad: 0.128431 Thermal: 0.000585 LR: 3.39e-06\n",
      "Epoch  31 [ 400/10697 (  3.7%)] Loss: 0.034490 L1: 0.020398 Grad: 0.140531 Thermal: 0.000781 LR: 3.39e-06\n",
      "Epoch  31 [ 400/10697 (  3.7%)] Loss: 0.034490 L1: 0.020398 Grad: 0.140531 Thermal: 0.000781 LR: 3.39e-06\n",
      "Epoch  31 [ 450/10697 (  4.2%)] Loss: 0.030986 L1: 0.018010 Grad: 0.129468 Thermal: 0.000591 LR: 3.39e-06\n",
      "Epoch  31 [ 450/10697 (  4.2%)] Loss: 0.030986 L1: 0.018010 Grad: 0.129468 Thermal: 0.000591 LR: 3.39e-06\n",
      "Epoch  31 [ 500/10697 (  4.7%)] Loss: 0.025220 L1: 0.014850 Grad: 0.103492 Thermal: 0.000416 LR: 3.39e-06\n",
      "Epoch  31 [ 500/10697 (  4.7%)] Loss: 0.025220 L1: 0.014850 Grad: 0.103492 Thermal: 0.000416 LR: 3.39e-06\n",
      "Epoch  31 [ 550/10697 (  5.1%)] Loss: 0.023176 L1: 0.013141 Grad: 0.100178 Thermal: 0.000336 LR: 3.39e-06\n",
      "Epoch  31 [ 550/10697 (  5.1%)] Loss: 0.023176 L1: 0.013141 Grad: 0.100178 Thermal: 0.000336 LR: 3.39e-06\n",
      "Epoch  31 [ 600/10697 (  5.6%)] Loss: 0.026578 L1: 0.015584 Grad: 0.109739 Thermal: 0.000405 LR: 3.39e-06\n",
      "Epoch  31 [ 600/10697 (  5.6%)] Loss: 0.026578 L1: 0.015584 Grad: 0.109739 Thermal: 0.000405 LR: 3.39e-06\n",
      "Epoch  31 [ 650/10697 (  6.1%)] Loss: 0.022631 L1: 0.012805 Grad: 0.098094 Thermal: 0.000323 LR: 3.39e-06\n",
      "Epoch  31 [ 650/10697 (  6.1%)] Loss: 0.022631 L1: 0.012805 Grad: 0.098094 Thermal: 0.000323 LR: 3.39e-06\n",
      "Epoch  31 [ 700/10697 (  6.5%)] Loss: 0.022977 L1: 0.013198 Grad: 0.097622 Thermal: 0.000343 LR: 3.39e-06\n",
      "Epoch  31 [ 700/10697 (  6.5%)] Loss: 0.022977 L1: 0.013198 Grad: 0.097622 Thermal: 0.000343 LR: 3.39e-06\n",
      "Epoch  31 [ 750/10697 (  7.0%)] Loss: 0.022039 L1: 0.012984 Grad: 0.090363 Thermal: 0.000370 LR: 3.39e-06\n",
      "Epoch  31 [ 750/10697 (  7.0%)] Loss: 0.022039 L1: 0.012984 Grad: 0.090363 Thermal: 0.000370 LR: 3.39e-06\n",
      "Epoch  31 [ 800/10697 (  7.5%)] Loss: 0.031022 L1: 0.018138 Grad: 0.128552 Thermal: 0.000592 LR: 3.39e-06\n",
      "Epoch  31 [ 800/10697 (  7.5%)] Loss: 0.031022 L1: 0.018138 Grad: 0.128552 Thermal: 0.000592 LR: 3.39e-06\n",
      "Epoch  31 [ 850/10697 (  7.9%)] Loss: 0.023287 L1: 0.013596 Grad: 0.096731 Thermal: 0.000363 LR: 3.39e-06\n",
      "Epoch  31 [ 850/10697 (  7.9%)] Loss: 0.023287 L1: 0.013596 Grad: 0.096731 Thermal: 0.000363 LR: 3.39e-06\n",
      "Epoch  31 [ 900/10697 (  8.4%)] Loss: 0.028114 L1: 0.016557 Grad: 0.115314 Thermal: 0.000513 LR: 3.39e-06\n",
      "Epoch  31 [ 900/10697 (  8.4%)] Loss: 0.028114 L1: 0.016557 Grad: 0.115314 Thermal: 0.000513 LR: 3.39e-06\n",
      "Epoch  31 [ 950/10697 (  8.9%)] Loss: 0.028037 L1: 0.016290 Grad: 0.117219 Thermal: 0.000502 LR: 3.39e-06\n",
      "Epoch  31 [ 950/10697 (  8.9%)] Loss: 0.028037 L1: 0.016290 Grad: 0.117219 Thermal: 0.000502 LR: 3.39e-06\n",
      "Epoch  31 [1000/10697 (  9.3%)] Loss: 0.021136 L1: 0.011807 Grad: 0.093124 Thermal: 0.000331 LR: 3.39e-06\n",
      "Epoch  31 [1000/10697 (  9.3%)] Loss: 0.021136 L1: 0.011807 Grad: 0.093124 Thermal: 0.000331 LR: 3.39e-06\n",
      "Epoch  31 [1050/10697 (  9.8%)] Loss: 0.024196 L1: 0.014256 Grad: 0.099215 Thermal: 0.000386 LR: 3.39e-06\n",
      "Epoch  31 [1050/10697 (  9.8%)] Loss: 0.024196 L1: 0.014256 Grad: 0.099215 Thermal: 0.000386 LR: 3.39e-06\n",
      "Epoch  31 [1100/10697 ( 10.3%)] Loss: 0.032586 L1: 0.018777 Grad: 0.137774 Thermal: 0.000623 LR: 3.39e-06\n",
      "Epoch  31 [1100/10697 ( 10.3%)] Loss: 0.032586 L1: 0.018777 Grad: 0.137774 Thermal: 0.000623 LR: 3.39e-06\n",
      "Epoch  31 [1150/10697 ( 10.8%)] Loss: 0.028828 L1: 0.016713 Grad: 0.120834 Thermal: 0.000631 LR: 3.39e-06\n",
      "Epoch  31 [1150/10697 ( 10.8%)] Loss: 0.028828 L1: 0.016713 Grad: 0.120834 Thermal: 0.000631 LR: 3.39e-06\n",
      "Epoch  31 [1200/10697 ( 11.2%)] Loss: 0.030981 L1: 0.017906 Grad: 0.130427 Thermal: 0.000634 LR: 3.39e-06\n",
      "Epoch  31 [1200/10697 ( 11.2%)] Loss: 0.030981 L1: 0.017906 Grad: 0.130427 Thermal: 0.000634 LR: 3.39e-06\n",
      "Epoch  31 [1250/10697 ( 11.7%)] Loss: 0.027002 L1: 0.015811 Grad: 0.111670 Thermal: 0.000486 LR: 3.39e-06\n",
      "Epoch  31 [1250/10697 ( 11.7%)] Loss: 0.027002 L1: 0.015811 Grad: 0.111670 Thermal: 0.000486 LR: 3.39e-06\n",
      "Epoch  31 [1300/10697 ( 12.2%)] Loss: 0.028058 L1: 0.016574 Grad: 0.114599 Thermal: 0.000472 LR: 3.39e-06\n",
      "Epoch  31 [1300/10697 ( 12.2%)] Loss: 0.028058 L1: 0.016574 Grad: 0.114599 Thermal: 0.000472 LR: 3.39e-06\n",
      "Epoch  31 [1350/10697 ( 12.6%)] Loss: 0.032258 L1: 0.018955 Grad: 0.132669 Thermal: 0.000730 LR: 3.39e-06\n",
      "Epoch  31 [1350/10697 ( 12.6%)] Loss: 0.032258 L1: 0.018955 Grad: 0.132669 Thermal: 0.000730 LR: 3.39e-06\n",
      "Epoch  31 [1400/10697 ( 13.1%)] Loss: 0.027337 L1: 0.015706 Grad: 0.116097 Thermal: 0.000434 LR: 3.39e-06\n",
      "Epoch  31 [1400/10697 ( 13.1%)] Loss: 0.027337 L1: 0.015706 Grad: 0.116097 Thermal: 0.000434 LR: 3.39e-06\n",
      "Epoch  31 [1450/10697 ( 13.6%)] Loss: 0.026920 L1: 0.015660 Grad: 0.112375 Thermal: 0.000449 LR: 3.39e-06\n",
      "Epoch  31 [1450/10697 ( 13.6%)] Loss: 0.026920 L1: 0.015660 Grad: 0.112375 Thermal: 0.000449 LR: 3.39e-06\n",
      "Epoch  31 [1500/10697 ( 14.0%)] Loss: 0.030299 L1: 0.017084 Grad: 0.131791 Thermal: 0.000713 LR: 3.39e-06\n",
      "Epoch  31 [1500/10697 ( 14.0%)] Loss: 0.030299 L1: 0.017084 Grad: 0.131791 Thermal: 0.000713 LR: 3.39e-06\n",
      "Epoch  31 [1550/10697 ( 14.5%)] Loss: 0.026610 L1: 0.016165 Grad: 0.104216 Thermal: 0.000470 LR: 3.39e-06\n",
      "Epoch  31 [1550/10697 ( 14.5%)] Loss: 0.026610 L1: 0.016165 Grad: 0.104216 Thermal: 0.000470 LR: 3.39e-06\n",
      "Epoch  31 [1600/10697 ( 15.0%)] Loss: 0.026219 L1: 0.015804 Grad: 0.103925 Thermal: 0.000450 LR: 3.39e-06\n",
      "Epoch  31 [1600/10697 ( 15.0%)] Loss: 0.026219 L1: 0.015804 Grad: 0.103925 Thermal: 0.000450 LR: 3.39e-06\n",
      "Epoch  31 [1650/10697 ( 15.4%)] Loss: 0.027301 L1: 0.015341 Grad: 0.119357 Thermal: 0.000481 LR: 3.39e-06\n",
      "Epoch  31 [1650/10697 ( 15.4%)] Loss: 0.027301 L1: 0.015341 Grad: 0.119357 Thermal: 0.000481 LR: 3.39e-06\n",
      "Epoch  31 [1700/10697 ( 15.9%)] Loss: 0.021958 L1: 0.012814 Grad: 0.091276 Thermal: 0.000324 LR: 3.39e-06\n",
      "Epoch  31 [1700/10697 ( 15.9%)] Loss: 0.021958 L1: 0.012814 Grad: 0.091276 Thermal: 0.000324 LR: 3.39e-06\n",
      "Epoch  31 [1750/10697 ( 16.4%)] Loss: 0.020857 L1: 0.012413 Grad: 0.084284 Thermal: 0.000319 LR: 3.39e-06\n",
      "Epoch  31 [1750/10697 ( 16.4%)] Loss: 0.020857 L1: 0.012413 Grad: 0.084284 Thermal: 0.000319 LR: 3.39e-06\n",
      "Epoch  31 [1800/10697 ( 16.8%)] Loss: 0.026121 L1: 0.015195 Grad: 0.109049 Thermal: 0.000435 LR: 3.39e-06\n",
      "Epoch  31 [1800/10697 ( 16.8%)] Loss: 0.026121 L1: 0.015195 Grad: 0.109049 Thermal: 0.000435 LR: 3.39e-06\n",
      "Epoch  31 [1850/10697 ( 17.3%)] Loss: 0.023570 L1: 0.013638 Grad: 0.099121 Thermal: 0.000388 LR: 3.39e-06\n",
      "Epoch  31 [1850/10697 ( 17.3%)] Loss: 0.023570 L1: 0.013638 Grad: 0.099121 Thermal: 0.000388 LR: 3.39e-06\n",
      "Epoch  31 [1900/10697 ( 17.8%)] Loss: 0.021117 L1: 0.012296 Grad: 0.088063 Thermal: 0.000307 LR: 3.39e-06\n",
      "Epoch  31 [1900/10697 ( 17.8%)] Loss: 0.021117 L1: 0.012296 Grad: 0.088063 Thermal: 0.000307 LR: 3.39e-06\n",
      "Epoch  31 [1950/10697 ( 18.2%)] Loss: 0.020905 L1: 0.012043 Grad: 0.088477 Thermal: 0.000294 LR: 3.39e-06\n",
      "Epoch  31 [1950/10697 ( 18.2%)] Loss: 0.020905 L1: 0.012043 Grad: 0.088477 Thermal: 0.000294 LR: 3.39e-06\n",
      "Epoch  31 [2000/10697 ( 18.7%)] Loss: 0.021440 L1: 0.012482 Grad: 0.089431 Thermal: 0.000306 LR: 3.39e-06\n",
      "Epoch  31 [2000/10697 ( 18.7%)] Loss: 0.021440 L1: 0.012482 Grad: 0.089431 Thermal: 0.000306 LR: 3.39e-06\n",
      "Epoch  31 [2050/10697 ( 19.2%)] Loss: 0.028147 L1: 0.016374 Grad: 0.117473 Thermal: 0.000510 LR: 3.39e-06\n",
      "Epoch  31 [2050/10697 ( 19.2%)] Loss: 0.028147 L1: 0.016374 Grad: 0.117473 Thermal: 0.000510 LR: 3.39e-06\n",
      "Epoch  31 [2100/10697 ( 19.6%)] Loss: 0.022834 L1: 0.013217 Grad: 0.095980 Thermal: 0.000382 LR: 3.39e-06\n",
      "Epoch  31 [2100/10697 ( 19.6%)] Loss: 0.022834 L1: 0.013217 Grad: 0.095980 Thermal: 0.000382 LR: 3.39e-06\n",
      "Epoch  31 [2150/10697 ( 20.1%)] Loss: 0.025828 L1: 0.014437 Grad: 0.113665 Thermal: 0.000501 LR: 3.39e-06\n",
      "Epoch  31 [2150/10697 ( 20.1%)] Loss: 0.025828 L1: 0.014437 Grad: 0.113665 Thermal: 0.000501 LR: 3.39e-06\n",
      "Epoch  31 [2200/10697 ( 20.6%)] Loss: 0.031499 L1: 0.018462 Grad: 0.130034 Thermal: 0.000671 LR: 3.39e-06\n",
      "Epoch  31 [2200/10697 ( 20.6%)] Loss: 0.031499 L1: 0.018462 Grad: 0.130034 Thermal: 0.000671 LR: 3.39e-06\n",
      "Epoch  31 [2250/10697 ( 21.0%)] Loss: 0.027359 L1: 0.015981 Grad: 0.113487 Thermal: 0.000574 LR: 3.39e-06\n",
      "Epoch  31 [2250/10697 ( 21.0%)] Loss: 0.027359 L1: 0.015981 Grad: 0.113487 Thermal: 0.000574 LR: 3.39e-06\n",
      "Epoch  31 [2300/10697 ( 21.5%)] Loss: 0.021907 L1: 0.012430 Grad: 0.094639 Thermal: 0.000267 LR: 3.39e-06\n",
      "Epoch  31 [2300/10697 ( 21.5%)] Loss: 0.021907 L1: 0.012430 Grad: 0.094639 Thermal: 0.000267 LR: 3.39e-06\n",
      "Epoch  31 [2350/10697 ( 22.0%)] Loss: 0.028453 L1: 0.016715 Grad: 0.117119 Thermal: 0.000520 LR: 3.39e-06\n",
      "Epoch  31 [2350/10697 ( 22.0%)] Loss: 0.028453 L1: 0.016715 Grad: 0.117119 Thermal: 0.000520 LR: 3.39e-06\n",
      "Epoch  31 [2400/10697 ( 22.4%)] Loss: 0.022979 L1: 0.013177 Grad: 0.097847 Thermal: 0.000337 LR: 3.39e-06\n",
      "Epoch  31 [2400/10697 ( 22.4%)] Loss: 0.022979 L1: 0.013177 Grad: 0.097847 Thermal: 0.000337 LR: 3.39e-06\n",
      "Epoch  31 [2450/10697 ( 22.9%)] Loss: 0.029008 L1: 0.017016 Grad: 0.119658 Thermal: 0.000527 LR: 3.39e-06\n",
      "Epoch  31 [2450/10697 ( 22.9%)] Loss: 0.029008 L1: 0.017016 Grad: 0.119658 Thermal: 0.000527 LR: 3.39e-06\n",
      "Epoch  31 [2500/10697 ( 23.4%)] Loss: 0.028937 L1: 0.016915 Grad: 0.119955 Thermal: 0.000534 LR: 3.39e-06\n",
      "Epoch  31 [2500/10697 ( 23.4%)] Loss: 0.028937 L1: 0.016915 Grad: 0.119955 Thermal: 0.000534 LR: 3.39e-06\n",
      "Epoch  31 [2550/10697 ( 23.8%)] Loss: 0.026916 L1: 0.015860 Grad: 0.110333 Thermal: 0.000456 LR: 3.39e-06\n",
      "Epoch  31 [2550/10697 ( 23.8%)] Loss: 0.026916 L1: 0.015860 Grad: 0.110333 Thermal: 0.000456 LR: 3.39e-06\n",
      "Epoch  31 [2600/10697 ( 24.3%)] Loss: 0.022152 L1: 0.013082 Grad: 0.090538 Thermal: 0.000334 LR: 3.39e-06\n",
      "Epoch  31 [2600/10697 ( 24.3%)] Loss: 0.022152 L1: 0.013082 Grad: 0.090538 Thermal: 0.000334 LR: 3.39e-06\n",
      "Epoch  31 [2650/10697 ( 24.8%)] Loss: 0.030513 L1: 0.017727 Grad: 0.127575 Thermal: 0.000577 LR: 3.39e-06\n",
      "Epoch  31 [2650/10697 ( 24.8%)] Loss: 0.030513 L1: 0.017727 Grad: 0.127575 Thermal: 0.000577 LR: 3.39e-06\n",
      "Epoch  31 [2700/10697 ( 25.2%)] Loss: 0.027866 L1: 0.015753 Grad: 0.120880 Thermal: 0.000499 LR: 3.39e-06\n",
      "Epoch  31 [2700/10697 ( 25.2%)] Loss: 0.027866 L1: 0.015753 Grad: 0.120880 Thermal: 0.000499 LR: 3.39e-06\n",
      "Epoch  31 [2750/10697 ( 25.7%)] Loss: 0.023933 L1: 0.014131 Grad: 0.097833 Thermal: 0.000371 LR: 3.39e-06\n",
      "Epoch  31 [2750/10697 ( 25.7%)] Loss: 0.023933 L1: 0.014131 Grad: 0.097833 Thermal: 0.000371 LR: 3.39e-06\n",
      "Epoch  31 [2800/10697 ( 26.2%)] Loss: 0.024416 L1: 0.014189 Grad: 0.102058 Thermal: 0.000411 LR: 3.39e-06\n",
      "Epoch  31 [2800/10697 ( 26.2%)] Loss: 0.024416 L1: 0.014189 Grad: 0.102058 Thermal: 0.000411 LR: 3.39e-06\n",
      "Epoch  31 [2850/10697 ( 26.6%)] Loss: 0.022256 L1: 0.013089 Grad: 0.091498 Thermal: 0.000339 LR: 3.39e-06\n",
      "Epoch  31 [2850/10697 ( 26.6%)] Loss: 0.022256 L1: 0.013089 Grad: 0.091498 Thermal: 0.000339 LR: 3.39e-06\n",
      "Epoch  31 [2900/10697 ( 27.1%)] Loss: 0.031910 L1: 0.018454 Grad: 0.134228 Thermal: 0.000651 LR: 3.39e-06\n",
      "Epoch  31 [2900/10697 ( 27.1%)] Loss: 0.031910 L1: 0.018454 Grad: 0.134228 Thermal: 0.000651 LR: 3.39e-06\n",
      "Epoch  31 [2950/10697 ( 27.6%)] Loss: 0.032006 L1: 0.018244 Grad: 0.137344 Thermal: 0.000556 LR: 3.39e-06\n",
      "Epoch  31 [2950/10697 ( 27.6%)] Loss: 0.032006 L1: 0.018244 Grad: 0.137344 Thermal: 0.000556 LR: 3.39e-06\n",
      "Epoch  31 [3000/10697 ( 28.0%)] Loss: 0.027164 L1: 0.016107 Grad: 0.110334 Thermal: 0.000466 LR: 3.39e-06\n",
      "Epoch  31 [3000/10697 ( 28.0%)] Loss: 0.027164 L1: 0.016107 Grad: 0.110334 Thermal: 0.000466 LR: 3.39e-06\n",
      "Epoch  31 [3050/10697 ( 28.5%)] Loss: 0.025274 L1: 0.015088 Grad: 0.101664 Thermal: 0.000405 LR: 3.39e-06\n",
      "Epoch  31 [3050/10697 ( 28.5%)] Loss: 0.025274 L1: 0.015088 Grad: 0.101664 Thermal: 0.000405 LR: 3.39e-06\n",
      "Epoch  31 [3100/10697 ( 29.0%)] Loss: 0.024099 L1: 0.014228 Grad: 0.098525 Thermal: 0.000376 LR: 3.39e-06\n",
      "Epoch  31 [3100/10697 ( 29.0%)] Loss: 0.024099 L1: 0.014228 Grad: 0.098525 Thermal: 0.000376 LR: 3.39e-06\n",
      "Epoch  31 [3150/10697 ( 29.4%)] Loss: 0.031672 L1: 0.017923 Grad: 0.137098 Thermal: 0.000786 LR: 3.39e-06\n",
      "Epoch  31 [3150/10697 ( 29.4%)] Loss: 0.031672 L1: 0.017923 Grad: 0.137098 Thermal: 0.000786 LR: 3.39e-06\n",
      "Epoch  31 [3200/10697 ( 29.9%)] Loss: 0.027595 L1: 0.015931 Grad: 0.116380 Thermal: 0.000526 LR: 3.39e-06\n",
      "Epoch  31 [3200/10697 ( 29.9%)] Loss: 0.027595 L1: 0.015931 Grad: 0.116380 Thermal: 0.000526 LR: 3.39e-06\n",
      "Epoch  31 [3250/10697 ( 30.4%)] Loss: 0.028197 L1: 0.016622 Grad: 0.115503 Thermal: 0.000505 LR: 3.39e-06\n",
      "Epoch  31 [3250/10697 ( 30.4%)] Loss: 0.028197 L1: 0.016622 Grad: 0.115503 Thermal: 0.000505 LR: 3.39e-06\n",
      "Epoch  31 [3300/10697 ( 30.8%)] Loss: 0.025504 L1: 0.014948 Grad: 0.105350 Thermal: 0.000423 LR: 3.39e-06\n",
      "Epoch  31 [3300/10697 ( 30.8%)] Loss: 0.025504 L1: 0.014948 Grad: 0.105350 Thermal: 0.000423 LR: 3.39e-06\n",
      "Epoch  31 [3350/10697 ( 31.3%)] Loss: 0.026364 L1: 0.015516 Grad: 0.108258 Thermal: 0.000430 LR: 3.39e-06\n",
      "Epoch  31 [3350/10697 ( 31.3%)] Loss: 0.026364 L1: 0.015516 Grad: 0.108258 Thermal: 0.000430 LR: 3.39e-06\n",
      "Epoch  31 [3400/10697 ( 31.8%)] Loss: 0.028002 L1: 0.016402 Grad: 0.115713 Thermal: 0.000554 LR: 3.39e-06\n",
      "Epoch  31 [3400/10697 ( 31.8%)] Loss: 0.028002 L1: 0.016402 Grad: 0.115713 Thermal: 0.000554 LR: 3.39e-06\n",
      "Epoch  31 [3450/10697 ( 32.3%)] Loss: 0.034193 L1: 0.019770 Grad: 0.143869 Thermal: 0.000736 LR: 3.39e-06\n",
      "Epoch  31 [3450/10697 ( 32.3%)] Loss: 0.034193 L1: 0.019770 Grad: 0.143869 Thermal: 0.000736 LR: 3.39e-06\n",
      "Epoch  31 [3500/10697 ( 32.7%)] Loss: 0.026044 L1: 0.015503 Grad: 0.105182 Thermal: 0.000446 LR: 3.39e-06\n",
      "Epoch  31 [3500/10697 ( 32.7%)] Loss: 0.026044 L1: 0.015503 Grad: 0.105182 Thermal: 0.000446 LR: 3.39e-06\n",
      "Epoch  31 [3550/10697 ( 33.2%)] Loss: 0.024944 L1: 0.014621 Grad: 0.103020 Thermal: 0.000408 LR: 3.39e-06\n",
      "Epoch  31 [3550/10697 ( 33.2%)] Loss: 0.024944 L1: 0.014621 Grad: 0.103020 Thermal: 0.000408 LR: 3.39e-06\n",
      "Epoch  31 [3600/10697 ( 33.7%)] Loss: 0.026685 L1: 0.015805 Grad: 0.108569 Thermal: 0.000457 LR: 3.39e-06\n",
      "Epoch  31 [3600/10697 ( 33.7%)] Loss: 0.026685 L1: 0.015805 Grad: 0.108569 Thermal: 0.000457 LR: 3.39e-06\n",
      "Epoch  31 [3650/10697 ( 34.1%)] Loss: 0.023815 L1: 0.013588 Grad: 0.102072 Thermal: 0.000396 LR: 3.39e-06\n",
      "Epoch  31 [3650/10697 ( 34.1%)] Loss: 0.023815 L1: 0.013588 Grad: 0.102072 Thermal: 0.000396 LR: 3.39e-06\n",
      "Epoch  31 [3700/10697 ( 34.6%)] Loss: 0.025743 L1: 0.014641 Grad: 0.110786 Thermal: 0.000458 LR: 3.39e-06\n",
      "Epoch  31 [3700/10697 ( 34.6%)] Loss: 0.025743 L1: 0.014641 Grad: 0.110786 Thermal: 0.000458 LR: 3.39e-06\n",
      "Epoch  31 [3750/10697 ( 35.1%)] Loss: 0.027498 L1: 0.016275 Grad: 0.111998 Thermal: 0.000467 LR: 3.39e-06\n",
      "Epoch  31 [3750/10697 ( 35.1%)] Loss: 0.027498 L1: 0.016275 Grad: 0.111998 Thermal: 0.000467 LR: 3.39e-06\n",
      "Epoch  31 [3800/10697 ( 35.5%)] Loss: 0.030733 L1: 0.017948 Grad: 0.127542 Thermal: 0.000598 LR: 3.39e-06\n",
      "Epoch  31 [3800/10697 ( 35.5%)] Loss: 0.030733 L1: 0.017948 Grad: 0.127542 Thermal: 0.000598 LR: 3.39e-06\n",
      "Epoch  31 [3850/10697 ( 36.0%)] Loss: 0.040381 L1: 0.023001 Grad: 0.173336 Thermal: 0.000926 LR: 3.39e-06\n",
      "Epoch  31 [3850/10697 ( 36.0%)] Loss: 0.040381 L1: 0.023001 Grad: 0.173336 Thermal: 0.000926 LR: 3.39e-06\n",
      "Epoch  31 [3900/10697 ( 36.5%)] Loss: 0.024242 L1: 0.014095 Grad: 0.101281 Thermal: 0.000390 LR: 3.39e-06\n",
      "Epoch  31 [3900/10697 ( 36.5%)] Loss: 0.024242 L1: 0.014095 Grad: 0.101281 Thermal: 0.000390 LR: 3.39e-06\n",
      "Epoch  31 [3950/10697 ( 36.9%)] Loss: 0.025906 L1: 0.015153 Grad: 0.107328 Thermal: 0.000407 LR: 3.39e-06\n",
      "Epoch  31 [3950/10697 ( 36.9%)] Loss: 0.025906 L1: 0.015153 Grad: 0.107328 Thermal: 0.000407 LR: 3.39e-06\n",
      "Epoch  31 [4000/10697 ( 37.4%)] Loss: 0.023285 L1: 0.012965 Grad: 0.103018 Thermal: 0.000366 LR: 3.39e-06\n",
      "Epoch  31 [4000/10697 ( 37.4%)] Loss: 0.023285 L1: 0.012965 Grad: 0.103018 Thermal: 0.000366 LR: 3.39e-06\n",
      "Epoch  31 [4050/10697 ( 37.9%)] Loss: 0.024659 L1: 0.014398 Grad: 0.102410 Thermal: 0.000414 LR: 3.39e-06\n",
      "Epoch  31 [4050/10697 ( 37.9%)] Loss: 0.024659 L1: 0.014398 Grad: 0.102410 Thermal: 0.000414 LR: 3.39e-06\n",
      "Epoch  31 [4100/10697 ( 38.3%)] Loss: 0.023484 L1: 0.013626 Grad: 0.098406 Thermal: 0.000345 LR: 3.39e-06\n",
      "Epoch  31 [4100/10697 ( 38.3%)] Loss: 0.023484 L1: 0.013626 Grad: 0.098406 Thermal: 0.000345 LR: 3.39e-06\n",
      "Epoch  31 [4150/10697 ( 38.8%)] Loss: 0.019668 L1: 0.011382 Grad: 0.082719 Thermal: 0.000273 LR: 3.39e-06\n",
      "Epoch  31 [4150/10697 ( 38.8%)] Loss: 0.019668 L1: 0.011382 Grad: 0.082719 Thermal: 0.000273 LR: 3.39e-06\n",
      "Epoch  31 [4200/10697 ( 39.3%)] Loss: 0.024553 L1: 0.014407 Grad: 0.101256 Thermal: 0.000395 LR: 3.39e-06\n",
      "Epoch  31 [4200/10697 ( 39.3%)] Loss: 0.024553 L1: 0.014407 Grad: 0.101256 Thermal: 0.000395 LR: 3.39e-06\n",
      "Epoch  31 [4250/10697 ( 39.7%)] Loss: 0.029110 L1: 0.016960 Grad: 0.121242 Thermal: 0.000515 LR: 3.39e-06\n",
      "Epoch  31 [4250/10697 ( 39.7%)] Loss: 0.029110 L1: 0.016960 Grad: 0.121242 Thermal: 0.000515 LR: 3.39e-06\n",
      "Epoch  31 [4300/10697 ( 40.2%)] Loss: 0.028615 L1: 0.016837 Grad: 0.117526 Thermal: 0.000509 LR: 3.39e-06\n",
      "Epoch  31 [4300/10697 ( 40.2%)] Loss: 0.028615 L1: 0.016837 Grad: 0.117526 Thermal: 0.000509 LR: 3.39e-06\n",
      "Epoch  31 [4350/10697 ( 40.7%)] Loss: 0.024020 L1: 0.013615 Grad: 0.103819 Thermal: 0.000454 LR: 3.39e-06\n",
      "Epoch  31 [4350/10697 ( 40.7%)] Loss: 0.024020 L1: 0.013615 Grad: 0.103819 Thermal: 0.000454 LR: 3.39e-06\n",
      "Epoch  31 [4400/10697 ( 41.1%)] Loss: 0.026152 L1: 0.015073 Grad: 0.110562 Thermal: 0.000466 LR: 3.39e-06\n",
      "Epoch  31 [4400/10697 ( 41.1%)] Loss: 0.026152 L1: 0.015073 Grad: 0.110562 Thermal: 0.000466 LR: 3.39e-06\n",
      "Epoch  31 [4450/10697 ( 41.6%)] Loss: 0.024421 L1: 0.014012 Grad: 0.103906 Thermal: 0.000357 LR: 3.39e-06\n",
      "Epoch  31 [4450/10697 ( 41.6%)] Loss: 0.024421 L1: 0.014012 Grad: 0.103906 Thermal: 0.000357 LR: 3.39e-06\n",
      "Epoch  31 [4500/10697 ( 42.1%)] Loss: 0.030107 L1: 0.017553 Grad: 0.125240 Thermal: 0.000599 LR: 3.39e-06\n",
      "Epoch  31 [4500/10697 ( 42.1%)] Loss: 0.030107 L1: 0.017553 Grad: 0.125240 Thermal: 0.000599 LR: 3.39e-06\n",
      "Epoch  31 [4550/10697 ( 42.5%)] Loss: 0.022620 L1: 0.013229 Grad: 0.093745 Thermal: 0.000325 LR: 3.39e-06\n",
      "Epoch  31 [4550/10697 ( 42.5%)] Loss: 0.022620 L1: 0.013229 Grad: 0.093745 Thermal: 0.000325 LR: 3.39e-06\n",
      "Epoch  31 [4600/10697 ( 43.0%)] Loss: 0.025550 L1: 0.014800 Grad: 0.107282 Thermal: 0.000451 LR: 3.39e-06\n",
      "Epoch  31 [4600/10697 ( 43.0%)] Loss: 0.025550 L1: 0.014800 Grad: 0.107282 Thermal: 0.000451 LR: 3.39e-06\n",
      "Epoch  31 [4650/10697 ( 43.5%)] Loss: 0.028459 L1: 0.017069 Grad: 0.113620 Thermal: 0.000561 LR: 3.39e-06\n",
      "Epoch  31 [4650/10697 ( 43.5%)] Loss: 0.028459 L1: 0.017069 Grad: 0.113620 Thermal: 0.000561 LR: 3.39e-06\n",
      "Epoch  31 [4700/10697 ( 43.9%)] Loss: 0.023350 L1: 0.013800 Grad: 0.095301 Thermal: 0.000388 LR: 3.39e-06\n",
      "Epoch  31 [4700/10697 ( 43.9%)] Loss: 0.023350 L1: 0.013800 Grad: 0.095301 Thermal: 0.000388 LR: 3.39e-06\n",
      "Epoch  31 [4750/10697 ( 44.4%)] Loss: 0.020114 L1: 0.011561 Grad: 0.085377 Thermal: 0.000301 LR: 3.39e-06\n",
      "Epoch  31 [4750/10697 ( 44.4%)] Loss: 0.020114 L1: 0.011561 Grad: 0.085377 Thermal: 0.000301 LR: 3.39e-06\n",
      "Epoch  31 [4800/10697 ( 44.9%)] Loss: 0.028114 L1: 0.016524 Grad: 0.115657 Thermal: 0.000496 LR: 3.39e-06\n",
      "Epoch  31 [4800/10697 ( 44.9%)] Loss: 0.028114 L1: 0.016524 Grad: 0.115657 Thermal: 0.000496 LR: 3.39e-06\n",
      "Epoch  31 [4850/10697 ( 45.3%)] Loss: 0.024158 L1: 0.014021 Grad: 0.101137 Thermal: 0.000467 LR: 3.39e-06\n",
      "Epoch  31 [4850/10697 ( 45.3%)] Loss: 0.024158 L1: 0.014021 Grad: 0.101137 Thermal: 0.000467 LR: 3.39e-06\n",
      "Epoch  31 [4900/10697 ( 45.8%)] Loss: 0.027862 L1: 0.016308 Grad: 0.115297 Thermal: 0.000485 LR: 3.39e-06\n",
      "Epoch  31 [4900/10697 ( 45.8%)] Loss: 0.027862 L1: 0.016308 Grad: 0.115297 Thermal: 0.000485 LR: 3.39e-06\n",
      "Epoch  31 [4950/10697 ( 46.3%)] Loss: 0.026891 L1: 0.015726 Grad: 0.111417 Thermal: 0.000467 LR: 3.39e-06\n",
      "Epoch  31 [4950/10697 ( 46.3%)] Loss: 0.026891 L1: 0.015726 Grad: 0.111417 Thermal: 0.000467 LR: 3.39e-06\n",
      "Epoch  31 [5000/10697 ( 46.7%)] Loss: 0.027306 L1: 0.015863 Grad: 0.114188 Thermal: 0.000481 LR: 3.39e-06\n",
      "Epoch  31 [5000/10697 ( 46.7%)] Loss: 0.027306 L1: 0.015863 Grad: 0.114188 Thermal: 0.000481 LR: 3.39e-06\n",
      "Epoch  31 [5050/10697 ( 47.2%)] Loss: 0.026163 L1: 0.014996 Grad: 0.111457 Thermal: 0.000429 LR: 3.39e-06\n",
      "Epoch  31 [5050/10697 ( 47.2%)] Loss: 0.026163 L1: 0.014996 Grad: 0.111457 Thermal: 0.000429 LR: 3.39e-06\n",
      "Epoch  31 [5100/10697 ( 47.7%)] Loss: 0.026958 L1: 0.016042 Grad: 0.108930 Thermal: 0.000470 LR: 3.39e-06\n",
      "Epoch  31 [5100/10697 ( 47.7%)] Loss: 0.026958 L1: 0.016042 Grad: 0.108930 Thermal: 0.000470 LR: 3.39e-06\n",
      "Epoch  31 [5150/10697 ( 48.1%)] Loss: 0.021378 L1: 0.012454 Grad: 0.089096 Thermal: 0.000303 LR: 3.39e-06\n",
      "Epoch  31 [5150/10697 ( 48.1%)] Loss: 0.021378 L1: 0.012454 Grad: 0.089096 Thermal: 0.000303 LR: 3.39e-06\n",
      "Epoch  31 [5200/10697 ( 48.6%)] Loss: 0.024088 L1: 0.014279 Grad: 0.097907 Thermal: 0.000372 LR: 3.39e-06\n",
      "Epoch  31 [5200/10697 ( 48.6%)] Loss: 0.024088 L1: 0.014279 Grad: 0.097907 Thermal: 0.000372 LR: 3.39e-06\n",
      "Epoch  31 [5250/10697 ( 49.1%)] Loss: 0.023088 L1: 0.013525 Grad: 0.095436 Thermal: 0.000385 LR: 3.39e-06\n",
      "Epoch  31 [5250/10697 ( 49.1%)] Loss: 0.023088 L1: 0.013525 Grad: 0.095436 Thermal: 0.000385 LR: 3.39e-06\n",
      "Epoch  31 [5300/10697 ( 49.5%)] Loss: 0.023146 L1: 0.012989 Grad: 0.101391 Thermal: 0.000354 LR: 3.39e-06\n",
      "Epoch  31 [5300/10697 ( 49.5%)] Loss: 0.023146 L1: 0.012989 Grad: 0.101391 Thermal: 0.000354 LR: 3.39e-06\n",
      "Epoch  31 [5350/10697 ( 50.0%)] Loss: 0.025085 L1: 0.014781 Grad: 0.102834 Thermal: 0.000412 LR: 3.39e-06\n",
      "Epoch  31 [5350/10697 ( 50.0%)] Loss: 0.025085 L1: 0.014781 Grad: 0.102834 Thermal: 0.000412 LR: 3.39e-06\n",
      "Epoch  31 [5400/10697 ( 50.5%)] Loss: 0.023438 L1: 0.014017 Grad: 0.094013 Thermal: 0.000379 LR: 3.39e-06\n",
      "Epoch  31 [5400/10697 ( 50.5%)] Loss: 0.023438 L1: 0.014017 Grad: 0.094013 Thermal: 0.000379 LR: 3.39e-06\n",
      "Epoch  31 [5450/10697 ( 50.9%)] Loss: 0.027218 L1: 0.016109 Grad: 0.110848 Thermal: 0.000475 LR: 3.39e-06\n",
      "Epoch  31 [5450/10697 ( 50.9%)] Loss: 0.027218 L1: 0.016109 Grad: 0.110848 Thermal: 0.000475 LR: 3.39e-06\n",
      "Epoch  31 [5500/10697 ( 51.4%)] Loss: 0.029873 L1: 0.017474 Grad: 0.123705 Thermal: 0.000564 LR: 3.39e-06\n",
      "Epoch  31 [5500/10697 ( 51.4%)] Loss: 0.029873 L1: 0.017474 Grad: 0.123705 Thermal: 0.000564 LR: 3.39e-06\n",
      "Epoch  31 [5550/10697 ( 51.9%)] Loss: 0.027106 L1: 0.015754 Grad: 0.113275 Thermal: 0.000474 LR: 3.39e-06\n",
      "Epoch  31 [5550/10697 ( 51.9%)] Loss: 0.027106 L1: 0.015754 Grad: 0.113275 Thermal: 0.000474 LR: 3.39e-06\n",
      "Epoch  31 [5600/10697 ( 52.4%)] Loss: 0.024618 L1: 0.014582 Grad: 0.100161 Thermal: 0.000399 LR: 3.39e-06\n",
      "Epoch  31 [5600/10697 ( 52.4%)] Loss: 0.024618 L1: 0.014582 Grad: 0.100161 Thermal: 0.000399 LR: 3.39e-06\n",
      "Epoch  31 [5650/10697 ( 52.8%)] Loss: 0.025473 L1: 0.014621 Grad: 0.108314 Thermal: 0.000413 LR: 3.39e-06\n",
      "Epoch  31 [5650/10697 ( 52.8%)] Loss: 0.025473 L1: 0.014621 Grad: 0.108314 Thermal: 0.000413 LR: 3.39e-06\n",
      "Epoch  31 [5700/10697 ( 53.3%)] Loss: 0.027859 L1: 0.016474 Grad: 0.113612 Thermal: 0.000487 LR: 3.39e-06\n",
      "Epoch  31 [5700/10697 ( 53.3%)] Loss: 0.027859 L1: 0.016474 Grad: 0.113612 Thermal: 0.000487 LR: 3.39e-06\n",
      "Epoch  31 [5750/10697 ( 53.8%)] Loss: 0.023798 L1: 0.013679 Grad: 0.101000 Thermal: 0.000371 LR: 3.39e-06\n",
      "Epoch  31 [5750/10697 ( 53.8%)] Loss: 0.023798 L1: 0.013679 Grad: 0.101000 Thermal: 0.000371 LR: 3.39e-06\n",
      "Epoch  31 [5800/10697 ( 54.2%)] Loss: 0.023290 L1: 0.013958 Grad: 0.093126 Thermal: 0.000382 LR: 3.39e-06\n",
      "Epoch  31 [5800/10697 ( 54.2%)] Loss: 0.023290 L1: 0.013958 Grad: 0.093126 Thermal: 0.000382 LR: 3.39e-06\n",
      "Epoch  31 [5850/10697 ( 54.7%)] Loss: 0.026538 L1: 0.015879 Grad: 0.106357 Thermal: 0.000459 LR: 3.39e-06\n",
      "Epoch  31 [5850/10697 ( 54.7%)] Loss: 0.026538 L1: 0.015879 Grad: 0.106357 Thermal: 0.000459 LR: 3.39e-06\n",
      "Epoch  31 [5900/10697 ( 55.2%)] Loss: 0.022064 L1: 0.012892 Grad: 0.091554 Thermal: 0.000323 LR: 3.39e-06\n",
      "Epoch  31 [5900/10697 ( 55.2%)] Loss: 0.022064 L1: 0.012892 Grad: 0.091554 Thermal: 0.000323 LR: 3.39e-06\n",
      "Epoch  31 [5950/10697 ( 55.6%)] Loss: 0.023924 L1: 0.013967 Grad: 0.099374 Thermal: 0.000381 LR: 3.39e-06\n",
      "Epoch  31 [5950/10697 ( 55.6%)] Loss: 0.023924 L1: 0.013967 Grad: 0.099374 Thermal: 0.000381 LR: 3.39e-06\n",
      "Epoch  31 [6000/10697 ( 56.1%)] Loss: 0.032583 L1: 0.018965 Grad: 0.135826 Thermal: 0.000695 LR: 3.39e-06\n",
      "Epoch  31 [6000/10697 ( 56.1%)] Loss: 0.032583 L1: 0.018965 Grad: 0.135826 Thermal: 0.000695 LR: 3.39e-06\n",
      "Epoch  31 [6050/10697 ( 56.6%)] Loss: 0.026105 L1: 0.015390 Grad: 0.106921 Thermal: 0.000458 LR: 3.39e-06\n",
      "Epoch  31 [6050/10697 ( 56.6%)] Loss: 0.026105 L1: 0.015390 Grad: 0.106921 Thermal: 0.000458 LR: 3.39e-06\n",
      "Epoch  31 [6100/10697 ( 57.0%)] Loss: 0.024509 L1: 0.014510 Grad: 0.099787 Thermal: 0.000401 LR: 3.39e-06\n",
      "Epoch  31 [6100/10697 ( 57.0%)] Loss: 0.024509 L1: 0.014510 Grad: 0.099787 Thermal: 0.000401 LR: 3.39e-06\n",
      "Epoch  31 [6150/10697 ( 57.5%)] Loss: 0.027326 L1: 0.016352 Grad: 0.109494 Thermal: 0.000481 LR: 3.39e-06\n",
      "Epoch  31 [6150/10697 ( 57.5%)] Loss: 0.027326 L1: 0.016352 Grad: 0.109494 Thermal: 0.000481 LR: 3.39e-06\n",
      "Epoch  31 [6200/10697 ( 58.0%)] Loss: 0.027430 L1: 0.016186 Grad: 0.112200 Thermal: 0.000485 LR: 3.39e-06\n",
      "Epoch  31 [6200/10697 ( 58.0%)] Loss: 0.027430 L1: 0.016186 Grad: 0.112200 Thermal: 0.000485 LR: 3.39e-06\n",
      "Epoch  31 [6250/10697 ( 58.4%)] Loss: 0.022795 L1: 0.013278 Grad: 0.094999 Thermal: 0.000335 LR: 3.39e-06\n",
      "Epoch  31 [6250/10697 ( 58.4%)] Loss: 0.022795 L1: 0.013278 Grad: 0.094999 Thermal: 0.000335 LR: 3.39e-06\n",
      "Epoch  31 [6300/10697 ( 58.9%)] Loss: 0.029043 L1: 0.017309 Grad: 0.117055 Thermal: 0.000570 LR: 3.39e-06\n",
      "Epoch  31 [6300/10697 ( 58.9%)] Loss: 0.029043 L1: 0.017309 Grad: 0.117055 Thermal: 0.000570 LR: 3.39e-06\n",
      "Epoch  31 [6350/10697 ( 59.4%)] Loss: 0.019656 L1: 0.011489 Grad: 0.081535 Thermal: 0.000278 LR: 3.39e-06\n",
      "Epoch  31 [6350/10697 ( 59.4%)] Loss: 0.019656 L1: 0.011489 Grad: 0.081535 Thermal: 0.000278 LR: 3.39e-06\n",
      "Epoch  31 [6400/10697 ( 59.8%)] Loss: 0.026429 L1: 0.015176 Grad: 0.112294 Thermal: 0.000468 LR: 3.39e-06\n",
      "Epoch  31 [6400/10697 ( 59.8%)] Loss: 0.026429 L1: 0.015176 Grad: 0.112294 Thermal: 0.000468 LR: 3.39e-06\n",
      "Epoch  31 [6450/10697 ( 60.3%)] Loss: 0.037911 L1: 0.022070 Grad: 0.157947 Thermal: 0.000931 LR: 3.39e-06\n",
      "Epoch  31 [6450/10697 ( 60.3%)] Loss: 0.037911 L1: 0.022070 Grad: 0.157947 Thermal: 0.000931 LR: 3.39e-06\n",
      "Epoch  31 [6500/10697 ( 60.8%)] Loss: 0.025482 L1: 0.014445 Grad: 0.110174 Thermal: 0.000390 LR: 3.39e-06\n",
      "Epoch  31 [6500/10697 ( 60.8%)] Loss: 0.025482 L1: 0.014445 Grad: 0.110174 Thermal: 0.000390 LR: 3.39e-06\n",
      "Epoch  31 [6550/10697 ( 61.2%)] Loss: 0.029097 L1: 0.017266 Grad: 0.118041 Thermal: 0.000541 LR: 3.39e-06\n",
      "Epoch  31 [6550/10697 ( 61.2%)] Loss: 0.029097 L1: 0.017266 Grad: 0.118041 Thermal: 0.000541 LR: 3.39e-06\n",
      "Epoch  31 [6600/10697 ( 61.7%)] Loss: 0.025992 L1: 0.014854 Grad: 0.111149 Thermal: 0.000461 LR: 3.39e-06\n",
      "Epoch  31 [6600/10697 ( 61.7%)] Loss: 0.025992 L1: 0.014854 Grad: 0.111149 Thermal: 0.000461 LR: 3.39e-06\n",
      "Epoch  31 [6650/10697 ( 62.2%)] Loss: 0.019008 L1: 0.011183 Grad: 0.078130 Thermal: 0.000246 LR: 3.39e-06\n",
      "Epoch  31 [6650/10697 ( 62.2%)] Loss: 0.019008 L1: 0.011183 Grad: 0.078130 Thermal: 0.000246 LR: 3.39e-06\n",
      "Epoch  31 [6700/10697 ( 62.6%)] Loss: 0.028971 L1: 0.016403 Grad: 0.125406 Thermal: 0.000557 LR: 3.39e-06\n",
      "Epoch  31 [6700/10697 ( 62.6%)] Loss: 0.028971 L1: 0.016403 Grad: 0.125406 Thermal: 0.000557 LR: 3.39e-06\n",
      "Epoch  31 [6750/10697 ( 63.1%)] Loss: 0.030686 L1: 0.018035 Grad: 0.126220 Thermal: 0.000585 LR: 3.39e-06\n",
      "Epoch  31 [6750/10697 ( 63.1%)] Loss: 0.030686 L1: 0.018035 Grad: 0.126220 Thermal: 0.000585 LR: 3.39e-06\n",
      "Epoch  31 [6800/10697 ( 63.6%)] Loss: 0.027617 L1: 0.016185 Grad: 0.114095 Thermal: 0.000455 LR: 3.39e-06\n",
      "Epoch  31 [6800/10697 ( 63.6%)] Loss: 0.027617 L1: 0.016185 Grad: 0.114095 Thermal: 0.000455 LR: 3.39e-06\n",
      "Epoch  31 [6850/10697 ( 64.0%)] Loss: 0.026769 L1: 0.015845 Grad: 0.109011 Thermal: 0.000466 LR: 3.39e-06\n",
      "Epoch  31 [6850/10697 ( 64.0%)] Loss: 0.026769 L1: 0.015845 Grad: 0.109011 Thermal: 0.000466 LR: 3.39e-06\n",
      "Epoch  31 [6900/10697 ( 64.5%)] Loss: 0.024695 L1: 0.014335 Grad: 0.103412 Thermal: 0.000376 LR: 3.39e-06\n",
      "Epoch  31 [6900/10697 ( 64.5%)] Loss: 0.024695 L1: 0.014335 Grad: 0.103412 Thermal: 0.000376 LR: 3.39e-06\n",
      "Epoch  31 [6950/10697 ( 65.0%)] Loss: 0.028366 L1: 0.016768 Grad: 0.115733 Thermal: 0.000505 LR: 3.39e-06\n",
      "Epoch  31 [6950/10697 ( 65.0%)] Loss: 0.028366 L1: 0.016768 Grad: 0.115733 Thermal: 0.000505 LR: 3.39e-06\n",
      "Epoch  31 [7000/10697 ( 65.4%)] Loss: 0.027063 L1: 0.016051 Grad: 0.109906 Thermal: 0.000437 LR: 3.39e-06\n",
      "Epoch  31 [7000/10697 ( 65.4%)] Loss: 0.027063 L1: 0.016051 Grad: 0.109906 Thermal: 0.000437 LR: 3.39e-06\n",
      "Epoch  31 [7050/10697 ( 65.9%)] Loss: 0.025725 L1: 0.015077 Grad: 0.106274 Thermal: 0.000416 LR: 3.39e-06\n",
      "Epoch  31 [7050/10697 ( 65.9%)] Loss: 0.025725 L1: 0.015077 Grad: 0.106274 Thermal: 0.000416 LR: 3.39e-06\n",
      "Epoch  31 [7100/10697 ( 66.4%)] Loss: 0.022171 L1: 0.012916 Grad: 0.092383 Thermal: 0.000331 LR: 3.39e-06\n",
      "Epoch  31 [7100/10697 ( 66.4%)] Loss: 0.022171 L1: 0.012916 Grad: 0.092383 Thermal: 0.000331 LR: 3.39e-06\n",
      "Epoch  31 [7150/10697 ( 66.8%)] Loss: 0.021113 L1: 0.012404 Grad: 0.086947 Thermal: 0.000295 LR: 3.39e-06\n",
      "Epoch  31 [7150/10697 ( 66.8%)] Loss: 0.021113 L1: 0.012404 Grad: 0.086947 Thermal: 0.000295 LR: 3.39e-06\n",
      "Epoch  31 [7200/10697 ( 67.3%)] Loss: 0.021205 L1: 0.012166 Grad: 0.090246 Thermal: 0.000304 LR: 3.39e-06\n",
      "Epoch  31 [7200/10697 ( 67.3%)] Loss: 0.021205 L1: 0.012166 Grad: 0.090246 Thermal: 0.000304 LR: 3.39e-06\n",
      "Epoch  31 [7250/10697 ( 67.8%)] Loss: 0.026911 L1: 0.015794 Grad: 0.110924 Thermal: 0.000490 LR: 3.39e-06\n",
      "Epoch  31 [7250/10697 ( 67.8%)] Loss: 0.026911 L1: 0.015794 Grad: 0.110924 Thermal: 0.000490 LR: 3.39e-06\n",
      "Epoch  31 [7300/10697 ( 68.2%)] Loss: 0.031749 L1: 0.018290 Grad: 0.134242 Thermal: 0.000692 LR: 3.39e-06\n",
      "Epoch  31 [7300/10697 ( 68.2%)] Loss: 0.031749 L1: 0.018290 Grad: 0.134242 Thermal: 0.000692 LR: 3.39e-06\n",
      "Epoch  31 [7350/10697 ( 68.7%)] Loss: 0.025184 L1: 0.014875 Grad: 0.102892 Thermal: 0.000400 LR: 3.39e-06\n",
      "Epoch  31 [7350/10697 ( 68.7%)] Loss: 0.025184 L1: 0.014875 Grad: 0.102892 Thermal: 0.000400 LR: 3.39e-06\n",
      "Epoch  31 [7400/10697 ( 69.2%)] Loss: 0.029523 L1: 0.017271 Grad: 0.122250 Thermal: 0.000543 LR: 3.39e-06\n",
      "Epoch  31 [7400/10697 ( 69.2%)] Loss: 0.029523 L1: 0.017271 Grad: 0.122250 Thermal: 0.000543 LR: 3.39e-06\n",
      "Epoch  31 [7450/10697 ( 69.6%)] Loss: 0.024814 L1: 0.014641 Grad: 0.101512 Thermal: 0.000425 LR: 3.39e-06\n",
      "Epoch  31 [7450/10697 ( 69.6%)] Loss: 0.024814 L1: 0.014641 Grad: 0.101512 Thermal: 0.000425 LR: 3.39e-06\n",
      "Epoch  31 [7500/10697 ( 70.1%)] Loss: 0.027888 L1: 0.016468 Grad: 0.113957 Thermal: 0.000483 LR: 3.39e-06\n",
      "Epoch  31 [7500/10697 ( 70.1%)] Loss: 0.027888 L1: 0.016468 Grad: 0.113957 Thermal: 0.000483 LR: 3.39e-06\n",
      "Epoch  31 [7550/10697 ( 70.6%)] Loss: 0.037025 L1: 0.021247 Grad: 0.157338 Thermal: 0.000888 LR: 3.39e-06\n",
      "Epoch  31 [7550/10697 ( 70.6%)] Loss: 0.037025 L1: 0.021247 Grad: 0.157338 Thermal: 0.000888 LR: 3.39e-06\n",
      "Epoch  31 [7600/10697 ( 71.0%)] Loss: 0.031400 L1: 0.018221 Grad: 0.131473 Thermal: 0.000628 LR: 3.39e-06\n",
      "Epoch  31 [7600/10697 ( 71.0%)] Loss: 0.031400 L1: 0.018221 Grad: 0.131473 Thermal: 0.000628 LR: 3.39e-06\n",
      "Epoch  31 [7650/10697 ( 71.5%)] Loss: 0.031735 L1: 0.018287 Grad: 0.134140 Thermal: 0.000678 LR: 3.39e-06\n",
      "Epoch  31 [7650/10697 ( 71.5%)] Loss: 0.031735 L1: 0.018287 Grad: 0.134140 Thermal: 0.000678 LR: 3.39e-06\n",
      "Epoch  31 [7700/10697 ( 72.0%)] Loss: 0.023932 L1: 0.014013 Grad: 0.099007 Thermal: 0.000372 LR: 3.39e-06\n",
      "Epoch  31 [7700/10697 ( 72.0%)] Loss: 0.023932 L1: 0.014013 Grad: 0.099007 Thermal: 0.000372 LR: 3.39e-06\n",
      "Epoch  31 [7750/10697 ( 72.5%)] Loss: 0.027553 L1: 0.016535 Grad: 0.109939 Thermal: 0.000491 LR: 3.39e-06\n",
      "Epoch  31 [7750/10697 ( 72.5%)] Loss: 0.027553 L1: 0.016535 Grad: 0.109939 Thermal: 0.000491 LR: 3.39e-06\n",
      "Epoch  31 [7800/10697 ( 72.9%)] Loss: 0.028671 L1: 0.016699 Grad: 0.119464 Thermal: 0.000515 LR: 3.39e-06\n",
      "Epoch  31 [7800/10697 ( 72.9%)] Loss: 0.028671 L1: 0.016699 Grad: 0.119464 Thermal: 0.000515 LR: 3.39e-06\n",
      "Epoch  31 [7850/10697 ( 73.4%)] Loss: 0.025857 L1: 0.015459 Grad: 0.103759 Thermal: 0.000440 LR: 3.39e-06\n",
      "Epoch  31 [7850/10697 ( 73.4%)] Loss: 0.025857 L1: 0.015459 Grad: 0.103759 Thermal: 0.000440 LR: 3.39e-06\n",
      "Epoch  31 [7900/10697 ( 73.9%)] Loss: 0.024940 L1: 0.014390 Grad: 0.105315 Thermal: 0.000372 LR: 3.39e-06\n",
      "Epoch  31 [7900/10697 ( 73.9%)] Loss: 0.024940 L1: 0.014390 Grad: 0.105315 Thermal: 0.000372 LR: 3.39e-06\n",
      "Epoch  31 [7950/10697 ( 74.3%)] Loss: 0.028108 L1: 0.016492 Grad: 0.115916 Thermal: 0.000478 LR: 3.39e-06\n",
      "Epoch  31 [7950/10697 ( 74.3%)] Loss: 0.028108 L1: 0.016492 Grad: 0.115916 Thermal: 0.000478 LR: 3.39e-06\n",
      "Epoch  31 [8000/10697 ( 74.8%)] Loss: 0.021054 L1: 0.012410 Grad: 0.086299 Thermal: 0.000291 LR: 3.39e-06\n",
      "Epoch  31 [8000/10697 ( 74.8%)] Loss: 0.021054 L1: 0.012410 Grad: 0.086299 Thermal: 0.000291 LR: 3.39e-06\n",
      "Epoch  31 [8050/10697 ( 75.3%)] Loss: 0.026688 L1: 0.015484 Grad: 0.111823 Thermal: 0.000424 LR: 3.39e-06\n",
      "Epoch  31 [8050/10697 ( 75.3%)] Loss: 0.026688 L1: 0.015484 Grad: 0.111823 Thermal: 0.000424 LR: 3.39e-06\n",
      "Epoch  31 [8100/10697 ( 75.7%)] Loss: 0.023902 L1: 0.014021 Grad: 0.098610 Thermal: 0.000399 LR: 3.39e-06\n",
      "Epoch  31 [8100/10697 ( 75.7%)] Loss: 0.023902 L1: 0.014021 Grad: 0.098610 Thermal: 0.000399 LR: 3.39e-06\n",
      "Epoch  31 [8150/10697 ( 76.2%)] Loss: 0.026507 L1: 0.015323 Grad: 0.111635 Thermal: 0.000412 LR: 3.39e-06\n",
      "Epoch  31 [8150/10697 ( 76.2%)] Loss: 0.026507 L1: 0.015323 Grad: 0.111635 Thermal: 0.000412 LR: 3.39e-06\n",
      "Epoch  31 [8200/10697 ( 76.7%)] Loss: 0.022613 L1: 0.013202 Grad: 0.093943 Thermal: 0.000332 LR: 3.39e-06\n",
      "Epoch  31 [8200/10697 ( 76.7%)] Loss: 0.022613 L1: 0.013202 Grad: 0.093943 Thermal: 0.000332 LR: 3.39e-06\n",
      "Epoch  31 [8250/10697 ( 77.1%)] Loss: 0.025778 L1: 0.014903 Grad: 0.108534 Thermal: 0.000431 LR: 3.39e-06\n",
      "Epoch  31 [8250/10697 ( 77.1%)] Loss: 0.025778 L1: 0.014903 Grad: 0.108534 Thermal: 0.000431 LR: 3.39e-06\n",
      "Epoch  31 [8300/10697 ( 77.6%)] Loss: 0.029505 L1: 0.017393 Grad: 0.120848 Thermal: 0.000550 LR: 3.39e-06\n",
      "Epoch  31 [8300/10697 ( 77.6%)] Loss: 0.029505 L1: 0.017393 Grad: 0.120848 Thermal: 0.000550 LR: 3.39e-06\n",
      "Epoch  31 [8350/10697 ( 78.1%)] Loss: 0.023884 L1: 0.013717 Grad: 0.101480 Thermal: 0.000391 LR: 3.39e-06\n",
      "Epoch  31 [8350/10697 ( 78.1%)] Loss: 0.023884 L1: 0.013717 Grad: 0.101480 Thermal: 0.000391 LR: 3.39e-06\n",
      "Epoch  31 [8400/10697 ( 78.5%)] Loss: 0.023750 L1: 0.013722 Grad: 0.100080 Thermal: 0.000394 LR: 3.39e-06\n",
      "Epoch  31 [8400/10697 ( 78.5%)] Loss: 0.023750 L1: 0.013722 Grad: 0.100080 Thermal: 0.000394 LR: 3.39e-06\n",
      "Epoch  31 [8450/10697 ( 79.0%)] Loss: 0.024242 L1: 0.014375 Grad: 0.098471 Thermal: 0.000386 LR: 3.39e-06\n",
      "Epoch  31 [8450/10697 ( 79.0%)] Loss: 0.024242 L1: 0.014375 Grad: 0.098471 Thermal: 0.000386 LR: 3.39e-06\n",
      "Epoch  31 [8500/10697 ( 79.5%)] Loss: 0.026057 L1: 0.015163 Grad: 0.108725 Thermal: 0.000447 LR: 3.39e-06\n",
      "Epoch  31 [8500/10697 ( 79.5%)] Loss: 0.026057 L1: 0.015163 Grad: 0.108725 Thermal: 0.000447 LR: 3.39e-06\n",
      "Epoch  31 [8550/10697 ( 79.9%)] Loss: 0.022991 L1: 0.013743 Grad: 0.092291 Thermal: 0.000366 LR: 3.39e-06\n",
      "Epoch  31 [8550/10697 ( 79.9%)] Loss: 0.022991 L1: 0.013743 Grad: 0.092291 Thermal: 0.000366 LR: 3.39e-06\n",
      "Epoch  31 [8600/10697 ( 80.4%)] Loss: 0.028244 L1: 0.016304 Grad: 0.119152 Thermal: 0.000491 LR: 3.39e-06\n",
      "Epoch  31 [8600/10697 ( 80.4%)] Loss: 0.028244 L1: 0.016304 Grad: 0.119152 Thermal: 0.000491 LR: 3.39e-06\n",
      "Epoch  31 [8650/10697 ( 80.9%)] Loss: 0.026110 L1: 0.015059 Grad: 0.110290 Thermal: 0.000429 LR: 3.39e-06\n",
      "Epoch  31 [8650/10697 ( 80.9%)] Loss: 0.026110 L1: 0.015059 Grad: 0.110290 Thermal: 0.000429 LR: 3.39e-06\n",
      "Epoch  31 [8700/10697 ( 81.3%)] Loss: 0.025270 L1: 0.015315 Grad: 0.099337 Thermal: 0.000418 LR: 3.39e-06\n",
      "Epoch  31 [8700/10697 ( 81.3%)] Loss: 0.025270 L1: 0.015315 Grad: 0.099337 Thermal: 0.000418 LR: 3.39e-06\n",
      "Epoch  31 [8750/10697 ( 81.8%)] Loss: 0.026152 L1: 0.015009 Grad: 0.111232 Thermal: 0.000413 LR: 3.39e-06\n",
      "Epoch  31 [8750/10697 ( 81.8%)] Loss: 0.026152 L1: 0.015009 Grad: 0.111232 Thermal: 0.000413 LR: 3.39e-06\n",
      "Epoch  31 [8800/10697 ( 82.3%)] Loss: 0.020713 L1: 0.011930 Grad: 0.087669 Thermal: 0.000328 LR: 3.39e-06\n",
      "Epoch  31 [8800/10697 ( 82.3%)] Loss: 0.020713 L1: 0.011930 Grad: 0.087669 Thermal: 0.000328 LR: 3.39e-06\n",
      "Epoch  31 [8850/10697 ( 82.7%)] Loss: 0.020898 L1: 0.012103 Grad: 0.087799 Thermal: 0.000305 LR: 3.39e-06\n",
      "Epoch  31 [8850/10697 ( 82.7%)] Loss: 0.020898 L1: 0.012103 Grad: 0.087799 Thermal: 0.000305 LR: 3.39e-06\n",
      "Epoch  31 [8900/10697 ( 83.2%)] Loss: 0.027678 L1: 0.016016 Grad: 0.116342 Thermal: 0.000550 LR: 3.39e-06\n",
      "Epoch  31 [8900/10697 ( 83.2%)] Loss: 0.027678 L1: 0.016016 Grad: 0.116342 Thermal: 0.000550 LR: 3.39e-06\n",
      "Epoch  31 [8950/10697 ( 83.7%)] Loss: 0.025834 L1: 0.014836 Grad: 0.109749 Thermal: 0.000476 LR: 3.39e-06\n",
      "Epoch  31 [8950/10697 ( 83.7%)] Loss: 0.025834 L1: 0.014836 Grad: 0.109749 Thermal: 0.000476 LR: 3.39e-06\n",
      "Epoch  31 [9000/10697 ( 84.1%)] Loss: 0.032888 L1: 0.018840 Grad: 0.140151 Thermal: 0.000654 LR: 3.39e-06\n",
      "Epoch  31 [9000/10697 ( 84.1%)] Loss: 0.032888 L1: 0.018840 Grad: 0.140151 Thermal: 0.000654 LR: 3.39e-06\n",
      "Epoch  31 [9050/10697 ( 84.6%)] Loss: 0.026027 L1: 0.015442 Grad: 0.105629 Thermal: 0.000454 LR: 3.39e-06\n",
      "Epoch  31 [9050/10697 ( 84.6%)] Loss: 0.026027 L1: 0.015442 Grad: 0.105629 Thermal: 0.000454 LR: 3.39e-06\n",
      "Epoch  31 [9100/10697 ( 85.1%)] Loss: 0.024257 L1: 0.014033 Grad: 0.102030 Thermal: 0.000417 LR: 3.39e-06\n",
      "Epoch  31 [9100/10697 ( 85.1%)] Loss: 0.024257 L1: 0.014033 Grad: 0.102030 Thermal: 0.000417 LR: 3.39e-06\n",
      "Epoch  31 [9150/10697 ( 85.5%)] Loss: 0.020247 L1: 0.011888 Grad: 0.083442 Thermal: 0.000305 LR: 3.39e-06\n",
      "Epoch  31 [9150/10697 ( 85.5%)] Loss: 0.020247 L1: 0.011888 Grad: 0.083442 Thermal: 0.000305 LR: 3.39e-06\n",
      "Epoch  31 [9200/10697 ( 86.0%)] Loss: 0.024761 L1: 0.014614 Grad: 0.101273 Thermal: 0.000407 LR: 3.39e-06\n",
      "Epoch  31 [9200/10697 ( 86.0%)] Loss: 0.024761 L1: 0.014614 Grad: 0.101273 Thermal: 0.000407 LR: 3.39e-06\n",
      "Epoch  31 [9250/10697 ( 86.5%)] Loss: 0.025372 L1: 0.015059 Grad: 0.102925 Thermal: 0.000420 LR: 3.39e-06\n",
      "Epoch  31 [9250/10697 ( 86.5%)] Loss: 0.025372 L1: 0.015059 Grad: 0.102925 Thermal: 0.000420 LR: 3.39e-06\n",
      "Epoch  31 [9300/10697 ( 86.9%)] Loss: 0.028508 L1: 0.016836 Grad: 0.116470 Thermal: 0.000499 LR: 3.39e-06\n",
      "Epoch  31 [9300/10697 ( 86.9%)] Loss: 0.028508 L1: 0.016836 Grad: 0.116470 Thermal: 0.000499 LR: 3.39e-06\n",
      "Epoch  31 [9350/10697 ( 87.4%)] Loss: 0.026772 L1: 0.015841 Grad: 0.109072 Thermal: 0.000465 LR: 3.39e-06\n",
      "Epoch  31 [9350/10697 ( 87.4%)] Loss: 0.026772 L1: 0.015841 Grad: 0.109072 Thermal: 0.000465 LR: 3.39e-06\n",
      "Epoch  31 [9400/10697 ( 87.9%)] Loss: 0.025417 L1: 0.015207 Grad: 0.101883 Thermal: 0.000430 LR: 3.39e-06\n",
      "Epoch  31 [9400/10697 ( 87.9%)] Loss: 0.025417 L1: 0.015207 Grad: 0.101883 Thermal: 0.000430 LR: 3.39e-06\n",
      "Epoch  31 [9450/10697 ( 88.3%)] Loss: 0.028398 L1: 0.016919 Grad: 0.114533 Thermal: 0.000519 LR: 3.39e-06\n",
      "Epoch  31 [9450/10697 ( 88.3%)] Loss: 0.028398 L1: 0.016919 Grad: 0.114533 Thermal: 0.000519 LR: 3.39e-06\n",
      "Epoch  31 [9500/10697 ( 88.8%)] Loss: 0.027711 L1: 0.016258 Grad: 0.114274 Thermal: 0.000515 LR: 3.39e-06\n",
      "Epoch  31 [9500/10697 ( 88.8%)] Loss: 0.027711 L1: 0.016258 Grad: 0.114274 Thermal: 0.000515 LR: 3.39e-06\n",
      "Epoch  31 [9550/10697 ( 89.3%)] Loss: 0.027951 L1: 0.016579 Grad: 0.113461 Thermal: 0.000500 LR: 3.39e-06\n",
      "Epoch  31 [9550/10697 ( 89.3%)] Loss: 0.027951 L1: 0.016579 Grad: 0.113461 Thermal: 0.000500 LR: 3.39e-06\n",
      "Epoch  31 [9600/10697 ( 89.7%)] Loss: 0.032583 L1: 0.018794 Grad: 0.137580 Thermal: 0.000624 LR: 3.39e-06\n",
      "Epoch  31 [9600/10697 ( 89.7%)] Loss: 0.032583 L1: 0.018794 Grad: 0.137580 Thermal: 0.000624 LR: 3.39e-06\n",
      "Epoch  31 [9650/10697 ( 90.2%)] Loss: 0.034157 L1: 0.019390 Grad: 0.147341 Thermal: 0.000655 LR: 3.39e-06\n",
      "Epoch  31 [9650/10697 ( 90.2%)] Loss: 0.034157 L1: 0.019390 Grad: 0.147341 Thermal: 0.000655 LR: 3.39e-06\n",
      "Epoch  31 [9700/10697 ( 90.7%)] Loss: 0.023738 L1: 0.013702 Grad: 0.100185 Thermal: 0.000348 LR: 3.39e-06\n",
      "Epoch  31 [9700/10697 ( 90.7%)] Loss: 0.023738 L1: 0.013702 Grad: 0.100185 Thermal: 0.000348 LR: 3.39e-06\n",
      "Epoch  31 [9750/10697 ( 91.1%)] Loss: 0.028839 L1: 0.017022 Grad: 0.117916 Thermal: 0.000505 LR: 3.39e-06\n",
      "Epoch  31 [9750/10697 ( 91.1%)] Loss: 0.028839 L1: 0.017022 Grad: 0.117916 Thermal: 0.000505 LR: 3.39e-06\n",
      "Epoch  31 [9800/10697 ( 91.6%)] Loss: 0.027652 L1: 0.015520 Grad: 0.121072 Thermal: 0.000487 LR: 3.39e-06\n",
      "Epoch  31 [9800/10697 ( 91.6%)] Loss: 0.027652 L1: 0.015520 Grad: 0.121072 Thermal: 0.000487 LR: 3.39e-06\n",
      "Epoch  31 [9850/10697 ( 92.1%)] Loss: 0.027580 L1: 0.015903 Grad: 0.116501 Thermal: 0.000523 LR: 3.39e-06\n",
      "Epoch  31 [9850/10697 ( 92.1%)] Loss: 0.027580 L1: 0.015903 Grad: 0.116501 Thermal: 0.000523 LR: 3.39e-06\n",
      "Epoch  31 [9900/10697 ( 92.5%)] Loss: 0.026254 L1: 0.015604 Grad: 0.106281 Thermal: 0.000455 LR: 3.39e-06\n",
      "Epoch  31 [9900/10697 ( 92.5%)] Loss: 0.026254 L1: 0.015604 Grad: 0.106281 Thermal: 0.000455 LR: 3.39e-06\n",
      "Epoch  31 [9950/10697 ( 93.0%)] Loss: 0.023602 L1: 0.013882 Grad: 0.097007 Thermal: 0.000386 LR: 3.39e-06\n",
      "Epoch  31 [9950/10697 ( 93.0%)] Loss: 0.023602 L1: 0.013882 Grad: 0.097007 Thermal: 0.000386 LR: 3.39e-06\n",
      "Epoch  31 [10000/10697 ( 93.5%)] Loss: 0.020345 L1: 0.011688 Grad: 0.086428 Thermal: 0.000289 LR: 3.39e-06\n",
      "Epoch  31 [10000/10697 ( 93.5%)] Loss: 0.020345 L1: 0.011688 Grad: 0.086428 Thermal: 0.000289 LR: 3.39e-06\n",
      "Epoch  31 [10050/10697 ( 94.0%)] Loss: 0.028038 L1: 0.016214 Grad: 0.118001 Thermal: 0.000466 LR: 3.39e-06\n",
      "Epoch  31 [10050/10697 ( 94.0%)] Loss: 0.028038 L1: 0.016214 Grad: 0.118001 Thermal: 0.000466 LR: 3.39e-06\n",
      "Epoch  31 [10100/10697 ( 94.4%)] Loss: 0.026540 L1: 0.015284 Grad: 0.112354 Thermal: 0.000414 LR: 3.39e-06\n",
      "Epoch  31 [10100/10697 ( 94.4%)] Loss: 0.026540 L1: 0.015284 Grad: 0.112354 Thermal: 0.000414 LR: 3.39e-06\n",
      "Epoch  31 [10150/10697 ( 94.9%)] Loss: 0.020791 L1: 0.011985 Grad: 0.087901 Thermal: 0.000305 LR: 3.39e-06\n",
      "Epoch  31 [10150/10697 ( 94.9%)] Loss: 0.020791 L1: 0.011985 Grad: 0.087901 Thermal: 0.000305 LR: 3.39e-06\n",
      "Epoch  31 [10200/10697 ( 95.4%)] Loss: 0.023258 L1: 0.013517 Grad: 0.097204 Thermal: 0.000415 LR: 3.39e-06\n",
      "Epoch  31 [10200/10697 ( 95.4%)] Loss: 0.023258 L1: 0.013517 Grad: 0.097204 Thermal: 0.000415 LR: 3.39e-06\n",
      "Epoch  31 [10250/10697 ( 95.8%)] Loss: 0.024729 L1: 0.014071 Grad: 0.106376 Thermal: 0.000418 LR: 3.39e-06\n",
      "Epoch  31 [10250/10697 ( 95.8%)] Loss: 0.024729 L1: 0.014071 Grad: 0.106376 Thermal: 0.000418 LR: 3.39e-06\n",
      "Epoch  31 [10300/10697 ( 96.3%)] Loss: 0.024012 L1: 0.013824 Grad: 0.101684 Thermal: 0.000383 LR: 3.39e-06\n",
      "Epoch  31 [10300/10697 ( 96.3%)] Loss: 0.024012 L1: 0.013824 Grad: 0.101684 Thermal: 0.000383 LR: 3.39e-06\n",
      "Epoch  31 [10350/10697 ( 96.8%)] Loss: 0.025958 L1: 0.015482 Grad: 0.104531 Thermal: 0.000453 LR: 3.39e-06\n",
      "Epoch  31 [10350/10697 ( 96.8%)] Loss: 0.025958 L1: 0.015482 Grad: 0.104531 Thermal: 0.000453 LR: 3.39e-06\n",
      "Epoch  31 [10400/10697 ( 97.2%)] Loss: 0.029317 L1: 0.016756 Grad: 0.125357 Thermal: 0.000512 LR: 3.39e-06\n",
      "Epoch  31 [10400/10697 ( 97.2%)] Loss: 0.029317 L1: 0.016756 Grad: 0.125357 Thermal: 0.000512 LR: 3.39e-06\n",
      "Epoch  31 [10450/10697 ( 97.7%)] Loss: 0.020310 L1: 0.011984 Grad: 0.083094 Thermal: 0.000315 LR: 3.39e-06\n",
      "Epoch  31 [10450/10697 ( 97.7%)] Loss: 0.020310 L1: 0.011984 Grad: 0.083094 Thermal: 0.000315 LR: 3.39e-06\n",
      "Epoch  31 [10500/10697 ( 98.2%)] Loss: 0.028746 L1: 0.017313 Grad: 0.114076 Thermal: 0.000511 LR: 3.39e-06\n",
      "Epoch  31 [10500/10697 ( 98.2%)] Loss: 0.028746 L1: 0.017313 Grad: 0.114076 Thermal: 0.000511 LR: 3.39e-06\n",
      "Epoch  31 [10550/10697 ( 98.6%)] Loss: 0.023890 L1: 0.014158 Grad: 0.097109 Thermal: 0.000421 LR: 3.39e-06\n",
      "Epoch  31 [10550/10697 ( 98.6%)] Loss: 0.023890 L1: 0.014158 Grad: 0.097109 Thermal: 0.000421 LR: 3.39e-06\n",
      "Epoch  31 [10600/10697 ( 99.1%)] Loss: 0.029441 L1: 0.017235 Grad: 0.121764 Thermal: 0.000591 LR: 3.39e-06\n",
      "Epoch  31 [10600/10697 ( 99.1%)] Loss: 0.029441 L1: 0.017235 Grad: 0.121764 Thermal: 0.000591 LR: 3.39e-06\n",
      "Epoch  31 [10650/10697 ( 99.6%)] Loss: 0.023048 L1: 0.013527 Grad: 0.095015 Thermal: 0.000383 LR: 3.39e-06\n",
      "Epoch  31 [10650/10697 ( 99.6%)] Loss: 0.023048 L1: 0.013527 Grad: 0.095015 Thermal: 0.000383 LR: 3.39e-06\n",
      "Epoch  31 Summary: Loss=0.026300 (L1:0.0153, Grad:0.1094, Thermal:0.0005) Val_PSNR=0.00dB Best=33.96dB Time=119.3min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  31 Summary: Loss=0.026300 (L1:0.0153, Grad:0.1094, Thermal:0.0005) Val_PSNR=0.00dB Best=33.96dB Time=119.3min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  32 [   0/10697 (  0.0%)] Loss: 0.030235 L1: 0.017052 Grad: 0.131550 Thermal: 0.000550 LR: 3.30e-06\n",
      "Epoch  32 [   0/10697 (  0.0%)] Loss: 0.030235 L1: 0.017052 Grad: 0.131550 Thermal: 0.000550 LR: 3.30e-06\n",
      "Epoch  32 [  50/10697 (  0.5%)] Loss: 0.026066 L1: 0.015427 Grad: 0.106146 Thermal: 0.000493 LR: 3.30e-06\n",
      "Epoch  32 [  50/10697 (  0.5%)] Loss: 0.026066 L1: 0.015427 Grad: 0.106146 Thermal: 0.000493 LR: 3.30e-06\n",
      "Epoch  32 [ 100/10697 (  0.9%)] Loss: 0.023505 L1: 0.013449 Grad: 0.100374 Thermal: 0.000380 LR: 3.30e-06\n",
      "Epoch  32 [ 100/10697 (  0.9%)] Loss: 0.023505 L1: 0.013449 Grad: 0.100374 Thermal: 0.000380 LR: 3.30e-06\n",
      "Epoch  32 [ 150/10697 (  1.4%)] Loss: 0.020149 L1: 0.011729 Grad: 0.084066 Thermal: 0.000286 LR: 3.30e-06\n",
      "Epoch  32 [ 150/10697 (  1.4%)] Loss: 0.020149 L1: 0.011729 Grad: 0.084066 Thermal: 0.000286 LR: 3.30e-06\n",
      "Epoch  32 [ 200/10697 (  1.9%)] Loss: 0.028834 L1: 0.017069 Grad: 0.117395 Thermal: 0.000508 LR: 3.30e-06\n",
      "Epoch  32 [ 200/10697 (  1.9%)] Loss: 0.028834 L1: 0.017069 Grad: 0.117395 Thermal: 0.000508 LR: 3.30e-06\n",
      "Epoch  32 [ 250/10697 (  2.3%)] Loss: 0.025556 L1: 0.015295 Grad: 0.102413 Thermal: 0.000410 LR: 3.30e-06\n",
      "Epoch  32 [ 250/10697 (  2.3%)] Loss: 0.025556 L1: 0.015295 Grad: 0.102413 Thermal: 0.000410 LR: 3.30e-06\n",
      "Epoch  32 [ 300/10697 (  2.8%)] Loss: 0.023913 L1: 0.013978 Grad: 0.099163 Thermal: 0.000377 LR: 3.30e-06\n",
      "Epoch  32 [ 300/10697 (  2.8%)] Loss: 0.023913 L1: 0.013978 Grad: 0.099163 Thermal: 0.000377 LR: 3.30e-06\n",
      "Epoch  32 [ 350/10697 (  3.3%)] Loss: 0.021069 L1: 0.012256 Grad: 0.087964 Thermal: 0.000329 LR: 3.30e-06\n",
      "Epoch  32 [ 350/10697 (  3.3%)] Loss: 0.021069 L1: 0.012256 Grad: 0.087964 Thermal: 0.000329 LR: 3.30e-06\n",
      "Epoch  32 [ 400/10697 (  3.7%)] Loss: 0.022393 L1: 0.012602 Grad: 0.097747 Thermal: 0.000329 LR: 3.30e-06\n",
      "Epoch  32 [ 400/10697 (  3.7%)] Loss: 0.022393 L1: 0.012602 Grad: 0.097747 Thermal: 0.000329 LR: 3.30e-06\n",
      "Epoch  32 [ 450/10697 (  4.2%)] Loss: 0.025581 L1: 0.015096 Grad: 0.104623 Thermal: 0.000444 LR: 3.30e-06\n",
      "Epoch  32 [ 450/10697 (  4.2%)] Loss: 0.025581 L1: 0.015096 Grad: 0.104623 Thermal: 0.000444 LR: 3.30e-06\n",
      "Epoch  32 [ 500/10697 (  4.7%)] Loss: 0.025391 L1: 0.014957 Grad: 0.104126 Thermal: 0.000428 LR: 3.30e-06\n",
      "Epoch  32 [ 500/10697 (  4.7%)] Loss: 0.025391 L1: 0.014957 Grad: 0.104126 Thermal: 0.000428 LR: 3.30e-06\n",
      "Epoch  32 [ 550/10697 (  5.1%)] Loss: 0.025510 L1: 0.014877 Grad: 0.106126 Thermal: 0.000407 LR: 3.30e-06\n",
      "Epoch  32 [ 550/10697 (  5.1%)] Loss: 0.025510 L1: 0.014877 Grad: 0.106126 Thermal: 0.000407 LR: 3.30e-06\n",
      "Epoch  32 [ 600/10697 (  5.6%)] Loss: 0.024922 L1: 0.014819 Grad: 0.100793 Thermal: 0.000473 LR: 3.30e-06\n",
      "Epoch  32 [ 600/10697 (  5.6%)] Loss: 0.024922 L1: 0.014819 Grad: 0.100793 Thermal: 0.000473 LR: 3.30e-06\n",
      "Epoch  32 [ 650/10697 (  6.1%)] Loss: 0.026966 L1: 0.015698 Grad: 0.112464 Thermal: 0.000439 LR: 3.30e-06\n",
      "Epoch  32 [ 650/10697 (  6.1%)] Loss: 0.026966 L1: 0.015698 Grad: 0.112464 Thermal: 0.000439 LR: 3.30e-06\n",
      "Epoch  32 [ 700/10697 (  6.5%)] Loss: 0.027852 L1: 0.016534 Grad: 0.112947 Thermal: 0.000478 LR: 3.30e-06\n",
      "Epoch  32 [ 700/10697 (  6.5%)] Loss: 0.027852 L1: 0.016534 Grad: 0.112947 Thermal: 0.000478 LR: 3.30e-06\n",
      "Epoch  32 [ 750/10697 (  7.0%)] Loss: 0.024606 L1: 0.014506 Grad: 0.100805 Thermal: 0.000394 LR: 3.30e-06\n",
      "Epoch  32 [ 750/10697 (  7.0%)] Loss: 0.024606 L1: 0.014506 Grad: 0.100805 Thermal: 0.000394 LR: 3.30e-06\n",
      "Epoch  32 [ 800/10697 (  7.5%)] Loss: 0.023835 L1: 0.014072 Grad: 0.097430 Thermal: 0.000394 LR: 3.30e-06\n",
      "Epoch  32 [ 800/10697 (  7.5%)] Loss: 0.023835 L1: 0.014072 Grad: 0.097430 Thermal: 0.000394 LR: 3.30e-06\n",
      "Epoch  32 [ 850/10697 (  7.9%)] Loss: 0.027153 L1: 0.015911 Grad: 0.112198 Thermal: 0.000455 LR: 3.30e-06\n",
      "Epoch  32 [ 850/10697 (  7.9%)] Loss: 0.027153 L1: 0.015911 Grad: 0.112198 Thermal: 0.000455 LR: 3.30e-06\n",
      "Epoch  32 [ 900/10697 (  8.4%)] Loss: 0.025441 L1: 0.014917 Grad: 0.105029 Thermal: 0.000425 LR: 3.30e-06\n",
      "Epoch  32 [ 900/10697 (  8.4%)] Loss: 0.025441 L1: 0.014917 Grad: 0.105029 Thermal: 0.000425 LR: 3.30e-06\n",
      "Epoch  32 [ 950/10697 (  8.9%)] Loss: 0.031265 L1: 0.017975 Grad: 0.132590 Thermal: 0.000621 LR: 3.30e-06\n",
      "Epoch  32 [ 950/10697 (  8.9%)] Loss: 0.031265 L1: 0.017975 Grad: 0.132590 Thermal: 0.000621 LR: 3.30e-06\n",
      "Epoch  32 [1000/10697 (  9.3%)] Loss: 0.028995 L1: 0.017233 Grad: 0.117360 Thermal: 0.000537 LR: 3.30e-06\n",
      "Epoch  32 [1000/10697 (  9.3%)] Loss: 0.028995 L1: 0.017233 Grad: 0.117360 Thermal: 0.000537 LR: 3.30e-06\n",
      "Epoch  32 [1050/10697 (  9.8%)] Loss: 0.026754 L1: 0.015886 Grad: 0.108455 Thermal: 0.000459 LR: 3.30e-06\n",
      "Epoch  32 [1050/10697 (  9.8%)] Loss: 0.026754 L1: 0.015886 Grad: 0.108455 Thermal: 0.000459 LR: 3.30e-06\n",
      "Epoch  32 [1100/10697 ( 10.3%)] Loss: 0.023283 L1: 0.013895 Grad: 0.093696 Thermal: 0.000359 LR: 3.30e-06\n",
      "Epoch  32 [1100/10697 ( 10.3%)] Loss: 0.023283 L1: 0.013895 Grad: 0.093696 Thermal: 0.000359 LR: 3.30e-06\n",
      "Epoch  32 [1150/10697 ( 10.8%)] Loss: 0.026918 L1: 0.016107 Grad: 0.107876 Thermal: 0.000475 LR: 3.30e-06\n",
      "Epoch  32 [1150/10697 ( 10.8%)] Loss: 0.026918 L1: 0.016107 Grad: 0.107876 Thermal: 0.000475 LR: 3.30e-06\n",
      "Epoch  32 [1200/10697 ( 11.2%)] Loss: 0.022272 L1: 0.012661 Grad: 0.095937 Thermal: 0.000335 LR: 3.30e-06\n",
      "Epoch  32 [1200/10697 ( 11.2%)] Loss: 0.022272 L1: 0.012661 Grad: 0.095937 Thermal: 0.000335 LR: 3.30e-06\n",
      "Epoch  32 [1250/10697 ( 11.7%)] Loss: 0.027697 L1: 0.016350 Grad: 0.113231 Thermal: 0.000486 LR: 3.30e-06\n",
      "Epoch  32 [1250/10697 ( 11.7%)] Loss: 0.027697 L1: 0.016350 Grad: 0.113231 Thermal: 0.000486 LR: 3.30e-06\n",
      "Epoch  32 [1300/10697 ( 12.2%)] Loss: 0.016578 L1: 0.009549 Grad: 0.070181 Thermal: 0.000204 LR: 3.30e-06\n",
      "Epoch  32 [1300/10697 ( 12.2%)] Loss: 0.016578 L1: 0.009549 Grad: 0.070181 Thermal: 0.000204 LR: 3.30e-06\n",
      "Epoch  32 [1350/10697 ( 12.6%)] Loss: 0.021617 L1: 0.012370 Grad: 0.092284 Thermal: 0.000366 LR: 3.30e-06\n",
      "Epoch  32 [1350/10697 ( 12.6%)] Loss: 0.021617 L1: 0.012370 Grad: 0.092284 Thermal: 0.000366 LR: 3.30e-06\n",
      "Epoch  32 [1400/10697 ( 13.1%)] Loss: 0.021976 L1: 0.012594 Grad: 0.093653 Thermal: 0.000341 LR: 3.30e-06\n",
      "Epoch  32 [1400/10697 ( 13.1%)] Loss: 0.021976 L1: 0.012594 Grad: 0.093653 Thermal: 0.000341 LR: 3.30e-06\n",
      "Epoch  32 [1450/10697 ( 13.6%)] Loss: 0.028463 L1: 0.016911 Grad: 0.115258 Thermal: 0.000521 LR: 3.30e-06\n",
      "Epoch  32 [1450/10697 ( 13.6%)] Loss: 0.028463 L1: 0.016911 Grad: 0.115258 Thermal: 0.000521 LR: 3.30e-06\n",
      "Epoch  32 [1500/10697 ( 14.0%)] Loss: 0.020806 L1: 0.012197 Grad: 0.085934 Thermal: 0.000313 LR: 3.30e-06\n",
      "Epoch  32 [1500/10697 ( 14.0%)] Loss: 0.020806 L1: 0.012197 Grad: 0.085934 Thermal: 0.000313 LR: 3.30e-06\n",
      "Epoch  32 [1550/10697 ( 14.5%)] Loss: 0.023814 L1: 0.013723 Grad: 0.100704 Thermal: 0.000408 LR: 3.30e-06\n",
      "Epoch  32 [1550/10697 ( 14.5%)] Loss: 0.023814 L1: 0.013723 Grad: 0.100704 Thermal: 0.000408 LR: 3.30e-06\n",
      "Epoch  32 [1600/10697 ( 15.0%)] Loss: 0.025610 L1: 0.015009 Grad: 0.105778 Thermal: 0.000470 LR: 3.30e-06\n",
      "Epoch  32 [1600/10697 ( 15.0%)] Loss: 0.025610 L1: 0.015009 Grad: 0.105778 Thermal: 0.000470 LR: 3.30e-06\n",
      "Epoch  32 [1650/10697 ( 15.4%)] Loss: 0.023507 L1: 0.013410 Grad: 0.100776 Thermal: 0.000384 LR: 3.30e-06\n",
      "Epoch  32 [1650/10697 ( 15.4%)] Loss: 0.023507 L1: 0.013410 Grad: 0.100776 Thermal: 0.000384 LR: 3.30e-06\n",
      "Epoch  32 [1700/10697 ( 15.9%)] Loss: 0.030535 L1: 0.017824 Grad: 0.126822 Thermal: 0.000566 LR: 3.30e-06\n",
      "Epoch  32 [1700/10697 ( 15.9%)] Loss: 0.030535 L1: 0.017824 Grad: 0.126822 Thermal: 0.000566 LR: 3.30e-06\n",
      "Epoch  32 [1750/10697 ( 16.4%)] Loss: 0.022571 L1: 0.013115 Grad: 0.094401 Thermal: 0.000322 LR: 3.30e-06\n",
      "Epoch  32 [1750/10697 ( 16.4%)] Loss: 0.022571 L1: 0.013115 Grad: 0.094401 Thermal: 0.000322 LR: 3.30e-06\n",
      "Epoch  32 [1800/10697 ( 16.8%)] Loss: 0.023046 L1: 0.012988 Grad: 0.100378 Thermal: 0.000400 LR: 3.30e-06\n",
      "Epoch  32 [1800/10697 ( 16.8%)] Loss: 0.023046 L1: 0.012988 Grad: 0.100378 Thermal: 0.000400 LR: 3.30e-06\n",
      "Epoch  32 [1850/10697 ( 17.3%)] Loss: 0.025355 L1: 0.015242 Grad: 0.100925 Thermal: 0.000412 LR: 3.30e-06\n",
      "Epoch  32 [1850/10697 ( 17.3%)] Loss: 0.025355 L1: 0.015242 Grad: 0.100925 Thermal: 0.000412 LR: 3.30e-06\n",
      "Epoch  32 [1900/10697 ( 17.8%)] Loss: 0.023369 L1: 0.013418 Grad: 0.099338 Thermal: 0.000352 LR: 3.30e-06\n",
      "Epoch  32 [1900/10697 ( 17.8%)] Loss: 0.023369 L1: 0.013418 Grad: 0.099338 Thermal: 0.000352 LR: 3.30e-06\n",
      "Epoch  32 [1950/10697 ( 18.2%)] Loss: 0.024298 L1: 0.014253 Grad: 0.100257 Thermal: 0.000390 LR: 3.30e-06\n",
      "Epoch  32 [1950/10697 ( 18.2%)] Loss: 0.024298 L1: 0.014253 Grad: 0.100257 Thermal: 0.000390 LR: 3.30e-06\n",
      "Epoch  32 [2000/10697 ( 18.7%)] Loss: 0.023311 L1: 0.013775 Grad: 0.095172 Thermal: 0.000374 LR: 3.30e-06\n",
      "Epoch  32 [2000/10697 ( 18.7%)] Loss: 0.023311 L1: 0.013775 Grad: 0.095172 Thermal: 0.000374 LR: 3.30e-06\n",
      "Epoch  32 [2050/10697 ( 19.2%)] Loss: 0.028287 L1: 0.016827 Grad: 0.114355 Thermal: 0.000506 LR: 3.30e-06\n",
      "Epoch  32 [2050/10697 ( 19.2%)] Loss: 0.028287 L1: 0.016827 Grad: 0.114355 Thermal: 0.000506 LR: 3.30e-06\n",
      "Epoch  32 [2100/10697 ( 19.6%)] Loss: 0.027048 L1: 0.016010 Grad: 0.110128 Thermal: 0.000508 LR: 3.30e-06\n",
      "Epoch  32 [2100/10697 ( 19.6%)] Loss: 0.027048 L1: 0.016010 Grad: 0.110128 Thermal: 0.000508 LR: 3.30e-06\n",
      "Epoch  32 [2150/10697 ( 20.1%)] Loss: 0.023781 L1: 0.014134 Grad: 0.096283 Thermal: 0.000375 LR: 3.30e-06\n",
      "Epoch  32 [2150/10697 ( 20.1%)] Loss: 0.023781 L1: 0.014134 Grad: 0.096283 Thermal: 0.000375 LR: 3.30e-06\n",
      "Epoch  32 [2200/10697 ( 20.6%)] Loss: 0.022280 L1: 0.013008 Grad: 0.092535 Thermal: 0.000353 LR: 3.30e-06\n",
      "Epoch  32 [2200/10697 ( 20.6%)] Loss: 0.022280 L1: 0.013008 Grad: 0.092535 Thermal: 0.000353 LR: 3.30e-06\n",
      "Epoch  32 [2250/10697 ( 21.0%)] Loss: 0.024918 L1: 0.014851 Grad: 0.100461 Thermal: 0.000416 LR: 3.30e-06\n",
      "Epoch  32 [2250/10697 ( 21.0%)] Loss: 0.024918 L1: 0.014851 Grad: 0.100461 Thermal: 0.000416 LR: 3.30e-06\n",
      "Epoch  32 [2300/10697 ( 21.5%)] Loss: 0.018550 L1: 0.010961 Grad: 0.075759 Thermal: 0.000268 LR: 3.30e-06\n",
      "Epoch  32 [2300/10697 ( 21.5%)] Loss: 0.018550 L1: 0.010961 Grad: 0.075759 Thermal: 0.000268 LR: 3.30e-06\n",
      "Epoch  32 [2350/10697 ( 22.0%)] Loss: 0.025964 L1: 0.014961 Grad: 0.109815 Thermal: 0.000428 LR: 3.30e-06\n",
      "Epoch  32 [2350/10697 ( 22.0%)] Loss: 0.025964 L1: 0.014961 Grad: 0.109815 Thermal: 0.000428 LR: 3.30e-06\n",
      "Epoch  32 [2400/10697 ( 22.4%)] Loss: 0.026750 L1: 0.015237 Grad: 0.114915 Thermal: 0.000432 LR: 3.30e-06\n",
      "Epoch  32 [2400/10697 ( 22.4%)] Loss: 0.026750 L1: 0.015237 Grad: 0.114915 Thermal: 0.000432 LR: 3.30e-06\n",
      "Epoch  32 [2450/10697 ( 22.9%)] Loss: 0.029978 L1: 0.017500 Grad: 0.124498 Thermal: 0.000555 LR: 3.30e-06\n",
      "Epoch  32 [2450/10697 ( 22.9%)] Loss: 0.029978 L1: 0.017500 Grad: 0.124498 Thermal: 0.000555 LR: 3.30e-06\n",
      "Epoch  32 [2500/10697 ( 23.4%)] Loss: 0.026834 L1: 0.015706 Grad: 0.111045 Thermal: 0.000467 LR: 3.30e-06\n",
      "Epoch  32 [2500/10697 ( 23.4%)] Loss: 0.026834 L1: 0.015706 Grad: 0.111045 Thermal: 0.000467 LR: 3.30e-06\n",
      "Epoch  32 [2550/10697 ( 23.8%)] Loss: 0.018823 L1: 0.010847 Grad: 0.079630 Thermal: 0.000258 LR: 3.30e-06\n",
      "Epoch  32 [2550/10697 ( 23.8%)] Loss: 0.018823 L1: 0.010847 Grad: 0.079630 Thermal: 0.000258 LR: 3.30e-06\n",
      "Epoch  32 [2600/10697 ( 24.3%)] Loss: 0.029937 L1: 0.017518 Grad: 0.123912 Thermal: 0.000561 LR: 3.30e-06\n",
      "Epoch  32 [2600/10697 ( 24.3%)] Loss: 0.029937 L1: 0.017518 Grad: 0.123912 Thermal: 0.000561 LR: 3.30e-06\n",
      "Epoch  32 [2650/10697 ( 24.8%)] Loss: 0.028656 L1: 0.016660 Grad: 0.119706 Thermal: 0.000513 LR: 3.30e-06\n",
      "Epoch  32 [2650/10697 ( 24.8%)] Loss: 0.028656 L1: 0.016660 Grad: 0.119706 Thermal: 0.000513 LR: 3.30e-06\n",
      "Epoch  32 [2700/10697 ( 25.2%)] Loss: 0.026136 L1: 0.015587 Grad: 0.105272 Thermal: 0.000438 LR: 3.30e-06\n",
      "Epoch  32 [2700/10697 ( 25.2%)] Loss: 0.026136 L1: 0.015587 Grad: 0.105272 Thermal: 0.000438 LR: 3.30e-06\n",
      "Epoch  32 [2750/10697 ( 25.7%)] Loss: 0.022508 L1: 0.013103 Grad: 0.093883 Thermal: 0.000339 LR: 3.30e-06\n",
      "Epoch  32 [2750/10697 ( 25.7%)] Loss: 0.022508 L1: 0.013103 Grad: 0.093883 Thermal: 0.000339 LR: 3.30e-06\n",
      "Epoch  32 [2800/10697 ( 26.2%)] Loss: 0.027212 L1: 0.016178 Grad: 0.110100 Thermal: 0.000468 LR: 3.30e-06\n",
      "Epoch  32 [2800/10697 ( 26.2%)] Loss: 0.027212 L1: 0.016178 Grad: 0.110100 Thermal: 0.000468 LR: 3.30e-06\n",
      "Epoch  32 [2850/10697 ( 26.6%)] Loss: 0.025138 L1: 0.014714 Grad: 0.104027 Thermal: 0.000414 LR: 3.30e-06\n",
      "Epoch  32 [2850/10697 ( 26.6%)] Loss: 0.025138 L1: 0.014714 Grad: 0.104027 Thermal: 0.000414 LR: 3.30e-06\n",
      "Epoch  32 [2900/10697 ( 27.1%)] Loss: 0.027142 L1: 0.015772 Grad: 0.113463 Thermal: 0.000480 LR: 3.30e-06\n",
      "Epoch  32 [2900/10697 ( 27.1%)] Loss: 0.027142 L1: 0.015772 Grad: 0.113463 Thermal: 0.000480 LR: 3.30e-06\n",
      "Epoch  32 [2950/10697 ( 27.6%)] Loss: 0.024289 L1: 0.014235 Grad: 0.100362 Thermal: 0.000374 LR: 3.30e-06\n",
      "Epoch  32 [2950/10697 ( 27.6%)] Loss: 0.024289 L1: 0.014235 Grad: 0.100362 Thermal: 0.000374 LR: 3.30e-06\n",
      "Epoch  32 [3000/10697 ( 28.0%)] Loss: 0.027871 L1: 0.016164 Grad: 0.116806 Thermal: 0.000526 LR: 3.30e-06\n",
      "Epoch  32 [3000/10697 ( 28.0%)] Loss: 0.027871 L1: 0.016164 Grad: 0.116806 Thermal: 0.000526 LR: 3.30e-06\n",
      "Epoch  32 [3050/10697 ( 28.5%)] Loss: 0.026678 L1: 0.015981 Grad: 0.106736 Thermal: 0.000460 LR: 3.30e-06\n",
      "Epoch  32 [3050/10697 ( 28.5%)] Loss: 0.026678 L1: 0.015981 Grad: 0.106736 Thermal: 0.000460 LR: 3.30e-06\n",
      "Epoch  32 [3100/10697 ( 29.0%)] Loss: 0.025541 L1: 0.015008 Grad: 0.105106 Thermal: 0.000435 LR: 3.30e-06\n",
      "Epoch  32 [3100/10697 ( 29.0%)] Loss: 0.025541 L1: 0.015008 Grad: 0.105106 Thermal: 0.000435 LR: 3.30e-06\n",
      "Epoch  32 [3150/10697 ( 29.4%)] Loss: 0.023475 L1: 0.013383 Grad: 0.100737 Thermal: 0.000363 LR: 3.30e-06\n",
      "Epoch  32 [3150/10697 ( 29.4%)] Loss: 0.023475 L1: 0.013383 Grad: 0.100737 Thermal: 0.000363 LR: 3.30e-06\n",
      "Epoch  32 [3200/10697 ( 29.9%)] Loss: 0.025621 L1: 0.014905 Grad: 0.106911 Thermal: 0.000487 LR: 3.30e-06\n",
      "Epoch  32 [3200/10697 ( 29.9%)] Loss: 0.025621 L1: 0.014905 Grad: 0.106911 Thermal: 0.000487 LR: 3.30e-06\n",
      "Epoch  32 [3250/10697 ( 30.4%)] Loss: 0.021987 L1: 0.012794 Grad: 0.091753 Thermal: 0.000347 LR: 3.30e-06\n",
      "Epoch  32 [3250/10697 ( 30.4%)] Loss: 0.021987 L1: 0.012794 Grad: 0.091753 Thermal: 0.000347 LR: 3.30e-06\n",
      "Epoch  32 [3300/10697 ( 30.8%)] Loss: 0.028347 L1: 0.016396 Grad: 0.119241 Thermal: 0.000537 LR: 3.30e-06\n",
      "Epoch  32 [3300/10697 ( 30.8%)] Loss: 0.028347 L1: 0.016396 Grad: 0.119241 Thermal: 0.000537 LR: 3.30e-06\n",
      "Epoch  32 [3350/10697 ( 31.3%)] Loss: 0.027597 L1: 0.015959 Grad: 0.116098 Thermal: 0.000566 LR: 3.30e-06\n",
      "Epoch  32 [3350/10697 ( 31.3%)] Loss: 0.027597 L1: 0.015959 Grad: 0.116098 Thermal: 0.000566 LR: 3.30e-06\n",
      "Epoch  32 [3400/10697 ( 31.8%)] Loss: 0.029161 L1: 0.017275 Grad: 0.118592 Thermal: 0.000536 LR: 3.30e-06\n",
      "Epoch  32 [3400/10697 ( 31.8%)] Loss: 0.029161 L1: 0.017275 Grad: 0.118592 Thermal: 0.000536 LR: 3.30e-06\n",
      "Epoch  32 [3450/10697 ( 32.3%)] Loss: 0.029970 L1: 0.017500 Grad: 0.124369 Thermal: 0.000669 LR: 3.30e-06\n",
      "Epoch  32 [3450/10697 ( 32.3%)] Loss: 0.029970 L1: 0.017500 Grad: 0.124369 Thermal: 0.000669 LR: 3.30e-06\n",
      "Epoch  32 [3500/10697 ( 32.7%)] Loss: 0.025153 L1: 0.015028 Grad: 0.101041 Thermal: 0.000422 LR: 3.30e-06\n",
      "Epoch  32 [3500/10697 ( 32.7%)] Loss: 0.025153 L1: 0.015028 Grad: 0.101041 Thermal: 0.000422 LR: 3.30e-06\n",
      "Epoch  32 [3550/10697 ( 33.2%)] Loss: 0.023448 L1: 0.013812 Grad: 0.096187 Thermal: 0.000363 LR: 3.30e-06\n",
      "Epoch  32 [3550/10697 ( 33.2%)] Loss: 0.023448 L1: 0.013812 Grad: 0.096187 Thermal: 0.000363 LR: 3.30e-06\n",
      "Epoch  32 [3600/10697 ( 33.7%)] Loss: 0.025117 L1: 0.014888 Grad: 0.102093 Thermal: 0.000391 LR: 3.30e-06\n",
      "Epoch  32 [3600/10697 ( 33.7%)] Loss: 0.025117 L1: 0.014888 Grad: 0.102093 Thermal: 0.000391 LR: 3.30e-06\n",
      "Epoch  32 [3650/10697 ( 34.1%)] Loss: 0.029957 L1: 0.017039 Grad: 0.128859 Thermal: 0.000643 LR: 3.30e-06\n",
      "Epoch  32 [3650/10697 ( 34.1%)] Loss: 0.029957 L1: 0.017039 Grad: 0.128859 Thermal: 0.000643 LR: 3.30e-06\n",
      "Epoch  32 [3700/10697 ( 34.6%)] Loss: 0.031612 L1: 0.018457 Grad: 0.131155 Thermal: 0.000795 LR: 3.30e-06\n",
      "Epoch  32 [3700/10697 ( 34.6%)] Loss: 0.031612 L1: 0.018457 Grad: 0.131155 Thermal: 0.000795 LR: 3.30e-06\n",
      "Epoch  32 [3750/10697 ( 35.1%)] Loss: 0.027867 L1: 0.016145 Grad: 0.116941 Thermal: 0.000554 LR: 3.30e-06\n",
      "Epoch  32 [3750/10697 ( 35.1%)] Loss: 0.027867 L1: 0.016145 Grad: 0.116941 Thermal: 0.000554 LR: 3.30e-06\n",
      "Epoch  32 [3800/10697 ( 35.5%)] Loss: 0.031238 L1: 0.018196 Grad: 0.130111 Thermal: 0.000608 LR: 3.30e-06\n",
      "Epoch  32 [3800/10697 ( 35.5%)] Loss: 0.031238 L1: 0.018196 Grad: 0.130111 Thermal: 0.000608 LR: 3.30e-06\n",
      "Epoch  32 [3850/10697 ( 36.0%)] Loss: 0.023354 L1: 0.013509 Grad: 0.098274 Thermal: 0.000356 LR: 3.30e-06\n",
      "Epoch  32 [3850/10697 ( 36.0%)] Loss: 0.023354 L1: 0.013509 Grad: 0.098274 Thermal: 0.000356 LR: 3.30e-06\n",
      "Epoch  32 [3900/10697 ( 36.5%)] Loss: 0.025601 L1: 0.015165 Grad: 0.104147 Thermal: 0.000428 LR: 3.30e-06\n",
      "Epoch  32 [3900/10697 ( 36.5%)] Loss: 0.025601 L1: 0.015165 Grad: 0.104147 Thermal: 0.000428 LR: 3.30e-06\n",
      "Epoch  32 [3950/10697 ( 36.9%)] Loss: 0.025406 L1: 0.014021 Grad: 0.113630 Thermal: 0.000439 LR: 3.30e-06\n",
      "Epoch  32 [3950/10697 ( 36.9%)] Loss: 0.025406 L1: 0.014021 Grad: 0.113630 Thermal: 0.000439 LR: 3.30e-06\n",
      "Epoch  32 [4000/10697 ( 37.4%)] Loss: 0.024131 L1: 0.014234 Grad: 0.098773 Thermal: 0.000389 LR: 3.30e-06\n",
      "Epoch  32 [4000/10697 ( 37.4%)] Loss: 0.024131 L1: 0.014234 Grad: 0.098773 Thermal: 0.000389 LR: 3.30e-06\n",
      "Epoch  32 [4050/10697 ( 37.9%)] Loss: 0.022335 L1: 0.012497 Grad: 0.098227 Thermal: 0.000313 LR: 3.30e-06\n",
      "Epoch  32 [4050/10697 ( 37.9%)] Loss: 0.022335 L1: 0.012497 Grad: 0.098227 Thermal: 0.000313 LR: 3.30e-06\n",
      "Epoch  32 [4100/10697 ( 38.3%)] Loss: 0.027039 L1: 0.015492 Grad: 0.115233 Thermal: 0.000463 LR: 3.30e-06\n",
      "Epoch  32 [4100/10697 ( 38.3%)] Loss: 0.027039 L1: 0.015492 Grad: 0.115233 Thermal: 0.000463 LR: 3.30e-06\n",
      "Epoch  32 [4150/10697 ( 38.8%)] Loss: 0.027182 L1: 0.015896 Grad: 0.112615 Thermal: 0.000479 LR: 3.30e-06\n",
      "Epoch  32 [4150/10697 ( 38.8%)] Loss: 0.027182 L1: 0.015896 Grad: 0.112615 Thermal: 0.000479 LR: 3.30e-06\n",
      "Epoch  32 [4200/10697 ( 39.3%)] Loss: 0.023156 L1: 0.013378 Grad: 0.097601 Thermal: 0.000365 LR: 3.30e-06\n",
      "Epoch  32 [4200/10697 ( 39.3%)] Loss: 0.023156 L1: 0.013378 Grad: 0.097601 Thermal: 0.000365 LR: 3.30e-06\n",
      "Epoch  32 [4250/10697 ( 39.7%)] Loss: 0.020753 L1: 0.011391 Grad: 0.093485 Thermal: 0.000267 LR: 3.30e-06\n",
      "Epoch  32 [4250/10697 ( 39.7%)] Loss: 0.020753 L1: 0.011391 Grad: 0.093485 Thermal: 0.000267 LR: 3.30e-06\n",
      "Epoch  32 [4300/10697 ( 40.2%)] Loss: 0.024432 L1: 0.014304 Grad: 0.101090 Thermal: 0.000389 LR: 3.30e-06\n",
      "Epoch  32 [4300/10697 ( 40.2%)] Loss: 0.024432 L1: 0.014304 Grad: 0.101090 Thermal: 0.000389 LR: 3.30e-06\n",
      "Epoch  32 [4350/10697 ( 40.7%)] Loss: 0.024622 L1: 0.014619 Grad: 0.099831 Thermal: 0.000405 LR: 3.30e-06\n",
      "Epoch  32 [4350/10697 ( 40.7%)] Loss: 0.024622 L1: 0.014619 Grad: 0.099831 Thermal: 0.000405 LR: 3.30e-06\n",
      "Epoch  32 [4400/10697 ( 41.1%)] Loss: 0.022671 L1: 0.013299 Grad: 0.093548 Thermal: 0.000342 LR: 3.30e-06\n",
      "Epoch  32 [4400/10697 ( 41.1%)] Loss: 0.022671 L1: 0.013299 Grad: 0.093548 Thermal: 0.000342 LR: 3.30e-06\n",
      "Epoch  32 [4450/10697 ( 41.6%)] Loss: 0.028024 L1: 0.016517 Grad: 0.114828 Thermal: 0.000475 LR: 3.30e-06\n",
      "Epoch  32 [4450/10697 ( 41.6%)] Loss: 0.028024 L1: 0.016517 Grad: 0.114828 Thermal: 0.000475 LR: 3.30e-06\n",
      "Epoch  32 [4500/10697 ( 42.1%)] Loss: 0.022559 L1: 0.012698 Grad: 0.098439 Thermal: 0.000338 LR: 3.30e-06\n",
      "Epoch  32 [4500/10697 ( 42.1%)] Loss: 0.022559 L1: 0.012698 Grad: 0.098439 Thermal: 0.000338 LR: 3.30e-06\n",
      "Epoch  32 [4550/10697 ( 42.5%)] Loss: 0.030269 L1: 0.017714 Grad: 0.125281 Thermal: 0.000528 LR: 3.30e-06\n",
      "Epoch  32 [4550/10697 ( 42.5%)] Loss: 0.030269 L1: 0.017714 Grad: 0.125281 Thermal: 0.000528 LR: 3.30e-06\n",
      "Epoch  32 [4600/10697 ( 43.0%)] Loss: 0.030321 L1: 0.017230 Grad: 0.130612 Thermal: 0.000594 LR: 3.30e-06\n",
      "Epoch  32 [4600/10697 ( 43.0%)] Loss: 0.030321 L1: 0.017230 Grad: 0.130612 Thermal: 0.000594 LR: 3.30e-06\n",
      "Epoch  32 [4650/10697 ( 43.5%)] Loss: 0.032065 L1: 0.018115 Grad: 0.139162 Thermal: 0.000680 LR: 3.30e-06\n",
      "Epoch  32 [4650/10697 ( 43.5%)] Loss: 0.032065 L1: 0.018115 Grad: 0.139162 Thermal: 0.000680 LR: 3.30e-06\n",
      "Epoch  32 [4700/10697 ( 43.9%)] Loss: 0.029680 L1: 0.016895 Grad: 0.127582 Thermal: 0.000545 LR: 3.30e-06\n",
      "Epoch  32 [4700/10697 ( 43.9%)] Loss: 0.029680 L1: 0.016895 Grad: 0.127582 Thermal: 0.000545 LR: 3.30e-06\n",
      "Epoch  32 [4750/10697 ( 44.4%)] Loss: 0.026116 L1: 0.015006 Grad: 0.110872 Thermal: 0.000453 LR: 3.30e-06\n",
      "Epoch  32 [4750/10697 ( 44.4%)] Loss: 0.026116 L1: 0.015006 Grad: 0.110872 Thermal: 0.000453 LR: 3.30e-06\n",
      "Epoch  32 [4800/10697 ( 44.9%)] Loss: 0.031232 L1: 0.017848 Grad: 0.133509 Thermal: 0.000663 LR: 3.30e-06\n",
      "Epoch  32 [4800/10697 ( 44.9%)] Loss: 0.031232 L1: 0.017848 Grad: 0.133509 Thermal: 0.000663 LR: 3.30e-06\n",
      "Epoch  32 [4850/10697 ( 45.3%)] Loss: 0.026208 L1: 0.015611 Grad: 0.105739 Thermal: 0.000461 LR: 3.30e-06\n",
      "Epoch  32 [4850/10697 ( 45.3%)] Loss: 0.026208 L1: 0.015611 Grad: 0.105739 Thermal: 0.000461 LR: 3.30e-06\n",
      "Epoch  32 [4900/10697 ( 45.8%)] Loss: 0.030771 L1: 0.017946 Grad: 0.127972 Thermal: 0.000571 LR: 3.30e-06\n",
      "Epoch  32 [4900/10697 ( 45.8%)] Loss: 0.030771 L1: 0.017946 Grad: 0.127972 Thermal: 0.000571 LR: 3.30e-06\n",
      "Epoch  32 [4950/10697 ( 46.3%)] Loss: 0.025041 L1: 0.014560 Grad: 0.104611 Thermal: 0.000397 LR: 3.30e-06\n",
      "Epoch  32 [4950/10697 ( 46.3%)] Loss: 0.025041 L1: 0.014560 Grad: 0.104611 Thermal: 0.000397 LR: 3.30e-06\n",
      "Epoch  32 [5000/10697 ( 46.7%)] Loss: 0.027559 L1: 0.016092 Grad: 0.114436 Thermal: 0.000479 LR: 3.30e-06\n",
      "Epoch  32 [5000/10697 ( 46.7%)] Loss: 0.027559 L1: 0.016092 Grad: 0.114436 Thermal: 0.000479 LR: 3.30e-06\n",
      "Epoch  32 [5050/10697 ( 47.2%)] Loss: 0.027678 L1: 0.016598 Grad: 0.110548 Thermal: 0.000509 LR: 3.30e-06\n",
      "Epoch  32 [5050/10697 ( 47.2%)] Loss: 0.027678 L1: 0.016598 Grad: 0.110548 Thermal: 0.000509 LR: 3.30e-06\n",
      "Epoch  32 [5100/10697 ( 47.7%)] Loss: 0.028722 L1: 0.016180 Grad: 0.125088 Thermal: 0.000669 LR: 3.30e-06\n",
      "Epoch  32 [5100/10697 ( 47.7%)] Loss: 0.028722 L1: 0.016180 Grad: 0.125088 Thermal: 0.000669 LR: 3.30e-06\n",
      "Epoch  32 [5150/10697 ( 48.1%)] Loss: 0.024161 L1: 0.013995 Grad: 0.101471 Thermal: 0.000381 LR: 3.30e-06\n",
      "Epoch  32 [5150/10697 ( 48.1%)] Loss: 0.024161 L1: 0.013995 Grad: 0.101471 Thermal: 0.000381 LR: 3.30e-06\n",
      "Epoch  32 [5200/10697 ( 48.6%)] Loss: 0.027876 L1: 0.016418 Grad: 0.114328 Thermal: 0.000494 LR: 3.30e-06\n",
      "Epoch  32 [5200/10697 ( 48.6%)] Loss: 0.027876 L1: 0.016418 Grad: 0.114328 Thermal: 0.000494 LR: 3.30e-06\n",
      "Epoch  32 [5250/10697 ( 49.1%)] Loss: 0.028070 L1: 0.016075 Grad: 0.119712 Thermal: 0.000477 LR: 3.30e-06\n",
      "Epoch  32 [5250/10697 ( 49.1%)] Loss: 0.028070 L1: 0.016075 Grad: 0.119712 Thermal: 0.000477 LR: 3.30e-06\n",
      "Epoch  32 [5300/10697 ( 49.5%)] Loss: 0.024698 L1: 0.014057 Grad: 0.106206 Thermal: 0.000407 LR: 3.30e-06\n",
      "Epoch  32 [5300/10697 ( 49.5%)] Loss: 0.024698 L1: 0.014057 Grad: 0.106206 Thermal: 0.000407 LR: 3.30e-06\n",
      "Epoch  32 [5350/10697 ( 50.0%)] Loss: 0.020997 L1: 0.012049 Grad: 0.089329 Thermal: 0.000291 LR: 3.30e-06\n",
      "Epoch  32 [5350/10697 ( 50.0%)] Loss: 0.020997 L1: 0.012049 Grad: 0.089329 Thermal: 0.000291 LR: 3.30e-06\n",
      "Epoch  32 [5400/10697 ( 50.5%)] Loss: 0.026720 L1: 0.014852 Grad: 0.118457 Thermal: 0.000455 LR: 3.30e-06\n",
      "Epoch  32 [5400/10697 ( 50.5%)] Loss: 0.026720 L1: 0.014852 Grad: 0.118457 Thermal: 0.000455 LR: 3.30e-06\n",
      "Epoch  32 [5450/10697 ( 50.9%)] Loss: 0.026984 L1: 0.015724 Grad: 0.112333 Thermal: 0.000523 LR: 3.30e-06\n",
      "Epoch  32 [5450/10697 ( 50.9%)] Loss: 0.026984 L1: 0.015724 Grad: 0.112333 Thermal: 0.000523 LR: 3.30e-06\n",
      "Epoch  32 [5500/10697 ( 51.4%)] Loss: 0.026565 L1: 0.015335 Grad: 0.112082 Thermal: 0.000436 LR: 3.30e-06\n",
      "Epoch  32 [5500/10697 ( 51.4%)] Loss: 0.026565 L1: 0.015335 Grad: 0.112082 Thermal: 0.000436 LR: 3.30e-06\n",
      "Epoch  32 [5550/10697 ( 51.9%)] Loss: 0.034859 L1: 0.020182 Grad: 0.146399 Thermal: 0.000737 LR: 3.30e-06\n",
      "Epoch  32 [5550/10697 ( 51.9%)] Loss: 0.034859 L1: 0.020182 Grad: 0.146399 Thermal: 0.000737 LR: 3.30e-06\n",
      "Epoch  32 [5600/10697 ( 52.4%)] Loss: 0.024838 L1: 0.014865 Grad: 0.099531 Thermal: 0.000401 LR: 3.30e-06\n",
      "Epoch  32 [5600/10697 ( 52.4%)] Loss: 0.024838 L1: 0.014865 Grad: 0.099531 Thermal: 0.000401 LR: 3.30e-06\n",
      "Epoch  32 [5650/10697 ( 52.8%)] Loss: 0.021813 L1: 0.012334 Grad: 0.094641 Thermal: 0.000307 LR: 3.30e-06\n",
      "Epoch  32 [5650/10697 ( 52.8%)] Loss: 0.021813 L1: 0.012334 Grad: 0.094641 Thermal: 0.000307 LR: 3.30e-06\n",
      "Epoch  32 [5700/10697 ( 53.3%)] Loss: 0.027622 L1: 0.016230 Grad: 0.113677 Thermal: 0.000479 LR: 3.30e-06\n",
      "Epoch  32 [5700/10697 ( 53.3%)] Loss: 0.027622 L1: 0.016230 Grad: 0.113677 Thermal: 0.000479 LR: 3.30e-06\n",
      "Epoch  32 [5750/10697 ( 53.8%)] Loss: 0.025176 L1: 0.014609 Grad: 0.105436 Thermal: 0.000454 LR: 3.30e-06\n",
      "Epoch  32 [5750/10697 ( 53.8%)] Loss: 0.025176 L1: 0.014609 Grad: 0.105436 Thermal: 0.000454 LR: 3.30e-06\n",
      "Epoch  32 [5800/10697 ( 54.2%)] Loss: 0.023616 L1: 0.013853 Grad: 0.097454 Thermal: 0.000359 LR: 3.30e-06\n",
      "Epoch  32 [5800/10697 ( 54.2%)] Loss: 0.023616 L1: 0.013853 Grad: 0.097454 Thermal: 0.000359 LR: 3.30e-06\n",
      "Epoch  32 [5850/10697 ( 54.7%)] Loss: 0.024515 L1: 0.014122 Grad: 0.103743 Thermal: 0.000384 LR: 3.30e-06\n",
      "Epoch  32 [5850/10697 ( 54.7%)] Loss: 0.024515 L1: 0.014122 Grad: 0.103743 Thermal: 0.000384 LR: 3.30e-06\n",
      "Epoch  32 [5900/10697 ( 55.2%)] Loss: 0.024808 L1: 0.014307 Grad: 0.104817 Thermal: 0.000384 LR: 3.30e-06\n",
      "Epoch  32 [5900/10697 ( 55.2%)] Loss: 0.024808 L1: 0.014307 Grad: 0.104817 Thermal: 0.000384 LR: 3.30e-06\n",
      "Epoch  32 [5950/10697 ( 55.6%)] Loss: 0.025297 L1: 0.014945 Grad: 0.103319 Thermal: 0.000413 LR: 3.30e-06\n",
      "Epoch  32 [5950/10697 ( 55.6%)] Loss: 0.025297 L1: 0.014945 Grad: 0.103319 Thermal: 0.000413 LR: 3.30e-06\n",
      "Epoch  32 [6000/10697 ( 56.1%)] Loss: 0.024572 L1: 0.014338 Grad: 0.102138 Thermal: 0.000396 LR: 3.30e-06\n",
      "Epoch  32 [6000/10697 ( 56.1%)] Loss: 0.024572 L1: 0.014338 Grad: 0.102138 Thermal: 0.000396 LR: 3.30e-06\n",
      "Epoch  32 [6050/10697 ( 56.6%)] Loss: 0.028195 L1: 0.016326 Grad: 0.118455 Thermal: 0.000472 LR: 3.30e-06\n",
      "Epoch  32 [6050/10697 ( 56.6%)] Loss: 0.028195 L1: 0.016326 Grad: 0.118455 Thermal: 0.000472 LR: 3.30e-06\n",
      "Epoch  32 [6100/10697 ( 57.0%)] Loss: 0.025395 L1: 0.014597 Grad: 0.107764 Thermal: 0.000427 LR: 3.30e-06\n",
      "Epoch  32 [6100/10697 ( 57.0%)] Loss: 0.025395 L1: 0.014597 Grad: 0.107764 Thermal: 0.000427 LR: 3.30e-06\n",
      "Epoch  32 [6150/10697 ( 57.5%)] Loss: 0.025162 L1: 0.014450 Grad: 0.106901 Thermal: 0.000437 LR: 3.30e-06\n",
      "Epoch  32 [6150/10697 ( 57.5%)] Loss: 0.025162 L1: 0.014450 Grad: 0.106901 Thermal: 0.000437 LR: 3.30e-06\n",
      "Epoch  32 [6200/10697 ( 58.0%)] Loss: 0.024709 L1: 0.014865 Grad: 0.098241 Thermal: 0.000400 LR: 3.30e-06\n",
      "Epoch  32 [6200/10697 ( 58.0%)] Loss: 0.024709 L1: 0.014865 Grad: 0.098241 Thermal: 0.000400 LR: 3.30e-06\n",
      "Epoch  32 [6250/10697 ( 58.4%)] Loss: 0.024825 L1: 0.014273 Grad: 0.105335 Thermal: 0.000362 LR: 3.30e-06\n",
      "Epoch  32 [6250/10697 ( 58.4%)] Loss: 0.024825 L1: 0.014273 Grad: 0.105335 Thermal: 0.000362 LR: 3.30e-06\n",
      "Epoch  32 [6300/10697 ( 58.9%)] Loss: 0.025532 L1: 0.014964 Grad: 0.105462 Thermal: 0.000418 LR: 3.30e-06\n",
      "Epoch  32 [6300/10697 ( 58.9%)] Loss: 0.025532 L1: 0.014964 Grad: 0.105462 Thermal: 0.000418 LR: 3.30e-06\n",
      "Epoch  32 [6350/10697 ( 59.4%)] Loss: 0.023220 L1: 0.013550 Grad: 0.096509 Thermal: 0.000367 LR: 3.30e-06\n",
      "Epoch  32 [6350/10697 ( 59.4%)] Loss: 0.023220 L1: 0.013550 Grad: 0.096509 Thermal: 0.000367 LR: 3.30e-06\n",
      "Epoch  32 [6400/10697 ( 59.8%)] Loss: 0.028034 L1: 0.016620 Grad: 0.113890 Thermal: 0.000492 LR: 3.30e-06\n",
      "Epoch  32 [6400/10697 ( 59.8%)] Loss: 0.028034 L1: 0.016620 Grad: 0.113890 Thermal: 0.000492 LR: 3.30e-06\n",
      "Epoch  32 [6450/10697 ( 60.3%)] Loss: 0.030840 L1: 0.017855 Grad: 0.129553 Thermal: 0.000599 LR: 3.30e-06\n",
      "Epoch  32 [6450/10697 ( 60.3%)] Loss: 0.030840 L1: 0.017855 Grad: 0.129553 Thermal: 0.000599 LR: 3.30e-06\n",
      "Epoch  32 [6500/10697 ( 60.8%)] Loss: 0.029841 L1: 0.017569 Grad: 0.122431 Thermal: 0.000585 LR: 3.30e-06\n",
      "Epoch  32 [6500/10697 ( 60.8%)] Loss: 0.029841 L1: 0.017569 Grad: 0.122431 Thermal: 0.000585 LR: 3.30e-06\n",
      "Epoch  32 [6550/10697 ( 61.2%)] Loss: 0.023466 L1: 0.013922 Grad: 0.095255 Thermal: 0.000370 LR: 3.30e-06\n",
      "Epoch  32 [6550/10697 ( 61.2%)] Loss: 0.023466 L1: 0.013922 Grad: 0.095255 Thermal: 0.000370 LR: 3.30e-06\n",
      "Epoch  32 [6600/10697 ( 61.7%)] Loss: 0.020284 L1: 0.011781 Grad: 0.084894 Thermal: 0.000279 LR: 3.30e-06\n",
      "Epoch  32 [6600/10697 ( 61.7%)] Loss: 0.020284 L1: 0.011781 Grad: 0.084894 Thermal: 0.000279 LR: 3.30e-06\n",
      "Epoch  32 [6650/10697 ( 62.2%)] Loss: 0.029116 L1: 0.016475 Grad: 0.126127 Thermal: 0.000565 LR: 3.30e-06\n",
      "Epoch  32 [6650/10697 ( 62.2%)] Loss: 0.029116 L1: 0.016475 Grad: 0.126127 Thermal: 0.000565 LR: 3.30e-06\n",
      "Epoch  32 [6700/10697 ( 62.6%)] Loss: 0.023229 L1: 0.013620 Grad: 0.095896 Thermal: 0.000385 LR: 3.30e-06\n",
      "Epoch  32 [6700/10697 ( 62.6%)] Loss: 0.023229 L1: 0.013620 Grad: 0.095896 Thermal: 0.000385 LR: 3.30e-06\n",
      "Epoch  32 [6750/10697 ( 63.1%)] Loss: 0.020625 L1: 0.011911 Grad: 0.086976 Thermal: 0.000316 LR: 3.30e-06\n",
      "Epoch  32 [6750/10697 ( 63.1%)] Loss: 0.020625 L1: 0.011911 Grad: 0.086976 Thermal: 0.000316 LR: 3.30e-06\n",
      "Epoch  32 [6800/10697 ( 63.6%)] Loss: 0.028963 L1: 0.016791 Grad: 0.121420 Thermal: 0.000612 LR: 3.30e-06\n",
      "Epoch  32 [6800/10697 ( 63.6%)] Loss: 0.028963 L1: 0.016791 Grad: 0.121420 Thermal: 0.000612 LR: 3.30e-06\n",
      "Epoch  32 [6850/10697 ( 64.0%)] Loss: 0.021767 L1: 0.012691 Grad: 0.090602 Thermal: 0.000313 LR: 3.30e-06\n",
      "Epoch  32 [6850/10697 ( 64.0%)] Loss: 0.021767 L1: 0.012691 Grad: 0.090602 Thermal: 0.000313 LR: 3.30e-06\n",
      "Epoch  32 [6900/10697 ( 64.5%)] Loss: 0.022941 L1: 0.013436 Grad: 0.094861 Thermal: 0.000368 LR: 3.30e-06\n",
      "Epoch  32 [6900/10697 ( 64.5%)] Loss: 0.022941 L1: 0.013436 Grad: 0.094861 Thermal: 0.000368 LR: 3.30e-06\n",
      "Epoch  32 [6950/10697 ( 65.0%)] Loss: 0.026057 L1: 0.015660 Grad: 0.103739 Thermal: 0.000446 LR: 3.30e-06\n",
      "Epoch  32 [6950/10697 ( 65.0%)] Loss: 0.026057 L1: 0.015660 Grad: 0.103739 Thermal: 0.000446 LR: 3.30e-06\n",
      "Epoch  32 [7000/10697 ( 65.4%)] Loss: 0.024231 L1: 0.014043 Grad: 0.101702 Thermal: 0.000345 LR: 3.30e-06\n",
      "Epoch  32 [7000/10697 ( 65.4%)] Loss: 0.024231 L1: 0.014043 Grad: 0.101702 Thermal: 0.000345 LR: 3.30e-06\n",
      "Epoch  32 [7050/10697 ( 65.9%)] Loss: 0.016445 L1: 0.009491 Grad: 0.069424 Thermal: 0.000215 LR: 3.30e-06\n",
      "Epoch  32 [7050/10697 ( 65.9%)] Loss: 0.016445 L1: 0.009491 Grad: 0.069424 Thermal: 0.000215 LR: 3.30e-06\n",
      "Epoch  32 [7100/10697 ( 66.4%)] Loss: 0.024965 L1: 0.014693 Grad: 0.102511 Thermal: 0.000414 LR: 3.30e-06\n",
      "Epoch  32 [7100/10697 ( 66.4%)] Loss: 0.024965 L1: 0.014693 Grad: 0.102511 Thermal: 0.000414 LR: 3.30e-06\n",
      "Epoch  32 [7150/10697 ( 66.8%)] Loss: 0.021810 L1: 0.012898 Grad: 0.088955 Thermal: 0.000333 LR: 3.30e-06\n",
      "Epoch  32 [7150/10697 ( 66.8%)] Loss: 0.021810 L1: 0.012898 Grad: 0.088955 Thermal: 0.000333 LR: 3.30e-06\n",
      "Epoch  32 [7200/10697 ( 67.3%)] Loss: 0.022384 L1: 0.013053 Grad: 0.093146 Thermal: 0.000330 LR: 3.30e-06\n",
      "Epoch  32 [7200/10697 ( 67.3%)] Loss: 0.022384 L1: 0.013053 Grad: 0.093146 Thermal: 0.000330 LR: 3.30e-06\n",
      "Epoch  32 [7250/10697 ( 67.8%)] Loss: 0.030314 L1: 0.017551 Grad: 0.127334 Thermal: 0.000599 LR: 3.30e-06\n",
      "Epoch  32 [7250/10697 ( 67.8%)] Loss: 0.030314 L1: 0.017551 Grad: 0.127334 Thermal: 0.000599 LR: 3.30e-06\n",
      "Epoch  32 [7300/10697 ( 68.2%)] Loss: 0.035005 L1: 0.020022 Grad: 0.149379 Thermal: 0.000899 LR: 3.30e-06\n",
      "Epoch  32 [7300/10697 ( 68.2%)] Loss: 0.035005 L1: 0.020022 Grad: 0.149379 Thermal: 0.000899 LR: 3.30e-06\n",
      "Epoch  32 [7350/10697 ( 68.7%)] Loss: 0.022546 L1: 0.013282 Grad: 0.092473 Thermal: 0.000332 LR: 3.30e-06\n",
      "Epoch  32 [7350/10697 ( 68.7%)] Loss: 0.022546 L1: 0.013282 Grad: 0.092473 Thermal: 0.000332 LR: 3.30e-06\n",
      "Epoch  32 [7400/10697 ( 69.2%)] Loss: 0.030430 L1: 0.017381 Grad: 0.130134 Thermal: 0.000714 LR: 3.30e-06\n",
      "Epoch  32 [7400/10697 ( 69.2%)] Loss: 0.030430 L1: 0.017381 Grad: 0.130134 Thermal: 0.000714 LR: 3.30e-06\n",
      "Epoch  32 [7450/10697 ( 69.6%)] Loss: 0.018516 L1: 0.010314 Grad: 0.081892 Thermal: 0.000250 LR: 3.30e-06\n",
      "Epoch  32 [7450/10697 ( 69.6%)] Loss: 0.018516 L1: 0.010314 Grad: 0.081892 Thermal: 0.000250 LR: 3.30e-06\n",
      "Epoch  32 [7500/10697 ( 70.1%)] Loss: 0.018588 L1: 0.010655 Grad: 0.079200 Thermal: 0.000272 LR: 3.30e-06\n",
      "Epoch  32 [7500/10697 ( 70.1%)] Loss: 0.018588 L1: 0.010655 Grad: 0.079200 Thermal: 0.000272 LR: 3.30e-06\n",
      "Epoch  32 [7550/10697 ( 70.6%)] Loss: 0.028502 L1: 0.016450 Grad: 0.120249 Thermal: 0.000549 LR: 3.30e-06\n",
      "Epoch  32 [7550/10697 ( 70.6%)] Loss: 0.028502 L1: 0.016450 Grad: 0.120249 Thermal: 0.000549 LR: 3.30e-06\n",
      "Epoch  32 [7600/10697 ( 71.0%)] Loss: 0.028554 L1: 0.016799 Grad: 0.117294 Thermal: 0.000513 LR: 3.30e-06\n",
      "Epoch  32 [7600/10697 ( 71.0%)] Loss: 0.028554 L1: 0.016799 Grad: 0.117294 Thermal: 0.000513 LR: 3.30e-06\n",
      "Epoch  32 [7650/10697 ( 71.5%)] Loss: 0.025033 L1: 0.014496 Grad: 0.105158 Thermal: 0.000420 LR: 3.30e-06\n",
      "Epoch  32 [7650/10697 ( 71.5%)] Loss: 0.025033 L1: 0.014496 Grad: 0.105158 Thermal: 0.000420 LR: 3.30e-06\n",
      "Epoch  32 [7700/10697 ( 72.0%)] Loss: 0.026555 L1: 0.015181 Grad: 0.113534 Thermal: 0.000405 LR: 3.30e-06\n",
      "Epoch  32 [7700/10697 ( 72.0%)] Loss: 0.026555 L1: 0.015181 Grad: 0.113534 Thermal: 0.000405 LR: 3.30e-06\n",
      "Epoch  32 [7750/10697 ( 72.5%)] Loss: 0.026077 L1: 0.015303 Grad: 0.107532 Thermal: 0.000412 LR: 3.30e-06\n",
      "Epoch  32 [7750/10697 ( 72.5%)] Loss: 0.026077 L1: 0.015303 Grad: 0.107532 Thermal: 0.000412 LR: 3.30e-06\n",
      "Epoch  32 [7800/10697 ( 72.9%)] Loss: 0.025593 L1: 0.014521 Grad: 0.110518 Thermal: 0.000404 LR: 3.30e-06\n",
      "Epoch  32 [7800/10697 ( 72.9%)] Loss: 0.025593 L1: 0.014521 Grad: 0.110518 Thermal: 0.000404 LR: 3.30e-06\n",
      "Epoch  32 [7850/10697 ( 73.4%)] Loss: 0.025795 L1: 0.015208 Grad: 0.105661 Thermal: 0.000420 LR: 3.30e-06\n",
      "Epoch  32 [7850/10697 ( 73.4%)] Loss: 0.025795 L1: 0.015208 Grad: 0.105661 Thermal: 0.000420 LR: 3.30e-06\n",
      "Epoch  32 [7900/10697 ( 73.9%)] Loss: 0.025650 L1: 0.014934 Grad: 0.106952 Thermal: 0.000428 LR: 3.30e-06\n",
      "Epoch  32 [7900/10697 ( 73.9%)] Loss: 0.025650 L1: 0.014934 Grad: 0.106952 Thermal: 0.000428 LR: 3.30e-06\n",
      "Epoch  32 [7950/10697 ( 74.3%)] Loss: 0.022810 L1: 0.013429 Grad: 0.093642 Thermal: 0.000335 LR: 3.30e-06\n",
      "Epoch  32 [7950/10697 ( 74.3%)] Loss: 0.022810 L1: 0.013429 Grad: 0.093642 Thermal: 0.000335 LR: 3.30e-06\n",
      "Epoch  32 [8000/10697 ( 74.8%)] Loss: 0.030918 L1: 0.018165 Grad: 0.127211 Thermal: 0.000650 LR: 3.30e-06\n",
      "Epoch  32 [8000/10697 ( 74.8%)] Loss: 0.030918 L1: 0.018165 Grad: 0.127211 Thermal: 0.000650 LR: 3.30e-06\n",
      "Epoch  32 [8050/10697 ( 75.3%)] Loss: 0.026185 L1: 0.015538 Grad: 0.106248 Thermal: 0.000444 LR: 3.30e-06\n",
      "Epoch  32 [8050/10697 ( 75.3%)] Loss: 0.026185 L1: 0.015538 Grad: 0.106248 Thermal: 0.000444 LR: 3.30e-06\n",
      "Epoch  32 [8100/10697 ( 75.7%)] Loss: 0.027092 L1: 0.015852 Grad: 0.112174 Thermal: 0.000444 LR: 3.30e-06\n",
      "Epoch  32 [8100/10697 ( 75.7%)] Loss: 0.027092 L1: 0.015852 Grad: 0.112174 Thermal: 0.000444 LR: 3.30e-06\n",
      "Epoch  32 [8150/10697 ( 76.2%)] Loss: 0.024703 L1: 0.014327 Grad: 0.103570 Thermal: 0.000385 LR: 3.30e-06\n",
      "Epoch  32 [8150/10697 ( 76.2%)] Loss: 0.024703 L1: 0.014327 Grad: 0.103570 Thermal: 0.000385 LR: 3.30e-06\n",
      "Epoch  32 [8200/10697 ( 76.7%)] Loss: 0.027573 L1: 0.016309 Grad: 0.112358 Thermal: 0.000566 LR: 3.30e-06\n",
      "Epoch  32 [8200/10697 ( 76.7%)] Loss: 0.027573 L1: 0.016309 Grad: 0.112358 Thermal: 0.000566 LR: 3.30e-06\n",
      "Epoch  32 [8250/10697 ( 77.1%)] Loss: 0.020351 L1: 0.011334 Grad: 0.090038 Thermal: 0.000258 LR: 3.30e-06\n",
      "Epoch  32 [8250/10697 ( 77.1%)] Loss: 0.020351 L1: 0.011334 Grad: 0.090038 Thermal: 0.000258 LR: 3.30e-06\n",
      "Epoch  32 [8300/10697 ( 77.6%)] Loss: 0.028199 L1: 0.016938 Grad: 0.112360 Thermal: 0.000505 LR: 3.30e-06\n",
      "Epoch  32 [8300/10697 ( 77.6%)] Loss: 0.028199 L1: 0.016938 Grad: 0.112360 Thermal: 0.000505 LR: 3.30e-06\n",
      "Epoch  32 [8350/10697 ( 78.1%)] Loss: 0.032523 L1: 0.018791 Grad: 0.136976 Thermal: 0.000686 LR: 3.30e-06\n",
      "Epoch  32 [8350/10697 ( 78.1%)] Loss: 0.032523 L1: 0.018791 Grad: 0.136976 Thermal: 0.000686 LR: 3.30e-06\n",
      "Epoch  32 [8400/10697 ( 78.5%)] Loss: 0.028756 L1: 0.016119 Grad: 0.126144 Thermal: 0.000467 LR: 3.30e-06\n",
      "Epoch  32 [8400/10697 ( 78.5%)] Loss: 0.028756 L1: 0.016119 Grad: 0.126144 Thermal: 0.000467 LR: 3.30e-06\n",
      "Epoch  32 [8450/10697 ( 79.0%)] Loss: 0.024949 L1: 0.014682 Grad: 0.102472 Thermal: 0.000398 LR: 3.30e-06\n",
      "Epoch  32 [8450/10697 ( 79.0%)] Loss: 0.024949 L1: 0.014682 Grad: 0.102472 Thermal: 0.000398 LR: 3.30e-06\n",
      "Epoch  32 [8500/10697 ( 79.5%)] Loss: 0.028469 L1: 0.016407 Grad: 0.120321 Thermal: 0.000606 LR: 3.30e-06\n",
      "Epoch  32 [8500/10697 ( 79.5%)] Loss: 0.028469 L1: 0.016407 Grad: 0.120321 Thermal: 0.000606 LR: 3.30e-06\n",
      "Epoch  32 [8550/10697 ( 79.9%)] Loss: 0.025529 L1: 0.015486 Grad: 0.100221 Thermal: 0.000421 LR: 3.30e-06\n",
      "Epoch  32 [8550/10697 ( 79.9%)] Loss: 0.025529 L1: 0.015486 Grad: 0.100221 Thermal: 0.000421 LR: 3.30e-06\n",
      "Epoch  32 [8600/10697 ( 80.4%)] Loss: 0.025769 L1: 0.015143 Grad: 0.106007 Thermal: 0.000505 LR: 3.30e-06\n",
      "Epoch  32 [8600/10697 ( 80.4%)] Loss: 0.025769 L1: 0.015143 Grad: 0.106007 Thermal: 0.000505 LR: 3.30e-06\n",
      "Epoch  32 [8650/10697 ( 80.9%)] Loss: 0.019970 L1: 0.011484 Grad: 0.084710 Thermal: 0.000302 LR: 3.30e-06\n",
      "Epoch  32 [8650/10697 ( 80.9%)] Loss: 0.019970 L1: 0.011484 Grad: 0.084710 Thermal: 0.000302 LR: 3.30e-06\n",
      "Epoch  32 [8700/10697 ( 81.3%)] Loss: 0.029747 L1: 0.017120 Grad: 0.126010 Thermal: 0.000523 LR: 3.30e-06\n",
      "Epoch  32 [8700/10697 ( 81.3%)] Loss: 0.029747 L1: 0.017120 Grad: 0.126010 Thermal: 0.000523 LR: 3.30e-06\n",
      "Epoch  32 [8750/10697 ( 81.8%)] Loss: 0.025400 L1: 0.014861 Grad: 0.105180 Thermal: 0.000415 LR: 3.30e-06\n",
      "Epoch  32 [8750/10697 ( 81.8%)] Loss: 0.025400 L1: 0.014861 Grad: 0.105180 Thermal: 0.000415 LR: 3.30e-06\n",
      "Epoch  32 [8800/10697 ( 82.3%)] Loss: 0.028147 L1: 0.016626 Grad: 0.114955 Thermal: 0.000510 LR: 3.30e-06\n",
      "Epoch  32 [8800/10697 ( 82.3%)] Loss: 0.028147 L1: 0.016626 Grad: 0.114955 Thermal: 0.000510 LR: 3.30e-06\n",
      "Epoch  32 [8850/10697 ( 82.7%)] Loss: 0.030344 L1: 0.017598 Grad: 0.127209 Thermal: 0.000521 LR: 3.30e-06\n",
      "Epoch  32 [8850/10697 ( 82.7%)] Loss: 0.030344 L1: 0.017598 Grad: 0.127209 Thermal: 0.000521 LR: 3.30e-06\n",
      "Epoch  32 [8900/10697 ( 83.2%)] Loss: 0.025485 L1: 0.014659 Grad: 0.108047 Thermal: 0.000427 LR: 3.30e-06\n",
      "Epoch  32 [8900/10697 ( 83.2%)] Loss: 0.025485 L1: 0.014659 Grad: 0.108047 Thermal: 0.000427 LR: 3.30e-06\n",
      "Epoch  32 [8950/10697 ( 83.7%)] Loss: 0.031779 L1: 0.018330 Grad: 0.134207 Thermal: 0.000566 LR: 3.30e-06\n",
      "Epoch  32 [8950/10697 ( 83.7%)] Loss: 0.031779 L1: 0.018330 Grad: 0.134207 Thermal: 0.000566 LR: 3.30e-06\n",
      "Epoch  32 [9000/10697 ( 84.1%)] Loss: 0.020028 L1: 0.011646 Grad: 0.083666 Thermal: 0.000306 LR: 3.30e-06\n",
      "Epoch  32 [9000/10697 ( 84.1%)] Loss: 0.020028 L1: 0.011646 Grad: 0.083666 Thermal: 0.000306 LR: 3.30e-06\n",
      "Epoch  32 [9050/10697 ( 84.6%)] Loss: 0.026882 L1: 0.015723 Grad: 0.111376 Thermal: 0.000439 LR: 3.30e-06\n",
      "Epoch  32 [9050/10697 ( 84.6%)] Loss: 0.026882 L1: 0.015723 Grad: 0.111376 Thermal: 0.000439 LR: 3.30e-06\n",
      "Epoch  32 [9100/10697 ( 85.1%)] Loss: 0.025873 L1: 0.015000 Grad: 0.108516 Thermal: 0.000418 LR: 3.30e-06\n",
      "Epoch  32 [9100/10697 ( 85.1%)] Loss: 0.025873 L1: 0.015000 Grad: 0.108516 Thermal: 0.000418 LR: 3.30e-06\n",
      "Epoch  32 [9150/10697 ( 85.5%)] Loss: 0.026491 L1: 0.015243 Grad: 0.112217 Thermal: 0.000537 LR: 3.30e-06\n",
      "Epoch  32 [9150/10697 ( 85.5%)] Loss: 0.026491 L1: 0.015243 Grad: 0.112217 Thermal: 0.000537 LR: 3.30e-06\n",
      "Epoch  32 [9200/10697 ( 86.0%)] Loss: 0.030434 L1: 0.017202 Grad: 0.132032 Thermal: 0.000587 LR: 3.30e-06\n",
      "Epoch  32 [9200/10697 ( 86.0%)] Loss: 0.030434 L1: 0.017202 Grad: 0.132032 Thermal: 0.000587 LR: 3.30e-06\n",
      "Epoch  32 [9250/10697 ( 86.5%)] Loss: 0.024414 L1: 0.014390 Grad: 0.100044 Thermal: 0.000387 LR: 3.30e-06\n",
      "Epoch  32 [9250/10697 ( 86.5%)] Loss: 0.024414 L1: 0.014390 Grad: 0.100044 Thermal: 0.000387 LR: 3.30e-06\n",
      "Epoch  32 [9300/10697 ( 86.9%)] Loss: 0.015587 L1: 0.009006 Grad: 0.065710 Thermal: 0.000201 LR: 3.30e-06\n",
      "Epoch  32 [9300/10697 ( 86.9%)] Loss: 0.015587 L1: 0.009006 Grad: 0.065710 Thermal: 0.000201 LR: 3.30e-06\n",
      "Epoch  32 [9350/10697 ( 87.4%)] Loss: 0.023904 L1: 0.013820 Grad: 0.100645 Thermal: 0.000373 LR: 3.30e-06\n",
      "Epoch  32 [9350/10697 ( 87.4%)] Loss: 0.023904 L1: 0.013820 Grad: 0.100645 Thermal: 0.000373 LR: 3.30e-06\n",
      "Epoch  32 [9400/10697 ( 87.9%)] Loss: 0.033559 L1: 0.019172 Grad: 0.143485 Thermal: 0.000780 LR: 3.30e-06\n",
      "Epoch  32 [9400/10697 ( 87.9%)] Loss: 0.033559 L1: 0.019172 Grad: 0.143485 Thermal: 0.000780 LR: 3.30e-06\n",
      "Epoch  32 [9450/10697 ( 88.3%)] Loss: 0.025060 L1: 0.014900 Grad: 0.101404 Thermal: 0.000402 LR: 3.30e-06\n",
      "Epoch  32 [9450/10697 ( 88.3%)] Loss: 0.025060 L1: 0.014900 Grad: 0.101404 Thermal: 0.000402 LR: 3.30e-06\n",
      "Epoch  32 [9500/10697 ( 88.8%)] Loss: 0.026290 L1: 0.015385 Grad: 0.108839 Thermal: 0.000426 LR: 3.30e-06\n",
      "Epoch  32 [9500/10697 ( 88.8%)] Loss: 0.026290 L1: 0.015385 Grad: 0.108839 Thermal: 0.000426 LR: 3.30e-06\n",
      "Epoch  32 [9550/10697 ( 89.3%)] Loss: 0.023231 L1: 0.013199 Grad: 0.100125 Thermal: 0.000387 LR: 3.30e-06\n",
      "Epoch  32 [9550/10697 ( 89.3%)] Loss: 0.023231 L1: 0.013199 Grad: 0.100125 Thermal: 0.000387 LR: 3.30e-06\n",
      "Epoch  32 [9600/10697 ( 89.7%)] Loss: 0.027844 L1: 0.016522 Grad: 0.112979 Thermal: 0.000486 LR: 3.30e-06\n",
      "Epoch  32 [9600/10697 ( 89.7%)] Loss: 0.027844 L1: 0.016522 Grad: 0.112979 Thermal: 0.000486 LR: 3.30e-06\n",
      "Epoch  32 [9650/10697 ( 90.2%)] Loss: 0.017672 L1: 0.010250 Grad: 0.074097 Thermal: 0.000252 LR: 3.30e-06\n",
      "Epoch  32 [9650/10697 ( 90.2%)] Loss: 0.017672 L1: 0.010250 Grad: 0.074097 Thermal: 0.000252 LR: 3.30e-06\n",
      "Epoch  32 [9700/10697 ( 90.7%)] Loss: 0.023314 L1: 0.013664 Grad: 0.096296 Thermal: 0.000403 LR: 3.30e-06\n",
      "Epoch  32 [9700/10697 ( 90.7%)] Loss: 0.023314 L1: 0.013664 Grad: 0.096296 Thermal: 0.000403 LR: 3.30e-06\n",
      "Epoch  32 [9750/10697 ( 91.1%)] Loss: 0.020459 L1: 0.011685 Grad: 0.087593 Thermal: 0.000287 LR: 3.30e-06\n",
      "Epoch  32 [9750/10697 ( 91.1%)] Loss: 0.020459 L1: 0.011685 Grad: 0.087593 Thermal: 0.000287 LR: 3.30e-06\n",
      "Epoch  32 [9800/10697 ( 91.6%)] Loss: 0.028154 L1: 0.016885 Grad: 0.112437 Thermal: 0.000510 LR: 3.30e-06\n",
      "Epoch  32 [9800/10697 ( 91.6%)] Loss: 0.028154 L1: 0.016885 Grad: 0.112437 Thermal: 0.000510 LR: 3.30e-06\n",
      "Epoch  32 [9850/10697 ( 92.1%)] Loss: 0.029093 L1: 0.016633 Grad: 0.124337 Thermal: 0.000530 LR: 3.30e-06\n",
      "Epoch  32 [9850/10697 ( 92.1%)] Loss: 0.029093 L1: 0.016633 Grad: 0.124337 Thermal: 0.000530 LR: 3.30e-06\n",
      "Epoch  32 [9900/10697 ( 92.5%)] Loss: 0.019063 L1: 0.010946 Grad: 0.081042 Thermal: 0.000261 LR: 3.30e-06\n",
      "Epoch  32 [9900/10697 ( 92.5%)] Loss: 0.019063 L1: 0.010946 Grad: 0.081042 Thermal: 0.000261 LR: 3.30e-06\n",
      "Epoch  32 [9950/10697 ( 93.0%)] Loss: 0.023470 L1: 0.013808 Grad: 0.096435 Thermal: 0.000366 LR: 3.30e-06\n",
      "Epoch  32 [9950/10697 ( 93.0%)] Loss: 0.023470 L1: 0.013808 Grad: 0.096435 Thermal: 0.000366 LR: 3.30e-06\n",
      "Epoch  32 [10000/10697 ( 93.5%)] Loss: 0.032005 L1: 0.018447 Grad: 0.135289 Thermal: 0.000589 LR: 3.30e-06\n",
      "Epoch  32 [10000/10697 ( 93.5%)] Loss: 0.032005 L1: 0.018447 Grad: 0.135289 Thermal: 0.000589 LR: 3.30e-06\n",
      "Epoch  32 [10050/10697 ( 94.0%)] Loss: 0.020518 L1: 0.011944 Grad: 0.085582 Thermal: 0.000319 LR: 3.30e-06\n",
      "Epoch  32 [10050/10697 ( 94.0%)] Loss: 0.020518 L1: 0.011944 Grad: 0.085582 Thermal: 0.000319 LR: 3.30e-06\n",
      "Epoch  32 [10100/10697 ( 94.4%)] Loss: 0.028766 L1: 0.017019 Grad: 0.117212 Thermal: 0.000518 LR: 3.30e-06\n",
      "Epoch  32 [10100/10697 ( 94.4%)] Loss: 0.028766 L1: 0.017019 Grad: 0.117212 Thermal: 0.000518 LR: 3.30e-06\n",
      "Epoch  32 [10150/10697 ( 94.9%)] Loss: 0.026571 L1: 0.015821 Grad: 0.107283 Thermal: 0.000436 LR: 3.30e-06\n",
      "Epoch  32 [10150/10697 ( 94.9%)] Loss: 0.026571 L1: 0.015821 Grad: 0.107283 Thermal: 0.000436 LR: 3.30e-06\n",
      "Epoch  32 [10200/10697 ( 95.4%)] Loss: 0.026969 L1: 0.015836 Grad: 0.111098 Thermal: 0.000457 LR: 3.30e-06\n",
      "Epoch  32 [10200/10697 ( 95.4%)] Loss: 0.026969 L1: 0.015836 Grad: 0.111098 Thermal: 0.000457 LR: 3.30e-06\n",
      "Epoch  32 [10250/10697 ( 95.8%)] Loss: 0.033486 L1: 0.019418 Grad: 0.140330 Thermal: 0.000698 LR: 3.30e-06\n",
      "Epoch  32 [10250/10697 ( 95.8%)] Loss: 0.033486 L1: 0.019418 Grad: 0.140330 Thermal: 0.000698 LR: 3.30e-06\n",
      "Epoch  32 [10300/10697 ( 96.3%)] Loss: 0.025977 L1: 0.015015 Grad: 0.109397 Thermal: 0.000459 LR: 3.30e-06\n",
      "Epoch  32 [10300/10697 ( 96.3%)] Loss: 0.025977 L1: 0.015015 Grad: 0.109397 Thermal: 0.000459 LR: 3.30e-06\n",
      "Epoch  32 [10350/10697 ( 96.8%)] Loss: 0.029265 L1: 0.017379 Grad: 0.118595 Thermal: 0.000544 LR: 3.30e-06\n",
      "Epoch  32 [10350/10697 ( 96.8%)] Loss: 0.029265 L1: 0.017379 Grad: 0.118595 Thermal: 0.000544 LR: 3.30e-06\n",
      "Epoch  32 [10400/10697 ( 97.2%)] Loss: 0.024582 L1: 0.014681 Grad: 0.098806 Thermal: 0.000406 LR: 3.30e-06\n",
      "Epoch  32 [10400/10697 ( 97.2%)] Loss: 0.024582 L1: 0.014681 Grad: 0.098806 Thermal: 0.000406 LR: 3.30e-06\n",
      "Epoch  32 [10450/10697 ( 97.7%)] Loss: 0.030625 L1: 0.018623 Grad: 0.119655 Thermal: 0.000720 LR: 3.30e-06\n",
      "Epoch  32 [10450/10697 ( 97.7%)] Loss: 0.030625 L1: 0.018623 Grad: 0.119655 Thermal: 0.000720 LR: 3.30e-06\n",
      "Epoch  32 [10500/10697 ( 98.2%)] Loss: 0.027840 L1: 0.016196 Grad: 0.116190 Thermal: 0.000504 LR: 3.30e-06\n",
      "Epoch  32 [10500/10697 ( 98.2%)] Loss: 0.027840 L1: 0.016196 Grad: 0.116190 Thermal: 0.000504 LR: 3.30e-06\n",
      "Epoch  32 [10550/10697 ( 98.6%)] Loss: 0.026204 L1: 0.015364 Grad: 0.108158 Thermal: 0.000477 LR: 3.30e-06\n",
      "Epoch  32 [10550/10697 ( 98.6%)] Loss: 0.026204 L1: 0.015364 Grad: 0.108158 Thermal: 0.000477 LR: 3.30e-06\n",
      "Epoch  32 [10600/10697 ( 99.1%)] Loss: 0.026496 L1: 0.015274 Grad: 0.112000 Thermal: 0.000441 LR: 3.30e-06\n",
      "Epoch  32 [10600/10697 ( 99.1%)] Loss: 0.026496 L1: 0.015274 Grad: 0.112000 Thermal: 0.000441 LR: 3.30e-06\n",
      "Epoch  32 [10650/10697 ( 99.6%)] Loss: 0.035565 L1: 0.020097 Grad: 0.154288 Thermal: 0.000771 LR: 3.30e-06\n",
      "Epoch  32 [10650/10697 ( 99.6%)] Loss: 0.035565 L1: 0.020097 Grad: 0.154288 Thermal: 0.000771 LR: 3.30e-06\n",
      "Epoch  32 Summary: Loss=0.026279 (L1:0.0153, Grad:0.1093, Thermal:0.0005) Val_PSNR=0.00dB Best=33.96dB Time=123.4min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  32 Summary: Loss=0.026279 (L1:0.0153, Grad:0.1093, Thermal:0.0005) Val_PSNR=0.00dB Best=33.96dB Time=123.4min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  33 [   0/10697 (  0.0%)] Loss: 0.022794 L1: 0.013429 Grad: 0.093473 Thermal: 0.000351 LR: 3.21e-06\n",
      "Epoch  33 [   0/10697 (  0.0%)] Loss: 0.022794 L1: 0.013429 Grad: 0.093473 Thermal: 0.000351 LR: 3.21e-06\n",
      "Epoch  33 [  50/10697 (  0.5%)] Loss: 0.026337 L1: 0.015644 Grad: 0.106706 Thermal: 0.000431 LR: 3.21e-06\n",
      "Epoch  33 [  50/10697 (  0.5%)] Loss: 0.026337 L1: 0.015644 Grad: 0.106706 Thermal: 0.000431 LR: 3.21e-06\n",
      "Epoch  33 [ 100/10697 (  0.9%)] Loss: 0.027942 L1: 0.016337 Grad: 0.115799 Thermal: 0.000503 LR: 3.21e-06\n",
      "Epoch  33 [ 100/10697 (  0.9%)] Loss: 0.027942 L1: 0.016337 Grad: 0.115799 Thermal: 0.000503 LR: 3.21e-06\n",
      "Epoch  33 [ 150/10697 (  1.4%)] Loss: 0.026233 L1: 0.015229 Grad: 0.109831 Thermal: 0.000411 LR: 3.21e-06\n",
      "Epoch  33 [ 150/10697 (  1.4%)] Loss: 0.026233 L1: 0.015229 Grad: 0.109831 Thermal: 0.000411 LR: 3.21e-06\n",
      "Epoch  33 [ 200/10697 (  1.9%)] Loss: 0.021633 L1: 0.012420 Grad: 0.091982 Thermal: 0.000313 LR: 3.21e-06\n",
      "Epoch  33 [ 200/10697 (  1.9%)] Loss: 0.021633 L1: 0.012420 Grad: 0.091982 Thermal: 0.000313 LR: 3.21e-06\n",
      "Epoch  33 [ 250/10697 (  2.3%)] Loss: 0.029982 L1: 0.017655 Grad: 0.122978 Thermal: 0.000583 LR: 3.21e-06\n",
      "Epoch  33 [ 250/10697 (  2.3%)] Loss: 0.029982 L1: 0.017655 Grad: 0.122978 Thermal: 0.000583 LR: 3.21e-06\n",
      "Epoch  33 [ 300/10697 (  2.8%)] Loss: 0.026245 L1: 0.015253 Grad: 0.109703 Thermal: 0.000427 LR: 3.21e-06\n",
      "Epoch  33 [ 300/10697 (  2.8%)] Loss: 0.026245 L1: 0.015253 Grad: 0.109703 Thermal: 0.000427 LR: 3.21e-06\n",
      "Epoch  33 [ 350/10697 (  3.3%)] Loss: 0.022791 L1: 0.013003 Grad: 0.097708 Thermal: 0.000341 LR: 3.21e-06\n",
      "Epoch  33 [ 350/10697 (  3.3%)] Loss: 0.022791 L1: 0.013003 Grad: 0.097708 Thermal: 0.000341 LR: 3.21e-06\n",
      "Epoch  33 [ 400/10697 (  3.7%)] Loss: 0.024936 L1: 0.014427 Grad: 0.104889 Thermal: 0.000401 LR: 3.21e-06\n",
      "Epoch  33 [ 400/10697 (  3.7%)] Loss: 0.024936 L1: 0.014427 Grad: 0.104889 Thermal: 0.000401 LR: 3.21e-06\n",
      "Epoch  33 [ 450/10697 (  4.2%)] Loss: 0.034337 L1: 0.019657 Grad: 0.146407 Thermal: 0.000770 LR: 3.21e-06\n",
      "Epoch  33 [ 450/10697 (  4.2%)] Loss: 0.034337 L1: 0.019657 Grad: 0.146407 Thermal: 0.000770 LR: 3.21e-06\n",
      "Epoch  33 [ 500/10697 (  4.7%)] Loss: 0.026740 L1: 0.015443 Grad: 0.112741 Thermal: 0.000457 LR: 3.21e-06\n",
      "Epoch  33 [ 500/10697 (  4.7%)] Loss: 0.026740 L1: 0.015443 Grad: 0.112741 Thermal: 0.000457 LR: 3.21e-06\n",
      "Epoch  33 [ 550/10697 (  5.1%)] Loss: 0.023057 L1: 0.013524 Grad: 0.095153 Thermal: 0.000360 LR: 3.21e-06\n",
      "Epoch  33 [ 550/10697 (  5.1%)] Loss: 0.023057 L1: 0.013524 Grad: 0.095153 Thermal: 0.000360 LR: 3.21e-06\n",
      "Epoch  33 [ 600/10697 (  5.6%)] Loss: 0.022397 L1: 0.013411 Grad: 0.089680 Thermal: 0.000356 LR: 3.21e-06\n",
      "Epoch  33 [ 600/10697 (  5.6%)] Loss: 0.022397 L1: 0.013411 Grad: 0.089680 Thermal: 0.000356 LR: 3.21e-06\n",
      "Epoch  33 [ 650/10697 (  6.1%)] Loss: 0.023739 L1: 0.013607 Grad: 0.101119 Thermal: 0.000401 LR: 3.21e-06\n",
      "Epoch  33 [ 650/10697 (  6.1%)] Loss: 0.023739 L1: 0.013607 Grad: 0.101119 Thermal: 0.000401 LR: 3.21e-06\n",
      "Epoch  33 [ 700/10697 (  6.5%)] Loss: 0.023741 L1: 0.013839 Grad: 0.098845 Thermal: 0.000355 LR: 3.21e-06\n",
      "Epoch  33 [ 700/10697 (  6.5%)] Loss: 0.023741 L1: 0.013839 Grad: 0.098845 Thermal: 0.000355 LR: 3.21e-06\n",
      "Epoch  33 [ 750/10697 (  7.0%)] Loss: 0.022704 L1: 0.012726 Grad: 0.099604 Thermal: 0.000356 LR: 3.21e-06\n",
      "Epoch  33 [ 750/10697 (  7.0%)] Loss: 0.022704 L1: 0.012726 Grad: 0.099604 Thermal: 0.000356 LR: 3.21e-06\n",
      "Epoch  33 [ 800/10697 (  7.5%)] Loss: 0.024186 L1: 0.014278 Grad: 0.098875 Thermal: 0.000410 LR: 3.21e-06\n",
      "Epoch  33 [ 800/10697 (  7.5%)] Loss: 0.024186 L1: 0.014278 Grad: 0.098875 Thermal: 0.000410 LR: 3.21e-06\n",
      "Epoch  33 [ 850/10697 (  7.9%)] Loss: 0.024060 L1: 0.013962 Grad: 0.100777 Thermal: 0.000421 LR: 3.21e-06\n",
      "Epoch  33 [ 850/10697 (  7.9%)] Loss: 0.024060 L1: 0.013962 Grad: 0.100777 Thermal: 0.000421 LR: 3.21e-06\n",
      "Epoch  33 [ 900/10697 (  8.4%)] Loss: 0.025804 L1: 0.014944 Grad: 0.108388 Thermal: 0.000413 LR: 3.21e-06\n",
      "Epoch  33 [ 900/10697 (  8.4%)] Loss: 0.025804 L1: 0.014944 Grad: 0.108388 Thermal: 0.000413 LR: 3.21e-06\n",
      "Epoch  33 [ 950/10697 (  8.9%)] Loss: 0.022931 L1: 0.013380 Grad: 0.095345 Thermal: 0.000334 LR: 3.21e-06\n",
      "Epoch  33 [ 950/10697 (  8.9%)] Loss: 0.022931 L1: 0.013380 Grad: 0.095345 Thermal: 0.000334 LR: 3.21e-06\n",
      "Epoch  33 [1000/10697 (  9.3%)] Loss: 0.023957 L1: 0.014194 Grad: 0.097436 Thermal: 0.000393 LR: 3.21e-06\n",
      "Epoch  33 [1000/10697 (  9.3%)] Loss: 0.023957 L1: 0.014194 Grad: 0.097436 Thermal: 0.000393 LR: 3.21e-06\n",
      "Epoch  33 [1050/10697 (  9.8%)] Loss: 0.022933 L1: 0.013693 Grad: 0.092213 Thermal: 0.000361 LR: 3.21e-06\n",
      "Epoch  33 [1050/10697 (  9.8%)] Loss: 0.022933 L1: 0.013693 Grad: 0.092213 Thermal: 0.000361 LR: 3.21e-06\n",
      "Epoch  33 [1100/10697 ( 10.3%)] Loss: 0.027952 L1: 0.016360 Grad: 0.115656 Thermal: 0.000530 LR: 3.21e-06\n",
      "Epoch  33 [1100/10697 ( 10.3%)] Loss: 0.027952 L1: 0.016360 Grad: 0.115656 Thermal: 0.000530 LR: 3.21e-06\n",
      "Epoch  33 [1150/10697 ( 10.8%)] Loss: 0.019510 L1: 0.011409 Grad: 0.080874 Thermal: 0.000271 LR: 3.21e-06\n",
      "Epoch  33 [1150/10697 ( 10.8%)] Loss: 0.019510 L1: 0.011409 Grad: 0.080874 Thermal: 0.000271 LR: 3.21e-06\n",
      "Epoch  33 [1200/10697 ( 11.2%)] Loss: 0.024781 L1: 0.014393 Grad: 0.103695 Thermal: 0.000387 LR: 3.21e-06\n",
      "Epoch  33 [1200/10697 ( 11.2%)] Loss: 0.024781 L1: 0.014393 Grad: 0.103695 Thermal: 0.000387 LR: 3.21e-06\n",
      "Epoch  33 [1250/10697 ( 11.7%)] Loss: 0.025918 L1: 0.015378 Grad: 0.105183 Thermal: 0.000436 LR: 3.21e-06\n",
      "Epoch  33 [1250/10697 ( 11.7%)] Loss: 0.025918 L1: 0.015378 Grad: 0.105183 Thermal: 0.000436 LR: 3.21e-06\n",
      "Epoch  33 [1300/10697 ( 12.2%)] Loss: 0.023365 L1: 0.013841 Grad: 0.095056 Thermal: 0.000364 LR: 3.21e-06\n",
      "Epoch  33 [1300/10697 ( 12.2%)] Loss: 0.023365 L1: 0.013841 Grad: 0.095056 Thermal: 0.000364 LR: 3.21e-06\n",
      "Epoch  33 [1350/10697 ( 12.6%)] Loss: 0.023130 L1: 0.013723 Grad: 0.093887 Thermal: 0.000359 LR: 3.21e-06\n",
      "Epoch  33 [1350/10697 ( 12.6%)] Loss: 0.023130 L1: 0.013723 Grad: 0.093887 Thermal: 0.000359 LR: 3.21e-06\n",
      "Epoch  33 [1400/10697 ( 13.1%)] Loss: 0.025662 L1: 0.014511 Grad: 0.111309 Thermal: 0.000395 LR: 3.21e-06\n",
      "Epoch  33 [1400/10697 ( 13.1%)] Loss: 0.025662 L1: 0.014511 Grad: 0.111309 Thermal: 0.000395 LR: 3.21e-06\n",
      "Epoch  33 [1450/10697 ( 13.6%)] Loss: 0.025172 L1: 0.014841 Grad: 0.103078 Thermal: 0.000454 LR: 3.21e-06\n",
      "Epoch  33 [1450/10697 ( 13.6%)] Loss: 0.025172 L1: 0.014841 Grad: 0.103078 Thermal: 0.000454 LR: 3.21e-06\n",
      "Epoch  33 [1500/10697 ( 14.0%)] Loss: 0.028100 L1: 0.016305 Grad: 0.117659 Thermal: 0.000578 LR: 3.21e-06\n",
      "Epoch  33 [1500/10697 ( 14.0%)] Loss: 0.028100 L1: 0.016305 Grad: 0.117659 Thermal: 0.000578 LR: 3.21e-06\n",
      "Epoch  33 [1550/10697 ( 14.5%)] Loss: 0.023765 L1: 0.013825 Grad: 0.099191 Thermal: 0.000414 LR: 3.21e-06\n",
      "Epoch  33 [1550/10697 ( 14.5%)] Loss: 0.023765 L1: 0.013825 Grad: 0.099191 Thermal: 0.000414 LR: 3.21e-06\n",
      "Epoch  33 [1600/10697 ( 15.0%)] Loss: 0.025013 L1: 0.014407 Grad: 0.105880 Thermal: 0.000374 LR: 3.21e-06\n",
      "Epoch  33 [1600/10697 ( 15.0%)] Loss: 0.025013 L1: 0.014407 Grad: 0.105880 Thermal: 0.000374 LR: 3.21e-06\n",
      "Epoch  33 [1650/10697 ( 15.4%)] Loss: 0.027698 L1: 0.016293 Grad: 0.113809 Thermal: 0.000494 LR: 3.21e-06\n",
      "Epoch  33 [1650/10697 ( 15.4%)] Loss: 0.027698 L1: 0.016293 Grad: 0.113809 Thermal: 0.000494 LR: 3.21e-06\n",
      "Epoch  33 [1700/10697 ( 15.9%)] Loss: 0.024579 L1: 0.014689 Grad: 0.098703 Thermal: 0.000404 LR: 3.21e-06\n",
      "Epoch  33 [1700/10697 ( 15.9%)] Loss: 0.024579 L1: 0.014689 Grad: 0.098703 Thermal: 0.000404 LR: 3.21e-06\n",
      "Epoch  33 [1750/10697 ( 16.4%)] Loss: 0.016792 L1: 0.009677 Grad: 0.071050 Thermal: 0.000210 LR: 3.21e-06\n",
      "Epoch  33 [1750/10697 ( 16.4%)] Loss: 0.016792 L1: 0.009677 Grad: 0.071050 Thermal: 0.000210 LR: 3.21e-06\n",
      "Epoch  33 [1800/10697 ( 16.8%)] Loss: 0.023335 L1: 0.013621 Grad: 0.096961 Thermal: 0.000369 LR: 3.21e-06\n",
      "Epoch  33 [1800/10697 ( 16.8%)] Loss: 0.023335 L1: 0.013621 Grad: 0.096961 Thermal: 0.000369 LR: 3.21e-06\n",
      "Epoch  33 [1850/10697 ( 17.3%)] Loss: 0.027398 L1: 0.016502 Grad: 0.108717 Thermal: 0.000486 LR: 3.21e-06\n",
      "Epoch  33 [1850/10697 ( 17.3%)] Loss: 0.027398 L1: 0.016502 Grad: 0.108717 Thermal: 0.000486 LR: 3.21e-06\n",
      "Epoch  33 [1900/10697 ( 17.8%)] Loss: 0.024763 L1: 0.014740 Grad: 0.100041 Thermal: 0.000382 LR: 3.21e-06\n",
      "Epoch  33 [1900/10697 ( 17.8%)] Loss: 0.024763 L1: 0.014740 Grad: 0.100041 Thermal: 0.000382 LR: 3.21e-06\n",
      "Epoch  33 [1950/10697 ( 18.2%)] Loss: 0.026684 L1: 0.015740 Grad: 0.109205 Thermal: 0.000477 LR: 3.21e-06\n",
      "Epoch  33 [1950/10697 ( 18.2%)] Loss: 0.026684 L1: 0.015740 Grad: 0.109205 Thermal: 0.000477 LR: 3.21e-06\n",
      "Epoch  33 [2000/10697 ( 18.7%)] Loss: 0.026933 L1: 0.016046 Grad: 0.108639 Thermal: 0.000459 LR: 3.21e-06\n",
      "Epoch  33 [2000/10697 ( 18.7%)] Loss: 0.026933 L1: 0.016046 Grad: 0.108639 Thermal: 0.000459 LR: 3.21e-06\n",
      "Epoch  33 [2050/10697 ( 19.2%)] Loss: 0.027038 L1: 0.015798 Grad: 0.112169 Thermal: 0.000464 LR: 3.21e-06\n",
      "Epoch  33 [2050/10697 ( 19.2%)] Loss: 0.027038 L1: 0.015798 Grad: 0.112169 Thermal: 0.000464 LR: 3.21e-06\n",
      "Epoch  33 [2100/10697 ( 19.6%)] Loss: 0.024463 L1: 0.013832 Grad: 0.106097 Thermal: 0.000426 LR: 3.21e-06\n",
      "Epoch  33 [2100/10697 ( 19.6%)] Loss: 0.024463 L1: 0.013832 Grad: 0.106097 Thermal: 0.000426 LR: 3.21e-06\n",
      "Epoch  33 [2150/10697 ( 20.1%)] Loss: 0.030154 L1: 0.017615 Grad: 0.125109 Thermal: 0.000559 LR: 3.21e-06\n",
      "Epoch  33 [2150/10697 ( 20.1%)] Loss: 0.030154 L1: 0.017615 Grad: 0.125109 Thermal: 0.000559 LR: 3.21e-06\n",
      "Epoch  33 [2200/10697 ( 20.6%)] Loss: 0.025921 L1: 0.015503 Grad: 0.103950 Thermal: 0.000447 LR: 3.21e-06\n",
      "Epoch  33 [2200/10697 ( 20.6%)] Loss: 0.025921 L1: 0.015503 Grad: 0.103950 Thermal: 0.000447 LR: 3.21e-06\n",
      "Epoch  33 [2250/10697 ( 21.0%)] Loss: 0.030866 L1: 0.018089 Grad: 0.127478 Thermal: 0.000585 LR: 3.21e-06\n",
      "Epoch  33 [2250/10697 ( 21.0%)] Loss: 0.030866 L1: 0.018089 Grad: 0.127478 Thermal: 0.000585 LR: 3.21e-06\n",
      "Epoch  33 [2300/10697 ( 21.5%)] Loss: 0.024822 L1: 0.014525 Grad: 0.102778 Thermal: 0.000382 LR: 3.21e-06\n",
      "Epoch  33 [2300/10697 ( 21.5%)] Loss: 0.024822 L1: 0.014525 Grad: 0.102778 Thermal: 0.000382 LR: 3.21e-06\n",
      "Epoch  33 [2350/10697 ( 22.0%)] Loss: 0.027932 L1: 0.015665 Grad: 0.122414 Thermal: 0.000513 LR: 3.21e-06\n",
      "Epoch  33 [2350/10697 ( 22.0%)] Loss: 0.027932 L1: 0.015665 Grad: 0.122414 Thermal: 0.000513 LR: 3.21e-06\n",
      "Epoch  33 [2400/10697 ( 22.4%)] Loss: 0.023197 L1: 0.013360 Grad: 0.098178 Thermal: 0.000369 LR: 3.21e-06\n",
      "Epoch  33 [2400/10697 ( 22.4%)] Loss: 0.023197 L1: 0.013360 Grad: 0.098178 Thermal: 0.000369 LR: 3.21e-06\n",
      "Epoch  33 [2450/10697 ( 22.9%)] Loss: 0.030758 L1: 0.017997 Grad: 0.127292 Thermal: 0.000636 LR: 3.21e-06\n",
      "Epoch  33 [2450/10697 ( 22.9%)] Loss: 0.030758 L1: 0.017997 Grad: 0.127292 Thermal: 0.000636 LR: 3.21e-06\n",
      "Epoch  33 [2500/10697 ( 23.4%)] Loss: 0.024754 L1: 0.014375 Grad: 0.103593 Thermal: 0.000396 LR: 3.21e-06\n",
      "Epoch  33 [2500/10697 ( 23.4%)] Loss: 0.024754 L1: 0.014375 Grad: 0.103593 Thermal: 0.000396 LR: 3.21e-06\n",
      "Epoch  33 [2550/10697 ( 23.8%)] Loss: 0.023624 L1: 0.013901 Grad: 0.097035 Thermal: 0.000396 LR: 3.21e-06\n",
      "Epoch  33 [2550/10697 ( 23.8%)] Loss: 0.023624 L1: 0.013901 Grad: 0.097035 Thermal: 0.000396 LR: 3.21e-06\n",
      "Epoch  33 [2600/10697 ( 24.3%)] Loss: 0.030840 L1: 0.018355 Grad: 0.124538 Thermal: 0.000611 LR: 3.21e-06\n",
      "Epoch  33 [2600/10697 ( 24.3%)] Loss: 0.030840 L1: 0.018355 Grad: 0.124538 Thermal: 0.000611 LR: 3.21e-06\n",
      "Epoch  33 [2650/10697 ( 24.8%)] Loss: 0.019845 L1: 0.011723 Grad: 0.081070 Thermal: 0.000296 LR: 3.21e-06\n",
      "Epoch  33 [2650/10697 ( 24.8%)] Loss: 0.019845 L1: 0.011723 Grad: 0.081070 Thermal: 0.000296 LR: 3.21e-06\n",
      "Epoch  33 [2700/10697 ( 25.2%)] Loss: 0.030615 L1: 0.018247 Grad: 0.123351 Thermal: 0.000657 LR: 3.21e-06\n",
      "Epoch  33 [2700/10697 ( 25.2%)] Loss: 0.030615 L1: 0.018247 Grad: 0.123351 Thermal: 0.000657 LR: 3.21e-06\n",
      "Epoch  33 [2750/10697 ( 25.7%)] Loss: 0.026996 L1: 0.015960 Grad: 0.110133 Thermal: 0.000454 LR: 3.21e-06\n",
      "Epoch  33 [2750/10697 ( 25.7%)] Loss: 0.026996 L1: 0.015960 Grad: 0.110133 Thermal: 0.000454 LR: 3.21e-06\n",
      "Epoch  33 [2800/10697 ( 26.2%)] Loss: 0.028876 L1: 0.016779 Grad: 0.120713 Thermal: 0.000525 LR: 3.21e-06\n",
      "Epoch  33 [2800/10697 ( 26.2%)] Loss: 0.028876 L1: 0.016779 Grad: 0.120713 Thermal: 0.000525 LR: 3.21e-06\n",
      "Epoch  33 [2850/10697 ( 26.6%)] Loss: 0.023072 L1: 0.013365 Grad: 0.096902 Thermal: 0.000355 LR: 3.21e-06\n",
      "Epoch  33 [2850/10697 ( 26.6%)] Loss: 0.023072 L1: 0.013365 Grad: 0.096902 Thermal: 0.000355 LR: 3.21e-06\n",
      "Epoch  33 [2900/10697 ( 27.1%)] Loss: 0.020544 L1: 0.011846 Grad: 0.086833 Thermal: 0.000292 LR: 3.21e-06\n",
      "Epoch  33 [2900/10697 ( 27.1%)] Loss: 0.020544 L1: 0.011846 Grad: 0.086833 Thermal: 0.000292 LR: 3.21e-06\n",
      "Epoch  33 [2950/10697 ( 27.6%)] Loss: 0.026954 L1: 0.015441 Grad: 0.114877 Thermal: 0.000512 LR: 3.21e-06\n",
      "Epoch  33 [2950/10697 ( 27.6%)] Loss: 0.026954 L1: 0.015441 Grad: 0.114877 Thermal: 0.000512 LR: 3.21e-06\n",
      "Epoch  33 [3000/10697 ( 28.0%)] Loss: 0.028490 L1: 0.016230 Grad: 0.122371 Thermal: 0.000453 LR: 3.21e-06\n",
      "Epoch  33 [3000/10697 ( 28.0%)] Loss: 0.028490 L1: 0.016230 Grad: 0.122371 Thermal: 0.000453 LR: 3.21e-06\n",
      "Epoch  33 [3050/10697 ( 28.5%)] Loss: 0.020769 L1: 0.011825 Grad: 0.089294 Thermal: 0.000292 LR: 3.21e-06\n",
      "Epoch  33 [3050/10697 ( 28.5%)] Loss: 0.020769 L1: 0.011825 Grad: 0.089294 Thermal: 0.000292 LR: 3.21e-06\n",
      "Epoch  33 [3100/10697 ( 29.0%)] Loss: 0.022268 L1: 0.013055 Grad: 0.091951 Thermal: 0.000350 LR: 3.21e-06\n",
      "Epoch  33 [3100/10697 ( 29.0%)] Loss: 0.022268 L1: 0.013055 Grad: 0.091951 Thermal: 0.000350 LR: 3.21e-06\n",
      "Epoch  33 [3150/10697 ( 29.4%)] Loss: 0.031048 L1: 0.017783 Grad: 0.132365 Thermal: 0.000579 LR: 3.21e-06\n",
      "Epoch  33 [3150/10697 ( 29.4%)] Loss: 0.031048 L1: 0.017783 Grad: 0.132365 Thermal: 0.000579 LR: 3.21e-06\n",
      "Epoch  33 [3200/10697 ( 29.9%)] Loss: 0.027500 L1: 0.015919 Grad: 0.115565 Thermal: 0.000498 LR: 3.21e-06\n",
      "Epoch  33 [3200/10697 ( 29.9%)] Loss: 0.027500 L1: 0.015919 Grad: 0.115565 Thermal: 0.000498 LR: 3.21e-06\n",
      "Epoch  33 [3250/10697 ( 30.4%)] Loss: 0.031030 L1: 0.018058 Grad: 0.129421 Thermal: 0.000590 LR: 3.21e-06\n",
      "Epoch  33 [3250/10697 ( 30.4%)] Loss: 0.031030 L1: 0.018058 Grad: 0.129421 Thermal: 0.000590 LR: 3.21e-06\n",
      "Epoch  33 [3300/10697 ( 30.8%)] Loss: 0.025929 L1: 0.015250 Grad: 0.106571 Thermal: 0.000438 LR: 3.21e-06\n",
      "Epoch  33 [3300/10697 ( 30.8%)] Loss: 0.025929 L1: 0.015250 Grad: 0.106571 Thermal: 0.000438 LR: 3.21e-06\n",
      "Epoch  33 [3350/10697 ( 31.3%)] Loss: 0.024288 L1: 0.014591 Grad: 0.096777 Thermal: 0.000393 LR: 3.21e-06\n",
      "Epoch  33 [3350/10697 ( 31.3%)] Loss: 0.024288 L1: 0.014591 Grad: 0.096777 Thermal: 0.000393 LR: 3.21e-06\n",
      "Epoch  33 [3400/10697 ( 31.8%)] Loss: 0.026077 L1: 0.015269 Grad: 0.107822 Thermal: 0.000500 LR: 3.21e-06\n",
      "Epoch  33 [3400/10697 ( 31.8%)] Loss: 0.026077 L1: 0.015269 Grad: 0.107822 Thermal: 0.000500 LR: 3.21e-06\n",
      "Epoch  33 [3450/10697 ( 32.3%)] Loss: 0.028927 L1: 0.017390 Grad: 0.115107 Thermal: 0.000532 LR: 3.21e-06\n",
      "Epoch  33 [3450/10697 ( 32.3%)] Loss: 0.028927 L1: 0.017390 Grad: 0.115107 Thermal: 0.000532 LR: 3.21e-06\n",
      "Epoch  33 [3500/10697 ( 32.7%)] Loss: 0.023667 L1: 0.014021 Grad: 0.096270 Thermal: 0.000390 LR: 3.21e-06\n",
      "Epoch  33 [3500/10697 ( 32.7%)] Loss: 0.023667 L1: 0.014021 Grad: 0.096270 Thermal: 0.000390 LR: 3.21e-06\n",
      "Epoch  33 [3550/10697 ( 33.2%)] Loss: 0.034494 L1: 0.019530 Grad: 0.149248 Thermal: 0.000786 LR: 3.21e-06\n",
      "Epoch  33 [3550/10697 ( 33.2%)] Loss: 0.034494 L1: 0.019530 Grad: 0.149248 Thermal: 0.000786 LR: 3.21e-06\n",
      "Epoch  33 [3600/10697 ( 33.7%)] Loss: 0.025773 L1: 0.014841 Grad: 0.109085 Thermal: 0.000483 LR: 3.21e-06\n",
      "Epoch  33 [3600/10697 ( 33.7%)] Loss: 0.025773 L1: 0.014841 Grad: 0.109085 Thermal: 0.000483 LR: 3.21e-06\n",
      "Epoch  33 [3650/10697 ( 34.1%)] Loss: 0.023148 L1: 0.013551 Grad: 0.095788 Thermal: 0.000366 LR: 3.21e-06\n",
      "Epoch  33 [3650/10697 ( 34.1%)] Loss: 0.023148 L1: 0.013551 Grad: 0.095788 Thermal: 0.000366 LR: 3.21e-06\n",
      "Epoch  33 [3700/10697 ( 34.6%)] Loss: 0.030893 L1: 0.017948 Grad: 0.129136 Thermal: 0.000632 LR: 3.21e-06\n",
      "Epoch  33 [3700/10697 ( 34.6%)] Loss: 0.030893 L1: 0.017948 Grad: 0.129136 Thermal: 0.000632 LR: 3.21e-06\n",
      "Epoch  33 [3750/10697 ( 35.1%)] Loss: 0.028585 L1: 0.016772 Grad: 0.117876 Thermal: 0.000507 LR: 3.21e-06\n",
      "Epoch  33 [3750/10697 ( 35.1%)] Loss: 0.028585 L1: 0.016772 Grad: 0.117876 Thermal: 0.000507 LR: 3.21e-06\n",
      "Epoch  33 [3800/10697 ( 35.5%)] Loss: 0.027624 L1: 0.016422 Grad: 0.111797 Thermal: 0.000459 LR: 3.21e-06\n",
      "Epoch  33 [3800/10697 ( 35.5%)] Loss: 0.027624 L1: 0.016422 Grad: 0.111797 Thermal: 0.000459 LR: 3.21e-06\n",
      "Epoch  33 [3850/10697 ( 36.0%)] Loss: 0.029373 L1: 0.017114 Grad: 0.122309 Thermal: 0.000555 LR: 3.21e-06\n",
      "Epoch  33 [3850/10697 ( 36.0%)] Loss: 0.029373 L1: 0.017114 Grad: 0.122309 Thermal: 0.000555 LR: 3.21e-06\n",
      "Epoch  33 [3900/10697 ( 36.5%)] Loss: 0.025595 L1: 0.014896 Grad: 0.106797 Thermal: 0.000390 LR: 3.21e-06\n",
      "Epoch  33 [3900/10697 ( 36.5%)] Loss: 0.025595 L1: 0.014896 Grad: 0.106797 Thermal: 0.000390 LR: 3.21e-06\n",
      "Epoch  33 [3950/10697 ( 36.9%)] Loss: 0.023777 L1: 0.014099 Grad: 0.096592 Thermal: 0.000368 LR: 3.21e-06\n",
      "Epoch  33 [3950/10697 ( 36.9%)] Loss: 0.023777 L1: 0.014099 Grad: 0.096592 Thermal: 0.000368 LR: 3.21e-06\n",
      "Epoch  33 [4000/10697 ( 37.4%)] Loss: 0.025813 L1: 0.014838 Grad: 0.109533 Thermal: 0.000438 LR: 3.21e-06\n",
      "Epoch  33 [4000/10697 ( 37.4%)] Loss: 0.025813 L1: 0.014838 Grad: 0.109533 Thermal: 0.000438 LR: 3.21e-06\n",
      "Epoch  33 [4050/10697 ( 37.9%)] Loss: 0.019906 L1: 0.011362 Grad: 0.085310 Thermal: 0.000252 LR: 3.21e-06\n",
      "Epoch  33 [4050/10697 ( 37.9%)] Loss: 0.019906 L1: 0.011362 Grad: 0.085310 Thermal: 0.000252 LR: 3.21e-06\n",
      "Epoch  33 [4100/10697 ( 38.3%)] Loss: 0.017126 L1: 0.009851 Grad: 0.072638 Thermal: 0.000232 LR: 3.21e-06\n",
      "Epoch  33 [4100/10697 ( 38.3%)] Loss: 0.017126 L1: 0.009851 Grad: 0.072638 Thermal: 0.000232 LR: 3.21e-06\n",
      "Epoch  33 [4150/10697 ( 38.8%)] Loss: 0.022834 L1: 0.013547 Grad: 0.092696 Thermal: 0.000351 LR: 3.21e-06\n",
      "Epoch  33 [4150/10697 ( 38.8%)] Loss: 0.022834 L1: 0.013547 Grad: 0.092696 Thermal: 0.000351 LR: 3.21e-06\n",
      "Epoch  33 [4200/10697 ( 39.3%)] Loss: 0.032739 L1: 0.018558 Grad: 0.141471 Thermal: 0.000676 LR: 3.21e-06\n",
      "Epoch  33 [4200/10697 ( 39.3%)] Loss: 0.032739 L1: 0.018558 Grad: 0.141471 Thermal: 0.000676 LR: 3.21e-06\n",
      "Epoch  33 [4250/10697 ( 39.7%)] Loss: 0.028691 L1: 0.016540 Grad: 0.121240 Thermal: 0.000541 LR: 3.21e-06\n",
      "Epoch  33 [4250/10697 ( 39.7%)] Loss: 0.028691 L1: 0.016540 Grad: 0.121240 Thermal: 0.000541 LR: 3.21e-06\n",
      "Epoch  33 [4300/10697 ( 40.2%)] Loss: 0.019228 L1: 0.010976 Grad: 0.082392 Thermal: 0.000255 LR: 3.21e-06\n",
      "Epoch  33 [4300/10697 ( 40.2%)] Loss: 0.019228 L1: 0.010976 Grad: 0.082392 Thermal: 0.000255 LR: 3.21e-06\n",
      "Epoch  33 [4350/10697 ( 40.7%)] Loss: 0.025071 L1: 0.014630 Grad: 0.104163 Thermal: 0.000503 LR: 3.21e-06\n",
      "Epoch  33 [4350/10697 ( 40.7%)] Loss: 0.025071 L1: 0.014630 Grad: 0.104163 Thermal: 0.000503 LR: 3.21e-06\n",
      "Epoch  33 [4400/10697 ( 41.1%)] Loss: 0.026513 L1: 0.015522 Grad: 0.109691 Thermal: 0.000431 LR: 3.21e-06\n",
      "Epoch  33 [4400/10697 ( 41.1%)] Loss: 0.026513 L1: 0.015522 Grad: 0.109691 Thermal: 0.000431 LR: 3.21e-06\n",
      "Epoch  33 [4450/10697 ( 41.6%)] Loss: 0.023857 L1: 0.014281 Grad: 0.095566 Thermal: 0.000402 LR: 3.21e-06\n",
      "Epoch  33 [4450/10697 ( 41.6%)] Loss: 0.023857 L1: 0.014281 Grad: 0.095566 Thermal: 0.000402 LR: 3.21e-06\n",
      "Epoch  33 [4500/10697 ( 42.1%)] Loss: 0.028621 L1: 0.016638 Grad: 0.119586 Thermal: 0.000496 LR: 3.21e-06\n",
      "Epoch  33 [4500/10697 ( 42.1%)] Loss: 0.028621 L1: 0.016638 Grad: 0.119586 Thermal: 0.000496 LR: 3.21e-06\n",
      "Epoch  33 [4550/10697 ( 42.5%)] Loss: 0.020872 L1: 0.012178 Grad: 0.086784 Thermal: 0.000318 LR: 3.21e-06\n",
      "Epoch  33 [4550/10697 ( 42.5%)] Loss: 0.020872 L1: 0.012178 Grad: 0.086784 Thermal: 0.000318 LR: 3.21e-06\n",
      "Epoch  33 [4600/10697 ( 43.0%)] Loss: 0.034056 L1: 0.019559 Grad: 0.144599 Thermal: 0.000742 LR: 3.21e-06\n",
      "Epoch  33 [4600/10697 ( 43.0%)] Loss: 0.034056 L1: 0.019559 Grad: 0.144599 Thermal: 0.000742 LR: 3.21e-06\n",
      "Epoch  33 [4650/10697 ( 43.5%)] Loss: 0.027349 L1: 0.015890 Grad: 0.114330 Thermal: 0.000520 LR: 3.21e-06\n",
      "Epoch  33 [4650/10697 ( 43.5%)] Loss: 0.027349 L1: 0.015890 Grad: 0.114330 Thermal: 0.000520 LR: 3.21e-06\n",
      "Epoch  33 [4700/10697 ( 43.9%)] Loss: 0.027537 L1: 0.015767 Grad: 0.117466 Thermal: 0.000468 LR: 3.21e-06\n",
      "Epoch  33 [4700/10697 ( 43.9%)] Loss: 0.027537 L1: 0.015767 Grad: 0.117466 Thermal: 0.000468 LR: 3.21e-06\n",
      "Epoch  33 [4750/10697 ( 44.4%)] Loss: 0.023987 L1: 0.013942 Grad: 0.100250 Thermal: 0.000409 LR: 3.21e-06\n",
      "Epoch  33 [4750/10697 ( 44.4%)] Loss: 0.023987 L1: 0.013942 Grad: 0.100250 Thermal: 0.000409 LR: 3.21e-06\n",
      "Epoch  33 [4800/10697 ( 44.9%)] Loss: 0.024603 L1: 0.014188 Grad: 0.103964 Thermal: 0.000366 LR: 3.21e-06\n",
      "Epoch  33 [4800/10697 ( 44.9%)] Loss: 0.024603 L1: 0.014188 Grad: 0.103964 Thermal: 0.000366 LR: 3.21e-06\n",
      "Epoch  33 [4850/10697 ( 45.3%)] Loss: 0.027734 L1: 0.015843 Grad: 0.118663 Thermal: 0.000493 LR: 3.21e-06\n",
      "Epoch  33 [4850/10697 ( 45.3%)] Loss: 0.027734 L1: 0.015843 Grad: 0.118663 Thermal: 0.000493 LR: 3.21e-06\n",
      "Epoch  33 [4900/10697 ( 45.8%)] Loss: 0.023791 L1: 0.013760 Grad: 0.100126 Thermal: 0.000373 LR: 3.21e-06\n",
      "Epoch  33 [4900/10697 ( 45.8%)] Loss: 0.023791 L1: 0.013760 Grad: 0.100126 Thermal: 0.000373 LR: 3.21e-06\n",
      "Epoch  33 [4950/10697 ( 46.3%)] Loss: 0.028147 L1: 0.016352 Grad: 0.117715 Thermal: 0.000479 LR: 3.21e-06\n",
      "Epoch  33 [4950/10697 ( 46.3%)] Loss: 0.028147 L1: 0.016352 Grad: 0.117715 Thermal: 0.000479 LR: 3.21e-06\n",
      "Epoch  33 [5000/10697 ( 46.7%)] Loss: 0.034627 L1: 0.019537 Grad: 0.150526 Thermal: 0.000740 LR: 3.21e-06\n",
      "Epoch  33 [5000/10697 ( 46.7%)] Loss: 0.034627 L1: 0.019537 Grad: 0.150526 Thermal: 0.000740 LR: 3.21e-06\n",
      "Epoch  33 [5050/10697 ( 47.2%)] Loss: 0.025082 L1: 0.014725 Grad: 0.103370 Thermal: 0.000400 LR: 3.21e-06\n",
      "Epoch  33 [5050/10697 ( 47.2%)] Loss: 0.025082 L1: 0.014725 Grad: 0.103370 Thermal: 0.000400 LR: 3.21e-06\n",
      "Epoch  33 [5100/10697 ( 47.7%)] Loss: 0.036108 L1: 0.020589 Grad: 0.154796 Thermal: 0.000789 LR: 3.21e-06\n",
      "Epoch  33 [5100/10697 ( 47.7%)] Loss: 0.036108 L1: 0.020589 Grad: 0.154796 Thermal: 0.000789 LR: 3.21e-06\n",
      "Epoch  33 [5150/10697 ( 48.1%)] Loss: 0.024869 L1: 0.014287 Grad: 0.105605 Thermal: 0.000421 LR: 3.21e-06\n",
      "Epoch  33 [5150/10697 ( 48.1%)] Loss: 0.024869 L1: 0.014287 Grad: 0.105605 Thermal: 0.000421 LR: 3.21e-06\n",
      "Epoch  33 [5200/10697 ( 48.6%)] Loss: 0.021898 L1: 0.012318 Grad: 0.095596 Thermal: 0.000415 LR: 3.21e-06\n",
      "Epoch  33 [5200/10697 ( 48.6%)] Loss: 0.021898 L1: 0.012318 Grad: 0.095596 Thermal: 0.000415 LR: 3.21e-06\n",
      "Epoch  33 [5250/10697 ( 49.1%)] Loss: 0.028502 L1: 0.016687 Grad: 0.117893 Thermal: 0.000503 LR: 3.21e-06\n",
      "Epoch  33 [5250/10697 ( 49.1%)] Loss: 0.028502 L1: 0.016687 Grad: 0.117893 Thermal: 0.000503 LR: 3.21e-06\n",
      "Epoch  33 [5300/10697 ( 49.5%)] Loss: 0.022131 L1: 0.012732 Grad: 0.093811 Thermal: 0.000339 LR: 3.21e-06\n",
      "Epoch  33 [5300/10697 ( 49.5%)] Loss: 0.022131 L1: 0.012732 Grad: 0.093811 Thermal: 0.000339 LR: 3.21e-06\n",
      "Epoch  33 [5350/10697 ( 50.0%)] Loss: 0.022629 L1: 0.013311 Grad: 0.093019 Thermal: 0.000327 LR: 3.21e-06\n",
      "Epoch  33 [5350/10697 ( 50.0%)] Loss: 0.022629 L1: 0.013311 Grad: 0.093019 Thermal: 0.000327 LR: 3.21e-06\n",
      "Epoch  33 [5400/10697 ( 50.5%)] Loss: 0.028910 L1: 0.017425 Grad: 0.114582 Thermal: 0.000538 LR: 3.21e-06\n",
      "Epoch  33 [5400/10697 ( 50.5%)] Loss: 0.028910 L1: 0.017425 Grad: 0.114582 Thermal: 0.000538 LR: 3.21e-06\n",
      "Epoch  33 [5450/10697 ( 50.9%)] Loss: 0.031164 L1: 0.017807 Grad: 0.133281 Thermal: 0.000574 LR: 3.21e-06\n",
      "Epoch  33 [5450/10697 ( 50.9%)] Loss: 0.031164 L1: 0.017807 Grad: 0.133281 Thermal: 0.000574 LR: 3.21e-06\n",
      "Epoch  33 [5500/10697 ( 51.4%)] Loss: 0.029172 L1: 0.016719 Grad: 0.124254 Thermal: 0.000548 LR: 3.21e-06\n",
      "Epoch  33 [5500/10697 ( 51.4%)] Loss: 0.029172 L1: 0.016719 Grad: 0.124254 Thermal: 0.000548 LR: 3.21e-06\n",
      "Epoch  33 [5550/10697 ( 51.9%)] Loss: 0.026477 L1: 0.015688 Grad: 0.107662 Thermal: 0.000451 LR: 3.21e-06\n",
      "Epoch  33 [5550/10697 ( 51.9%)] Loss: 0.026477 L1: 0.015688 Grad: 0.107662 Thermal: 0.000451 LR: 3.21e-06\n",
      "Epoch  33 [5600/10697 ( 52.4%)] Loss: 0.028753 L1: 0.016399 Grad: 0.123265 Thermal: 0.000537 LR: 3.21e-06\n",
      "Epoch  33 [5600/10697 ( 52.4%)] Loss: 0.028753 L1: 0.016399 Grad: 0.123265 Thermal: 0.000537 LR: 3.21e-06\n",
      "Epoch  33 [5650/10697 ( 52.8%)] Loss: 0.024675 L1: 0.014396 Grad: 0.102597 Thermal: 0.000393 LR: 3.21e-06\n",
      "Epoch  33 [5650/10697 ( 52.8%)] Loss: 0.024675 L1: 0.014396 Grad: 0.102597 Thermal: 0.000393 LR: 3.21e-06\n",
      "Epoch  33 [5700/10697 ( 53.3%)] Loss: 0.026611 L1: 0.015756 Grad: 0.108305 Thermal: 0.000493 LR: 3.21e-06\n",
      "Epoch  33 [5700/10697 ( 53.3%)] Loss: 0.026611 L1: 0.015756 Grad: 0.108305 Thermal: 0.000493 LR: 3.21e-06\n",
      "Epoch  33 [5750/10697 ( 53.8%)] Loss: 0.020903 L1: 0.011806 Grad: 0.090803 Thermal: 0.000348 LR: 3.21e-06\n",
      "Epoch  33 [5750/10697 ( 53.8%)] Loss: 0.020903 L1: 0.011806 Grad: 0.090803 Thermal: 0.000348 LR: 3.21e-06\n",
      "Epoch  33 [5800/10697 ( 54.2%)] Loss: 0.020329 L1: 0.011842 Grad: 0.084721 Thermal: 0.000296 LR: 3.21e-06\n",
      "Epoch  33 [5800/10697 ( 54.2%)] Loss: 0.020329 L1: 0.011842 Grad: 0.084721 Thermal: 0.000296 LR: 3.21e-06\n",
      "Epoch  33 [5850/10697 ( 54.7%)] Loss: 0.027605 L1: 0.016325 Grad: 0.112562 Thermal: 0.000479 LR: 3.21e-06\n",
      "Epoch  33 [5850/10697 ( 54.7%)] Loss: 0.027605 L1: 0.016325 Grad: 0.112562 Thermal: 0.000479 LR: 3.21e-06\n",
      "Epoch  33 [5900/10697 ( 55.2%)] Loss: 0.029693 L1: 0.017314 Grad: 0.123493 Thermal: 0.000578 LR: 3.21e-06\n",
      "Epoch  33 [5900/10697 ( 55.2%)] Loss: 0.029693 L1: 0.017314 Grad: 0.123493 Thermal: 0.000578 LR: 3.21e-06\n",
      "Epoch  33 [5950/10697 ( 55.6%)] Loss: 0.029221 L1: 0.016896 Grad: 0.122978 Thermal: 0.000533 LR: 3.21e-06\n",
      "Epoch  33 [5950/10697 ( 55.6%)] Loss: 0.029221 L1: 0.016896 Grad: 0.122978 Thermal: 0.000533 LR: 3.21e-06\n",
      "Epoch  33 [6000/10697 ( 56.1%)] Loss: 0.028198 L1: 0.016770 Grad: 0.114022 Thermal: 0.000505 LR: 3.21e-06\n",
      "Epoch  33 [6000/10697 ( 56.1%)] Loss: 0.028198 L1: 0.016770 Grad: 0.114022 Thermal: 0.000505 LR: 3.21e-06\n",
      "Epoch  33 [6050/10697 ( 56.6%)] Loss: 0.031769 L1: 0.018061 Grad: 0.136743 Thermal: 0.000670 LR: 3.21e-06\n",
      "Epoch  33 [6050/10697 ( 56.6%)] Loss: 0.031769 L1: 0.018061 Grad: 0.136743 Thermal: 0.000670 LR: 3.21e-06\n",
      "Epoch  33 [6100/10697 ( 57.0%)] Loss: 0.026641 L1: 0.015771 Grad: 0.108474 Thermal: 0.000455 LR: 3.21e-06\n",
      "Epoch  33 [6100/10697 ( 57.0%)] Loss: 0.026641 L1: 0.015771 Grad: 0.108474 Thermal: 0.000455 LR: 3.21e-06\n",
      "Epoch  33 [6150/10697 ( 57.5%)] Loss: 0.022368 L1: 0.012807 Grad: 0.095460 Thermal: 0.000308 LR: 3.21e-06\n",
      "Epoch  33 [6150/10697 ( 57.5%)] Loss: 0.022368 L1: 0.012807 Grad: 0.095460 Thermal: 0.000308 LR: 3.21e-06\n",
      "Epoch  33 [6200/10697 ( 58.0%)] Loss: 0.029252 L1: 0.016729 Grad: 0.124966 Thermal: 0.000521 LR: 3.21e-06\n",
      "Epoch  33 [6200/10697 ( 58.0%)] Loss: 0.029252 L1: 0.016729 Grad: 0.124966 Thermal: 0.000521 LR: 3.21e-06\n",
      "Epoch  33 [6250/10697 ( 58.4%)] Loss: 0.031935 L1: 0.018136 Grad: 0.137664 Thermal: 0.000639 LR: 3.21e-06\n",
      "Epoch  33 [6250/10697 ( 58.4%)] Loss: 0.031935 L1: 0.018136 Grad: 0.137664 Thermal: 0.000639 LR: 3.21e-06\n",
      "Epoch  33 [6300/10697 ( 58.9%)] Loss: 0.030812 L1: 0.017868 Grad: 0.129147 Thermal: 0.000596 LR: 3.21e-06\n",
      "Epoch  33 [6300/10697 ( 58.9%)] Loss: 0.030812 L1: 0.017868 Grad: 0.129147 Thermal: 0.000596 LR: 3.21e-06\n",
      "Epoch  33 [6350/10697 ( 59.4%)] Loss: 0.030176 L1: 0.017375 Grad: 0.127733 Thermal: 0.000549 LR: 3.21e-06\n",
      "Epoch  33 [6350/10697 ( 59.4%)] Loss: 0.030176 L1: 0.017375 Grad: 0.127733 Thermal: 0.000549 LR: 3.21e-06\n",
      "Epoch  33 [6400/10697 ( 59.8%)] Loss: 0.023123 L1: 0.013338 Grad: 0.097661 Thermal: 0.000383 LR: 3.21e-06\n",
      "Epoch  33 [6400/10697 ( 59.8%)] Loss: 0.023123 L1: 0.013338 Grad: 0.097661 Thermal: 0.000383 LR: 3.21e-06\n",
      "Epoch  33 [6450/10697 ( 60.3%)] Loss: 0.028182 L1: 0.016230 Grad: 0.119269 Thermal: 0.000497 LR: 3.21e-06\n",
      "Epoch  33 [6450/10697 ( 60.3%)] Loss: 0.028182 L1: 0.016230 Grad: 0.119269 Thermal: 0.000497 LR: 3.21e-06\n",
      "Epoch  33 [6500/10697 ( 60.8%)] Loss: 0.028229 L1: 0.016549 Grad: 0.116569 Thermal: 0.000474 LR: 3.21e-06\n",
      "Epoch  33 [6500/10697 ( 60.8%)] Loss: 0.028229 L1: 0.016549 Grad: 0.116569 Thermal: 0.000474 LR: 3.21e-06\n",
      "Epoch  33 [6550/10697 ( 61.2%)] Loss: 0.030637 L1: 0.017878 Grad: 0.127279 Thermal: 0.000620 LR: 3.21e-06\n",
      "Epoch  33 [6550/10697 ( 61.2%)] Loss: 0.030637 L1: 0.017878 Grad: 0.127279 Thermal: 0.000620 LR: 3.21e-06\n",
      "Epoch  33 [6600/10697 ( 61.7%)] Loss: 0.026617 L1: 0.015876 Grad: 0.107170 Thermal: 0.000490 LR: 3.21e-06\n",
      "Epoch  33 [6600/10697 ( 61.7%)] Loss: 0.026617 L1: 0.015876 Grad: 0.107170 Thermal: 0.000490 LR: 3.21e-06\n",
      "Epoch  33 [6650/10697 ( 62.2%)] Loss: 0.023276 L1: 0.013646 Grad: 0.096125 Thermal: 0.000356 LR: 3.21e-06\n",
      "Epoch  33 [6650/10697 ( 62.2%)] Loss: 0.023276 L1: 0.013646 Grad: 0.096125 Thermal: 0.000356 LR: 3.21e-06\n",
      "Epoch  33 [6700/10697 ( 62.6%)] Loss: 0.021435 L1: 0.012632 Grad: 0.087862 Thermal: 0.000326 LR: 3.21e-06\n",
      "Epoch  33 [6700/10697 ( 62.6%)] Loss: 0.021435 L1: 0.012632 Grad: 0.087862 Thermal: 0.000326 LR: 3.21e-06\n",
      "Epoch  33 [6750/10697 ( 63.1%)] Loss: 0.023093 L1: 0.013483 Grad: 0.095933 Thermal: 0.000336 LR: 3.21e-06\n",
      "Epoch  33 [6750/10697 ( 63.1%)] Loss: 0.023093 L1: 0.013483 Grad: 0.095933 Thermal: 0.000336 LR: 3.21e-06\n",
      "Epoch  33 [6800/10697 ( 63.6%)] Loss: 0.027545 L1: 0.016114 Grad: 0.114043 Thermal: 0.000536 LR: 3.21e-06\n",
      "Epoch  33 [6800/10697 ( 63.6%)] Loss: 0.027545 L1: 0.016114 Grad: 0.114043 Thermal: 0.000536 LR: 3.21e-06\n",
      "Epoch  33 [6850/10697 ( 64.0%)] Loss: 0.028069 L1: 0.016117 Grad: 0.119249 Thermal: 0.000539 LR: 3.21e-06\n",
      "Epoch  33 [6850/10697 ( 64.0%)] Loss: 0.028069 L1: 0.016117 Grad: 0.119249 Thermal: 0.000539 LR: 3.21e-06\n",
      "Epoch  33 [6900/10697 ( 64.5%)] Loss: 0.031160 L1: 0.017680 Grad: 0.134482 Thermal: 0.000624 LR: 3.21e-06\n",
      "Epoch  33 [6900/10697 ( 64.5%)] Loss: 0.031160 L1: 0.017680 Grad: 0.134482 Thermal: 0.000624 LR: 3.21e-06\n",
      "Epoch  33 [6950/10697 ( 65.0%)] Loss: 0.020108 L1: 0.011676 Grad: 0.084172 Thermal: 0.000287 LR: 3.21e-06\n",
      "Epoch  33 [6950/10697 ( 65.0%)] Loss: 0.020108 L1: 0.011676 Grad: 0.084172 Thermal: 0.000287 LR: 3.21e-06\n",
      "Epoch  33 [7000/10697 ( 65.4%)] Loss: 0.024056 L1: 0.014036 Grad: 0.100023 Thermal: 0.000359 LR: 3.21e-06\n",
      "Epoch  33 [7000/10697 ( 65.4%)] Loss: 0.024056 L1: 0.014036 Grad: 0.100023 Thermal: 0.000359 LR: 3.21e-06\n",
      "Epoch  33 [7050/10697 ( 65.9%)] Loss: 0.021857 L1: 0.012887 Grad: 0.089520 Thermal: 0.000361 LR: 3.21e-06\n",
      "Epoch  33 [7050/10697 ( 65.9%)] Loss: 0.021857 L1: 0.012887 Grad: 0.089520 Thermal: 0.000361 LR: 3.21e-06\n",
      "Epoch  33 [7100/10697 ( 66.4%)] Loss: 0.031090 L1: 0.018491 Grad: 0.125679 Thermal: 0.000615 LR: 3.21e-06\n",
      "Epoch  33 [7100/10697 ( 66.4%)] Loss: 0.031090 L1: 0.018491 Grad: 0.125679 Thermal: 0.000615 LR: 3.21e-06\n",
      "Epoch  33 [7150/10697 ( 66.8%)] Loss: 0.023826 L1: 0.014095 Grad: 0.097121 Thermal: 0.000384 LR: 3.21e-06\n",
      "Epoch  33 [7150/10697 ( 66.8%)] Loss: 0.023826 L1: 0.014095 Grad: 0.097121 Thermal: 0.000384 LR: 3.21e-06\n",
      "Epoch  33 [7200/10697 ( 67.3%)] Loss: 0.021639 L1: 0.012536 Grad: 0.090869 Thermal: 0.000317 LR: 3.21e-06\n",
      "Epoch  33 [7200/10697 ( 67.3%)] Loss: 0.021639 L1: 0.012536 Grad: 0.090869 Thermal: 0.000317 LR: 3.21e-06\n",
      "Epoch  33 [7250/10697 ( 67.8%)] Loss: 0.026008 L1: 0.015535 Grad: 0.104520 Thermal: 0.000431 LR: 3.21e-06\n",
      "Epoch  33 [7250/10697 ( 67.8%)] Loss: 0.026008 L1: 0.015535 Grad: 0.104520 Thermal: 0.000431 LR: 3.21e-06\n",
      "Epoch  33 [7300/10697 ( 68.2%)] Loss: 0.024419 L1: 0.014426 Grad: 0.099733 Thermal: 0.000391 LR: 3.21e-06\n",
      "Epoch  33 [7300/10697 ( 68.2%)] Loss: 0.024419 L1: 0.014426 Grad: 0.099733 Thermal: 0.000391 LR: 3.21e-06\n",
      "Epoch  33 [7350/10697 ( 68.7%)] Loss: 0.029930 L1: 0.017120 Grad: 0.127829 Thermal: 0.000548 LR: 3.21e-06\n",
      "Epoch  33 [7350/10697 ( 68.7%)] Loss: 0.029930 L1: 0.017120 Grad: 0.127829 Thermal: 0.000548 LR: 3.21e-06\n",
      "Epoch  33 [7400/10697 ( 69.2%)] Loss: 0.025008 L1: 0.014582 Grad: 0.104083 Thermal: 0.000370 LR: 3.21e-06\n",
      "Epoch  33 [7400/10697 ( 69.2%)] Loss: 0.025008 L1: 0.014582 Grad: 0.104083 Thermal: 0.000370 LR: 3.21e-06\n",
      "Epoch  33 [7450/10697 ( 69.6%)] Loss: 0.026898 L1: 0.015483 Grad: 0.113913 Thermal: 0.000468 LR: 3.21e-06\n",
      "Epoch  33 [7450/10697 ( 69.6%)] Loss: 0.026898 L1: 0.015483 Grad: 0.113913 Thermal: 0.000468 LR: 3.21e-06\n",
      "Epoch  33 [7500/10697 ( 70.1%)] Loss: 0.027026 L1: 0.016179 Grad: 0.108235 Thermal: 0.000468 LR: 3.21e-06\n",
      "Epoch  33 [7500/10697 ( 70.1%)] Loss: 0.027026 L1: 0.016179 Grad: 0.108235 Thermal: 0.000468 LR: 3.21e-06\n",
      "Epoch  33 [7550/10697 ( 70.6%)] Loss: 0.025807 L1: 0.014905 Grad: 0.108813 Thermal: 0.000405 LR: 3.21e-06\n",
      "Epoch  33 [7550/10697 ( 70.6%)] Loss: 0.025807 L1: 0.014905 Grad: 0.108813 Thermal: 0.000405 LR: 3.21e-06\n",
      "Epoch  33 [7600/10697 ( 71.0%)] Loss: 0.026358 L1: 0.015240 Grad: 0.110957 Thermal: 0.000443 LR: 3.21e-06\n",
      "Epoch  33 [7600/10697 ( 71.0%)] Loss: 0.026358 L1: 0.015240 Grad: 0.110957 Thermal: 0.000443 LR: 3.21e-06\n",
      "Epoch  33 [7650/10697 ( 71.5%)] Loss: 0.028677 L1: 0.016375 Grad: 0.122774 Thermal: 0.000491 LR: 3.21e-06\n",
      "Epoch  33 [7650/10697 ( 71.5%)] Loss: 0.028677 L1: 0.016375 Grad: 0.122774 Thermal: 0.000491 LR: 3.21e-06\n",
      "Epoch  33 [7700/10697 ( 72.0%)] Loss: 0.026413 L1: 0.015378 Grad: 0.110136 Thermal: 0.000414 LR: 3.21e-06\n",
      "Epoch  33 [7700/10697 ( 72.0%)] Loss: 0.026413 L1: 0.015378 Grad: 0.110136 Thermal: 0.000414 LR: 3.21e-06\n",
      "Epoch  33 [7750/10697 ( 72.5%)] Loss: 0.024098 L1: 0.014178 Grad: 0.099017 Thermal: 0.000374 LR: 3.21e-06\n",
      "Epoch  33 [7750/10697 ( 72.5%)] Loss: 0.024098 L1: 0.014178 Grad: 0.099017 Thermal: 0.000374 LR: 3.21e-06\n",
      "Epoch  33 [7800/10697 ( 72.9%)] Loss: 0.024318 L1: 0.014293 Grad: 0.100054 Thermal: 0.000402 LR: 3.21e-06\n",
      "Epoch  33 [7800/10697 ( 72.9%)] Loss: 0.024318 L1: 0.014293 Grad: 0.100054 Thermal: 0.000402 LR: 3.21e-06\n",
      "Epoch  33 [7850/10697 ( 73.4%)] Loss: 0.025884 L1: 0.015378 Grad: 0.104840 Thermal: 0.000429 LR: 3.21e-06\n",
      "Epoch  33 [7850/10697 ( 73.4%)] Loss: 0.025884 L1: 0.015378 Grad: 0.104840 Thermal: 0.000429 LR: 3.21e-06\n",
      "Epoch  33 [7900/10697 ( 73.9%)] Loss: 0.023454 L1: 0.013544 Grad: 0.098920 Thermal: 0.000351 LR: 3.21e-06\n",
      "Epoch  33 [7900/10697 ( 73.9%)] Loss: 0.023454 L1: 0.013544 Grad: 0.098920 Thermal: 0.000351 LR: 3.21e-06\n",
      "Epoch  33 [7950/10697 ( 74.3%)] Loss: 0.022466 L1: 0.012949 Grad: 0.094996 Thermal: 0.000349 LR: 3.21e-06\n",
      "Epoch  33 [7950/10697 ( 74.3%)] Loss: 0.022466 L1: 0.012949 Grad: 0.094996 Thermal: 0.000349 LR: 3.21e-06\n",
      "Epoch  33 [8000/10697 ( 74.8%)] Loss: 0.025047 L1: 0.014127 Grad: 0.109009 Thermal: 0.000386 LR: 3.21e-06\n",
      "Epoch  33 [8000/10697 ( 74.8%)] Loss: 0.025047 L1: 0.014127 Grad: 0.109009 Thermal: 0.000386 LR: 3.21e-06\n",
      "Epoch  33 [8050/10697 ( 75.3%)] Loss: 0.030541 L1: 0.017709 Grad: 0.128027 Thermal: 0.000583 LR: 3.21e-06\n",
      "Epoch  33 [8050/10697 ( 75.3%)] Loss: 0.030541 L1: 0.017709 Grad: 0.128027 Thermal: 0.000583 LR: 3.21e-06\n",
      "Epoch  33 [8100/10697 ( 75.7%)] Loss: 0.025589 L1: 0.014561 Grad: 0.110082 Thermal: 0.000399 LR: 3.21e-06\n",
      "Epoch  33 [8100/10697 ( 75.7%)] Loss: 0.025589 L1: 0.014561 Grad: 0.110082 Thermal: 0.000399 LR: 3.21e-06\n",
      "Epoch  33 [8150/10697 ( 76.2%)] Loss: 0.021573 L1: 0.012361 Grad: 0.091980 Thermal: 0.000280 LR: 3.21e-06\n",
      "Epoch  33 [8150/10697 ( 76.2%)] Loss: 0.021573 L1: 0.012361 Grad: 0.091980 Thermal: 0.000280 LR: 3.21e-06\n",
      "Epoch  33 [8200/10697 ( 76.7%)] Loss: 0.025494 L1: 0.014478 Grad: 0.109921 Thermal: 0.000479 LR: 3.21e-06\n",
      "Epoch  33 [8200/10697 ( 76.7%)] Loss: 0.025494 L1: 0.014478 Grad: 0.109921 Thermal: 0.000479 LR: 3.21e-06\n",
      "Epoch  33 [8250/10697 ( 77.1%)] Loss: 0.024536 L1: 0.014174 Grad: 0.103425 Thermal: 0.000392 LR: 3.21e-06\n",
      "Epoch  33 [8250/10697 ( 77.1%)] Loss: 0.024536 L1: 0.014174 Grad: 0.103425 Thermal: 0.000392 LR: 3.21e-06\n",
      "Epoch  33 [8300/10697 ( 77.6%)] Loss: 0.023747 L1: 0.013844 Grad: 0.098831 Thermal: 0.000404 LR: 3.21e-06\n",
      "Epoch  33 [8300/10697 ( 77.6%)] Loss: 0.023747 L1: 0.013844 Grad: 0.098831 Thermal: 0.000404 LR: 3.21e-06\n",
      "Epoch  33 [8350/10697 ( 78.1%)] Loss: 0.030705 L1: 0.017845 Grad: 0.128289 Thermal: 0.000616 LR: 3.21e-06\n",
      "Epoch  33 [8350/10697 ( 78.1%)] Loss: 0.030705 L1: 0.017845 Grad: 0.128289 Thermal: 0.000616 LR: 3.21e-06\n",
      "Epoch  33 [8400/10697 ( 78.5%)] Loss: 0.019636 L1: 0.011233 Grad: 0.083901 Thermal: 0.000257 LR: 3.21e-06\n",
      "Epoch  33 [8400/10697 ( 78.5%)] Loss: 0.019636 L1: 0.011233 Grad: 0.083901 Thermal: 0.000257 LR: 3.21e-06\n",
      "Epoch  33 [8450/10697 ( 79.0%)] Loss: 0.027024 L1: 0.016042 Grad: 0.109591 Thermal: 0.000449 LR: 3.21e-06\n",
      "Epoch  33 [8450/10697 ( 79.0%)] Loss: 0.027024 L1: 0.016042 Grad: 0.109591 Thermal: 0.000449 LR: 3.21e-06\n",
      "Epoch  33 [8500/10697 ( 79.5%)] Loss: 0.027380 L1: 0.015976 Grad: 0.113827 Thermal: 0.000441 LR: 3.21e-06\n",
      "Epoch  33 [8500/10697 ( 79.5%)] Loss: 0.027380 L1: 0.015976 Grad: 0.113827 Thermal: 0.000441 LR: 3.21e-06\n",
      "Epoch  33 [8550/10697 ( 79.9%)] Loss: 0.027409 L1: 0.015509 Grad: 0.118715 Thermal: 0.000583 LR: 3.21e-06\n",
      "Epoch  33 [8550/10697 ( 79.9%)] Loss: 0.027409 L1: 0.015509 Grad: 0.118715 Thermal: 0.000583 LR: 3.21e-06\n",
      "Epoch  33 [8600/10697 ( 80.4%)] Loss: 0.029305 L1: 0.016790 Grad: 0.124879 Thermal: 0.000542 LR: 3.21e-06\n",
      "Epoch  33 [8600/10697 ( 80.4%)] Loss: 0.029305 L1: 0.016790 Grad: 0.124879 Thermal: 0.000542 LR: 3.21e-06\n",
      "Epoch  33 [8650/10697 ( 80.9%)] Loss: 0.025678 L1: 0.014960 Grad: 0.106948 Thermal: 0.000463 LR: 3.21e-06\n",
      "Epoch  33 [8650/10697 ( 80.9%)] Loss: 0.025678 L1: 0.014960 Grad: 0.106948 Thermal: 0.000463 LR: 3.21e-06\n",
      "Epoch  33 [8700/10697 ( 81.3%)] Loss: 0.022334 L1: 0.012573 Grad: 0.097446 Thermal: 0.000323 LR: 3.21e-06\n",
      "Epoch  33 [8700/10697 ( 81.3%)] Loss: 0.022334 L1: 0.012573 Grad: 0.097446 Thermal: 0.000323 LR: 3.21e-06\n",
      "Epoch  33 [8750/10697 ( 81.8%)] Loss: 0.024472 L1: 0.014707 Grad: 0.097451 Thermal: 0.000395 LR: 3.21e-06\n",
      "Epoch  33 [8750/10697 ( 81.8%)] Loss: 0.024472 L1: 0.014707 Grad: 0.097451 Thermal: 0.000395 LR: 3.21e-06\n",
      "Epoch  33 [8800/10697 ( 82.3%)] Loss: 0.020423 L1: 0.012138 Grad: 0.082704 Thermal: 0.000291 LR: 3.21e-06\n",
      "Epoch  33 [8800/10697 ( 82.3%)] Loss: 0.020423 L1: 0.012138 Grad: 0.082704 Thermal: 0.000291 LR: 3.21e-06\n",
      "Epoch  33 [8850/10697 ( 82.7%)] Loss: 0.026308 L1: 0.015681 Grad: 0.106057 Thermal: 0.000427 LR: 3.21e-06\n",
      "Epoch  33 [8850/10697 ( 82.7%)] Loss: 0.026308 L1: 0.015681 Grad: 0.106057 Thermal: 0.000427 LR: 3.21e-06\n",
      "Epoch  33 [8900/10697 ( 83.2%)] Loss: 0.026238 L1: 0.015893 Grad: 0.103235 Thermal: 0.000445 LR: 3.21e-06\n",
      "Epoch  33 [8900/10697 ( 83.2%)] Loss: 0.026238 L1: 0.015893 Grad: 0.103235 Thermal: 0.000445 LR: 3.21e-06\n",
      "Epoch  33 [8950/10697 ( 83.7%)] Loss: 0.026150 L1: 0.015232 Grad: 0.108963 Thermal: 0.000444 LR: 3.21e-06\n",
      "Epoch  33 [8950/10697 ( 83.7%)] Loss: 0.026150 L1: 0.015232 Grad: 0.108963 Thermal: 0.000444 LR: 3.21e-06\n",
      "Epoch  33 [9000/10697 ( 84.1%)] Loss: 0.024232 L1: 0.014483 Grad: 0.097298 Thermal: 0.000379 LR: 3.21e-06\n",
      "Epoch  33 [9000/10697 ( 84.1%)] Loss: 0.024232 L1: 0.014483 Grad: 0.097298 Thermal: 0.000379 LR: 3.21e-06\n",
      "Epoch  33 [9050/10697 ( 84.6%)] Loss: 0.026622 L1: 0.015341 Grad: 0.112564 Thermal: 0.000485 LR: 3.21e-06\n",
      "Epoch  33 [9050/10697 ( 84.6%)] Loss: 0.026622 L1: 0.015341 Grad: 0.112564 Thermal: 0.000485 LR: 3.21e-06\n",
      "Epoch  33 [9100/10697 ( 85.1%)] Loss: 0.027903 L1: 0.016387 Grad: 0.114929 Thermal: 0.000466 LR: 3.21e-06\n",
      "Epoch  33 [9100/10697 ( 85.1%)] Loss: 0.027903 L1: 0.016387 Grad: 0.114929 Thermal: 0.000466 LR: 3.21e-06\n",
      "Epoch  33 [9150/10697 ( 85.5%)] Loss: 0.024343 L1: 0.014450 Grad: 0.098727 Thermal: 0.000398 LR: 3.21e-06\n",
      "Epoch  33 [9150/10697 ( 85.5%)] Loss: 0.024343 L1: 0.014450 Grad: 0.098727 Thermal: 0.000398 LR: 3.21e-06\n",
      "Epoch  33 [9200/10697 ( 86.0%)] Loss: 0.028026 L1: 0.016414 Grad: 0.115879 Thermal: 0.000484 LR: 3.21e-06\n",
      "Epoch  33 [9200/10697 ( 86.0%)] Loss: 0.028026 L1: 0.016414 Grad: 0.115879 Thermal: 0.000484 LR: 3.21e-06\n",
      "Epoch  33 [9250/10697 ( 86.5%)] Loss: 0.020488 L1: 0.012005 Grad: 0.084685 Thermal: 0.000297 LR: 3.21e-06\n",
      "Epoch  33 [9250/10697 ( 86.5%)] Loss: 0.020488 L1: 0.012005 Grad: 0.084685 Thermal: 0.000297 LR: 3.21e-06\n",
      "Epoch  33 [9300/10697 ( 86.9%)] Loss: 0.025711 L1: 0.015226 Grad: 0.104631 Thermal: 0.000427 LR: 3.21e-06\n",
      "Epoch  33 [9300/10697 ( 86.9%)] Loss: 0.025711 L1: 0.015226 Grad: 0.104631 Thermal: 0.000427 LR: 3.21e-06\n",
      "Epoch  33 [9350/10697 ( 87.4%)] Loss: 0.025178 L1: 0.014604 Grad: 0.105549 Thermal: 0.000393 LR: 3.21e-06\n",
      "Epoch  33 [9350/10697 ( 87.4%)] Loss: 0.025178 L1: 0.014604 Grad: 0.105549 Thermal: 0.000393 LR: 3.21e-06\n",
      "Epoch  33 [9400/10697 ( 87.9%)] Loss: 0.026621 L1: 0.015614 Grad: 0.109841 Thermal: 0.000450 LR: 3.21e-06\n",
      "Epoch  33 [9400/10697 ( 87.9%)] Loss: 0.026621 L1: 0.015614 Grad: 0.109841 Thermal: 0.000450 LR: 3.21e-06\n",
      "Epoch  33 [9450/10697 ( 88.3%)] Loss: 0.021159 L1: 0.012311 Grad: 0.088292 Thermal: 0.000376 LR: 3.21e-06\n",
      "Epoch  33 [9450/10697 ( 88.3%)] Loss: 0.021159 L1: 0.012311 Grad: 0.088292 Thermal: 0.000376 LR: 3.21e-06\n",
      "Epoch  33 [9500/10697 ( 88.8%)] Loss: 0.039264 L1: 0.022894 Grad: 0.163222 Thermal: 0.000954 LR: 3.21e-06\n",
      "Epoch  33 [9500/10697 ( 88.8%)] Loss: 0.039264 L1: 0.022894 Grad: 0.163222 Thermal: 0.000954 LR: 3.21e-06\n",
      "Epoch  33 [9550/10697 ( 89.3%)] Loss: 0.024455 L1: 0.014487 Grad: 0.099494 Thermal: 0.000386 LR: 3.21e-06\n",
      "Epoch  33 [9550/10697 ( 89.3%)] Loss: 0.024455 L1: 0.014487 Grad: 0.099494 Thermal: 0.000386 LR: 3.21e-06\n",
      "Epoch  33 [9600/10697 ( 89.7%)] Loss: 0.029284 L1: 0.016720 Grad: 0.125383 Thermal: 0.000512 LR: 3.21e-06\n",
      "Epoch  33 [9600/10697 ( 89.7%)] Loss: 0.029284 L1: 0.016720 Grad: 0.125383 Thermal: 0.000512 LR: 3.21e-06\n",
      "Epoch  33 [9650/10697 ( 90.2%)] Loss: 0.029777 L1: 0.017498 Grad: 0.122506 Thermal: 0.000569 LR: 3.21e-06\n",
      "Epoch  33 [9650/10697 ( 90.2%)] Loss: 0.029777 L1: 0.017498 Grad: 0.122506 Thermal: 0.000569 LR: 3.21e-06\n",
      "Epoch  33 [9700/10697 ( 90.7%)] Loss: 0.021749 L1: 0.012247 Grad: 0.094839 Thermal: 0.000351 LR: 3.21e-06\n",
      "Epoch  33 [9700/10697 ( 90.7%)] Loss: 0.021749 L1: 0.012247 Grad: 0.094839 Thermal: 0.000351 LR: 3.21e-06\n",
      "Epoch  33 [9750/10697 ( 91.1%)] Loss: 0.025615 L1: 0.014934 Grad: 0.106609 Thermal: 0.000408 LR: 3.21e-06\n",
      "Epoch  33 [9750/10697 ( 91.1%)] Loss: 0.025615 L1: 0.014934 Grad: 0.106609 Thermal: 0.000408 LR: 3.21e-06\n",
      "Epoch  33 [9800/10697 ( 91.6%)] Loss: 0.027104 L1: 0.015465 Grad: 0.116161 Thermal: 0.000454 LR: 3.21e-06\n",
      "Epoch  33 [9800/10697 ( 91.6%)] Loss: 0.027104 L1: 0.015465 Grad: 0.116161 Thermal: 0.000454 LR: 3.21e-06\n",
      "Epoch  33 [9850/10697 ( 92.1%)] Loss: 0.028536 L1: 0.016916 Grad: 0.115912 Thermal: 0.000580 LR: 3.21e-06\n",
      "Epoch  33 [9850/10697 ( 92.1%)] Loss: 0.028536 L1: 0.016916 Grad: 0.115912 Thermal: 0.000580 LR: 3.21e-06\n",
      "Epoch  33 [9900/10697 ( 92.5%)] Loss: 0.017795 L1: 0.010160 Grad: 0.076239 Thermal: 0.000227 LR: 3.21e-06\n",
      "Epoch  33 [9900/10697 ( 92.5%)] Loss: 0.017795 L1: 0.010160 Grad: 0.076239 Thermal: 0.000227 LR: 3.21e-06\n",
      "Epoch  33 [9950/10697 ( 93.0%)] Loss: 0.029939 L1: 0.017746 Grad: 0.121648 Thermal: 0.000568 LR: 3.21e-06\n",
      "Epoch  33 [9950/10697 ( 93.0%)] Loss: 0.029939 L1: 0.017746 Grad: 0.121648 Thermal: 0.000568 LR: 3.21e-06\n",
      "Epoch  33 [10000/10697 ( 93.5%)] Loss: 0.024045 L1: 0.014349 Grad: 0.096766 Thermal: 0.000390 LR: 3.21e-06\n",
      "Epoch  33 [10000/10697 ( 93.5%)] Loss: 0.024045 L1: 0.014349 Grad: 0.096766 Thermal: 0.000390 LR: 3.21e-06\n",
      "Epoch  33 [10050/10697 ( 94.0%)] Loss: 0.029074 L1: 0.016897 Grad: 0.121501 Thermal: 0.000538 LR: 3.21e-06\n",
      "Epoch  33 [10050/10697 ( 94.0%)] Loss: 0.029074 L1: 0.016897 Grad: 0.121501 Thermal: 0.000538 LR: 3.21e-06\n",
      "Epoch  33 [10100/10697 ( 94.4%)] Loss: 0.025279 L1: 0.014950 Grad: 0.103076 Thermal: 0.000434 LR: 3.21e-06\n",
      "Epoch  33 [10100/10697 ( 94.4%)] Loss: 0.025279 L1: 0.014950 Grad: 0.103076 Thermal: 0.000434 LR: 3.21e-06\n",
      "Epoch  33 [10150/10697 ( 94.9%)] Loss: 0.023194 L1: 0.013451 Grad: 0.097219 Thermal: 0.000417 LR: 3.21e-06\n",
      "Epoch  33 [10150/10697 ( 94.9%)] Loss: 0.023194 L1: 0.013451 Grad: 0.097219 Thermal: 0.000417 LR: 3.21e-06\n",
      "Epoch  33 [10200/10697 ( 95.4%)] Loss: 0.024140 L1: 0.014411 Grad: 0.097098 Thermal: 0.000379 LR: 3.21e-06\n",
      "Epoch  33 [10200/10697 ( 95.4%)] Loss: 0.024140 L1: 0.014411 Grad: 0.097098 Thermal: 0.000379 LR: 3.21e-06\n",
      "Epoch  33 [10250/10697 ( 95.8%)] Loss: 0.022526 L1: 0.013146 Grad: 0.093628 Thermal: 0.000352 LR: 3.21e-06\n",
      "Epoch  33 [10250/10697 ( 95.8%)] Loss: 0.022526 L1: 0.013146 Grad: 0.093628 Thermal: 0.000352 LR: 3.21e-06\n",
      "Epoch  33 [10300/10697 ( 96.3%)] Loss: 0.029033 L1: 0.017049 Grad: 0.119588 Thermal: 0.000516 LR: 3.21e-06\n",
      "Epoch  33 [10300/10697 ( 96.3%)] Loss: 0.029033 L1: 0.017049 Grad: 0.119588 Thermal: 0.000516 LR: 3.21e-06\n",
      "Epoch  33 [10350/10697 ( 96.8%)] Loss: 0.027222 L1: 0.016167 Grad: 0.110294 Thermal: 0.000501 LR: 3.21e-06\n",
      "Epoch  33 [10350/10697 ( 96.8%)] Loss: 0.027222 L1: 0.016167 Grad: 0.110294 Thermal: 0.000501 LR: 3.21e-06\n",
      "Epoch  33 [10400/10697 ( 97.2%)] Loss: 0.029525 L1: 0.017356 Grad: 0.121419 Thermal: 0.000539 LR: 3.21e-06\n",
      "Epoch  33 [10400/10697 ( 97.2%)] Loss: 0.029525 L1: 0.017356 Grad: 0.121419 Thermal: 0.000539 LR: 3.21e-06\n",
      "Epoch  33 [10450/10697 ( 97.7%)] Loss: 0.027892 L1: 0.015654 Grad: 0.122120 Thermal: 0.000534 LR: 3.21e-06\n",
      "Epoch  33 [10450/10697 ( 97.7%)] Loss: 0.027892 L1: 0.015654 Grad: 0.122120 Thermal: 0.000534 LR: 3.21e-06\n",
      "Epoch  33 [10500/10697 ( 98.2%)] Loss: 0.021582 L1: 0.012591 Grad: 0.089750 Thermal: 0.000323 LR: 3.21e-06\n",
      "Epoch  33 [10500/10697 ( 98.2%)] Loss: 0.021582 L1: 0.012591 Grad: 0.089750 Thermal: 0.000323 LR: 3.21e-06\n",
      "Epoch  33 [10550/10697 ( 98.6%)] Loss: 0.028908 L1: 0.016990 Grad: 0.118879 Thermal: 0.000610 LR: 3.21e-06\n",
      "Epoch  33 [10550/10697 ( 98.6%)] Loss: 0.028908 L1: 0.016990 Grad: 0.118879 Thermal: 0.000610 LR: 3.21e-06\n",
      "Epoch  33 [10600/10697 ( 99.1%)] Loss: 0.031212 L1: 0.017969 Grad: 0.132151 Thermal: 0.000552 LR: 3.21e-06\n",
      "Epoch  33 [10600/10697 ( 99.1%)] Loss: 0.031212 L1: 0.017969 Grad: 0.132151 Thermal: 0.000552 LR: 3.21e-06\n",
      "Epoch  33 [10650/10697 ( 99.6%)] Loss: 0.025698 L1: 0.015162 Grad: 0.105164 Thermal: 0.000396 LR: 3.21e-06\n",
      "Epoch  33 [10650/10697 ( 99.6%)] Loss: 0.025698 L1: 0.015162 Grad: 0.105164 Thermal: 0.000396 LR: 3.21e-06\n",
      "Epoch  33 Summary: Loss=0.026242 (L1:0.0153, Grad:0.1091, Thermal:0.0005) Val_PSNR=0.00dB Best=33.96dB Time=127.6min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  33 Summary: Loss=0.026242 (L1:0.0153, Grad:0.1091, Thermal:0.0005) Val_PSNR=0.00dB Best=33.96dB Time=127.6min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  34 [   0/10697 (  0.0%)] Loss: 0.023067 L1: 0.013193 Grad: 0.098566 Thermal: 0.000341 LR: 3.12e-06\n",
      "Epoch  34 [   0/10697 (  0.0%)] Loss: 0.023067 L1: 0.013193 Grad: 0.098566 Thermal: 0.000341 LR: 3.12e-06\n",
      "Epoch  34 [  50/10697 (  0.5%)] Loss: 0.026130 L1: 0.015404 Grad: 0.107043 Thermal: 0.000417 LR: 3.12e-06\n",
      "Epoch  34 [  50/10697 (  0.5%)] Loss: 0.026130 L1: 0.015404 Grad: 0.107043 Thermal: 0.000417 LR: 3.12e-06\n",
      "Epoch  34 [ 100/10697 (  0.9%)] Loss: 0.025705 L1: 0.014474 Grad: 0.112067 Thermal: 0.000472 LR: 3.12e-06\n",
      "Epoch  34 [ 100/10697 (  0.9%)] Loss: 0.025705 L1: 0.014474 Grad: 0.112067 Thermal: 0.000472 LR: 3.12e-06\n",
      "Epoch  34 [ 150/10697 (  1.4%)] Loss: 0.026843 L1: 0.016096 Grad: 0.107228 Thermal: 0.000468 LR: 3.12e-06\n",
      "Epoch  34 [ 150/10697 (  1.4%)] Loss: 0.026843 L1: 0.016096 Grad: 0.107228 Thermal: 0.000468 LR: 3.12e-06\n",
      "Epoch  34 [ 200/10697 (  1.9%)] Loss: 0.020761 L1: 0.011867 Grad: 0.088797 Thermal: 0.000293 LR: 3.12e-06\n",
      "Epoch  34 [ 200/10697 (  1.9%)] Loss: 0.020761 L1: 0.011867 Grad: 0.088797 Thermal: 0.000293 LR: 3.12e-06\n",
      "Epoch  34 [ 250/10697 (  2.3%)] Loss: 0.027238 L1: 0.015801 Grad: 0.114130 Thermal: 0.000493 LR: 3.12e-06\n",
      "Epoch  34 [ 250/10697 (  2.3%)] Loss: 0.027238 L1: 0.015801 Grad: 0.114130 Thermal: 0.000493 LR: 3.12e-06\n",
      "Epoch  34 [ 300/10697 (  2.8%)] Loss: 0.027635 L1: 0.016184 Grad: 0.114265 Thermal: 0.000495 LR: 3.12e-06\n",
      "Epoch  34 [ 300/10697 (  2.8%)] Loss: 0.027635 L1: 0.016184 Grad: 0.114265 Thermal: 0.000495 LR: 3.12e-06\n",
      "Epoch  34 [ 350/10697 (  3.3%)] Loss: 0.029209 L1: 0.017253 Grad: 0.119298 Thermal: 0.000533 LR: 3.12e-06\n",
      "Epoch  34 [ 350/10697 (  3.3%)] Loss: 0.029209 L1: 0.017253 Grad: 0.119298 Thermal: 0.000533 LR: 3.12e-06\n",
      "Epoch  34 [ 400/10697 (  3.7%)] Loss: 0.029808 L1: 0.017309 Grad: 0.124716 Thermal: 0.000555 LR: 3.12e-06\n",
      "Epoch  34 [ 400/10697 (  3.7%)] Loss: 0.029808 L1: 0.017309 Grad: 0.124716 Thermal: 0.000555 LR: 3.12e-06\n",
      "Epoch  34 [ 450/10697 (  4.2%)] Loss: 0.023880 L1: 0.014005 Grad: 0.098554 Thermal: 0.000399 LR: 3.12e-06\n",
      "Epoch  34 [ 450/10697 (  4.2%)] Loss: 0.023880 L1: 0.014005 Grad: 0.098554 Thermal: 0.000399 LR: 3.12e-06\n",
      "Epoch  34 [ 500/10697 (  4.7%)] Loss: 0.031537 L1: 0.018251 Grad: 0.132497 Thermal: 0.000721 LR: 3.12e-06\n",
      "Epoch  34 [ 500/10697 (  4.7%)] Loss: 0.031537 L1: 0.018251 Grad: 0.132497 Thermal: 0.000721 LR: 3.12e-06\n",
      "Epoch  34 [ 550/10697 (  5.1%)] Loss: 0.029830 L1: 0.017567 Grad: 0.122338 Thermal: 0.000574 LR: 3.12e-06\n",
      "Epoch  34 [ 550/10697 (  5.1%)] Loss: 0.029830 L1: 0.017567 Grad: 0.122338 Thermal: 0.000574 LR: 3.12e-06\n",
      "Epoch  34 [ 600/10697 (  5.6%)] Loss: 0.029950 L1: 0.016964 Grad: 0.129576 Thermal: 0.000577 LR: 3.12e-06\n",
      "Epoch  34 [ 600/10697 (  5.6%)] Loss: 0.029950 L1: 0.016964 Grad: 0.129576 Thermal: 0.000577 LR: 3.12e-06\n",
      "Epoch  34 [ 650/10697 (  6.1%)] Loss: 0.027263 L1: 0.016340 Grad: 0.108992 Thermal: 0.000470 LR: 3.12e-06\n",
      "Epoch  34 [ 650/10697 (  6.1%)] Loss: 0.027263 L1: 0.016340 Grad: 0.108992 Thermal: 0.000470 LR: 3.12e-06\n",
      "Epoch  34 [ 700/10697 (  6.5%)] Loss: 0.023197 L1: 0.013698 Grad: 0.094812 Thermal: 0.000367 LR: 3.12e-06\n",
      "Epoch  34 [ 700/10697 (  6.5%)] Loss: 0.023197 L1: 0.013698 Grad: 0.094812 Thermal: 0.000367 LR: 3.12e-06\n",
      "Epoch  34 [ 750/10697 (  7.0%)] Loss: 0.029721 L1: 0.017350 Grad: 0.123403 Thermal: 0.000608 LR: 3.12e-06\n",
      "Epoch  34 [ 750/10697 (  7.0%)] Loss: 0.029721 L1: 0.017350 Grad: 0.123403 Thermal: 0.000608 LR: 3.12e-06\n",
      "Epoch  34 [ 800/10697 (  7.5%)] Loss: 0.025744 L1: 0.014793 Grad: 0.109287 Thermal: 0.000447 LR: 3.12e-06\n",
      "Epoch  34 [ 800/10697 (  7.5%)] Loss: 0.025744 L1: 0.014793 Grad: 0.109287 Thermal: 0.000447 LR: 3.12e-06\n",
      "Epoch  34 [ 850/10697 (  7.9%)] Loss: 0.026350 L1: 0.015502 Grad: 0.108271 Thermal: 0.000433 LR: 3.12e-06\n",
      "Epoch  34 [ 850/10697 (  7.9%)] Loss: 0.026350 L1: 0.015502 Grad: 0.108271 Thermal: 0.000433 LR: 3.12e-06\n",
      "Epoch  34 [ 900/10697 (  8.4%)] Loss: 0.021761 L1: 0.012038 Grad: 0.097081 Thermal: 0.000294 LR: 3.12e-06\n",
      "Epoch  34 [ 900/10697 (  8.4%)] Loss: 0.021761 L1: 0.012038 Grad: 0.097081 Thermal: 0.000294 LR: 3.12e-06\n",
      "Epoch  34 [ 950/10697 (  8.9%)] Loss: 0.025052 L1: 0.014402 Grad: 0.106287 Thermal: 0.000428 LR: 3.12e-06\n",
      "Epoch  34 [ 950/10697 (  8.9%)] Loss: 0.025052 L1: 0.014402 Grad: 0.106287 Thermal: 0.000428 LR: 3.12e-06\n",
      "Epoch  34 [1000/10697 (  9.3%)] Loss: 0.026830 L1: 0.015675 Grad: 0.111297 Thermal: 0.000512 LR: 3.12e-06\n",
      "Epoch  34 [1000/10697 (  9.3%)] Loss: 0.026830 L1: 0.015675 Grad: 0.111297 Thermal: 0.000512 LR: 3.12e-06\n",
      "Epoch  34 [1050/10697 (  9.8%)] Loss: 0.027628 L1: 0.015946 Grad: 0.116585 Thermal: 0.000467 LR: 3.12e-06\n",
      "Epoch  34 [1050/10697 (  9.8%)] Loss: 0.027628 L1: 0.015946 Grad: 0.116585 Thermal: 0.000467 LR: 3.12e-06\n",
      "Epoch  34 [1100/10697 ( 10.3%)] Loss: 0.030492 L1: 0.017799 Grad: 0.126586 Thermal: 0.000678 LR: 3.12e-06\n",
      "Epoch  34 [1100/10697 ( 10.3%)] Loss: 0.030492 L1: 0.017799 Grad: 0.126586 Thermal: 0.000678 LR: 3.12e-06\n",
      "Epoch  34 [1150/10697 ( 10.8%)] Loss: 0.029693 L1: 0.017611 Grad: 0.120545 Thermal: 0.000546 LR: 3.12e-06\n",
      "Epoch  34 [1150/10697 ( 10.8%)] Loss: 0.029693 L1: 0.017611 Grad: 0.120545 Thermal: 0.000546 LR: 3.12e-06\n",
      "Epoch  34 [1200/10697 ( 11.2%)] Loss: 0.033137 L1: 0.019668 Grad: 0.134289 Thermal: 0.000789 LR: 3.12e-06\n",
      "Epoch  34 [1200/10697 ( 11.2%)] Loss: 0.033137 L1: 0.019668 Grad: 0.134289 Thermal: 0.000789 LR: 3.12e-06\n",
      "Epoch  34 [1250/10697 ( 11.7%)] Loss: 0.031768 L1: 0.018400 Grad: 0.133394 Thermal: 0.000582 LR: 3.12e-06\n",
      "Epoch  34 [1250/10697 ( 11.7%)] Loss: 0.031768 L1: 0.018400 Grad: 0.133394 Thermal: 0.000582 LR: 3.12e-06\n",
      "Epoch  34 [1300/10697 ( 12.2%)] Loss: 0.028831 L1: 0.016527 Grad: 0.122777 Thermal: 0.000527 LR: 3.12e-06\n",
      "Epoch  34 [1300/10697 ( 12.2%)] Loss: 0.028831 L1: 0.016527 Grad: 0.122777 Thermal: 0.000527 LR: 3.12e-06\n",
      "Epoch  34 [1350/10697 ( 12.6%)] Loss: 0.023861 L1: 0.013835 Grad: 0.100062 Thermal: 0.000381 LR: 3.12e-06\n",
      "Epoch  34 [1350/10697 ( 12.6%)] Loss: 0.023861 L1: 0.013835 Grad: 0.100062 Thermal: 0.000381 LR: 3.12e-06\n",
      "Epoch  34 [1400/10697 ( 13.1%)] Loss: 0.027618 L1: 0.016026 Grad: 0.115688 Thermal: 0.000465 LR: 3.12e-06\n",
      "Epoch  34 [1400/10697 ( 13.1%)] Loss: 0.027618 L1: 0.016026 Grad: 0.115688 Thermal: 0.000465 LR: 3.12e-06\n",
      "Epoch  34 [1450/10697 ( 13.6%)] Loss: 0.024618 L1: 0.014736 Grad: 0.098621 Thermal: 0.000397 LR: 3.12e-06\n",
      "Epoch  34 [1450/10697 ( 13.6%)] Loss: 0.024618 L1: 0.014736 Grad: 0.098621 Thermal: 0.000397 LR: 3.12e-06\n",
      "Epoch  34 [1500/10697 ( 14.0%)] Loss: 0.031179 L1: 0.018111 Grad: 0.130371 Thermal: 0.000609 LR: 3.12e-06\n",
      "Epoch  34 [1500/10697 ( 14.0%)] Loss: 0.031179 L1: 0.018111 Grad: 0.130371 Thermal: 0.000609 LR: 3.12e-06\n",
      "Epoch  34 [1550/10697 ( 14.5%)] Loss: 0.022201 L1: 0.013222 Grad: 0.089630 Thermal: 0.000321 LR: 3.12e-06\n",
      "Epoch  34 [1550/10697 ( 14.5%)] Loss: 0.022201 L1: 0.013222 Grad: 0.089630 Thermal: 0.000321 LR: 3.12e-06\n",
      "Epoch  34 [1600/10697 ( 15.0%)] Loss: 0.024085 L1: 0.014174 Grad: 0.098937 Thermal: 0.000354 LR: 3.12e-06\n",
      "Epoch  34 [1600/10697 ( 15.0%)] Loss: 0.024085 L1: 0.014174 Grad: 0.098937 Thermal: 0.000354 LR: 3.12e-06\n",
      "Epoch  34 [1650/10697 ( 15.4%)] Loss: 0.033358 L1: 0.018990 Grad: 0.143317 Thermal: 0.000716 LR: 3.12e-06\n",
      "Epoch  34 [1650/10697 ( 15.4%)] Loss: 0.033358 L1: 0.018990 Grad: 0.143317 Thermal: 0.000716 LR: 3.12e-06\n",
      "Epoch  34 [1700/10697 ( 15.9%)] Loss: 0.023882 L1: 0.013438 Grad: 0.104251 Thermal: 0.000378 LR: 3.12e-06\n",
      "Epoch  34 [1700/10697 ( 15.9%)] Loss: 0.023882 L1: 0.013438 Grad: 0.104251 Thermal: 0.000378 LR: 3.12e-06\n",
      "Epoch  34 [1750/10697 ( 16.4%)] Loss: 0.024354 L1: 0.014174 Grad: 0.101614 Thermal: 0.000364 LR: 3.12e-06\n",
      "Epoch  34 [1750/10697 ( 16.4%)] Loss: 0.024354 L1: 0.014174 Grad: 0.101614 Thermal: 0.000364 LR: 3.12e-06\n",
      "Epoch  34 [1800/10697 ( 16.8%)] Loss: 0.021916 L1: 0.012689 Grad: 0.092118 Thermal: 0.000314 LR: 3.12e-06\n",
      "Epoch  34 [1800/10697 ( 16.8%)] Loss: 0.021916 L1: 0.012689 Grad: 0.092118 Thermal: 0.000314 LR: 3.12e-06\n",
      "Epoch  34 [1850/10697 ( 17.3%)] Loss: 0.030406 L1: 0.017554 Grad: 0.128240 Thermal: 0.000566 LR: 3.12e-06\n",
      "Epoch  34 [1850/10697 ( 17.3%)] Loss: 0.030406 L1: 0.017554 Grad: 0.128240 Thermal: 0.000566 LR: 3.12e-06\n",
      "Epoch  34 [1900/10697 ( 17.8%)] Loss: 0.028057 L1: 0.016309 Grad: 0.117239 Thermal: 0.000481 LR: 3.12e-06\n",
      "Epoch  34 [1900/10697 ( 17.8%)] Loss: 0.028057 L1: 0.016309 Grad: 0.117239 Thermal: 0.000481 LR: 3.12e-06\n",
      "Epoch  34 [1950/10697 ( 18.2%)] Loss: 0.029045 L1: 0.016762 Grad: 0.122527 Thermal: 0.000607 LR: 3.12e-06\n",
      "Epoch  34 [1950/10697 ( 18.2%)] Loss: 0.029045 L1: 0.016762 Grad: 0.122527 Thermal: 0.000607 LR: 3.12e-06\n",
      "Epoch  34 [2000/10697 ( 18.7%)] Loss: 0.027893 L1: 0.016428 Grad: 0.114409 Thermal: 0.000486 LR: 3.12e-06\n",
      "Epoch  34 [2000/10697 ( 18.7%)] Loss: 0.027893 L1: 0.016428 Grad: 0.114409 Thermal: 0.000486 LR: 3.12e-06\n",
      "Epoch  34 [2050/10697 ( 19.2%)] Loss: 0.027030 L1: 0.015790 Grad: 0.112160 Thermal: 0.000474 LR: 3.12e-06\n",
      "Epoch  34 [2050/10697 ( 19.2%)] Loss: 0.027030 L1: 0.015790 Grad: 0.112160 Thermal: 0.000474 LR: 3.12e-06\n",
      "Epoch  34 [2100/10697 ( 19.6%)] Loss: 0.028082 L1: 0.016601 Grad: 0.114558 Thermal: 0.000499 LR: 3.12e-06\n",
      "Epoch  34 [2100/10697 ( 19.6%)] Loss: 0.028082 L1: 0.016601 Grad: 0.114558 Thermal: 0.000499 LR: 3.12e-06\n",
      "Epoch  34 [2150/10697 ( 20.1%)] Loss: 0.027225 L1: 0.016268 Grad: 0.109325 Thermal: 0.000481 LR: 3.12e-06\n",
      "Epoch  34 [2150/10697 ( 20.1%)] Loss: 0.027225 L1: 0.016268 Grad: 0.109325 Thermal: 0.000481 LR: 3.12e-06\n",
      "Epoch  34 [2200/10697 ( 20.6%)] Loss: 0.026184 L1: 0.015384 Grad: 0.107784 Thermal: 0.000442 LR: 3.12e-06\n",
      "Epoch  34 [2200/10697 ( 20.6%)] Loss: 0.026184 L1: 0.015384 Grad: 0.107784 Thermal: 0.000442 LR: 3.12e-06\n",
      "Epoch  34 [2250/10697 ( 21.0%)] Loss: 0.022357 L1: 0.012845 Grad: 0.094965 Thermal: 0.000325 LR: 3.12e-06\n",
      "Epoch  34 [2250/10697 ( 21.0%)] Loss: 0.022357 L1: 0.012845 Grad: 0.094965 Thermal: 0.000325 LR: 3.12e-06\n",
      "Epoch  34 [2300/10697 ( 21.5%)] Loss: 0.030482 L1: 0.017752 Grad: 0.126997 Thermal: 0.000606 LR: 3.12e-06\n",
      "Epoch  34 [2300/10697 ( 21.5%)] Loss: 0.030482 L1: 0.017752 Grad: 0.126997 Thermal: 0.000606 LR: 3.12e-06\n",
      "Epoch  34 [2350/10697 ( 22.0%)] Loss: 0.023156 L1: 0.013234 Grad: 0.099049 Thermal: 0.000346 LR: 3.12e-06\n",
      "Epoch  34 [2350/10697 ( 22.0%)] Loss: 0.023156 L1: 0.013234 Grad: 0.099049 Thermal: 0.000346 LR: 3.12e-06\n",
      "Epoch  34 [2400/10697 ( 22.4%)] Loss: 0.021565 L1: 0.012494 Grad: 0.090551 Thermal: 0.000321 LR: 3.12e-06\n",
      "Epoch  34 [2400/10697 ( 22.4%)] Loss: 0.021565 L1: 0.012494 Grad: 0.090551 Thermal: 0.000321 LR: 3.12e-06\n",
      "Epoch  34 [2450/10697 ( 22.9%)] Loss: 0.027239 L1: 0.016477 Grad: 0.107383 Thermal: 0.000475 LR: 3.12e-06\n",
      "Epoch  34 [2450/10697 ( 22.9%)] Loss: 0.027239 L1: 0.016477 Grad: 0.107383 Thermal: 0.000475 LR: 3.12e-06\n",
      "Epoch  34 [2500/10697 ( 23.4%)] Loss: 0.025330 L1: 0.014768 Grad: 0.105411 Thermal: 0.000406 LR: 3.12e-06\n",
      "Epoch  34 [2500/10697 ( 23.4%)] Loss: 0.025330 L1: 0.014768 Grad: 0.105411 Thermal: 0.000406 LR: 3.12e-06\n",
      "Epoch  34 [2550/10697 ( 23.8%)] Loss: 0.026195 L1: 0.015204 Grad: 0.109675 Thermal: 0.000461 LR: 3.12e-06\n",
      "Epoch  34 [2550/10697 ( 23.8%)] Loss: 0.026195 L1: 0.015204 Grad: 0.109675 Thermal: 0.000461 LR: 3.12e-06\n",
      "Epoch  34 [2600/10697 ( 24.3%)] Loss: 0.027479 L1: 0.016379 Grad: 0.110761 Thermal: 0.000480 LR: 3.12e-06\n",
      "Epoch  34 [2600/10697 ( 24.3%)] Loss: 0.027479 L1: 0.016379 Grad: 0.110761 Thermal: 0.000480 LR: 3.12e-06\n",
      "Epoch  34 [2650/10697 ( 24.8%)] Loss: 0.026883 L1: 0.016057 Grad: 0.108023 Thermal: 0.000475 LR: 3.12e-06\n",
      "Epoch  34 [2650/10697 ( 24.8%)] Loss: 0.026883 L1: 0.016057 Grad: 0.108023 Thermal: 0.000475 LR: 3.12e-06\n",
      "Epoch  34 [2700/10697 ( 25.2%)] Loss: 0.023597 L1: 0.013835 Grad: 0.097437 Thermal: 0.000354 LR: 3.12e-06\n",
      "Epoch  34 [2700/10697 ( 25.2%)] Loss: 0.023597 L1: 0.013835 Grad: 0.097437 Thermal: 0.000354 LR: 3.12e-06\n",
      "Epoch  34 [2750/10697 ( 25.7%)] Loss: 0.020433 L1: 0.011784 Grad: 0.086327 Thermal: 0.000325 LR: 3.12e-06\n",
      "Epoch  34 [2750/10697 ( 25.7%)] Loss: 0.020433 L1: 0.011784 Grad: 0.086327 Thermal: 0.000325 LR: 3.12e-06\n",
      "Epoch  34 [2800/10697 ( 26.2%)] Loss: 0.025781 L1: 0.015413 Grad: 0.103456 Thermal: 0.000452 LR: 3.12e-06\n",
      "Epoch  34 [2800/10697 ( 26.2%)] Loss: 0.025781 L1: 0.015413 Grad: 0.103456 Thermal: 0.000452 LR: 3.12e-06\n",
      "Epoch  34 [2850/10697 ( 26.6%)] Loss: 0.026540 L1: 0.015375 Grad: 0.111431 Thermal: 0.000448 LR: 3.12e-06\n",
      "Epoch  34 [2850/10697 ( 26.6%)] Loss: 0.026540 L1: 0.015375 Grad: 0.111431 Thermal: 0.000448 LR: 3.12e-06\n",
      "Epoch  34 [2900/10697 ( 27.1%)] Loss: 0.029284 L1: 0.017273 Grad: 0.119830 Thermal: 0.000554 LR: 3.12e-06\n",
      "Epoch  34 [2900/10697 ( 27.1%)] Loss: 0.029284 L1: 0.017273 Grad: 0.119830 Thermal: 0.000554 LR: 3.12e-06\n",
      "Epoch  34 [2950/10697 ( 27.6%)] Loss: 0.028075 L1: 0.015978 Grad: 0.120703 Thermal: 0.000534 LR: 3.12e-06\n",
      "Epoch  34 [2950/10697 ( 27.6%)] Loss: 0.028075 L1: 0.015978 Grad: 0.120703 Thermal: 0.000534 LR: 3.12e-06\n",
      "Epoch  34 [3000/10697 ( 28.0%)] Loss: 0.026021 L1: 0.015802 Grad: 0.101971 Thermal: 0.000444 LR: 3.12e-06\n",
      "Epoch  34 [3000/10697 ( 28.0%)] Loss: 0.026021 L1: 0.015802 Grad: 0.101971 Thermal: 0.000444 LR: 3.12e-06\n",
      "Epoch  34 [3050/10697 ( 28.5%)] Loss: 0.030536 L1: 0.017480 Grad: 0.130272 Thermal: 0.000587 LR: 3.12e-06\n",
      "Epoch  34 [3050/10697 ( 28.5%)] Loss: 0.030536 L1: 0.017480 Grad: 0.130272 Thermal: 0.000587 LR: 3.12e-06\n",
      "Epoch  34 [3100/10697 ( 29.0%)] Loss: 0.024916 L1: 0.014599 Grad: 0.102967 Thermal: 0.000402 LR: 3.12e-06\n",
      "Epoch  34 [3100/10697 ( 29.0%)] Loss: 0.024916 L1: 0.014599 Grad: 0.102967 Thermal: 0.000402 LR: 3.12e-06\n",
      "Epoch  34 [3150/10697 ( 29.4%)] Loss: 0.023685 L1: 0.014253 Grad: 0.094126 Thermal: 0.000385 LR: 3.12e-06\n",
      "Epoch  34 [3150/10697 ( 29.4%)] Loss: 0.023685 L1: 0.014253 Grad: 0.094126 Thermal: 0.000385 LR: 3.12e-06\n",
      "Epoch  34 [3200/10697 ( 29.9%)] Loss: 0.029957 L1: 0.017402 Grad: 0.125218 Thermal: 0.000656 LR: 3.12e-06\n",
      "Epoch  34 [3200/10697 ( 29.9%)] Loss: 0.029957 L1: 0.017402 Grad: 0.125218 Thermal: 0.000656 LR: 3.12e-06\n",
      "Epoch  34 [3250/10697 ( 30.4%)] Loss: 0.026070 L1: 0.015708 Grad: 0.103395 Thermal: 0.000442 LR: 3.12e-06\n",
      "Epoch  34 [3250/10697 ( 30.4%)] Loss: 0.026070 L1: 0.015708 Grad: 0.103395 Thermal: 0.000442 LR: 3.12e-06\n",
      "Epoch  34 [3300/10697 ( 30.8%)] Loss: 0.026450 L1: 0.015403 Grad: 0.110215 Thermal: 0.000510 LR: 3.12e-06\n",
      "Epoch  34 [3300/10697 ( 30.8%)] Loss: 0.026450 L1: 0.015403 Grad: 0.110215 Thermal: 0.000510 LR: 3.12e-06\n",
      "Epoch  34 [3350/10697 ( 31.3%)] Loss: 0.026654 L1: 0.015509 Grad: 0.111221 Thermal: 0.000461 LR: 3.12e-06\n",
      "Epoch  34 [3350/10697 ( 31.3%)] Loss: 0.026654 L1: 0.015509 Grad: 0.111221 Thermal: 0.000461 LR: 3.12e-06\n",
      "Epoch  34 [3400/10697 ( 31.8%)] Loss: 0.027369 L1: 0.016228 Grad: 0.111167 Thermal: 0.000490 LR: 3.12e-06\n",
      "Epoch  34 [3400/10697 ( 31.8%)] Loss: 0.027369 L1: 0.016228 Grad: 0.111167 Thermal: 0.000490 LR: 3.12e-06\n",
      "Epoch  34 [3450/10697 ( 32.3%)] Loss: 0.031422 L1: 0.017502 Grad: 0.138830 Thermal: 0.000731 LR: 3.12e-06\n",
      "Epoch  34 [3450/10697 ( 32.3%)] Loss: 0.031422 L1: 0.017502 Grad: 0.138830 Thermal: 0.000731 LR: 3.12e-06\n",
      "Epoch  34 [3500/10697 ( 32.7%)] Loss: 0.025653 L1: 0.015392 Grad: 0.102380 Thermal: 0.000453 LR: 3.12e-06\n",
      "Epoch  34 [3500/10697 ( 32.7%)] Loss: 0.025653 L1: 0.015392 Grad: 0.102380 Thermal: 0.000453 LR: 3.12e-06\n",
      "Epoch  34 [3550/10697 ( 33.2%)] Loss: 0.025040 L1: 0.014429 Grad: 0.105922 Thermal: 0.000389 LR: 3.12e-06\n",
      "Epoch  34 [3550/10697 ( 33.2%)] Loss: 0.025040 L1: 0.014429 Grad: 0.105922 Thermal: 0.000389 LR: 3.12e-06\n",
      "Epoch  34 [3600/10697 ( 33.7%)] Loss: 0.028531 L1: 0.017081 Grad: 0.114240 Thermal: 0.000523 LR: 3.12e-06\n",
      "Epoch  34 [3600/10697 ( 33.7%)] Loss: 0.028531 L1: 0.017081 Grad: 0.114240 Thermal: 0.000523 LR: 3.12e-06\n",
      "Epoch  34 [3650/10697 ( 34.1%)] Loss: 0.027755 L1: 0.015600 Grad: 0.121319 Thermal: 0.000452 LR: 3.12e-06\n",
      "Epoch  34 [3650/10697 ( 34.1%)] Loss: 0.027755 L1: 0.015600 Grad: 0.121319 Thermal: 0.000452 LR: 3.12e-06\n",
      "Epoch  34 [3700/10697 ( 34.6%)] Loss: 0.032396 L1: 0.018586 Grad: 0.137801 Thermal: 0.000608 LR: 3.12e-06\n",
      "Epoch  34 [3700/10697 ( 34.6%)] Loss: 0.032396 L1: 0.018586 Grad: 0.137801 Thermal: 0.000608 LR: 3.12e-06\n",
      "Epoch  34 [3750/10697 ( 35.1%)] Loss: 0.027022 L1: 0.015839 Grad: 0.111605 Thermal: 0.000455 LR: 3.12e-06\n",
      "Epoch  34 [3750/10697 ( 35.1%)] Loss: 0.027022 L1: 0.015839 Grad: 0.111605 Thermal: 0.000455 LR: 3.12e-06\n",
      "Epoch  34 [3800/10697 ( 35.5%)] Loss: 0.025583 L1: 0.014873 Grad: 0.106885 Thermal: 0.000441 LR: 3.12e-06\n",
      "Epoch  34 [3800/10697 ( 35.5%)] Loss: 0.025583 L1: 0.014873 Grad: 0.106885 Thermal: 0.000441 LR: 3.12e-06\n",
      "Epoch  34 [3850/10697 ( 36.0%)] Loss: 0.027398 L1: 0.016460 Grad: 0.109121 Thermal: 0.000510 LR: 3.12e-06\n",
      "Epoch  34 [3850/10697 ( 36.0%)] Loss: 0.027398 L1: 0.016460 Grad: 0.109121 Thermal: 0.000510 LR: 3.12e-06\n",
      "Epoch  34 [3900/10697 ( 36.5%)] Loss: 0.021736 L1: 0.012678 Grad: 0.090424 Thermal: 0.000314 LR: 3.12e-06\n",
      "Epoch  34 [3900/10697 ( 36.5%)] Loss: 0.021736 L1: 0.012678 Grad: 0.090424 Thermal: 0.000314 LR: 3.12e-06\n",
      "Epoch  34 [3950/10697 ( 36.9%)] Loss: 0.022216 L1: 0.012889 Grad: 0.093100 Thermal: 0.000341 LR: 3.12e-06\n",
      "Epoch  34 [3950/10697 ( 36.9%)] Loss: 0.022216 L1: 0.012889 Grad: 0.093100 Thermal: 0.000341 LR: 3.12e-06\n",
      "Epoch  34 [4000/10697 ( 37.4%)] Loss: 0.028774 L1: 0.016320 Grad: 0.124302 Thermal: 0.000480 LR: 3.12e-06\n",
      "Epoch  34 [4000/10697 ( 37.4%)] Loss: 0.028774 L1: 0.016320 Grad: 0.124302 Thermal: 0.000480 LR: 3.12e-06\n",
      "Epoch  34 [4050/10697 ( 37.9%)] Loss: 0.026928 L1: 0.015338 Grad: 0.115667 Thermal: 0.000456 LR: 3.12e-06\n",
      "Epoch  34 [4050/10697 ( 37.9%)] Loss: 0.026928 L1: 0.015338 Grad: 0.115667 Thermal: 0.000456 LR: 3.12e-06\n",
      "Epoch  34 [4100/10697 ( 38.3%)] Loss: 0.027694 L1: 0.016322 Grad: 0.113485 Thermal: 0.000476 LR: 3.12e-06\n",
      "Epoch  34 [4100/10697 ( 38.3%)] Loss: 0.027694 L1: 0.016322 Grad: 0.113485 Thermal: 0.000476 LR: 3.12e-06\n",
      "Epoch  34 [4150/10697 ( 38.8%)] Loss: 0.029022 L1: 0.016755 Grad: 0.122410 Thermal: 0.000522 LR: 3.12e-06\n",
      "Epoch  34 [4150/10697 ( 38.8%)] Loss: 0.029022 L1: 0.016755 Grad: 0.122410 Thermal: 0.000522 LR: 3.12e-06\n",
      "Epoch  34 [4200/10697 ( 39.3%)] Loss: 0.023320 L1: 0.013687 Grad: 0.096158 Thermal: 0.000359 LR: 3.12e-06\n",
      "Epoch  34 [4200/10697 ( 39.3%)] Loss: 0.023320 L1: 0.013687 Grad: 0.096158 Thermal: 0.000359 LR: 3.12e-06\n",
      "Epoch  34 [4250/10697 ( 39.7%)] Loss: 0.025511 L1: 0.014525 Grad: 0.109650 Thermal: 0.000413 LR: 3.12e-06\n",
      "Epoch  34 [4250/10697 ( 39.7%)] Loss: 0.025511 L1: 0.014525 Grad: 0.109650 Thermal: 0.000413 LR: 3.12e-06\n",
      "Epoch  34 [4300/10697 ( 40.2%)] Loss: 0.029086 L1: 0.017153 Grad: 0.119057 Thermal: 0.000549 LR: 3.12e-06\n",
      "Epoch  34 [4300/10697 ( 40.2%)] Loss: 0.029086 L1: 0.017153 Grad: 0.119057 Thermal: 0.000549 LR: 3.12e-06\n",
      "Epoch  34 [4350/10697 ( 40.7%)] Loss: 0.027288 L1: 0.015828 Grad: 0.114374 Thermal: 0.000453 LR: 3.12e-06\n",
      "Epoch  34 [4350/10697 ( 40.7%)] Loss: 0.027288 L1: 0.015828 Grad: 0.114374 Thermal: 0.000453 LR: 3.12e-06\n",
      "Epoch  34 [4400/10697 ( 41.1%)] Loss: 0.028654 L1: 0.016906 Grad: 0.117234 Thermal: 0.000493 LR: 3.12e-06\n",
      "Epoch  34 [4400/10697 ( 41.1%)] Loss: 0.028654 L1: 0.016906 Grad: 0.117234 Thermal: 0.000493 LR: 3.12e-06\n",
      "Epoch  34 [4450/10697 ( 41.6%)] Loss: 0.026920 L1: 0.015760 Grad: 0.111346 Thermal: 0.000504 LR: 3.12e-06\n",
      "Epoch  34 [4450/10697 ( 41.6%)] Loss: 0.026920 L1: 0.015760 Grad: 0.111346 Thermal: 0.000504 LR: 3.12e-06\n",
      "Epoch  34 [4500/10697 ( 42.1%)] Loss: 0.025669 L1: 0.015404 Grad: 0.102449 Thermal: 0.000402 LR: 3.12e-06\n",
      "Epoch  34 [4500/10697 ( 42.1%)] Loss: 0.025669 L1: 0.015404 Grad: 0.102449 Thermal: 0.000402 LR: 3.12e-06\n",
      "Epoch  34 [4550/10697 ( 42.5%)] Loss: 0.015841 L1: 0.008855 Grad: 0.069763 Thermal: 0.000176 LR: 3.12e-06\n",
      "Epoch  34 [4550/10697 ( 42.5%)] Loss: 0.015841 L1: 0.008855 Grad: 0.069763 Thermal: 0.000176 LR: 3.12e-06\n",
      "Epoch  34 [4600/10697 ( 43.0%)] Loss: 0.019570 L1: 0.011221 Grad: 0.083365 Thermal: 0.000246 LR: 3.12e-06\n",
      "Epoch  34 [4600/10697 ( 43.0%)] Loss: 0.019570 L1: 0.011221 Grad: 0.083365 Thermal: 0.000246 LR: 3.12e-06\n",
      "Epoch  34 [4650/10697 ( 43.5%)] Loss: 0.026421 L1: 0.015557 Grad: 0.108410 Thermal: 0.000461 LR: 3.12e-06\n",
      "Epoch  34 [4650/10697 ( 43.5%)] Loss: 0.026421 L1: 0.015557 Grad: 0.108410 Thermal: 0.000461 LR: 3.12e-06\n",
      "Epoch  34 [4700/10697 ( 43.9%)] Loss: 0.024911 L1: 0.014784 Grad: 0.101056 Thermal: 0.000430 LR: 3.12e-06\n",
      "Epoch  34 [4700/10697 ( 43.9%)] Loss: 0.024911 L1: 0.014784 Grad: 0.101056 Thermal: 0.000430 LR: 3.12e-06\n",
      "Epoch  34 [4750/10697 ( 44.4%)] Loss: 0.029355 L1: 0.017538 Grad: 0.117893 Thermal: 0.000538 LR: 3.12e-06\n",
      "Epoch  34 [4750/10697 ( 44.4%)] Loss: 0.029355 L1: 0.017538 Grad: 0.117893 Thermal: 0.000538 LR: 3.12e-06\n",
      "Epoch  34 [4800/10697 ( 44.9%)] Loss: 0.026695 L1: 0.015896 Grad: 0.107771 Thermal: 0.000446 LR: 3.12e-06\n",
      "Epoch  34 [4800/10697 ( 44.9%)] Loss: 0.026695 L1: 0.015896 Grad: 0.107771 Thermal: 0.000446 LR: 3.12e-06\n",
      "Epoch  34 [4850/10697 ( 45.3%)] Loss: 0.017924 L1: 0.010144 Grad: 0.077655 Thermal: 0.000291 LR: 3.12e-06\n",
      "Epoch  34 [4850/10697 ( 45.3%)] Loss: 0.017924 L1: 0.010144 Grad: 0.077655 Thermal: 0.000291 LR: 3.12e-06\n",
      "Epoch  34 [4900/10697 ( 45.8%)] Loss: 0.030825 L1: 0.017972 Grad: 0.128261 Thermal: 0.000551 LR: 3.12e-06\n",
      "Epoch  34 [4900/10697 ( 45.8%)] Loss: 0.030825 L1: 0.017972 Grad: 0.128261 Thermal: 0.000551 LR: 3.12e-06\n",
      "Epoch  34 [4950/10697 ( 46.3%)] Loss: 0.025703 L1: 0.014890 Grad: 0.107915 Thermal: 0.000430 LR: 3.12e-06\n",
      "Epoch  34 [4950/10697 ( 46.3%)] Loss: 0.025703 L1: 0.014890 Grad: 0.107915 Thermal: 0.000430 LR: 3.12e-06\n",
      "Epoch  34 [5000/10697 ( 46.7%)] Loss: 0.018436 L1: 0.010406 Grad: 0.080145 Thermal: 0.000309 LR: 3.12e-06\n",
      "Epoch  34 [5000/10697 ( 46.7%)] Loss: 0.018436 L1: 0.010406 Grad: 0.080145 Thermal: 0.000309 LR: 3.12e-06\n",
      "Epoch  34 [5050/10697 ( 47.2%)] Loss: 0.027751 L1: 0.015791 Grad: 0.119363 Thermal: 0.000457 LR: 3.12e-06\n",
      "Epoch  34 [5050/10697 ( 47.2%)] Loss: 0.027751 L1: 0.015791 Grad: 0.119363 Thermal: 0.000457 LR: 3.12e-06\n",
      "Epoch  34 [5100/10697 ( 47.7%)] Loss: 0.026460 L1: 0.015730 Grad: 0.107055 Thermal: 0.000485 LR: 3.12e-06\n",
      "Epoch  34 [5100/10697 ( 47.7%)] Loss: 0.026460 L1: 0.015730 Grad: 0.107055 Thermal: 0.000485 LR: 3.12e-06\n",
      "Epoch  34 [5150/10697 ( 48.1%)] Loss: 0.028771 L1: 0.017245 Grad: 0.115001 Thermal: 0.000518 LR: 3.12e-06\n",
      "Epoch  34 [5150/10697 ( 48.1%)] Loss: 0.028771 L1: 0.017245 Grad: 0.115001 Thermal: 0.000518 LR: 3.12e-06\n",
      "Epoch  34 [5200/10697 ( 48.6%)] Loss: 0.019044 L1: 0.010856 Grad: 0.081744 Thermal: 0.000275 LR: 3.12e-06\n",
      "Epoch  34 [5200/10697 ( 48.6%)] Loss: 0.019044 L1: 0.010856 Grad: 0.081744 Thermal: 0.000275 LR: 3.12e-06\n",
      "Epoch  34 [5250/10697 ( 49.1%)] Loss: 0.024761 L1: 0.014295 Grad: 0.104461 Thermal: 0.000406 LR: 3.12e-06\n",
      "Epoch  34 [5250/10697 ( 49.1%)] Loss: 0.024761 L1: 0.014295 Grad: 0.104461 Thermal: 0.000406 LR: 3.12e-06\n",
      "Epoch  34 [5300/10697 ( 49.5%)] Loss: 0.030560 L1: 0.017878 Grad: 0.126512 Thermal: 0.000608 LR: 3.12e-06\n",
      "Epoch  34 [5300/10697 ( 49.5%)] Loss: 0.030560 L1: 0.017878 Grad: 0.126512 Thermal: 0.000608 LR: 3.12e-06\n",
      "Epoch  34 [5350/10697 ( 50.0%)] Loss: 0.024754 L1: 0.014389 Grad: 0.103464 Thermal: 0.000386 LR: 3.12e-06\n",
      "Epoch  34 [5350/10697 ( 50.0%)] Loss: 0.024754 L1: 0.014389 Grad: 0.103464 Thermal: 0.000386 LR: 3.12e-06\n",
      "Epoch  34 [5400/10697 ( 50.5%)] Loss: 0.028501 L1: 0.016916 Grad: 0.115595 Thermal: 0.000498 LR: 3.12e-06\n",
      "Epoch  34 [5400/10697 ( 50.5%)] Loss: 0.028501 L1: 0.016916 Grad: 0.115595 Thermal: 0.000498 LR: 3.12e-06\n",
      "Epoch  34 [5450/10697 ( 50.9%)] Loss: 0.029080 L1: 0.016950 Grad: 0.121057 Thermal: 0.000497 LR: 3.12e-06\n",
      "Epoch  34 [5450/10697 ( 50.9%)] Loss: 0.029080 L1: 0.016950 Grad: 0.121057 Thermal: 0.000497 LR: 3.12e-06\n",
      "Epoch  34 [5500/10697 ( 51.4%)] Loss: 0.024752 L1: 0.014332 Grad: 0.103990 Thermal: 0.000428 LR: 3.12e-06\n",
      "Epoch  34 [5500/10697 ( 51.4%)] Loss: 0.024752 L1: 0.014332 Grad: 0.103990 Thermal: 0.000428 LR: 3.12e-06\n",
      "Epoch  34 [5550/10697 ( 51.9%)] Loss: 0.022401 L1: 0.012855 Grad: 0.095292 Thermal: 0.000326 LR: 3.12e-06\n",
      "Epoch  34 [5550/10697 ( 51.9%)] Loss: 0.022401 L1: 0.012855 Grad: 0.095292 Thermal: 0.000326 LR: 3.12e-06\n",
      "Epoch  34 [5600/10697 ( 52.4%)] Loss: 0.023194 L1: 0.013830 Grad: 0.093459 Thermal: 0.000365 LR: 3.12e-06\n",
      "Epoch  34 [5600/10697 ( 52.4%)] Loss: 0.023194 L1: 0.013830 Grad: 0.093459 Thermal: 0.000365 LR: 3.12e-06\n",
      "Epoch  34 [5650/10697 ( 52.8%)] Loss: 0.022368 L1: 0.012968 Grad: 0.093829 Thermal: 0.000336 LR: 3.12e-06\n",
      "Epoch  34 [5650/10697 ( 52.8%)] Loss: 0.022368 L1: 0.012968 Grad: 0.093829 Thermal: 0.000336 LR: 3.12e-06\n",
      "Epoch  34 [5700/10697 ( 53.3%)] Loss: 0.024455 L1: 0.014149 Grad: 0.102882 Thermal: 0.000360 LR: 3.12e-06\n",
      "Epoch  34 [5700/10697 ( 53.3%)] Loss: 0.024455 L1: 0.014149 Grad: 0.102882 Thermal: 0.000360 LR: 3.12e-06\n",
      "Epoch  34 [5750/10697 ( 53.8%)] Loss: 0.028882 L1: 0.016858 Grad: 0.119923 Thermal: 0.000632 LR: 3.12e-06\n",
      "Epoch  34 [5750/10697 ( 53.8%)] Loss: 0.028882 L1: 0.016858 Grad: 0.119923 Thermal: 0.000632 LR: 3.12e-06\n",
      "Epoch  34 [5800/10697 ( 54.2%)] Loss: 0.027550 L1: 0.015732 Grad: 0.117917 Thermal: 0.000524 LR: 3.12e-06\n",
      "Epoch  34 [5800/10697 ( 54.2%)] Loss: 0.027550 L1: 0.015732 Grad: 0.117917 Thermal: 0.000524 LR: 3.12e-06\n",
      "Epoch  34 [5850/10697 ( 54.7%)] Loss: 0.024656 L1: 0.014467 Grad: 0.101700 Thermal: 0.000379 LR: 3.12e-06\n",
      "Epoch  34 [5850/10697 ( 54.7%)] Loss: 0.024656 L1: 0.014467 Grad: 0.101700 Thermal: 0.000379 LR: 3.12e-06\n",
      "Epoch  34 [5900/10697 ( 55.2%)] Loss: 0.029743 L1: 0.017324 Grad: 0.123853 Thermal: 0.000668 LR: 3.12e-06\n",
      "Epoch  34 [5900/10697 ( 55.2%)] Loss: 0.029743 L1: 0.017324 Grad: 0.123853 Thermal: 0.000668 LR: 3.12e-06\n",
      "Epoch  34 [5950/10697 ( 55.6%)] Loss: 0.022078 L1: 0.013213 Grad: 0.088482 Thermal: 0.000350 LR: 3.12e-06\n",
      "Epoch  34 [5950/10697 ( 55.6%)] Loss: 0.022078 L1: 0.013213 Grad: 0.088482 Thermal: 0.000350 LR: 3.12e-06\n",
      "Epoch  34 [6000/10697 ( 56.1%)] Loss: 0.025194 L1: 0.014888 Grad: 0.102846 Thermal: 0.000419 LR: 3.12e-06\n",
      "Epoch  34 [6000/10697 ( 56.1%)] Loss: 0.025194 L1: 0.014888 Grad: 0.102846 Thermal: 0.000419 LR: 3.12e-06\n",
      "Epoch  34 [6050/10697 ( 56.6%)] Loss: 0.025100 L1: 0.014841 Grad: 0.102377 Thermal: 0.000416 LR: 3.12e-06\n",
      "Epoch  34 [6050/10697 ( 56.6%)] Loss: 0.025100 L1: 0.014841 Grad: 0.102377 Thermal: 0.000416 LR: 3.12e-06\n",
      "Epoch  34 [6100/10697 ( 57.0%)] Loss: 0.032537 L1: 0.018438 Grad: 0.140679 Thermal: 0.000635 LR: 3.12e-06\n",
      "Epoch  34 [6100/10697 ( 57.0%)] Loss: 0.032537 L1: 0.018438 Grad: 0.140679 Thermal: 0.000635 LR: 3.12e-06\n",
      "Epoch  34 [6150/10697 ( 57.5%)] Loss: 0.028195 L1: 0.016499 Grad: 0.116722 Thermal: 0.000474 LR: 3.12e-06\n",
      "Epoch  34 [6150/10697 ( 57.5%)] Loss: 0.028195 L1: 0.016499 Grad: 0.116722 Thermal: 0.000474 LR: 3.12e-06\n",
      "Epoch  34 [6200/10697 ( 58.0%)] Loss: 0.022557 L1: 0.013243 Grad: 0.092961 Thermal: 0.000363 LR: 3.12e-06\n",
      "Epoch  34 [6200/10697 ( 58.0%)] Loss: 0.022557 L1: 0.013243 Grad: 0.092961 Thermal: 0.000363 LR: 3.12e-06\n",
      "Epoch  34 [6250/10697 ( 58.4%)] Loss: 0.027399 L1: 0.015578 Grad: 0.117963 Thermal: 0.000497 LR: 3.12e-06\n",
      "Epoch  34 [6250/10697 ( 58.4%)] Loss: 0.027399 L1: 0.015578 Grad: 0.117963 Thermal: 0.000497 LR: 3.12e-06\n",
      "Epoch  34 [6300/10697 ( 58.9%)] Loss: 0.025793 L1: 0.015125 Grad: 0.106469 Thermal: 0.000409 LR: 3.12e-06\n",
      "Epoch  34 [6300/10697 ( 58.9%)] Loss: 0.025793 L1: 0.015125 Grad: 0.106469 Thermal: 0.000409 LR: 3.12e-06\n",
      "Epoch  34 [6350/10697 ( 59.4%)] Loss: 0.023876 L1: 0.013612 Grad: 0.102461 Thermal: 0.000346 LR: 3.12e-06\n",
      "Epoch  34 [6350/10697 ( 59.4%)] Loss: 0.023876 L1: 0.013612 Grad: 0.102461 Thermal: 0.000346 LR: 3.12e-06\n",
      "Epoch  34 [6400/10697 ( 59.8%)] Loss: 0.025131 L1: 0.014755 Grad: 0.103563 Thermal: 0.000402 LR: 3.12e-06\n",
      "Epoch  34 [6400/10697 ( 59.8%)] Loss: 0.025131 L1: 0.014755 Grad: 0.103563 Thermal: 0.000402 LR: 3.12e-06\n",
      "Epoch  34 [6450/10697 ( 60.3%)] Loss: 0.019121 L1: 0.011350 Grad: 0.077565 Thermal: 0.000273 LR: 3.12e-06\n",
      "Epoch  34 [6450/10697 ( 60.3%)] Loss: 0.019121 L1: 0.011350 Grad: 0.077565 Thermal: 0.000273 LR: 3.12e-06\n",
      "Epoch  34 [6500/10697 ( 60.8%)] Loss: 0.021918 L1: 0.012782 Grad: 0.091180 Thermal: 0.000355 LR: 3.12e-06\n",
      "Epoch  34 [6500/10697 ( 60.8%)] Loss: 0.021918 L1: 0.012782 Grad: 0.091180 Thermal: 0.000355 LR: 3.12e-06\n",
      "Epoch  34 [6550/10697 ( 61.2%)] Loss: 0.023483 L1: 0.013448 Grad: 0.100172 Thermal: 0.000348 LR: 3.12e-06\n",
      "Epoch  34 [6550/10697 ( 61.2%)] Loss: 0.023483 L1: 0.013448 Grad: 0.100172 Thermal: 0.000348 LR: 3.12e-06\n",
      "Epoch  34 [6600/10697 ( 61.7%)] Loss: 0.027604 L1: 0.016140 Grad: 0.114374 Thermal: 0.000523 LR: 3.12e-06\n",
      "Epoch  34 [6600/10697 ( 61.7%)] Loss: 0.027604 L1: 0.016140 Grad: 0.114374 Thermal: 0.000523 LR: 3.12e-06\n",
      "Epoch  34 [6650/10697 ( 62.2%)] Loss: 0.026360 L1: 0.015290 Grad: 0.110471 Thermal: 0.000463 LR: 3.12e-06\n",
      "Epoch  34 [6650/10697 ( 62.2%)] Loss: 0.026360 L1: 0.015290 Grad: 0.110471 Thermal: 0.000463 LR: 3.12e-06\n",
      "Epoch  34 [6700/10697 ( 62.6%)] Loss: 0.029489 L1: 0.017634 Grad: 0.118279 Thermal: 0.000535 LR: 3.12e-06\n",
      "Epoch  34 [6700/10697 ( 62.6%)] Loss: 0.029489 L1: 0.017634 Grad: 0.118279 Thermal: 0.000535 LR: 3.12e-06\n",
      "Epoch  34 [6750/10697 ( 63.1%)] Loss: 0.023503 L1: 0.013591 Grad: 0.098942 Thermal: 0.000360 LR: 3.12e-06\n",
      "Epoch  34 [6750/10697 ( 63.1%)] Loss: 0.023503 L1: 0.013591 Grad: 0.098942 Thermal: 0.000360 LR: 3.12e-06\n",
      "Epoch  34 [6800/10697 ( 63.6%)] Loss: 0.027087 L1: 0.016162 Grad: 0.109023 Thermal: 0.000450 LR: 3.12e-06\n",
      "Epoch  34 [6800/10697 ( 63.6%)] Loss: 0.027087 L1: 0.016162 Grad: 0.109023 Thermal: 0.000450 LR: 3.12e-06\n",
      "Epoch  34 [6850/10697 ( 64.0%)] Loss: 0.028161 L1: 0.016535 Grad: 0.116005 Thermal: 0.000513 LR: 3.12e-06\n",
      "Epoch  34 [6850/10697 ( 64.0%)] Loss: 0.028161 L1: 0.016535 Grad: 0.116005 Thermal: 0.000513 LR: 3.12e-06\n",
      "Epoch  34 [6900/10697 ( 64.5%)] Loss: 0.028824 L1: 0.017185 Grad: 0.116138 Thermal: 0.000511 LR: 3.12e-06\n",
      "Epoch  34 [6900/10697 ( 64.5%)] Loss: 0.028824 L1: 0.017185 Grad: 0.116138 Thermal: 0.000511 LR: 3.12e-06\n",
      "Epoch  34 [6950/10697 ( 65.0%)] Loss: 0.025161 L1: 0.015139 Grad: 0.100010 Thermal: 0.000423 LR: 3.12e-06\n",
      "Epoch  34 [6950/10697 ( 65.0%)] Loss: 0.025161 L1: 0.015139 Grad: 0.100010 Thermal: 0.000423 LR: 3.12e-06\n",
      "Epoch  34 [7000/10697 ( 65.4%)] Loss: 0.025072 L1: 0.014957 Grad: 0.100952 Thermal: 0.000399 LR: 3.12e-06\n",
      "Epoch  34 [7000/10697 ( 65.4%)] Loss: 0.025072 L1: 0.014957 Grad: 0.100952 Thermal: 0.000399 LR: 3.12e-06\n",
      "Epoch  34 [7050/10697 ( 65.9%)] Loss: 0.026387 L1: 0.015924 Grad: 0.104402 Thermal: 0.000448 LR: 3.12e-06\n",
      "Epoch  34 [7050/10697 ( 65.9%)] Loss: 0.026387 L1: 0.015924 Grad: 0.104402 Thermal: 0.000448 LR: 3.12e-06\n",
      "Epoch  34 [7100/10697 ( 66.4%)] Loss: 0.028694 L1: 0.016585 Grad: 0.120841 Thermal: 0.000507 LR: 3.12e-06\n",
      "Epoch  34 [7100/10697 ( 66.4%)] Loss: 0.028694 L1: 0.016585 Grad: 0.120841 Thermal: 0.000507 LR: 3.12e-06\n",
      "Epoch  34 [7150/10697 ( 66.8%)] Loss: 0.022669 L1: 0.013017 Grad: 0.096357 Thermal: 0.000325 LR: 3.12e-06\n",
      "Epoch  34 [7150/10697 ( 66.8%)] Loss: 0.022669 L1: 0.013017 Grad: 0.096357 Thermal: 0.000325 LR: 3.12e-06\n",
      "Epoch  34 [7200/10697 ( 67.3%)] Loss: 0.019129 L1: 0.011271 Grad: 0.078441 Thermal: 0.000276 LR: 3.12e-06\n",
      "Epoch  34 [7200/10697 ( 67.3%)] Loss: 0.019129 L1: 0.011271 Grad: 0.078441 Thermal: 0.000276 LR: 3.12e-06\n",
      "Epoch  34 [7250/10697 ( 67.8%)] Loss: 0.027649 L1: 0.016021 Grad: 0.116029 Thermal: 0.000496 LR: 3.12e-06\n",
      "Epoch  34 [7250/10697 ( 67.8%)] Loss: 0.027649 L1: 0.016021 Grad: 0.116029 Thermal: 0.000496 LR: 3.12e-06\n",
      "Epoch  34 [7300/10697 ( 68.2%)] Loss: 0.030481 L1: 0.018247 Grad: 0.122029 Thermal: 0.000626 LR: 3.12e-06\n",
      "Epoch  34 [7300/10697 ( 68.2%)] Loss: 0.030481 L1: 0.018247 Grad: 0.122029 Thermal: 0.000626 LR: 3.12e-06\n",
      "Epoch  34 [7350/10697 ( 68.7%)] Loss: 0.027595 L1: 0.016019 Grad: 0.115517 Thermal: 0.000485 LR: 3.12e-06\n",
      "Epoch  34 [7350/10697 ( 68.7%)] Loss: 0.027595 L1: 0.016019 Grad: 0.115517 Thermal: 0.000485 LR: 3.12e-06\n",
      "Epoch  34 [7400/10697 ( 69.2%)] Loss: 0.029308 L1: 0.016307 Grad: 0.129739 Thermal: 0.000537 LR: 3.12e-06\n",
      "Epoch  34 [7400/10697 ( 69.2%)] Loss: 0.029308 L1: 0.016307 Grad: 0.129739 Thermal: 0.000537 LR: 3.12e-06\n",
      "Epoch  34 [7450/10697 ( 69.6%)] Loss: 0.023440 L1: 0.013052 Grad: 0.103687 Thermal: 0.000379 LR: 3.12e-06\n",
      "Epoch  34 [7450/10697 ( 69.6%)] Loss: 0.023440 L1: 0.013052 Grad: 0.103687 Thermal: 0.000379 LR: 3.12e-06\n",
      "Epoch  34 [7500/10697 ( 70.1%)] Loss: 0.023267 L1: 0.013794 Grad: 0.094565 Thermal: 0.000340 LR: 3.12e-06\n",
      "Epoch  34 [7500/10697 ( 70.1%)] Loss: 0.023267 L1: 0.013794 Grad: 0.094565 Thermal: 0.000340 LR: 3.12e-06\n",
      "Epoch  34 [7550/10697 ( 70.6%)] Loss: 0.026765 L1: 0.015354 Grad: 0.113886 Thermal: 0.000441 LR: 3.12e-06\n",
      "Epoch  34 [7550/10697 ( 70.6%)] Loss: 0.026765 L1: 0.015354 Grad: 0.113886 Thermal: 0.000441 LR: 3.12e-06\n",
      "Epoch  34 [7600/10697 ( 71.0%)] Loss: 0.026106 L1: 0.015306 Grad: 0.107761 Thermal: 0.000473 LR: 3.12e-06\n",
      "Epoch  34 [7600/10697 ( 71.0%)] Loss: 0.026106 L1: 0.015306 Grad: 0.107761 Thermal: 0.000473 LR: 3.12e-06\n",
      "Epoch  34 [7650/10697 ( 71.5%)] Loss: 0.024049 L1: 0.014089 Grad: 0.099396 Thermal: 0.000402 LR: 3.12e-06\n",
      "Epoch  34 [7650/10697 ( 71.5%)] Loss: 0.024049 L1: 0.014089 Grad: 0.099396 Thermal: 0.000402 LR: 3.12e-06\n",
      "Epoch  34 [7700/10697 ( 72.0%)] Loss: 0.025820 L1: 0.015154 Grad: 0.106439 Thermal: 0.000443 LR: 3.12e-06\n",
      "Epoch  34 [7700/10697 ( 72.0%)] Loss: 0.025820 L1: 0.015154 Grad: 0.106439 Thermal: 0.000443 LR: 3.12e-06\n",
      "Epoch  34 [7750/10697 ( 72.5%)] Loss: 0.030860 L1: 0.017926 Grad: 0.129038 Thermal: 0.000599 LR: 3.12e-06\n",
      "Epoch  34 [7750/10697 ( 72.5%)] Loss: 0.030860 L1: 0.017926 Grad: 0.129038 Thermal: 0.000599 LR: 3.12e-06\n",
      "Epoch  34 [7800/10697 ( 72.9%)] Loss: 0.025356 L1: 0.014953 Grad: 0.103817 Thermal: 0.000421 LR: 3.12e-06\n",
      "Epoch  34 [7800/10697 ( 72.9%)] Loss: 0.025356 L1: 0.014953 Grad: 0.103817 Thermal: 0.000421 LR: 3.12e-06\n",
      "Epoch  34 [7850/10697 ( 73.4%)] Loss: 0.030372 L1: 0.017705 Grad: 0.126408 Thermal: 0.000527 LR: 3.12e-06\n",
      "Epoch  34 [7850/10697 ( 73.4%)] Loss: 0.030372 L1: 0.017705 Grad: 0.126408 Thermal: 0.000527 LR: 3.12e-06\n",
      "Epoch  34 [7900/10697 ( 73.9%)] Loss: 0.029032 L1: 0.016673 Grad: 0.123325 Thermal: 0.000525 LR: 3.12e-06\n",
      "Epoch  34 [7900/10697 ( 73.9%)] Loss: 0.029032 L1: 0.016673 Grad: 0.123325 Thermal: 0.000525 LR: 3.12e-06\n",
      "Epoch  34 [7950/10697 ( 74.3%)] Loss: 0.029470 L1: 0.017141 Grad: 0.122983 Thermal: 0.000612 LR: 3.12e-06\n",
      "Epoch  34 [7950/10697 ( 74.3%)] Loss: 0.029470 L1: 0.017141 Grad: 0.122983 Thermal: 0.000612 LR: 3.12e-06\n",
      "Epoch  34 [8000/10697 ( 74.8%)] Loss: 0.024570 L1: 0.014442 Grad: 0.101093 Thermal: 0.000388 LR: 3.12e-06\n",
      "Epoch  34 [8000/10697 ( 74.8%)] Loss: 0.024570 L1: 0.014442 Grad: 0.101093 Thermal: 0.000388 LR: 3.12e-06\n",
      "Epoch  34 [8050/10697 ( 75.3%)] Loss: 0.029386 L1: 0.017056 Grad: 0.123014 Thermal: 0.000568 LR: 3.12e-06\n",
      "Epoch  34 [8050/10697 ( 75.3%)] Loss: 0.029386 L1: 0.017056 Grad: 0.123014 Thermal: 0.000568 LR: 3.12e-06\n",
      "Epoch  34 [8100/10697 ( 75.7%)] Loss: 0.025740 L1: 0.014937 Grad: 0.107818 Thermal: 0.000410 LR: 3.12e-06\n",
      "Epoch  34 [8100/10697 ( 75.7%)] Loss: 0.025740 L1: 0.014937 Grad: 0.107818 Thermal: 0.000410 LR: 3.12e-06\n",
      "Epoch  34 [8150/10697 ( 76.2%)] Loss: 0.025067 L1: 0.014365 Grad: 0.106810 Thermal: 0.000420 LR: 3.12e-06\n",
      "Epoch  34 [8150/10697 ( 76.2%)] Loss: 0.025067 L1: 0.014365 Grad: 0.106810 Thermal: 0.000420 LR: 3.12e-06\n",
      "Epoch  34 [8200/10697 ( 76.7%)] Loss: 0.028044 L1: 0.016305 Grad: 0.117111 Thermal: 0.000565 LR: 3.12e-06\n",
      "Epoch  34 [8200/10697 ( 76.7%)] Loss: 0.028044 L1: 0.016305 Grad: 0.117111 Thermal: 0.000565 LR: 3.12e-06\n",
      "Epoch  34 [8250/10697 ( 77.1%)] Loss: 0.034487 L1: 0.019859 Grad: 0.145901 Thermal: 0.000763 LR: 3.12e-06\n",
      "Epoch  34 [8250/10697 ( 77.1%)] Loss: 0.034487 L1: 0.019859 Grad: 0.145901 Thermal: 0.000763 LR: 3.12e-06\n",
      "Epoch  34 [8300/10697 ( 77.6%)] Loss: 0.027990 L1: 0.016552 Grad: 0.114129 Thermal: 0.000515 LR: 3.12e-06\n",
      "Epoch  34 [8300/10697 ( 77.6%)] Loss: 0.027990 L1: 0.016552 Grad: 0.114129 Thermal: 0.000515 LR: 3.12e-06\n",
      "Epoch  34 [8350/10697 ( 78.1%)] Loss: 0.024938 L1: 0.014760 Grad: 0.101564 Thermal: 0.000433 LR: 3.12e-06\n",
      "Epoch  34 [8350/10697 ( 78.1%)] Loss: 0.024938 L1: 0.014760 Grad: 0.101564 Thermal: 0.000433 LR: 3.12e-06\n",
      "Epoch  34 [8400/10697 ( 78.5%)] Loss: 0.025236 L1: 0.015348 Grad: 0.098670 Thermal: 0.000428 LR: 3.12e-06\n",
      "Epoch  34 [8400/10697 ( 78.5%)] Loss: 0.025236 L1: 0.015348 Grad: 0.098670 Thermal: 0.000428 LR: 3.12e-06\n",
      "Epoch  34 [8450/10697 ( 79.0%)] Loss: 0.027514 L1: 0.016293 Grad: 0.111960 Thermal: 0.000504 LR: 3.12e-06\n",
      "Epoch  34 [8450/10697 ( 79.0%)] Loss: 0.027514 L1: 0.016293 Grad: 0.111960 Thermal: 0.000504 LR: 3.12e-06\n",
      "Epoch  34 [8500/10697 ( 79.5%)] Loss: 0.025142 L1: 0.014800 Grad: 0.103206 Thermal: 0.000435 LR: 3.12e-06\n",
      "Epoch  34 [8500/10697 ( 79.5%)] Loss: 0.025142 L1: 0.014800 Grad: 0.103206 Thermal: 0.000435 LR: 3.12e-06\n",
      "Epoch  34 [8550/10697 ( 79.9%)] Loss: 0.024653 L1: 0.014455 Grad: 0.101784 Thermal: 0.000387 LR: 3.12e-06\n",
      "Epoch  34 [8550/10697 ( 79.9%)] Loss: 0.024653 L1: 0.014455 Grad: 0.101784 Thermal: 0.000387 LR: 3.12e-06\n",
      "Epoch  34 [8600/10697 ( 80.4%)] Loss: 0.025435 L1: 0.014805 Grad: 0.106106 Thermal: 0.000393 LR: 3.12e-06\n",
      "Epoch  34 [8600/10697 ( 80.4%)] Loss: 0.025435 L1: 0.014805 Grad: 0.106106 Thermal: 0.000393 LR: 3.12e-06\n",
      "Epoch  34 [8650/10697 ( 80.9%)] Loss: 0.031436 L1: 0.018246 Grad: 0.131587 Thermal: 0.000617 LR: 3.12e-06\n",
      "Epoch  34 [8650/10697 ( 80.9%)] Loss: 0.031436 L1: 0.018246 Grad: 0.131587 Thermal: 0.000617 LR: 3.12e-06\n",
      "Epoch  34 [8700/10697 ( 81.3%)] Loss: 0.019940 L1: 0.011673 Grad: 0.082527 Thermal: 0.000280 LR: 3.12e-06\n",
      "Epoch  34 [8700/10697 ( 81.3%)] Loss: 0.019940 L1: 0.011673 Grad: 0.082527 Thermal: 0.000280 LR: 3.12e-06\n",
      "Epoch  34 [8750/10697 ( 81.8%)] Loss: 0.023817 L1: 0.013253 Grad: 0.105448 Thermal: 0.000400 LR: 3.12e-06\n",
      "Epoch  34 [8750/10697 ( 81.8%)] Loss: 0.023817 L1: 0.013253 Grad: 0.105448 Thermal: 0.000400 LR: 3.12e-06\n",
      "Epoch  34 [8800/10697 ( 82.3%)] Loss: 0.036689 L1: 0.021159 Grad: 0.154867 Thermal: 0.000861 LR: 3.12e-06\n",
      "Epoch  34 [8800/10697 ( 82.3%)] Loss: 0.036689 L1: 0.021159 Grad: 0.154867 Thermal: 0.000861 LR: 3.12e-06\n",
      "Epoch  34 [8850/10697 ( 82.7%)] Loss: 0.026929 L1: 0.016019 Grad: 0.108873 Thermal: 0.000454 LR: 3.12e-06\n",
      "Epoch  34 [8850/10697 ( 82.7%)] Loss: 0.026929 L1: 0.016019 Grad: 0.108873 Thermal: 0.000454 LR: 3.12e-06\n",
      "Epoch  34 [8900/10697 ( 83.2%)] Loss: 0.023133 L1: 0.013606 Grad: 0.095084 Thermal: 0.000355 LR: 3.12e-06\n",
      "Epoch  34 [8900/10697 ( 83.2%)] Loss: 0.023133 L1: 0.013606 Grad: 0.095084 Thermal: 0.000355 LR: 3.12e-06\n",
      "Epoch  34 [8950/10697 ( 83.7%)] Loss: 0.025535 L1: 0.014972 Grad: 0.105413 Thermal: 0.000423 LR: 3.12e-06\n",
      "Epoch  34 [8950/10697 ( 83.7%)] Loss: 0.025535 L1: 0.014972 Grad: 0.105413 Thermal: 0.000423 LR: 3.12e-06\n",
      "Epoch  34 [9000/10697 ( 84.1%)] Loss: 0.029180 L1: 0.016957 Grad: 0.121986 Thermal: 0.000498 LR: 3.12e-06\n",
      "Epoch  34 [9000/10697 ( 84.1%)] Loss: 0.029180 L1: 0.016957 Grad: 0.121986 Thermal: 0.000498 LR: 3.12e-06\n",
      "Epoch  34 [9050/10697 ( 84.6%)] Loss: 0.027448 L1: 0.016272 Grad: 0.111529 Thermal: 0.000465 LR: 3.12e-06\n",
      "Epoch  34 [9050/10697 ( 84.6%)] Loss: 0.027448 L1: 0.016272 Grad: 0.111529 Thermal: 0.000465 LR: 3.12e-06\n",
      "Epoch  34 [9100/10697 ( 85.1%)] Loss: 0.023373 L1: 0.013537 Grad: 0.098178 Thermal: 0.000359 LR: 3.12e-06\n",
      "Epoch  34 [9100/10697 ( 85.1%)] Loss: 0.023373 L1: 0.013537 Grad: 0.098178 Thermal: 0.000359 LR: 3.12e-06\n",
      "Epoch  34 [9150/10697 ( 85.5%)] Loss: 0.029963 L1: 0.017386 Grad: 0.125473 Thermal: 0.000595 LR: 3.12e-06\n",
      "Epoch  34 [9150/10697 ( 85.5%)] Loss: 0.029963 L1: 0.017386 Grad: 0.125473 Thermal: 0.000595 LR: 3.12e-06\n",
      "Epoch  34 [9200/10697 ( 86.0%)] Loss: 0.022215 L1: 0.013102 Grad: 0.090966 Thermal: 0.000333 LR: 3.12e-06\n",
      "Epoch  34 [9200/10697 ( 86.0%)] Loss: 0.022215 L1: 0.013102 Grad: 0.090966 Thermal: 0.000333 LR: 3.12e-06\n",
      "Epoch  34 [9250/10697 ( 86.5%)] Loss: 0.021972 L1: 0.012483 Grad: 0.094717 Thermal: 0.000339 LR: 3.12e-06\n",
      "Epoch  34 [9250/10697 ( 86.5%)] Loss: 0.021972 L1: 0.012483 Grad: 0.094717 Thermal: 0.000339 LR: 3.12e-06\n",
      "Epoch  34 [9300/10697 ( 86.9%)] Loss: 0.022224 L1: 0.012912 Grad: 0.092968 Thermal: 0.000305 LR: 3.12e-06\n",
      "Epoch  34 [9300/10697 ( 86.9%)] Loss: 0.022224 L1: 0.012912 Grad: 0.092968 Thermal: 0.000305 LR: 3.12e-06\n",
      "Epoch  34 [9350/10697 ( 87.4%)] Loss: 0.036432 L1: 0.020966 Grad: 0.154246 Thermal: 0.000825 LR: 3.12e-06\n",
      "Epoch  34 [9350/10697 ( 87.4%)] Loss: 0.036432 L1: 0.020966 Grad: 0.154246 Thermal: 0.000825 LR: 3.12e-06\n",
      "Epoch  34 [9400/10697 ( 87.9%)] Loss: 0.029659 L1: 0.017419 Grad: 0.122094 Thermal: 0.000613 LR: 3.12e-06\n",
      "Epoch  34 [9400/10697 ( 87.9%)] Loss: 0.029659 L1: 0.017419 Grad: 0.122094 Thermal: 0.000613 LR: 3.12e-06\n",
      "Epoch  34 [9450/10697 ( 88.3%)] Loss: 0.031270 L1: 0.018269 Grad: 0.129705 Thermal: 0.000617 LR: 3.12e-06\n",
      "Epoch  34 [9450/10697 ( 88.3%)] Loss: 0.031270 L1: 0.018269 Grad: 0.129705 Thermal: 0.000617 LR: 3.12e-06\n",
      "Epoch  34 [9500/10697 ( 88.8%)] Loss: 0.029145 L1: 0.017266 Grad: 0.118496 Thermal: 0.000590 LR: 3.12e-06\n",
      "Epoch  34 [9500/10697 ( 88.8%)] Loss: 0.029145 L1: 0.017266 Grad: 0.118496 Thermal: 0.000590 LR: 3.12e-06\n",
      "Epoch  34 [9550/10697 ( 89.3%)] Loss: 0.034022 L1: 0.018914 Grad: 0.150654 Thermal: 0.000838 LR: 3.12e-06\n",
      "Epoch  34 [9550/10697 ( 89.3%)] Loss: 0.034022 L1: 0.018914 Grad: 0.150654 Thermal: 0.000838 LR: 3.12e-06\n",
      "Epoch  34 [9600/10697 ( 89.7%)] Loss: 0.028563 L1: 0.017025 Grad: 0.115123 Thermal: 0.000517 LR: 3.12e-06\n",
      "Epoch  34 [9600/10697 ( 89.7%)] Loss: 0.028563 L1: 0.017025 Grad: 0.115123 Thermal: 0.000517 LR: 3.12e-06\n",
      "Epoch  34 [9650/10697 ( 90.2%)] Loss: 0.026205 L1: 0.015310 Grad: 0.108736 Thermal: 0.000440 LR: 3.12e-06\n",
      "Epoch  34 [9650/10697 ( 90.2%)] Loss: 0.026205 L1: 0.015310 Grad: 0.108736 Thermal: 0.000440 LR: 3.12e-06\n",
      "Epoch  34 [9700/10697 ( 90.7%)] Loss: 0.028966 L1: 0.017152 Grad: 0.117885 Thermal: 0.000511 LR: 3.12e-06\n",
      "Epoch  34 [9700/10697 ( 90.7%)] Loss: 0.028966 L1: 0.017152 Grad: 0.117885 Thermal: 0.000511 LR: 3.12e-06\n",
      "Epoch  34 [9750/10697 ( 91.1%)] Loss: 0.028149 L1: 0.016680 Grad: 0.114425 Thermal: 0.000525 LR: 3.12e-06\n",
      "Epoch  34 [9750/10697 ( 91.1%)] Loss: 0.028149 L1: 0.016680 Grad: 0.114425 Thermal: 0.000525 LR: 3.12e-06\n",
      "Epoch  34 [9800/10697 ( 91.6%)] Loss: 0.027400 L1: 0.015553 Grad: 0.118206 Thermal: 0.000525 LR: 3.12e-06\n",
      "Epoch  34 [9800/10697 ( 91.6%)] Loss: 0.027400 L1: 0.015553 Grad: 0.118206 Thermal: 0.000525 LR: 3.12e-06\n",
      "Epoch  34 [9850/10697 ( 92.1%)] Loss: 0.018494 L1: 0.010674 Grad: 0.078078 Thermal: 0.000254 LR: 3.12e-06\n",
      "Epoch  34 [9850/10697 ( 92.1%)] Loss: 0.018494 L1: 0.010674 Grad: 0.078078 Thermal: 0.000254 LR: 3.12e-06\n",
      "Epoch  34 [9900/10697 ( 92.5%)] Loss: 0.025945 L1: 0.015136 Grad: 0.107863 Thermal: 0.000447 LR: 3.12e-06\n",
      "Epoch  34 [9900/10697 ( 92.5%)] Loss: 0.025945 L1: 0.015136 Grad: 0.107863 Thermal: 0.000447 LR: 3.12e-06\n",
      "Epoch  34 [9950/10697 ( 93.0%)] Loss: 0.023553 L1: 0.013450 Grad: 0.100855 Thermal: 0.000338 LR: 3.12e-06\n",
      "Epoch  34 [9950/10697 ( 93.0%)] Loss: 0.023553 L1: 0.013450 Grad: 0.100855 Thermal: 0.000338 LR: 3.12e-06\n",
      "Epoch  34 [10000/10697 ( 93.5%)] Loss: 0.025308 L1: 0.014634 Grad: 0.106538 Thermal: 0.000404 LR: 3.12e-06\n",
      "Epoch  34 [10000/10697 ( 93.5%)] Loss: 0.025308 L1: 0.014634 Grad: 0.106538 Thermal: 0.000404 LR: 3.12e-06\n",
      "Epoch  34 [10050/10697 ( 94.0%)] Loss: 0.026639 L1: 0.015495 Grad: 0.111222 Thermal: 0.000447 LR: 3.12e-06\n",
      "Epoch  34 [10050/10697 ( 94.0%)] Loss: 0.026639 L1: 0.015495 Grad: 0.111222 Thermal: 0.000447 LR: 3.12e-06\n",
      "Epoch  34 [10100/10697 ( 94.4%)] Loss: 0.025682 L1: 0.014613 Grad: 0.110437 Thermal: 0.000492 LR: 3.12e-06\n",
      "Epoch  34 [10100/10697 ( 94.4%)] Loss: 0.025682 L1: 0.014613 Grad: 0.110437 Thermal: 0.000492 LR: 3.12e-06\n",
      "Epoch  34 [10150/10697 ( 94.9%)] Loss: 0.025980 L1: 0.015381 Grad: 0.105770 Thermal: 0.000440 LR: 3.12e-06\n",
      "Epoch  34 [10150/10697 ( 94.9%)] Loss: 0.025980 L1: 0.015381 Grad: 0.105770 Thermal: 0.000440 LR: 3.12e-06\n",
      "Epoch  34 [10200/10697 ( 95.4%)] Loss: 0.028188 L1: 0.016736 Grad: 0.114268 Thermal: 0.000506 LR: 3.12e-06\n",
      "Epoch  34 [10200/10697 ( 95.4%)] Loss: 0.028188 L1: 0.016736 Grad: 0.114268 Thermal: 0.000506 LR: 3.12e-06\n",
      "Epoch  34 [10250/10697 ( 95.8%)] Loss: 0.023850 L1: 0.013953 Grad: 0.098771 Thermal: 0.000395 LR: 3.12e-06\n",
      "Epoch  34 [10250/10697 ( 95.8%)] Loss: 0.023850 L1: 0.013953 Grad: 0.098771 Thermal: 0.000395 LR: 3.12e-06\n",
      "Epoch  34 [10300/10697 ( 96.3%)] Loss: 0.026809 L1: 0.015533 Grad: 0.112522 Thermal: 0.000463 LR: 3.12e-06\n",
      "Epoch  34 [10300/10697 ( 96.3%)] Loss: 0.026809 L1: 0.015533 Grad: 0.112522 Thermal: 0.000463 LR: 3.12e-06\n",
      "Epoch  34 [10350/10697 ( 96.8%)] Loss: 0.025024 L1: 0.014523 Grad: 0.104803 Thermal: 0.000407 LR: 3.12e-06\n",
      "Epoch  34 [10350/10697 ( 96.8%)] Loss: 0.025024 L1: 0.014523 Grad: 0.104803 Thermal: 0.000407 LR: 3.12e-06\n",
      "Epoch  34 [10400/10697 ( 97.2%)] Loss: 0.025275 L1: 0.014785 Grad: 0.104685 Thermal: 0.000420 LR: 3.12e-06\n",
      "Epoch  34 [10400/10697 ( 97.2%)] Loss: 0.025275 L1: 0.014785 Grad: 0.104685 Thermal: 0.000420 LR: 3.12e-06\n",
      "Epoch  34 [10450/10697 ( 97.7%)] Loss: 0.028372 L1: 0.016555 Grad: 0.117928 Thermal: 0.000478 LR: 3.12e-06\n",
      "Epoch  34 [10450/10697 ( 97.7%)] Loss: 0.028372 L1: 0.016555 Grad: 0.117928 Thermal: 0.000478 LR: 3.12e-06\n",
      "Epoch  34 [10500/10697 ( 98.2%)] Loss: 0.022031 L1: 0.012577 Grad: 0.094393 Thermal: 0.000303 LR: 3.12e-06\n",
      "Epoch  34 [10500/10697 ( 98.2%)] Loss: 0.022031 L1: 0.012577 Grad: 0.094393 Thermal: 0.000303 LR: 3.12e-06\n",
      "Epoch  34 [10550/10697 ( 98.6%)] Loss: 0.032567 L1: 0.018585 Grad: 0.139490 Thermal: 0.000671 LR: 3.12e-06\n",
      "Epoch  34 [10550/10697 ( 98.6%)] Loss: 0.032567 L1: 0.018585 Grad: 0.139490 Thermal: 0.000671 LR: 3.12e-06\n",
      "Epoch  34 [10600/10697 ( 99.1%)] Loss: 0.034812 L1: 0.020025 Grad: 0.147469 Thermal: 0.000809 LR: 3.12e-06\n",
      "Epoch  34 [10600/10697 ( 99.1%)] Loss: 0.034812 L1: 0.020025 Grad: 0.147469 Thermal: 0.000809 LR: 3.12e-06\n",
      "Epoch  34 [10650/10697 ( 99.6%)] Loss: 0.024081 L1: 0.013683 Grad: 0.103770 Thermal: 0.000416 LR: 3.12e-06\n",
      "Epoch  34 [10650/10697 ( 99.6%)] Loss: 0.024081 L1: 0.013683 Grad: 0.103770 Thermal: 0.000416 LR: 3.12e-06\n",
      "Epoch  34 Summary: Loss=0.026252 (L1:0.0153, Grad:0.1092, Thermal:0.0005) Val_PSNR=0.00dB Best=33.96dB Time=131.7min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  34 Summary: Loss=0.026252 (L1:0.0153, Grad:0.1092, Thermal:0.0005) Val_PSNR=0.00dB Best=33.96dB Time=131.7min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  35 [   0/10697 (  0.0%)] Loss: 0.018866 L1: 0.011087 Grad: 0.077655 Thermal: 0.000270 LR: 3.02e-06\n",
      "Epoch  35 [   0/10697 (  0.0%)] Loss: 0.018866 L1: 0.011087 Grad: 0.077655 Thermal: 0.000270 LR: 3.02e-06\n",
      "Epoch  35 [  50/10697 (  0.5%)] Loss: 0.025844 L1: 0.015292 Grad: 0.105304 Thermal: 0.000431 LR: 3.02e-06\n",
      "Epoch  35 [  50/10697 (  0.5%)] Loss: 0.025844 L1: 0.015292 Grad: 0.105304 Thermal: 0.000431 LR: 3.02e-06\n",
      "Epoch  35 [ 100/10697 (  0.9%)] Loss: 0.028750 L1: 0.016801 Grad: 0.119242 Thermal: 0.000499 LR: 3.02e-06\n",
      "Epoch  35 [ 100/10697 (  0.9%)] Loss: 0.028750 L1: 0.016801 Grad: 0.119242 Thermal: 0.000499 LR: 3.02e-06\n",
      "Epoch  35 [ 150/10697 (  1.4%)] Loss: 0.020462 L1: 0.011931 Grad: 0.085166 Thermal: 0.000295 LR: 3.02e-06\n",
      "Epoch  35 [ 150/10697 (  1.4%)] Loss: 0.020462 L1: 0.011931 Grad: 0.085166 Thermal: 0.000295 LR: 3.02e-06\n",
      "Epoch  35 [ 200/10697 (  1.9%)] Loss: 0.021943 L1: 0.012418 Grad: 0.095054 Thermal: 0.000410 LR: 3.02e-06\n",
      "Epoch  35 [ 200/10697 (  1.9%)] Loss: 0.021943 L1: 0.012418 Grad: 0.095054 Thermal: 0.000410 LR: 3.02e-06\n",
      "Epoch  35 [ 250/10697 (  2.3%)] Loss: 0.026451 L1: 0.015873 Grad: 0.105560 Thermal: 0.000439 LR: 3.02e-06\n",
      "Epoch  35 [ 250/10697 (  2.3%)] Loss: 0.026451 L1: 0.015873 Grad: 0.105560 Thermal: 0.000439 LR: 3.02e-06\n",
      "Epoch  35 [ 300/10697 (  2.8%)] Loss: 0.025680 L1: 0.014755 Grad: 0.108984 Thermal: 0.000524 LR: 3.02e-06\n",
      "Epoch  35 [ 300/10697 (  2.8%)] Loss: 0.025680 L1: 0.014755 Grad: 0.108984 Thermal: 0.000524 LR: 3.02e-06\n",
      "Epoch  35 [ 350/10697 (  3.3%)] Loss: 0.025193 L1: 0.014892 Grad: 0.102788 Thermal: 0.000449 LR: 3.02e-06\n",
      "Epoch  35 [ 350/10697 (  3.3%)] Loss: 0.025193 L1: 0.014892 Grad: 0.102788 Thermal: 0.000449 LR: 3.02e-06\n",
      "Epoch  35 [ 400/10697 (  3.7%)] Loss: 0.027974 L1: 0.015699 Grad: 0.122481 Thermal: 0.000547 LR: 3.02e-06\n",
      "Epoch  35 [ 400/10697 (  3.7%)] Loss: 0.027974 L1: 0.015699 Grad: 0.122481 Thermal: 0.000547 LR: 3.02e-06\n",
      "Epoch  35 [ 450/10697 (  4.2%)] Loss: 0.029627 L1: 0.017067 Grad: 0.125337 Thermal: 0.000536 LR: 3.02e-06\n",
      "Epoch  35 [ 450/10697 (  4.2%)] Loss: 0.029627 L1: 0.017067 Grad: 0.125337 Thermal: 0.000536 LR: 3.02e-06\n",
      "Epoch  35 [ 500/10697 (  4.7%)] Loss: 0.033637 L1: 0.019332 Grad: 0.142686 Thermal: 0.000733 LR: 3.02e-06\n",
      "Epoch  35 [ 500/10697 (  4.7%)] Loss: 0.033637 L1: 0.019332 Grad: 0.142686 Thermal: 0.000733 LR: 3.02e-06\n",
      "Epoch  35 [ 550/10697 (  5.1%)] Loss: 0.028704 L1: 0.016946 Grad: 0.117316 Thermal: 0.000535 LR: 3.02e-06\n",
      "Epoch  35 [ 550/10697 (  5.1%)] Loss: 0.028704 L1: 0.016946 Grad: 0.117316 Thermal: 0.000535 LR: 3.02e-06\n",
      "Epoch  35 [ 600/10697 (  5.6%)] Loss: 0.024726 L1: 0.014465 Grad: 0.102400 Thermal: 0.000430 LR: 3.02e-06\n",
      "Epoch  35 [ 600/10697 (  5.6%)] Loss: 0.024726 L1: 0.014465 Grad: 0.102400 Thermal: 0.000430 LR: 3.02e-06\n",
      "Epoch  35 [ 650/10697 (  6.1%)] Loss: 0.026874 L1: 0.015615 Grad: 0.112382 Thermal: 0.000419 LR: 3.02e-06\n",
      "Epoch  35 [ 650/10697 (  6.1%)] Loss: 0.026874 L1: 0.015615 Grad: 0.112382 Thermal: 0.000419 LR: 3.02e-06\n",
      "Epoch  35 [ 700/10697 (  6.5%)] Loss: 0.027361 L1: 0.016565 Grad: 0.107714 Thermal: 0.000482 LR: 3.02e-06\n",
      "Epoch  35 [ 700/10697 (  6.5%)] Loss: 0.027361 L1: 0.016565 Grad: 0.107714 Thermal: 0.000482 LR: 3.02e-06\n",
      "Epoch  35 [ 750/10697 (  7.0%)] Loss: 0.026849 L1: 0.015835 Grad: 0.109903 Thermal: 0.000468 LR: 3.02e-06\n",
      "Epoch  35 [ 750/10697 (  7.0%)] Loss: 0.026849 L1: 0.015835 Grad: 0.109903 Thermal: 0.000468 LR: 3.02e-06\n",
      "Epoch  35 [ 800/10697 (  7.5%)] Loss: 0.025711 L1: 0.015560 Grad: 0.101284 Thermal: 0.000454 LR: 3.02e-06\n",
      "Epoch  35 [ 800/10697 (  7.5%)] Loss: 0.025711 L1: 0.015560 Grad: 0.101284 Thermal: 0.000454 LR: 3.02e-06\n",
      "Epoch  35 [ 850/10697 (  7.9%)] Loss: 0.021738 L1: 0.012604 Grad: 0.091167 Thermal: 0.000347 LR: 3.02e-06\n",
      "Epoch  35 [ 850/10697 (  7.9%)] Loss: 0.021738 L1: 0.012604 Grad: 0.091167 Thermal: 0.000347 LR: 3.02e-06\n",
      "Epoch  35 [ 900/10697 (  8.4%)] Loss: 0.020491 L1: 0.011529 Grad: 0.089471 Thermal: 0.000302 LR: 3.02e-06\n",
      "Epoch  35 [ 900/10697 (  8.4%)] Loss: 0.020491 L1: 0.011529 Grad: 0.089471 Thermal: 0.000302 LR: 3.02e-06\n",
      "Epoch  35 [ 950/10697 (  8.9%)] Loss: 0.028348 L1: 0.016643 Grad: 0.116798 Thermal: 0.000510 LR: 3.02e-06\n",
      "Epoch  35 [ 950/10697 (  8.9%)] Loss: 0.028348 L1: 0.016643 Grad: 0.116798 Thermal: 0.000510 LR: 3.02e-06\n",
      "Epoch  35 [1000/10697 (  9.3%)] Loss: 0.023830 L1: 0.013878 Grad: 0.099320 Thermal: 0.000394 LR: 3.02e-06\n",
      "Epoch  35 [1000/10697 (  9.3%)] Loss: 0.023830 L1: 0.013878 Grad: 0.099320 Thermal: 0.000394 LR: 3.02e-06\n",
      "Epoch  35 [1050/10697 (  9.8%)] Loss: 0.023631 L1: 0.013993 Grad: 0.096186 Thermal: 0.000386 LR: 3.02e-06\n",
      "Epoch  35 [1050/10697 (  9.8%)] Loss: 0.023631 L1: 0.013993 Grad: 0.096186 Thermal: 0.000386 LR: 3.02e-06\n",
      "Epoch  35 [1100/10697 ( 10.3%)] Loss: 0.027222 L1: 0.015786 Grad: 0.114128 Thermal: 0.000467 LR: 3.02e-06\n",
      "Epoch  35 [1100/10697 ( 10.3%)] Loss: 0.027222 L1: 0.015786 Grad: 0.114128 Thermal: 0.000467 LR: 3.02e-06\n",
      "Epoch  35 [1150/10697 ( 10.8%)] Loss: 0.020533 L1: 0.012119 Grad: 0.083987 Thermal: 0.000306 LR: 3.02e-06\n",
      "Epoch  35 [1150/10697 ( 10.8%)] Loss: 0.020533 L1: 0.012119 Grad: 0.083987 Thermal: 0.000306 LR: 3.02e-06\n",
      "Epoch  35 [1200/10697 ( 11.2%)] Loss: 0.020933 L1: 0.012019 Grad: 0.088985 Thermal: 0.000301 LR: 3.02e-06\n",
      "Epoch  35 [1200/10697 ( 11.2%)] Loss: 0.020933 L1: 0.012019 Grad: 0.088985 Thermal: 0.000301 LR: 3.02e-06\n",
      "Epoch  35 [1250/10697 ( 11.7%)] Loss: 0.026325 L1: 0.015068 Grad: 0.112347 Thermal: 0.000444 LR: 3.02e-06\n",
      "Epoch  35 [1250/10697 ( 11.7%)] Loss: 0.026325 L1: 0.015068 Grad: 0.112347 Thermal: 0.000444 LR: 3.02e-06\n",
      "Epoch  35 [1300/10697 ( 12.2%)] Loss: 0.026920 L1: 0.015690 Grad: 0.112062 Thermal: 0.000473 LR: 3.02e-06\n",
      "Epoch  35 [1300/10697 ( 12.2%)] Loss: 0.026920 L1: 0.015690 Grad: 0.112062 Thermal: 0.000473 LR: 3.02e-06\n",
      "Epoch  35 [1350/10697 ( 12.6%)] Loss: 0.027462 L1: 0.016230 Grad: 0.112080 Thermal: 0.000472 LR: 3.02e-06\n",
      "Epoch  35 [1350/10697 ( 12.6%)] Loss: 0.027462 L1: 0.016230 Grad: 0.112080 Thermal: 0.000472 LR: 3.02e-06\n",
      "Epoch  35 [1400/10697 ( 13.1%)] Loss: 0.028252 L1: 0.016298 Grad: 0.119261 Thermal: 0.000560 LR: 3.02e-06\n",
      "Epoch  35 [1400/10697 ( 13.1%)] Loss: 0.028252 L1: 0.016298 Grad: 0.119261 Thermal: 0.000560 LR: 3.02e-06\n",
      "Epoch  35 [1450/10697 ( 13.6%)] Loss: 0.026900 L1: 0.015494 Grad: 0.113813 Thermal: 0.000484 LR: 3.02e-06\n",
      "Epoch  35 [1450/10697 ( 13.6%)] Loss: 0.026900 L1: 0.015494 Grad: 0.113813 Thermal: 0.000484 LR: 3.02e-06\n",
      "Epoch  35 [1500/10697 ( 14.0%)] Loss: 0.020157 L1: 0.011546 Grad: 0.085958 Thermal: 0.000304 LR: 3.02e-06\n",
      "Epoch  35 [1500/10697 ( 14.0%)] Loss: 0.020157 L1: 0.011546 Grad: 0.085958 Thermal: 0.000304 LR: 3.02e-06\n",
      "Epoch  35 [1550/10697 ( 14.5%)] Loss: 0.025152 L1: 0.014735 Grad: 0.103964 Thermal: 0.000407 LR: 3.02e-06\n",
      "Epoch  35 [1550/10697 ( 14.5%)] Loss: 0.025152 L1: 0.014735 Grad: 0.103964 Thermal: 0.000407 LR: 3.02e-06\n",
      "Epoch  35 [1600/10697 ( 15.0%)] Loss: 0.031421 L1: 0.018301 Grad: 0.130899 Thermal: 0.000601 LR: 3.02e-06\n",
      "Epoch  35 [1600/10697 ( 15.0%)] Loss: 0.031421 L1: 0.018301 Grad: 0.130899 Thermal: 0.000601 LR: 3.02e-06\n",
      "Epoch  35 [1650/10697 ( 15.4%)] Loss: 0.026998 L1: 0.015807 Grad: 0.111648 Thermal: 0.000513 LR: 3.02e-06\n",
      "Epoch  35 [1650/10697 ( 15.4%)] Loss: 0.026998 L1: 0.015807 Grad: 0.111648 Thermal: 0.000513 LR: 3.02e-06\n",
      "Epoch  35 [1700/10697 ( 15.9%)] Loss: 0.028781 L1: 0.017023 Grad: 0.117316 Thermal: 0.000522 LR: 3.02e-06\n",
      "Epoch  35 [1700/10697 ( 15.9%)] Loss: 0.028781 L1: 0.017023 Grad: 0.117316 Thermal: 0.000522 LR: 3.02e-06\n",
      "Epoch  35 [1750/10697 ( 16.4%)] Loss: 0.025413 L1: 0.015425 Grad: 0.099675 Thermal: 0.000415 LR: 3.02e-06\n",
      "Epoch  35 [1750/10697 ( 16.4%)] Loss: 0.025413 L1: 0.015425 Grad: 0.099675 Thermal: 0.000415 LR: 3.02e-06\n",
      "Epoch  35 [1800/10697 ( 16.8%)] Loss: 0.026939 L1: 0.015827 Grad: 0.110885 Thermal: 0.000462 LR: 3.02e-06\n",
      "Epoch  35 [1800/10697 ( 16.8%)] Loss: 0.026939 L1: 0.015827 Grad: 0.110885 Thermal: 0.000462 LR: 3.02e-06\n",
      "Epoch  35 [1850/10697 ( 17.3%)] Loss: 0.026836 L1: 0.015790 Grad: 0.110239 Thermal: 0.000432 LR: 3.02e-06\n",
      "Epoch  35 [1850/10697 ( 17.3%)] Loss: 0.026836 L1: 0.015790 Grad: 0.110239 Thermal: 0.000432 LR: 3.02e-06\n",
      "Epoch  35 [1900/10697 ( 17.8%)] Loss: 0.023030 L1: 0.013697 Grad: 0.093152 Thermal: 0.000359 LR: 3.02e-06\n",
      "Epoch  35 [1900/10697 ( 17.8%)] Loss: 0.023030 L1: 0.013697 Grad: 0.093152 Thermal: 0.000359 LR: 3.02e-06\n",
      "Epoch  35 [1950/10697 ( 18.2%)] Loss: 0.026743 L1: 0.015817 Grad: 0.109037 Thermal: 0.000442 LR: 3.02e-06\n",
      "Epoch  35 [1950/10697 ( 18.2%)] Loss: 0.026743 L1: 0.015817 Grad: 0.109037 Thermal: 0.000442 LR: 3.02e-06\n",
      "Epoch  35 [2000/10697 ( 18.7%)] Loss: 0.028123 L1: 0.016060 Grad: 0.120374 Thermal: 0.000497 LR: 3.02e-06\n",
      "Epoch  35 [2000/10697 ( 18.7%)] Loss: 0.028123 L1: 0.016060 Grad: 0.120374 Thermal: 0.000497 LR: 3.02e-06\n",
      "Epoch  35 [2050/10697 ( 19.2%)] Loss: 0.027531 L1: 0.016325 Grad: 0.111830 Thermal: 0.000472 LR: 3.02e-06\n",
      "Epoch  35 [2050/10697 ( 19.2%)] Loss: 0.027531 L1: 0.016325 Grad: 0.111830 Thermal: 0.000472 LR: 3.02e-06\n",
      "Epoch  35 [2100/10697 ( 19.6%)] Loss: 0.022388 L1: 0.013034 Grad: 0.093368 Thermal: 0.000355 LR: 3.02e-06\n",
      "Epoch  35 [2100/10697 ( 19.6%)] Loss: 0.022388 L1: 0.013034 Grad: 0.093368 Thermal: 0.000355 LR: 3.02e-06\n",
      "Epoch  35 [2150/10697 ( 20.1%)] Loss: 0.024573 L1: 0.014316 Grad: 0.102354 Thermal: 0.000433 LR: 3.02e-06\n",
      "Epoch  35 [2150/10697 ( 20.1%)] Loss: 0.024573 L1: 0.014316 Grad: 0.102354 Thermal: 0.000433 LR: 3.02e-06\n",
      "Epoch  35 [2200/10697 ( 20.6%)] Loss: 0.022604 L1: 0.013107 Grad: 0.094784 Thermal: 0.000372 LR: 3.02e-06\n",
      "Epoch  35 [2200/10697 ( 20.6%)] Loss: 0.022604 L1: 0.013107 Grad: 0.094784 Thermal: 0.000372 LR: 3.02e-06\n",
      "Epoch  35 [2250/10697 ( 21.0%)] Loss: 0.024384 L1: 0.013997 Grad: 0.103681 Thermal: 0.000365 LR: 3.02e-06\n",
      "Epoch  35 [2250/10697 ( 21.0%)] Loss: 0.024384 L1: 0.013997 Grad: 0.103681 Thermal: 0.000365 LR: 3.02e-06\n",
      "Epoch  35 [2300/10697 ( 21.5%)] Loss: 0.022770 L1: 0.013182 Grad: 0.095694 Thermal: 0.000362 LR: 3.02e-06\n",
      "Epoch  35 [2300/10697 ( 21.5%)] Loss: 0.022770 L1: 0.013182 Grad: 0.095694 Thermal: 0.000362 LR: 3.02e-06\n",
      "Epoch  35 [2350/10697 ( 22.0%)] Loss: 0.029189 L1: 0.017424 Grad: 0.117378 Thermal: 0.000544 LR: 3.02e-06\n",
      "Epoch  35 [2350/10697 ( 22.0%)] Loss: 0.029189 L1: 0.017424 Grad: 0.117378 Thermal: 0.000544 LR: 3.02e-06\n",
      "Epoch  35 [2400/10697 ( 22.4%)] Loss: 0.019339 L1: 0.011168 Grad: 0.081591 Thermal: 0.000253 LR: 3.02e-06\n",
      "Epoch  35 [2400/10697 ( 22.4%)] Loss: 0.019339 L1: 0.011168 Grad: 0.081591 Thermal: 0.000253 LR: 3.02e-06\n",
      "Epoch  35 [2450/10697 ( 22.9%)] Loss: 0.020736 L1: 0.012036 Grad: 0.086852 Thermal: 0.000311 LR: 3.02e-06\n",
      "Epoch  35 [2450/10697 ( 22.9%)] Loss: 0.020736 L1: 0.012036 Grad: 0.086852 Thermal: 0.000311 LR: 3.02e-06\n",
      "Epoch  35 [2500/10697 ( 23.4%)] Loss: 0.031771 L1: 0.017995 Grad: 0.137468 Thermal: 0.000592 LR: 3.02e-06\n",
      "Epoch  35 [2500/10697 ( 23.4%)] Loss: 0.031771 L1: 0.017995 Grad: 0.137468 Thermal: 0.000592 LR: 3.02e-06\n",
      "Epoch  35 [2550/10697 ( 23.8%)] Loss: 0.030332 L1: 0.017920 Grad: 0.123824 Thermal: 0.000595 LR: 3.02e-06\n",
      "Epoch  35 [2550/10697 ( 23.8%)] Loss: 0.030332 L1: 0.017920 Grad: 0.123824 Thermal: 0.000595 LR: 3.02e-06\n",
      "Epoch  35 [2600/10697 ( 24.3%)] Loss: 0.030250 L1: 0.018023 Grad: 0.121977 Thermal: 0.000589 LR: 3.02e-06\n",
      "Epoch  35 [2600/10697 ( 24.3%)] Loss: 0.030250 L1: 0.018023 Grad: 0.121977 Thermal: 0.000589 LR: 3.02e-06\n",
      "Epoch  35 [2650/10697 ( 24.8%)] Loss: 0.032474 L1: 0.019279 Grad: 0.131619 Thermal: 0.000657 LR: 3.02e-06\n",
      "Epoch  35 [2650/10697 ( 24.8%)] Loss: 0.032474 L1: 0.019279 Grad: 0.131619 Thermal: 0.000657 LR: 3.02e-06\n",
      "Epoch  35 [2700/10697 ( 25.2%)] Loss: 0.028010 L1: 0.016427 Grad: 0.115594 Thermal: 0.000480 LR: 3.02e-06\n",
      "Epoch  35 [2700/10697 ( 25.2%)] Loss: 0.028010 L1: 0.016427 Grad: 0.115594 Thermal: 0.000480 LR: 3.02e-06\n",
      "Epoch  35 [2750/10697 ( 25.7%)] Loss: 0.026109 L1: 0.015091 Grad: 0.109965 Thermal: 0.000428 LR: 3.02e-06\n",
      "Epoch  35 [2750/10697 ( 25.7%)] Loss: 0.026109 L1: 0.015091 Grad: 0.109965 Thermal: 0.000428 LR: 3.02e-06\n",
      "Epoch  35 [2800/10697 ( 26.2%)] Loss: 0.024814 L1: 0.014569 Grad: 0.102232 Thermal: 0.000437 LR: 3.02e-06\n",
      "Epoch  35 [2800/10697 ( 26.2%)] Loss: 0.024814 L1: 0.014569 Grad: 0.102232 Thermal: 0.000437 LR: 3.02e-06\n",
      "Epoch  35 [2850/10697 ( 26.6%)] Loss: 0.025755 L1: 0.014866 Grad: 0.108680 Thermal: 0.000420 LR: 3.02e-06\n",
      "Epoch  35 [2850/10697 ( 26.6%)] Loss: 0.025755 L1: 0.014866 Grad: 0.108680 Thermal: 0.000420 LR: 3.02e-06\n",
      "Epoch  35 [2900/10697 ( 27.1%)] Loss: 0.023949 L1: 0.013564 Grad: 0.103645 Thermal: 0.000398 LR: 3.02e-06\n",
      "Epoch  35 [2900/10697 ( 27.1%)] Loss: 0.023949 L1: 0.013564 Grad: 0.103645 Thermal: 0.000398 LR: 3.02e-06\n",
      "Epoch  35 [2950/10697 ( 27.6%)] Loss: 0.022092 L1: 0.012893 Grad: 0.091815 Thermal: 0.000352 LR: 3.02e-06\n",
      "Epoch  35 [2950/10697 ( 27.6%)] Loss: 0.022092 L1: 0.012893 Grad: 0.091815 Thermal: 0.000352 LR: 3.02e-06\n",
      "Epoch  35 [3000/10697 ( 28.0%)] Loss: 0.026126 L1: 0.014753 Grad: 0.113513 Thermal: 0.000420 LR: 3.02e-06\n",
      "Epoch  35 [3000/10697 ( 28.0%)] Loss: 0.026126 L1: 0.014753 Grad: 0.113513 Thermal: 0.000420 LR: 3.02e-06\n",
      "Epoch  35 [3050/10697 ( 28.5%)] Loss: 0.025843 L1: 0.015368 Grad: 0.104527 Thermal: 0.000452 LR: 3.02e-06\n",
      "Epoch  35 [3050/10697 ( 28.5%)] Loss: 0.025843 L1: 0.015368 Grad: 0.104527 Thermal: 0.000452 LR: 3.02e-06\n",
      "Epoch  35 [3100/10697 ( 29.0%)] Loss: 0.027073 L1: 0.016146 Grad: 0.109036 Thermal: 0.000467 LR: 3.02e-06\n",
      "Epoch  35 [3100/10697 ( 29.0%)] Loss: 0.027073 L1: 0.016146 Grad: 0.109036 Thermal: 0.000467 LR: 3.02e-06\n",
      "Epoch  35 [3150/10697 ( 29.4%)] Loss: 0.023076 L1: 0.013496 Grad: 0.095616 Thermal: 0.000369 LR: 3.02e-06\n",
      "Epoch  35 [3150/10697 ( 29.4%)] Loss: 0.023076 L1: 0.013496 Grad: 0.095616 Thermal: 0.000369 LR: 3.02e-06\n",
      "Epoch  35 [3200/10697 ( 29.9%)] Loss: 0.031820 L1: 0.018314 Grad: 0.134714 Thermal: 0.000683 LR: 3.02e-06\n",
      "Epoch  35 [3200/10697 ( 29.9%)] Loss: 0.031820 L1: 0.018314 Grad: 0.134714 Thermal: 0.000683 LR: 3.02e-06\n",
      "Epoch  35 [3250/10697 ( 30.4%)] Loss: 0.025781 L1: 0.015435 Grad: 0.103245 Thermal: 0.000448 LR: 3.02e-06\n",
      "Epoch  35 [3250/10697 ( 30.4%)] Loss: 0.025781 L1: 0.015435 Grad: 0.103245 Thermal: 0.000448 LR: 3.02e-06\n",
      "Epoch  35 [3300/10697 ( 30.8%)] Loss: 0.021838 L1: 0.012863 Grad: 0.089569 Thermal: 0.000357 LR: 3.02e-06\n",
      "Epoch  35 [3300/10697 ( 30.8%)] Loss: 0.021838 L1: 0.012863 Grad: 0.089569 Thermal: 0.000357 LR: 3.02e-06\n",
      "Epoch  35 [3350/10697 ( 31.3%)] Loss: 0.026696 L1: 0.015692 Grad: 0.109812 Thermal: 0.000466 LR: 3.02e-06\n",
      "Epoch  35 [3350/10697 ( 31.3%)] Loss: 0.026696 L1: 0.015692 Grad: 0.109812 Thermal: 0.000466 LR: 3.02e-06\n",
      "Epoch  35 [3400/10697 ( 31.8%)] Loss: 0.025490 L1: 0.014786 Grad: 0.106838 Thermal: 0.000406 LR: 3.02e-06\n",
      "Epoch  35 [3400/10697 ( 31.8%)] Loss: 0.025490 L1: 0.014786 Grad: 0.106838 Thermal: 0.000406 LR: 3.02e-06\n",
      "Epoch  35 [3450/10697 ( 32.3%)] Loss: 0.034452 L1: 0.019839 Grad: 0.145696 Thermal: 0.000867 LR: 3.02e-06\n",
      "Epoch  35 [3450/10697 ( 32.3%)] Loss: 0.034452 L1: 0.019839 Grad: 0.145696 Thermal: 0.000867 LR: 3.02e-06\n",
      "Epoch  35 [3500/10697 ( 32.7%)] Loss: 0.020347 L1: 0.011831 Grad: 0.085006 Thermal: 0.000300 LR: 3.02e-06\n",
      "Epoch  35 [3500/10697 ( 32.7%)] Loss: 0.020347 L1: 0.011831 Grad: 0.085006 Thermal: 0.000300 LR: 3.02e-06\n",
      "Epoch  35 [3550/10697 ( 33.2%)] Loss: 0.028082 L1: 0.016166 Grad: 0.118902 Thermal: 0.000517 LR: 3.02e-06\n",
      "Epoch  35 [3550/10697 ( 33.2%)] Loss: 0.028082 L1: 0.016166 Grad: 0.118902 Thermal: 0.000517 LR: 3.02e-06\n",
      "Epoch  35 [3600/10697 ( 33.7%)] Loss: 0.024461 L1: 0.014181 Grad: 0.102589 Thermal: 0.000425 LR: 3.02e-06\n",
      "Epoch  35 [3600/10697 ( 33.7%)] Loss: 0.024461 L1: 0.014181 Grad: 0.102589 Thermal: 0.000425 LR: 3.02e-06\n",
      "Epoch  35 [3650/10697 ( 34.1%)] Loss: 0.026111 L1: 0.015467 Grad: 0.106199 Thermal: 0.000478 LR: 3.02e-06\n",
      "Epoch  35 [3650/10697 ( 34.1%)] Loss: 0.026111 L1: 0.015467 Grad: 0.106199 Thermal: 0.000478 LR: 3.02e-06\n",
      "Epoch  35 [3700/10697 ( 34.6%)] Loss: 0.027696 L1: 0.016214 Grad: 0.114589 Thermal: 0.000453 LR: 3.02e-06\n",
      "Epoch  35 [3700/10697 ( 34.6%)] Loss: 0.027696 L1: 0.016214 Grad: 0.114589 Thermal: 0.000453 LR: 3.02e-06\n",
      "Epoch  35 [3750/10697 ( 35.1%)] Loss: 0.023197 L1: 0.013397 Grad: 0.097822 Thermal: 0.000362 LR: 3.02e-06\n",
      "Epoch  35 [3750/10697 ( 35.1%)] Loss: 0.023197 L1: 0.013397 Grad: 0.097822 Thermal: 0.000362 LR: 3.02e-06\n",
      "Epoch  35 [3800/10697 ( 35.5%)] Loss: 0.033741 L1: 0.019586 Grad: 0.141199 Thermal: 0.000701 LR: 3.02e-06\n",
      "Epoch  35 [3800/10697 ( 35.5%)] Loss: 0.033741 L1: 0.019586 Grad: 0.141199 Thermal: 0.000701 LR: 3.02e-06\n",
      "Epoch  35 [3850/10697 ( 36.0%)] Loss: 0.023099 L1: 0.013397 Grad: 0.096850 Thermal: 0.000344 LR: 3.02e-06\n",
      "Epoch  35 [3850/10697 ( 36.0%)] Loss: 0.023099 L1: 0.013397 Grad: 0.096850 Thermal: 0.000344 LR: 3.02e-06\n",
      "Epoch  35 [3900/10697 ( 36.5%)] Loss: 0.026335 L1: 0.015276 Grad: 0.110381 Thermal: 0.000425 LR: 3.02e-06\n",
      "Epoch  35 [3900/10697 ( 36.5%)] Loss: 0.026335 L1: 0.015276 Grad: 0.110381 Thermal: 0.000425 LR: 3.02e-06\n",
      "Epoch  35 [3950/10697 ( 36.9%)] Loss: 0.027434 L1: 0.016284 Grad: 0.111272 Thermal: 0.000466 LR: 3.02e-06\n",
      "Epoch  35 [3950/10697 ( 36.9%)] Loss: 0.027434 L1: 0.016284 Grad: 0.111272 Thermal: 0.000466 LR: 3.02e-06\n",
      "Epoch  35 [4000/10697 ( 37.4%)] Loss: 0.029235 L1: 0.016260 Grad: 0.129430 Thermal: 0.000641 LR: 3.02e-06\n",
      "Epoch  35 [4000/10697 ( 37.4%)] Loss: 0.029235 L1: 0.016260 Grad: 0.129430 Thermal: 0.000641 LR: 3.02e-06\n",
      "Epoch  35 [4050/10697 ( 37.9%)] Loss: 0.023569 L1: 0.013819 Grad: 0.097318 Thermal: 0.000361 LR: 3.02e-06\n",
      "Epoch  35 [4050/10697 ( 37.9%)] Loss: 0.023569 L1: 0.013819 Grad: 0.097318 Thermal: 0.000361 LR: 3.02e-06\n",
      "Epoch  35 [4100/10697 ( 38.3%)] Loss: 0.026890 L1: 0.016130 Grad: 0.107374 Thermal: 0.000460 LR: 3.02e-06\n",
      "Epoch  35 [4100/10697 ( 38.3%)] Loss: 0.026890 L1: 0.016130 Grad: 0.107374 Thermal: 0.000460 LR: 3.02e-06\n",
      "Epoch  35 [4150/10697 ( 38.8%)] Loss: 0.024558 L1: 0.014139 Grad: 0.104000 Thermal: 0.000381 LR: 3.02e-06\n",
      "Epoch  35 [4150/10697 ( 38.8%)] Loss: 0.024558 L1: 0.014139 Grad: 0.104000 Thermal: 0.000381 LR: 3.02e-06\n",
      "Epoch  35 [4200/10697 ( 39.3%)] Loss: 0.030495 L1: 0.017847 Grad: 0.126129 Thermal: 0.000693 LR: 3.02e-06\n",
      "Epoch  35 [4200/10697 ( 39.3%)] Loss: 0.030495 L1: 0.017847 Grad: 0.126129 Thermal: 0.000693 LR: 3.02e-06\n",
      "Epoch  35 [4250/10697 ( 39.7%)] Loss: 0.033472 L1: 0.020052 Grad: 0.133844 Thermal: 0.000724 LR: 3.02e-06\n",
      "Epoch  35 [4250/10697 ( 39.7%)] Loss: 0.033472 L1: 0.020052 Grad: 0.133844 Thermal: 0.000724 LR: 3.02e-06\n",
      "Epoch  35 [4300/10697 ( 40.2%)] Loss: 0.028834 L1: 0.016525 Grad: 0.122828 Thermal: 0.000527 LR: 3.02e-06\n",
      "Epoch  35 [4300/10697 ( 40.2%)] Loss: 0.028834 L1: 0.016525 Grad: 0.122828 Thermal: 0.000527 LR: 3.02e-06\n",
      "Epoch  35 [4350/10697 ( 40.7%)] Loss: 0.029409 L1: 0.016869 Grad: 0.125125 Thermal: 0.000542 LR: 3.02e-06\n",
      "Epoch  35 [4350/10697 ( 40.7%)] Loss: 0.029409 L1: 0.016869 Grad: 0.125125 Thermal: 0.000542 LR: 3.02e-06\n",
      "Epoch  35 [4400/10697 ( 41.1%)] Loss: 0.029310 L1: 0.016426 Grad: 0.128543 Thermal: 0.000603 LR: 3.02e-06\n",
      "Epoch  35 [4400/10697 ( 41.1%)] Loss: 0.029310 L1: 0.016426 Grad: 0.128543 Thermal: 0.000603 LR: 3.02e-06\n",
      "Epoch  35 [4450/10697 ( 41.6%)] Loss: 0.021127 L1: 0.011952 Grad: 0.091605 Thermal: 0.000280 LR: 3.02e-06\n",
      "Epoch  35 [4450/10697 ( 41.6%)] Loss: 0.021127 L1: 0.011952 Grad: 0.091605 Thermal: 0.000280 LR: 3.02e-06\n",
      "Epoch  35 [4500/10697 ( 42.1%)] Loss: 0.027127 L1: 0.015689 Grad: 0.114153 Thermal: 0.000442 LR: 3.02e-06\n",
      "Epoch  35 [4500/10697 ( 42.1%)] Loss: 0.027127 L1: 0.015689 Grad: 0.114153 Thermal: 0.000442 LR: 3.02e-06\n",
      "Epoch  35 [4550/10697 ( 42.5%)] Loss: 0.020627 L1: 0.012100 Grad: 0.085122 Thermal: 0.000307 LR: 3.02e-06\n",
      "Epoch  35 [4550/10697 ( 42.5%)] Loss: 0.020627 L1: 0.012100 Grad: 0.085122 Thermal: 0.000307 LR: 3.02e-06\n",
      "Epoch  35 [4600/10697 ( 43.0%)] Loss: 0.028651 L1: 0.016585 Grad: 0.120402 Thermal: 0.000505 LR: 3.02e-06\n",
      "Epoch  35 [4600/10697 ( 43.0%)] Loss: 0.028651 L1: 0.016585 Grad: 0.120402 Thermal: 0.000505 LR: 3.02e-06\n",
      "Epoch  35 [4650/10697 ( 43.5%)] Loss: 0.025086 L1: 0.014153 Grad: 0.109138 Thermal: 0.000381 LR: 3.02e-06\n",
      "Epoch  35 [4650/10697 ( 43.5%)] Loss: 0.025086 L1: 0.014153 Grad: 0.109138 Thermal: 0.000381 LR: 3.02e-06\n",
      "Epoch  35 [4700/10697 ( 43.9%)] Loss: 0.026414 L1: 0.015040 Grad: 0.113514 Thermal: 0.000448 LR: 3.02e-06\n",
      "Epoch  35 [4700/10697 ( 43.9%)] Loss: 0.026414 L1: 0.015040 Grad: 0.113514 Thermal: 0.000448 LR: 3.02e-06\n",
      "Epoch  35 [4750/10697 ( 44.4%)] Loss: 0.027279 L1: 0.015956 Grad: 0.112992 Thermal: 0.000470 LR: 3.02e-06\n",
      "Epoch  35 [4750/10697 ( 44.4%)] Loss: 0.027279 L1: 0.015956 Grad: 0.112992 Thermal: 0.000470 LR: 3.02e-06\n",
      "Epoch  35 [4800/10697 ( 44.9%)] Loss: 0.022982 L1: 0.012937 Grad: 0.100285 Thermal: 0.000331 LR: 3.02e-06\n",
      "Epoch  35 [4800/10697 ( 44.9%)] Loss: 0.022982 L1: 0.012937 Grad: 0.100285 Thermal: 0.000331 LR: 3.02e-06\n",
      "Epoch  35 [4850/10697 ( 45.3%)] Loss: 0.024435 L1: 0.014051 Grad: 0.103651 Thermal: 0.000375 LR: 3.02e-06\n",
      "Epoch  35 [4850/10697 ( 45.3%)] Loss: 0.024435 L1: 0.014051 Grad: 0.103651 Thermal: 0.000375 LR: 3.02e-06\n",
      "Epoch  35 [4900/10697 ( 45.8%)] Loss: 0.027540 L1: 0.016499 Grad: 0.110177 Thermal: 0.000478 LR: 3.02e-06\n",
      "Epoch  35 [4900/10697 ( 45.8%)] Loss: 0.027540 L1: 0.016499 Grad: 0.110177 Thermal: 0.000478 LR: 3.02e-06\n",
      "Epoch  35 [4950/10697 ( 46.3%)] Loss: 0.024080 L1: 0.014250 Grad: 0.098105 Thermal: 0.000389 LR: 3.02e-06\n",
      "Epoch  35 [4950/10697 ( 46.3%)] Loss: 0.024080 L1: 0.014250 Grad: 0.098105 Thermal: 0.000389 LR: 3.02e-06\n",
      "Epoch  35 [5000/10697 ( 46.7%)] Loss: 0.031832 L1: 0.018369 Grad: 0.134308 Thermal: 0.000646 LR: 3.02e-06\n",
      "Epoch  35 [5000/10697 ( 46.7%)] Loss: 0.031832 L1: 0.018369 Grad: 0.134308 Thermal: 0.000646 LR: 3.02e-06\n",
      "Epoch  35 [5050/10697 ( 47.2%)] Loss: 0.026003 L1: 0.015045 Grad: 0.109360 Thermal: 0.000426 LR: 3.02e-06\n",
      "Epoch  35 [5050/10697 ( 47.2%)] Loss: 0.026003 L1: 0.015045 Grad: 0.109360 Thermal: 0.000426 LR: 3.02e-06\n",
      "Epoch  35 [5100/10697 ( 47.7%)] Loss: 0.033214 L1: 0.019349 Grad: 0.138267 Thermal: 0.000771 LR: 3.02e-06\n",
      "Epoch  35 [5100/10697 ( 47.7%)] Loss: 0.033214 L1: 0.019349 Grad: 0.138267 Thermal: 0.000771 LR: 3.02e-06\n",
      "Epoch  35 [5150/10697 ( 48.1%)] Loss: 0.028985 L1: 0.017538 Grad: 0.114181 Thermal: 0.000583 LR: 3.02e-06\n",
      "Epoch  35 [5150/10697 ( 48.1%)] Loss: 0.028985 L1: 0.017538 Grad: 0.114181 Thermal: 0.000583 LR: 3.02e-06\n",
      "Epoch  35 [5200/10697 ( 48.6%)] Loss: 0.027278 L1: 0.016169 Grad: 0.110754 Thermal: 0.000660 LR: 3.02e-06\n",
      "Epoch  35 [5200/10697 ( 48.6%)] Loss: 0.027278 L1: 0.016169 Grad: 0.110754 Thermal: 0.000660 LR: 3.02e-06\n",
      "Epoch  35 [5250/10697 ( 49.1%)] Loss: 0.027715 L1: 0.016306 Grad: 0.113848 Thermal: 0.000480 LR: 3.02e-06\n",
      "Epoch  35 [5250/10697 ( 49.1%)] Loss: 0.027715 L1: 0.016306 Grad: 0.113848 Thermal: 0.000480 LR: 3.02e-06\n",
      "Epoch  35 [5300/10697 ( 49.5%)] Loss: 0.030526 L1: 0.018170 Grad: 0.123273 Thermal: 0.000585 LR: 3.02e-06\n",
      "Epoch  35 [5300/10697 ( 49.5%)] Loss: 0.030526 L1: 0.018170 Grad: 0.123273 Thermal: 0.000585 LR: 3.02e-06\n",
      "Epoch  35 [5350/10697 ( 50.0%)] Loss: 0.022709 L1: 0.013330 Grad: 0.093596 Thermal: 0.000376 LR: 3.02e-06\n",
      "Epoch  35 [5350/10697 ( 50.0%)] Loss: 0.022709 L1: 0.013330 Grad: 0.093596 Thermal: 0.000376 LR: 3.02e-06\n",
      "Epoch  35 [5400/10697 ( 50.5%)] Loss: 0.028907 L1: 0.016716 Grad: 0.121651 Thermal: 0.000519 LR: 3.02e-06\n",
      "Epoch  35 [5400/10697 ( 50.5%)] Loss: 0.028907 L1: 0.016716 Grad: 0.121651 Thermal: 0.000519 LR: 3.02e-06\n",
      "Epoch  35 [5450/10697 ( 50.9%)] Loss: 0.028925 L1: 0.017091 Grad: 0.118084 Thermal: 0.000516 LR: 3.02e-06\n",
      "Epoch  35 [5450/10697 ( 50.9%)] Loss: 0.028925 L1: 0.017091 Grad: 0.118084 Thermal: 0.000516 LR: 3.02e-06\n",
      "Epoch  35 [5500/10697 ( 51.4%)] Loss: 0.026531 L1: 0.016019 Grad: 0.104895 Thermal: 0.000456 LR: 3.02e-06\n",
      "Epoch  35 [5500/10697 ( 51.4%)] Loss: 0.026531 L1: 0.016019 Grad: 0.104895 Thermal: 0.000456 LR: 3.02e-06\n",
      "Epoch  35 [5550/10697 ( 51.9%)] Loss: 0.022907 L1: 0.013490 Grad: 0.093979 Thermal: 0.000386 LR: 3.02e-06\n",
      "Epoch  35 [5550/10697 ( 51.9%)] Loss: 0.022907 L1: 0.013490 Grad: 0.093979 Thermal: 0.000386 LR: 3.02e-06\n",
      "Epoch  35 [5600/10697 ( 52.4%)] Loss: 0.025433 L1: 0.015210 Grad: 0.102010 Thermal: 0.000440 LR: 3.02e-06\n",
      "Epoch  35 [5600/10697 ( 52.4%)] Loss: 0.025433 L1: 0.015210 Grad: 0.102010 Thermal: 0.000440 LR: 3.02e-06\n",
      "Epoch  35 [5650/10697 ( 52.8%)] Loss: 0.027906 L1: 0.016613 Grad: 0.112685 Thermal: 0.000483 LR: 3.02e-06\n",
      "Epoch  35 [5650/10697 ( 52.8%)] Loss: 0.027906 L1: 0.016613 Grad: 0.112685 Thermal: 0.000483 LR: 3.02e-06\n",
      "Epoch  35 [5700/10697 ( 53.3%)] Loss: 0.024883 L1: 0.014554 Grad: 0.103091 Thermal: 0.000408 LR: 3.02e-06\n",
      "Epoch  35 [5700/10697 ( 53.3%)] Loss: 0.024883 L1: 0.014554 Grad: 0.103091 Thermal: 0.000408 LR: 3.02e-06\n",
      "Epoch  35 [5750/10697 ( 53.8%)] Loss: 0.034970 L1: 0.020337 Grad: 0.145946 Thermal: 0.000755 LR: 3.02e-06\n",
      "Epoch  35 [5750/10697 ( 53.8%)] Loss: 0.034970 L1: 0.020337 Grad: 0.145946 Thermal: 0.000755 LR: 3.02e-06\n",
      "Epoch  35 [5800/10697 ( 54.2%)] Loss: 0.027826 L1: 0.016021 Grad: 0.117821 Thermal: 0.000468 LR: 3.02e-06\n",
      "Epoch  35 [5800/10697 ( 54.2%)] Loss: 0.027826 L1: 0.016021 Grad: 0.117821 Thermal: 0.000468 LR: 3.02e-06\n",
      "Epoch  35 [5850/10697 ( 54.7%)] Loss: 0.025092 L1: 0.014426 Grad: 0.106478 Thermal: 0.000363 LR: 3.02e-06\n",
      "Epoch  35 [5850/10697 ( 54.7%)] Loss: 0.025092 L1: 0.014426 Grad: 0.106478 Thermal: 0.000363 LR: 3.02e-06\n",
      "Epoch  35 [5900/10697 ( 55.2%)] Loss: 0.031426 L1: 0.017869 Grad: 0.135273 Thermal: 0.000593 LR: 3.02e-06\n",
      "Epoch  35 [5900/10697 ( 55.2%)] Loss: 0.031426 L1: 0.017869 Grad: 0.135273 Thermal: 0.000593 LR: 3.02e-06\n",
      "Epoch  35 [5950/10697 ( 55.6%)] Loss: 0.022187 L1: 0.012677 Grad: 0.094931 Thermal: 0.000347 LR: 3.02e-06\n",
      "Epoch  35 [5950/10697 ( 55.6%)] Loss: 0.022187 L1: 0.012677 Grad: 0.094931 Thermal: 0.000347 LR: 3.02e-06\n",
      "Epoch  35 [6000/10697 ( 56.1%)] Loss: 0.028719 L1: 0.016396 Grad: 0.122936 Thermal: 0.000589 LR: 3.02e-06\n",
      "Epoch  35 [6000/10697 ( 56.1%)] Loss: 0.028719 L1: 0.016396 Grad: 0.122936 Thermal: 0.000589 LR: 3.02e-06\n",
      "Epoch  35 [6050/10697 ( 56.6%)] Loss: 0.023137 L1: 0.013600 Grad: 0.095180 Thermal: 0.000374 LR: 3.02e-06\n",
      "Epoch  35 [6050/10697 ( 56.6%)] Loss: 0.023137 L1: 0.013600 Grad: 0.095180 Thermal: 0.000374 LR: 3.02e-06\n",
      "Epoch  35 [6100/10697 ( 57.0%)] Loss: 0.022851 L1: 0.013049 Grad: 0.097857 Thermal: 0.000341 LR: 3.02e-06\n",
      "Epoch  35 [6100/10697 ( 57.0%)] Loss: 0.022851 L1: 0.013049 Grad: 0.097857 Thermal: 0.000341 LR: 3.02e-06\n",
      "Epoch  35 [6150/10697 ( 57.5%)] Loss: 0.028867 L1: 0.016302 Grad: 0.125372 Thermal: 0.000553 LR: 3.02e-06\n",
      "Epoch  35 [6150/10697 ( 57.5%)] Loss: 0.028867 L1: 0.016302 Grad: 0.125372 Thermal: 0.000553 LR: 3.02e-06\n",
      "Epoch  35 [6200/10697 ( 58.0%)] Loss: 0.030722 L1: 0.017988 Grad: 0.127046 Thermal: 0.000585 LR: 3.02e-06\n",
      "Epoch  35 [6200/10697 ( 58.0%)] Loss: 0.030722 L1: 0.017988 Grad: 0.127046 Thermal: 0.000585 LR: 3.02e-06\n",
      "Epoch  35 [6250/10697 ( 58.4%)] Loss: 0.024530 L1: 0.014315 Grad: 0.101931 Thermal: 0.000445 LR: 3.02e-06\n",
      "Epoch  35 [6250/10697 ( 58.4%)] Loss: 0.024530 L1: 0.014315 Grad: 0.101931 Thermal: 0.000445 LR: 3.02e-06\n",
      "Epoch  35 [6300/10697 ( 58.9%)] Loss: 0.022916 L1: 0.013180 Grad: 0.097182 Thermal: 0.000350 LR: 3.02e-06\n",
      "Epoch  35 [6300/10697 ( 58.9%)] Loss: 0.022916 L1: 0.013180 Grad: 0.097182 Thermal: 0.000350 LR: 3.02e-06\n",
      "Epoch  35 [6350/10697 ( 59.4%)] Loss: 0.023011 L1: 0.013419 Grad: 0.095737 Thermal: 0.000371 LR: 3.02e-06\n",
      "Epoch  35 [6350/10697 ( 59.4%)] Loss: 0.023011 L1: 0.013419 Grad: 0.095737 Thermal: 0.000371 LR: 3.02e-06\n",
      "Epoch  35 [6400/10697 ( 59.8%)] Loss: 0.026229 L1: 0.014868 Grad: 0.113413 Thermal: 0.000402 LR: 3.02e-06\n",
      "Epoch  35 [6400/10697 ( 59.8%)] Loss: 0.026229 L1: 0.014868 Grad: 0.113413 Thermal: 0.000402 LR: 3.02e-06\n",
      "Epoch  35 [6450/10697 ( 60.3%)] Loss: 0.023629 L1: 0.014101 Grad: 0.095096 Thermal: 0.000369 LR: 3.02e-06\n",
      "Epoch  35 [6450/10697 ( 60.3%)] Loss: 0.023629 L1: 0.014101 Grad: 0.095096 Thermal: 0.000369 LR: 3.02e-06\n",
      "Epoch  35 [6500/10697 ( 60.8%)] Loss: 0.025949 L1: 0.015369 Grad: 0.105584 Thermal: 0.000421 LR: 3.02e-06\n",
      "Epoch  35 [6500/10697 ( 60.8%)] Loss: 0.025949 L1: 0.015369 Grad: 0.105584 Thermal: 0.000421 LR: 3.02e-06\n",
      "Epoch  35 [6550/10697 ( 61.2%)] Loss: 0.025322 L1: 0.015016 Grad: 0.102863 Thermal: 0.000407 LR: 3.02e-06\n",
      "Epoch  35 [6550/10697 ( 61.2%)] Loss: 0.025322 L1: 0.015016 Grad: 0.102863 Thermal: 0.000407 LR: 3.02e-06\n",
      "Epoch  35 [6600/10697 ( 61.7%)] Loss: 0.031402 L1: 0.018445 Grad: 0.129278 Thermal: 0.000587 LR: 3.02e-06\n",
      "Epoch  35 [6600/10697 ( 61.7%)] Loss: 0.031402 L1: 0.018445 Grad: 0.129278 Thermal: 0.000587 LR: 3.02e-06\n",
      "Epoch  35 [6650/10697 ( 62.2%)] Loss: 0.026711 L1: 0.015336 Grad: 0.113526 Thermal: 0.000436 LR: 3.02e-06\n",
      "Epoch  35 [6650/10697 ( 62.2%)] Loss: 0.026711 L1: 0.015336 Grad: 0.113526 Thermal: 0.000436 LR: 3.02e-06\n",
      "Epoch  35 [6700/10697 ( 62.6%)] Loss: 0.027304 L1: 0.016517 Grad: 0.107630 Thermal: 0.000479 LR: 3.02e-06\n",
      "Epoch  35 [6700/10697 ( 62.6%)] Loss: 0.027304 L1: 0.016517 Grad: 0.107630 Thermal: 0.000479 LR: 3.02e-06\n",
      "Epoch  35 [6750/10697 ( 63.1%)] Loss: 0.022987 L1: 0.013122 Grad: 0.098486 Thermal: 0.000335 LR: 3.02e-06\n",
      "Epoch  35 [6750/10697 ( 63.1%)] Loss: 0.022987 L1: 0.013122 Grad: 0.098486 Thermal: 0.000335 LR: 3.02e-06\n",
      "Epoch  35 [6800/10697 ( 63.6%)] Loss: 0.027157 L1: 0.015950 Grad: 0.111813 Thermal: 0.000501 LR: 3.02e-06\n",
      "Epoch  35 [6800/10697 ( 63.6%)] Loss: 0.027157 L1: 0.015950 Grad: 0.111813 Thermal: 0.000501 LR: 3.02e-06\n",
      "Epoch  35 [6850/10697 ( 64.0%)] Loss: 0.023538 L1: 0.013746 Grad: 0.097724 Thermal: 0.000395 LR: 3.02e-06\n",
      "Epoch  35 [6850/10697 ( 64.0%)] Loss: 0.023538 L1: 0.013746 Grad: 0.097724 Thermal: 0.000395 LR: 3.02e-06\n",
      "Epoch  35 [6900/10697 ( 64.5%)] Loss: 0.027653 L1: 0.016047 Grad: 0.115814 Thermal: 0.000489 LR: 3.02e-06\n",
      "Epoch  35 [6900/10697 ( 64.5%)] Loss: 0.027653 L1: 0.016047 Grad: 0.115814 Thermal: 0.000489 LR: 3.02e-06\n",
      "Epoch  35 [6950/10697 ( 65.0%)] Loss: 0.020179 L1: 0.011672 Grad: 0.084920 Thermal: 0.000307 LR: 3.02e-06\n",
      "Epoch  35 [6950/10697 ( 65.0%)] Loss: 0.020179 L1: 0.011672 Grad: 0.084920 Thermal: 0.000307 LR: 3.02e-06\n",
      "Epoch  35 [7000/10697 ( 65.4%)] Loss: 0.025551 L1: 0.014934 Grad: 0.105912 Thermal: 0.000522 LR: 3.02e-06\n",
      "Epoch  35 [7000/10697 ( 65.4%)] Loss: 0.025551 L1: 0.014934 Grad: 0.105912 Thermal: 0.000522 LR: 3.02e-06\n",
      "Epoch  35 [7050/10697 ( 65.9%)] Loss: 0.023123 L1: 0.013499 Grad: 0.096070 Thermal: 0.000328 LR: 3.02e-06\n",
      "Epoch  35 [7050/10697 ( 65.9%)] Loss: 0.023123 L1: 0.013499 Grad: 0.096070 Thermal: 0.000328 LR: 3.02e-06\n",
      "Epoch  35 [7100/10697 ( 66.4%)] Loss: 0.029039 L1: 0.016949 Grad: 0.120615 Thermal: 0.000569 LR: 3.02e-06\n",
      "Epoch  35 [7100/10697 ( 66.4%)] Loss: 0.029039 L1: 0.016949 Grad: 0.120615 Thermal: 0.000569 LR: 3.02e-06\n",
      "Epoch  35 [7150/10697 ( 66.8%)] Loss: 0.024869 L1: 0.014670 Grad: 0.101785 Thermal: 0.000412 LR: 3.02e-06\n",
      "Epoch  35 [7150/10697 ( 66.8%)] Loss: 0.024869 L1: 0.014670 Grad: 0.101785 Thermal: 0.000412 LR: 3.02e-06\n",
      "Epoch  35 [7200/10697 ( 67.3%)] Loss: 0.029813 L1: 0.017946 Grad: 0.118348 Thermal: 0.000636 LR: 3.02e-06\n",
      "Epoch  35 [7200/10697 ( 67.3%)] Loss: 0.029813 L1: 0.017946 Grad: 0.118348 Thermal: 0.000636 LR: 3.02e-06\n",
      "Epoch  35 [7250/10697 ( 67.8%)] Loss: 0.026981 L1: 0.016049 Grad: 0.109089 Thermal: 0.000460 LR: 3.02e-06\n",
      "Epoch  35 [7250/10697 ( 67.8%)] Loss: 0.026981 L1: 0.016049 Grad: 0.109089 Thermal: 0.000460 LR: 3.02e-06\n",
      "Epoch  35 [7300/10697 ( 68.2%)] Loss: 0.023159 L1: 0.013312 Grad: 0.098294 Thermal: 0.000362 LR: 3.02e-06\n",
      "Epoch  35 [7300/10697 ( 68.2%)] Loss: 0.023159 L1: 0.013312 Grad: 0.098294 Thermal: 0.000362 LR: 3.02e-06\n",
      "Epoch  35 [7350/10697 ( 68.7%)] Loss: 0.018802 L1: 0.010852 Grad: 0.079371 Thermal: 0.000244 LR: 3.02e-06\n",
      "Epoch  35 [7350/10697 ( 68.7%)] Loss: 0.018802 L1: 0.010852 Grad: 0.079371 Thermal: 0.000244 LR: 3.02e-06\n",
      "Epoch  35 [7400/10697 ( 69.2%)] Loss: 0.023854 L1: 0.014061 Grad: 0.097746 Thermal: 0.000369 LR: 3.02e-06\n",
      "Epoch  35 [7400/10697 ( 69.2%)] Loss: 0.023854 L1: 0.014061 Grad: 0.097746 Thermal: 0.000369 LR: 3.02e-06\n",
      "Epoch  35 [7450/10697 ( 69.6%)] Loss: 0.027468 L1: 0.016071 Grad: 0.113710 Thermal: 0.000519 LR: 3.02e-06\n",
      "Epoch  35 [7450/10697 ( 69.6%)] Loss: 0.027468 L1: 0.016071 Grad: 0.113710 Thermal: 0.000519 LR: 3.02e-06\n",
      "Epoch  35 [7500/10697 ( 70.1%)] Loss: 0.029175 L1: 0.017003 Grad: 0.121449 Thermal: 0.000540 LR: 3.02e-06\n",
      "Epoch  35 [7500/10697 ( 70.1%)] Loss: 0.029175 L1: 0.017003 Grad: 0.121449 Thermal: 0.000540 LR: 3.02e-06\n",
      "Epoch  35 [7550/10697 ( 70.6%)] Loss: 0.026198 L1: 0.015056 Grad: 0.111179 Thermal: 0.000488 LR: 3.02e-06\n",
      "Epoch  35 [7550/10697 ( 70.6%)] Loss: 0.026198 L1: 0.015056 Grad: 0.111179 Thermal: 0.000488 LR: 3.02e-06\n",
      "Epoch  35 [7600/10697 ( 71.0%)] Loss: 0.027085 L1: 0.015226 Grad: 0.118330 Thermal: 0.000521 LR: 3.02e-06\n",
      "Epoch  35 [7600/10697 ( 71.0%)] Loss: 0.027085 L1: 0.015226 Grad: 0.118330 Thermal: 0.000521 LR: 3.02e-06\n",
      "Epoch  35 [7650/10697 ( 71.5%)] Loss: 0.028554 L1: 0.017000 Grad: 0.115263 Thermal: 0.000568 LR: 3.02e-06\n",
      "Epoch  35 [7650/10697 ( 71.5%)] Loss: 0.028554 L1: 0.017000 Grad: 0.115263 Thermal: 0.000568 LR: 3.02e-06\n",
      "Epoch  35 [7700/10697 ( 72.0%)] Loss: 0.027215 L1: 0.015866 Grad: 0.113267 Thermal: 0.000444 LR: 3.02e-06\n",
      "Epoch  35 [7700/10697 ( 72.0%)] Loss: 0.027215 L1: 0.015866 Grad: 0.113267 Thermal: 0.000444 LR: 3.02e-06\n",
      "Epoch  35 [7750/10697 ( 72.5%)] Loss: 0.028460 L1: 0.016671 Grad: 0.117611 Thermal: 0.000568 LR: 3.02e-06\n",
      "Epoch  35 [7750/10697 ( 72.5%)] Loss: 0.028460 L1: 0.016671 Grad: 0.117611 Thermal: 0.000568 LR: 3.02e-06\n",
      "Epoch  35 [7800/10697 ( 72.9%)] Loss: 0.028822 L1: 0.016367 Grad: 0.124318 Thermal: 0.000483 LR: 3.02e-06\n",
      "Epoch  35 [7800/10697 ( 72.9%)] Loss: 0.028822 L1: 0.016367 Grad: 0.124318 Thermal: 0.000483 LR: 3.02e-06\n",
      "Epoch  35 [7850/10697 ( 73.4%)] Loss: 0.023485 L1: 0.014075 Grad: 0.093923 Thermal: 0.000359 LR: 3.02e-06\n",
      "Epoch  35 [7850/10697 ( 73.4%)] Loss: 0.023485 L1: 0.014075 Grad: 0.093923 Thermal: 0.000359 LR: 3.02e-06\n",
      "Epoch  35 [7900/10697 ( 73.9%)] Loss: 0.027365 L1: 0.015866 Grad: 0.114756 Thermal: 0.000468 LR: 3.02e-06\n",
      "Epoch  35 [7900/10697 ( 73.9%)] Loss: 0.027365 L1: 0.015866 Grad: 0.114756 Thermal: 0.000468 LR: 3.02e-06\n",
      "Epoch  35 [7950/10697 ( 74.3%)] Loss: 0.025229 L1: 0.014408 Grad: 0.108000 Thermal: 0.000428 LR: 3.02e-06\n",
      "Epoch  35 [7950/10697 ( 74.3%)] Loss: 0.025229 L1: 0.014408 Grad: 0.108000 Thermal: 0.000428 LR: 3.02e-06\n",
      "Epoch  35 [8000/10697 ( 74.8%)] Loss: 0.020438 L1: 0.011663 Grad: 0.087606 Thermal: 0.000272 LR: 3.02e-06\n",
      "Epoch  35 [8000/10697 ( 74.8%)] Loss: 0.020438 L1: 0.011663 Grad: 0.087606 Thermal: 0.000272 LR: 3.02e-06\n",
      "Epoch  35 [8050/10697 ( 75.3%)] Loss: 0.028914 L1: 0.017103 Grad: 0.117849 Thermal: 0.000539 LR: 3.02e-06\n",
      "Epoch  35 [8050/10697 ( 75.3%)] Loss: 0.028914 L1: 0.017103 Grad: 0.117849 Thermal: 0.000539 LR: 3.02e-06\n",
      "Epoch  35 [8100/10697 ( 75.7%)] Loss: 0.023917 L1: 0.013805 Grad: 0.100941 Thermal: 0.000359 LR: 3.02e-06\n",
      "Epoch  35 [8100/10697 ( 75.7%)] Loss: 0.023917 L1: 0.013805 Grad: 0.100941 Thermal: 0.000359 LR: 3.02e-06\n",
      "Epoch  35 [8150/10697 ( 76.2%)] Loss: 0.025940 L1: 0.015340 Grad: 0.105780 Thermal: 0.000454 LR: 3.02e-06\n",
      "Epoch  35 [8150/10697 ( 76.2%)] Loss: 0.025940 L1: 0.015340 Grad: 0.105780 Thermal: 0.000454 LR: 3.02e-06\n",
      "Epoch  35 [8200/10697 ( 76.7%)] Loss: 0.022236 L1: 0.013344 Grad: 0.088739 Thermal: 0.000371 LR: 3.02e-06\n",
      "Epoch  35 [8200/10697 ( 76.7%)] Loss: 0.022236 L1: 0.013344 Grad: 0.088739 Thermal: 0.000371 LR: 3.02e-06\n",
      "Epoch  35 [8250/10697 ( 77.1%)] Loss: 0.021472 L1: 0.012357 Grad: 0.091005 Thermal: 0.000288 LR: 3.02e-06\n",
      "Epoch  35 [8250/10697 ( 77.1%)] Loss: 0.021472 L1: 0.012357 Grad: 0.091005 Thermal: 0.000288 LR: 3.02e-06\n",
      "Epoch  35 [8300/10697 ( 77.6%)] Loss: 0.028578 L1: 0.017022 Grad: 0.115300 Thermal: 0.000509 LR: 3.02e-06\n",
      "Epoch  35 [8300/10697 ( 77.6%)] Loss: 0.028578 L1: 0.017022 Grad: 0.115300 Thermal: 0.000509 LR: 3.02e-06\n",
      "Epoch  35 [8350/10697 ( 78.1%)] Loss: 0.027626 L1: 0.015936 Grad: 0.116670 Thermal: 0.000456 LR: 3.02e-06\n",
      "Epoch  35 [8350/10697 ( 78.1%)] Loss: 0.027626 L1: 0.015936 Grad: 0.116670 Thermal: 0.000456 LR: 3.02e-06\n",
      "Epoch  35 [8400/10697 ( 78.5%)] Loss: 0.025834 L1: 0.014675 Grad: 0.111373 Thermal: 0.000438 LR: 3.02e-06\n",
      "Epoch  35 [8400/10697 ( 78.5%)] Loss: 0.025834 L1: 0.014675 Grad: 0.111373 Thermal: 0.000438 LR: 3.02e-06\n",
      "Epoch  35 [8450/10697 ( 79.0%)] Loss: 0.023021 L1: 0.013604 Grad: 0.093990 Thermal: 0.000355 LR: 3.02e-06\n",
      "Epoch  35 [8450/10697 ( 79.0%)] Loss: 0.023021 L1: 0.013604 Grad: 0.093990 Thermal: 0.000355 LR: 3.02e-06\n",
      "Epoch  35 [8500/10697 ( 79.5%)] Loss: 0.029159 L1: 0.017775 Grad: 0.113570 Thermal: 0.000544 LR: 3.02e-06\n",
      "Epoch  35 [8500/10697 ( 79.5%)] Loss: 0.029159 L1: 0.017775 Grad: 0.113570 Thermal: 0.000544 LR: 3.02e-06\n",
      "Epoch  35 [8550/10697 ( 79.9%)] Loss: 0.026367 L1: 0.015802 Grad: 0.105426 Thermal: 0.000433 LR: 3.02e-06\n",
      "Epoch  35 [8550/10697 ( 79.9%)] Loss: 0.026367 L1: 0.015802 Grad: 0.105426 Thermal: 0.000433 LR: 3.02e-06\n",
      "Epoch  35 [8600/10697 ( 80.4%)] Loss: 0.020282 L1: 0.011761 Grad: 0.085063 Thermal: 0.000282 LR: 3.02e-06\n",
      "Epoch  35 [8600/10697 ( 80.4%)] Loss: 0.020282 L1: 0.011761 Grad: 0.085063 Thermal: 0.000282 LR: 3.02e-06\n",
      "Epoch  35 [8650/10697 ( 80.9%)] Loss: 0.022566 L1: 0.013121 Grad: 0.094280 Thermal: 0.000337 LR: 3.02e-06\n",
      "Epoch  35 [8650/10697 ( 80.9%)] Loss: 0.022566 L1: 0.013121 Grad: 0.094280 Thermal: 0.000337 LR: 3.02e-06\n",
      "Epoch  35 [8700/10697 ( 81.3%)] Loss: 0.027953 L1: 0.016157 Grad: 0.117715 Thermal: 0.000493 LR: 3.02e-06\n",
      "Epoch  35 [8700/10697 ( 81.3%)] Loss: 0.027953 L1: 0.016157 Grad: 0.117715 Thermal: 0.000493 LR: 3.02e-06\n",
      "Epoch  35 [8750/10697 ( 81.8%)] Loss: 0.027216 L1: 0.016063 Grad: 0.111311 Thermal: 0.000440 LR: 3.02e-06\n",
      "Epoch  35 [8750/10697 ( 81.8%)] Loss: 0.027216 L1: 0.016063 Grad: 0.111311 Thermal: 0.000440 LR: 3.02e-06\n",
      "Epoch  35 [8800/10697 ( 82.3%)] Loss: 0.023281 L1: 0.013784 Grad: 0.094792 Thermal: 0.000365 LR: 3.02e-06\n",
      "Epoch  35 [8800/10697 ( 82.3%)] Loss: 0.023281 L1: 0.013784 Grad: 0.094792 Thermal: 0.000365 LR: 3.02e-06\n",
      "Epoch  35 [8850/10697 ( 82.7%)] Loss: 0.025807 L1: 0.014889 Grad: 0.108967 Thermal: 0.000418 LR: 3.02e-06\n",
      "Epoch  35 [8850/10697 ( 82.7%)] Loss: 0.025807 L1: 0.014889 Grad: 0.108967 Thermal: 0.000418 LR: 3.02e-06\n",
      "Epoch  35 [8900/10697 ( 83.2%)] Loss: 0.028361 L1: 0.016774 Grad: 0.115620 Thermal: 0.000498 LR: 3.02e-06\n",
      "Epoch  35 [8900/10697 ( 83.2%)] Loss: 0.028361 L1: 0.016774 Grad: 0.115620 Thermal: 0.000498 LR: 3.02e-06\n",
      "Epoch  35 [8950/10697 ( 83.7%)] Loss: 0.028601 L1: 0.016326 Grad: 0.122502 Thermal: 0.000500 LR: 3.02e-06\n",
      "Epoch  35 [8950/10697 ( 83.7%)] Loss: 0.028601 L1: 0.016326 Grad: 0.122502 Thermal: 0.000500 LR: 3.02e-06\n",
      "Epoch  35 [9000/10697 ( 84.1%)] Loss: 0.021904 L1: 0.012795 Grad: 0.090926 Thermal: 0.000338 LR: 3.02e-06\n",
      "Epoch  35 [9000/10697 ( 84.1%)] Loss: 0.021904 L1: 0.012795 Grad: 0.090926 Thermal: 0.000338 LR: 3.02e-06\n",
      "Epoch  35 [9050/10697 ( 84.6%)] Loss: 0.023006 L1: 0.013575 Grad: 0.094122 Thermal: 0.000375 LR: 3.02e-06\n",
      "Epoch  35 [9050/10697 ( 84.6%)] Loss: 0.023006 L1: 0.013575 Grad: 0.094122 Thermal: 0.000375 LR: 3.02e-06\n",
      "Epoch  35 [9100/10697 ( 85.1%)] Loss: 0.032209 L1: 0.018460 Grad: 0.137051 Thermal: 0.000871 LR: 3.02e-06\n",
      "Epoch  35 [9100/10697 ( 85.1%)] Loss: 0.032209 L1: 0.018460 Grad: 0.137051 Thermal: 0.000871 LR: 3.02e-06\n",
      "Epoch  35 [9150/10697 ( 85.5%)] Loss: 0.029176 L1: 0.017030 Grad: 0.121182 Thermal: 0.000553 LR: 3.02e-06\n",
      "Epoch  35 [9150/10697 ( 85.5%)] Loss: 0.029176 L1: 0.017030 Grad: 0.121182 Thermal: 0.000553 LR: 3.02e-06\n",
      "Epoch  35 [9200/10697 ( 86.0%)] Loss: 0.026366 L1: 0.015168 Grad: 0.111734 Thermal: 0.000484 LR: 3.02e-06\n",
      "Epoch  35 [9200/10697 ( 86.0%)] Loss: 0.026366 L1: 0.015168 Grad: 0.111734 Thermal: 0.000484 LR: 3.02e-06\n",
      "Epoch  35 [9250/10697 ( 86.5%)] Loss: 0.025226 L1: 0.014792 Grad: 0.104115 Thermal: 0.000448 LR: 3.02e-06\n",
      "Epoch  35 [9250/10697 ( 86.5%)] Loss: 0.025226 L1: 0.014792 Grad: 0.104115 Thermal: 0.000448 LR: 3.02e-06\n",
      "Epoch  35 [9300/10697 ( 86.9%)] Loss: 0.029246 L1: 0.017093 Grad: 0.121248 Thermal: 0.000564 LR: 3.02e-06\n",
      "Epoch  35 [9300/10697 ( 86.9%)] Loss: 0.029246 L1: 0.017093 Grad: 0.121248 Thermal: 0.000564 LR: 3.02e-06\n",
      "Epoch  35 [9350/10697 ( 87.4%)] Loss: 0.030050 L1: 0.017336 Grad: 0.126858 Thermal: 0.000564 LR: 3.02e-06\n",
      "Epoch  35 [9350/10697 ( 87.4%)] Loss: 0.030050 L1: 0.017336 Grad: 0.126858 Thermal: 0.000564 LR: 3.02e-06\n",
      "Epoch  35 [9400/10697 ( 87.9%)] Loss: 0.026325 L1: 0.015118 Grad: 0.111849 Thermal: 0.000449 LR: 3.02e-06\n",
      "Epoch  35 [9400/10697 ( 87.9%)] Loss: 0.026325 L1: 0.015118 Grad: 0.111849 Thermal: 0.000449 LR: 3.02e-06\n",
      "Epoch  35 [9450/10697 ( 88.3%)] Loss: 0.031486 L1: 0.018063 Grad: 0.133880 Thermal: 0.000703 LR: 3.02e-06\n",
      "Epoch  35 [9450/10697 ( 88.3%)] Loss: 0.031486 L1: 0.018063 Grad: 0.133880 Thermal: 0.000703 LR: 3.02e-06\n",
      "Epoch  35 [9500/10697 ( 88.8%)] Loss: 0.028437 L1: 0.016645 Grad: 0.117664 Thermal: 0.000517 LR: 3.02e-06\n",
      "Epoch  35 [9500/10697 ( 88.8%)] Loss: 0.028437 L1: 0.016645 Grad: 0.117664 Thermal: 0.000517 LR: 3.02e-06\n",
      "Epoch  35 [9550/10697 ( 89.3%)] Loss: 0.025110 L1: 0.014470 Grad: 0.106208 Thermal: 0.000381 LR: 3.02e-06\n",
      "Epoch  35 [9550/10697 ( 89.3%)] Loss: 0.025110 L1: 0.014470 Grad: 0.106208 Thermal: 0.000381 LR: 3.02e-06\n",
      "Epoch  35 [9600/10697 ( 89.7%)] Loss: 0.021290 L1: 0.012510 Grad: 0.087646 Thermal: 0.000310 LR: 3.02e-06\n",
      "Epoch  35 [9600/10697 ( 89.7%)] Loss: 0.021290 L1: 0.012510 Grad: 0.087646 Thermal: 0.000310 LR: 3.02e-06\n",
      "Epoch  35 [9650/10697 ( 90.2%)] Loss: 0.025569 L1: 0.014976 Grad: 0.105712 Thermal: 0.000429 LR: 3.02e-06\n",
      "Epoch  35 [9650/10697 ( 90.2%)] Loss: 0.025569 L1: 0.014976 Grad: 0.105712 Thermal: 0.000429 LR: 3.02e-06\n",
      "Epoch  35 [9700/10697 ( 90.7%)] Loss: 0.022484 L1: 0.013265 Grad: 0.092017 Thermal: 0.000345 LR: 3.02e-06\n",
      "Epoch  35 [9700/10697 ( 90.7%)] Loss: 0.022484 L1: 0.013265 Grad: 0.092017 Thermal: 0.000345 LR: 3.02e-06\n",
      "Epoch  35 [9750/10697 ( 91.1%)] Loss: 0.026835 L1: 0.015753 Grad: 0.110584 Thermal: 0.000482 LR: 3.02e-06\n",
      "Epoch  35 [9750/10697 ( 91.1%)] Loss: 0.026835 L1: 0.015753 Grad: 0.110584 Thermal: 0.000482 LR: 3.02e-06\n",
      "Epoch  35 [9800/10697 ( 91.6%)] Loss: 0.026073 L1: 0.015379 Grad: 0.106720 Thermal: 0.000445 LR: 3.02e-06\n",
      "Epoch  35 [9800/10697 ( 91.6%)] Loss: 0.026073 L1: 0.015379 Grad: 0.106720 Thermal: 0.000445 LR: 3.02e-06\n",
      "Epoch  35 [9850/10697 ( 92.1%)] Loss: 0.034772 L1: 0.020316 Grad: 0.144192 Thermal: 0.000739 LR: 3.02e-06\n",
      "Epoch  35 [9850/10697 ( 92.1%)] Loss: 0.034772 L1: 0.020316 Grad: 0.144192 Thermal: 0.000739 LR: 3.02e-06\n",
      "Epoch  35 [9900/10697 ( 92.5%)] Loss: 0.021534 L1: 0.012193 Grad: 0.093266 Thermal: 0.000290 LR: 3.02e-06\n",
      "Epoch  35 [9900/10697 ( 92.5%)] Loss: 0.021534 L1: 0.012193 Grad: 0.093266 Thermal: 0.000290 LR: 3.02e-06\n",
      "Epoch  35 [9950/10697 ( 93.0%)] Loss: 0.024445 L1: 0.014424 Grad: 0.100016 Thermal: 0.000382 LR: 3.02e-06\n",
      "Epoch  35 [9950/10697 ( 93.0%)] Loss: 0.024445 L1: 0.014424 Grad: 0.100016 Thermal: 0.000382 LR: 3.02e-06\n",
      "Epoch  35 [10000/10697 ( 93.5%)] Loss: 0.030231 L1: 0.017991 Grad: 0.122096 Thermal: 0.000604 LR: 3.02e-06\n",
      "Epoch  35 [10000/10697 ( 93.5%)] Loss: 0.030231 L1: 0.017991 Grad: 0.122096 Thermal: 0.000604 LR: 3.02e-06\n",
      "Epoch  35 [10050/10697 ( 94.0%)] Loss: 0.031628 L1: 0.018222 Grad: 0.133745 Thermal: 0.000632 LR: 3.02e-06\n",
      "Epoch  35 [10050/10697 ( 94.0%)] Loss: 0.031628 L1: 0.018222 Grad: 0.133745 Thermal: 0.000632 LR: 3.02e-06\n",
      "Epoch  35 [10100/10697 ( 94.4%)] Loss: 0.021260 L1: 0.012229 Grad: 0.090151 Thermal: 0.000312 LR: 3.02e-06\n",
      "Epoch  35 [10100/10697 ( 94.4%)] Loss: 0.021260 L1: 0.012229 Grad: 0.090151 Thermal: 0.000312 LR: 3.02e-06\n",
      "Epoch  35 [10150/10697 ( 94.9%)] Loss: 0.026746 L1: 0.015540 Grad: 0.111828 Thermal: 0.000465 LR: 3.02e-06\n",
      "Epoch  35 [10150/10697 ( 94.9%)] Loss: 0.026746 L1: 0.015540 Grad: 0.111828 Thermal: 0.000465 LR: 3.02e-06\n",
      "Epoch  35 [10200/10697 ( 95.4%)] Loss: 0.022031 L1: 0.013005 Grad: 0.090098 Thermal: 0.000313 LR: 3.02e-06\n",
      "Epoch  35 [10200/10697 ( 95.4%)] Loss: 0.022031 L1: 0.013005 Grad: 0.090098 Thermal: 0.000313 LR: 3.02e-06\n",
      "Epoch  35 [10250/10697 ( 95.8%)] Loss: 0.023121 L1: 0.013593 Grad: 0.095119 Thermal: 0.000338 LR: 3.02e-06\n",
      "Epoch  35 [10250/10697 ( 95.8%)] Loss: 0.023121 L1: 0.013593 Grad: 0.095119 Thermal: 0.000338 LR: 3.02e-06\n",
      "Epoch  35 [10300/10697 ( 96.3%)] Loss: 0.029781 L1: 0.017386 Grad: 0.123665 Thermal: 0.000565 LR: 3.02e-06\n",
      "Epoch  35 [10300/10697 ( 96.3%)] Loss: 0.029781 L1: 0.017386 Grad: 0.123665 Thermal: 0.000565 LR: 3.02e-06\n",
      "Epoch  35 [10350/10697 ( 96.8%)] Loss: 0.022502 L1: 0.012938 Grad: 0.095482 Thermal: 0.000317 LR: 3.02e-06\n",
      "Epoch  35 [10350/10697 ( 96.8%)] Loss: 0.022502 L1: 0.012938 Grad: 0.095482 Thermal: 0.000317 LR: 3.02e-06\n",
      "Epoch  35 [10400/10697 ( 97.2%)] Loss: 0.024725 L1: 0.014798 Grad: 0.099042 Thermal: 0.000464 LR: 3.02e-06\n",
      "Epoch  35 [10400/10697 ( 97.2%)] Loss: 0.024725 L1: 0.014798 Grad: 0.099042 Thermal: 0.000464 LR: 3.02e-06\n",
      "Epoch  35 [10450/10697 ( 97.7%)] Loss: 0.023296 L1: 0.013949 Grad: 0.093277 Thermal: 0.000377 LR: 3.02e-06\n",
      "Epoch  35 [10450/10697 ( 97.7%)] Loss: 0.023296 L1: 0.013949 Grad: 0.093277 Thermal: 0.000377 LR: 3.02e-06\n",
      "Epoch  35 [10500/10697 ( 98.2%)] Loss: 0.029745 L1: 0.016807 Grad: 0.129110 Thermal: 0.000531 LR: 3.02e-06\n",
      "Epoch  35 [10500/10697 ( 98.2%)] Loss: 0.029745 L1: 0.016807 Grad: 0.129110 Thermal: 0.000531 LR: 3.02e-06\n",
      "Epoch  35 [10550/10697 ( 98.6%)] Loss: 0.019329 L1: 0.011078 Grad: 0.082375 Thermal: 0.000269 LR: 3.02e-06\n",
      "Epoch  35 [10550/10697 ( 98.6%)] Loss: 0.019329 L1: 0.011078 Grad: 0.082375 Thermal: 0.000269 LR: 3.02e-06\n",
      "Epoch  35 [10600/10697 ( 99.1%)] Loss: 0.032461 L1: 0.018625 Grad: 0.138014 Thermal: 0.000679 LR: 3.02e-06\n",
      "Epoch  35 [10600/10697 ( 99.1%)] Loss: 0.032461 L1: 0.018625 Grad: 0.138014 Thermal: 0.000679 LR: 3.02e-06\n",
      "Epoch  35 [10650/10697 ( 99.6%)] Loss: 0.029928 L1: 0.017320 Grad: 0.125797 Thermal: 0.000566 LR: 3.02e-06\n",
      "Epoch  35 [10650/10697 ( 99.6%)] Loss: 0.029928 L1: 0.017320 Grad: 0.125797 Thermal: 0.000566 LR: 3.02e-06\n",
      "üí´ New best model saved! PSNR: 33.96\n",
      "Epoch  35 Summary: Loss=0.026280 (L1:0.0153, Grad:0.1093, Thermal:0.0005) Val_PSNR=33.96dB Best=33.96dB Time=135.9min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "üí´ New best model saved! PSNR: 33.96\n",
      "Epoch  35 Summary: Loss=0.026280 (L1:0.0153, Grad:0.1093, Thermal:0.0005) Val_PSNR=33.96dB Best=33.96dB Time=135.9min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  36 [   0/10697 (  0.0%)] Loss: 0.028685 L1: 0.016403 Grad: 0.122562 Thermal: 0.000516 LR: 2.93e-06\n",
      "Epoch  36 [   0/10697 (  0.0%)] Loss: 0.028685 L1: 0.016403 Grad: 0.122562 Thermal: 0.000516 LR: 2.93e-06\n",
      "Epoch  36 [  50/10697 (  0.5%)] Loss: 0.023726 L1: 0.014129 Grad: 0.095782 Thermal: 0.000374 LR: 2.93e-06\n",
      "Epoch  36 [  50/10697 (  0.5%)] Loss: 0.023726 L1: 0.014129 Grad: 0.095782 Thermal: 0.000374 LR: 2.93e-06\n",
      "Epoch  36 [ 100/10697 (  0.9%)] Loss: 0.024251 L1: 0.014174 Grad: 0.100579 Thermal: 0.000374 LR: 2.93e-06\n",
      "Epoch  36 [ 100/10697 (  0.9%)] Loss: 0.024251 L1: 0.014174 Grad: 0.100579 Thermal: 0.000374 LR: 2.93e-06\n",
      "Epoch  36 [ 150/10697 (  1.4%)] Loss: 0.032318 L1: 0.018356 Grad: 0.139238 Thermal: 0.000758 LR: 2.93e-06\n",
      "Epoch  36 [ 150/10697 (  1.4%)] Loss: 0.032318 L1: 0.018356 Grad: 0.139238 Thermal: 0.000758 LR: 2.93e-06\n",
      "Epoch  36 [ 200/10697 (  1.9%)] Loss: 0.029057 L1: 0.016827 Grad: 0.122031 Thermal: 0.000541 LR: 2.93e-06\n",
      "Epoch  36 [ 200/10697 (  1.9%)] Loss: 0.029057 L1: 0.016827 Grad: 0.122031 Thermal: 0.000541 LR: 2.93e-06\n",
      "Epoch  36 [ 250/10697 (  2.3%)] Loss: 0.021707 L1: 0.012597 Grad: 0.090930 Thermal: 0.000338 LR: 2.93e-06\n",
      "Epoch  36 [ 250/10697 (  2.3%)] Loss: 0.021707 L1: 0.012597 Grad: 0.090930 Thermal: 0.000338 LR: 2.93e-06\n",
      "Epoch  36 [ 300/10697 (  2.8%)] Loss: 0.026707 L1: 0.015743 Grad: 0.109407 Thermal: 0.000468 LR: 2.93e-06\n",
      "Epoch  36 [ 300/10697 (  2.8%)] Loss: 0.026707 L1: 0.015743 Grad: 0.109407 Thermal: 0.000468 LR: 2.93e-06\n",
      "Epoch  36 [ 350/10697 (  3.3%)] Loss: 0.036792 L1: 0.021777 Grad: 0.149639 Thermal: 0.001013 LR: 2.93e-06\n",
      "Epoch  36 [ 350/10697 (  3.3%)] Loss: 0.036792 L1: 0.021777 Grad: 0.149639 Thermal: 0.001013 LR: 2.93e-06\n",
      "Epoch  36 [ 400/10697 (  3.7%)] Loss: 0.023270 L1: 0.013370 Grad: 0.098821 Thermal: 0.000352 LR: 2.93e-06\n",
      "Epoch  36 [ 400/10697 (  3.7%)] Loss: 0.023270 L1: 0.013370 Grad: 0.098821 Thermal: 0.000352 LR: 2.93e-06\n",
      "Epoch  36 [ 450/10697 (  4.2%)] Loss: 0.027119 L1: 0.015927 Grad: 0.111684 Thermal: 0.000473 LR: 2.93e-06\n",
      "Epoch  36 [ 450/10697 (  4.2%)] Loss: 0.027119 L1: 0.015927 Grad: 0.111684 Thermal: 0.000473 LR: 2.93e-06\n",
      "Epoch  36 [ 500/10697 (  4.7%)] Loss: 0.024678 L1: 0.014514 Grad: 0.101433 Thermal: 0.000402 LR: 2.93e-06\n",
      "Epoch  36 [ 500/10697 (  4.7%)] Loss: 0.024678 L1: 0.014514 Grad: 0.101433 Thermal: 0.000402 LR: 2.93e-06\n",
      "Epoch  36 [ 550/10697 (  5.1%)] Loss: 0.021707 L1: 0.012591 Grad: 0.090981 Thermal: 0.000350 LR: 2.93e-06\n",
      "Epoch  36 [ 550/10697 (  5.1%)] Loss: 0.021707 L1: 0.012591 Grad: 0.090981 Thermal: 0.000350 LR: 2.93e-06\n",
      "Epoch  36 [ 600/10697 (  5.6%)] Loss: 0.028075 L1: 0.016207 Grad: 0.118429 Thermal: 0.000502 LR: 2.93e-06\n",
      "Epoch  36 [ 600/10697 (  5.6%)] Loss: 0.028075 L1: 0.016207 Grad: 0.118429 Thermal: 0.000502 LR: 2.93e-06\n",
      "Epoch  36 [ 650/10697 (  6.1%)] Loss: 0.026360 L1: 0.015964 Grad: 0.103734 Thermal: 0.000454 LR: 2.93e-06\n",
      "Epoch  36 [ 650/10697 (  6.1%)] Loss: 0.026360 L1: 0.015964 Grad: 0.103734 Thermal: 0.000454 LR: 2.93e-06\n",
      "Epoch  36 [ 700/10697 (  6.5%)] Loss: 0.024308 L1: 0.014533 Grad: 0.097561 Thermal: 0.000391 LR: 2.93e-06\n",
      "Epoch  36 [ 700/10697 (  6.5%)] Loss: 0.024308 L1: 0.014533 Grad: 0.097561 Thermal: 0.000391 LR: 2.93e-06\n",
      "Epoch  36 [ 750/10697 (  7.0%)] Loss: 0.028397 L1: 0.016128 Grad: 0.122429 Thermal: 0.000519 LR: 2.93e-06\n",
      "Epoch  36 [ 750/10697 (  7.0%)] Loss: 0.028397 L1: 0.016128 Grad: 0.122429 Thermal: 0.000519 LR: 2.93e-06\n",
      "Epoch  36 [ 800/10697 (  7.5%)] Loss: 0.025079 L1: 0.014798 Grad: 0.102565 Thermal: 0.000499 LR: 2.93e-06\n",
      "Epoch  36 [ 800/10697 (  7.5%)] Loss: 0.025079 L1: 0.014798 Grad: 0.102565 Thermal: 0.000499 LR: 2.93e-06\n",
      "Epoch  36 [ 850/10697 (  7.9%)] Loss: 0.026691 L1: 0.015929 Grad: 0.107394 Thermal: 0.000462 LR: 2.93e-06\n",
      "Epoch  36 [ 850/10697 (  7.9%)] Loss: 0.026691 L1: 0.015929 Grad: 0.107394 Thermal: 0.000462 LR: 2.93e-06\n",
      "Epoch  36 [ 900/10697 (  8.4%)] Loss: 0.028401 L1: 0.016657 Grad: 0.117171 Thermal: 0.000542 LR: 2.93e-06\n",
      "Epoch  36 [ 900/10697 (  8.4%)] Loss: 0.028401 L1: 0.016657 Grad: 0.117171 Thermal: 0.000542 LR: 2.93e-06\n",
      "Epoch  36 [ 950/10697 (  8.9%)] Loss: 0.026131 L1: 0.015046 Grad: 0.110654 Thermal: 0.000403 LR: 2.93e-06\n",
      "Epoch  36 [ 950/10697 (  8.9%)] Loss: 0.026131 L1: 0.015046 Grad: 0.110654 Thermal: 0.000403 LR: 2.93e-06\n",
      "Epoch  36 [1000/10697 (  9.3%)] Loss: 0.019548 L1: 0.011431 Grad: 0.081035 Thermal: 0.000265 LR: 2.93e-06\n",
      "Epoch  36 [1000/10697 (  9.3%)] Loss: 0.019548 L1: 0.011431 Grad: 0.081035 Thermal: 0.000265 LR: 2.93e-06\n",
      "Epoch  36 [1050/10697 (  9.8%)] Loss: 0.022805 L1: 0.013615 Grad: 0.091726 Thermal: 0.000362 LR: 2.93e-06\n",
      "Epoch  36 [1050/10697 (  9.8%)] Loss: 0.022805 L1: 0.013615 Grad: 0.091726 Thermal: 0.000362 LR: 2.93e-06\n",
      "Epoch  36 [1100/10697 ( 10.3%)] Loss: 0.028616 L1: 0.016524 Grad: 0.120648 Thermal: 0.000543 LR: 2.93e-06\n",
      "Epoch  36 [1100/10697 ( 10.3%)] Loss: 0.028616 L1: 0.016524 Grad: 0.120648 Thermal: 0.000543 LR: 2.93e-06\n",
      "Epoch  36 [1150/10697 ( 10.8%)] Loss: 0.020059 L1: 0.011770 Grad: 0.082741 Thermal: 0.000290 LR: 2.93e-06\n",
      "Epoch  36 [1150/10697 ( 10.8%)] Loss: 0.020059 L1: 0.011770 Grad: 0.082741 Thermal: 0.000290 LR: 2.93e-06\n",
      "Epoch  36 [1200/10697 ( 11.2%)] Loss: 0.023186 L1: 0.013098 Grad: 0.100711 Thermal: 0.000338 LR: 2.93e-06\n",
      "Epoch  36 [1200/10697 ( 11.2%)] Loss: 0.023186 L1: 0.013098 Grad: 0.100711 Thermal: 0.000338 LR: 2.93e-06\n",
      "Epoch  36 [1250/10697 ( 11.7%)] Loss: 0.029141 L1: 0.017108 Grad: 0.120043 Thermal: 0.000572 LR: 2.93e-06\n",
      "Epoch  36 [1250/10697 ( 11.7%)] Loss: 0.029141 L1: 0.017108 Grad: 0.120043 Thermal: 0.000572 LR: 2.93e-06\n",
      "Epoch  36 [1300/10697 ( 12.2%)] Loss: 0.024155 L1: 0.014025 Grad: 0.101121 Thermal: 0.000371 LR: 2.93e-06\n",
      "Epoch  36 [1300/10697 ( 12.2%)] Loss: 0.024155 L1: 0.014025 Grad: 0.101121 Thermal: 0.000371 LR: 2.93e-06\n",
      "Epoch  36 [1350/10697 ( 12.6%)] Loss: 0.031507 L1: 0.018200 Grad: 0.132773 Thermal: 0.000604 LR: 2.93e-06\n",
      "Epoch  36 [1350/10697 ( 12.6%)] Loss: 0.031507 L1: 0.018200 Grad: 0.132773 Thermal: 0.000604 LR: 2.93e-06\n",
      "Epoch  36 [1400/10697 ( 13.1%)] Loss: 0.027592 L1: 0.016048 Grad: 0.115196 Thermal: 0.000490 LR: 2.93e-06\n",
      "Epoch  36 [1400/10697 ( 13.1%)] Loss: 0.027592 L1: 0.016048 Grad: 0.115196 Thermal: 0.000490 LR: 2.93e-06\n",
      "Epoch  36 [1450/10697 ( 13.6%)] Loss: 0.029778 L1: 0.017321 Grad: 0.124279 Thermal: 0.000579 LR: 2.93e-06\n",
      "Epoch  36 [1450/10697 ( 13.6%)] Loss: 0.029778 L1: 0.017321 Grad: 0.124279 Thermal: 0.000579 LR: 2.93e-06\n",
      "Epoch  36 [1500/10697 ( 14.0%)] Loss: 0.028444 L1: 0.016529 Grad: 0.118914 Thermal: 0.000486 LR: 2.93e-06\n",
      "Epoch  36 [1500/10697 ( 14.0%)] Loss: 0.028444 L1: 0.016529 Grad: 0.118914 Thermal: 0.000486 LR: 2.93e-06\n",
      "Epoch  36 [1550/10697 ( 14.5%)] Loss: 0.027489 L1: 0.015789 Grad: 0.116758 Thermal: 0.000478 LR: 2.93e-06\n",
      "Epoch  36 [1550/10697 ( 14.5%)] Loss: 0.027489 L1: 0.015789 Grad: 0.116758 Thermal: 0.000478 LR: 2.93e-06\n",
      "Epoch  36 [1600/10697 ( 15.0%)] Loss: 0.019993 L1: 0.011621 Grad: 0.083582 Thermal: 0.000268 LR: 2.93e-06\n",
      "Epoch  36 [1600/10697 ( 15.0%)] Loss: 0.019993 L1: 0.011621 Grad: 0.083582 Thermal: 0.000268 LR: 2.93e-06\n",
      "Epoch  36 [1650/10697 ( 15.4%)] Loss: 0.025541 L1: 0.015149 Grad: 0.103698 Thermal: 0.000439 LR: 2.93e-06\n",
      "Epoch  36 [1650/10697 ( 15.4%)] Loss: 0.025541 L1: 0.015149 Grad: 0.103698 Thermal: 0.000439 LR: 2.93e-06\n",
      "Epoch  36 [1700/10697 ( 15.9%)] Loss: 0.025785 L1: 0.014949 Grad: 0.108147 Thermal: 0.000422 LR: 2.93e-06\n",
      "Epoch  36 [1700/10697 ( 15.9%)] Loss: 0.025785 L1: 0.014949 Grad: 0.108147 Thermal: 0.000422 LR: 2.93e-06\n",
      "Epoch  36 [1750/10697 ( 16.4%)] Loss: 0.024160 L1: 0.014284 Grad: 0.098568 Thermal: 0.000388 LR: 2.93e-06\n",
      "Epoch  36 [1750/10697 ( 16.4%)] Loss: 0.024160 L1: 0.014284 Grad: 0.098568 Thermal: 0.000388 LR: 2.93e-06\n",
      "Epoch  36 [1800/10697 ( 16.8%)] Loss: 0.025121 L1: 0.014758 Grad: 0.103423 Thermal: 0.000414 LR: 2.93e-06\n",
      "Epoch  36 [1800/10697 ( 16.8%)] Loss: 0.025121 L1: 0.014758 Grad: 0.103423 Thermal: 0.000414 LR: 2.93e-06\n",
      "Epoch  36 [1850/10697 ( 17.3%)] Loss: 0.030824 L1: 0.017392 Grad: 0.134042 Thermal: 0.000568 LR: 2.93e-06\n",
      "Epoch  36 [1850/10697 ( 17.3%)] Loss: 0.030824 L1: 0.017392 Grad: 0.134042 Thermal: 0.000568 LR: 2.93e-06\n",
      "Epoch  36 [1900/10697 ( 17.8%)] Loss: 0.032083 L1: 0.018465 Grad: 0.135835 Thermal: 0.000691 LR: 2.93e-06\n",
      "Epoch  36 [1900/10697 ( 17.8%)] Loss: 0.032083 L1: 0.018465 Grad: 0.135835 Thermal: 0.000691 LR: 2.93e-06\n",
      "Epoch  36 [1950/10697 ( 18.2%)] Loss: 0.023720 L1: 0.013497 Grad: 0.102022 Thermal: 0.000416 LR: 2.93e-06\n",
      "Epoch  36 [1950/10697 ( 18.2%)] Loss: 0.023720 L1: 0.013497 Grad: 0.102022 Thermal: 0.000416 LR: 2.93e-06\n",
      "Epoch  36 [2000/10697 ( 18.7%)] Loss: 0.024451 L1: 0.014412 Grad: 0.100195 Thermal: 0.000384 LR: 2.93e-06\n",
      "Epoch  36 [2000/10697 ( 18.7%)] Loss: 0.024451 L1: 0.014412 Grad: 0.100195 Thermal: 0.000384 LR: 2.93e-06\n",
      "Epoch  36 [2050/10697 ( 19.2%)] Loss: 0.029655 L1: 0.017477 Grad: 0.121515 Thermal: 0.000546 LR: 2.93e-06\n",
      "Epoch  36 [2050/10697 ( 19.2%)] Loss: 0.029655 L1: 0.017477 Grad: 0.121515 Thermal: 0.000546 LR: 2.93e-06\n",
      "Epoch  36 [2100/10697 ( 19.6%)] Loss: 0.030843 L1: 0.017748 Grad: 0.130677 Thermal: 0.000546 LR: 2.93e-06\n",
      "Epoch  36 [2100/10697 ( 19.6%)] Loss: 0.030843 L1: 0.017748 Grad: 0.130677 Thermal: 0.000546 LR: 2.93e-06\n",
      "Epoch  36 [2150/10697 ( 20.1%)] Loss: 0.026755 L1: 0.015654 Grad: 0.110745 Thermal: 0.000532 LR: 2.93e-06\n",
      "Epoch  36 [2150/10697 ( 20.1%)] Loss: 0.026755 L1: 0.015654 Grad: 0.110745 Thermal: 0.000532 LR: 2.93e-06\n",
      "Epoch  36 [2200/10697 ( 20.6%)] Loss: 0.031617 L1: 0.017972 Grad: 0.136128 Thermal: 0.000653 LR: 2.93e-06\n",
      "Epoch  36 [2200/10697 ( 20.6%)] Loss: 0.031617 L1: 0.017972 Grad: 0.136128 Thermal: 0.000653 LR: 2.93e-06\n",
      "Epoch  36 [2250/10697 ( 21.0%)] Loss: 0.026924 L1: 0.015590 Grad: 0.113096 Thermal: 0.000498 LR: 2.93e-06\n",
      "Epoch  36 [2250/10697 ( 21.0%)] Loss: 0.026924 L1: 0.015590 Grad: 0.113096 Thermal: 0.000498 LR: 2.93e-06\n",
      "Epoch  36 [2300/10697 ( 21.5%)] Loss: 0.022047 L1: 0.013160 Grad: 0.088703 Thermal: 0.000345 LR: 2.93e-06\n",
      "Epoch  36 [2300/10697 ( 21.5%)] Loss: 0.022047 L1: 0.013160 Grad: 0.088703 Thermal: 0.000345 LR: 2.93e-06\n",
      "Epoch  36 [2350/10697 ( 22.0%)] Loss: 0.025870 L1: 0.014873 Grad: 0.109750 Thermal: 0.000447 LR: 2.93e-06\n",
      "Epoch  36 [2350/10697 ( 22.0%)] Loss: 0.025870 L1: 0.014873 Grad: 0.109750 Thermal: 0.000447 LR: 2.93e-06\n",
      "Epoch  36 [2400/10697 ( 22.4%)] Loss: 0.028758 L1: 0.016724 Grad: 0.120071 Thermal: 0.000537 LR: 2.93e-06\n",
      "Epoch  36 [2400/10697 ( 22.4%)] Loss: 0.028758 L1: 0.016724 Grad: 0.120071 Thermal: 0.000537 LR: 2.93e-06\n",
      "Epoch  36 [2450/10697 ( 22.9%)] Loss: 0.023179 L1: 0.013295 Grad: 0.098666 Thermal: 0.000336 LR: 2.93e-06\n",
      "Epoch  36 [2450/10697 ( 22.9%)] Loss: 0.023179 L1: 0.013295 Grad: 0.098666 Thermal: 0.000336 LR: 2.93e-06\n",
      "Epoch  36 [2500/10697 ( 23.4%)] Loss: 0.027171 L1: 0.016084 Grad: 0.110630 Thermal: 0.000488 LR: 2.93e-06\n",
      "Epoch  36 [2500/10697 ( 23.4%)] Loss: 0.027171 L1: 0.016084 Grad: 0.110630 Thermal: 0.000488 LR: 2.93e-06\n",
      "Epoch  36 [2550/10697 ( 23.8%)] Loss: 0.020987 L1: 0.011645 Grad: 0.093260 Thermal: 0.000319 LR: 2.93e-06\n",
      "Epoch  36 [2550/10697 ( 23.8%)] Loss: 0.020987 L1: 0.011645 Grad: 0.093260 Thermal: 0.000319 LR: 2.93e-06\n",
      "Epoch  36 [2600/10697 ( 24.3%)] Loss: 0.025100 L1: 0.014829 Grad: 0.102499 Thermal: 0.000427 LR: 2.93e-06\n",
      "Epoch  36 [2600/10697 ( 24.3%)] Loss: 0.025100 L1: 0.014829 Grad: 0.102499 Thermal: 0.000427 LR: 2.93e-06\n",
      "Epoch  36 [2650/10697 ( 24.8%)] Loss: 0.031493 L1: 0.018083 Grad: 0.133807 Thermal: 0.000584 LR: 2.93e-06\n",
      "Epoch  36 [2650/10697 ( 24.8%)] Loss: 0.031493 L1: 0.018083 Grad: 0.133807 Thermal: 0.000584 LR: 2.93e-06\n",
      "Epoch  36 [2700/10697 ( 25.2%)] Loss: 0.024095 L1: 0.014262 Grad: 0.098135 Thermal: 0.000391 LR: 2.93e-06\n",
      "Epoch  36 [2700/10697 ( 25.2%)] Loss: 0.024095 L1: 0.014262 Grad: 0.098135 Thermal: 0.000391 LR: 2.93e-06\n",
      "Epoch  36 [2750/10697 ( 25.7%)] Loss: 0.027579 L1: 0.016312 Grad: 0.112436 Thermal: 0.000461 LR: 2.93e-06\n",
      "Epoch  36 [2750/10697 ( 25.7%)] Loss: 0.027579 L1: 0.016312 Grad: 0.112436 Thermal: 0.000461 LR: 2.93e-06\n",
      "Epoch  36 [2800/10697 ( 26.2%)] Loss: 0.026938 L1: 0.015760 Grad: 0.111544 Thermal: 0.000477 LR: 2.93e-06\n",
      "Epoch  36 [2800/10697 ( 26.2%)] Loss: 0.026938 L1: 0.015760 Grad: 0.111544 Thermal: 0.000477 LR: 2.93e-06\n",
      "Epoch  36 [2850/10697 ( 26.6%)] Loss: 0.025202 L1: 0.014972 Grad: 0.102092 Thermal: 0.000407 LR: 2.93e-06\n",
      "Epoch  36 [2850/10697 ( 26.6%)] Loss: 0.025202 L1: 0.014972 Grad: 0.102092 Thermal: 0.000407 LR: 2.93e-06\n",
      "Epoch  36 [2900/10697 ( 27.1%)] Loss: 0.028524 L1: 0.016405 Grad: 0.120944 Thermal: 0.000490 LR: 2.93e-06\n",
      "Epoch  36 [2900/10697 ( 27.1%)] Loss: 0.028524 L1: 0.016405 Grad: 0.120944 Thermal: 0.000490 LR: 2.93e-06\n",
      "Epoch  36 [2950/10697 ( 27.6%)] Loss: 0.028039 L1: 0.016174 Grad: 0.118430 Thermal: 0.000439 LR: 2.93e-06\n",
      "Epoch  36 [2950/10697 ( 27.6%)] Loss: 0.028039 L1: 0.016174 Grad: 0.118430 Thermal: 0.000439 LR: 2.93e-06\n",
      "Epoch  36 [3000/10697 ( 28.0%)] Loss: 0.025248 L1: 0.014425 Grad: 0.108011 Thermal: 0.000437 LR: 2.93e-06\n",
      "Epoch  36 [3000/10697 ( 28.0%)] Loss: 0.025248 L1: 0.014425 Grad: 0.108011 Thermal: 0.000437 LR: 2.93e-06\n",
      "Epoch  36 [3050/10697 ( 28.5%)] Loss: 0.024718 L1: 0.014081 Grad: 0.106171 Thermal: 0.000398 LR: 2.93e-06\n",
      "Epoch  36 [3050/10697 ( 28.5%)] Loss: 0.024718 L1: 0.014081 Grad: 0.106171 Thermal: 0.000398 LR: 2.93e-06\n",
      "Epoch  36 [3100/10697 ( 29.0%)] Loss: 0.024824 L1: 0.014572 Grad: 0.102327 Thermal: 0.000387 LR: 2.93e-06\n",
      "Epoch  36 [3100/10697 ( 29.0%)] Loss: 0.024824 L1: 0.014572 Grad: 0.102327 Thermal: 0.000387 LR: 2.93e-06\n",
      "Epoch  36 [3150/10697 ( 29.4%)] Loss: 0.029716 L1: 0.017829 Grad: 0.118583 Thermal: 0.000565 LR: 2.93e-06\n",
      "Epoch  36 [3150/10697 ( 29.4%)] Loss: 0.029716 L1: 0.017829 Grad: 0.118583 Thermal: 0.000565 LR: 2.93e-06\n",
      "Epoch  36 [3200/10697 ( 29.9%)] Loss: 0.020807 L1: 0.012156 Grad: 0.086362 Thermal: 0.000304 LR: 2.93e-06\n",
      "Epoch  36 [3200/10697 ( 29.9%)] Loss: 0.020807 L1: 0.012156 Grad: 0.086362 Thermal: 0.000304 LR: 2.93e-06\n",
      "Epoch  36 [3250/10697 ( 30.4%)] Loss: 0.023776 L1: 0.014054 Grad: 0.096999 Thermal: 0.000432 LR: 2.93e-06\n",
      "Epoch  36 [3250/10697 ( 30.4%)] Loss: 0.023776 L1: 0.014054 Grad: 0.096999 Thermal: 0.000432 LR: 2.93e-06\n",
      "Epoch  36 [3300/10697 ( 30.8%)] Loss: 0.024822 L1: 0.014335 Grad: 0.104673 Thermal: 0.000397 LR: 2.93e-06\n",
      "Epoch  36 [3300/10697 ( 30.8%)] Loss: 0.024822 L1: 0.014335 Grad: 0.104673 Thermal: 0.000397 LR: 2.93e-06\n",
      "Epoch  36 [3350/10697 ( 31.3%)] Loss: 0.027799 L1: 0.016210 Grad: 0.115667 Thermal: 0.000460 LR: 2.93e-06\n",
      "Epoch  36 [3350/10697 ( 31.3%)] Loss: 0.027799 L1: 0.016210 Grad: 0.115667 Thermal: 0.000460 LR: 2.93e-06\n",
      "Epoch  36 [3400/10697 ( 31.8%)] Loss: 0.023208 L1: 0.013259 Grad: 0.099331 Thermal: 0.000311 LR: 2.93e-06\n",
      "Epoch  36 [3400/10697 ( 31.8%)] Loss: 0.023208 L1: 0.013259 Grad: 0.099331 Thermal: 0.000311 LR: 2.93e-06\n",
      "Epoch  36 [3450/10697 ( 32.3%)] Loss: 0.021394 L1: 0.012314 Grad: 0.090641 Thermal: 0.000312 LR: 2.93e-06\n",
      "Epoch  36 [3450/10697 ( 32.3%)] Loss: 0.021394 L1: 0.012314 Grad: 0.090641 Thermal: 0.000312 LR: 2.93e-06\n",
      "Epoch  36 [3500/10697 ( 32.7%)] Loss: 0.022097 L1: 0.012856 Grad: 0.092249 Thermal: 0.000326 LR: 2.93e-06\n",
      "Epoch  36 [3500/10697 ( 32.7%)] Loss: 0.022097 L1: 0.012856 Grad: 0.092249 Thermal: 0.000326 LR: 2.93e-06\n",
      "Epoch  36 [3550/10697 ( 33.2%)] Loss: 0.027669 L1: 0.016244 Grad: 0.114021 Thermal: 0.000456 LR: 2.93e-06\n",
      "Epoch  36 [3550/10697 ( 33.2%)] Loss: 0.027669 L1: 0.016244 Grad: 0.114021 Thermal: 0.000456 LR: 2.93e-06\n",
      "Epoch  36 [3600/10697 ( 33.7%)] Loss: 0.024518 L1: 0.014266 Grad: 0.102328 Thermal: 0.000377 LR: 2.93e-06\n",
      "Epoch  36 [3600/10697 ( 33.7%)] Loss: 0.024518 L1: 0.014266 Grad: 0.102328 Thermal: 0.000377 LR: 2.93e-06\n",
      "Epoch  36 [3650/10697 ( 34.1%)] Loss: 0.023852 L1: 0.014064 Grad: 0.097643 Thermal: 0.000460 LR: 2.93e-06\n",
      "Epoch  36 [3650/10697 ( 34.1%)] Loss: 0.023852 L1: 0.014064 Grad: 0.097643 Thermal: 0.000460 LR: 2.93e-06\n",
      "Epoch  36 [3700/10697 ( 34.6%)] Loss: 0.031393 L1: 0.018187 Grad: 0.131756 Thermal: 0.000620 LR: 2.93e-06\n",
      "Epoch  36 [3700/10697 ( 34.6%)] Loss: 0.031393 L1: 0.018187 Grad: 0.131756 Thermal: 0.000620 LR: 2.93e-06\n",
      "Epoch  36 [3750/10697 ( 35.1%)] Loss: 0.025766 L1: 0.015378 Grad: 0.103666 Thermal: 0.000426 LR: 2.93e-06\n",
      "Epoch  36 [3750/10697 ( 35.1%)] Loss: 0.025766 L1: 0.015378 Grad: 0.103666 Thermal: 0.000426 LR: 2.93e-06\n",
      "Epoch  36 [3800/10697 ( 35.5%)] Loss: 0.029197 L1: 0.017104 Grad: 0.120679 Thermal: 0.000499 LR: 2.93e-06\n",
      "Epoch  36 [3800/10697 ( 35.5%)] Loss: 0.029197 L1: 0.017104 Grad: 0.120679 Thermal: 0.000499 LR: 2.93e-06\n",
      "Epoch  36 [3850/10697 ( 36.0%)] Loss: 0.024208 L1: 0.014066 Grad: 0.101210 Thermal: 0.000431 LR: 2.93e-06\n",
      "Epoch  36 [3850/10697 ( 36.0%)] Loss: 0.024208 L1: 0.014066 Grad: 0.101210 Thermal: 0.000431 LR: 2.93e-06\n",
      "Epoch  36 [3900/10697 ( 36.5%)] Loss: 0.028434 L1: 0.016084 Grad: 0.123265 Thermal: 0.000484 LR: 2.93e-06\n",
      "Epoch  36 [3900/10697 ( 36.5%)] Loss: 0.028434 L1: 0.016084 Grad: 0.123265 Thermal: 0.000484 LR: 2.93e-06\n",
      "Epoch  36 [3950/10697 ( 36.9%)] Loss: 0.020478 L1: 0.012031 Grad: 0.084275 Thermal: 0.000404 LR: 2.93e-06\n",
      "Epoch  36 [3950/10697 ( 36.9%)] Loss: 0.020478 L1: 0.012031 Grad: 0.084275 Thermal: 0.000404 LR: 2.93e-06\n",
      "Epoch  36 [4000/10697 ( 37.4%)] Loss: 0.027413 L1: 0.016171 Grad: 0.112186 Thermal: 0.000472 LR: 2.93e-06\n",
      "Epoch  36 [4000/10697 ( 37.4%)] Loss: 0.027413 L1: 0.016171 Grad: 0.112186 Thermal: 0.000472 LR: 2.93e-06\n",
      "Epoch  36 [4050/10697 ( 37.9%)] Loss: 0.027783 L1: 0.016458 Grad: 0.113006 Thermal: 0.000475 LR: 2.93e-06\n",
      "Epoch  36 [4050/10697 ( 37.9%)] Loss: 0.027783 L1: 0.016458 Grad: 0.113006 Thermal: 0.000475 LR: 2.93e-06\n",
      "Epoch  36 [4100/10697 ( 38.3%)] Loss: 0.024664 L1: 0.014719 Grad: 0.099249 Thermal: 0.000405 LR: 2.93e-06\n",
      "Epoch  36 [4100/10697 ( 38.3%)] Loss: 0.024664 L1: 0.014719 Grad: 0.099249 Thermal: 0.000405 LR: 2.93e-06\n",
      "Epoch  36 [4150/10697 ( 38.8%)] Loss: 0.026065 L1: 0.015422 Grad: 0.106202 Thermal: 0.000452 LR: 2.93e-06\n",
      "Epoch  36 [4150/10697 ( 38.8%)] Loss: 0.026065 L1: 0.015422 Grad: 0.106202 Thermal: 0.000452 LR: 2.93e-06\n",
      "Epoch  36 [4200/10697 ( 39.3%)] Loss: 0.025997 L1: 0.015400 Grad: 0.105754 Thermal: 0.000425 LR: 2.93e-06\n",
      "Epoch  36 [4200/10697 ( 39.3%)] Loss: 0.025997 L1: 0.015400 Grad: 0.105754 Thermal: 0.000425 LR: 2.93e-06\n",
      "Epoch  36 [4250/10697 ( 39.7%)] Loss: 0.023856 L1: 0.013956 Grad: 0.098814 Thermal: 0.000369 LR: 2.93e-06\n",
      "Epoch  36 [4250/10697 ( 39.7%)] Loss: 0.023856 L1: 0.013956 Grad: 0.098814 Thermal: 0.000369 LR: 2.93e-06\n",
      "Epoch  36 [4300/10697 ( 40.2%)] Loss: 0.029877 L1: 0.017065 Grad: 0.127848 Thermal: 0.000549 LR: 2.93e-06\n",
      "Epoch  36 [4300/10697 ( 40.2%)] Loss: 0.029877 L1: 0.017065 Grad: 0.127848 Thermal: 0.000549 LR: 2.93e-06\n",
      "Epoch  36 [4350/10697 ( 40.7%)] Loss: 0.031745 L1: 0.018354 Grad: 0.133587 Thermal: 0.000639 LR: 2.93e-06\n",
      "Epoch  36 [4350/10697 ( 40.7%)] Loss: 0.031745 L1: 0.018354 Grad: 0.133587 Thermal: 0.000639 LR: 2.93e-06\n",
      "Epoch  36 [4400/10697 ( 41.1%)] Loss: 0.027663 L1: 0.016159 Grad: 0.114787 Thermal: 0.000515 LR: 2.93e-06\n",
      "Epoch  36 [4400/10697 ( 41.1%)] Loss: 0.027663 L1: 0.016159 Grad: 0.114787 Thermal: 0.000515 LR: 2.93e-06\n",
      "Epoch  36 [4450/10697 ( 41.6%)] Loss: 0.025137 L1: 0.014538 Grad: 0.105782 Thermal: 0.000412 LR: 2.93e-06\n",
      "Epoch  36 [4450/10697 ( 41.6%)] Loss: 0.025137 L1: 0.014538 Grad: 0.105782 Thermal: 0.000412 LR: 2.93e-06\n",
      "Epoch  36 [4500/10697 ( 42.1%)] Loss: 0.023919 L1: 0.013378 Grad: 0.105219 Thermal: 0.000385 LR: 2.93e-06\n",
      "Epoch  36 [4500/10697 ( 42.1%)] Loss: 0.023919 L1: 0.013378 Grad: 0.105219 Thermal: 0.000385 LR: 2.93e-06\n",
      "Epoch  36 [4550/10697 ( 42.5%)] Loss: 0.019974 L1: 0.011561 Grad: 0.084000 Thermal: 0.000267 LR: 2.93e-06\n",
      "Epoch  36 [4550/10697 ( 42.5%)] Loss: 0.019974 L1: 0.011561 Grad: 0.084000 Thermal: 0.000267 LR: 2.93e-06\n",
      "Epoch  36 [4600/10697 ( 43.0%)] Loss: 0.027679 L1: 0.016164 Grad: 0.114896 Thermal: 0.000508 LR: 2.93e-06\n",
      "Epoch  36 [4600/10697 ( 43.0%)] Loss: 0.027679 L1: 0.016164 Grad: 0.114896 Thermal: 0.000508 LR: 2.93e-06\n",
      "Epoch  36 [4650/10697 ( 43.5%)] Loss: 0.026604 L1: 0.015665 Grad: 0.109172 Thermal: 0.000447 LR: 2.93e-06\n",
      "Epoch  36 [4650/10697 ( 43.5%)] Loss: 0.026604 L1: 0.015665 Grad: 0.109172 Thermal: 0.000447 LR: 2.93e-06\n",
      "Epoch  36 [4700/10697 ( 43.9%)] Loss: 0.027300 L1: 0.016038 Grad: 0.112390 Thermal: 0.000449 LR: 2.93e-06\n",
      "Epoch  36 [4700/10697 ( 43.9%)] Loss: 0.027300 L1: 0.016038 Grad: 0.112390 Thermal: 0.000449 LR: 2.93e-06\n",
      "Epoch  36 [4750/10697 ( 44.4%)] Loss: 0.030360 L1: 0.017863 Grad: 0.124691 Thermal: 0.000568 LR: 2.93e-06\n",
      "Epoch  36 [4750/10697 ( 44.4%)] Loss: 0.030360 L1: 0.017863 Grad: 0.124691 Thermal: 0.000568 LR: 2.93e-06\n",
      "Epoch  36 [4800/10697 ( 44.9%)] Loss: 0.026009 L1: 0.015012 Grad: 0.109763 Thermal: 0.000421 LR: 2.93e-06\n",
      "Epoch  36 [4800/10697 ( 44.9%)] Loss: 0.026009 L1: 0.015012 Grad: 0.109763 Thermal: 0.000421 LR: 2.93e-06\n",
      "Epoch  36 [4850/10697 ( 45.3%)] Loss: 0.021291 L1: 0.012324 Grad: 0.089529 Thermal: 0.000298 LR: 2.93e-06\n",
      "Epoch  36 [4850/10697 ( 45.3%)] Loss: 0.021291 L1: 0.012324 Grad: 0.089529 Thermal: 0.000298 LR: 2.93e-06\n",
      "Epoch  36 [4900/10697 ( 45.8%)] Loss: 0.024056 L1: 0.014129 Grad: 0.099076 Thermal: 0.000389 LR: 2.93e-06\n",
      "Epoch  36 [4900/10697 ( 45.8%)] Loss: 0.024056 L1: 0.014129 Grad: 0.099076 Thermal: 0.000389 LR: 2.93e-06\n",
      "Epoch  36 [4950/10697 ( 46.3%)] Loss: 0.021821 L1: 0.012666 Grad: 0.091406 Thermal: 0.000292 LR: 2.93e-06\n",
      "Epoch  36 [4950/10697 ( 46.3%)] Loss: 0.021821 L1: 0.012666 Grad: 0.091406 Thermal: 0.000292 LR: 2.93e-06\n",
      "Epoch  36 [5000/10697 ( 46.7%)] Loss: 0.034269 L1: 0.020013 Grad: 0.142199 Thermal: 0.000717 LR: 2.93e-06\n",
      "Epoch  36 [5000/10697 ( 46.7%)] Loss: 0.034269 L1: 0.020013 Grad: 0.142199 Thermal: 0.000717 LR: 2.93e-06\n",
      "Epoch  36 [5050/10697 ( 47.2%)] Loss: 0.027819 L1: 0.016627 Grad: 0.111650 Thermal: 0.000539 LR: 2.93e-06\n",
      "Epoch  36 [5050/10697 ( 47.2%)] Loss: 0.027819 L1: 0.016627 Grad: 0.111650 Thermal: 0.000539 LR: 2.93e-06\n",
      "Epoch  36 [5100/10697 ( 47.7%)] Loss: 0.029273 L1: 0.017074 Grad: 0.121714 Thermal: 0.000539 LR: 2.93e-06\n",
      "Epoch  36 [5100/10697 ( 47.7%)] Loss: 0.029273 L1: 0.017074 Grad: 0.121714 Thermal: 0.000539 LR: 2.93e-06\n",
      "Epoch  36 [5150/10697 ( 48.1%)] Loss: 0.023010 L1: 0.013400 Grad: 0.095905 Thermal: 0.000386 LR: 2.93e-06\n",
      "Epoch  36 [5150/10697 ( 48.1%)] Loss: 0.023010 L1: 0.013400 Grad: 0.095905 Thermal: 0.000386 LR: 2.93e-06\n",
      "Epoch  36 [5200/10697 ( 48.6%)] Loss: 0.026727 L1: 0.015781 Grad: 0.109218 Thermal: 0.000488 LR: 2.93e-06\n",
      "Epoch  36 [5200/10697 ( 48.6%)] Loss: 0.026727 L1: 0.015781 Grad: 0.109218 Thermal: 0.000488 LR: 2.93e-06\n",
      "Epoch  36 [5250/10697 ( 49.1%)] Loss: 0.026543 L1: 0.015851 Grad: 0.106699 Thermal: 0.000444 LR: 2.93e-06\n",
      "Epoch  36 [5250/10697 ( 49.1%)] Loss: 0.026543 L1: 0.015851 Grad: 0.106699 Thermal: 0.000444 LR: 2.93e-06\n",
      "Epoch  36 [5300/10697 ( 49.5%)] Loss: 0.023971 L1: 0.013795 Grad: 0.101574 Thermal: 0.000372 LR: 2.93e-06\n",
      "Epoch  36 [5300/10697 ( 49.5%)] Loss: 0.023971 L1: 0.013795 Grad: 0.101574 Thermal: 0.000372 LR: 2.93e-06\n",
      "Epoch  36 [5350/10697 ( 50.0%)] Loss: 0.026432 L1: 0.015907 Grad: 0.105019 Thermal: 0.000458 LR: 2.93e-06\n",
      "Epoch  36 [5350/10697 ( 50.0%)] Loss: 0.026432 L1: 0.015907 Grad: 0.105019 Thermal: 0.000458 LR: 2.93e-06\n",
      "Epoch  36 [5400/10697 ( 50.5%)] Loss: 0.024663 L1: 0.014689 Grad: 0.099529 Thermal: 0.000418 LR: 2.93e-06\n",
      "Epoch  36 [5400/10697 ( 50.5%)] Loss: 0.024663 L1: 0.014689 Grad: 0.099529 Thermal: 0.000418 LR: 2.93e-06\n",
      "Epoch  36 [5450/10697 ( 50.9%)] Loss: 0.019066 L1: 0.010978 Grad: 0.080741 Thermal: 0.000277 LR: 2.93e-06\n",
      "Epoch  36 [5450/10697 ( 50.9%)] Loss: 0.019066 L1: 0.010978 Grad: 0.080741 Thermal: 0.000277 LR: 2.93e-06\n",
      "Epoch  36 [5500/10697 ( 51.4%)] Loss: 0.022838 L1: 0.013259 Grad: 0.095610 Thermal: 0.000365 LR: 2.93e-06\n",
      "Epoch  36 [5500/10697 ( 51.4%)] Loss: 0.022838 L1: 0.013259 Grad: 0.095610 Thermal: 0.000365 LR: 2.93e-06\n",
      "Epoch  36 [5550/10697 ( 51.9%)] Loss: 0.032135 L1: 0.018697 Grad: 0.134053 Thermal: 0.000644 LR: 2.93e-06\n",
      "Epoch  36 [5550/10697 ( 51.9%)] Loss: 0.032135 L1: 0.018697 Grad: 0.134053 Thermal: 0.000644 LR: 2.93e-06\n",
      "Epoch  36 [5600/10697 ( 52.4%)] Loss: 0.022593 L1: 0.013586 Grad: 0.089887 Thermal: 0.000375 LR: 2.93e-06\n",
      "Epoch  36 [5600/10697 ( 52.4%)] Loss: 0.022593 L1: 0.013586 Grad: 0.089887 Thermal: 0.000375 LR: 2.93e-06\n",
      "Epoch  36 [5650/10697 ( 52.8%)] Loss: 0.029381 L1: 0.017078 Grad: 0.122769 Thermal: 0.000534 LR: 2.93e-06\n",
      "Epoch  36 [5650/10697 ( 52.8%)] Loss: 0.029381 L1: 0.017078 Grad: 0.122769 Thermal: 0.000534 LR: 2.93e-06\n",
      "Epoch  36 [5700/10697 ( 53.3%)] Loss: 0.025888 L1: 0.014919 Grad: 0.109471 Thermal: 0.000440 LR: 2.93e-06\n",
      "Epoch  36 [5700/10697 ( 53.3%)] Loss: 0.025888 L1: 0.014919 Grad: 0.109471 Thermal: 0.000440 LR: 2.93e-06\n",
      "Epoch  36 [5750/10697 ( 53.8%)] Loss: 0.026131 L1: 0.015690 Grad: 0.104190 Thermal: 0.000430 LR: 2.93e-06\n",
      "Epoch  36 [5750/10697 ( 53.8%)] Loss: 0.026131 L1: 0.015690 Grad: 0.104190 Thermal: 0.000430 LR: 2.93e-06\n",
      "Epoch  36 [5800/10697 ( 54.2%)] Loss: 0.023621 L1: 0.013884 Grad: 0.097184 Thermal: 0.000362 LR: 2.93e-06\n",
      "Epoch  36 [5800/10697 ( 54.2%)] Loss: 0.023621 L1: 0.013884 Grad: 0.097184 Thermal: 0.000362 LR: 2.93e-06\n",
      "Epoch  36 [5850/10697 ( 54.7%)] Loss: 0.032191 L1: 0.018705 Grad: 0.134533 Thermal: 0.000654 LR: 2.93e-06\n",
      "Epoch  36 [5850/10697 ( 54.7%)] Loss: 0.032191 L1: 0.018705 Grad: 0.134533 Thermal: 0.000654 LR: 2.93e-06\n",
      "Epoch  36 [5900/10697 ( 55.2%)] Loss: 0.016467 L1: 0.009470 Grad: 0.069879 Thermal: 0.000190 LR: 2.93e-06\n",
      "Epoch  36 [5900/10697 ( 55.2%)] Loss: 0.016467 L1: 0.009470 Grad: 0.069879 Thermal: 0.000190 LR: 2.93e-06\n",
      "Epoch  36 [5950/10697 ( 55.6%)] Loss: 0.025396 L1: 0.014675 Grad: 0.107008 Thermal: 0.000403 LR: 2.93e-06\n",
      "Epoch  36 [5950/10697 ( 55.6%)] Loss: 0.025396 L1: 0.014675 Grad: 0.107008 Thermal: 0.000403 LR: 2.93e-06\n",
      "Epoch  36 [6000/10697 ( 56.1%)] Loss: 0.027092 L1: 0.015986 Grad: 0.110828 Thermal: 0.000473 LR: 2.93e-06\n",
      "Epoch  36 [6000/10697 ( 56.1%)] Loss: 0.027092 L1: 0.015986 Grad: 0.110828 Thermal: 0.000473 LR: 2.93e-06\n",
      "Epoch  36 [6050/10697 ( 56.6%)] Loss: 0.025999 L1: 0.014708 Grad: 0.112658 Thermal: 0.000491 LR: 2.93e-06\n",
      "Epoch  36 [6050/10697 ( 56.6%)] Loss: 0.025999 L1: 0.014708 Grad: 0.112658 Thermal: 0.000491 LR: 2.93e-06\n",
      "Epoch  36 [6100/10697 ( 57.0%)] Loss: 0.028551 L1: 0.017000 Grad: 0.115250 Thermal: 0.000501 LR: 2.93e-06\n",
      "Epoch  36 [6100/10697 ( 57.0%)] Loss: 0.028551 L1: 0.017000 Grad: 0.115250 Thermal: 0.000501 LR: 2.93e-06\n",
      "Epoch  36 [6150/10697 ( 57.5%)] Loss: 0.024592 L1: 0.014523 Grad: 0.100487 Thermal: 0.000400 LR: 2.93e-06\n",
      "Epoch  36 [6150/10697 ( 57.5%)] Loss: 0.024592 L1: 0.014523 Grad: 0.100487 Thermal: 0.000400 LR: 2.93e-06\n",
      "Epoch  36 [6200/10697 ( 58.0%)] Loss: 0.021277 L1: 0.012574 Grad: 0.086868 Thermal: 0.000319 LR: 2.93e-06\n",
      "Epoch  36 [6200/10697 ( 58.0%)] Loss: 0.021277 L1: 0.012574 Grad: 0.086868 Thermal: 0.000319 LR: 2.93e-06\n",
      "Epoch  36 [6250/10697 ( 58.4%)] Loss: 0.028612 L1: 0.016678 Grad: 0.119080 Thermal: 0.000511 LR: 2.93e-06\n",
      "Epoch  36 [6250/10697 ( 58.4%)] Loss: 0.028612 L1: 0.016678 Grad: 0.119080 Thermal: 0.000511 LR: 2.93e-06\n",
      "Epoch  36 [6300/10697 ( 58.9%)] Loss: 0.024408 L1: 0.013840 Grad: 0.105500 Thermal: 0.000373 LR: 2.93e-06\n",
      "Epoch  36 [6300/10697 ( 58.9%)] Loss: 0.024408 L1: 0.013840 Grad: 0.105500 Thermal: 0.000373 LR: 2.93e-06\n",
      "Epoch  36 [6350/10697 ( 59.4%)] Loss: 0.030124 L1: 0.017268 Grad: 0.128291 Thermal: 0.000549 LR: 2.93e-06\n",
      "Epoch  36 [6350/10697 ( 59.4%)] Loss: 0.030124 L1: 0.017268 Grad: 0.128291 Thermal: 0.000549 LR: 2.93e-06\n",
      "Epoch  36 [6400/10697 ( 59.8%)] Loss: 0.019141 L1: 0.011324 Grad: 0.078034 Thermal: 0.000275 LR: 2.93e-06\n",
      "Epoch  36 [6400/10697 ( 59.8%)] Loss: 0.019141 L1: 0.011324 Grad: 0.078034 Thermal: 0.000275 LR: 2.93e-06\n",
      "Epoch  36 [6450/10697 ( 60.3%)] Loss: 0.026248 L1: 0.015515 Grad: 0.107116 Thermal: 0.000433 LR: 2.93e-06\n",
      "Epoch  36 [6450/10697 ( 60.3%)] Loss: 0.026248 L1: 0.015515 Grad: 0.107116 Thermal: 0.000433 LR: 2.93e-06\n",
      "Epoch  36 [6500/10697 ( 60.8%)] Loss: 0.024467 L1: 0.014111 Grad: 0.103367 Thermal: 0.000381 LR: 2.93e-06\n",
      "Epoch  36 [6500/10697 ( 60.8%)] Loss: 0.024467 L1: 0.014111 Grad: 0.103367 Thermal: 0.000381 LR: 2.93e-06\n",
      "Epoch  36 [6550/10697 ( 61.2%)] Loss: 0.024983 L1: 0.014660 Grad: 0.103034 Thermal: 0.000401 LR: 2.93e-06\n",
      "Epoch  36 [6550/10697 ( 61.2%)] Loss: 0.024983 L1: 0.014660 Grad: 0.103034 Thermal: 0.000401 LR: 2.93e-06\n",
      "Epoch  36 [6600/10697 ( 61.7%)] Loss: 0.030833 L1: 0.018569 Grad: 0.122325 Thermal: 0.000623 LR: 2.93e-06\n",
      "Epoch  36 [6600/10697 ( 61.7%)] Loss: 0.030833 L1: 0.018569 Grad: 0.122325 Thermal: 0.000623 LR: 2.93e-06\n",
      "Epoch  36 [6650/10697 ( 62.2%)] Loss: 0.025866 L1: 0.014828 Grad: 0.110177 Thermal: 0.000402 LR: 2.93e-06\n",
      "Epoch  36 [6650/10697 ( 62.2%)] Loss: 0.025866 L1: 0.014828 Grad: 0.110177 Thermal: 0.000402 LR: 2.93e-06\n",
      "Epoch  36 [6700/10697 ( 62.6%)] Loss: 0.021146 L1: 0.012275 Grad: 0.088559 Thermal: 0.000301 LR: 2.93e-06\n",
      "Epoch  36 [6700/10697 ( 62.6%)] Loss: 0.021146 L1: 0.012275 Grad: 0.088559 Thermal: 0.000301 LR: 2.93e-06\n",
      "Epoch  36 [6750/10697 ( 63.1%)] Loss: 0.032452 L1: 0.018414 Grad: 0.140062 Thermal: 0.000635 LR: 2.93e-06\n",
      "Epoch  36 [6750/10697 ( 63.1%)] Loss: 0.032452 L1: 0.018414 Grad: 0.140062 Thermal: 0.000635 LR: 2.93e-06\n",
      "Epoch  36 [6800/10697 ( 63.6%)] Loss: 0.028033 L1: 0.015823 Grad: 0.121826 Thermal: 0.000549 LR: 2.93e-06\n",
      "Epoch  36 [6800/10697 ( 63.6%)] Loss: 0.028033 L1: 0.015823 Grad: 0.121826 Thermal: 0.000549 LR: 2.93e-06\n",
      "Epoch  36 [6850/10697 ( 64.0%)] Loss: 0.026520 L1: 0.015380 Grad: 0.111174 Thermal: 0.000442 LR: 2.93e-06\n",
      "Epoch  36 [6850/10697 ( 64.0%)] Loss: 0.026520 L1: 0.015380 Grad: 0.111174 Thermal: 0.000442 LR: 2.93e-06\n",
      "Epoch  36 [6900/10697 ( 64.5%)] Loss: 0.025719 L1: 0.015152 Grad: 0.105466 Thermal: 0.000420 LR: 2.93e-06\n",
      "Epoch  36 [6900/10697 ( 64.5%)] Loss: 0.025719 L1: 0.015152 Grad: 0.105466 Thermal: 0.000420 LR: 2.93e-06\n",
      "Epoch  36 [6950/10697 ( 65.0%)] Loss: 0.018636 L1: 0.010869 Grad: 0.077550 Thermal: 0.000239 LR: 2.93e-06\n",
      "Epoch  36 [6950/10697 ( 65.0%)] Loss: 0.018636 L1: 0.010869 Grad: 0.077550 Thermal: 0.000239 LR: 2.93e-06\n",
      "Epoch  36 [7000/10697 ( 65.4%)] Loss: 0.022957 L1: 0.013493 Grad: 0.094472 Thermal: 0.000342 LR: 2.93e-06\n",
      "Epoch  36 [7000/10697 ( 65.4%)] Loss: 0.022957 L1: 0.013493 Grad: 0.094472 Thermal: 0.000342 LR: 2.93e-06\n",
      "Epoch  36 [7050/10697 ( 65.9%)] Loss: 0.022747 L1: 0.013500 Grad: 0.092283 Thermal: 0.000376 LR: 2.93e-06\n",
      "Epoch  36 [7050/10697 ( 65.9%)] Loss: 0.022747 L1: 0.013500 Grad: 0.092283 Thermal: 0.000376 LR: 2.93e-06\n",
      "Epoch  36 [7100/10697 ( 66.4%)] Loss: 0.026243 L1: 0.015160 Grad: 0.110594 Thermal: 0.000461 LR: 2.93e-06\n",
      "Epoch  36 [7100/10697 ( 66.4%)] Loss: 0.026243 L1: 0.015160 Grad: 0.110594 Thermal: 0.000461 LR: 2.93e-06\n",
      "Epoch  36 [7150/10697 ( 66.8%)] Loss: 0.025161 L1: 0.015041 Grad: 0.100996 Thermal: 0.000413 LR: 2.93e-06\n",
      "Epoch  36 [7150/10697 ( 66.8%)] Loss: 0.025161 L1: 0.015041 Grad: 0.100996 Thermal: 0.000413 LR: 2.93e-06\n",
      "Epoch  36 [7200/10697 ( 67.3%)] Loss: 0.029671 L1: 0.016721 Grad: 0.129201 Thermal: 0.000593 LR: 2.93e-06\n",
      "Epoch  36 [7200/10697 ( 67.3%)] Loss: 0.029671 L1: 0.016721 Grad: 0.129201 Thermal: 0.000593 LR: 2.93e-06\n",
      "Epoch  36 [7250/10697 ( 67.8%)] Loss: 0.030919 L1: 0.018065 Grad: 0.128246 Thermal: 0.000582 LR: 2.93e-06\n",
      "Epoch  36 [7250/10697 ( 67.8%)] Loss: 0.030919 L1: 0.018065 Grad: 0.128246 Thermal: 0.000582 LR: 2.93e-06\n",
      "Epoch  36 [7300/10697 ( 68.2%)] Loss: 0.026789 L1: 0.015508 Grad: 0.112569 Thermal: 0.000466 LR: 2.93e-06\n",
      "Epoch  36 [7300/10697 ( 68.2%)] Loss: 0.026789 L1: 0.015508 Grad: 0.112569 Thermal: 0.000466 LR: 2.93e-06\n",
      "Epoch  36 [7350/10697 ( 68.7%)] Loss: 0.027533 L1: 0.016186 Grad: 0.113237 Thermal: 0.000465 LR: 2.93e-06\n",
      "Epoch  36 [7350/10697 ( 68.7%)] Loss: 0.027533 L1: 0.016186 Grad: 0.113237 Thermal: 0.000465 LR: 2.93e-06\n",
      "Epoch  36 [7400/10697 ( 69.2%)] Loss: 0.026611 L1: 0.016110 Grad: 0.104786 Thermal: 0.000457 LR: 2.93e-06\n",
      "Epoch  36 [7400/10697 ( 69.2%)] Loss: 0.026611 L1: 0.016110 Grad: 0.104786 Thermal: 0.000457 LR: 2.93e-06\n",
      "Epoch  36 [7450/10697 ( 69.6%)] Loss: 0.029482 L1: 0.017588 Grad: 0.118678 Thermal: 0.000536 LR: 2.93e-06\n",
      "Epoch  36 [7450/10697 ( 69.6%)] Loss: 0.029482 L1: 0.017588 Grad: 0.118678 Thermal: 0.000536 LR: 2.93e-06\n",
      "Epoch  36 [7500/10697 ( 70.1%)] Loss: 0.027216 L1: 0.015889 Grad: 0.113036 Thermal: 0.000479 LR: 2.93e-06\n",
      "Epoch  36 [7500/10697 ( 70.1%)] Loss: 0.027216 L1: 0.015889 Grad: 0.113036 Thermal: 0.000479 LR: 2.93e-06\n",
      "Epoch  36 [7550/10697 ( 70.6%)] Loss: 0.019094 L1: 0.010785 Grad: 0.082945 Thermal: 0.000280 LR: 2.93e-06\n",
      "Epoch  36 [7550/10697 ( 70.6%)] Loss: 0.019094 L1: 0.010785 Grad: 0.082945 Thermal: 0.000280 LR: 2.93e-06\n",
      "Epoch  36 [7600/10697 ( 71.0%)] Loss: 0.025823 L1: 0.014753 Grad: 0.110501 Thermal: 0.000394 LR: 2.93e-06\n",
      "Epoch  36 [7600/10697 ( 71.0%)] Loss: 0.025823 L1: 0.014753 Grad: 0.110501 Thermal: 0.000394 LR: 2.93e-06\n",
      "Epoch  36 [7650/10697 ( 71.5%)] Loss: 0.024984 L1: 0.014541 Grad: 0.104240 Thermal: 0.000387 LR: 2.93e-06\n",
      "Epoch  36 [7650/10697 ( 71.5%)] Loss: 0.024984 L1: 0.014541 Grad: 0.104240 Thermal: 0.000387 LR: 2.93e-06\n",
      "Epoch  36 [7700/10697 ( 72.0%)] Loss: 0.026457 L1: 0.015471 Grad: 0.109634 Thermal: 0.000457 LR: 2.93e-06\n",
      "Epoch  36 [7700/10697 ( 72.0%)] Loss: 0.026457 L1: 0.015471 Grad: 0.109634 Thermal: 0.000457 LR: 2.93e-06\n",
      "Epoch  36 [7750/10697 ( 72.5%)] Loss: 0.023764 L1: 0.014011 Grad: 0.097353 Thermal: 0.000363 LR: 2.93e-06\n",
      "Epoch  36 [7750/10697 ( 72.5%)] Loss: 0.023764 L1: 0.014011 Grad: 0.097353 Thermal: 0.000363 LR: 2.93e-06\n",
      "Epoch  36 [7800/10697 ( 72.9%)] Loss: 0.024452 L1: 0.014093 Grad: 0.103394 Thermal: 0.000402 LR: 2.93e-06\n",
      "Epoch  36 [7800/10697 ( 72.9%)] Loss: 0.024452 L1: 0.014093 Grad: 0.103394 Thermal: 0.000402 LR: 2.93e-06\n",
      "Epoch  36 [7850/10697 ( 73.4%)] Loss: 0.029872 L1: 0.017313 Grad: 0.125286 Thermal: 0.000610 LR: 2.93e-06\n",
      "Epoch  36 [7850/10697 ( 73.4%)] Loss: 0.029872 L1: 0.017313 Grad: 0.125286 Thermal: 0.000610 LR: 2.93e-06\n",
      "Epoch  36 [7900/10697 ( 73.9%)] Loss: 0.026261 L1: 0.015339 Grad: 0.109008 Thermal: 0.000426 LR: 2.93e-06\n",
      "Epoch  36 [7900/10697 ( 73.9%)] Loss: 0.026261 L1: 0.015339 Grad: 0.109008 Thermal: 0.000426 LR: 2.93e-06\n",
      "Epoch  36 [7950/10697 ( 74.3%)] Loss: 0.025500 L1: 0.014778 Grad: 0.107015 Thermal: 0.000422 LR: 2.93e-06\n",
      "Epoch  36 [7950/10697 ( 74.3%)] Loss: 0.025500 L1: 0.014778 Grad: 0.107015 Thermal: 0.000422 LR: 2.93e-06\n",
      "Epoch  36 [8000/10697 ( 74.8%)] Loss: 0.024757 L1: 0.014083 Grad: 0.106551 Thermal: 0.000380 LR: 2.93e-06\n",
      "Epoch  36 [8000/10697 ( 74.8%)] Loss: 0.024757 L1: 0.014083 Grad: 0.106551 Thermal: 0.000380 LR: 2.93e-06\n",
      "Epoch  36 [8050/10697 ( 75.3%)] Loss: 0.028713 L1: 0.016283 Grad: 0.124058 Thermal: 0.000476 LR: 2.93e-06\n",
      "Epoch  36 [8050/10697 ( 75.3%)] Loss: 0.028713 L1: 0.016283 Grad: 0.124058 Thermal: 0.000476 LR: 2.93e-06\n",
      "Epoch  36 [8100/10697 ( 75.7%)] Loss: 0.026903 L1: 0.016102 Grad: 0.107786 Thermal: 0.000444 LR: 2.93e-06\n",
      "Epoch  36 [8100/10697 ( 75.7%)] Loss: 0.026903 L1: 0.016102 Grad: 0.107786 Thermal: 0.000444 LR: 2.93e-06\n",
      "Epoch  36 [8150/10697 ( 76.2%)] Loss: 0.030457 L1: 0.017820 Grad: 0.126070 Thermal: 0.000615 LR: 2.93e-06\n",
      "Epoch  36 [8150/10697 ( 76.2%)] Loss: 0.030457 L1: 0.017820 Grad: 0.126070 Thermal: 0.000615 LR: 2.93e-06\n",
      "Epoch  36 [8200/10697 ( 76.7%)] Loss: 0.025470 L1: 0.014783 Grad: 0.106656 Thermal: 0.000413 LR: 2.93e-06\n",
      "Epoch  36 [8200/10697 ( 76.7%)] Loss: 0.025470 L1: 0.014783 Grad: 0.106656 Thermal: 0.000413 LR: 2.93e-06\n",
      "Epoch  36 [8250/10697 ( 77.1%)] Loss: 0.028653 L1: 0.016029 Grad: 0.125986 Thermal: 0.000505 LR: 2.93e-06\n",
      "Epoch  36 [8250/10697 ( 77.1%)] Loss: 0.028653 L1: 0.016029 Grad: 0.125986 Thermal: 0.000505 LR: 2.93e-06\n",
      "Epoch  36 [8300/10697 ( 77.6%)] Loss: 0.027236 L1: 0.016297 Grad: 0.109162 Thermal: 0.000474 LR: 2.93e-06\n",
      "Epoch  36 [8300/10697 ( 77.6%)] Loss: 0.027236 L1: 0.016297 Grad: 0.109162 Thermal: 0.000474 LR: 2.93e-06\n",
      "Epoch  36 [8350/10697 ( 78.1%)] Loss: 0.028997 L1: 0.016902 Grad: 0.120698 Thermal: 0.000513 LR: 2.93e-06\n",
      "Epoch  36 [8350/10697 ( 78.1%)] Loss: 0.028997 L1: 0.016902 Grad: 0.120698 Thermal: 0.000513 LR: 2.93e-06\n",
      "Epoch  36 [8400/10697 ( 78.5%)] Loss: 0.026269 L1: 0.015243 Grad: 0.110055 Thermal: 0.000426 LR: 2.93e-06\n",
      "Epoch  36 [8400/10697 ( 78.5%)] Loss: 0.026269 L1: 0.015243 Grad: 0.110055 Thermal: 0.000426 LR: 2.93e-06\n",
      "Epoch  36 [8450/10697 ( 79.0%)] Loss: 0.027260 L1: 0.015711 Grad: 0.115266 Thermal: 0.000450 LR: 2.93e-06\n",
      "Epoch  36 [8450/10697 ( 79.0%)] Loss: 0.027260 L1: 0.015711 Grad: 0.115266 Thermal: 0.000450 LR: 2.93e-06\n",
      "Epoch  36 [8500/10697 ( 79.5%)] Loss: 0.027784 L1: 0.016348 Grad: 0.114111 Thermal: 0.000492 LR: 2.93e-06\n",
      "Epoch  36 [8500/10697 ( 79.5%)] Loss: 0.027784 L1: 0.016348 Grad: 0.114111 Thermal: 0.000492 LR: 2.93e-06\n",
      "Epoch  36 [8550/10697 ( 79.9%)] Loss: 0.030661 L1: 0.017446 Grad: 0.131845 Thermal: 0.000606 LR: 2.93e-06\n",
      "Epoch  36 [8550/10697 ( 79.9%)] Loss: 0.030661 L1: 0.017446 Grad: 0.131845 Thermal: 0.000606 LR: 2.93e-06\n",
      "Epoch  36 [8600/10697 ( 80.4%)] Loss: 0.024439 L1: 0.014821 Grad: 0.095974 Thermal: 0.000407 LR: 2.93e-06\n",
      "Epoch  36 [8600/10697 ( 80.4%)] Loss: 0.024439 L1: 0.014821 Grad: 0.095974 Thermal: 0.000407 LR: 2.93e-06\n",
      "Epoch  36 [8650/10697 ( 80.9%)] Loss: 0.025262 L1: 0.014845 Grad: 0.103965 Thermal: 0.000415 LR: 2.93e-06\n",
      "Epoch  36 [8650/10697 ( 80.9%)] Loss: 0.025262 L1: 0.014845 Grad: 0.103965 Thermal: 0.000415 LR: 2.93e-06\n",
      "Epoch  36 [8700/10697 ( 81.3%)] Loss: 0.019351 L1: 0.011179 Grad: 0.081572 Thermal: 0.000280 LR: 2.93e-06\n",
      "Epoch  36 [8700/10697 ( 81.3%)] Loss: 0.019351 L1: 0.011179 Grad: 0.081572 Thermal: 0.000280 LR: 2.93e-06\n",
      "Epoch  36 [8750/10697 ( 81.8%)] Loss: 0.030358 L1: 0.017431 Grad: 0.129000 Thermal: 0.000557 LR: 2.93e-06\n",
      "Epoch  36 [8750/10697 ( 81.8%)] Loss: 0.030358 L1: 0.017431 Grad: 0.129000 Thermal: 0.000557 LR: 2.93e-06\n",
      "Epoch  36 [8800/10697 ( 82.3%)] Loss: 0.026360 L1: 0.015677 Grad: 0.106598 Thermal: 0.000451 LR: 2.93e-06\n",
      "Epoch  36 [8800/10697 ( 82.3%)] Loss: 0.026360 L1: 0.015677 Grad: 0.106598 Thermal: 0.000451 LR: 2.93e-06\n",
      "Epoch  36 [8850/10697 ( 82.7%)] Loss: 0.023545 L1: 0.013609 Grad: 0.099181 Thermal: 0.000351 LR: 2.93e-06\n",
      "Epoch  36 [8850/10697 ( 82.7%)] Loss: 0.023545 L1: 0.013609 Grad: 0.099181 Thermal: 0.000351 LR: 2.93e-06\n",
      "Epoch  36 [8900/10697 ( 83.2%)] Loss: 0.029701 L1: 0.017360 Grad: 0.123137 Thermal: 0.000549 LR: 2.93e-06\n",
      "Epoch  36 [8900/10697 ( 83.2%)] Loss: 0.029701 L1: 0.017360 Grad: 0.123137 Thermal: 0.000549 LR: 2.93e-06\n",
      "Epoch  36 [8950/10697 ( 83.7%)] Loss: 0.027751 L1: 0.016650 Grad: 0.110757 Thermal: 0.000493 LR: 2.93e-06\n",
      "Epoch  36 [8950/10697 ( 83.7%)] Loss: 0.027751 L1: 0.016650 Grad: 0.110757 Thermal: 0.000493 LR: 2.93e-06\n",
      "Epoch  36 [9000/10697 ( 84.1%)] Loss: 0.023174 L1: 0.013550 Grad: 0.096042 Thermal: 0.000385 LR: 2.93e-06\n",
      "Epoch  36 [9000/10697 ( 84.1%)] Loss: 0.023174 L1: 0.013550 Grad: 0.096042 Thermal: 0.000385 LR: 2.93e-06\n",
      "Epoch  36 [9050/10697 ( 84.6%)] Loss: 0.024446 L1: 0.014145 Grad: 0.102822 Thermal: 0.000390 LR: 2.93e-06\n",
      "Epoch  36 [9050/10697 ( 84.6%)] Loss: 0.024446 L1: 0.014145 Grad: 0.102822 Thermal: 0.000390 LR: 2.93e-06\n",
      "Epoch  36 [9100/10697 ( 85.1%)] Loss: 0.031055 L1: 0.017976 Grad: 0.130410 Thermal: 0.000775 LR: 2.93e-06\n",
      "Epoch  36 [9100/10697 ( 85.1%)] Loss: 0.031055 L1: 0.017976 Grad: 0.130410 Thermal: 0.000775 LR: 2.93e-06\n",
      "Epoch  36 [9150/10697 ( 85.5%)] Loss: 0.030863 L1: 0.017623 Grad: 0.132112 Thermal: 0.000579 LR: 2.93e-06\n",
      "Epoch  36 [9150/10697 ( 85.5%)] Loss: 0.030863 L1: 0.017623 Grad: 0.132112 Thermal: 0.000579 LR: 2.93e-06\n",
      "Epoch  36 [9200/10697 ( 86.0%)] Loss: 0.030560 L1: 0.017828 Grad: 0.127028 Thermal: 0.000579 LR: 2.93e-06\n",
      "Epoch  36 [9200/10697 ( 86.0%)] Loss: 0.030560 L1: 0.017828 Grad: 0.127028 Thermal: 0.000579 LR: 2.93e-06\n",
      "Epoch  36 [9250/10697 ( 86.5%)] Loss: 0.028009 L1: 0.016745 Grad: 0.112391 Thermal: 0.000505 LR: 2.93e-06\n",
      "Epoch  36 [9250/10697 ( 86.5%)] Loss: 0.028009 L1: 0.016745 Grad: 0.112391 Thermal: 0.000505 LR: 2.93e-06\n",
      "Epoch  36 [9300/10697 ( 86.9%)] Loss: 0.023076 L1: 0.013120 Grad: 0.099393 Thermal: 0.000339 LR: 2.93e-06\n",
      "Epoch  36 [9300/10697 ( 86.9%)] Loss: 0.023076 L1: 0.013120 Grad: 0.099393 Thermal: 0.000339 LR: 2.93e-06\n",
      "Epoch  36 [9350/10697 ( 87.4%)] Loss: 0.022597 L1: 0.012921 Grad: 0.096601 Thermal: 0.000311 LR: 2.93e-06\n",
      "Epoch  36 [9350/10697 ( 87.4%)] Loss: 0.022597 L1: 0.012921 Grad: 0.096601 Thermal: 0.000311 LR: 2.93e-06\n",
      "Epoch  36 [9400/10697 ( 87.9%)] Loss: 0.028349 L1: 0.016597 Grad: 0.117277 Thermal: 0.000495 LR: 2.93e-06\n",
      "Epoch  36 [9400/10697 ( 87.9%)] Loss: 0.028349 L1: 0.016597 Grad: 0.117277 Thermal: 0.000495 LR: 2.93e-06\n",
      "Epoch  36 [9450/10697 ( 88.3%)] Loss: 0.032410 L1: 0.018899 Grad: 0.134772 Thermal: 0.000674 LR: 2.93e-06\n",
      "Epoch  36 [9450/10697 ( 88.3%)] Loss: 0.032410 L1: 0.018899 Grad: 0.134772 Thermal: 0.000674 LR: 2.93e-06\n",
      "Epoch  36 [9500/10697 ( 88.8%)] Loss: 0.030516 L1: 0.017790 Grad: 0.126988 Thermal: 0.000555 LR: 2.93e-06\n",
      "Epoch  36 [9500/10697 ( 88.8%)] Loss: 0.030516 L1: 0.017790 Grad: 0.126988 Thermal: 0.000555 LR: 2.93e-06\n",
      "Epoch  36 [9550/10697 ( 89.3%)] Loss: 0.019302 L1: 0.011064 Grad: 0.082263 Thermal: 0.000247 LR: 2.93e-06\n",
      "Epoch  36 [9550/10697 ( 89.3%)] Loss: 0.019302 L1: 0.011064 Grad: 0.082263 Thermal: 0.000247 LR: 2.93e-06\n",
      "Epoch  36 [9600/10697 ( 89.7%)] Loss: 0.031491 L1: 0.018248 Grad: 0.132055 Thermal: 0.000746 LR: 2.93e-06\n",
      "Epoch  36 [9600/10697 ( 89.7%)] Loss: 0.031491 L1: 0.018248 Grad: 0.132055 Thermal: 0.000746 LR: 2.93e-06\n",
      "Epoch  36 [9650/10697 ( 90.2%)] Loss: 0.022669 L1: 0.013506 Grad: 0.091464 Thermal: 0.000328 LR: 2.93e-06\n",
      "Epoch  36 [9650/10697 ( 90.2%)] Loss: 0.022669 L1: 0.013506 Grad: 0.091464 Thermal: 0.000328 LR: 2.93e-06\n",
      "Epoch  36 [9700/10697 ( 90.7%)] Loss: 0.028865 L1: 0.016738 Grad: 0.121007 Thermal: 0.000525 LR: 2.93e-06\n",
      "Epoch  36 [9700/10697 ( 90.7%)] Loss: 0.028865 L1: 0.016738 Grad: 0.121007 Thermal: 0.000525 LR: 2.93e-06\n",
      "Epoch  36 [9750/10697 ( 91.1%)] Loss: 0.021529 L1: 0.012739 Grad: 0.087724 Thermal: 0.000333 LR: 2.93e-06\n",
      "Epoch  36 [9750/10697 ( 91.1%)] Loss: 0.021529 L1: 0.012739 Grad: 0.087724 Thermal: 0.000333 LR: 2.93e-06\n",
      "Epoch  36 [9800/10697 ( 91.6%)] Loss: 0.023393 L1: 0.013808 Grad: 0.095667 Thermal: 0.000358 LR: 2.93e-06\n",
      "Epoch  36 [9800/10697 ( 91.6%)] Loss: 0.023393 L1: 0.013808 Grad: 0.095667 Thermal: 0.000358 LR: 2.93e-06\n",
      "Epoch  36 [9850/10697 ( 92.1%)] Loss: 0.028895 L1: 0.017070 Grad: 0.117977 Thermal: 0.000546 LR: 2.93e-06\n",
      "Epoch  36 [9850/10697 ( 92.1%)] Loss: 0.028895 L1: 0.017070 Grad: 0.117977 Thermal: 0.000546 LR: 2.93e-06\n",
      "Epoch  36 [9900/10697 ( 92.5%)] Loss: 0.023023 L1: 0.013489 Grad: 0.095169 Thermal: 0.000342 LR: 2.93e-06\n",
      "Epoch  36 [9900/10697 ( 92.5%)] Loss: 0.023023 L1: 0.013489 Grad: 0.095169 Thermal: 0.000342 LR: 2.93e-06\n",
      "Epoch  36 [9950/10697 ( 93.0%)] Loss: 0.022150 L1: 0.012701 Grad: 0.094291 Thermal: 0.000383 LR: 2.93e-06\n",
      "Epoch  36 [9950/10697 ( 93.0%)] Loss: 0.022150 L1: 0.012701 Grad: 0.094291 Thermal: 0.000383 LR: 2.93e-06\n",
      "Epoch  36 [10000/10697 ( 93.5%)] Loss: 0.024391 L1: 0.014031 Grad: 0.103388 Thermal: 0.000412 LR: 2.93e-06\n",
      "Epoch  36 [10000/10697 ( 93.5%)] Loss: 0.024391 L1: 0.014031 Grad: 0.103388 Thermal: 0.000412 LR: 2.93e-06\n",
      "Epoch  36 [10050/10697 ( 94.0%)] Loss: 0.026562 L1: 0.015583 Grad: 0.109558 Thermal: 0.000460 LR: 2.93e-06\n",
      "Epoch  36 [10050/10697 ( 94.0%)] Loss: 0.026562 L1: 0.015583 Grad: 0.109558 Thermal: 0.000460 LR: 2.93e-06\n",
      "Epoch  36 [10100/10697 ( 94.4%)] Loss: 0.028812 L1: 0.016488 Grad: 0.122983 Thermal: 0.000514 LR: 2.93e-06\n",
      "Epoch  36 [10100/10697 ( 94.4%)] Loss: 0.028812 L1: 0.016488 Grad: 0.122983 Thermal: 0.000514 LR: 2.93e-06\n",
      "Epoch  36 [10150/10697 ( 94.9%)] Loss: 0.030363 L1: 0.017688 Grad: 0.126470 Thermal: 0.000563 LR: 2.93e-06\n",
      "Epoch  36 [10150/10697 ( 94.9%)] Loss: 0.030363 L1: 0.017688 Grad: 0.126470 Thermal: 0.000563 LR: 2.93e-06\n",
      "Epoch  36 [10200/10697 ( 95.4%)] Loss: 0.025937 L1: 0.015245 Grad: 0.106702 Thermal: 0.000424 LR: 2.93e-06\n",
      "Epoch  36 [10200/10697 ( 95.4%)] Loss: 0.025937 L1: 0.015245 Grad: 0.106702 Thermal: 0.000424 LR: 2.93e-06\n",
      "Epoch  36 [10250/10697 ( 95.8%)] Loss: 0.034018 L1: 0.019268 Grad: 0.147112 Thermal: 0.000769 LR: 2.93e-06\n",
      "Epoch  36 [10250/10697 ( 95.8%)] Loss: 0.034018 L1: 0.019268 Grad: 0.147112 Thermal: 0.000769 LR: 2.93e-06\n",
      "Epoch  36 [10300/10697 ( 96.3%)] Loss: 0.020511 L1: 0.012080 Grad: 0.084150 Thermal: 0.000319 LR: 2.93e-06\n",
      "Epoch  36 [10300/10697 ( 96.3%)] Loss: 0.020511 L1: 0.012080 Grad: 0.084150 Thermal: 0.000319 LR: 2.93e-06\n",
      "Epoch  36 [10350/10697 ( 96.8%)] Loss: 0.021002 L1: 0.012411 Grad: 0.085755 Thermal: 0.000303 LR: 2.93e-06\n",
      "Epoch  36 [10350/10697 ( 96.8%)] Loss: 0.021002 L1: 0.012411 Grad: 0.085755 Thermal: 0.000303 LR: 2.93e-06\n",
      "Epoch  36 [10400/10697 ( 97.2%)] Loss: 0.027727 L1: 0.016443 Grad: 0.112590 Thermal: 0.000510 LR: 2.93e-06\n",
      "Epoch  36 [10400/10697 ( 97.2%)] Loss: 0.027727 L1: 0.016443 Grad: 0.112590 Thermal: 0.000510 LR: 2.93e-06\n",
      "Epoch  36 [10450/10697 ( 97.7%)] Loss: 0.027663 L1: 0.015931 Grad: 0.117086 Thermal: 0.000477 LR: 2.93e-06\n",
      "Epoch  36 [10450/10697 ( 97.7%)] Loss: 0.027663 L1: 0.015931 Grad: 0.117086 Thermal: 0.000477 LR: 2.93e-06\n",
      "Epoch  36 [10500/10697 ( 98.2%)] Loss: 0.024308 L1: 0.014297 Grad: 0.099899 Thermal: 0.000411 LR: 2.93e-06\n",
      "Epoch  36 [10500/10697 ( 98.2%)] Loss: 0.024308 L1: 0.014297 Grad: 0.099899 Thermal: 0.000411 LR: 2.93e-06\n",
      "Epoch  36 [10550/10697 ( 98.6%)] Loss: 0.026229 L1: 0.015380 Grad: 0.108276 Thermal: 0.000417 LR: 2.93e-06\n",
      "Epoch  36 [10550/10697 ( 98.6%)] Loss: 0.026229 L1: 0.015380 Grad: 0.108276 Thermal: 0.000417 LR: 2.93e-06\n",
      "Epoch  36 [10600/10697 ( 99.1%)] Loss: 0.023916 L1: 0.014114 Grad: 0.097814 Thermal: 0.000417 LR: 2.93e-06\n",
      "Epoch  36 [10600/10697 ( 99.1%)] Loss: 0.023916 L1: 0.014114 Grad: 0.097814 Thermal: 0.000417 LR: 2.93e-06\n",
      "Epoch  36 [10650/10697 ( 99.6%)] Loss: 0.024595 L1: 0.014650 Grad: 0.099248 Thermal: 0.000389 LR: 2.93e-06\n",
      "Epoch  36 [10650/10697 ( 99.6%)] Loss: 0.024595 L1: 0.014650 Grad: 0.099248 Thermal: 0.000389 LR: 2.93e-06\n",
      "Epoch  36 Summary: Loss=0.026217 (L1:0.0153, Grad:0.1090, Thermal:0.0005) Val_PSNR=0.00dB Best=33.96dB Time=140.0min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  36 Summary: Loss=0.026217 (L1:0.0153, Grad:0.1090, Thermal:0.0005) Val_PSNR=0.00dB Best=33.96dB Time=140.0min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  37 [   0/10697 (  0.0%)] Loss: 0.027093 L1: 0.015517 Grad: 0.115539 Thermal: 0.000442 LR: 2.83e-06\n",
      "Epoch  37 [   0/10697 (  0.0%)] Loss: 0.027093 L1: 0.015517 Grad: 0.115539 Thermal: 0.000442 LR: 2.83e-06\n",
      "Epoch  37 [  50/10697 (  0.5%)] Loss: 0.025049 L1: 0.014668 Grad: 0.103612 Thermal: 0.000394 LR: 2.83e-06\n",
      "Epoch  37 [  50/10697 (  0.5%)] Loss: 0.025049 L1: 0.014668 Grad: 0.103612 Thermal: 0.000394 LR: 2.83e-06\n",
      "Epoch  37 [ 100/10697 (  0.9%)] Loss: 0.025030 L1: 0.014381 Grad: 0.106291 Thermal: 0.000382 LR: 2.83e-06\n",
      "Epoch  37 [ 100/10697 (  0.9%)] Loss: 0.025030 L1: 0.014381 Grad: 0.106291 Thermal: 0.000382 LR: 2.83e-06\n",
      "Epoch  37 [ 150/10697 (  1.4%)] Loss: 0.022219 L1: 0.012932 Grad: 0.092696 Thermal: 0.000351 LR: 2.83e-06\n",
      "Epoch  37 [ 150/10697 (  1.4%)] Loss: 0.022219 L1: 0.012932 Grad: 0.092696 Thermal: 0.000351 LR: 2.83e-06\n",
      "Epoch  37 [ 200/10697 (  1.9%)] Loss: 0.027994 L1: 0.015865 Grad: 0.121057 Thermal: 0.000467 LR: 2.83e-06\n",
      "Epoch  37 [ 200/10697 (  1.9%)] Loss: 0.027994 L1: 0.015865 Grad: 0.121057 Thermal: 0.000467 LR: 2.83e-06\n",
      "Epoch  37 [ 250/10697 (  2.3%)] Loss: 0.024320 L1: 0.014008 Grad: 0.102912 Thermal: 0.000423 LR: 2.83e-06\n",
      "Epoch  37 [ 250/10697 (  2.3%)] Loss: 0.024320 L1: 0.014008 Grad: 0.102912 Thermal: 0.000423 LR: 2.83e-06\n",
      "Epoch  37 [ 300/10697 (  2.8%)] Loss: 0.024803 L1: 0.014552 Grad: 0.102315 Thermal: 0.000394 LR: 2.83e-06\n",
      "Epoch  37 [ 300/10697 (  2.8%)] Loss: 0.024803 L1: 0.014552 Grad: 0.102315 Thermal: 0.000394 LR: 2.83e-06\n",
      "Epoch  37 [ 350/10697 (  3.3%)] Loss: 0.026797 L1: 0.015233 Grad: 0.115429 Thermal: 0.000422 LR: 2.83e-06\n",
      "Epoch  37 [ 350/10697 (  3.3%)] Loss: 0.026797 L1: 0.015233 Grad: 0.115429 Thermal: 0.000422 LR: 2.83e-06\n",
      "Epoch  37 [ 400/10697 (  3.7%)] Loss: 0.026283 L1: 0.015439 Grad: 0.108218 Thermal: 0.000441 LR: 2.83e-06\n",
      "Epoch  37 [ 400/10697 (  3.7%)] Loss: 0.026283 L1: 0.015439 Grad: 0.108218 Thermal: 0.000441 LR: 2.83e-06\n",
      "Epoch  37 [ 450/10697 (  4.2%)] Loss: 0.025402 L1: 0.014873 Grad: 0.105082 Thermal: 0.000430 LR: 2.83e-06\n",
      "Epoch  37 [ 450/10697 (  4.2%)] Loss: 0.025402 L1: 0.014873 Grad: 0.105082 Thermal: 0.000430 LR: 2.83e-06\n",
      "Epoch  37 [ 500/10697 (  4.7%)] Loss: 0.027778 L1: 0.016183 Grad: 0.115671 Thermal: 0.000550 LR: 2.83e-06\n",
      "Epoch  37 [ 500/10697 (  4.7%)] Loss: 0.027778 L1: 0.016183 Grad: 0.115671 Thermal: 0.000550 LR: 2.83e-06\n",
      "Epoch  37 [ 550/10697 (  5.1%)] Loss: 0.021899 L1: 0.012909 Grad: 0.089738 Thermal: 0.000326 LR: 2.83e-06\n",
      "Epoch  37 [ 550/10697 (  5.1%)] Loss: 0.021899 L1: 0.012909 Grad: 0.089738 Thermal: 0.000326 LR: 2.83e-06\n",
      "Epoch  37 [ 600/10697 (  5.6%)] Loss: 0.032802 L1: 0.018778 Grad: 0.139884 Thermal: 0.000699 LR: 2.83e-06\n",
      "Epoch  37 [ 600/10697 (  5.6%)] Loss: 0.032802 L1: 0.018778 Grad: 0.139884 Thermal: 0.000699 LR: 2.83e-06\n",
      "Epoch  37 [ 650/10697 (  6.1%)] Loss: 0.028243 L1: 0.016804 Grad: 0.114130 Thermal: 0.000526 LR: 2.83e-06\n",
      "Epoch  37 [ 650/10697 (  6.1%)] Loss: 0.028243 L1: 0.016804 Grad: 0.114130 Thermal: 0.000526 LR: 2.83e-06\n",
      "Epoch  37 [ 700/10697 (  6.5%)] Loss: 0.026613 L1: 0.015657 Grad: 0.109349 Thermal: 0.000434 LR: 2.83e-06\n",
      "Epoch  37 [ 700/10697 (  6.5%)] Loss: 0.026613 L1: 0.015657 Grad: 0.109349 Thermal: 0.000434 LR: 2.83e-06\n",
      "Epoch  37 [ 750/10697 (  7.0%)] Loss: 0.023949 L1: 0.013944 Grad: 0.099859 Thermal: 0.000375 LR: 2.83e-06\n",
      "Epoch  37 [ 750/10697 (  7.0%)] Loss: 0.023949 L1: 0.013944 Grad: 0.099859 Thermal: 0.000375 LR: 2.83e-06\n",
      "Epoch  37 [ 800/10697 (  7.5%)] Loss: 0.026659 L1: 0.015858 Grad: 0.107787 Thermal: 0.000444 LR: 2.83e-06\n",
      "Epoch  37 [ 800/10697 (  7.5%)] Loss: 0.026659 L1: 0.015858 Grad: 0.107787 Thermal: 0.000444 LR: 2.83e-06\n",
      "Epoch  37 [ 850/10697 (  7.9%)] Loss: 0.024912 L1: 0.014467 Grad: 0.104259 Thermal: 0.000392 LR: 2.83e-06\n",
      "Epoch  37 [ 850/10697 (  7.9%)] Loss: 0.024912 L1: 0.014467 Grad: 0.104259 Thermal: 0.000392 LR: 2.83e-06\n",
      "Epoch  37 [ 900/10697 (  8.4%)] Loss: 0.023022 L1: 0.013543 Grad: 0.094620 Thermal: 0.000340 LR: 2.83e-06\n",
      "Epoch  37 [ 900/10697 (  8.4%)] Loss: 0.023022 L1: 0.013543 Grad: 0.094620 Thermal: 0.000340 LR: 2.83e-06\n",
      "Epoch  37 [ 950/10697 (  8.9%)] Loss: 0.025240 L1: 0.015128 Grad: 0.100915 Thermal: 0.000418 LR: 2.83e-06\n",
      "Epoch  37 [ 950/10697 (  8.9%)] Loss: 0.025240 L1: 0.015128 Grad: 0.100915 Thermal: 0.000418 LR: 2.83e-06\n",
      "Epoch  37 [1000/10697 (  9.3%)] Loss: 0.023955 L1: 0.014159 Grad: 0.097756 Thermal: 0.000396 LR: 2.83e-06\n",
      "Epoch  37 [1000/10697 (  9.3%)] Loss: 0.023955 L1: 0.014159 Grad: 0.097756 Thermal: 0.000396 LR: 2.83e-06\n",
      "Epoch  37 [1050/10697 (  9.8%)] Loss: 0.021535 L1: 0.012877 Grad: 0.086403 Thermal: 0.000340 LR: 2.83e-06\n",
      "Epoch  37 [1050/10697 (  9.8%)] Loss: 0.021535 L1: 0.012877 Grad: 0.086403 Thermal: 0.000340 LR: 2.83e-06\n",
      "Epoch  37 [1100/10697 ( 10.3%)] Loss: 0.026141 L1: 0.015372 Grad: 0.107479 Thermal: 0.000419 LR: 2.83e-06\n",
      "Epoch  37 [1100/10697 ( 10.3%)] Loss: 0.026141 L1: 0.015372 Grad: 0.107479 Thermal: 0.000419 LR: 2.83e-06\n",
      "Epoch  37 [1150/10697 ( 10.8%)] Loss: 0.023772 L1: 0.014085 Grad: 0.096695 Thermal: 0.000367 LR: 2.83e-06\n",
      "Epoch  37 [1150/10697 ( 10.8%)] Loss: 0.023772 L1: 0.014085 Grad: 0.096695 Thermal: 0.000367 LR: 2.83e-06\n",
      "Epoch  37 [1200/10697 ( 11.2%)] Loss: 0.030577 L1: 0.017489 Grad: 0.130585 Thermal: 0.000588 LR: 2.83e-06\n",
      "Epoch  37 [1200/10697 ( 11.2%)] Loss: 0.030577 L1: 0.017489 Grad: 0.130585 Thermal: 0.000588 LR: 2.83e-06\n",
      "Epoch  37 [1250/10697 ( 11.7%)] Loss: 0.024107 L1: 0.013733 Grad: 0.103567 Thermal: 0.000351 LR: 2.83e-06\n",
      "Epoch  37 [1250/10697 ( 11.7%)] Loss: 0.024107 L1: 0.013733 Grad: 0.103567 Thermal: 0.000351 LR: 2.83e-06\n",
      "Epoch  37 [1300/10697 ( 12.2%)] Loss: 0.025721 L1: 0.014586 Grad: 0.111127 Thermal: 0.000439 LR: 2.83e-06\n",
      "Epoch  37 [1300/10697 ( 12.2%)] Loss: 0.025721 L1: 0.014586 Grad: 0.111127 Thermal: 0.000439 LR: 2.83e-06\n",
      "Epoch  37 [1350/10697 ( 12.6%)] Loss: 0.031173 L1: 0.018311 Grad: 0.128314 Thermal: 0.000600 LR: 2.83e-06\n",
      "Epoch  37 [1350/10697 ( 12.6%)] Loss: 0.031173 L1: 0.018311 Grad: 0.128314 Thermal: 0.000600 LR: 2.83e-06\n",
      "Epoch  37 [1400/10697 ( 13.1%)] Loss: 0.021928 L1: 0.012426 Grad: 0.094836 Thermal: 0.000365 LR: 2.83e-06\n",
      "Epoch  37 [1400/10697 ( 13.1%)] Loss: 0.021928 L1: 0.012426 Grad: 0.094836 Thermal: 0.000365 LR: 2.83e-06\n",
      "Epoch  37 [1450/10697 ( 13.6%)] Loss: 0.026432 L1: 0.014985 Grad: 0.114246 Thermal: 0.000458 LR: 2.83e-06\n",
      "Epoch  37 [1450/10697 ( 13.6%)] Loss: 0.026432 L1: 0.014985 Grad: 0.114246 Thermal: 0.000458 LR: 2.83e-06\n",
      "Epoch  37 [1500/10697 ( 14.0%)] Loss: 0.025278 L1: 0.014316 Grad: 0.109436 Thermal: 0.000378 LR: 2.83e-06\n",
      "Epoch  37 [1500/10697 ( 14.0%)] Loss: 0.025278 L1: 0.014316 Grad: 0.109436 Thermal: 0.000378 LR: 2.83e-06\n",
      "Epoch  37 [1550/10697 ( 14.5%)] Loss: 0.028980 L1: 0.017038 Grad: 0.119153 Thermal: 0.000534 LR: 2.83e-06\n",
      "Epoch  37 [1550/10697 ( 14.5%)] Loss: 0.028980 L1: 0.017038 Grad: 0.119153 Thermal: 0.000534 LR: 2.83e-06\n",
      "Epoch  37 [1600/10697 ( 15.0%)] Loss: 0.025089 L1: 0.014583 Grad: 0.104863 Thermal: 0.000396 LR: 2.83e-06\n",
      "Epoch  37 [1600/10697 ( 15.0%)] Loss: 0.025089 L1: 0.014583 Grad: 0.104863 Thermal: 0.000396 LR: 2.83e-06\n",
      "Epoch  37 [1650/10697 ( 15.4%)] Loss: 0.028682 L1: 0.016564 Grad: 0.120938 Thermal: 0.000491 LR: 2.83e-06\n",
      "Epoch  37 [1650/10697 ( 15.4%)] Loss: 0.028682 L1: 0.016564 Grad: 0.120938 Thermal: 0.000491 LR: 2.83e-06\n",
      "Epoch  37 [1700/10697 ( 15.9%)] Loss: 0.023974 L1: 0.014266 Grad: 0.096891 Thermal: 0.000373 LR: 2.83e-06\n",
      "Epoch  37 [1700/10697 ( 15.9%)] Loss: 0.023974 L1: 0.014266 Grad: 0.096891 Thermal: 0.000373 LR: 2.83e-06\n",
      "Epoch  37 [1750/10697 ( 16.4%)] Loss: 0.022631 L1: 0.013032 Grad: 0.095816 Thermal: 0.000335 LR: 2.83e-06\n",
      "Epoch  37 [1750/10697 ( 16.4%)] Loss: 0.022631 L1: 0.013032 Grad: 0.095816 Thermal: 0.000335 LR: 2.83e-06\n",
      "Epoch  37 [1800/10697 ( 16.8%)] Loss: 0.024325 L1: 0.014261 Grad: 0.100465 Thermal: 0.000358 LR: 2.83e-06\n",
      "Epoch  37 [1800/10697 ( 16.8%)] Loss: 0.024325 L1: 0.014261 Grad: 0.100465 Thermal: 0.000358 LR: 2.83e-06\n",
      "Epoch  37 [1850/10697 ( 17.3%)] Loss: 0.027368 L1: 0.016042 Grad: 0.113031 Thermal: 0.000454 LR: 2.83e-06\n",
      "Epoch  37 [1850/10697 ( 17.3%)] Loss: 0.027368 L1: 0.016042 Grad: 0.113031 Thermal: 0.000454 LR: 2.83e-06\n",
      "Epoch  37 [1900/10697 ( 17.8%)] Loss: 0.024507 L1: 0.014386 Grad: 0.101018 Thermal: 0.000388 LR: 2.83e-06\n",
      "Epoch  37 [1900/10697 ( 17.8%)] Loss: 0.024507 L1: 0.014386 Grad: 0.101018 Thermal: 0.000388 LR: 2.83e-06\n",
      "Epoch  37 [1950/10697 ( 18.2%)] Loss: 0.028969 L1: 0.016708 Grad: 0.122356 Thermal: 0.000502 LR: 2.83e-06\n",
      "Epoch  37 [1950/10697 ( 18.2%)] Loss: 0.028969 L1: 0.016708 Grad: 0.122356 Thermal: 0.000502 LR: 2.83e-06\n",
      "Epoch  37 [2000/10697 ( 18.7%)] Loss: 0.027131 L1: 0.015839 Grad: 0.112673 Thermal: 0.000499 LR: 2.83e-06\n",
      "Epoch  37 [2000/10697 ( 18.7%)] Loss: 0.027131 L1: 0.015839 Grad: 0.112673 Thermal: 0.000499 LR: 2.83e-06\n",
      "Epoch  37 [2050/10697 ( 19.2%)] Loss: 0.024208 L1: 0.014215 Grad: 0.099747 Thermal: 0.000379 LR: 2.83e-06\n",
      "Epoch  37 [2050/10697 ( 19.2%)] Loss: 0.024208 L1: 0.014215 Grad: 0.099747 Thermal: 0.000379 LR: 2.83e-06\n",
      "Epoch  37 [2100/10697 ( 19.6%)] Loss: 0.034333 L1: 0.019812 Grad: 0.144838 Thermal: 0.000752 LR: 2.83e-06\n",
      "Epoch  37 [2100/10697 ( 19.6%)] Loss: 0.034333 L1: 0.019812 Grad: 0.144838 Thermal: 0.000752 LR: 2.83e-06\n",
      "Epoch  37 [2150/10697 ( 20.1%)] Loss: 0.021905 L1: 0.012958 Grad: 0.089296 Thermal: 0.000344 LR: 2.83e-06\n",
      "Epoch  37 [2150/10697 ( 20.1%)] Loss: 0.021905 L1: 0.012958 Grad: 0.089296 Thermal: 0.000344 LR: 2.83e-06\n",
      "Epoch  37 [2200/10697 ( 20.6%)] Loss: 0.026029 L1: 0.015500 Grad: 0.105057 Thermal: 0.000477 LR: 2.83e-06\n",
      "Epoch  37 [2200/10697 ( 20.6%)] Loss: 0.026029 L1: 0.015500 Grad: 0.105057 Thermal: 0.000477 LR: 2.83e-06\n",
      "Epoch  37 [2250/10697 ( 21.0%)] Loss: 0.023199 L1: 0.013615 Grad: 0.095676 Thermal: 0.000330 LR: 2.83e-06\n",
      "Epoch  37 [2250/10697 ( 21.0%)] Loss: 0.023199 L1: 0.013615 Grad: 0.095676 Thermal: 0.000330 LR: 2.83e-06\n",
      "Epoch  37 [2300/10697 ( 21.5%)] Loss: 0.028153 L1: 0.016391 Grad: 0.117372 Thermal: 0.000505 LR: 2.83e-06\n",
      "Epoch  37 [2300/10697 ( 21.5%)] Loss: 0.028153 L1: 0.016391 Grad: 0.117372 Thermal: 0.000505 LR: 2.83e-06\n",
      "Epoch  37 [2350/10697 ( 22.0%)] Loss: 0.026604 L1: 0.015575 Grad: 0.110067 Thermal: 0.000436 LR: 2.83e-06\n",
      "Epoch  37 [2350/10697 ( 22.0%)] Loss: 0.026604 L1: 0.015575 Grad: 0.110067 Thermal: 0.000436 LR: 2.83e-06\n",
      "Epoch  37 [2400/10697 ( 22.4%)] Loss: 0.025509 L1: 0.014842 Grad: 0.106438 Thermal: 0.000474 LR: 2.83e-06\n",
      "Epoch  37 [2400/10697 ( 22.4%)] Loss: 0.025509 L1: 0.014842 Grad: 0.106438 Thermal: 0.000474 LR: 2.83e-06\n",
      "Epoch  37 [2450/10697 ( 22.9%)] Loss: 0.026584 L1: 0.015755 Grad: 0.108067 Thermal: 0.000433 LR: 2.83e-06\n",
      "Epoch  37 [2450/10697 ( 22.9%)] Loss: 0.026584 L1: 0.015755 Grad: 0.108067 Thermal: 0.000433 LR: 2.83e-06\n",
      "Epoch  37 [2500/10697 ( 23.4%)] Loss: 0.027361 L1: 0.015946 Grad: 0.113909 Thermal: 0.000468 LR: 2.83e-06\n",
      "Epoch  37 [2500/10697 ( 23.4%)] Loss: 0.027361 L1: 0.015946 Grad: 0.113909 Thermal: 0.000468 LR: 2.83e-06\n",
      "Epoch  37 [2550/10697 ( 23.8%)] Loss: 0.024637 L1: 0.014639 Grad: 0.099775 Thermal: 0.000406 LR: 2.83e-06\n",
      "Epoch  37 [2550/10697 ( 23.8%)] Loss: 0.024637 L1: 0.014639 Grad: 0.099775 Thermal: 0.000406 LR: 2.83e-06\n",
      "Epoch  37 [2600/10697 ( 24.3%)] Loss: 0.026254 L1: 0.015615 Grad: 0.106172 Thermal: 0.000436 LR: 2.83e-06\n",
      "Epoch  37 [2600/10697 ( 24.3%)] Loss: 0.026254 L1: 0.015615 Grad: 0.106172 Thermal: 0.000436 LR: 2.83e-06\n",
      "Epoch  37 [2650/10697 ( 24.8%)] Loss: 0.021452 L1: 0.012865 Grad: 0.085698 Thermal: 0.000341 LR: 2.83e-06\n",
      "Epoch  37 [2650/10697 ( 24.8%)] Loss: 0.021452 L1: 0.012865 Grad: 0.085698 Thermal: 0.000341 LR: 2.83e-06\n",
      "Epoch  37 [2700/10697 ( 25.2%)] Loss: 0.028410 L1: 0.015957 Grad: 0.124281 Thermal: 0.000496 LR: 2.83e-06\n",
      "Epoch  37 [2700/10697 ( 25.2%)] Loss: 0.028410 L1: 0.015957 Grad: 0.124281 Thermal: 0.000496 LR: 2.83e-06\n",
      "Epoch  37 [2750/10697 ( 25.7%)] Loss: 0.024178 L1: 0.014054 Grad: 0.101037 Thermal: 0.000409 LR: 2.83e-06\n",
      "Epoch  37 [2750/10697 ( 25.7%)] Loss: 0.024178 L1: 0.014054 Grad: 0.101037 Thermal: 0.000409 LR: 2.83e-06\n",
      "Epoch  37 [2800/10697 ( 26.2%)] Loss: 0.030017 L1: 0.017492 Grad: 0.124961 Thermal: 0.000588 LR: 2.83e-06\n",
      "Epoch  37 [2800/10697 ( 26.2%)] Loss: 0.030017 L1: 0.017492 Grad: 0.124961 Thermal: 0.000588 LR: 2.83e-06\n",
      "Epoch  37 [2850/10697 ( 26.6%)] Loss: 0.026800 L1: 0.016081 Grad: 0.106964 Thermal: 0.000454 LR: 2.83e-06\n",
      "Epoch  37 [2850/10697 ( 26.6%)] Loss: 0.026800 L1: 0.016081 Grad: 0.106964 Thermal: 0.000454 LR: 2.83e-06\n",
      "Epoch  37 [2900/10697 ( 27.1%)] Loss: 0.024090 L1: 0.014227 Grad: 0.098439 Thermal: 0.000381 LR: 2.83e-06\n",
      "Epoch  37 [2900/10697 ( 27.1%)] Loss: 0.024090 L1: 0.014227 Grad: 0.098439 Thermal: 0.000381 LR: 2.83e-06\n",
      "Epoch  37 [2950/10697 ( 27.6%)] Loss: 0.030884 L1: 0.018123 Grad: 0.127301 Thermal: 0.000626 LR: 2.83e-06\n",
      "Epoch  37 [2950/10697 ( 27.6%)] Loss: 0.030884 L1: 0.018123 Grad: 0.127301 Thermal: 0.000626 LR: 2.83e-06\n",
      "Epoch  37 [3000/10697 ( 28.0%)] Loss: 0.022449 L1: 0.012806 Grad: 0.096270 Thermal: 0.000323 LR: 2.83e-06\n",
      "Epoch  37 [3000/10697 ( 28.0%)] Loss: 0.022449 L1: 0.012806 Grad: 0.096270 Thermal: 0.000323 LR: 2.83e-06\n",
      "Epoch  37 [3050/10697 ( 28.5%)] Loss: 0.022708 L1: 0.013272 Grad: 0.094181 Thermal: 0.000348 LR: 2.83e-06\n",
      "Epoch  37 [3050/10697 ( 28.5%)] Loss: 0.022708 L1: 0.013272 Grad: 0.094181 Thermal: 0.000348 LR: 2.83e-06\n",
      "Epoch  37 [3100/10697 ( 29.0%)] Loss: 0.024150 L1: 0.014357 Grad: 0.097740 Thermal: 0.000382 LR: 2.83e-06\n",
      "Epoch  37 [3100/10697 ( 29.0%)] Loss: 0.024150 L1: 0.014357 Grad: 0.097740 Thermal: 0.000382 LR: 2.83e-06\n",
      "Epoch  37 [3150/10697 ( 29.4%)] Loss: 0.028419 L1: 0.017008 Grad: 0.113850 Thermal: 0.000506 LR: 2.83e-06\n",
      "Epoch  37 [3150/10697 ( 29.4%)] Loss: 0.028419 L1: 0.017008 Grad: 0.113850 Thermal: 0.000506 LR: 2.83e-06\n",
      "Epoch  37 [3200/10697 ( 29.9%)] Loss: 0.027147 L1: 0.015791 Grad: 0.113307 Thermal: 0.000492 LR: 2.83e-06\n",
      "Epoch  37 [3200/10697 ( 29.9%)] Loss: 0.027147 L1: 0.015791 Grad: 0.113307 Thermal: 0.000492 LR: 2.83e-06\n",
      "Epoch  37 [3250/10697 ( 30.4%)] Loss: 0.022379 L1: 0.013181 Grad: 0.091796 Thermal: 0.000371 LR: 2.83e-06\n",
      "Epoch  37 [3250/10697 ( 30.4%)] Loss: 0.022379 L1: 0.013181 Grad: 0.091796 Thermal: 0.000371 LR: 2.83e-06\n",
      "Epoch  37 [3300/10697 ( 30.8%)] Loss: 0.025208 L1: 0.014557 Grad: 0.106319 Thermal: 0.000390 LR: 2.83e-06\n",
      "Epoch  37 [3300/10697 ( 30.8%)] Loss: 0.025208 L1: 0.014557 Grad: 0.106319 Thermal: 0.000390 LR: 2.83e-06\n",
      "Epoch  37 [3350/10697 ( 31.3%)] Loss: 0.028024 L1: 0.015484 Grad: 0.125163 Thermal: 0.000459 LR: 2.83e-06\n",
      "Epoch  37 [3350/10697 ( 31.3%)] Loss: 0.028024 L1: 0.015484 Grad: 0.125163 Thermal: 0.000459 LR: 2.83e-06\n",
      "Epoch  37 [3400/10697 ( 31.8%)] Loss: 0.023660 L1: 0.013796 Grad: 0.098470 Thermal: 0.000357 LR: 2.83e-06\n",
      "Epoch  37 [3400/10697 ( 31.8%)] Loss: 0.023660 L1: 0.013796 Grad: 0.098470 Thermal: 0.000357 LR: 2.83e-06\n",
      "Epoch  37 [3450/10697 ( 32.3%)] Loss: 0.030213 L1: 0.017605 Grad: 0.125788 Thermal: 0.000592 LR: 2.83e-06\n",
      "Epoch  37 [3450/10697 ( 32.3%)] Loss: 0.030213 L1: 0.017605 Grad: 0.125788 Thermal: 0.000592 LR: 2.83e-06\n",
      "Epoch  37 [3500/10697 ( 32.7%)] Loss: 0.033040 L1: 0.018897 Grad: 0.141112 Thermal: 0.000645 LR: 2.83e-06\n",
      "Epoch  37 [3500/10697 ( 32.7%)] Loss: 0.033040 L1: 0.018897 Grad: 0.141112 Thermal: 0.000645 LR: 2.83e-06\n",
      "Epoch  37 [3550/10697 ( 33.2%)] Loss: 0.031812 L1: 0.018037 Grad: 0.137476 Thermal: 0.000557 LR: 2.83e-06\n",
      "Epoch  37 [3550/10697 ( 33.2%)] Loss: 0.031812 L1: 0.018037 Grad: 0.137476 Thermal: 0.000557 LR: 2.83e-06\n",
      "Epoch  37 [3600/10697 ( 33.7%)] Loss: 0.033336 L1: 0.018879 Grad: 0.144246 Thermal: 0.000647 LR: 2.83e-06\n",
      "Epoch  37 [3600/10697 ( 33.7%)] Loss: 0.033336 L1: 0.018879 Grad: 0.144246 Thermal: 0.000647 LR: 2.83e-06\n",
      "Epoch  37 [3650/10697 ( 34.1%)] Loss: 0.027193 L1: 0.015753 Grad: 0.114180 Thermal: 0.000443 LR: 2.83e-06\n",
      "Epoch  37 [3650/10697 ( 34.1%)] Loss: 0.027193 L1: 0.015753 Grad: 0.114180 Thermal: 0.000443 LR: 2.83e-06\n",
      "Epoch  37 [3700/10697 ( 34.6%)] Loss: 0.025732 L1: 0.015228 Grad: 0.104830 Thermal: 0.000421 LR: 2.83e-06\n",
      "Epoch  37 [3700/10697 ( 34.6%)] Loss: 0.025732 L1: 0.015228 Grad: 0.104830 Thermal: 0.000421 LR: 2.83e-06\n",
      "Epoch  37 [3750/10697 ( 35.1%)] Loss: 0.020906 L1: 0.012019 Grad: 0.088704 Thermal: 0.000336 LR: 2.83e-06\n",
      "Epoch  37 [3750/10697 ( 35.1%)] Loss: 0.020906 L1: 0.012019 Grad: 0.088704 Thermal: 0.000336 LR: 2.83e-06\n",
      "Epoch  37 [3800/10697 ( 35.5%)] Loss: 0.028661 L1: 0.016956 Grad: 0.116742 Thermal: 0.000625 LR: 2.83e-06\n",
      "Epoch  37 [3800/10697 ( 35.5%)] Loss: 0.028661 L1: 0.016956 Grad: 0.116742 Thermal: 0.000625 LR: 2.83e-06\n",
      "Epoch  37 [3850/10697 ( 36.0%)] Loss: 0.026403 L1: 0.015793 Grad: 0.105867 Thermal: 0.000452 LR: 2.83e-06\n",
      "Epoch  37 [3850/10697 ( 36.0%)] Loss: 0.026403 L1: 0.015793 Grad: 0.105867 Thermal: 0.000452 LR: 2.83e-06\n",
      "Epoch  37 [3900/10697 ( 36.5%)] Loss: 0.027090 L1: 0.015674 Grad: 0.113943 Thermal: 0.000435 LR: 2.83e-06\n",
      "Epoch  37 [3900/10697 ( 36.5%)] Loss: 0.027090 L1: 0.015674 Grad: 0.113943 Thermal: 0.000435 LR: 2.83e-06\n",
      "Epoch  37 [3950/10697 ( 36.9%)] Loss: 0.025448 L1: 0.015149 Grad: 0.102761 Thermal: 0.000464 LR: 2.83e-06\n",
      "Epoch  37 [3950/10697 ( 36.9%)] Loss: 0.025448 L1: 0.015149 Grad: 0.102761 Thermal: 0.000464 LR: 2.83e-06\n",
      "Epoch  37 [4000/10697 ( 37.4%)] Loss: 0.023764 L1: 0.013910 Grad: 0.098335 Thermal: 0.000421 LR: 2.83e-06\n",
      "Epoch  37 [4000/10697 ( 37.4%)] Loss: 0.023764 L1: 0.013910 Grad: 0.098335 Thermal: 0.000421 LR: 2.83e-06\n",
      "Epoch  37 [4050/10697 ( 37.9%)] Loss: 0.021885 L1: 0.012438 Grad: 0.094314 Thermal: 0.000309 LR: 2.83e-06\n",
      "Epoch  37 [4050/10697 ( 37.9%)] Loss: 0.021885 L1: 0.012438 Grad: 0.094314 Thermal: 0.000309 LR: 2.83e-06\n",
      "Epoch  37 [4100/10697 ( 38.3%)] Loss: 0.028594 L1: 0.016704 Grad: 0.118659 Thermal: 0.000485 LR: 2.83e-06\n",
      "Epoch  37 [4100/10697 ( 38.3%)] Loss: 0.028594 L1: 0.016704 Grad: 0.118659 Thermal: 0.000485 LR: 2.83e-06\n",
      "Epoch  37 [4150/10697 ( 38.8%)] Loss: 0.022919 L1: 0.013227 Grad: 0.096729 Thermal: 0.000383 LR: 2.83e-06\n",
      "Epoch  37 [4150/10697 ( 38.8%)] Loss: 0.022919 L1: 0.013227 Grad: 0.096729 Thermal: 0.000383 LR: 2.83e-06\n",
      "Epoch  37 [4200/10697 ( 39.3%)] Loss: 0.025201 L1: 0.015002 Grad: 0.101791 Thermal: 0.000405 LR: 2.83e-06\n",
      "Epoch  37 [4200/10697 ( 39.3%)] Loss: 0.025201 L1: 0.015002 Grad: 0.101791 Thermal: 0.000405 LR: 2.83e-06\n",
      "Epoch  37 [4250/10697 ( 39.7%)] Loss: 0.031113 L1: 0.018443 Grad: 0.126367 Thermal: 0.000671 LR: 2.83e-06\n",
      "Epoch  37 [4250/10697 ( 39.7%)] Loss: 0.031113 L1: 0.018443 Grad: 0.126367 Thermal: 0.000671 LR: 2.83e-06\n",
      "Epoch  37 [4300/10697 ( 40.2%)] Loss: 0.023125 L1: 0.013553 Grad: 0.095538 Thermal: 0.000369 LR: 2.83e-06\n",
      "Epoch  37 [4300/10697 ( 40.2%)] Loss: 0.023125 L1: 0.013553 Grad: 0.095538 Thermal: 0.000369 LR: 2.83e-06\n",
      "Epoch  37 [4350/10697 ( 40.7%)] Loss: 0.026463 L1: 0.015564 Grad: 0.108761 Thermal: 0.000447 LR: 2.83e-06\n",
      "Epoch  37 [4350/10697 ( 40.7%)] Loss: 0.026463 L1: 0.015564 Grad: 0.108761 Thermal: 0.000447 LR: 2.83e-06\n",
      "Epoch  37 [4400/10697 ( 41.1%)] Loss: 0.028072 L1: 0.016637 Grad: 0.114069 Thermal: 0.000556 LR: 2.83e-06\n",
      "Epoch  37 [4400/10697 ( 41.1%)] Loss: 0.028072 L1: 0.016637 Grad: 0.114069 Thermal: 0.000556 LR: 2.83e-06\n",
      "Epoch  37 [4450/10697 ( 41.6%)] Loss: 0.027694 L1: 0.016058 Grad: 0.116086 Thermal: 0.000536 LR: 2.83e-06\n",
      "Epoch  37 [4450/10697 ( 41.6%)] Loss: 0.027694 L1: 0.016058 Grad: 0.116086 Thermal: 0.000536 LR: 2.83e-06\n",
      "Epoch  37 [4500/10697 ( 42.1%)] Loss: 0.022112 L1: 0.012739 Grad: 0.093557 Thermal: 0.000345 LR: 2.83e-06\n",
      "Epoch  37 [4500/10697 ( 42.1%)] Loss: 0.022112 L1: 0.012739 Grad: 0.093557 Thermal: 0.000345 LR: 2.83e-06\n",
      "Epoch  37 [4550/10697 ( 42.5%)] Loss: 0.020038 L1: 0.011294 Grad: 0.087296 Thermal: 0.000292 LR: 2.83e-06\n",
      "Epoch  37 [4550/10697 ( 42.5%)] Loss: 0.020038 L1: 0.011294 Grad: 0.087296 Thermal: 0.000292 LR: 2.83e-06\n",
      "Epoch  37 [4600/10697 ( 43.0%)] Loss: 0.026244 L1: 0.014812 Grad: 0.114076 Thermal: 0.000486 LR: 2.83e-06\n",
      "Epoch  37 [4600/10697 ( 43.0%)] Loss: 0.026244 L1: 0.014812 Grad: 0.114076 Thermal: 0.000486 LR: 2.83e-06\n",
      "Epoch  37 [4650/10697 ( 43.5%)] Loss: 0.022220 L1: 0.012940 Grad: 0.092616 Thermal: 0.000362 LR: 2.83e-06\n",
      "Epoch  37 [4650/10697 ( 43.5%)] Loss: 0.022220 L1: 0.012940 Grad: 0.092616 Thermal: 0.000362 LR: 2.83e-06\n",
      "Epoch  37 [4700/10697 ( 43.9%)] Loss: 0.024449 L1: 0.014269 Grad: 0.101605 Thermal: 0.000395 LR: 2.83e-06\n",
      "Epoch  37 [4700/10697 ( 43.9%)] Loss: 0.024449 L1: 0.014269 Grad: 0.101605 Thermal: 0.000395 LR: 2.83e-06\n",
      "Epoch  37 [4750/10697 ( 44.4%)] Loss: 0.029282 L1: 0.016616 Grad: 0.126379 Thermal: 0.000552 LR: 2.83e-06\n",
      "Epoch  37 [4750/10697 ( 44.4%)] Loss: 0.029282 L1: 0.016616 Grad: 0.126379 Thermal: 0.000552 LR: 2.83e-06\n",
      "Epoch  37 [4800/10697 ( 44.9%)] Loss: 0.022726 L1: 0.013212 Grad: 0.094963 Thermal: 0.000358 LR: 2.83e-06\n",
      "Epoch  37 [4800/10697 ( 44.9%)] Loss: 0.022726 L1: 0.013212 Grad: 0.094963 Thermal: 0.000358 LR: 2.83e-06\n",
      "Epoch  37 [4850/10697 ( 45.3%)] Loss: 0.025428 L1: 0.014753 Grad: 0.106547 Thermal: 0.000399 LR: 2.83e-06\n",
      "Epoch  37 [4850/10697 ( 45.3%)] Loss: 0.025428 L1: 0.014753 Grad: 0.106547 Thermal: 0.000399 LR: 2.83e-06\n",
      "Epoch  37 [4900/10697 ( 45.8%)] Loss: 0.017508 L1: 0.010156 Grad: 0.073401 Thermal: 0.000238 LR: 2.83e-06\n",
      "Epoch  37 [4900/10697 ( 45.8%)] Loss: 0.017508 L1: 0.010156 Grad: 0.073401 Thermal: 0.000238 LR: 2.83e-06\n",
      "Epoch  37 [4950/10697 ( 46.3%)] Loss: 0.025328 L1: 0.014395 Grad: 0.109129 Thermal: 0.000389 LR: 2.83e-06\n",
      "Epoch  37 [4950/10697 ( 46.3%)] Loss: 0.025328 L1: 0.014395 Grad: 0.109129 Thermal: 0.000389 LR: 2.83e-06\n",
      "Epoch  37 [5000/10697 ( 46.7%)] Loss: 0.030730 L1: 0.017914 Grad: 0.127874 Thermal: 0.000585 LR: 2.83e-06\n",
      "Epoch  37 [5000/10697 ( 46.7%)] Loss: 0.030730 L1: 0.017914 Grad: 0.127874 Thermal: 0.000585 LR: 2.83e-06\n",
      "Epoch  37 [5050/10697 ( 47.2%)] Loss: 0.027361 L1: 0.016217 Grad: 0.111206 Thermal: 0.000471 LR: 2.83e-06\n",
      "Epoch  37 [5050/10697 ( 47.2%)] Loss: 0.027361 L1: 0.016217 Grad: 0.111206 Thermal: 0.000471 LR: 2.83e-06\n",
      "Epoch  37 [5100/10697 ( 47.7%)] Loss: 0.029403 L1: 0.017122 Grad: 0.122528 Thermal: 0.000569 LR: 2.83e-06\n",
      "Epoch  37 [5100/10697 ( 47.7%)] Loss: 0.029403 L1: 0.017122 Grad: 0.122528 Thermal: 0.000569 LR: 2.83e-06\n",
      "Epoch  37 [5150/10697 ( 48.1%)] Loss: 0.026598 L1: 0.015449 Grad: 0.111254 Thermal: 0.000466 LR: 2.83e-06\n",
      "Epoch  37 [5150/10697 ( 48.1%)] Loss: 0.026598 L1: 0.015449 Grad: 0.111254 Thermal: 0.000466 LR: 2.83e-06\n",
      "Epoch  37 [5200/10697 ( 48.6%)] Loss: 0.029834 L1: 0.017602 Grad: 0.121983 Thermal: 0.000672 LR: 2.83e-06\n",
      "Epoch  37 [5200/10697 ( 48.6%)] Loss: 0.029834 L1: 0.017602 Grad: 0.121983 Thermal: 0.000672 LR: 2.83e-06\n",
      "Epoch  37 [5250/10697 ( 49.1%)] Loss: 0.024455 L1: 0.014175 Grad: 0.102572 Thermal: 0.000453 LR: 2.83e-06\n",
      "Epoch  37 [5250/10697 ( 49.1%)] Loss: 0.024455 L1: 0.014175 Grad: 0.102572 Thermal: 0.000453 LR: 2.83e-06\n",
      "Epoch  37 [5300/10697 ( 49.5%)] Loss: 0.027480 L1: 0.016213 Grad: 0.112427 Thermal: 0.000481 LR: 2.83e-06\n",
      "Epoch  37 [5300/10697 ( 49.5%)] Loss: 0.027480 L1: 0.016213 Grad: 0.112427 Thermal: 0.000481 LR: 2.83e-06\n",
      "Epoch  37 [5350/10697 ( 50.0%)] Loss: 0.026797 L1: 0.016066 Grad: 0.107087 Thermal: 0.000455 LR: 2.83e-06\n",
      "Epoch  37 [5350/10697 ( 50.0%)] Loss: 0.026797 L1: 0.016066 Grad: 0.107087 Thermal: 0.000455 LR: 2.83e-06\n",
      "Epoch  37 [5400/10697 ( 50.5%)] Loss: 0.025164 L1: 0.014394 Grad: 0.107509 Thermal: 0.000388 LR: 2.83e-06\n",
      "Epoch  37 [5400/10697 ( 50.5%)] Loss: 0.025164 L1: 0.014394 Grad: 0.107509 Thermal: 0.000388 LR: 2.83e-06\n",
      "Epoch  37 [5450/10697 ( 50.9%)] Loss: 0.022803 L1: 0.012697 Grad: 0.100878 Thermal: 0.000358 LR: 2.83e-06\n",
      "Epoch  37 [5450/10697 ( 50.9%)] Loss: 0.022803 L1: 0.012697 Grad: 0.100878 Thermal: 0.000358 LR: 2.83e-06\n",
      "Epoch  37 [5500/10697 ( 51.4%)] Loss: 0.024471 L1: 0.014276 Grad: 0.101767 Thermal: 0.000368 LR: 2.83e-06\n",
      "Epoch  37 [5500/10697 ( 51.4%)] Loss: 0.024471 L1: 0.014276 Grad: 0.101767 Thermal: 0.000368 LR: 2.83e-06\n",
      "Epoch  37 [5550/10697 ( 51.9%)] Loss: 0.029191 L1: 0.016677 Grad: 0.124845 Thermal: 0.000586 LR: 2.83e-06\n",
      "Epoch  37 [5550/10697 ( 51.9%)] Loss: 0.029191 L1: 0.016677 Grad: 0.124845 Thermal: 0.000586 LR: 2.83e-06\n",
      "Epoch  37 [5600/10697 ( 52.4%)] Loss: 0.024983 L1: 0.015172 Grad: 0.097914 Thermal: 0.000401 LR: 2.83e-06\n",
      "Epoch  37 [5600/10697 ( 52.4%)] Loss: 0.024983 L1: 0.015172 Grad: 0.097914 Thermal: 0.000401 LR: 2.83e-06\n",
      "Epoch  37 [5650/10697 ( 52.8%)] Loss: 0.029057 L1: 0.016988 Grad: 0.120418 Thermal: 0.000541 LR: 2.83e-06\n",
      "Epoch  37 [5650/10697 ( 52.8%)] Loss: 0.029057 L1: 0.016988 Grad: 0.120418 Thermal: 0.000541 LR: 2.83e-06\n",
      "Epoch  37 [5700/10697 ( 53.3%)] Loss: 0.033735 L1: 0.019519 Grad: 0.141811 Thermal: 0.000696 LR: 2.83e-06\n",
      "Epoch  37 [5700/10697 ( 53.3%)] Loss: 0.033735 L1: 0.019519 Grad: 0.141811 Thermal: 0.000696 LR: 2.83e-06\n",
      "Epoch  37 [5750/10697 ( 53.8%)] Loss: 0.024903 L1: 0.014396 Grad: 0.104858 Thermal: 0.000425 LR: 2.83e-06\n",
      "Epoch  37 [5750/10697 ( 53.8%)] Loss: 0.024903 L1: 0.014396 Grad: 0.104858 Thermal: 0.000425 LR: 2.83e-06\n",
      "Epoch  37 [5800/10697 ( 54.2%)] Loss: 0.023864 L1: 0.014125 Grad: 0.097196 Thermal: 0.000383 LR: 2.83e-06\n",
      "Epoch  37 [5800/10697 ( 54.2%)] Loss: 0.023864 L1: 0.014125 Grad: 0.097196 Thermal: 0.000383 LR: 2.83e-06\n",
      "Epoch  37 [5850/10697 ( 54.7%)] Loss: 0.025361 L1: 0.015199 Grad: 0.101409 Thermal: 0.000430 LR: 2.83e-06\n",
      "Epoch  37 [5850/10697 ( 54.7%)] Loss: 0.025361 L1: 0.015199 Grad: 0.101409 Thermal: 0.000430 LR: 2.83e-06\n",
      "Epoch  37 [5900/10697 ( 55.2%)] Loss: 0.024209 L1: 0.014090 Grad: 0.100998 Thermal: 0.000380 LR: 2.83e-06\n",
      "Epoch  37 [5900/10697 ( 55.2%)] Loss: 0.024209 L1: 0.014090 Grad: 0.100998 Thermal: 0.000380 LR: 2.83e-06\n",
      "Epoch  37 [5950/10697 ( 55.6%)] Loss: 0.024328 L1: 0.014711 Grad: 0.095969 Thermal: 0.000399 LR: 2.83e-06\n",
      "Epoch  37 [5950/10697 ( 55.6%)] Loss: 0.024328 L1: 0.014711 Grad: 0.095969 Thermal: 0.000399 LR: 2.83e-06\n",
      "Epoch  37 [6000/10697 ( 56.1%)] Loss: 0.026799 L1: 0.015215 Grad: 0.115635 Thermal: 0.000402 LR: 2.83e-06\n",
      "Epoch  37 [6000/10697 ( 56.1%)] Loss: 0.026799 L1: 0.015215 Grad: 0.115635 Thermal: 0.000402 LR: 2.83e-06\n",
      "Epoch  37 [6050/10697 ( 56.6%)] Loss: 0.030756 L1: 0.017822 Grad: 0.129032 Thermal: 0.000622 LR: 2.83e-06\n",
      "Epoch  37 [6050/10697 ( 56.6%)] Loss: 0.030756 L1: 0.017822 Grad: 0.129032 Thermal: 0.000622 LR: 2.83e-06\n",
      "Epoch  37 [6100/10697 ( 57.0%)] Loss: 0.028758 L1: 0.016828 Grad: 0.119041 Thermal: 0.000522 LR: 2.83e-06\n",
      "Epoch  37 [6100/10697 ( 57.0%)] Loss: 0.028758 L1: 0.016828 Grad: 0.119041 Thermal: 0.000522 LR: 2.83e-06\n",
      "Epoch  37 [6150/10697 ( 57.5%)] Loss: 0.018986 L1: 0.010640 Grad: 0.083349 Thermal: 0.000238 LR: 2.83e-06\n",
      "Epoch  37 [6150/10697 ( 57.5%)] Loss: 0.018986 L1: 0.010640 Grad: 0.083349 Thermal: 0.000238 LR: 2.83e-06\n",
      "Epoch  37 [6200/10697 ( 58.0%)] Loss: 0.023615 L1: 0.013341 Grad: 0.102557 Thermal: 0.000368 LR: 2.83e-06\n",
      "Epoch  37 [6200/10697 ( 58.0%)] Loss: 0.023615 L1: 0.013341 Grad: 0.102557 Thermal: 0.000368 LR: 2.83e-06\n",
      "Epoch  37 [6250/10697 ( 58.4%)] Loss: 0.026237 L1: 0.015303 Grad: 0.109117 Thermal: 0.000441 LR: 2.83e-06\n",
      "Epoch  37 [6250/10697 ( 58.4%)] Loss: 0.026237 L1: 0.015303 Grad: 0.109117 Thermal: 0.000441 LR: 2.83e-06\n",
      "Epoch  37 [6300/10697 ( 58.9%)] Loss: 0.028094 L1: 0.016476 Grad: 0.115939 Thermal: 0.000492 LR: 2.83e-06\n",
      "Epoch  37 [6300/10697 ( 58.9%)] Loss: 0.028094 L1: 0.016476 Grad: 0.115939 Thermal: 0.000492 LR: 2.83e-06\n",
      "Epoch  37 [6350/10697 ( 59.4%)] Loss: 0.026677 L1: 0.015650 Grad: 0.110039 Thermal: 0.000459 LR: 2.83e-06\n",
      "Epoch  37 [6350/10697 ( 59.4%)] Loss: 0.026677 L1: 0.015650 Grad: 0.110039 Thermal: 0.000459 LR: 2.83e-06\n",
      "Epoch  37 [6400/10697 ( 59.8%)] Loss: 0.025227 L1: 0.014455 Grad: 0.107496 Thermal: 0.000446 LR: 2.83e-06\n",
      "Epoch  37 [6400/10697 ( 59.8%)] Loss: 0.025227 L1: 0.014455 Grad: 0.107496 Thermal: 0.000446 LR: 2.83e-06\n",
      "Epoch  37 [6450/10697 ( 60.3%)] Loss: 0.025284 L1: 0.014841 Grad: 0.104210 Thermal: 0.000430 LR: 2.83e-06\n",
      "Epoch  37 [6450/10697 ( 60.3%)] Loss: 0.025284 L1: 0.014841 Grad: 0.104210 Thermal: 0.000430 LR: 2.83e-06\n",
      "Epoch  37 [6500/10697 ( 60.8%)] Loss: 0.029414 L1: 0.017134 Grad: 0.122538 Thermal: 0.000532 LR: 2.83e-06\n",
      "Epoch  37 [6500/10697 ( 60.8%)] Loss: 0.029414 L1: 0.017134 Grad: 0.122538 Thermal: 0.000532 LR: 2.83e-06\n",
      "Epoch  37 [6550/10697 ( 61.2%)] Loss: 0.035566 L1: 0.021038 Grad: 0.144882 Thermal: 0.000790 LR: 2.83e-06\n",
      "Epoch  37 [6550/10697 ( 61.2%)] Loss: 0.035566 L1: 0.021038 Grad: 0.144882 Thermal: 0.000790 LR: 2.83e-06\n",
      "Epoch  37 [6600/10697 ( 61.7%)] Loss: 0.025667 L1: 0.015020 Grad: 0.106234 Thermal: 0.000458 LR: 2.83e-06\n",
      "Epoch  37 [6600/10697 ( 61.7%)] Loss: 0.025667 L1: 0.015020 Grad: 0.106234 Thermal: 0.000458 LR: 2.83e-06\n",
      "Epoch  37 [6650/10697 ( 62.2%)] Loss: 0.020709 L1: 0.012182 Grad: 0.085108 Thermal: 0.000325 LR: 2.83e-06\n",
      "Epoch  37 [6650/10697 ( 62.2%)] Loss: 0.020709 L1: 0.012182 Grad: 0.085108 Thermal: 0.000325 LR: 2.83e-06\n",
      "Epoch  37 [6700/10697 ( 62.6%)] Loss: 0.023797 L1: 0.013858 Grad: 0.099202 Thermal: 0.000371 LR: 2.83e-06\n",
      "Epoch  37 [6700/10697 ( 62.6%)] Loss: 0.023797 L1: 0.013858 Grad: 0.099202 Thermal: 0.000371 LR: 2.83e-06\n",
      "Epoch  37 [6750/10697 ( 63.1%)] Loss: 0.026275 L1: 0.015251 Grad: 0.110013 Thermal: 0.000455 LR: 2.83e-06\n",
      "Epoch  37 [6750/10697 ( 63.1%)] Loss: 0.026275 L1: 0.015251 Grad: 0.110013 Thermal: 0.000455 LR: 2.83e-06\n",
      "Epoch  37 [6800/10697 ( 63.6%)] Loss: 0.028933 L1: 0.017049 Grad: 0.118582 Thermal: 0.000521 LR: 2.83e-06\n",
      "Epoch  37 [6800/10697 ( 63.6%)] Loss: 0.028933 L1: 0.017049 Grad: 0.118582 Thermal: 0.000521 LR: 2.83e-06\n",
      "Epoch  37 [6850/10697 ( 64.0%)] Loss: 0.028564 L1: 0.016459 Grad: 0.120798 Thermal: 0.000493 LR: 2.83e-06\n",
      "Epoch  37 [6850/10697 ( 64.0%)] Loss: 0.028564 L1: 0.016459 Grad: 0.120798 Thermal: 0.000493 LR: 2.83e-06\n",
      "Epoch  37 [6900/10697 ( 64.5%)] Loss: 0.027141 L1: 0.015738 Grad: 0.113801 Thermal: 0.000461 LR: 2.83e-06\n",
      "Epoch  37 [6900/10697 ( 64.5%)] Loss: 0.027141 L1: 0.015738 Grad: 0.113801 Thermal: 0.000461 LR: 2.83e-06\n",
      "Epoch  37 [6950/10697 ( 65.0%)] Loss: 0.024485 L1: 0.014274 Grad: 0.101875 Thermal: 0.000467 LR: 2.83e-06\n",
      "Epoch  37 [6950/10697 ( 65.0%)] Loss: 0.024485 L1: 0.014274 Grad: 0.101875 Thermal: 0.000467 LR: 2.83e-06\n",
      "Epoch  37 [7000/10697 ( 65.4%)] Loss: 0.025597 L1: 0.015094 Grad: 0.104818 Thermal: 0.000426 LR: 2.83e-06\n",
      "Epoch  37 [7000/10697 ( 65.4%)] Loss: 0.025597 L1: 0.015094 Grad: 0.104818 Thermal: 0.000426 LR: 2.83e-06\n",
      "Epoch  37 [7050/10697 ( 65.9%)] Loss: 0.021249 L1: 0.012212 Grad: 0.090200 Thermal: 0.000338 LR: 2.83e-06\n",
      "Epoch  37 [7050/10697 ( 65.9%)] Loss: 0.021249 L1: 0.012212 Grad: 0.090200 Thermal: 0.000338 LR: 2.83e-06\n",
      "Epoch  37 [7100/10697 ( 66.4%)] Loss: 0.024325 L1: 0.014478 Grad: 0.098246 Thermal: 0.000440 LR: 2.83e-06\n",
      "Epoch  37 [7100/10697 ( 66.4%)] Loss: 0.024325 L1: 0.014478 Grad: 0.098246 Thermal: 0.000440 LR: 2.83e-06\n",
      "Epoch  37 [7150/10697 ( 66.8%)] Loss: 0.027736 L1: 0.016173 Grad: 0.115415 Thermal: 0.000438 LR: 2.83e-06\n",
      "Epoch  37 [7150/10697 ( 66.8%)] Loss: 0.027736 L1: 0.016173 Grad: 0.115415 Thermal: 0.000438 LR: 2.83e-06\n",
      "Epoch  37 [7200/10697 ( 67.3%)] Loss: 0.025735 L1: 0.014853 Grad: 0.108609 Thermal: 0.000421 LR: 2.83e-06\n",
      "Epoch  37 [7200/10697 ( 67.3%)] Loss: 0.025735 L1: 0.014853 Grad: 0.108609 Thermal: 0.000421 LR: 2.83e-06\n",
      "Epoch  37 [7250/10697 ( 67.8%)] Loss: 0.024323 L1: 0.014389 Grad: 0.099157 Thermal: 0.000383 LR: 2.83e-06\n",
      "Epoch  37 [7250/10697 ( 67.8%)] Loss: 0.024323 L1: 0.014389 Grad: 0.099157 Thermal: 0.000383 LR: 2.83e-06\n",
      "Epoch  37 [7300/10697 ( 68.2%)] Loss: 0.025095 L1: 0.015199 Grad: 0.098749 Thermal: 0.000429 LR: 2.83e-06\n",
      "Epoch  37 [7300/10697 ( 68.2%)] Loss: 0.025095 L1: 0.015199 Grad: 0.098749 Thermal: 0.000429 LR: 2.83e-06\n",
      "Epoch  37 [7350/10697 ( 68.7%)] Loss: 0.019633 L1: 0.011476 Grad: 0.081432 Thermal: 0.000270 LR: 2.83e-06\n",
      "Epoch  37 [7350/10697 ( 68.7%)] Loss: 0.019633 L1: 0.011476 Grad: 0.081432 Thermal: 0.000270 LR: 2.83e-06\n",
      "Epoch  37 [7400/10697 ( 69.2%)] Loss: 0.027106 L1: 0.015755 Grad: 0.113278 Thermal: 0.000455 LR: 2.83e-06\n",
      "Epoch  37 [7400/10697 ( 69.2%)] Loss: 0.027106 L1: 0.015755 Grad: 0.113278 Thermal: 0.000455 LR: 2.83e-06\n",
      "Epoch  37 [7450/10697 ( 69.6%)] Loss: 0.026009 L1: 0.015314 Grad: 0.106749 Thermal: 0.000405 LR: 2.83e-06\n",
      "Epoch  37 [7450/10697 ( 69.6%)] Loss: 0.026009 L1: 0.015314 Grad: 0.106749 Thermal: 0.000405 LR: 2.83e-06\n",
      "Epoch  37 [7500/10697 ( 70.1%)] Loss: 0.022843 L1: 0.013510 Grad: 0.093150 Thermal: 0.000360 LR: 2.83e-06\n",
      "Epoch  37 [7500/10697 ( 70.1%)] Loss: 0.022843 L1: 0.013510 Grad: 0.093150 Thermal: 0.000360 LR: 2.83e-06\n",
      "Epoch  37 [7550/10697 ( 70.6%)] Loss: 0.029347 L1: 0.016832 Grad: 0.124877 Thermal: 0.000536 LR: 2.83e-06\n",
      "Epoch  37 [7550/10697 ( 70.6%)] Loss: 0.029347 L1: 0.016832 Grad: 0.124877 Thermal: 0.000536 LR: 2.83e-06\n",
      "Epoch  37 [7600/10697 ( 71.0%)] Loss: 0.021056 L1: 0.012138 Grad: 0.089040 Thermal: 0.000285 LR: 2.83e-06\n",
      "Epoch  37 [7600/10697 ( 71.0%)] Loss: 0.021056 L1: 0.012138 Grad: 0.089040 Thermal: 0.000285 LR: 2.83e-06\n",
      "Epoch  37 [7650/10697 ( 71.5%)] Loss: 0.023920 L1: 0.014084 Grad: 0.098167 Thermal: 0.000399 LR: 2.83e-06\n",
      "Epoch  37 [7650/10697 ( 71.5%)] Loss: 0.023920 L1: 0.014084 Grad: 0.098167 Thermal: 0.000399 LR: 2.83e-06\n",
      "Epoch  37 [7700/10697 ( 72.0%)] Loss: 0.033689 L1: 0.019374 Grad: 0.142779 Thermal: 0.000745 LR: 2.83e-06\n",
      "Epoch  37 [7700/10697 ( 72.0%)] Loss: 0.033689 L1: 0.019374 Grad: 0.142779 Thermal: 0.000745 LR: 2.83e-06\n",
      "Epoch  37 [7750/10697 ( 72.5%)] Loss: 0.027079 L1: 0.015650 Grad: 0.114048 Thermal: 0.000489 LR: 2.83e-06\n",
      "Epoch  37 [7750/10697 ( 72.5%)] Loss: 0.027079 L1: 0.015650 Grad: 0.114048 Thermal: 0.000489 LR: 2.83e-06\n",
      "Epoch  37 [7800/10697 ( 72.9%)] Loss: 0.031936 L1: 0.018180 Grad: 0.137180 Thermal: 0.000756 LR: 2.83e-06\n",
      "Epoch  37 [7800/10697 ( 72.9%)] Loss: 0.031936 L1: 0.018180 Grad: 0.137180 Thermal: 0.000756 LR: 2.83e-06\n",
      "Epoch  37 [7850/10697 ( 73.4%)] Loss: 0.024748 L1: 0.014099 Grad: 0.106270 Thermal: 0.000441 LR: 2.83e-06\n",
      "Epoch  37 [7850/10697 ( 73.4%)] Loss: 0.024748 L1: 0.014099 Grad: 0.106270 Thermal: 0.000441 LR: 2.83e-06\n",
      "Epoch  37 [7900/10697 ( 73.9%)] Loss: 0.025866 L1: 0.014506 Grad: 0.113349 Thermal: 0.000497 LR: 2.83e-06\n",
      "Epoch  37 [7900/10697 ( 73.9%)] Loss: 0.025866 L1: 0.014506 Grad: 0.113349 Thermal: 0.000497 LR: 2.83e-06\n",
      "Epoch  37 [7950/10697 ( 74.3%)] Loss: 0.024363 L1: 0.014059 Grad: 0.102813 Thermal: 0.000442 LR: 2.83e-06\n",
      "Epoch  37 [7950/10697 ( 74.3%)] Loss: 0.024363 L1: 0.014059 Grad: 0.102813 Thermal: 0.000442 LR: 2.83e-06\n",
      "Epoch  37 [8000/10697 ( 74.8%)] Loss: 0.027711 L1: 0.016377 Grad: 0.113108 Thermal: 0.000477 LR: 2.83e-06\n",
      "Epoch  37 [8000/10697 ( 74.8%)] Loss: 0.027711 L1: 0.016377 Grad: 0.113108 Thermal: 0.000477 LR: 2.83e-06\n",
      "Epoch  37 [8050/10697 ( 75.3%)] Loss: 0.022353 L1: 0.013008 Grad: 0.093272 Thermal: 0.000358 LR: 2.83e-06\n",
      "Epoch  37 [8050/10697 ( 75.3%)] Loss: 0.022353 L1: 0.013008 Grad: 0.093272 Thermal: 0.000358 LR: 2.83e-06\n",
      "Epoch  37 [8100/10697 ( 75.7%)] Loss: 0.028652 L1: 0.017063 Grad: 0.115646 Thermal: 0.000499 LR: 2.83e-06\n",
      "Epoch  37 [8100/10697 ( 75.7%)] Loss: 0.028652 L1: 0.017063 Grad: 0.115646 Thermal: 0.000499 LR: 2.83e-06\n",
      "Epoch  37 [8150/10697 ( 76.2%)] Loss: 0.027841 L1: 0.016759 Grad: 0.110580 Thermal: 0.000480 LR: 2.83e-06\n",
      "Epoch  37 [8150/10697 ( 76.2%)] Loss: 0.027841 L1: 0.016759 Grad: 0.110580 Thermal: 0.000480 LR: 2.83e-06\n",
      "Epoch  37 [8200/10697 ( 76.7%)] Loss: 0.020614 L1: 0.012068 Grad: 0.085297 Thermal: 0.000316 LR: 2.83e-06\n",
      "Epoch  37 [8200/10697 ( 76.7%)] Loss: 0.020614 L1: 0.012068 Grad: 0.085297 Thermal: 0.000316 LR: 2.83e-06\n",
      "Epoch  37 [8250/10697 ( 77.1%)] Loss: 0.030227 L1: 0.018518 Grad: 0.116788 Thermal: 0.000593 LR: 2.83e-06\n",
      "Epoch  37 [8250/10697 ( 77.1%)] Loss: 0.030227 L1: 0.018518 Grad: 0.116788 Thermal: 0.000593 LR: 2.83e-06\n",
      "Epoch  37 [8300/10697 ( 77.6%)] Loss: 0.024960 L1: 0.014644 Grad: 0.102943 Thermal: 0.000436 LR: 2.83e-06\n",
      "Epoch  37 [8300/10697 ( 77.6%)] Loss: 0.024960 L1: 0.014644 Grad: 0.102943 Thermal: 0.000436 LR: 2.83e-06\n",
      "Epoch  37 [8350/10697 ( 78.1%)] Loss: 0.024433 L1: 0.014322 Grad: 0.100914 Thermal: 0.000392 LR: 2.83e-06\n",
      "Epoch  37 [8350/10697 ( 78.1%)] Loss: 0.024433 L1: 0.014322 Grad: 0.100914 Thermal: 0.000392 LR: 2.83e-06\n",
      "Epoch  37 [8400/10697 ( 78.5%)] Loss: 0.026134 L1: 0.014933 Grad: 0.111784 Thermal: 0.000461 LR: 2.83e-06\n",
      "Epoch  37 [8400/10697 ( 78.5%)] Loss: 0.026134 L1: 0.014933 Grad: 0.111784 Thermal: 0.000461 LR: 2.83e-06\n",
      "Epoch  37 [8450/10697 ( 79.0%)] Loss: 0.025420 L1: 0.015132 Grad: 0.102681 Thermal: 0.000411 LR: 2.83e-06\n",
      "Epoch  37 [8450/10697 ( 79.0%)] Loss: 0.025420 L1: 0.015132 Grad: 0.102681 Thermal: 0.000411 LR: 2.83e-06\n",
      "Epoch  37 [8500/10697 ( 79.5%)] Loss: 0.029644 L1: 0.017298 Grad: 0.123186 Thermal: 0.000549 LR: 2.83e-06\n",
      "Epoch  37 [8500/10697 ( 79.5%)] Loss: 0.029644 L1: 0.017298 Grad: 0.123186 Thermal: 0.000549 LR: 2.83e-06\n",
      "Epoch  37 [8550/10697 ( 79.9%)] Loss: 0.028153 L1: 0.016618 Grad: 0.115104 Thermal: 0.000489 LR: 2.83e-06\n",
      "Epoch  37 [8550/10697 ( 79.9%)] Loss: 0.028153 L1: 0.016618 Grad: 0.115104 Thermal: 0.000489 LR: 2.83e-06\n",
      "Epoch  37 [8600/10697 ( 80.4%)] Loss: 0.022795 L1: 0.012870 Grad: 0.099078 Thermal: 0.000336 LR: 2.83e-06\n",
      "Epoch  37 [8600/10697 ( 80.4%)] Loss: 0.022795 L1: 0.012870 Grad: 0.099078 Thermal: 0.000336 LR: 2.83e-06\n",
      "Epoch  37 [8650/10697 ( 80.9%)] Loss: 0.024301 L1: 0.014252 Grad: 0.100285 Thermal: 0.000406 LR: 2.83e-06\n",
      "Epoch  37 [8650/10697 ( 80.9%)] Loss: 0.024301 L1: 0.014252 Grad: 0.100285 Thermal: 0.000406 LR: 2.83e-06\n",
      "Epoch  37 [8700/10697 ( 81.3%)] Loss: 0.027143 L1: 0.015813 Grad: 0.113071 Thermal: 0.000465 LR: 2.83e-06\n",
      "Epoch  37 [8700/10697 ( 81.3%)] Loss: 0.027143 L1: 0.015813 Grad: 0.113071 Thermal: 0.000465 LR: 2.83e-06\n",
      "Epoch  37 [8750/10697 ( 81.8%)] Loss: 0.017886 L1: 0.010276 Grad: 0.075979 Thermal: 0.000238 LR: 2.83e-06\n",
      "Epoch  37 [8750/10697 ( 81.8%)] Loss: 0.017886 L1: 0.010276 Grad: 0.075979 Thermal: 0.000238 LR: 2.83e-06\n",
      "Epoch  37 [8800/10697 ( 82.3%)] Loss: 0.030080 L1: 0.017427 Grad: 0.126194 Thermal: 0.000671 LR: 2.83e-06\n",
      "Epoch  37 [8800/10697 ( 82.3%)] Loss: 0.030080 L1: 0.017427 Grad: 0.126194 Thermal: 0.000671 LR: 2.83e-06\n",
      "Epoch  37 [8850/10697 ( 82.7%)] Loss: 0.021525 L1: 0.012906 Grad: 0.086029 Thermal: 0.000327 LR: 2.83e-06\n",
      "Epoch  37 [8850/10697 ( 82.7%)] Loss: 0.021525 L1: 0.012906 Grad: 0.086029 Thermal: 0.000327 LR: 2.83e-06\n",
      "Epoch  37 [8900/10697 ( 83.2%)] Loss: 0.022241 L1: 0.012602 Grad: 0.096222 Thermal: 0.000340 LR: 2.83e-06\n",
      "Epoch  37 [8900/10697 ( 83.2%)] Loss: 0.022241 L1: 0.012602 Grad: 0.096222 Thermal: 0.000340 LR: 2.83e-06\n",
      "Epoch  37 [8950/10697 ( 83.7%)] Loss: 0.023936 L1: 0.014397 Grad: 0.095189 Thermal: 0.000385 LR: 2.83e-06\n",
      "Epoch  37 [8950/10697 ( 83.7%)] Loss: 0.023936 L1: 0.014397 Grad: 0.095189 Thermal: 0.000385 LR: 2.83e-06\n",
      "Epoch  37 [9000/10697 ( 84.1%)] Loss: 0.027339 L1: 0.015675 Grad: 0.116380 Thermal: 0.000516 LR: 2.83e-06\n",
      "Epoch  37 [9000/10697 ( 84.1%)] Loss: 0.027339 L1: 0.015675 Grad: 0.116380 Thermal: 0.000516 LR: 2.83e-06\n",
      "Epoch  37 [9050/10697 ( 84.6%)] Loss: 0.031110 L1: 0.018215 Grad: 0.128655 Thermal: 0.000599 LR: 2.83e-06\n",
      "Epoch  37 [9050/10697 ( 84.6%)] Loss: 0.031110 L1: 0.018215 Grad: 0.128655 Thermal: 0.000599 LR: 2.83e-06\n",
      "Epoch  37 [9100/10697 ( 85.1%)] Loss: 0.024441 L1: 0.014292 Grad: 0.101290 Thermal: 0.000400 LR: 2.83e-06\n",
      "Epoch  37 [9100/10697 ( 85.1%)] Loss: 0.024441 L1: 0.014292 Grad: 0.101290 Thermal: 0.000400 LR: 2.83e-06\n",
      "Epoch  37 [9150/10697 ( 85.5%)] Loss: 0.030798 L1: 0.018047 Grad: 0.127210 Thermal: 0.000595 LR: 2.83e-06\n",
      "Epoch  37 [9150/10697 ( 85.5%)] Loss: 0.030798 L1: 0.018047 Grad: 0.127210 Thermal: 0.000595 LR: 2.83e-06\n",
      "Epoch  37 [9200/10697 ( 86.0%)] Loss: 0.029156 L1: 0.017127 Grad: 0.120037 Thermal: 0.000509 LR: 2.83e-06\n",
      "Epoch  37 [9200/10697 ( 86.0%)] Loss: 0.029156 L1: 0.017127 Grad: 0.120037 Thermal: 0.000509 LR: 2.83e-06\n",
      "Epoch  37 [9250/10697 ( 86.5%)] Loss: 0.027436 L1: 0.016392 Grad: 0.110199 Thermal: 0.000482 LR: 2.83e-06\n",
      "Epoch  37 [9250/10697 ( 86.5%)] Loss: 0.027436 L1: 0.016392 Grad: 0.110199 Thermal: 0.000482 LR: 2.83e-06\n",
      "Epoch  37 [9300/10697 ( 86.9%)] Loss: 0.024076 L1: 0.014146 Grad: 0.099117 Thermal: 0.000378 LR: 2.83e-06\n",
      "Epoch  37 [9300/10697 ( 86.9%)] Loss: 0.024076 L1: 0.014146 Grad: 0.099117 Thermal: 0.000378 LR: 2.83e-06\n",
      "Epoch  37 [9350/10697 ( 87.4%)] Loss: 0.026027 L1: 0.015103 Grad: 0.109029 Thermal: 0.000415 LR: 2.83e-06\n",
      "Epoch  37 [9350/10697 ( 87.4%)] Loss: 0.026027 L1: 0.015103 Grad: 0.109029 Thermal: 0.000415 LR: 2.83e-06\n",
      "Epoch  37 [9400/10697 ( 87.9%)] Loss: 0.025545 L1: 0.015124 Grad: 0.104002 Thermal: 0.000430 LR: 2.83e-06\n",
      "Epoch  37 [9400/10697 ( 87.9%)] Loss: 0.025545 L1: 0.015124 Grad: 0.104002 Thermal: 0.000430 LR: 2.83e-06\n",
      "Epoch  37 [9450/10697 ( 88.3%)] Loss: 0.025918 L1: 0.015273 Grad: 0.106245 Thermal: 0.000416 LR: 2.83e-06\n",
      "Epoch  37 [9450/10697 ( 88.3%)] Loss: 0.025918 L1: 0.015273 Grad: 0.106245 Thermal: 0.000416 LR: 2.83e-06\n",
      "Epoch  37 [9500/10697 ( 88.8%)] Loss: 0.033298 L1: 0.018547 Grad: 0.147158 Thermal: 0.000689 LR: 2.83e-06\n",
      "Epoch  37 [9500/10697 ( 88.8%)] Loss: 0.033298 L1: 0.018547 Grad: 0.147158 Thermal: 0.000689 LR: 2.83e-06\n",
      "Epoch  37 [9550/10697 ( 89.3%)] Loss: 0.026162 L1: 0.015262 Grad: 0.108783 Thermal: 0.000431 LR: 2.83e-06\n",
      "Epoch  37 [9550/10697 ( 89.3%)] Loss: 0.026162 L1: 0.015262 Grad: 0.108783 Thermal: 0.000431 LR: 2.83e-06\n",
      "Epoch  37 [9600/10697 ( 89.7%)] Loss: 0.028978 L1: 0.017048 Grad: 0.119037 Thermal: 0.000537 LR: 2.83e-06\n",
      "Epoch  37 [9600/10697 ( 89.7%)] Loss: 0.028978 L1: 0.017048 Grad: 0.119037 Thermal: 0.000537 LR: 2.83e-06\n",
      "Epoch  37 [9650/10697 ( 90.2%)] Loss: 0.024888 L1: 0.014497 Grad: 0.103705 Thermal: 0.000423 LR: 2.83e-06\n",
      "Epoch  37 [9650/10697 ( 90.2%)] Loss: 0.024888 L1: 0.014497 Grad: 0.103705 Thermal: 0.000423 LR: 2.83e-06\n",
      "Epoch  37 [9700/10697 ( 90.7%)] Loss: 0.030723 L1: 0.017988 Grad: 0.127063 Thermal: 0.000573 LR: 2.83e-06\n",
      "Epoch  37 [9700/10697 ( 90.7%)] Loss: 0.030723 L1: 0.017988 Grad: 0.127063 Thermal: 0.000573 LR: 2.83e-06\n",
      "Epoch  37 [9750/10697 ( 91.1%)] Loss: 0.024707 L1: 0.014151 Grad: 0.105366 Thermal: 0.000390 LR: 2.83e-06\n",
      "Epoch  37 [9750/10697 ( 91.1%)] Loss: 0.024707 L1: 0.014151 Grad: 0.105366 Thermal: 0.000390 LR: 2.83e-06\n",
      "Epoch  37 [9800/10697 ( 91.6%)] Loss: 0.019689 L1: 0.011282 Grad: 0.083931 Thermal: 0.000271 LR: 2.83e-06\n",
      "Epoch  37 [9800/10697 ( 91.6%)] Loss: 0.019689 L1: 0.011282 Grad: 0.083931 Thermal: 0.000271 LR: 2.83e-06\n",
      "Epoch  37 [9850/10697 ( 92.1%)] Loss: 0.029184 L1: 0.017055 Grad: 0.121018 Thermal: 0.000544 LR: 2.83e-06\n",
      "Epoch  37 [9850/10697 ( 92.1%)] Loss: 0.029184 L1: 0.017055 Grad: 0.121018 Thermal: 0.000544 LR: 2.83e-06\n",
      "Epoch  37 [9900/10697 ( 92.5%)] Loss: 0.022799 L1: 0.013579 Grad: 0.092025 Thermal: 0.000366 LR: 2.83e-06\n",
      "Epoch  37 [9900/10697 ( 92.5%)] Loss: 0.022799 L1: 0.013579 Grad: 0.092025 Thermal: 0.000366 LR: 2.83e-06\n",
      "Epoch  37 [9950/10697 ( 93.0%)] Loss: 0.028629 L1: 0.016992 Grad: 0.116109 Thermal: 0.000512 LR: 2.83e-06\n",
      "Epoch  37 [9950/10697 ( 93.0%)] Loss: 0.028629 L1: 0.016992 Grad: 0.116109 Thermal: 0.000512 LR: 2.83e-06\n",
      "Epoch  37 [10000/10697 ( 93.5%)] Loss: 0.026540 L1: 0.015274 Grad: 0.112450 Thermal: 0.000428 LR: 2.83e-06\n",
      "Epoch  37 [10000/10697 ( 93.5%)] Loss: 0.026540 L1: 0.015274 Grad: 0.112450 Thermal: 0.000428 LR: 2.83e-06\n",
      "Epoch  37 [10050/10697 ( 94.0%)] Loss: 0.024565 L1: 0.014766 Grad: 0.097788 Thermal: 0.000407 LR: 2.83e-06\n",
      "Epoch  37 [10050/10697 ( 94.0%)] Loss: 0.024565 L1: 0.014766 Grad: 0.097788 Thermal: 0.000407 LR: 2.83e-06\n",
      "Epoch  37 [10100/10697 ( 94.4%)] Loss: 0.025158 L1: 0.014674 Grad: 0.104620 Thermal: 0.000429 LR: 2.83e-06\n",
      "Epoch  37 [10100/10697 ( 94.4%)] Loss: 0.025158 L1: 0.014674 Grad: 0.104620 Thermal: 0.000429 LR: 2.83e-06\n",
      "Epoch  37 [10150/10697 ( 94.9%)] Loss: 0.028475 L1: 0.016568 Grad: 0.118817 Thermal: 0.000500 LR: 2.83e-06\n",
      "Epoch  37 [10150/10697 ( 94.9%)] Loss: 0.028475 L1: 0.016568 Grad: 0.118817 Thermal: 0.000500 LR: 2.83e-06\n",
      "Epoch  37 [10200/10697 ( 95.4%)] Loss: 0.033245 L1: 0.019667 Grad: 0.135412 Thermal: 0.000744 LR: 2.83e-06\n",
      "Epoch  37 [10200/10697 ( 95.4%)] Loss: 0.033245 L1: 0.019667 Grad: 0.135412 Thermal: 0.000744 LR: 2.83e-06\n",
      "Epoch  37 [10250/10697 ( 95.8%)] Loss: 0.028488 L1: 0.016659 Grad: 0.118029 Thermal: 0.000533 LR: 2.83e-06\n",
      "Epoch  37 [10250/10697 ( 95.8%)] Loss: 0.028488 L1: 0.016659 Grad: 0.118029 Thermal: 0.000533 LR: 2.83e-06\n",
      "Epoch  37 [10300/10697 ( 96.3%)] Loss: 0.027311 L1: 0.015471 Grad: 0.118151 Thermal: 0.000493 LR: 2.83e-06\n",
      "Epoch  37 [10300/10697 ( 96.3%)] Loss: 0.027311 L1: 0.015471 Grad: 0.118151 Thermal: 0.000493 LR: 2.83e-06\n",
      "Epoch  37 [10350/10697 ( 96.8%)] Loss: 0.023464 L1: 0.013487 Grad: 0.099584 Thermal: 0.000369 LR: 2.83e-06\n",
      "Epoch  37 [10350/10697 ( 96.8%)] Loss: 0.023464 L1: 0.013487 Grad: 0.099584 Thermal: 0.000369 LR: 2.83e-06\n",
      "Epoch  37 [10400/10697 ( 97.2%)] Loss: 0.030439 L1: 0.017700 Grad: 0.127108 Thermal: 0.000562 LR: 2.83e-06\n",
      "Epoch  37 [10400/10697 ( 97.2%)] Loss: 0.030439 L1: 0.017700 Grad: 0.127108 Thermal: 0.000562 LR: 2.83e-06\n",
      "Epoch  37 [10450/10697 ( 97.7%)] Loss: 0.024682 L1: 0.014535 Grad: 0.101258 Thermal: 0.000444 LR: 2.83e-06\n",
      "Epoch  37 [10450/10697 ( 97.7%)] Loss: 0.024682 L1: 0.014535 Grad: 0.101258 Thermal: 0.000444 LR: 2.83e-06\n",
      "Epoch  37 [10500/10697 ( 98.2%)] Loss: 0.025412 L1: 0.014623 Grad: 0.107656 Thermal: 0.000453 LR: 2.83e-06\n",
      "Epoch  37 [10500/10697 ( 98.2%)] Loss: 0.025412 L1: 0.014623 Grad: 0.107656 Thermal: 0.000453 LR: 2.83e-06\n",
      "Epoch  37 [10550/10697 ( 98.6%)] Loss: 0.023873 L1: 0.014106 Grad: 0.097481 Thermal: 0.000369 LR: 2.83e-06\n",
      "Epoch  37 [10550/10697 ( 98.6%)] Loss: 0.023873 L1: 0.014106 Grad: 0.097481 Thermal: 0.000369 LR: 2.83e-06\n",
      "Epoch  37 [10600/10697 ( 99.1%)] Loss: 0.025073 L1: 0.014796 Grad: 0.102572 Thermal: 0.000404 LR: 2.83e-06\n",
      "Epoch  37 [10600/10697 ( 99.1%)] Loss: 0.025073 L1: 0.014796 Grad: 0.102572 Thermal: 0.000404 LR: 2.83e-06\n",
      "Epoch  37 [10650/10697 ( 99.6%)] Loss: 0.029216 L1: 0.017380 Grad: 0.118091 Thermal: 0.000542 LR: 2.83e-06\n",
      "Epoch  37 [10650/10697 ( 99.6%)] Loss: 0.029216 L1: 0.017380 Grad: 0.118091 Thermal: 0.000542 LR: 2.83e-06\n",
      "Epoch  37 Summary: Loss=0.026229 (L1:0.0153, Grad:0.1090, Thermal:0.0005) Val_PSNR=0.00dB Best=33.96dB Time=144.2min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  37 Summary: Loss=0.026229 (L1:0.0153, Grad:0.1090, Thermal:0.0005) Val_PSNR=0.00dB Best=33.96dB Time=144.2min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  38 [   0/10697 (  0.0%)] Loss: 0.031125 L1: 0.018451 Grad: 0.126428 Thermal: 0.000620 LR: 2.74e-06\n",
      "Epoch  38 [   0/10697 (  0.0%)] Loss: 0.031125 L1: 0.018451 Grad: 0.126428 Thermal: 0.000620 LR: 2.74e-06\n",
      "Epoch  38 [  50/10697 (  0.5%)] Loss: 0.029338 L1: 0.017212 Grad: 0.120992 Thermal: 0.000519 LR: 2.74e-06\n",
      "Epoch  38 [  50/10697 (  0.5%)] Loss: 0.029338 L1: 0.017212 Grad: 0.120992 Thermal: 0.000519 LR: 2.74e-06\n",
      "Epoch  38 [ 100/10697 (  0.9%)] Loss: 0.028537 L1: 0.016950 Grad: 0.115592 Thermal: 0.000561 LR: 2.74e-06\n",
      "Epoch  38 [ 100/10697 (  0.9%)] Loss: 0.028537 L1: 0.016950 Grad: 0.115592 Thermal: 0.000561 LR: 2.74e-06\n",
      "Epoch  38 [ 150/10697 (  1.4%)] Loss: 0.026108 L1: 0.014961 Grad: 0.111258 Thermal: 0.000427 LR: 2.74e-06\n",
      "Epoch  38 [ 150/10697 (  1.4%)] Loss: 0.026108 L1: 0.014961 Grad: 0.111258 Thermal: 0.000427 LR: 2.74e-06\n",
      "Epoch  38 [ 200/10697 (  1.9%)] Loss: 0.027096 L1: 0.015829 Grad: 0.112451 Thermal: 0.000441 LR: 2.74e-06\n",
      "Epoch  38 [ 200/10697 (  1.9%)] Loss: 0.027096 L1: 0.015829 Grad: 0.112451 Thermal: 0.000441 LR: 2.74e-06\n",
      "Epoch  38 [ 250/10697 (  2.3%)] Loss: 0.025088 L1: 0.014627 Grad: 0.104399 Thermal: 0.000424 LR: 2.74e-06\n",
      "Epoch  38 [ 250/10697 (  2.3%)] Loss: 0.025088 L1: 0.014627 Grad: 0.104399 Thermal: 0.000424 LR: 2.74e-06\n",
      "Epoch  38 [ 300/10697 (  2.8%)] Loss: 0.024405 L1: 0.013911 Grad: 0.104755 Thermal: 0.000379 LR: 2.74e-06\n",
      "Epoch  38 [ 300/10697 (  2.8%)] Loss: 0.024405 L1: 0.013911 Grad: 0.104755 Thermal: 0.000379 LR: 2.74e-06\n",
      "Epoch  38 [ 350/10697 (  3.3%)] Loss: 0.028100 L1: 0.016539 Grad: 0.115365 Thermal: 0.000487 LR: 2.74e-06\n",
      "Epoch  38 [ 350/10697 (  3.3%)] Loss: 0.028100 L1: 0.016539 Grad: 0.115365 Thermal: 0.000487 LR: 2.74e-06\n",
      "Epoch  38 [ 400/10697 (  3.7%)] Loss: 0.031139 L1: 0.017988 Grad: 0.131204 Thermal: 0.000621 LR: 2.74e-06\n",
      "Epoch  38 [ 400/10697 (  3.7%)] Loss: 0.031139 L1: 0.017988 Grad: 0.131204 Thermal: 0.000621 LR: 2.74e-06\n",
      "Epoch  38 [ 450/10697 (  4.2%)] Loss: 0.030129 L1: 0.017640 Grad: 0.124574 Thermal: 0.000635 LR: 2.74e-06\n",
      "Epoch  38 [ 450/10697 (  4.2%)] Loss: 0.030129 L1: 0.017640 Grad: 0.124574 Thermal: 0.000635 LR: 2.74e-06\n",
      "Epoch  38 [ 500/10697 (  4.7%)] Loss: 0.023871 L1: 0.013459 Grad: 0.103926 Thermal: 0.000394 LR: 2.74e-06\n",
      "Epoch  38 [ 500/10697 (  4.7%)] Loss: 0.023871 L1: 0.013459 Grad: 0.103926 Thermal: 0.000394 LR: 2.74e-06\n",
      "Epoch  38 [ 550/10697 (  5.1%)] Loss: 0.027389 L1: 0.016201 Grad: 0.111624 Thermal: 0.000506 LR: 2.74e-06\n",
      "Epoch  38 [ 550/10697 (  5.1%)] Loss: 0.027389 L1: 0.016201 Grad: 0.111624 Thermal: 0.000506 LR: 2.74e-06\n",
      "Epoch  38 [ 600/10697 (  5.6%)] Loss: 0.029763 L1: 0.017192 Grad: 0.125454 Thermal: 0.000520 LR: 2.74e-06\n",
      "Epoch  38 [ 600/10697 (  5.6%)] Loss: 0.029763 L1: 0.017192 Grad: 0.125454 Thermal: 0.000520 LR: 2.74e-06\n",
      "Epoch  38 [ 650/10697 (  6.1%)] Loss: 0.028697 L1: 0.016666 Grad: 0.120085 Thermal: 0.000459 LR: 2.74e-06\n",
      "Epoch  38 [ 650/10697 (  6.1%)] Loss: 0.028697 L1: 0.016666 Grad: 0.120085 Thermal: 0.000459 LR: 2.74e-06\n",
      "Epoch  38 [ 700/10697 (  6.5%)] Loss: 0.028203 L1: 0.016546 Grad: 0.116307 Thermal: 0.000528 LR: 2.74e-06\n",
      "Epoch  38 [ 700/10697 (  6.5%)] Loss: 0.028203 L1: 0.016546 Grad: 0.116307 Thermal: 0.000528 LR: 2.74e-06\n",
      "Epoch  38 [ 750/10697 (  7.0%)] Loss: 0.026234 L1: 0.015210 Grad: 0.109995 Thermal: 0.000492 LR: 2.74e-06\n",
      "Epoch  38 [ 750/10697 (  7.0%)] Loss: 0.026234 L1: 0.015210 Grad: 0.109995 Thermal: 0.000492 LR: 2.74e-06\n",
      "Epoch  38 [ 800/10697 (  7.5%)] Loss: 0.026436 L1: 0.015500 Grad: 0.109149 Thermal: 0.000434 LR: 2.74e-06\n",
      "Epoch  38 [ 800/10697 (  7.5%)] Loss: 0.026436 L1: 0.015500 Grad: 0.109149 Thermal: 0.000434 LR: 2.74e-06\n",
      "Epoch  38 [ 850/10697 (  7.9%)] Loss: 0.023026 L1: 0.013558 Grad: 0.094492 Thermal: 0.000363 LR: 2.74e-06\n",
      "Epoch  38 [ 850/10697 (  7.9%)] Loss: 0.023026 L1: 0.013558 Grad: 0.094492 Thermal: 0.000363 LR: 2.74e-06\n",
      "Epoch  38 [ 900/10697 (  8.4%)] Loss: 0.027123 L1: 0.015823 Grad: 0.112784 Thermal: 0.000442 LR: 2.74e-06\n",
      "Epoch  38 [ 900/10697 (  8.4%)] Loss: 0.027123 L1: 0.015823 Grad: 0.112784 Thermal: 0.000442 LR: 2.74e-06\n",
      "Epoch  38 [ 950/10697 (  8.9%)] Loss: 0.025121 L1: 0.014823 Grad: 0.102763 Thermal: 0.000422 LR: 2.74e-06\n",
      "Epoch  38 [ 950/10697 (  8.9%)] Loss: 0.025121 L1: 0.014823 Grad: 0.102763 Thermal: 0.000422 LR: 2.74e-06\n",
      "Epoch  38 [1000/10697 (  9.3%)] Loss: 0.031744 L1: 0.018141 Grad: 0.135727 Thermal: 0.000617 LR: 2.74e-06\n",
      "Epoch  38 [1000/10697 (  9.3%)] Loss: 0.031744 L1: 0.018141 Grad: 0.135727 Thermal: 0.000617 LR: 2.74e-06\n",
      "Epoch  38 [1050/10697 (  9.8%)] Loss: 0.024760 L1: 0.014561 Grad: 0.101792 Thermal: 0.000409 LR: 2.74e-06\n",
      "Epoch  38 [1050/10697 (  9.8%)] Loss: 0.024760 L1: 0.014561 Grad: 0.101792 Thermal: 0.000409 LR: 2.74e-06\n",
      "Epoch  38 [1100/10697 ( 10.3%)] Loss: 0.026200 L1: 0.015710 Grad: 0.104675 Thermal: 0.000439 LR: 2.74e-06\n",
      "Epoch  38 [1100/10697 ( 10.3%)] Loss: 0.026200 L1: 0.015710 Grad: 0.104675 Thermal: 0.000439 LR: 2.74e-06\n",
      "Epoch  38 [1150/10697 ( 10.8%)] Loss: 0.024031 L1: 0.013831 Grad: 0.101806 Thermal: 0.000382 LR: 2.74e-06\n",
      "Epoch  38 [1150/10697 ( 10.8%)] Loss: 0.024031 L1: 0.013831 Grad: 0.101806 Thermal: 0.000382 LR: 2.74e-06\n",
      "Epoch  38 [1200/10697 ( 11.2%)] Loss: 0.024139 L1: 0.014038 Grad: 0.100804 Thermal: 0.000415 LR: 2.74e-06\n",
      "Epoch  38 [1200/10697 ( 11.2%)] Loss: 0.024139 L1: 0.014038 Grad: 0.100804 Thermal: 0.000415 LR: 2.74e-06\n",
      "Epoch  38 [1250/10697 ( 11.7%)] Loss: 0.023859 L1: 0.013635 Grad: 0.102068 Thermal: 0.000356 LR: 2.74e-06\n",
      "Epoch  38 [1250/10697 ( 11.7%)] Loss: 0.023859 L1: 0.013635 Grad: 0.102068 Thermal: 0.000356 LR: 2.74e-06\n",
      "Epoch  38 [1300/10697 ( 12.2%)] Loss: 0.019607 L1: 0.011409 Grad: 0.081850 Thermal: 0.000258 LR: 2.74e-06\n",
      "Epoch  38 [1300/10697 ( 12.2%)] Loss: 0.019607 L1: 0.011409 Grad: 0.081850 Thermal: 0.000258 LR: 2.74e-06\n",
      "Epoch  38 [1350/10697 ( 12.6%)] Loss: 0.025045 L1: 0.014605 Grad: 0.104166 Thermal: 0.000457 LR: 2.74e-06\n",
      "Epoch  38 [1350/10697 ( 12.6%)] Loss: 0.025045 L1: 0.014605 Grad: 0.104166 Thermal: 0.000457 LR: 2.74e-06\n",
      "Epoch  38 [1400/10697 ( 13.1%)] Loss: 0.023576 L1: 0.013820 Grad: 0.097360 Thermal: 0.000388 LR: 2.74e-06\n",
      "Epoch  38 [1400/10697 ( 13.1%)] Loss: 0.023576 L1: 0.013820 Grad: 0.097360 Thermal: 0.000388 LR: 2.74e-06\n",
      "Epoch  38 [1450/10697 ( 13.6%)] Loss: 0.028040 L1: 0.016192 Grad: 0.118200 Thermal: 0.000560 LR: 2.74e-06\n",
      "Epoch  38 [1450/10697 ( 13.6%)] Loss: 0.028040 L1: 0.016192 Grad: 0.118200 Thermal: 0.000560 LR: 2.74e-06\n",
      "Epoch  38 [1500/10697 ( 14.0%)] Loss: 0.029573 L1: 0.016966 Grad: 0.125803 Thermal: 0.000523 LR: 2.74e-06\n",
      "Epoch  38 [1500/10697 ( 14.0%)] Loss: 0.029573 L1: 0.016966 Grad: 0.125803 Thermal: 0.000523 LR: 2.74e-06\n",
      "Epoch  38 [1550/10697 ( 14.5%)] Loss: 0.023976 L1: 0.013592 Grad: 0.103652 Thermal: 0.000376 LR: 2.74e-06\n",
      "Epoch  38 [1550/10697 ( 14.5%)] Loss: 0.023976 L1: 0.013592 Grad: 0.103652 Thermal: 0.000376 LR: 2.74e-06\n",
      "Epoch  38 [1600/10697 ( 15.0%)] Loss: 0.028339 L1: 0.016251 Grad: 0.120640 Thermal: 0.000478 LR: 2.74e-06\n",
      "Epoch  38 [1600/10697 ( 15.0%)] Loss: 0.028339 L1: 0.016251 Grad: 0.120640 Thermal: 0.000478 LR: 2.74e-06\n",
      "Epoch  38 [1650/10697 ( 15.4%)] Loss: 0.026249 L1: 0.015044 Grad: 0.111827 Thermal: 0.000436 LR: 2.74e-06\n",
      "Epoch  38 [1650/10697 ( 15.4%)] Loss: 0.026249 L1: 0.015044 Grad: 0.111827 Thermal: 0.000436 LR: 2.74e-06\n",
      "Epoch  38 [1700/10697 ( 15.9%)] Loss: 0.023109 L1: 0.013073 Grad: 0.100189 Thermal: 0.000352 LR: 2.74e-06\n",
      "Epoch  38 [1700/10697 ( 15.9%)] Loss: 0.023109 L1: 0.013073 Grad: 0.100189 Thermal: 0.000352 LR: 2.74e-06\n",
      "Epoch  38 [1750/10697 ( 16.4%)] Loss: 0.030792 L1: 0.018050 Grad: 0.127107 Thermal: 0.000633 LR: 2.74e-06\n",
      "Epoch  38 [1750/10697 ( 16.4%)] Loss: 0.030792 L1: 0.018050 Grad: 0.127107 Thermal: 0.000633 LR: 2.74e-06\n",
      "Epoch  38 [1800/10697 ( 16.8%)] Loss: 0.030466 L1: 0.018261 Grad: 0.121750 Thermal: 0.000593 LR: 2.74e-06\n",
      "Epoch  38 [1800/10697 ( 16.8%)] Loss: 0.030466 L1: 0.018261 Grad: 0.121750 Thermal: 0.000593 LR: 2.74e-06\n",
      "Epoch  38 [1850/10697 ( 17.3%)] Loss: 0.024728 L1: 0.014139 Grad: 0.105706 Thermal: 0.000360 LR: 2.74e-06\n",
      "Epoch  38 [1850/10697 ( 17.3%)] Loss: 0.024728 L1: 0.014139 Grad: 0.105706 Thermal: 0.000360 LR: 2.74e-06\n",
      "Epoch  38 [1900/10697 ( 17.8%)] Loss: 0.024973 L1: 0.014869 Grad: 0.100832 Thermal: 0.000422 LR: 2.74e-06\n",
      "Epoch  38 [1900/10697 ( 17.8%)] Loss: 0.024973 L1: 0.014869 Grad: 0.100832 Thermal: 0.000422 LR: 2.74e-06\n",
      "Epoch  38 [1950/10697 ( 18.2%)] Loss: 0.022225 L1: 0.012960 Grad: 0.092475 Thermal: 0.000345 LR: 2.74e-06\n",
      "Epoch  38 [1950/10697 ( 18.2%)] Loss: 0.022225 L1: 0.012960 Grad: 0.092475 Thermal: 0.000345 LR: 2.74e-06\n",
      "Epoch  38 [2000/10697 ( 18.7%)] Loss: 0.025158 L1: 0.014734 Grad: 0.104026 Thermal: 0.000439 LR: 2.74e-06\n",
      "Epoch  38 [2000/10697 ( 18.7%)] Loss: 0.025158 L1: 0.014734 Grad: 0.104026 Thermal: 0.000439 LR: 2.74e-06\n",
      "Epoch  38 [2050/10697 ( 19.2%)] Loss: 0.024654 L1: 0.014637 Grad: 0.099984 Thermal: 0.000384 LR: 2.74e-06\n",
      "Epoch  38 [2050/10697 ( 19.2%)] Loss: 0.024654 L1: 0.014637 Grad: 0.099984 Thermal: 0.000384 LR: 2.74e-06\n",
      "Epoch  38 [2100/10697 ( 19.6%)] Loss: 0.029385 L1: 0.017083 Grad: 0.122765 Thermal: 0.000500 LR: 2.74e-06\n",
      "Epoch  38 [2100/10697 ( 19.6%)] Loss: 0.029385 L1: 0.017083 Grad: 0.122765 Thermal: 0.000500 LR: 2.74e-06\n",
      "Epoch  38 [2150/10697 ( 20.1%)] Loss: 0.028554 L1: 0.016771 Grad: 0.117567 Thermal: 0.000513 LR: 2.74e-06\n",
      "Epoch  38 [2150/10697 ( 20.1%)] Loss: 0.028554 L1: 0.016771 Grad: 0.117567 Thermal: 0.000513 LR: 2.74e-06\n",
      "Epoch  38 [2200/10697 ( 20.6%)] Loss: 0.028404 L1: 0.016864 Grad: 0.115144 Thermal: 0.000504 LR: 2.74e-06\n",
      "Epoch  38 [2200/10697 ( 20.6%)] Loss: 0.028404 L1: 0.016864 Grad: 0.115144 Thermal: 0.000504 LR: 2.74e-06\n",
      "Epoch  38 [2250/10697 ( 21.0%)] Loss: 0.028557 L1: 0.016768 Grad: 0.117643 Thermal: 0.000497 LR: 2.74e-06\n",
      "Epoch  38 [2250/10697 ( 21.0%)] Loss: 0.028557 L1: 0.016768 Grad: 0.117643 Thermal: 0.000497 LR: 2.74e-06\n",
      "Epoch  38 [2300/10697 ( 21.5%)] Loss: 0.029810 L1: 0.017585 Grad: 0.121969 Thermal: 0.000562 LR: 2.74e-06\n",
      "Epoch  38 [2300/10697 ( 21.5%)] Loss: 0.029810 L1: 0.017585 Grad: 0.121969 Thermal: 0.000562 LR: 2.74e-06\n",
      "Epoch  38 [2350/10697 ( 22.0%)] Loss: 0.022755 L1: 0.013646 Grad: 0.090898 Thermal: 0.000383 LR: 2.74e-06\n",
      "Epoch  38 [2350/10697 ( 22.0%)] Loss: 0.022755 L1: 0.013646 Grad: 0.090898 Thermal: 0.000383 LR: 2.74e-06\n",
      "Epoch  38 [2400/10697 ( 22.4%)] Loss: 0.014022 L1: 0.007728 Grad: 0.062858 Thermal: 0.000154 LR: 2.74e-06\n",
      "Epoch  38 [2400/10697 ( 22.4%)] Loss: 0.014022 L1: 0.007728 Grad: 0.062858 Thermal: 0.000154 LR: 2.74e-06\n",
      "Epoch  38 [2450/10697 ( 22.9%)] Loss: 0.023956 L1: 0.013764 Grad: 0.101742 Thermal: 0.000347 LR: 2.74e-06\n",
      "Epoch  38 [2450/10697 ( 22.9%)] Loss: 0.023956 L1: 0.013764 Grad: 0.101742 Thermal: 0.000347 LR: 2.74e-06\n",
      "Epoch  38 [2500/10697 ( 23.4%)] Loss: 0.023265 L1: 0.013384 Grad: 0.098642 Thermal: 0.000347 LR: 2.74e-06\n",
      "Epoch  38 [2500/10697 ( 23.4%)] Loss: 0.023265 L1: 0.013384 Grad: 0.098642 Thermal: 0.000347 LR: 2.74e-06\n",
      "Epoch  38 [2550/10697 ( 23.8%)] Loss: 0.030548 L1: 0.017649 Grad: 0.128712 Thermal: 0.000565 LR: 2.74e-06\n",
      "Epoch  38 [2550/10697 ( 23.8%)] Loss: 0.030548 L1: 0.017649 Grad: 0.128712 Thermal: 0.000565 LR: 2.74e-06\n",
      "Epoch  38 [2600/10697 ( 24.3%)] Loss: 0.024809 L1: 0.013950 Grad: 0.108393 Thermal: 0.000381 LR: 2.74e-06\n",
      "Epoch  38 [2600/10697 ( 24.3%)] Loss: 0.024809 L1: 0.013950 Grad: 0.108393 Thermal: 0.000381 LR: 2.74e-06\n",
      "Epoch  38 [2650/10697 ( 24.8%)] Loss: 0.026510 L1: 0.015387 Grad: 0.110984 Thermal: 0.000491 LR: 2.74e-06\n",
      "Epoch  38 [2650/10697 ( 24.8%)] Loss: 0.026510 L1: 0.015387 Grad: 0.110984 Thermal: 0.000491 LR: 2.74e-06\n",
      "Epoch  38 [2700/10697 ( 25.2%)] Loss: 0.022889 L1: 0.013763 Grad: 0.091075 Thermal: 0.000358 LR: 2.74e-06\n",
      "Epoch  38 [2700/10697 ( 25.2%)] Loss: 0.022889 L1: 0.013763 Grad: 0.091075 Thermal: 0.000358 LR: 2.74e-06\n",
      "Epoch  38 [2750/10697 ( 25.7%)] Loss: 0.025143 L1: 0.015016 Grad: 0.101059 Thermal: 0.000423 LR: 2.74e-06\n",
      "Epoch  38 [2750/10697 ( 25.7%)] Loss: 0.025143 L1: 0.015016 Grad: 0.101059 Thermal: 0.000423 LR: 2.74e-06\n",
      "Epoch  38 [2800/10697 ( 26.2%)] Loss: 0.028193 L1: 0.016131 Grad: 0.120321 Thermal: 0.000597 LR: 2.74e-06\n",
      "Epoch  38 [2800/10697 ( 26.2%)] Loss: 0.028193 L1: 0.016131 Grad: 0.120321 Thermal: 0.000597 LR: 2.74e-06\n",
      "Epoch  38 [2850/10697 ( 26.6%)] Loss: 0.026494 L1: 0.015331 Grad: 0.111417 Thermal: 0.000439 LR: 2.74e-06\n",
      "Epoch  38 [2850/10697 ( 26.6%)] Loss: 0.026494 L1: 0.015331 Grad: 0.111417 Thermal: 0.000439 LR: 2.74e-06\n",
      "Epoch  38 [2900/10697 ( 27.1%)] Loss: 0.020302 L1: 0.011787 Grad: 0.084988 Thermal: 0.000314 LR: 2.74e-06\n",
      "Epoch  38 [2900/10697 ( 27.1%)] Loss: 0.020302 L1: 0.011787 Grad: 0.084988 Thermal: 0.000314 LR: 2.74e-06\n",
      "Epoch  38 [2950/10697 ( 27.6%)] Loss: 0.028907 L1: 0.016885 Grad: 0.119980 Thermal: 0.000488 LR: 2.74e-06\n",
      "Epoch  38 [2950/10697 ( 27.6%)] Loss: 0.028907 L1: 0.016885 Grad: 0.119980 Thermal: 0.000488 LR: 2.74e-06\n",
      "Epoch  38 [3000/10697 ( 28.0%)] Loss: 0.027892 L1: 0.016009 Grad: 0.118596 Thermal: 0.000472 LR: 2.74e-06\n",
      "Epoch  38 [3000/10697 ( 28.0%)] Loss: 0.027892 L1: 0.016009 Grad: 0.118596 Thermal: 0.000472 LR: 2.74e-06\n",
      "Epoch  38 [3050/10697 ( 28.5%)] Loss: 0.019741 L1: 0.011326 Grad: 0.084022 Thermal: 0.000261 LR: 2.74e-06\n",
      "Epoch  38 [3050/10697 ( 28.5%)] Loss: 0.019741 L1: 0.011326 Grad: 0.084022 Thermal: 0.000261 LR: 2.74e-06\n",
      "Epoch  38 [3100/10697 ( 29.0%)] Loss: 0.025128 L1: 0.015175 Grad: 0.099317 Thermal: 0.000425 LR: 2.74e-06\n",
      "Epoch  38 [3100/10697 ( 29.0%)] Loss: 0.025128 L1: 0.015175 Grad: 0.099317 Thermal: 0.000425 LR: 2.74e-06\n",
      "Epoch  38 [3150/10697 ( 29.4%)] Loss: 0.025374 L1: 0.014852 Grad: 0.105019 Thermal: 0.000412 LR: 2.74e-06\n",
      "Epoch  38 [3150/10697 ( 29.4%)] Loss: 0.025374 L1: 0.014852 Grad: 0.105019 Thermal: 0.000412 LR: 2.74e-06\n",
      "Epoch  38 [3200/10697 ( 29.9%)] Loss: 0.031653 L1: 0.018196 Grad: 0.134205 Thermal: 0.000719 LR: 2.74e-06\n",
      "Epoch  38 [3200/10697 ( 29.9%)] Loss: 0.031653 L1: 0.018196 Grad: 0.134205 Thermal: 0.000719 LR: 2.74e-06\n",
      "Epoch  38 [3250/10697 ( 30.4%)] Loss: 0.021650 L1: 0.012532 Grad: 0.091013 Thermal: 0.000324 LR: 2.74e-06\n",
      "Epoch  38 [3250/10697 ( 30.4%)] Loss: 0.021650 L1: 0.012532 Grad: 0.091013 Thermal: 0.000324 LR: 2.74e-06\n",
      "Epoch  38 [3300/10697 ( 30.8%)] Loss: 0.027424 L1: 0.016290 Grad: 0.111094 Thermal: 0.000483 LR: 2.74e-06\n",
      "Epoch  38 [3300/10697 ( 30.8%)] Loss: 0.027424 L1: 0.016290 Grad: 0.111094 Thermal: 0.000483 LR: 2.74e-06\n",
      "Epoch  38 [3350/10697 ( 31.3%)] Loss: 0.029437 L1: 0.017071 Grad: 0.123394 Thermal: 0.000541 LR: 2.74e-06\n",
      "Epoch  38 [3350/10697 ( 31.3%)] Loss: 0.029437 L1: 0.017071 Grad: 0.123394 Thermal: 0.000541 LR: 2.74e-06\n",
      "Epoch  38 [3400/10697 ( 31.8%)] Loss: 0.024832 L1: 0.014550 Grad: 0.102608 Thermal: 0.000432 LR: 2.74e-06\n",
      "Epoch  38 [3400/10697 ( 31.8%)] Loss: 0.024832 L1: 0.014550 Grad: 0.102608 Thermal: 0.000432 LR: 2.74e-06\n",
      "Epoch  38 [3450/10697 ( 32.3%)] Loss: 0.023940 L1: 0.013430 Grad: 0.104922 Thermal: 0.000365 LR: 2.74e-06\n",
      "Epoch  38 [3450/10697 ( 32.3%)] Loss: 0.023940 L1: 0.013430 Grad: 0.104922 Thermal: 0.000365 LR: 2.74e-06\n",
      "Epoch  38 [3500/10697 ( 32.7%)] Loss: 0.029168 L1: 0.017611 Grad: 0.115287 Thermal: 0.000567 LR: 2.74e-06\n",
      "Epoch  38 [3500/10697 ( 32.7%)] Loss: 0.029168 L1: 0.017611 Grad: 0.115287 Thermal: 0.000567 LR: 2.74e-06\n",
      "Epoch  38 [3550/10697 ( 33.2%)] Loss: 0.019913 L1: 0.011640 Grad: 0.082590 Thermal: 0.000280 LR: 2.74e-06\n",
      "Epoch  38 [3550/10697 ( 33.2%)] Loss: 0.019913 L1: 0.011640 Grad: 0.082590 Thermal: 0.000280 LR: 2.74e-06\n",
      "Epoch  38 [3600/10697 ( 33.7%)] Loss: 0.026327 L1: 0.014981 Grad: 0.113257 Thermal: 0.000418 LR: 2.74e-06\n",
      "Epoch  38 [3600/10697 ( 33.7%)] Loss: 0.026327 L1: 0.014981 Grad: 0.113257 Thermal: 0.000418 LR: 2.74e-06\n",
      "Epoch  38 [3650/10697 ( 34.1%)] Loss: 0.024518 L1: 0.013674 Grad: 0.108257 Thermal: 0.000379 LR: 2.74e-06\n",
      "Epoch  38 [3650/10697 ( 34.1%)] Loss: 0.024518 L1: 0.013674 Grad: 0.108257 Thermal: 0.000379 LR: 2.74e-06\n",
      "Epoch  38 [3700/10697 ( 34.6%)] Loss: 0.027433 L1: 0.015698 Grad: 0.117072 Thermal: 0.000553 LR: 2.74e-06\n",
      "Epoch  38 [3700/10697 ( 34.6%)] Loss: 0.027433 L1: 0.015698 Grad: 0.117072 Thermal: 0.000553 LR: 2.74e-06\n",
      "Epoch  38 [3750/10697 ( 35.1%)] Loss: 0.027986 L1: 0.016520 Grad: 0.114435 Thermal: 0.000458 LR: 2.74e-06\n",
      "Epoch  38 [3750/10697 ( 35.1%)] Loss: 0.027986 L1: 0.016520 Grad: 0.114435 Thermal: 0.000458 LR: 2.74e-06\n",
      "Epoch  38 [3800/10697 ( 35.5%)] Loss: 0.030574 L1: 0.017894 Grad: 0.126507 Thermal: 0.000588 LR: 2.74e-06\n",
      "Epoch  38 [3800/10697 ( 35.5%)] Loss: 0.030574 L1: 0.017894 Grad: 0.126507 Thermal: 0.000588 LR: 2.74e-06\n",
      "Epoch  38 [3850/10697 ( 36.0%)] Loss: 0.025371 L1: 0.015209 Grad: 0.101409 Thermal: 0.000420 LR: 2.74e-06\n",
      "Epoch  38 [3850/10697 ( 36.0%)] Loss: 0.025371 L1: 0.015209 Grad: 0.101409 Thermal: 0.000420 LR: 2.74e-06\n",
      "Epoch  38 [3900/10697 ( 36.5%)] Loss: 0.029392 L1: 0.016551 Grad: 0.128173 Thermal: 0.000481 LR: 2.74e-06\n",
      "Epoch  38 [3900/10697 ( 36.5%)] Loss: 0.029392 L1: 0.016551 Grad: 0.128173 Thermal: 0.000481 LR: 2.74e-06\n",
      "Epoch  38 [3950/10697 ( 36.9%)] Loss: 0.028096 L1: 0.016518 Grad: 0.115534 Thermal: 0.000493 LR: 2.74e-06\n",
      "Epoch  38 [3950/10697 ( 36.9%)] Loss: 0.028096 L1: 0.016518 Grad: 0.115534 Thermal: 0.000493 LR: 2.74e-06\n",
      "Epoch  38 [4000/10697 ( 37.4%)] Loss: 0.026503 L1: 0.015706 Grad: 0.107754 Thermal: 0.000430 LR: 2.74e-06\n",
      "Epoch  38 [4000/10697 ( 37.4%)] Loss: 0.026503 L1: 0.015706 Grad: 0.107754 Thermal: 0.000430 LR: 2.74e-06\n",
      "Epoch  38 [4050/10697 ( 37.9%)] Loss: 0.016695 L1: 0.009471 Grad: 0.072141 Thermal: 0.000189 LR: 2.74e-06\n",
      "Epoch  38 [4050/10697 ( 37.9%)] Loss: 0.016695 L1: 0.009471 Grad: 0.072141 Thermal: 0.000189 LR: 2.74e-06\n",
      "Epoch  38 [4100/10697 ( 38.3%)] Loss: 0.023833 L1: 0.014161 Grad: 0.096523 Thermal: 0.000376 LR: 2.74e-06\n",
      "Epoch  38 [4100/10697 ( 38.3%)] Loss: 0.023833 L1: 0.014161 Grad: 0.096523 Thermal: 0.000376 LR: 2.74e-06\n",
      "Epoch  38 [4150/10697 ( 38.8%)] Loss: 0.027154 L1: 0.015666 Grad: 0.114640 Thermal: 0.000490 LR: 2.74e-06\n",
      "Epoch  38 [4150/10697 ( 38.8%)] Loss: 0.027154 L1: 0.015666 Grad: 0.114640 Thermal: 0.000490 LR: 2.74e-06\n",
      "Epoch  38 [4200/10697 ( 39.3%)] Loss: 0.029138 L1: 0.016828 Grad: 0.122844 Thermal: 0.000514 LR: 2.74e-06\n",
      "Epoch  38 [4200/10697 ( 39.3%)] Loss: 0.029138 L1: 0.016828 Grad: 0.122844 Thermal: 0.000514 LR: 2.74e-06\n",
      "Epoch  38 [4250/10697 ( 39.7%)] Loss: 0.032311 L1: 0.019324 Grad: 0.129519 Thermal: 0.000698 LR: 2.74e-06\n",
      "Epoch  38 [4250/10697 ( 39.7%)] Loss: 0.032311 L1: 0.019324 Grad: 0.129519 Thermal: 0.000698 LR: 2.74e-06\n",
      "Epoch  38 [4300/10697 ( 40.2%)] Loss: 0.023367 L1: 0.013109 Grad: 0.102379 Thermal: 0.000401 LR: 2.74e-06\n",
      "Epoch  38 [4300/10697 ( 40.2%)] Loss: 0.023367 L1: 0.013109 Grad: 0.102379 Thermal: 0.000401 LR: 2.74e-06\n",
      "Epoch  38 [4350/10697 ( 40.7%)] Loss: 0.021317 L1: 0.012515 Grad: 0.087860 Thermal: 0.000323 LR: 2.74e-06\n",
      "Epoch  38 [4350/10697 ( 40.7%)] Loss: 0.021317 L1: 0.012515 Grad: 0.087860 Thermal: 0.000323 LR: 2.74e-06\n",
      "Epoch  38 [4400/10697 ( 41.1%)] Loss: 0.026587 L1: 0.015528 Grad: 0.110389 Thermal: 0.000413 LR: 2.74e-06\n",
      "Epoch  38 [4400/10697 ( 41.1%)] Loss: 0.026587 L1: 0.015528 Grad: 0.110389 Thermal: 0.000413 LR: 2.74e-06\n",
      "Epoch  38 [4450/10697 ( 41.6%)] Loss: 0.026959 L1: 0.015754 Grad: 0.111779 Thermal: 0.000536 LR: 2.74e-06\n",
      "Epoch  38 [4450/10697 ( 41.6%)] Loss: 0.026959 L1: 0.015754 Grad: 0.111779 Thermal: 0.000536 LR: 2.74e-06\n",
      "Epoch  38 [4500/10697 ( 42.1%)] Loss: 0.026629 L1: 0.015492 Grad: 0.111155 Thermal: 0.000427 LR: 2.74e-06\n",
      "Epoch  38 [4500/10697 ( 42.1%)] Loss: 0.026629 L1: 0.015492 Grad: 0.111155 Thermal: 0.000427 LR: 2.74e-06\n",
      "Epoch  38 [4550/10697 ( 42.5%)] Loss: 0.025448 L1: 0.014966 Grad: 0.104615 Thermal: 0.000402 LR: 2.74e-06\n",
      "Epoch  38 [4550/10697 ( 42.5%)] Loss: 0.025448 L1: 0.014966 Grad: 0.104615 Thermal: 0.000402 LR: 2.74e-06\n",
      "Epoch  38 [4600/10697 ( 43.0%)] Loss: 0.023018 L1: 0.013716 Grad: 0.092842 Thermal: 0.000345 LR: 2.74e-06\n",
      "Epoch  38 [4600/10697 ( 43.0%)] Loss: 0.023018 L1: 0.013716 Grad: 0.092842 Thermal: 0.000345 LR: 2.74e-06\n",
      "Epoch  38 [4650/10697 ( 43.5%)] Loss: 0.025409 L1: 0.015004 Grad: 0.103844 Thermal: 0.000412 LR: 2.74e-06\n",
      "Epoch  38 [4650/10697 ( 43.5%)] Loss: 0.025409 L1: 0.015004 Grad: 0.103844 Thermal: 0.000412 LR: 2.74e-06\n",
      "Epoch  38 [4700/10697 ( 43.9%)] Loss: 0.027998 L1: 0.016107 Grad: 0.118670 Thermal: 0.000475 LR: 2.74e-06\n",
      "Epoch  38 [4700/10697 ( 43.9%)] Loss: 0.027998 L1: 0.016107 Grad: 0.118670 Thermal: 0.000475 LR: 2.74e-06\n",
      "Epoch  38 [4750/10697 ( 44.4%)] Loss: 0.026370 L1: 0.015585 Grad: 0.107628 Thermal: 0.000443 LR: 2.74e-06\n",
      "Epoch  38 [4750/10697 ( 44.4%)] Loss: 0.026370 L1: 0.015585 Grad: 0.107628 Thermal: 0.000443 LR: 2.74e-06\n",
      "Epoch  38 [4800/10697 ( 44.9%)] Loss: 0.023276 L1: 0.013098 Grad: 0.101591 Thermal: 0.000393 LR: 2.74e-06\n",
      "Epoch  38 [4800/10697 ( 44.9%)] Loss: 0.023276 L1: 0.013098 Grad: 0.101591 Thermal: 0.000393 LR: 2.74e-06\n",
      "Epoch  38 [4850/10697 ( 45.3%)] Loss: 0.023323 L1: 0.013801 Grad: 0.095050 Thermal: 0.000353 LR: 2.74e-06\n",
      "Epoch  38 [4850/10697 ( 45.3%)] Loss: 0.023323 L1: 0.013801 Grad: 0.095050 Thermal: 0.000353 LR: 2.74e-06\n",
      "Epoch  38 [4900/10697 ( 45.8%)] Loss: 0.026714 L1: 0.015658 Grad: 0.110331 Thermal: 0.000457 LR: 2.74e-06\n",
      "Epoch  38 [4900/10697 ( 45.8%)] Loss: 0.026714 L1: 0.015658 Grad: 0.110331 Thermal: 0.000457 LR: 2.74e-06\n",
      "Epoch  38 [4950/10697 ( 46.3%)] Loss: 0.026992 L1: 0.016212 Grad: 0.107580 Thermal: 0.000459 LR: 2.74e-06\n",
      "Epoch  38 [4950/10697 ( 46.3%)] Loss: 0.026992 L1: 0.016212 Grad: 0.107580 Thermal: 0.000459 LR: 2.74e-06\n",
      "Epoch  38 [5000/10697 ( 46.7%)] Loss: 0.028847 L1: 0.016948 Grad: 0.118736 Thermal: 0.000498 LR: 2.74e-06\n",
      "Epoch  38 [5000/10697 ( 46.7%)] Loss: 0.028847 L1: 0.016948 Grad: 0.118736 Thermal: 0.000498 LR: 2.74e-06\n",
      "Epoch  38 [5050/10697 ( 47.2%)] Loss: 0.031183 L1: 0.017962 Grad: 0.131905 Thermal: 0.000615 LR: 2.74e-06\n",
      "Epoch  38 [5050/10697 ( 47.2%)] Loss: 0.031183 L1: 0.017962 Grad: 0.131905 Thermal: 0.000615 LR: 2.74e-06\n",
      "Epoch  38 [5100/10697 ( 47.7%)] Loss: 0.030569 L1: 0.017440 Grad: 0.130988 Thermal: 0.000604 LR: 2.74e-06\n",
      "Epoch  38 [5100/10697 ( 47.7%)] Loss: 0.030569 L1: 0.017440 Grad: 0.130988 Thermal: 0.000604 LR: 2.74e-06\n",
      "Epoch  38 [5150/10697 ( 48.1%)] Loss: 0.025088 L1: 0.014629 Grad: 0.104375 Thermal: 0.000425 LR: 2.74e-06\n",
      "Epoch  38 [5150/10697 ( 48.1%)] Loss: 0.025088 L1: 0.014629 Grad: 0.104375 Thermal: 0.000425 LR: 2.74e-06\n",
      "Epoch  38 [5200/10697 ( 48.6%)] Loss: 0.024691 L1: 0.014392 Grad: 0.102790 Thermal: 0.000416 LR: 2.74e-06\n",
      "Epoch  38 [5200/10697 ( 48.6%)] Loss: 0.024691 L1: 0.014392 Grad: 0.102790 Thermal: 0.000416 LR: 2.74e-06\n",
      "Epoch  38 [5250/10697 ( 49.1%)] Loss: 0.028109 L1: 0.016808 Grad: 0.112768 Thermal: 0.000491 LR: 2.74e-06\n",
      "Epoch  38 [5250/10697 ( 49.1%)] Loss: 0.028109 L1: 0.016808 Grad: 0.112768 Thermal: 0.000491 LR: 2.74e-06\n",
      "Epoch  38 [5300/10697 ( 49.5%)] Loss: 0.029786 L1: 0.017395 Grad: 0.123620 Thermal: 0.000585 LR: 2.74e-06\n",
      "Epoch  38 [5300/10697 ( 49.5%)] Loss: 0.029786 L1: 0.017395 Grad: 0.123620 Thermal: 0.000585 LR: 2.74e-06\n",
      "Epoch  38 [5350/10697 ( 50.0%)] Loss: 0.025186 L1: 0.014008 Grad: 0.111571 Thermal: 0.000415 LR: 2.74e-06\n",
      "Epoch  38 [5350/10697 ( 50.0%)] Loss: 0.025186 L1: 0.014008 Grad: 0.111571 Thermal: 0.000415 LR: 2.74e-06\n",
      "Epoch  38 [5400/10697 ( 50.5%)] Loss: 0.020334 L1: 0.011641 Grad: 0.086797 Thermal: 0.000285 LR: 2.74e-06\n",
      "Epoch  38 [5400/10697 ( 50.5%)] Loss: 0.020334 L1: 0.011641 Grad: 0.086797 Thermal: 0.000285 LR: 2.74e-06\n",
      "Epoch  38 [5450/10697 ( 50.9%)] Loss: 0.027702 L1: 0.016055 Grad: 0.116218 Thermal: 0.000506 LR: 2.74e-06\n",
      "Epoch  38 [5450/10697 ( 50.9%)] Loss: 0.027702 L1: 0.016055 Grad: 0.116218 Thermal: 0.000506 LR: 2.74e-06\n",
      "Epoch  38 [5500/10697 ( 51.4%)] Loss: 0.025413 L1: 0.014644 Grad: 0.107457 Thermal: 0.000470 LR: 2.74e-06\n",
      "Epoch  38 [5500/10697 ( 51.4%)] Loss: 0.025413 L1: 0.014644 Grad: 0.107457 Thermal: 0.000470 LR: 2.74e-06\n",
      "Epoch  38 [5550/10697 ( 51.9%)] Loss: 0.023947 L1: 0.014299 Grad: 0.096292 Thermal: 0.000382 LR: 2.74e-06\n",
      "Epoch  38 [5550/10697 ( 51.9%)] Loss: 0.023947 L1: 0.014299 Grad: 0.096292 Thermal: 0.000382 LR: 2.74e-06\n",
      "Epoch  38 [5600/10697 ( 52.4%)] Loss: 0.030674 L1: 0.017916 Grad: 0.127289 Thermal: 0.000575 LR: 2.74e-06\n",
      "Epoch  38 [5600/10697 ( 52.4%)] Loss: 0.030674 L1: 0.017916 Grad: 0.127289 Thermal: 0.000575 LR: 2.74e-06\n",
      "Epoch  38 [5650/10697 ( 52.8%)] Loss: 0.025828 L1: 0.015349 Grad: 0.104567 Thermal: 0.000444 LR: 2.74e-06\n",
      "Epoch  38 [5650/10697 ( 52.8%)] Loss: 0.025828 L1: 0.015349 Grad: 0.104567 Thermal: 0.000444 LR: 2.74e-06\n",
      "Epoch  38 [5700/10697 ( 53.3%)] Loss: 0.025162 L1: 0.014952 Grad: 0.101903 Thermal: 0.000401 LR: 2.74e-06\n",
      "Epoch  38 [5700/10697 ( 53.3%)] Loss: 0.025162 L1: 0.014952 Grad: 0.101903 Thermal: 0.000401 LR: 2.74e-06\n",
      "Epoch  38 [5750/10697 ( 53.8%)] Loss: 0.018956 L1: 0.011148 Grad: 0.077949 Thermal: 0.000262 LR: 2.74e-06\n",
      "Epoch  38 [5750/10697 ( 53.8%)] Loss: 0.018956 L1: 0.011148 Grad: 0.077949 Thermal: 0.000262 LR: 2.74e-06\n",
      "Epoch  38 [5800/10697 ( 54.2%)] Loss: 0.028664 L1: 0.016825 Grad: 0.118130 Thermal: 0.000516 LR: 2.74e-06\n",
      "Epoch  38 [5800/10697 ( 54.2%)] Loss: 0.028664 L1: 0.016825 Grad: 0.118130 Thermal: 0.000516 LR: 2.74e-06\n",
      "Epoch  38 [5850/10697 ( 54.7%)] Loss: 0.028319 L1: 0.016854 Grad: 0.114404 Thermal: 0.000493 LR: 2.74e-06\n",
      "Epoch  38 [5850/10697 ( 54.7%)] Loss: 0.028319 L1: 0.016854 Grad: 0.114404 Thermal: 0.000493 LR: 2.74e-06\n",
      "Epoch  38 [5900/10697 ( 55.2%)] Loss: 0.033464 L1: 0.019201 Grad: 0.142273 Thermal: 0.000703 LR: 2.74e-06\n",
      "Epoch  38 [5900/10697 ( 55.2%)] Loss: 0.033464 L1: 0.019201 Grad: 0.142273 Thermal: 0.000703 LR: 2.74e-06\n",
      "Epoch  38 [5950/10697 ( 55.6%)] Loss: 0.026866 L1: 0.015651 Grad: 0.111921 Thermal: 0.000452 LR: 2.74e-06\n",
      "Epoch  38 [5950/10697 ( 55.6%)] Loss: 0.026866 L1: 0.015651 Grad: 0.111921 Thermal: 0.000452 LR: 2.74e-06\n",
      "Epoch  38 [6000/10697 ( 56.1%)] Loss: 0.029581 L1: 0.016913 Grad: 0.126392 Thermal: 0.000584 LR: 2.74e-06\n",
      "Epoch  38 [6000/10697 ( 56.1%)] Loss: 0.029581 L1: 0.016913 Grad: 0.126392 Thermal: 0.000584 LR: 2.74e-06\n",
      "Epoch  38 [6050/10697 ( 56.6%)] Loss: 0.029003 L1: 0.016914 Grad: 0.120615 Thermal: 0.000550 LR: 2.74e-06\n",
      "Epoch  38 [6050/10697 ( 56.6%)] Loss: 0.029003 L1: 0.016914 Grad: 0.120615 Thermal: 0.000550 LR: 2.74e-06\n",
      "Epoch  38 [6100/10697 ( 57.0%)] Loss: 0.025035 L1: 0.014159 Grad: 0.108559 Thermal: 0.000392 LR: 2.74e-06\n",
      "Epoch  38 [6100/10697 ( 57.0%)] Loss: 0.025035 L1: 0.014159 Grad: 0.108559 Thermal: 0.000392 LR: 2.74e-06\n",
      "Epoch  38 [6150/10697 ( 57.5%)] Loss: 0.023768 L1: 0.013441 Grad: 0.103068 Thermal: 0.000396 LR: 2.74e-06\n",
      "Epoch  38 [6150/10697 ( 57.5%)] Loss: 0.023768 L1: 0.013441 Grad: 0.103068 Thermal: 0.000396 LR: 2.74e-06\n",
      "Epoch  38 [6200/10697 ( 58.0%)] Loss: 0.024661 L1: 0.014776 Grad: 0.098649 Thermal: 0.000388 LR: 2.74e-06\n",
      "Epoch  38 [6200/10697 ( 58.0%)] Loss: 0.024661 L1: 0.014776 Grad: 0.098649 Thermal: 0.000388 LR: 2.74e-06\n",
      "Epoch  38 [6250/10697 ( 58.4%)] Loss: 0.026921 L1: 0.015570 Grad: 0.113262 Thermal: 0.000485 LR: 2.74e-06\n",
      "Epoch  38 [6250/10697 ( 58.4%)] Loss: 0.026921 L1: 0.015570 Grad: 0.113262 Thermal: 0.000485 LR: 2.74e-06\n",
      "Epoch  38 [6300/10697 ( 58.9%)] Loss: 0.025522 L1: 0.015403 Grad: 0.100971 Thermal: 0.000434 LR: 2.74e-06\n",
      "Epoch  38 [6300/10697 ( 58.9%)] Loss: 0.025522 L1: 0.015403 Grad: 0.100971 Thermal: 0.000434 LR: 2.74e-06\n",
      "Epoch  38 [6350/10697 ( 59.4%)] Loss: 0.026634 L1: 0.015346 Grad: 0.112615 Thermal: 0.000530 LR: 2.74e-06\n",
      "Epoch  38 [6350/10697 ( 59.4%)] Loss: 0.026634 L1: 0.015346 Grad: 0.112615 Thermal: 0.000530 LR: 2.74e-06\n",
      "Epoch  38 [6400/10697 ( 59.8%)] Loss: 0.027527 L1: 0.016028 Grad: 0.114744 Thermal: 0.000479 LR: 2.74e-06\n",
      "Epoch  38 [6400/10697 ( 59.8%)] Loss: 0.027527 L1: 0.016028 Grad: 0.114744 Thermal: 0.000479 LR: 2.74e-06\n",
      "Epoch  38 [6450/10697 ( 60.3%)] Loss: 0.028513 L1: 0.016754 Grad: 0.117351 Thermal: 0.000481 LR: 2.74e-06\n",
      "Epoch  38 [6450/10697 ( 60.3%)] Loss: 0.028513 L1: 0.016754 Grad: 0.117351 Thermal: 0.000481 LR: 2.74e-06\n",
      "Epoch  38 [6500/10697 ( 60.8%)] Loss: 0.022720 L1: 0.012865 Grad: 0.098353 Thermal: 0.000382 LR: 2.74e-06\n",
      "Epoch  38 [6500/10697 ( 60.8%)] Loss: 0.022720 L1: 0.012865 Grad: 0.098353 Thermal: 0.000382 LR: 2.74e-06\n",
      "Epoch  38 [6550/10697 ( 61.2%)] Loss: 0.023985 L1: 0.014055 Grad: 0.099107 Thermal: 0.000393 LR: 2.74e-06\n",
      "Epoch  38 [6550/10697 ( 61.2%)] Loss: 0.023985 L1: 0.014055 Grad: 0.099107 Thermal: 0.000393 LR: 2.74e-06\n",
      "Epoch  38 [6600/10697 ( 61.7%)] Loss: 0.025259 L1: 0.015024 Grad: 0.102145 Thermal: 0.000413 LR: 2.74e-06\n",
      "Epoch  38 [6600/10697 ( 61.7%)] Loss: 0.025259 L1: 0.015024 Grad: 0.102145 Thermal: 0.000413 LR: 2.74e-06\n",
      "Epoch  38 [6650/10697 ( 62.2%)] Loss: 0.030598 L1: 0.018040 Grad: 0.125275 Thermal: 0.000615 LR: 2.74e-06\n",
      "Epoch  38 [6650/10697 ( 62.2%)] Loss: 0.030598 L1: 0.018040 Grad: 0.125275 Thermal: 0.000615 LR: 2.74e-06\n",
      "Epoch  38 [6700/10697 ( 62.6%)] Loss: 0.028997 L1: 0.017414 Grad: 0.115554 Thermal: 0.000544 LR: 2.74e-06\n",
      "Epoch  38 [6700/10697 ( 62.6%)] Loss: 0.028997 L1: 0.017414 Grad: 0.115554 Thermal: 0.000544 LR: 2.74e-06\n",
      "Epoch  38 [6750/10697 ( 63.1%)] Loss: 0.025869 L1: 0.015172 Grad: 0.106749 Thermal: 0.000434 LR: 2.74e-06\n",
      "Epoch  38 [6750/10697 ( 63.1%)] Loss: 0.025869 L1: 0.015172 Grad: 0.106749 Thermal: 0.000434 LR: 2.74e-06\n",
      "Epoch  38 [6800/10697 ( 63.6%)] Loss: 0.024109 L1: 0.014451 Grad: 0.096395 Thermal: 0.000380 LR: 2.74e-06\n",
      "Epoch  38 [6800/10697 ( 63.6%)] Loss: 0.024109 L1: 0.014451 Grad: 0.096395 Thermal: 0.000380 LR: 2.74e-06\n",
      "Epoch  38 [6850/10697 ( 64.0%)] Loss: 0.027018 L1: 0.016043 Grad: 0.109514 Thermal: 0.000482 LR: 2.74e-06\n",
      "Epoch  38 [6850/10697 ( 64.0%)] Loss: 0.027018 L1: 0.016043 Grad: 0.109514 Thermal: 0.000482 LR: 2.74e-06\n",
      "Epoch  38 [6900/10697 ( 64.5%)] Loss: 0.022851 L1: 0.013201 Grad: 0.096321 Thermal: 0.000358 LR: 2.74e-06\n",
      "Epoch  38 [6900/10697 ( 64.5%)] Loss: 0.022851 L1: 0.013201 Grad: 0.096321 Thermal: 0.000358 LR: 2.74e-06\n",
      "Epoch  38 [6950/10697 ( 65.0%)] Loss: 0.023636 L1: 0.013878 Grad: 0.097381 Thermal: 0.000394 LR: 2.74e-06\n",
      "Epoch  38 [6950/10697 ( 65.0%)] Loss: 0.023636 L1: 0.013878 Grad: 0.097381 Thermal: 0.000394 LR: 2.74e-06\n",
      "Epoch  38 [7000/10697 ( 65.4%)] Loss: 0.025331 L1: 0.014926 Grad: 0.103856 Thermal: 0.000405 LR: 2.74e-06\n",
      "Epoch  38 [7000/10697 ( 65.4%)] Loss: 0.025331 L1: 0.014926 Grad: 0.103856 Thermal: 0.000405 LR: 2.74e-06\n",
      "Epoch  38 [7050/10697 ( 65.9%)] Loss: 0.027213 L1: 0.015819 Grad: 0.113694 Thermal: 0.000496 LR: 2.74e-06\n",
      "Epoch  38 [7050/10697 ( 65.9%)] Loss: 0.027213 L1: 0.015819 Grad: 0.113694 Thermal: 0.000496 LR: 2.74e-06\n",
      "Epoch  38 [7100/10697 ( 66.4%)] Loss: 0.022385 L1: 0.013062 Grad: 0.093070 Thermal: 0.000319 LR: 2.74e-06\n",
      "Epoch  38 [7100/10697 ( 66.4%)] Loss: 0.022385 L1: 0.013062 Grad: 0.093070 Thermal: 0.000319 LR: 2.74e-06\n",
      "Epoch  38 [7150/10697 ( 66.8%)] Loss: 0.024951 L1: 0.013847 Grad: 0.110859 Thermal: 0.000364 LR: 2.74e-06\n",
      "Epoch  38 [7150/10697 ( 66.8%)] Loss: 0.024951 L1: 0.013847 Grad: 0.110859 Thermal: 0.000364 LR: 2.74e-06\n",
      "Epoch  38 [7200/10697 ( 67.3%)] Loss: 0.027643 L1: 0.015572 Grad: 0.120476 Thermal: 0.000483 LR: 2.74e-06\n",
      "Epoch  38 [7200/10697 ( 67.3%)] Loss: 0.027643 L1: 0.015572 Grad: 0.120476 Thermal: 0.000483 LR: 2.74e-06\n",
      "Epoch  38 [7250/10697 ( 67.8%)] Loss: 0.024877 L1: 0.014561 Grad: 0.102976 Thermal: 0.000375 LR: 2.74e-06\n",
      "Epoch  38 [7250/10697 ( 67.8%)] Loss: 0.024877 L1: 0.014561 Grad: 0.102976 Thermal: 0.000375 LR: 2.74e-06\n",
      "Epoch  38 [7300/10697 ( 68.2%)] Loss: 0.025936 L1: 0.015181 Grad: 0.107354 Thermal: 0.000405 LR: 2.74e-06\n",
      "Epoch  38 [7300/10697 ( 68.2%)] Loss: 0.025936 L1: 0.015181 Grad: 0.107354 Thermal: 0.000405 LR: 2.74e-06\n",
      "Epoch  38 [7350/10697 ( 68.7%)] Loss: 0.027467 L1: 0.016188 Grad: 0.112559 Thermal: 0.000461 LR: 2.74e-06\n",
      "Epoch  38 [7350/10697 ( 68.7%)] Loss: 0.027467 L1: 0.016188 Grad: 0.112559 Thermal: 0.000461 LR: 2.74e-06\n",
      "Epoch  38 [7400/10697 ( 69.2%)] Loss: 0.028786 L1: 0.016321 Grad: 0.124384 Thermal: 0.000534 LR: 2.74e-06\n",
      "Epoch  38 [7400/10697 ( 69.2%)] Loss: 0.028786 L1: 0.016321 Grad: 0.124384 Thermal: 0.000534 LR: 2.74e-06\n",
      "Epoch  38 [7450/10697 ( 69.6%)] Loss: 0.027407 L1: 0.016344 Grad: 0.110388 Thermal: 0.000476 LR: 2.74e-06\n",
      "Epoch  38 [7450/10697 ( 69.6%)] Loss: 0.027407 L1: 0.016344 Grad: 0.110388 Thermal: 0.000476 LR: 2.74e-06\n",
      "Epoch  38 [7500/10697 ( 70.1%)] Loss: 0.031357 L1: 0.017831 Grad: 0.134972 Thermal: 0.000584 LR: 2.74e-06\n",
      "Epoch  38 [7500/10697 ( 70.1%)] Loss: 0.031357 L1: 0.017831 Grad: 0.134972 Thermal: 0.000584 LR: 2.74e-06\n",
      "Epoch  38 [7550/10697 ( 70.6%)] Loss: 0.025929 L1: 0.014962 Grad: 0.109455 Thermal: 0.000429 LR: 2.74e-06\n",
      "Epoch  38 [7550/10697 ( 70.6%)] Loss: 0.025929 L1: 0.014962 Grad: 0.109455 Thermal: 0.000429 LR: 2.74e-06\n",
      "Epoch  38 [7600/10697 ( 71.0%)] Loss: 0.022815 L1: 0.012982 Grad: 0.098134 Thermal: 0.000379 LR: 2.74e-06\n",
      "Epoch  38 [7600/10697 ( 71.0%)] Loss: 0.022815 L1: 0.012982 Grad: 0.098134 Thermal: 0.000379 LR: 2.74e-06\n",
      "Epoch  38 [7650/10697 ( 71.5%)] Loss: 0.026220 L1: 0.014951 Grad: 0.112456 Thermal: 0.000470 LR: 2.74e-06\n",
      "Epoch  38 [7650/10697 ( 71.5%)] Loss: 0.026220 L1: 0.014951 Grad: 0.112456 Thermal: 0.000470 LR: 2.74e-06\n",
      "Epoch  38 [7700/10697 ( 72.0%)] Loss: 0.032866 L1: 0.018926 Grad: 0.139059 Thermal: 0.000689 LR: 2.74e-06\n",
      "Epoch  38 [7700/10697 ( 72.0%)] Loss: 0.032866 L1: 0.018926 Grad: 0.139059 Thermal: 0.000689 LR: 2.74e-06\n",
      "Epoch  38 [7750/10697 ( 72.5%)] Loss: 0.028807 L1: 0.017011 Grad: 0.117707 Thermal: 0.000506 LR: 2.74e-06\n",
      "Epoch  38 [7750/10697 ( 72.5%)] Loss: 0.028807 L1: 0.017011 Grad: 0.117707 Thermal: 0.000506 LR: 2.74e-06\n",
      "Epoch  38 [7800/10697 ( 72.9%)] Loss: 0.026483 L1: 0.015828 Grad: 0.106327 Thermal: 0.000437 LR: 2.74e-06\n",
      "Epoch  38 [7800/10697 ( 72.9%)] Loss: 0.026483 L1: 0.015828 Grad: 0.106327 Thermal: 0.000437 LR: 2.74e-06\n",
      "Epoch  38 [7850/10697 ( 73.4%)] Loss: 0.029884 L1: 0.017311 Grad: 0.125442 Thermal: 0.000591 LR: 2.74e-06\n",
      "Epoch  38 [7850/10697 ( 73.4%)] Loss: 0.029884 L1: 0.017311 Grad: 0.125442 Thermal: 0.000591 LR: 2.74e-06\n",
      "Epoch  38 [7900/10697 ( 73.9%)] Loss: 0.027367 L1: 0.015350 Grad: 0.119942 Thermal: 0.000444 LR: 2.74e-06\n",
      "Epoch  38 [7900/10697 ( 73.9%)] Loss: 0.027367 L1: 0.015350 Grad: 0.119942 Thermal: 0.000444 LR: 2.74e-06\n",
      "Epoch  38 [7950/10697 ( 74.3%)] Loss: 0.031613 L1: 0.018382 Grad: 0.131982 Thermal: 0.000658 LR: 2.74e-06\n",
      "Epoch  38 [7950/10697 ( 74.3%)] Loss: 0.031613 L1: 0.018382 Grad: 0.131982 Thermal: 0.000658 LR: 2.74e-06\n",
      "Epoch  38 [8000/10697 ( 74.8%)] Loss: 0.026260 L1: 0.015059 Grad: 0.111808 Thermal: 0.000407 LR: 2.74e-06\n",
      "Epoch  38 [8000/10697 ( 74.8%)] Loss: 0.026260 L1: 0.015059 Grad: 0.111808 Thermal: 0.000407 LR: 2.74e-06\n",
      "Epoch  38 [8050/10697 ( 75.3%)] Loss: 0.026452 L1: 0.015397 Grad: 0.110308 Thermal: 0.000484 LR: 2.74e-06\n",
      "Epoch  38 [8050/10697 ( 75.3%)] Loss: 0.026452 L1: 0.015397 Grad: 0.110308 Thermal: 0.000484 LR: 2.74e-06\n",
      "Epoch  38 [8100/10697 ( 75.7%)] Loss: 0.028973 L1: 0.016367 Grad: 0.125826 Thermal: 0.000466 LR: 2.74e-06\n",
      "Epoch  38 [8100/10697 ( 75.7%)] Loss: 0.028973 L1: 0.016367 Grad: 0.125826 Thermal: 0.000466 LR: 2.74e-06\n",
      "Epoch  38 [8150/10697 ( 76.2%)] Loss: 0.031843 L1: 0.018156 Grad: 0.136558 Thermal: 0.000622 LR: 2.74e-06\n",
      "Epoch  38 [8150/10697 ( 76.2%)] Loss: 0.031843 L1: 0.018156 Grad: 0.136558 Thermal: 0.000622 LR: 2.74e-06\n",
      "Epoch  38 [8200/10697 ( 76.7%)] Loss: 0.027998 L1: 0.016761 Grad: 0.112117 Thermal: 0.000509 LR: 2.74e-06\n",
      "Epoch  38 [8200/10697 ( 76.7%)] Loss: 0.027998 L1: 0.016761 Grad: 0.112117 Thermal: 0.000509 LR: 2.74e-06\n",
      "Epoch  38 [8250/10697 ( 77.1%)] Loss: 0.025031 L1: 0.014204 Grad: 0.108070 Thermal: 0.000407 LR: 2.74e-06\n",
      "Epoch  38 [8250/10697 ( 77.1%)] Loss: 0.025031 L1: 0.014204 Grad: 0.108070 Thermal: 0.000407 LR: 2.74e-06\n",
      "Epoch  38 [8300/10697 ( 77.6%)] Loss: 0.024509 L1: 0.013759 Grad: 0.107310 Thermal: 0.000382 LR: 2.74e-06\n",
      "Epoch  38 [8300/10697 ( 77.6%)] Loss: 0.024509 L1: 0.013759 Grad: 0.107310 Thermal: 0.000382 LR: 2.74e-06\n",
      "Epoch  38 [8350/10697 ( 78.1%)] Loss: 0.038988 L1: 0.022458 Grad: 0.164745 Thermal: 0.001111 LR: 2.74e-06\n",
      "Epoch  38 [8350/10697 ( 78.1%)] Loss: 0.038988 L1: 0.022458 Grad: 0.164745 Thermal: 0.001111 LR: 2.74e-06\n",
      "Epoch  38 [8400/10697 ( 78.5%)] Loss: 0.029021 L1: 0.017137 Grad: 0.118539 Thermal: 0.000586 LR: 2.74e-06\n",
      "Epoch  38 [8400/10697 ( 78.5%)] Loss: 0.029021 L1: 0.017137 Grad: 0.118539 Thermal: 0.000586 LR: 2.74e-06\n",
      "Epoch  38 [8450/10697 ( 79.0%)] Loss: 0.026517 L1: 0.015597 Grad: 0.108979 Thermal: 0.000432 LR: 2.74e-06\n",
      "Epoch  38 [8450/10697 ( 79.0%)] Loss: 0.026517 L1: 0.015597 Grad: 0.108979 Thermal: 0.000432 LR: 2.74e-06\n",
      "Epoch  38 [8500/10697 ( 79.5%)] Loss: 0.029287 L1: 0.017119 Grad: 0.121399 Thermal: 0.000550 LR: 2.74e-06\n",
      "Epoch  38 [8500/10697 ( 79.5%)] Loss: 0.029287 L1: 0.017119 Grad: 0.121399 Thermal: 0.000550 LR: 2.74e-06\n",
      "Epoch  38 [8550/10697 ( 79.9%)] Loss: 0.026852 L1: 0.015765 Grad: 0.110623 Thermal: 0.000487 LR: 2.74e-06\n",
      "Epoch  38 [8550/10697 ( 79.9%)] Loss: 0.026852 L1: 0.015765 Grad: 0.110623 Thermal: 0.000487 LR: 2.74e-06\n",
      "Epoch  38 [8600/10697 ( 80.4%)] Loss: 0.021849 L1: 0.012952 Grad: 0.088818 Thermal: 0.000302 LR: 2.74e-06\n",
      "Epoch  38 [8600/10697 ( 80.4%)] Loss: 0.021849 L1: 0.012952 Grad: 0.088818 Thermal: 0.000302 LR: 2.74e-06\n",
      "Epoch  38 [8650/10697 ( 80.9%)] Loss: 0.026930 L1: 0.016192 Grad: 0.107149 Thermal: 0.000466 LR: 2.74e-06\n",
      "Epoch  38 [8650/10697 ( 80.9%)] Loss: 0.026930 L1: 0.016192 Grad: 0.107149 Thermal: 0.000466 LR: 2.74e-06\n",
      "Epoch  38 [8700/10697 ( 81.3%)] Loss: 0.036996 L1: 0.021378 Grad: 0.155785 Thermal: 0.000801 LR: 2.74e-06\n",
      "Epoch  38 [8700/10697 ( 81.3%)] Loss: 0.036996 L1: 0.021378 Grad: 0.155785 Thermal: 0.000801 LR: 2.74e-06\n",
      "Epoch  38 [8750/10697 ( 81.8%)] Loss: 0.024476 L1: 0.014253 Grad: 0.102032 Thermal: 0.000398 LR: 2.74e-06\n",
      "Epoch  38 [8750/10697 ( 81.8%)] Loss: 0.024476 L1: 0.014253 Grad: 0.102032 Thermal: 0.000398 LR: 2.74e-06\n",
      "Epoch  38 [8800/10697 ( 82.3%)] Loss: 0.023192 L1: 0.013427 Grad: 0.097458 Thermal: 0.000373 LR: 2.74e-06\n",
      "Epoch  38 [8800/10697 ( 82.3%)] Loss: 0.023192 L1: 0.013427 Grad: 0.097458 Thermal: 0.000373 LR: 2.74e-06\n",
      "Epoch  38 [8850/10697 ( 82.7%)] Loss: 0.027504 L1: 0.016001 Grad: 0.114792 Thermal: 0.000476 LR: 2.74e-06\n",
      "Epoch  38 [8850/10697 ( 82.7%)] Loss: 0.027504 L1: 0.016001 Grad: 0.114792 Thermal: 0.000476 LR: 2.74e-06\n",
      "Epoch  38 [8900/10697 ( 83.2%)] Loss: 0.025690 L1: 0.015214 Grad: 0.104506 Thermal: 0.000513 LR: 2.74e-06\n",
      "Epoch  38 [8900/10697 ( 83.2%)] Loss: 0.025690 L1: 0.015214 Grad: 0.104506 Thermal: 0.000513 LR: 2.74e-06\n",
      "Epoch  38 [8950/10697 ( 83.7%)] Loss: 0.026966 L1: 0.015953 Grad: 0.109914 Thermal: 0.000438 LR: 2.74e-06\n",
      "Epoch  38 [8950/10697 ( 83.7%)] Loss: 0.026966 L1: 0.015953 Grad: 0.109914 Thermal: 0.000438 LR: 2.74e-06\n",
      "Epoch  38 [9000/10697 ( 84.1%)] Loss: 0.026367 L1: 0.015727 Grad: 0.106176 Thermal: 0.000451 LR: 2.74e-06\n",
      "Epoch  38 [9000/10697 ( 84.1%)] Loss: 0.026367 L1: 0.015727 Grad: 0.106176 Thermal: 0.000451 LR: 2.74e-06\n",
      "Epoch  38 [9050/10697 ( 84.6%)] Loss: 0.024630 L1: 0.014365 Grad: 0.102452 Thermal: 0.000400 LR: 2.74e-06\n",
      "Epoch  38 [9050/10697 ( 84.6%)] Loss: 0.024630 L1: 0.014365 Grad: 0.102452 Thermal: 0.000400 LR: 2.74e-06\n",
      "Epoch  38 [9100/10697 ( 85.1%)] Loss: 0.021484 L1: 0.012110 Grad: 0.093576 Thermal: 0.000332 LR: 2.74e-06\n",
      "Epoch  38 [9100/10697 ( 85.1%)] Loss: 0.021484 L1: 0.012110 Grad: 0.093576 Thermal: 0.000332 LR: 2.74e-06\n",
      "Epoch  38 [9150/10697 ( 85.5%)] Loss: 0.024091 L1: 0.013599 Grad: 0.104733 Thermal: 0.000367 LR: 2.74e-06\n",
      "Epoch  38 [9150/10697 ( 85.5%)] Loss: 0.024091 L1: 0.013599 Grad: 0.104733 Thermal: 0.000367 LR: 2.74e-06\n",
      "Epoch  38 [9200/10697 ( 86.0%)] Loss: 0.025200 L1: 0.014900 Grad: 0.102784 Thermal: 0.000441 LR: 2.74e-06\n",
      "Epoch  38 [9200/10697 ( 86.0%)] Loss: 0.025200 L1: 0.014900 Grad: 0.102784 Thermal: 0.000441 LR: 2.74e-06\n",
      "Epoch  38 [9250/10697 ( 86.5%)] Loss: 0.022580 L1: 0.013066 Grad: 0.094961 Thermal: 0.000365 LR: 2.74e-06\n",
      "Epoch  38 [9250/10697 ( 86.5%)] Loss: 0.022580 L1: 0.013066 Grad: 0.094961 Thermal: 0.000365 LR: 2.74e-06\n",
      "Epoch  38 [9300/10697 ( 86.9%)] Loss: 0.030741 L1: 0.018059 Grad: 0.126531 Thermal: 0.000591 LR: 2.74e-06\n",
      "Epoch  38 [9300/10697 ( 86.9%)] Loss: 0.030741 L1: 0.018059 Grad: 0.126531 Thermal: 0.000591 LR: 2.74e-06\n",
      "Epoch  38 [9350/10697 ( 87.4%)] Loss: 0.029283 L1: 0.017090 Grad: 0.121676 Thermal: 0.000505 LR: 2.74e-06\n",
      "Epoch  38 [9350/10697 ( 87.4%)] Loss: 0.029283 L1: 0.017090 Grad: 0.121676 Thermal: 0.000505 LR: 2.74e-06\n",
      "Epoch  38 [9400/10697 ( 87.9%)] Loss: 0.020853 L1: 0.011950 Grad: 0.088881 Thermal: 0.000313 LR: 2.74e-06\n",
      "Epoch  38 [9400/10697 ( 87.9%)] Loss: 0.020853 L1: 0.011950 Grad: 0.088881 Thermal: 0.000313 LR: 2.74e-06\n",
      "Epoch  38 [9450/10697 ( 88.3%)] Loss: 0.029388 L1: 0.017630 Grad: 0.117303 Thermal: 0.000541 LR: 2.74e-06\n",
      "Epoch  38 [9450/10697 ( 88.3%)] Loss: 0.029388 L1: 0.017630 Grad: 0.117303 Thermal: 0.000541 LR: 2.74e-06\n",
      "Epoch  38 [9500/10697 ( 88.8%)] Loss: 0.023542 L1: 0.013191 Grad: 0.103338 Thermal: 0.000343 LR: 2.74e-06\n",
      "Epoch  38 [9500/10697 ( 88.8%)] Loss: 0.023542 L1: 0.013191 Grad: 0.103338 Thermal: 0.000343 LR: 2.74e-06\n",
      "Epoch  38 [9550/10697 ( 89.3%)] Loss: 0.024356 L1: 0.014715 Grad: 0.096210 Thermal: 0.000397 LR: 2.74e-06\n",
      "Epoch  38 [9550/10697 ( 89.3%)] Loss: 0.024356 L1: 0.014715 Grad: 0.096210 Thermal: 0.000397 LR: 2.74e-06\n",
      "Epoch  38 [9600/10697 ( 89.7%)] Loss: 0.022582 L1: 0.013357 Grad: 0.092075 Thermal: 0.000347 LR: 2.74e-06\n",
      "Epoch  38 [9600/10697 ( 89.7%)] Loss: 0.022582 L1: 0.013357 Grad: 0.092075 Thermal: 0.000347 LR: 2.74e-06\n",
      "Epoch  38 [9650/10697 ( 90.2%)] Loss: 0.022913 L1: 0.013227 Grad: 0.096683 Thermal: 0.000342 LR: 2.74e-06\n",
      "Epoch  38 [9650/10697 ( 90.2%)] Loss: 0.022913 L1: 0.013227 Grad: 0.096683 Thermal: 0.000342 LR: 2.74e-06\n",
      "Epoch  38 [9700/10697 ( 90.7%)] Loss: 0.018440 L1: 0.010742 Grad: 0.076852 Thermal: 0.000243 LR: 2.74e-06\n",
      "Epoch  38 [9700/10697 ( 90.7%)] Loss: 0.018440 L1: 0.010742 Grad: 0.076852 Thermal: 0.000243 LR: 2.74e-06\n",
      "Epoch  38 [9750/10697 ( 91.1%)] Loss: 0.021647 L1: 0.012428 Grad: 0.092036 Thermal: 0.000296 LR: 2.74e-06\n",
      "Epoch  38 [9750/10697 ( 91.1%)] Loss: 0.021647 L1: 0.012428 Grad: 0.092036 Thermal: 0.000296 LR: 2.74e-06\n",
      "Epoch  38 [9800/10697 ( 91.6%)] Loss: 0.020796 L1: 0.012105 Grad: 0.086751 Thermal: 0.000314 LR: 2.74e-06\n",
      "Epoch  38 [9800/10697 ( 91.6%)] Loss: 0.020796 L1: 0.012105 Grad: 0.086751 Thermal: 0.000314 LR: 2.74e-06\n",
      "Epoch  38 [9850/10697 ( 92.1%)] Loss: 0.024381 L1: 0.014490 Grad: 0.098713 Thermal: 0.000385 LR: 2.74e-06\n",
      "Epoch  38 [9850/10697 ( 92.1%)] Loss: 0.024381 L1: 0.014490 Grad: 0.098713 Thermal: 0.000385 LR: 2.74e-06\n",
      "Epoch  38 [9900/10697 ( 92.5%)] Loss: 0.029024 L1: 0.016780 Grad: 0.122173 Thermal: 0.000549 LR: 2.74e-06\n",
      "Epoch  38 [9900/10697 ( 92.5%)] Loss: 0.029024 L1: 0.016780 Grad: 0.122173 Thermal: 0.000549 LR: 2.74e-06\n",
      "Epoch  38 [9950/10697 ( 93.0%)] Loss: 0.025189 L1: 0.014761 Grad: 0.104091 Thermal: 0.000386 LR: 2.74e-06\n",
      "Epoch  38 [9950/10697 ( 93.0%)] Loss: 0.025189 L1: 0.014761 Grad: 0.104091 Thermal: 0.000386 LR: 2.74e-06\n",
      "Epoch  38 [10000/10697 ( 93.5%)] Loss: 0.028899 L1: 0.017296 Grad: 0.115762 Thermal: 0.000549 LR: 2.74e-06\n",
      "Epoch  38 [10000/10697 ( 93.5%)] Loss: 0.028899 L1: 0.017296 Grad: 0.115762 Thermal: 0.000549 LR: 2.74e-06\n",
      "Epoch  38 [10050/10697 ( 94.0%)] Loss: 0.027184 L1: 0.016148 Grad: 0.110126 Thermal: 0.000455 LR: 2.74e-06\n",
      "Epoch  38 [10050/10697 ( 94.0%)] Loss: 0.027184 L1: 0.016148 Grad: 0.110126 Thermal: 0.000455 LR: 2.74e-06\n",
      "Epoch  38 [10100/10697 ( 94.4%)] Loss: 0.027538 L1: 0.015767 Grad: 0.117464 Thermal: 0.000502 LR: 2.74e-06\n",
      "Epoch  38 [10100/10697 ( 94.4%)] Loss: 0.027538 L1: 0.015767 Grad: 0.117464 Thermal: 0.000502 LR: 2.74e-06\n",
      "Epoch  38 [10150/10697 ( 94.9%)] Loss: 0.026340 L1: 0.015284 Grad: 0.110343 Thermal: 0.000440 LR: 2.74e-06\n",
      "Epoch  38 [10150/10697 ( 94.9%)] Loss: 0.026340 L1: 0.015284 Grad: 0.110343 Thermal: 0.000440 LR: 2.74e-06\n",
      "Epoch  38 [10200/10697 ( 95.4%)] Loss: 0.029864 L1: 0.016688 Grad: 0.131481 Thermal: 0.000564 LR: 2.74e-06\n",
      "Epoch  38 [10200/10697 ( 95.4%)] Loss: 0.029864 L1: 0.016688 Grad: 0.131481 Thermal: 0.000564 LR: 2.74e-06\n",
      "Epoch  38 [10250/10697 ( 95.8%)] Loss: 0.026179 L1: 0.015415 Grad: 0.107416 Thermal: 0.000458 LR: 2.74e-06\n",
      "Epoch  38 [10250/10697 ( 95.8%)] Loss: 0.026179 L1: 0.015415 Grad: 0.107416 Thermal: 0.000458 LR: 2.74e-06\n",
      "Epoch  38 [10300/10697 ( 96.3%)] Loss: 0.021314 L1: 0.012695 Grad: 0.086023 Thermal: 0.000322 LR: 2.74e-06\n",
      "Epoch  38 [10300/10697 ( 96.3%)] Loss: 0.021314 L1: 0.012695 Grad: 0.086023 Thermal: 0.000322 LR: 2.74e-06\n",
      "Epoch  38 [10350/10697 ( 96.8%)] Loss: 0.029716 L1: 0.017479 Grad: 0.122085 Thermal: 0.000576 LR: 2.74e-06\n",
      "Epoch  38 [10350/10697 ( 96.8%)] Loss: 0.029716 L1: 0.017479 Grad: 0.122085 Thermal: 0.000576 LR: 2.74e-06\n",
      "Epoch  38 [10400/10697 ( 97.2%)] Loss: 0.028758 L1: 0.016921 Grad: 0.118105 Thermal: 0.000519 LR: 2.74e-06\n",
      "Epoch  38 [10400/10697 ( 97.2%)] Loss: 0.028758 L1: 0.016921 Grad: 0.118105 Thermal: 0.000519 LR: 2.74e-06\n",
      "Epoch  38 [10450/10697 ( 97.7%)] Loss: 0.027441 L1: 0.015867 Grad: 0.115487 Thermal: 0.000500 LR: 2.74e-06\n",
      "Epoch  38 [10450/10697 ( 97.7%)] Loss: 0.027441 L1: 0.015867 Grad: 0.115487 Thermal: 0.000500 LR: 2.74e-06\n",
      "Epoch  38 [10500/10697 ( 98.2%)] Loss: 0.028087 L1: 0.016446 Grad: 0.116121 Thermal: 0.000592 LR: 2.74e-06\n",
      "Epoch  38 [10500/10697 ( 98.2%)] Loss: 0.028087 L1: 0.016446 Grad: 0.116121 Thermal: 0.000592 LR: 2.74e-06\n",
      "Epoch  38 [10550/10697 ( 98.6%)] Loss: 0.025213 L1: 0.015051 Grad: 0.101407 Thermal: 0.000418 LR: 2.74e-06\n",
      "Epoch  38 [10550/10697 ( 98.6%)] Loss: 0.025213 L1: 0.015051 Grad: 0.101407 Thermal: 0.000418 LR: 2.74e-06\n",
      "Epoch  38 [10600/10697 ( 99.1%)] Loss: 0.024482 L1: 0.013890 Grad: 0.105704 Thermal: 0.000433 LR: 2.74e-06\n",
      "Epoch  38 [10600/10697 ( 99.1%)] Loss: 0.024482 L1: 0.013890 Grad: 0.105704 Thermal: 0.000433 LR: 2.74e-06\n",
      "Epoch  38 [10650/10697 ( 99.6%)] Loss: 0.023043 L1: 0.013497 Grad: 0.095268 Thermal: 0.000368 LR: 2.74e-06\n",
      "Epoch  38 [10650/10697 ( 99.6%)] Loss: 0.023043 L1: 0.013497 Grad: 0.095268 Thermal: 0.000368 LR: 2.74e-06\n",
      "Epoch  38 Summary: Loss=0.026233 (L1:0.0153, Grad:0.1091, Thermal:0.0005) Val_PSNR=0.00dB Best=33.96dB Time=149.6min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  38 Summary: Loss=0.026233 (L1:0.0153, Grad:0.1091, Thermal:0.0005) Val_PSNR=0.00dB Best=33.96dB Time=149.6min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  39 [   0/10697 (  0.0%)] Loss: 0.026974 L1: 0.015877 Grad: 0.110719 Thermal: 0.000493 LR: 2.64e-06\n",
      "Epoch  39 [   0/10697 (  0.0%)] Loss: 0.026974 L1: 0.015877 Grad: 0.110719 Thermal: 0.000493 LR: 2.64e-06\n",
      "Epoch  39 [  50/10697 (  0.5%)] Loss: 0.031009 L1: 0.017870 Grad: 0.131025 Thermal: 0.000737 LR: 2.64e-06\n",
      "Epoch  39 [  50/10697 (  0.5%)] Loss: 0.031009 L1: 0.017870 Grad: 0.131025 Thermal: 0.000737 LR: 2.64e-06\n",
      "Epoch  39 [ 100/10697 (  0.9%)] Loss: 0.021952 L1: 0.012985 Grad: 0.089505 Thermal: 0.000341 LR: 2.64e-06\n",
      "Epoch  39 [ 100/10697 (  0.9%)] Loss: 0.021952 L1: 0.012985 Grad: 0.089505 Thermal: 0.000341 LR: 2.64e-06\n",
      "Epoch  39 [ 150/10697 (  1.4%)] Loss: 0.020287 L1: 0.011539 Grad: 0.087299 Thermal: 0.000365 LR: 2.64e-06\n",
      "Epoch  39 [ 150/10697 (  1.4%)] Loss: 0.020287 L1: 0.011539 Grad: 0.087299 Thermal: 0.000365 LR: 2.64e-06\n",
      "Epoch  39 [ 200/10697 (  1.9%)] Loss: 0.031402 L1: 0.017991 Grad: 0.133790 Thermal: 0.000655 LR: 2.64e-06\n",
      "Epoch  39 [ 200/10697 (  1.9%)] Loss: 0.031402 L1: 0.017991 Grad: 0.133790 Thermal: 0.000655 LR: 2.64e-06\n",
      "Epoch  39 [ 250/10697 (  2.3%)] Loss: 0.028060 L1: 0.016688 Grad: 0.113466 Thermal: 0.000501 LR: 2.64e-06\n",
      "Epoch  39 [ 250/10697 (  2.3%)] Loss: 0.028060 L1: 0.016688 Grad: 0.113466 Thermal: 0.000501 LR: 2.64e-06\n",
      "Epoch  39 [ 300/10697 (  2.8%)] Loss: 0.018852 L1: 0.010669 Grad: 0.081697 Thermal: 0.000264 LR: 2.64e-06\n",
      "Epoch  39 [ 300/10697 (  2.8%)] Loss: 0.018852 L1: 0.010669 Grad: 0.081697 Thermal: 0.000264 LR: 2.64e-06\n",
      "Epoch  39 [ 350/10697 (  3.3%)] Loss: 0.027935 L1: 0.016538 Grad: 0.113716 Thermal: 0.000501 LR: 2.64e-06\n",
      "Epoch  39 [ 350/10697 (  3.3%)] Loss: 0.027935 L1: 0.016538 Grad: 0.113716 Thermal: 0.000501 LR: 2.64e-06\n",
      "Epoch  39 [ 400/10697 (  3.7%)] Loss: 0.030965 L1: 0.017729 Grad: 0.132037 Thermal: 0.000639 LR: 2.64e-06\n",
      "Epoch  39 [ 400/10697 (  3.7%)] Loss: 0.030965 L1: 0.017729 Grad: 0.132037 Thermal: 0.000639 LR: 2.64e-06\n",
      "Epoch  39 [ 450/10697 (  4.2%)] Loss: 0.029162 L1: 0.017185 Grad: 0.119508 Thermal: 0.000537 LR: 2.64e-06\n",
      "Epoch  39 [ 450/10697 (  4.2%)] Loss: 0.029162 L1: 0.017185 Grad: 0.119508 Thermal: 0.000537 LR: 2.64e-06\n",
      "Epoch  39 [ 500/10697 (  4.7%)] Loss: 0.028918 L1: 0.016963 Grad: 0.119302 Thermal: 0.000496 LR: 2.64e-06\n",
      "Epoch  39 [ 500/10697 (  4.7%)] Loss: 0.028918 L1: 0.016963 Grad: 0.119302 Thermal: 0.000496 LR: 2.64e-06\n",
      "Epoch  39 [ 550/10697 (  5.1%)] Loss: 0.025189 L1: 0.014769 Grad: 0.104003 Thermal: 0.000395 LR: 2.64e-06\n",
      "Epoch  39 [ 550/10697 (  5.1%)] Loss: 0.025189 L1: 0.014769 Grad: 0.104003 Thermal: 0.000395 LR: 2.64e-06\n",
      "Epoch  39 [ 600/10697 (  5.6%)] Loss: 0.026083 L1: 0.015642 Grad: 0.104192 Thermal: 0.000441 LR: 2.64e-06\n",
      "Epoch  39 [ 600/10697 (  5.6%)] Loss: 0.026083 L1: 0.015642 Grad: 0.104192 Thermal: 0.000441 LR: 2.64e-06\n",
      "Epoch  39 [ 650/10697 (  6.1%)] Loss: 0.022979 L1: 0.013163 Grad: 0.097986 Thermal: 0.000346 LR: 2.64e-06\n",
      "Epoch  39 [ 650/10697 (  6.1%)] Loss: 0.022979 L1: 0.013163 Grad: 0.097986 Thermal: 0.000346 LR: 2.64e-06\n",
      "Epoch  39 [ 700/10697 (  6.5%)] Loss: 0.025721 L1: 0.014471 Grad: 0.112300 Thermal: 0.000405 LR: 2.64e-06\n",
      "Epoch  39 [ 700/10697 (  6.5%)] Loss: 0.025721 L1: 0.014471 Grad: 0.112300 Thermal: 0.000405 LR: 2.64e-06\n",
      "Epoch  39 [ 750/10697 (  7.0%)] Loss: 0.025305 L1: 0.014504 Grad: 0.107784 Thermal: 0.000449 LR: 2.64e-06\n",
      "Epoch  39 [ 750/10697 (  7.0%)] Loss: 0.025305 L1: 0.014504 Grad: 0.107784 Thermal: 0.000449 LR: 2.64e-06\n",
      "Epoch  39 [ 800/10697 (  7.5%)] Loss: 0.028571 L1: 0.016838 Grad: 0.117067 Thermal: 0.000522 LR: 2.64e-06\n",
      "Epoch  39 [ 800/10697 (  7.5%)] Loss: 0.028571 L1: 0.016838 Grad: 0.117067 Thermal: 0.000522 LR: 2.64e-06\n",
      "Epoch  39 [ 850/10697 (  7.9%)] Loss: 0.023173 L1: 0.013830 Grad: 0.093254 Thermal: 0.000354 LR: 2.64e-06\n",
      "Epoch  39 [ 850/10697 (  7.9%)] Loss: 0.023173 L1: 0.013830 Grad: 0.093254 Thermal: 0.000354 LR: 2.64e-06\n",
      "Epoch  39 [ 900/10697 (  8.4%)] Loss: 0.024395 L1: 0.014517 Grad: 0.098578 Thermal: 0.000407 LR: 2.64e-06\n",
      "Epoch  39 [ 900/10697 (  8.4%)] Loss: 0.024395 L1: 0.014517 Grad: 0.098578 Thermal: 0.000407 LR: 2.64e-06\n",
      "Epoch  39 [ 950/10697 (  8.9%)] Loss: 0.024963 L1: 0.014833 Grad: 0.101101 Thermal: 0.000408 LR: 2.64e-06\n",
      "Epoch  39 [ 950/10697 (  8.9%)] Loss: 0.024963 L1: 0.014833 Grad: 0.101101 Thermal: 0.000408 LR: 2.64e-06\n",
      "Epoch  39 [1000/10697 (  9.3%)] Loss: 0.018570 L1: 0.010718 Grad: 0.078405 Thermal: 0.000238 LR: 2.64e-06\n",
      "Epoch  39 [1000/10697 (  9.3%)] Loss: 0.018570 L1: 0.010718 Grad: 0.078405 Thermal: 0.000238 LR: 2.64e-06\n",
      "Epoch  39 [1050/10697 (  9.8%)] Loss: 0.024934 L1: 0.014189 Grad: 0.107249 Thermal: 0.000393 LR: 2.64e-06\n",
      "Epoch  39 [1050/10697 (  9.8%)] Loss: 0.024934 L1: 0.014189 Grad: 0.107249 Thermal: 0.000393 LR: 2.64e-06\n",
      "Epoch  39 [1100/10697 ( 10.3%)] Loss: 0.029457 L1: 0.017576 Grad: 0.118527 Thermal: 0.000555 LR: 2.64e-06\n",
      "Epoch  39 [1100/10697 ( 10.3%)] Loss: 0.029457 L1: 0.017576 Grad: 0.118527 Thermal: 0.000555 LR: 2.64e-06\n",
      "Epoch  39 [1150/10697 ( 10.8%)] Loss: 0.024200 L1: 0.014240 Grad: 0.099389 Thermal: 0.000419 LR: 2.64e-06\n",
      "Epoch  39 [1150/10697 ( 10.8%)] Loss: 0.024200 L1: 0.014240 Grad: 0.099389 Thermal: 0.000419 LR: 2.64e-06\n",
      "Epoch  39 [1200/10697 ( 11.2%)] Loss: 0.018185 L1: 0.010496 Grad: 0.076754 Thermal: 0.000274 LR: 2.64e-06\n",
      "Epoch  39 [1200/10697 ( 11.2%)] Loss: 0.018185 L1: 0.010496 Grad: 0.076754 Thermal: 0.000274 LR: 2.64e-06\n",
      "Epoch  39 [1250/10697 ( 11.7%)] Loss: 0.022586 L1: 0.013473 Grad: 0.090960 Thermal: 0.000344 LR: 2.64e-06\n",
      "Epoch  39 [1250/10697 ( 11.7%)] Loss: 0.022586 L1: 0.013473 Grad: 0.090960 Thermal: 0.000344 LR: 2.64e-06\n",
      "Epoch  39 [1300/10697 ( 12.2%)] Loss: 0.025182 L1: 0.014719 Grad: 0.104427 Thermal: 0.000411 LR: 2.64e-06\n",
      "Epoch  39 [1300/10697 ( 12.2%)] Loss: 0.025182 L1: 0.014719 Grad: 0.104427 Thermal: 0.000411 LR: 2.64e-06\n",
      "Epoch  39 [1350/10697 ( 12.6%)] Loss: 0.019008 L1: 0.010934 Grad: 0.080613 Thermal: 0.000247 LR: 2.64e-06\n",
      "Epoch  39 [1350/10697 ( 12.6%)] Loss: 0.019008 L1: 0.010934 Grad: 0.080613 Thermal: 0.000247 LR: 2.64e-06\n",
      "Epoch  39 [1400/10697 ( 13.1%)] Loss: 0.026386 L1: 0.015742 Grad: 0.106213 Thermal: 0.000458 LR: 2.64e-06\n",
      "Epoch  39 [1400/10697 ( 13.1%)] Loss: 0.026386 L1: 0.015742 Grad: 0.106213 Thermal: 0.000458 LR: 2.64e-06\n",
      "Epoch  39 [1450/10697 ( 13.6%)] Loss: 0.018799 L1: 0.011119 Grad: 0.076667 Thermal: 0.000277 LR: 2.64e-06\n",
      "Epoch  39 [1450/10697 ( 13.6%)] Loss: 0.018799 L1: 0.011119 Grad: 0.076667 Thermal: 0.000277 LR: 2.64e-06\n",
      "Epoch  39 [1500/10697 ( 14.0%)] Loss: 0.033349 L1: 0.018777 Grad: 0.145395 Thermal: 0.000660 LR: 2.64e-06\n",
      "Epoch  39 [1500/10697 ( 14.0%)] Loss: 0.033349 L1: 0.018777 Grad: 0.145395 Thermal: 0.000660 LR: 2.64e-06\n",
      "Epoch  39 [1550/10697 ( 14.5%)] Loss: 0.026973 L1: 0.015998 Grad: 0.109504 Thermal: 0.000476 LR: 2.64e-06\n",
      "Epoch  39 [1550/10697 ( 14.5%)] Loss: 0.026973 L1: 0.015998 Grad: 0.109504 Thermal: 0.000476 LR: 2.64e-06\n",
      "Epoch  39 [1600/10697 ( 15.0%)] Loss: 0.025527 L1: 0.015210 Grad: 0.102955 Thermal: 0.000436 LR: 2.64e-06\n",
      "Epoch  39 [1600/10697 ( 15.0%)] Loss: 0.025527 L1: 0.015210 Grad: 0.102955 Thermal: 0.000436 LR: 2.64e-06\n",
      "Epoch  39 [1650/10697 ( 15.4%)] Loss: 0.023899 L1: 0.013747 Grad: 0.101346 Thermal: 0.000350 LR: 2.64e-06\n",
      "Epoch  39 [1650/10697 ( 15.4%)] Loss: 0.023899 L1: 0.013747 Grad: 0.101346 Thermal: 0.000350 LR: 2.64e-06\n",
      "Epoch  39 [1700/10697 ( 15.9%)] Loss: 0.020995 L1: 0.012580 Grad: 0.083990 Thermal: 0.000321 LR: 2.64e-06\n",
      "Epoch  39 [1700/10697 ( 15.9%)] Loss: 0.020995 L1: 0.012580 Grad: 0.083990 Thermal: 0.000321 LR: 2.64e-06\n",
      "Epoch  39 [1750/10697 ( 16.4%)] Loss: 0.031115 L1: 0.017997 Grad: 0.130874 Thermal: 0.000615 LR: 2.64e-06\n",
      "Epoch  39 [1750/10697 ( 16.4%)] Loss: 0.031115 L1: 0.017997 Grad: 0.130874 Thermal: 0.000615 LR: 2.64e-06\n",
      "Epoch  39 [1800/10697 ( 16.8%)] Loss: 0.027001 L1: 0.016112 Grad: 0.108657 Thermal: 0.000473 LR: 2.64e-06\n",
      "Epoch  39 [1800/10697 ( 16.8%)] Loss: 0.027001 L1: 0.016112 Grad: 0.108657 Thermal: 0.000473 LR: 2.64e-06\n",
      "Epoch  39 [1850/10697 ( 17.3%)] Loss: 0.031205 L1: 0.017783 Grad: 0.133859 Thermal: 0.000714 LR: 2.64e-06\n",
      "Epoch  39 [1850/10697 ( 17.3%)] Loss: 0.031205 L1: 0.017783 Grad: 0.133859 Thermal: 0.000714 LR: 2.64e-06\n",
      "Epoch  39 [1900/10697 ( 17.8%)] Loss: 0.030242 L1: 0.017307 Grad: 0.129060 Thermal: 0.000580 LR: 2.64e-06\n",
      "Epoch  39 [1900/10697 ( 17.8%)] Loss: 0.030242 L1: 0.017307 Grad: 0.129060 Thermal: 0.000580 LR: 2.64e-06\n",
      "Epoch  39 [1950/10697 ( 18.2%)] Loss: 0.026706 L1: 0.015954 Grad: 0.107295 Thermal: 0.000439 LR: 2.64e-06\n",
      "Epoch  39 [1950/10697 ( 18.2%)] Loss: 0.026706 L1: 0.015954 Grad: 0.107295 Thermal: 0.000439 LR: 2.64e-06\n",
      "Epoch  39 [2000/10697 ( 18.7%)] Loss: 0.028953 L1: 0.017273 Grad: 0.116546 Thermal: 0.000520 LR: 2.64e-06\n",
      "Epoch  39 [2000/10697 ( 18.7%)] Loss: 0.028953 L1: 0.017273 Grad: 0.116546 Thermal: 0.000520 LR: 2.64e-06\n",
      "Epoch  39 [2050/10697 ( 19.2%)] Loss: 0.027445 L1: 0.016230 Grad: 0.111921 Thermal: 0.000458 LR: 2.64e-06\n",
      "Epoch  39 [2050/10697 ( 19.2%)] Loss: 0.027445 L1: 0.016230 Grad: 0.111921 Thermal: 0.000458 LR: 2.64e-06\n",
      "Epoch  39 [2100/10697 ( 19.6%)] Loss: 0.023088 L1: 0.013445 Grad: 0.096261 Thermal: 0.000345 LR: 2.64e-06\n",
      "Epoch  39 [2100/10697 ( 19.6%)] Loss: 0.023088 L1: 0.013445 Grad: 0.096261 Thermal: 0.000345 LR: 2.64e-06\n",
      "Epoch  39 [2150/10697 ( 20.1%)] Loss: 0.023047 L1: 0.013435 Grad: 0.095938 Thermal: 0.000370 LR: 2.64e-06\n",
      "Epoch  39 [2150/10697 ( 20.1%)] Loss: 0.023047 L1: 0.013435 Grad: 0.095938 Thermal: 0.000370 LR: 2.64e-06\n",
      "Epoch  39 [2200/10697 ( 20.6%)] Loss: 0.031001 L1: 0.018351 Grad: 0.126192 Thermal: 0.000608 LR: 2.64e-06\n",
      "Epoch  39 [2200/10697 ( 20.6%)] Loss: 0.031001 L1: 0.018351 Grad: 0.126192 Thermal: 0.000608 LR: 2.64e-06\n",
      "Epoch  39 [2250/10697 ( 21.0%)] Loss: 0.021137 L1: 0.012243 Grad: 0.088793 Thermal: 0.000295 LR: 2.64e-06\n",
      "Epoch  39 [2250/10697 ( 21.0%)] Loss: 0.021137 L1: 0.012243 Grad: 0.088793 Thermal: 0.000295 LR: 2.64e-06\n",
      "Epoch  39 [2300/10697 ( 21.5%)] Loss: 0.028734 L1: 0.016913 Grad: 0.117933 Thermal: 0.000547 LR: 2.64e-06\n",
      "Epoch  39 [2300/10697 ( 21.5%)] Loss: 0.028734 L1: 0.016913 Grad: 0.117933 Thermal: 0.000547 LR: 2.64e-06\n",
      "Epoch  39 [2350/10697 ( 22.0%)] Loss: 0.023624 L1: 0.013572 Grad: 0.100332 Thermal: 0.000373 LR: 2.64e-06\n",
      "Epoch  39 [2350/10697 ( 22.0%)] Loss: 0.023624 L1: 0.013572 Grad: 0.100332 Thermal: 0.000373 LR: 2.64e-06\n",
      "Epoch  39 [2400/10697 ( 22.4%)] Loss: 0.027752 L1: 0.016354 Grad: 0.113743 Thermal: 0.000466 LR: 2.64e-06\n",
      "Epoch  39 [2400/10697 ( 22.4%)] Loss: 0.027752 L1: 0.016354 Grad: 0.113743 Thermal: 0.000466 LR: 2.64e-06\n",
      "Epoch  39 [2450/10697 ( 22.9%)] Loss: 0.022418 L1: 0.013168 Grad: 0.092329 Thermal: 0.000333 LR: 2.64e-06\n",
      "Epoch  39 [2450/10697 ( 22.9%)] Loss: 0.022418 L1: 0.013168 Grad: 0.092329 Thermal: 0.000333 LR: 2.64e-06\n",
      "Epoch  39 [2500/10697 ( 23.4%)] Loss: 0.022595 L1: 0.013163 Grad: 0.094117 Thermal: 0.000400 LR: 2.64e-06\n",
      "Epoch  39 [2500/10697 ( 23.4%)] Loss: 0.022595 L1: 0.013163 Grad: 0.094117 Thermal: 0.000400 LR: 2.64e-06\n",
      "Epoch  39 [2550/10697 ( 23.8%)] Loss: 0.027362 L1: 0.015813 Grad: 0.115264 Thermal: 0.000444 LR: 2.64e-06\n",
      "Epoch  39 [2550/10697 ( 23.8%)] Loss: 0.027362 L1: 0.015813 Grad: 0.115264 Thermal: 0.000444 LR: 2.64e-06\n",
      "Epoch  39 [2600/10697 ( 24.3%)] Loss: 0.029424 L1: 0.017334 Grad: 0.120603 Thermal: 0.000584 LR: 2.64e-06\n",
      "Epoch  39 [2600/10697 ( 24.3%)] Loss: 0.029424 L1: 0.017334 Grad: 0.120603 Thermal: 0.000584 LR: 2.64e-06\n",
      "Epoch  39 [2650/10697 ( 24.8%)] Loss: 0.020213 L1: 0.011922 Grad: 0.082758 Thermal: 0.000292 LR: 2.64e-06\n",
      "Epoch  39 [2650/10697 ( 24.8%)] Loss: 0.020213 L1: 0.011922 Grad: 0.082758 Thermal: 0.000292 LR: 2.64e-06\n",
      "Epoch  39 [2700/10697 ( 25.2%)] Loss: 0.024647 L1: 0.014077 Grad: 0.105491 Thermal: 0.000413 LR: 2.64e-06\n",
      "Epoch  39 [2700/10697 ( 25.2%)] Loss: 0.024647 L1: 0.014077 Grad: 0.105491 Thermal: 0.000413 LR: 2.64e-06\n",
      "Epoch  39 [2750/10697 ( 25.7%)] Loss: 0.025377 L1: 0.014935 Grad: 0.104202 Thermal: 0.000423 LR: 2.64e-06\n",
      "Epoch  39 [2750/10697 ( 25.7%)] Loss: 0.025377 L1: 0.014935 Grad: 0.104202 Thermal: 0.000423 LR: 2.64e-06\n",
      "Epoch  39 [2800/10697 ( 26.2%)] Loss: 0.026222 L1: 0.015292 Grad: 0.109069 Thermal: 0.000468 LR: 2.64e-06\n",
      "Epoch  39 [2800/10697 ( 26.2%)] Loss: 0.026222 L1: 0.015292 Grad: 0.109069 Thermal: 0.000468 LR: 2.64e-06\n",
      "Epoch  39 [2850/10697 ( 26.6%)] Loss: 0.026863 L1: 0.015455 Grad: 0.113867 Thermal: 0.000437 LR: 2.64e-06\n",
      "Epoch  39 [2850/10697 ( 26.6%)] Loss: 0.026863 L1: 0.015455 Grad: 0.113867 Thermal: 0.000437 LR: 2.64e-06\n",
      "Epoch  39 [2900/10697 ( 27.1%)] Loss: 0.024148 L1: 0.014105 Grad: 0.100233 Thermal: 0.000399 LR: 2.64e-06\n",
      "Epoch  39 [2900/10697 ( 27.1%)] Loss: 0.024148 L1: 0.014105 Grad: 0.100233 Thermal: 0.000399 LR: 2.64e-06\n",
      "Epoch  39 [2950/10697 ( 27.6%)] Loss: 0.031694 L1: 0.018240 Grad: 0.134213 Thermal: 0.000655 LR: 2.64e-06\n",
      "Epoch  39 [2950/10697 ( 27.6%)] Loss: 0.031694 L1: 0.018240 Grad: 0.134213 Thermal: 0.000655 LR: 2.64e-06\n",
      "Epoch  39 [3000/10697 ( 28.0%)] Loss: 0.020906 L1: 0.011950 Grad: 0.089412 Thermal: 0.000305 LR: 2.64e-06\n",
      "Epoch  39 [3000/10697 ( 28.0%)] Loss: 0.020906 L1: 0.011950 Grad: 0.089412 Thermal: 0.000305 LR: 2.64e-06\n",
      "Epoch  39 [3050/10697 ( 28.5%)] Loss: 0.030186 L1: 0.017591 Grad: 0.125612 Thermal: 0.000678 LR: 2.64e-06\n",
      "Epoch  39 [3050/10697 ( 28.5%)] Loss: 0.030186 L1: 0.017591 Grad: 0.125612 Thermal: 0.000678 LR: 2.64e-06\n",
      "Epoch  39 [3100/10697 ( 29.0%)] Loss: 0.024447 L1: 0.013950 Grad: 0.104782 Thermal: 0.000391 LR: 2.64e-06\n",
      "Epoch  39 [3100/10697 ( 29.0%)] Loss: 0.024447 L1: 0.013950 Grad: 0.104782 Thermal: 0.000391 LR: 2.64e-06\n",
      "Epoch  39 [3150/10697 ( 29.4%)] Loss: 0.025354 L1: 0.014820 Grad: 0.105105 Thermal: 0.000460 LR: 2.64e-06\n",
      "Epoch  39 [3150/10697 ( 29.4%)] Loss: 0.025354 L1: 0.014820 Grad: 0.105105 Thermal: 0.000460 LR: 2.64e-06\n",
      "Epoch  39 [3200/10697 ( 29.9%)] Loss: 0.023929 L1: 0.014262 Grad: 0.096480 Thermal: 0.000375 LR: 2.64e-06\n",
      "Epoch  39 [3200/10697 ( 29.9%)] Loss: 0.023929 L1: 0.014262 Grad: 0.096480 Thermal: 0.000375 LR: 2.64e-06\n",
      "Epoch  39 [3250/10697 ( 30.4%)] Loss: 0.024375 L1: 0.014411 Grad: 0.099440 Thermal: 0.000397 LR: 2.64e-06\n",
      "Epoch  39 [3250/10697 ( 30.4%)] Loss: 0.024375 L1: 0.014411 Grad: 0.099440 Thermal: 0.000397 LR: 2.64e-06\n",
      "Epoch  39 [3300/10697 ( 30.8%)] Loss: 0.022586 L1: 0.012750 Grad: 0.098188 Thermal: 0.000340 LR: 2.64e-06\n",
      "Epoch  39 [3300/10697 ( 30.8%)] Loss: 0.022586 L1: 0.012750 Grad: 0.098188 Thermal: 0.000340 LR: 2.64e-06\n",
      "Epoch  39 [3350/10697 ( 31.3%)] Loss: 0.024369 L1: 0.014363 Grad: 0.099864 Thermal: 0.000383 LR: 2.64e-06\n",
      "Epoch  39 [3350/10697 ( 31.3%)] Loss: 0.024369 L1: 0.014363 Grad: 0.099864 Thermal: 0.000383 LR: 2.64e-06\n",
      "Epoch  39 [3400/10697 ( 31.8%)] Loss: 0.028834 L1: 0.016835 Grad: 0.119700 Thermal: 0.000578 LR: 2.64e-06\n",
      "Epoch  39 [3400/10697 ( 31.8%)] Loss: 0.028834 L1: 0.016835 Grad: 0.119700 Thermal: 0.000578 LR: 2.64e-06\n",
      "Epoch  39 [3450/10697 ( 32.3%)] Loss: 0.029549 L1: 0.017768 Grad: 0.117529 Thermal: 0.000573 LR: 2.64e-06\n",
      "Epoch  39 [3450/10697 ( 32.3%)] Loss: 0.029549 L1: 0.017768 Grad: 0.117529 Thermal: 0.000573 LR: 2.64e-06\n",
      "Epoch  39 [3500/10697 ( 32.7%)] Loss: 0.022776 L1: 0.013011 Grad: 0.097456 Thermal: 0.000390 LR: 2.64e-06\n",
      "Epoch  39 [3500/10697 ( 32.7%)] Loss: 0.022776 L1: 0.013011 Grad: 0.097456 Thermal: 0.000390 LR: 2.64e-06\n",
      "Epoch  39 [3550/10697 ( 33.2%)] Loss: 0.024278 L1: 0.014128 Grad: 0.101304 Thermal: 0.000393 LR: 2.64e-06\n",
      "Epoch  39 [3550/10697 ( 33.2%)] Loss: 0.024278 L1: 0.014128 Grad: 0.101304 Thermal: 0.000393 LR: 2.64e-06\n",
      "Epoch  39 [3600/10697 ( 33.7%)] Loss: 0.024766 L1: 0.013871 Grad: 0.108756 Thermal: 0.000381 LR: 2.64e-06\n",
      "Epoch  39 [3600/10697 ( 33.7%)] Loss: 0.024766 L1: 0.013871 Grad: 0.108756 Thermal: 0.000381 LR: 2.64e-06\n",
      "Epoch  39 [3650/10697 ( 34.1%)] Loss: 0.028609 L1: 0.016195 Grad: 0.123880 Thermal: 0.000537 LR: 2.64e-06\n",
      "Epoch  39 [3650/10697 ( 34.1%)] Loss: 0.028609 L1: 0.016195 Grad: 0.123880 Thermal: 0.000537 LR: 2.64e-06\n",
      "Epoch  39 [3700/10697 ( 34.6%)] Loss: 0.027294 L1: 0.015788 Grad: 0.114824 Thermal: 0.000480 LR: 2.64e-06\n",
      "Epoch  39 [3700/10697 ( 34.6%)] Loss: 0.027294 L1: 0.015788 Grad: 0.114824 Thermal: 0.000480 LR: 2.64e-06\n",
      "Epoch  39 [3750/10697 ( 35.1%)] Loss: 0.030359 L1: 0.017333 Grad: 0.129967 Thermal: 0.000580 LR: 2.64e-06\n",
      "Epoch  39 [3750/10697 ( 35.1%)] Loss: 0.030359 L1: 0.017333 Grad: 0.129967 Thermal: 0.000580 LR: 2.64e-06\n",
      "Epoch  39 [3800/10697 ( 35.5%)] Loss: 0.024260 L1: 0.014175 Grad: 0.100655 Thermal: 0.000389 LR: 2.64e-06\n",
      "Epoch  39 [3800/10697 ( 35.5%)] Loss: 0.024260 L1: 0.014175 Grad: 0.100655 Thermal: 0.000389 LR: 2.64e-06\n",
      "Epoch  39 [3850/10697 ( 36.0%)] Loss: 0.028264 L1: 0.016565 Grad: 0.116736 Thermal: 0.000515 LR: 2.64e-06\n",
      "Epoch  39 [3850/10697 ( 36.0%)] Loss: 0.028264 L1: 0.016565 Grad: 0.116736 Thermal: 0.000515 LR: 2.64e-06\n",
      "Epoch  39 [3900/10697 ( 36.5%)] Loss: 0.026847 L1: 0.015886 Grad: 0.109383 Thermal: 0.000458 LR: 2.64e-06\n",
      "Epoch  39 [3900/10697 ( 36.5%)] Loss: 0.026847 L1: 0.015886 Grad: 0.109383 Thermal: 0.000458 LR: 2.64e-06\n",
      "Epoch  39 [3950/10697 ( 36.9%)] Loss: 0.024655 L1: 0.014602 Grad: 0.100315 Thermal: 0.000432 LR: 2.64e-06\n",
      "Epoch  39 [3950/10697 ( 36.9%)] Loss: 0.024655 L1: 0.014602 Grad: 0.100315 Thermal: 0.000432 LR: 2.64e-06\n",
      "Epoch  39 [4000/10697 ( 37.4%)] Loss: 0.022150 L1: 0.012927 Grad: 0.092055 Thermal: 0.000351 LR: 2.64e-06\n",
      "Epoch  39 [4000/10697 ( 37.4%)] Loss: 0.022150 L1: 0.012927 Grad: 0.092055 Thermal: 0.000351 LR: 2.64e-06\n",
      "Epoch  39 [4050/10697 ( 37.9%)] Loss: 0.027617 L1: 0.015521 Grad: 0.120674 Thermal: 0.000568 LR: 2.64e-06\n",
      "Epoch  39 [4050/10697 ( 37.9%)] Loss: 0.027617 L1: 0.015521 Grad: 0.120674 Thermal: 0.000568 LR: 2.64e-06\n",
      "Epoch  39 [4100/10697 ( 38.3%)] Loss: 0.030380 L1: 0.018169 Grad: 0.121759 Thermal: 0.000706 LR: 2.64e-06\n",
      "Epoch  39 [4100/10697 ( 38.3%)] Loss: 0.030380 L1: 0.018169 Grad: 0.121759 Thermal: 0.000706 LR: 2.64e-06\n",
      "Epoch  39 [4150/10697 ( 38.8%)] Loss: 0.028898 L1: 0.016991 Grad: 0.118798 Thermal: 0.000543 LR: 2.64e-06\n",
      "Epoch  39 [4150/10697 ( 38.8%)] Loss: 0.028898 L1: 0.016991 Grad: 0.118798 Thermal: 0.000543 LR: 2.64e-06\n",
      "Epoch  39 [4200/10697 ( 39.3%)] Loss: 0.018957 L1: 0.011030 Grad: 0.079131 Thermal: 0.000267 LR: 2.64e-06\n",
      "Epoch  39 [4200/10697 ( 39.3%)] Loss: 0.018957 L1: 0.011030 Grad: 0.079131 Thermal: 0.000267 LR: 2.64e-06\n",
      "Epoch  39 [4250/10697 ( 39.7%)] Loss: 0.024612 L1: 0.014204 Grad: 0.103872 Thermal: 0.000433 LR: 2.64e-06\n",
      "Epoch  39 [4250/10697 ( 39.7%)] Loss: 0.024612 L1: 0.014204 Grad: 0.103872 Thermal: 0.000433 LR: 2.64e-06\n",
      "Epoch  39 [4300/10697 ( 40.2%)] Loss: 0.027193 L1: 0.016186 Grad: 0.109818 Thermal: 0.000499 LR: 2.64e-06\n",
      "Epoch  39 [4300/10697 ( 40.2%)] Loss: 0.027193 L1: 0.016186 Grad: 0.109818 Thermal: 0.000499 LR: 2.64e-06\n",
      "Epoch  39 [4350/10697 ( 40.7%)] Loss: 0.026071 L1: 0.015610 Grad: 0.104381 Thermal: 0.000450 LR: 2.64e-06\n",
      "Epoch  39 [4350/10697 ( 40.7%)] Loss: 0.026071 L1: 0.015610 Grad: 0.104381 Thermal: 0.000450 LR: 2.64e-06\n",
      "Epoch  39 [4400/10697 ( 41.1%)] Loss: 0.022555 L1: 0.013231 Grad: 0.093065 Thermal: 0.000348 LR: 2.64e-06\n",
      "Epoch  39 [4400/10697 ( 41.1%)] Loss: 0.022555 L1: 0.013231 Grad: 0.093065 Thermal: 0.000348 LR: 2.64e-06\n",
      "Epoch  39 [4450/10697 ( 41.6%)] Loss: 0.028288 L1: 0.016034 Grad: 0.122287 Thermal: 0.000517 LR: 2.64e-06\n",
      "Epoch  39 [4450/10697 ( 41.6%)] Loss: 0.028288 L1: 0.016034 Grad: 0.122287 Thermal: 0.000517 LR: 2.64e-06\n",
      "Epoch  39 [4500/10697 ( 42.1%)] Loss: 0.028276 L1: 0.016710 Grad: 0.115391 Thermal: 0.000519 LR: 2.64e-06\n",
      "Epoch  39 [4500/10697 ( 42.1%)] Loss: 0.028276 L1: 0.016710 Grad: 0.115391 Thermal: 0.000519 LR: 2.64e-06\n",
      "Epoch  39 [4550/10697 ( 42.5%)] Loss: 0.023060 L1: 0.013137 Grad: 0.099061 Thermal: 0.000334 LR: 2.64e-06\n",
      "Epoch  39 [4550/10697 ( 42.5%)] Loss: 0.023060 L1: 0.013137 Grad: 0.099061 Thermal: 0.000334 LR: 2.64e-06\n",
      "Epoch  39 [4600/10697 ( 43.0%)] Loss: 0.025254 L1: 0.014447 Grad: 0.107808 Thermal: 0.000516 LR: 2.64e-06\n",
      "Epoch  39 [4600/10697 ( 43.0%)] Loss: 0.025254 L1: 0.014447 Grad: 0.107808 Thermal: 0.000516 LR: 2.64e-06\n",
      "Epoch  39 [4650/10697 ( 43.5%)] Loss: 0.025891 L1: 0.015416 Grad: 0.104536 Thermal: 0.000432 LR: 2.64e-06\n",
      "Epoch  39 [4650/10697 ( 43.5%)] Loss: 0.025891 L1: 0.015416 Grad: 0.104536 Thermal: 0.000432 LR: 2.64e-06\n",
      "Epoch  39 [4700/10697 ( 43.9%)] Loss: 0.022087 L1: 0.012894 Grad: 0.091746 Thermal: 0.000380 LR: 2.64e-06\n",
      "Epoch  39 [4700/10697 ( 43.9%)] Loss: 0.022087 L1: 0.012894 Grad: 0.091746 Thermal: 0.000380 LR: 2.64e-06\n",
      "Epoch  39 [4750/10697 ( 44.4%)] Loss: 0.026257 L1: 0.015493 Grad: 0.107419 Thermal: 0.000440 LR: 2.64e-06\n",
      "Epoch  39 [4750/10697 ( 44.4%)] Loss: 0.026257 L1: 0.015493 Grad: 0.107419 Thermal: 0.000440 LR: 2.64e-06\n",
      "Epoch  39 [4800/10697 ( 44.9%)] Loss: 0.025778 L1: 0.014823 Grad: 0.109339 Thermal: 0.000437 LR: 2.64e-06\n",
      "Epoch  39 [4800/10697 ( 44.9%)] Loss: 0.025778 L1: 0.014823 Grad: 0.109339 Thermal: 0.000437 LR: 2.64e-06\n",
      "Epoch  39 [4850/10697 ( 45.3%)] Loss: 0.025428 L1: 0.014917 Grad: 0.104901 Thermal: 0.000416 LR: 2.64e-06\n",
      "Epoch  39 [4850/10697 ( 45.3%)] Loss: 0.025428 L1: 0.014917 Grad: 0.104901 Thermal: 0.000416 LR: 2.64e-06\n",
      "Epoch  39 [4900/10697 ( 45.8%)] Loss: 0.024566 L1: 0.014119 Grad: 0.104280 Thermal: 0.000371 LR: 2.64e-06\n",
      "Epoch  39 [4900/10697 ( 45.8%)] Loss: 0.024566 L1: 0.014119 Grad: 0.104280 Thermal: 0.000371 LR: 2.64e-06\n",
      "Epoch  39 [4950/10697 ( 46.3%)] Loss: 0.022661 L1: 0.013337 Grad: 0.093069 Thermal: 0.000347 LR: 2.64e-06\n",
      "Epoch  39 [4950/10697 ( 46.3%)] Loss: 0.022661 L1: 0.013337 Grad: 0.093069 Thermal: 0.000347 LR: 2.64e-06\n",
      "Epoch  39 [5000/10697 ( 46.7%)] Loss: 0.030089 L1: 0.017380 Grad: 0.126821 Thermal: 0.000539 LR: 2.64e-06\n",
      "Epoch  39 [5000/10697 ( 46.7%)] Loss: 0.030089 L1: 0.017380 Grad: 0.126821 Thermal: 0.000539 LR: 2.64e-06\n",
      "Epoch  39 [5050/10697 ( 47.2%)] Loss: 0.026761 L1: 0.015875 Grad: 0.108643 Thermal: 0.000434 LR: 2.64e-06\n",
      "Epoch  39 [5050/10697 ( 47.2%)] Loss: 0.026761 L1: 0.015875 Grad: 0.108643 Thermal: 0.000434 LR: 2.64e-06\n",
      "Epoch  39 [5100/10697 ( 47.7%)] Loss: 0.027966 L1: 0.016024 Grad: 0.119197 Thermal: 0.000458 LR: 2.64e-06\n",
      "Epoch  39 [5100/10697 ( 47.7%)] Loss: 0.027966 L1: 0.016024 Grad: 0.119197 Thermal: 0.000458 LR: 2.64e-06\n",
      "Epoch  39 [5150/10697 ( 48.1%)] Loss: 0.026908 L1: 0.015477 Grad: 0.114063 Thermal: 0.000488 LR: 2.64e-06\n",
      "Epoch  39 [5150/10697 ( 48.1%)] Loss: 0.026908 L1: 0.015477 Grad: 0.114063 Thermal: 0.000488 LR: 2.64e-06\n",
      "Epoch  39 [5200/10697 ( 48.6%)] Loss: 0.022665 L1: 0.013232 Grad: 0.094159 Thermal: 0.000326 LR: 2.64e-06\n",
      "Epoch  39 [5200/10697 ( 48.6%)] Loss: 0.022665 L1: 0.013232 Grad: 0.094159 Thermal: 0.000326 LR: 2.64e-06\n",
      "Epoch  39 [5250/10697 ( 49.1%)] Loss: 0.022069 L1: 0.012792 Grad: 0.092611 Thermal: 0.000315 LR: 2.64e-06\n",
      "Epoch  39 [5250/10697 ( 49.1%)] Loss: 0.022069 L1: 0.012792 Grad: 0.092611 Thermal: 0.000315 LR: 2.64e-06\n",
      "Epoch  39 [5300/10697 ( 49.5%)] Loss: 0.019453 L1: 0.011148 Grad: 0.082905 Thermal: 0.000281 LR: 2.64e-06\n",
      "Epoch  39 [5300/10697 ( 49.5%)] Loss: 0.019453 L1: 0.011148 Grad: 0.082905 Thermal: 0.000281 LR: 2.64e-06\n",
      "Epoch  39 [5350/10697 ( 50.0%)] Loss: 0.025402 L1: 0.014364 Grad: 0.110174 Thermal: 0.000414 LR: 2.64e-06\n",
      "Epoch  39 [5350/10697 ( 50.0%)] Loss: 0.025402 L1: 0.014364 Grad: 0.110174 Thermal: 0.000414 LR: 2.64e-06\n",
      "Epoch  39 [5400/10697 ( 50.5%)] Loss: 0.016260 L1: 0.009456 Grad: 0.067930 Thermal: 0.000213 LR: 2.64e-06\n",
      "Epoch  39 [5400/10697 ( 50.5%)] Loss: 0.016260 L1: 0.009456 Grad: 0.067930 Thermal: 0.000213 LR: 2.64e-06\n",
      "Epoch  39 [5450/10697 ( 50.9%)] Loss: 0.027688 L1: 0.016324 Grad: 0.113407 Thermal: 0.000477 LR: 2.64e-06\n",
      "Epoch  39 [5450/10697 ( 50.9%)] Loss: 0.027688 L1: 0.016324 Grad: 0.113407 Thermal: 0.000477 LR: 2.64e-06\n",
      "Epoch  39 [5500/10697 ( 51.4%)] Loss: 0.027100 L1: 0.015802 Grad: 0.112733 Thermal: 0.000493 LR: 2.64e-06\n",
      "Epoch  39 [5500/10697 ( 51.4%)] Loss: 0.027100 L1: 0.015802 Grad: 0.112733 Thermal: 0.000493 LR: 2.64e-06\n",
      "Epoch  39 [5550/10697 ( 51.9%)] Loss: 0.025788 L1: 0.014945 Grad: 0.108199 Thermal: 0.000468 LR: 2.64e-06\n",
      "Epoch  39 [5550/10697 ( 51.9%)] Loss: 0.025788 L1: 0.014945 Grad: 0.108199 Thermal: 0.000468 LR: 2.64e-06\n",
      "Epoch  39 [5600/10697 ( 52.4%)] Loss: 0.025228 L1: 0.014626 Grad: 0.105821 Thermal: 0.000410 LR: 2.64e-06\n",
      "Epoch  39 [5600/10697 ( 52.4%)] Loss: 0.025228 L1: 0.014626 Grad: 0.105821 Thermal: 0.000410 LR: 2.64e-06\n",
      "Epoch  39 [5650/10697 ( 52.8%)] Loss: 0.022736 L1: 0.013155 Grad: 0.095616 Thermal: 0.000384 LR: 2.64e-06\n",
      "Epoch  39 [5650/10697 ( 52.8%)] Loss: 0.022736 L1: 0.013155 Grad: 0.095616 Thermal: 0.000384 LR: 2.64e-06\n",
      "Epoch  39 [5700/10697 ( 53.3%)] Loss: 0.021407 L1: 0.012701 Grad: 0.086906 Thermal: 0.000314 LR: 2.64e-06\n",
      "Epoch  39 [5700/10697 ( 53.3%)] Loss: 0.021407 L1: 0.012701 Grad: 0.086906 Thermal: 0.000314 LR: 2.64e-06\n",
      "Epoch  39 [5750/10697 ( 53.8%)] Loss: 0.021444 L1: 0.012493 Grad: 0.089343 Thermal: 0.000334 LR: 2.64e-06\n",
      "Epoch  39 [5750/10697 ( 53.8%)] Loss: 0.021444 L1: 0.012493 Grad: 0.089343 Thermal: 0.000334 LR: 2.64e-06\n",
      "Epoch  39 [5800/10697 ( 54.2%)] Loss: 0.026617 L1: 0.015679 Grad: 0.109167 Thermal: 0.000433 LR: 2.64e-06\n",
      "Epoch  39 [5800/10697 ( 54.2%)] Loss: 0.026617 L1: 0.015679 Grad: 0.109167 Thermal: 0.000433 LR: 2.64e-06\n",
      "Epoch  39 [5850/10697 ( 54.7%)] Loss: 0.023330 L1: 0.013743 Grad: 0.095690 Thermal: 0.000360 LR: 2.64e-06\n",
      "Epoch  39 [5850/10697 ( 54.7%)] Loss: 0.023330 L1: 0.013743 Grad: 0.095690 Thermal: 0.000360 LR: 2.64e-06\n",
      "Epoch  39 [5900/10697 ( 55.2%)] Loss: 0.023223 L1: 0.013630 Grad: 0.095751 Thermal: 0.000364 LR: 2.64e-06\n",
      "Epoch  39 [5900/10697 ( 55.2%)] Loss: 0.023223 L1: 0.013630 Grad: 0.095751 Thermal: 0.000364 LR: 2.64e-06\n",
      "Epoch  39 [5950/10697 ( 55.6%)] Loss: 0.033745 L1: 0.019606 Grad: 0.141022 Thermal: 0.000726 LR: 2.64e-06\n",
      "Epoch  39 [5950/10697 ( 55.6%)] Loss: 0.033745 L1: 0.019606 Grad: 0.141022 Thermal: 0.000726 LR: 2.64e-06\n",
      "Epoch  39 [6000/10697 ( 56.1%)] Loss: 0.024985 L1: 0.014799 Grad: 0.101643 Thermal: 0.000431 LR: 2.64e-06\n",
      "Epoch  39 [6000/10697 ( 56.1%)] Loss: 0.024985 L1: 0.014799 Grad: 0.101643 Thermal: 0.000431 LR: 2.64e-06\n",
      "Epoch  39 [6050/10697 ( 56.6%)] Loss: 0.024592 L1: 0.014395 Grad: 0.101759 Thermal: 0.000431 LR: 2.64e-06\n",
      "Epoch  39 [6050/10697 ( 56.6%)] Loss: 0.024592 L1: 0.014395 Grad: 0.101759 Thermal: 0.000431 LR: 2.64e-06\n",
      "Epoch  39 [6100/10697 ( 57.0%)] Loss: 0.032098 L1: 0.018846 Grad: 0.132160 Thermal: 0.000727 LR: 2.64e-06\n",
      "Epoch  39 [6100/10697 ( 57.0%)] Loss: 0.032098 L1: 0.018846 Grad: 0.132160 Thermal: 0.000727 LR: 2.64e-06\n",
      "Epoch  39 [6150/10697 ( 57.5%)] Loss: 0.032796 L1: 0.019405 Grad: 0.133567 Thermal: 0.000684 LR: 2.64e-06\n",
      "Epoch  39 [6150/10697 ( 57.5%)] Loss: 0.032796 L1: 0.019405 Grad: 0.133567 Thermal: 0.000684 LR: 2.64e-06\n",
      "Epoch  39 [6200/10697 ( 58.0%)] Loss: 0.018450 L1: 0.010907 Grad: 0.075301 Thermal: 0.000265 LR: 2.64e-06\n",
      "Epoch  39 [6200/10697 ( 58.0%)] Loss: 0.018450 L1: 0.010907 Grad: 0.075301 Thermal: 0.000265 LR: 2.64e-06\n",
      "Epoch  39 [6250/10697 ( 58.4%)] Loss: 0.021760 L1: 0.012773 Grad: 0.089696 Thermal: 0.000341 LR: 2.64e-06\n",
      "Epoch  39 [6250/10697 ( 58.4%)] Loss: 0.021760 L1: 0.012773 Grad: 0.089696 Thermal: 0.000341 LR: 2.64e-06\n",
      "Epoch  39 [6300/10697 ( 58.9%)] Loss: 0.030520 L1: 0.017845 Grad: 0.126447 Thermal: 0.000617 LR: 2.64e-06\n",
      "Epoch  39 [6300/10697 ( 58.9%)] Loss: 0.030520 L1: 0.017845 Grad: 0.126447 Thermal: 0.000617 LR: 2.64e-06\n",
      "Epoch  39 [6350/10697 ( 59.4%)] Loss: 0.022144 L1: 0.012746 Grad: 0.093822 Thermal: 0.000318 LR: 2.64e-06\n",
      "Epoch  39 [6350/10697 ( 59.4%)] Loss: 0.022144 L1: 0.012746 Grad: 0.093822 Thermal: 0.000318 LR: 2.64e-06\n",
      "Epoch  39 [6400/10697 ( 59.8%)] Loss: 0.026564 L1: 0.015026 Grad: 0.115154 Thermal: 0.000452 LR: 2.64e-06\n",
      "Epoch  39 [6400/10697 ( 59.8%)] Loss: 0.026564 L1: 0.015026 Grad: 0.115154 Thermal: 0.000452 LR: 2.64e-06\n",
      "Epoch  39 [6450/10697 ( 60.3%)] Loss: 0.026051 L1: 0.015236 Grad: 0.107944 Thermal: 0.000425 LR: 2.64e-06\n",
      "Epoch  39 [6450/10697 ( 60.3%)] Loss: 0.026051 L1: 0.015236 Grad: 0.107944 Thermal: 0.000425 LR: 2.64e-06\n",
      "Epoch  39 [6500/10697 ( 60.8%)] Loss: 0.027454 L1: 0.016469 Grad: 0.109601 Thermal: 0.000497 LR: 2.64e-06\n",
      "Epoch  39 [6500/10697 ( 60.8%)] Loss: 0.027454 L1: 0.016469 Grad: 0.109601 Thermal: 0.000497 LR: 2.64e-06\n",
      "Epoch  39 [6550/10697 ( 61.2%)] Loss: 0.028630 L1: 0.017011 Grad: 0.115936 Thermal: 0.000514 LR: 2.64e-06\n",
      "Epoch  39 [6550/10697 ( 61.2%)] Loss: 0.028630 L1: 0.017011 Grad: 0.115936 Thermal: 0.000514 LR: 2.64e-06\n",
      "Epoch  39 [6600/10697 ( 61.7%)] Loss: 0.018916 L1: 0.010480 Grad: 0.084223 Thermal: 0.000260 LR: 2.64e-06\n",
      "Epoch  39 [6600/10697 ( 61.7%)] Loss: 0.018916 L1: 0.010480 Grad: 0.084223 Thermal: 0.000260 LR: 2.64e-06\n",
      "Epoch  39 [6650/10697 ( 62.2%)] Loss: 0.025895 L1: 0.015291 Grad: 0.105819 Thermal: 0.000438 LR: 2.64e-06\n",
      "Epoch  39 [6650/10697 ( 62.2%)] Loss: 0.025895 L1: 0.015291 Grad: 0.105819 Thermal: 0.000438 LR: 2.64e-06\n",
      "Epoch  39 [6700/10697 ( 62.6%)] Loss: 0.027552 L1: 0.016289 Grad: 0.112394 Thermal: 0.000479 LR: 2.64e-06\n",
      "Epoch  39 [6700/10697 ( 62.6%)] Loss: 0.027552 L1: 0.016289 Grad: 0.112394 Thermal: 0.000479 LR: 2.64e-06\n",
      "Epoch  39 [6750/10697 ( 63.1%)] Loss: 0.021922 L1: 0.012713 Grad: 0.091932 Thermal: 0.000317 LR: 2.64e-06\n",
      "Epoch  39 [6750/10697 ( 63.1%)] Loss: 0.021922 L1: 0.012713 Grad: 0.091932 Thermal: 0.000317 LR: 2.64e-06\n",
      "Epoch  39 [6800/10697 ( 63.6%)] Loss: 0.022509 L1: 0.013170 Grad: 0.093219 Thermal: 0.000345 LR: 2.64e-06\n",
      "Epoch  39 [6800/10697 ( 63.6%)] Loss: 0.022509 L1: 0.013170 Grad: 0.093219 Thermal: 0.000345 LR: 2.64e-06\n",
      "Epoch  39 [6850/10697 ( 64.0%)] Loss: 0.026980 L1: 0.016160 Grad: 0.107970 Thermal: 0.000460 LR: 2.64e-06\n",
      "Epoch  39 [6850/10697 ( 64.0%)] Loss: 0.026980 L1: 0.016160 Grad: 0.107970 Thermal: 0.000460 LR: 2.64e-06\n",
      "Epoch  39 [6900/10697 ( 64.5%)] Loss: 0.025222 L1: 0.014373 Grad: 0.108280 Thermal: 0.000425 LR: 2.64e-06\n",
      "Epoch  39 [6900/10697 ( 64.5%)] Loss: 0.025222 L1: 0.014373 Grad: 0.108280 Thermal: 0.000425 LR: 2.64e-06\n",
      "Epoch  39 [6950/10697 ( 65.0%)] Loss: 0.027540 L1: 0.015520 Grad: 0.119947 Thermal: 0.000504 LR: 2.64e-06\n",
      "Epoch  39 [6950/10697 ( 65.0%)] Loss: 0.027540 L1: 0.015520 Grad: 0.119947 Thermal: 0.000504 LR: 2.64e-06\n",
      "Epoch  39 [7000/10697 ( 65.4%)] Loss: 0.023745 L1: 0.014204 Grad: 0.095226 Thermal: 0.000382 LR: 2.64e-06\n",
      "Epoch  39 [7000/10697 ( 65.4%)] Loss: 0.023745 L1: 0.014204 Grad: 0.095226 Thermal: 0.000382 LR: 2.64e-06\n",
      "Epoch  39 [7050/10697 ( 65.9%)] Loss: 0.028259 L1: 0.016277 Grad: 0.119538 Thermal: 0.000566 LR: 2.64e-06\n",
      "Epoch  39 [7050/10697 ( 65.9%)] Loss: 0.028259 L1: 0.016277 Grad: 0.119538 Thermal: 0.000566 LR: 2.64e-06\n",
      "Epoch  39 [7100/10697 ( 66.4%)] Loss: 0.028178 L1: 0.016342 Grad: 0.118110 Thermal: 0.000500 LR: 2.64e-06\n",
      "Epoch  39 [7100/10697 ( 66.4%)] Loss: 0.028178 L1: 0.016342 Grad: 0.118110 Thermal: 0.000500 LR: 2.64e-06\n",
      "Epoch  39 [7150/10697 ( 66.8%)] Loss: 0.034285 L1: 0.020031 Grad: 0.142128 Thermal: 0.000834 LR: 2.64e-06\n",
      "Epoch  39 [7150/10697 ( 66.8%)] Loss: 0.034285 L1: 0.020031 Grad: 0.142128 Thermal: 0.000834 LR: 2.64e-06\n",
      "Epoch  39 [7200/10697 ( 67.3%)] Loss: 0.020891 L1: 0.011866 Grad: 0.090102 Thermal: 0.000295 LR: 2.64e-06\n",
      "Epoch  39 [7200/10697 ( 67.3%)] Loss: 0.020891 L1: 0.011866 Grad: 0.090102 Thermal: 0.000295 LR: 2.64e-06\n",
      "Epoch  39 [7250/10697 ( 67.8%)] Loss: 0.028997 L1: 0.017225 Grad: 0.117425 Thermal: 0.000581 LR: 2.64e-06\n",
      "Epoch  39 [7250/10697 ( 67.8%)] Loss: 0.028997 L1: 0.017225 Grad: 0.117425 Thermal: 0.000581 LR: 2.64e-06\n",
      "Epoch  39 [7300/10697 ( 68.2%)] Loss: 0.026614 L1: 0.016092 Grad: 0.104997 Thermal: 0.000455 LR: 2.64e-06\n",
      "Epoch  39 [7300/10697 ( 68.2%)] Loss: 0.026614 L1: 0.016092 Grad: 0.104997 Thermal: 0.000455 LR: 2.64e-06\n",
      "Epoch  39 [7350/10697 ( 68.7%)] Loss: 0.028922 L1: 0.016527 Grad: 0.123685 Thermal: 0.000531 LR: 2.64e-06\n",
      "Epoch  39 [7350/10697 ( 68.7%)] Loss: 0.028922 L1: 0.016527 Grad: 0.123685 Thermal: 0.000531 LR: 2.64e-06\n",
      "Epoch  39 [7400/10697 ( 69.2%)] Loss: 0.025955 L1: 0.015430 Grad: 0.105044 Thermal: 0.000418 LR: 2.64e-06\n",
      "Epoch  39 [7400/10697 ( 69.2%)] Loss: 0.025955 L1: 0.015430 Grad: 0.105044 Thermal: 0.000418 LR: 2.64e-06\n",
      "Epoch  39 [7450/10697 ( 69.6%)] Loss: 0.032965 L1: 0.019152 Grad: 0.137795 Thermal: 0.000683 LR: 2.64e-06\n",
      "Epoch  39 [7450/10697 ( 69.6%)] Loss: 0.032965 L1: 0.019152 Grad: 0.137795 Thermal: 0.000683 LR: 2.64e-06\n",
      "Epoch  39 [7500/10697 ( 70.1%)] Loss: 0.033396 L1: 0.019715 Grad: 0.136437 Thermal: 0.000751 LR: 2.64e-06\n",
      "Epoch  39 [7500/10697 ( 70.1%)] Loss: 0.033396 L1: 0.019715 Grad: 0.136437 Thermal: 0.000751 LR: 2.64e-06\n",
      "Epoch  39 [7550/10697 ( 70.6%)] Loss: 0.025282 L1: 0.014536 Grad: 0.107253 Thermal: 0.000400 LR: 2.64e-06\n",
      "Epoch  39 [7550/10697 ( 70.6%)] Loss: 0.025282 L1: 0.014536 Grad: 0.107253 Thermal: 0.000400 LR: 2.64e-06\n",
      "Epoch  39 [7600/10697 ( 71.0%)] Loss: 0.025968 L1: 0.015188 Grad: 0.107589 Thermal: 0.000435 LR: 2.64e-06\n",
      "Epoch  39 [7600/10697 ( 71.0%)] Loss: 0.025968 L1: 0.015188 Grad: 0.107589 Thermal: 0.000435 LR: 2.64e-06\n",
      "Epoch  39 [7650/10697 ( 71.5%)] Loss: 0.028187 L1: 0.016724 Grad: 0.114372 Thermal: 0.000501 LR: 2.64e-06\n",
      "Epoch  39 [7650/10697 ( 71.5%)] Loss: 0.028187 L1: 0.016724 Grad: 0.114372 Thermal: 0.000501 LR: 2.64e-06\n",
      "Epoch  39 [7700/10697 ( 72.0%)] Loss: 0.032769 L1: 0.019587 Grad: 0.131486 Thermal: 0.000665 LR: 2.64e-06\n",
      "Epoch  39 [7700/10697 ( 72.0%)] Loss: 0.032769 L1: 0.019587 Grad: 0.131486 Thermal: 0.000665 LR: 2.64e-06\n",
      "Epoch  39 [7750/10697 ( 72.5%)] Loss: 0.023995 L1: 0.013596 Grad: 0.103813 Thermal: 0.000351 LR: 2.64e-06\n",
      "Epoch  39 [7750/10697 ( 72.5%)] Loss: 0.023995 L1: 0.013596 Grad: 0.103813 Thermal: 0.000351 LR: 2.64e-06\n",
      "Epoch  39 [7800/10697 ( 72.9%)] Loss: 0.032964 L1: 0.018986 Grad: 0.139460 Thermal: 0.000655 LR: 2.64e-06\n",
      "Epoch  39 [7800/10697 ( 72.9%)] Loss: 0.032964 L1: 0.018986 Grad: 0.139460 Thermal: 0.000655 LR: 2.64e-06\n",
      "Epoch  39 [7850/10697 ( 73.4%)] Loss: 0.024495 L1: 0.014781 Grad: 0.096933 Thermal: 0.000414 LR: 2.64e-06\n",
      "Epoch  39 [7850/10697 ( 73.4%)] Loss: 0.024495 L1: 0.014781 Grad: 0.096933 Thermal: 0.000414 LR: 2.64e-06\n",
      "Epoch  39 [7900/10697 ( 73.9%)] Loss: 0.025966 L1: 0.015342 Grad: 0.106020 Thermal: 0.000438 LR: 2.64e-06\n",
      "Epoch  39 [7900/10697 ( 73.9%)] Loss: 0.025966 L1: 0.015342 Grad: 0.106020 Thermal: 0.000438 LR: 2.64e-06\n",
      "Epoch  39 [7950/10697 ( 74.3%)] Loss: 0.030775 L1: 0.017856 Grad: 0.128902 Thermal: 0.000585 LR: 2.64e-06\n",
      "Epoch  39 [7950/10697 ( 74.3%)] Loss: 0.030775 L1: 0.017856 Grad: 0.128902 Thermal: 0.000585 LR: 2.64e-06\n",
      "Epoch  39 [8000/10697 ( 74.8%)] Loss: 0.021822 L1: 0.012831 Grad: 0.089741 Thermal: 0.000339 LR: 2.64e-06\n",
      "Epoch  39 [8000/10697 ( 74.8%)] Loss: 0.021822 L1: 0.012831 Grad: 0.089741 Thermal: 0.000339 LR: 2.64e-06\n",
      "Epoch  39 [8050/10697 ( 75.3%)] Loss: 0.028784 L1: 0.016496 Grad: 0.122569 Thermal: 0.000623 LR: 2.64e-06\n",
      "Epoch  39 [8050/10697 ( 75.3%)] Loss: 0.028784 L1: 0.016496 Grad: 0.122569 Thermal: 0.000623 LR: 2.64e-06\n",
      "Epoch  39 [8100/10697 ( 75.7%)] Loss: 0.027364 L1: 0.016482 Grad: 0.108588 Thermal: 0.000469 LR: 2.64e-06\n",
      "Epoch  39 [8100/10697 ( 75.7%)] Loss: 0.027364 L1: 0.016482 Grad: 0.108588 Thermal: 0.000469 LR: 2.64e-06\n",
      "Epoch  39 [8150/10697 ( 76.2%)] Loss: 0.026943 L1: 0.015220 Grad: 0.117005 Thermal: 0.000457 LR: 2.64e-06\n",
      "Epoch  39 [8150/10697 ( 76.2%)] Loss: 0.026943 L1: 0.015220 Grad: 0.117005 Thermal: 0.000457 LR: 2.64e-06\n",
      "Epoch  39 [8200/10697 ( 76.7%)] Loss: 0.020097 L1: 0.011511 Grad: 0.085722 Thermal: 0.000272 LR: 2.64e-06\n",
      "Epoch  39 [8200/10697 ( 76.7%)] Loss: 0.020097 L1: 0.011511 Grad: 0.085722 Thermal: 0.000272 LR: 2.64e-06\n",
      "Epoch  39 [8250/10697 ( 77.1%)] Loss: 0.028568 L1: 0.016335 Grad: 0.122075 Thermal: 0.000507 LR: 2.64e-06\n",
      "Epoch  39 [8250/10697 ( 77.1%)] Loss: 0.028568 L1: 0.016335 Grad: 0.122075 Thermal: 0.000507 LR: 2.64e-06\n",
      "Epoch  39 [8300/10697 ( 77.6%)] Loss: 0.026492 L1: 0.015767 Grad: 0.107012 Thermal: 0.000476 LR: 2.64e-06\n",
      "Epoch  39 [8300/10697 ( 77.6%)] Loss: 0.026492 L1: 0.015767 Grad: 0.107012 Thermal: 0.000476 LR: 2.64e-06\n",
      "Epoch  39 [8350/10697 ( 78.1%)] Loss: 0.027677 L1: 0.016490 Grad: 0.111618 Thermal: 0.000505 LR: 2.64e-06\n",
      "Epoch  39 [8350/10697 ( 78.1%)] Loss: 0.027677 L1: 0.016490 Grad: 0.111618 Thermal: 0.000505 LR: 2.64e-06\n",
      "Epoch  39 [8400/10697 ( 78.5%)] Loss: 0.025368 L1: 0.015254 Grad: 0.100931 Thermal: 0.000425 LR: 2.64e-06\n",
      "Epoch  39 [8400/10697 ( 78.5%)] Loss: 0.025368 L1: 0.015254 Grad: 0.100931 Thermal: 0.000425 LR: 2.64e-06\n",
      "Epoch  39 [8450/10697 ( 79.0%)] Loss: 0.028412 L1: 0.016473 Grad: 0.119133 Thermal: 0.000519 LR: 2.64e-06\n",
      "Epoch  39 [8450/10697 ( 79.0%)] Loss: 0.028412 L1: 0.016473 Grad: 0.119133 Thermal: 0.000519 LR: 2.64e-06\n",
      "Epoch  39 [8500/10697 ( 79.5%)] Loss: 0.024007 L1: 0.013936 Grad: 0.100522 Thermal: 0.000371 LR: 2.64e-06\n",
      "Epoch  39 [8500/10697 ( 79.5%)] Loss: 0.024007 L1: 0.013936 Grad: 0.100522 Thermal: 0.000371 LR: 2.64e-06\n",
      "Epoch  39 [8550/10697 ( 79.9%)] Loss: 0.030081 L1: 0.017508 Grad: 0.125395 Thermal: 0.000661 LR: 2.64e-06\n",
      "Epoch  39 [8550/10697 ( 79.9%)] Loss: 0.030081 L1: 0.017508 Grad: 0.125395 Thermal: 0.000661 LR: 2.64e-06\n",
      "Epoch  39 [8600/10697 ( 80.4%)] Loss: 0.026482 L1: 0.015464 Grad: 0.109937 Thermal: 0.000482 LR: 2.64e-06\n",
      "Epoch  39 [8600/10697 ( 80.4%)] Loss: 0.026482 L1: 0.015464 Grad: 0.109937 Thermal: 0.000482 LR: 2.64e-06\n",
      "Epoch  39 [8650/10697 ( 80.9%)] Loss: 0.026549 L1: 0.015991 Grad: 0.105360 Thermal: 0.000439 LR: 2.64e-06\n",
      "Epoch  39 [8650/10697 ( 80.9%)] Loss: 0.026549 L1: 0.015991 Grad: 0.105360 Thermal: 0.000439 LR: 2.64e-06\n",
      "Epoch  39 [8700/10697 ( 81.3%)] Loss: 0.025004 L1: 0.014525 Grad: 0.104570 Thermal: 0.000438 LR: 2.64e-06\n",
      "Epoch  39 [8700/10697 ( 81.3%)] Loss: 0.025004 L1: 0.014525 Grad: 0.104570 Thermal: 0.000438 LR: 2.64e-06\n",
      "Epoch  39 [8750/10697 ( 81.8%)] Loss: 0.027355 L1: 0.015758 Grad: 0.115757 Thermal: 0.000427 LR: 2.64e-06\n",
      "Epoch  39 [8750/10697 ( 81.8%)] Loss: 0.027355 L1: 0.015758 Grad: 0.115757 Thermal: 0.000427 LR: 2.64e-06\n",
      "Epoch  39 [8800/10697 ( 82.3%)] Loss: 0.029124 L1: 0.016848 Grad: 0.122493 Thermal: 0.000539 LR: 2.64e-06\n",
      "Epoch  39 [8800/10697 ( 82.3%)] Loss: 0.029124 L1: 0.016848 Grad: 0.122493 Thermal: 0.000539 LR: 2.64e-06\n",
      "Epoch  39 [8850/10697 ( 82.7%)] Loss: 0.024001 L1: 0.013704 Grad: 0.102799 Thermal: 0.000350 LR: 2.64e-06\n",
      "Epoch  39 [8850/10697 ( 82.7%)] Loss: 0.024001 L1: 0.013704 Grad: 0.102799 Thermal: 0.000350 LR: 2.64e-06\n",
      "Epoch  39 [8900/10697 ( 83.2%)] Loss: 0.026600 L1: 0.015567 Grad: 0.110115 Thermal: 0.000436 LR: 2.64e-06\n",
      "Epoch  39 [8900/10697 ( 83.2%)] Loss: 0.026600 L1: 0.015567 Grad: 0.110115 Thermal: 0.000436 LR: 2.64e-06\n",
      "Epoch  39 [8950/10697 ( 83.7%)] Loss: 0.027831 L1: 0.016084 Grad: 0.117197 Thermal: 0.000537 LR: 2.64e-06\n",
      "Epoch  39 [8950/10697 ( 83.7%)] Loss: 0.027831 L1: 0.016084 Grad: 0.117197 Thermal: 0.000537 LR: 2.64e-06\n",
      "Epoch  39 [9000/10697 ( 84.1%)] Loss: 0.029454 L1: 0.017080 Grad: 0.123435 Thermal: 0.000611 LR: 2.64e-06\n",
      "Epoch  39 [9000/10697 ( 84.1%)] Loss: 0.029454 L1: 0.017080 Grad: 0.123435 Thermal: 0.000611 LR: 2.64e-06\n",
      "Epoch  39 [9050/10697 ( 84.6%)] Loss: 0.026323 L1: 0.015173 Grad: 0.111284 Thermal: 0.000437 LR: 2.64e-06\n",
      "Epoch  39 [9050/10697 ( 84.6%)] Loss: 0.026323 L1: 0.015173 Grad: 0.111284 Thermal: 0.000437 LR: 2.64e-06\n",
      "Epoch  39 [9100/10697 ( 85.1%)] Loss: 0.034309 L1: 0.020123 Grad: 0.141481 Thermal: 0.000745 LR: 2.64e-06\n",
      "Epoch  39 [9100/10697 ( 85.1%)] Loss: 0.034309 L1: 0.020123 Grad: 0.141481 Thermal: 0.000745 LR: 2.64e-06\n",
      "Epoch  39 [9150/10697 ( 85.5%)] Loss: 0.026369 L1: 0.015600 Grad: 0.107476 Thermal: 0.000444 LR: 2.64e-06\n",
      "Epoch  39 [9150/10697 ( 85.5%)] Loss: 0.026369 L1: 0.015600 Grad: 0.107476 Thermal: 0.000444 LR: 2.64e-06\n",
      "Epoch  39 [9200/10697 ( 86.0%)] Loss: 0.027797 L1: 0.016784 Grad: 0.109880 Thermal: 0.000501 LR: 2.64e-06\n",
      "Epoch  39 [9200/10697 ( 86.0%)] Loss: 0.027797 L1: 0.016784 Grad: 0.109880 Thermal: 0.000501 LR: 2.64e-06\n",
      "Epoch  39 [9250/10697 ( 86.5%)] Loss: 0.027704 L1: 0.016223 Grad: 0.114573 Thermal: 0.000471 LR: 2.64e-06\n",
      "Epoch  39 [9250/10697 ( 86.5%)] Loss: 0.027704 L1: 0.016223 Grad: 0.114573 Thermal: 0.000471 LR: 2.64e-06\n",
      "Epoch  39 [9300/10697 ( 86.9%)] Loss: 0.022940 L1: 0.013311 Grad: 0.096123 Thermal: 0.000351 LR: 2.64e-06\n",
      "Epoch  39 [9300/10697 ( 86.9%)] Loss: 0.022940 L1: 0.013311 Grad: 0.096123 Thermal: 0.000351 LR: 2.64e-06\n",
      "Epoch  39 [9350/10697 ( 87.4%)] Loss: 0.026072 L1: 0.015543 Grad: 0.105067 Thermal: 0.000437 LR: 2.64e-06\n",
      "Epoch  39 [9350/10697 ( 87.4%)] Loss: 0.026072 L1: 0.015543 Grad: 0.105067 Thermal: 0.000437 LR: 2.64e-06\n",
      "Epoch  39 [9400/10697 ( 87.9%)] Loss: 0.025624 L1: 0.015493 Grad: 0.101091 Thermal: 0.000430 LR: 2.64e-06\n",
      "Epoch  39 [9400/10697 ( 87.9%)] Loss: 0.025624 L1: 0.015493 Grad: 0.101091 Thermal: 0.000430 LR: 2.64e-06\n",
      "Epoch  39 [9450/10697 ( 88.3%)] Loss: 0.021504 L1: 0.012519 Grad: 0.089689 Thermal: 0.000328 LR: 2.64e-06\n",
      "Epoch  39 [9450/10697 ( 88.3%)] Loss: 0.021504 L1: 0.012519 Grad: 0.089689 Thermal: 0.000328 LR: 2.64e-06\n",
      "Epoch  39 [9500/10697 ( 88.8%)] Loss: 0.024873 L1: 0.014305 Grad: 0.105486 Thermal: 0.000386 LR: 2.64e-06\n",
      "Epoch  39 [9500/10697 ( 88.8%)] Loss: 0.024873 L1: 0.014305 Grad: 0.105486 Thermal: 0.000386 LR: 2.64e-06\n",
      "Epoch  39 [9550/10697 ( 89.3%)] Loss: 0.022192 L1: 0.013244 Grad: 0.089309 Thermal: 0.000335 LR: 2.64e-06\n",
      "Epoch  39 [9550/10697 ( 89.3%)] Loss: 0.022192 L1: 0.013244 Grad: 0.089309 Thermal: 0.000335 LR: 2.64e-06\n",
      "Epoch  39 [9600/10697 ( 89.7%)] Loss: 0.024371 L1: 0.014113 Grad: 0.102380 Thermal: 0.000403 LR: 2.64e-06\n",
      "Epoch  39 [9600/10697 ( 89.7%)] Loss: 0.024371 L1: 0.014113 Grad: 0.102380 Thermal: 0.000403 LR: 2.64e-06\n",
      "Epoch  39 [9650/10697 ( 90.2%)] Loss: 0.028741 L1: 0.016774 Grad: 0.119418 Thermal: 0.000506 LR: 2.64e-06\n",
      "Epoch  39 [9650/10697 ( 90.2%)] Loss: 0.028741 L1: 0.016774 Grad: 0.119418 Thermal: 0.000506 LR: 2.64e-06\n",
      "Epoch  39 [9700/10697 ( 90.7%)] Loss: 0.026831 L1: 0.016044 Grad: 0.107633 Thermal: 0.000469 LR: 2.64e-06\n",
      "Epoch  39 [9700/10697 ( 90.7%)] Loss: 0.026831 L1: 0.016044 Grad: 0.107633 Thermal: 0.000469 LR: 2.64e-06\n",
      "Epoch  39 [9750/10697 ( 91.1%)] Loss: 0.029423 L1: 0.017461 Grad: 0.119336 Thermal: 0.000577 LR: 2.64e-06\n",
      "Epoch  39 [9750/10697 ( 91.1%)] Loss: 0.029423 L1: 0.017461 Grad: 0.119336 Thermal: 0.000577 LR: 2.64e-06\n",
      "Epoch  39 [9800/10697 ( 91.6%)] Loss: 0.022984 L1: 0.013562 Grad: 0.094029 Thermal: 0.000390 LR: 2.64e-06\n",
      "Epoch  39 [9800/10697 ( 91.6%)] Loss: 0.022984 L1: 0.013562 Grad: 0.094029 Thermal: 0.000390 LR: 2.64e-06\n",
      "Epoch  39 [9850/10697 ( 92.1%)] Loss: 0.025714 L1: 0.015074 Grad: 0.106165 Thermal: 0.000458 LR: 2.64e-06\n",
      "Epoch  39 [9850/10697 ( 92.1%)] Loss: 0.025714 L1: 0.015074 Grad: 0.106165 Thermal: 0.000458 LR: 2.64e-06\n",
      "Epoch  39 [9900/10697 ( 92.5%)] Loss: 0.029074 L1: 0.017051 Grad: 0.119969 Thermal: 0.000517 LR: 2.64e-06\n",
      "Epoch  39 [9900/10697 ( 92.5%)] Loss: 0.029074 L1: 0.017051 Grad: 0.119969 Thermal: 0.000517 LR: 2.64e-06\n",
      "Epoch  39 [9950/10697 ( 93.0%)] Loss: 0.021847 L1: 0.012825 Grad: 0.090062 Thermal: 0.000321 LR: 2.64e-06\n",
      "Epoch  39 [9950/10697 ( 93.0%)] Loss: 0.021847 L1: 0.012825 Grad: 0.090062 Thermal: 0.000321 LR: 2.64e-06\n",
      "Epoch  39 [10000/10697 ( 93.5%)] Loss: 0.030868 L1: 0.017608 Grad: 0.132316 Thermal: 0.000572 LR: 2.64e-06\n",
      "Epoch  39 [10000/10697 ( 93.5%)] Loss: 0.030868 L1: 0.017608 Grad: 0.132316 Thermal: 0.000572 LR: 2.64e-06\n",
      "Epoch  39 [10050/10697 ( 94.0%)] Loss: 0.022630 L1: 0.012973 Grad: 0.096395 Thermal: 0.000348 LR: 2.64e-06\n",
      "Epoch  39 [10050/10697 ( 94.0%)] Loss: 0.022630 L1: 0.012973 Grad: 0.096395 Thermal: 0.000348 LR: 2.64e-06\n",
      "Epoch  39 [10100/10697 ( 94.4%)] Loss: 0.020681 L1: 0.012279 Grad: 0.083865 Thermal: 0.000304 LR: 2.64e-06\n",
      "Epoch  39 [10100/10697 ( 94.4%)] Loss: 0.020681 L1: 0.012279 Grad: 0.083865 Thermal: 0.000304 LR: 2.64e-06\n",
      "Epoch  39 [10150/10697 ( 94.9%)] Loss: 0.023564 L1: 0.013890 Grad: 0.096535 Thermal: 0.000398 LR: 2.64e-06\n",
      "Epoch  39 [10150/10697 ( 94.9%)] Loss: 0.023564 L1: 0.013890 Grad: 0.096535 Thermal: 0.000398 LR: 2.64e-06\n",
      "Epoch  39 [10200/10697 ( 95.4%)] Loss: 0.028951 L1: 0.016909 Grad: 0.120147 Thermal: 0.000534 LR: 2.64e-06\n",
      "Epoch  39 [10200/10697 ( 95.4%)] Loss: 0.028951 L1: 0.016909 Grad: 0.120147 Thermal: 0.000534 LR: 2.64e-06\n",
      "Epoch  39 [10250/10697 ( 95.8%)] Loss: 0.027402 L1: 0.016462 Grad: 0.109158 Thermal: 0.000467 LR: 2.64e-06\n",
      "Epoch  39 [10250/10697 ( 95.8%)] Loss: 0.027402 L1: 0.016462 Grad: 0.109158 Thermal: 0.000467 LR: 2.64e-06\n",
      "Epoch  39 [10300/10697 ( 96.3%)] Loss: 0.029365 L1: 0.016923 Grad: 0.124157 Thermal: 0.000512 LR: 2.64e-06\n",
      "Epoch  39 [10300/10697 ( 96.3%)] Loss: 0.029365 L1: 0.016923 Grad: 0.124157 Thermal: 0.000512 LR: 2.64e-06\n",
      "Epoch  39 [10350/10697 ( 96.8%)] Loss: 0.029053 L1: 0.016641 Grad: 0.123871 Thermal: 0.000493 LR: 2.64e-06\n",
      "Epoch  39 [10350/10697 ( 96.8%)] Loss: 0.029053 L1: 0.016641 Grad: 0.123871 Thermal: 0.000493 LR: 2.64e-06\n",
      "Epoch  39 [10400/10697 ( 97.2%)] Loss: 0.027876 L1: 0.016523 Grad: 0.113268 Thermal: 0.000522 LR: 2.64e-06\n",
      "Epoch  39 [10400/10697 ( 97.2%)] Loss: 0.027876 L1: 0.016523 Grad: 0.113268 Thermal: 0.000522 LR: 2.64e-06\n",
      "Epoch  39 [10450/10697 ( 97.7%)] Loss: 0.029429 L1: 0.016950 Grad: 0.124520 Thermal: 0.000540 LR: 2.64e-06\n",
      "Epoch  39 [10450/10697 ( 97.7%)] Loss: 0.029429 L1: 0.016950 Grad: 0.124520 Thermal: 0.000540 LR: 2.64e-06\n",
      "Epoch  39 [10500/10697 ( 98.2%)] Loss: 0.030155 L1: 0.017457 Grad: 0.126696 Thermal: 0.000562 LR: 2.64e-06\n",
      "Epoch  39 [10500/10697 ( 98.2%)] Loss: 0.030155 L1: 0.017457 Grad: 0.126696 Thermal: 0.000562 LR: 2.64e-06\n",
      "Epoch  39 [10550/10697 ( 98.6%)] Loss: 0.028211 L1: 0.016920 Grad: 0.112658 Thermal: 0.000499 LR: 2.64e-06\n",
      "Epoch  39 [10550/10697 ( 98.6%)] Loss: 0.028211 L1: 0.016920 Grad: 0.112658 Thermal: 0.000499 LR: 2.64e-06\n",
      "Epoch  39 [10600/10697 ( 99.1%)] Loss: 0.023389 L1: 0.013410 Grad: 0.099623 Thermal: 0.000348 LR: 2.64e-06\n",
      "Epoch  39 [10600/10697 ( 99.1%)] Loss: 0.023389 L1: 0.013410 Grad: 0.099623 Thermal: 0.000348 LR: 2.64e-06\n",
      "Epoch  39 [10650/10697 ( 99.6%)] Loss: 0.025673 L1: 0.014754 Grad: 0.108982 Thermal: 0.000418 LR: 2.64e-06\n",
      "Epoch  39 [10650/10697 ( 99.6%)] Loss: 0.025673 L1: 0.014754 Grad: 0.108982 Thermal: 0.000418 LR: 2.64e-06\n",
      "Epoch  39 Summary: Loss=0.026230 (L1:0.0153, Grad:0.1091, Thermal:0.0005) Val_PSNR=0.00dB Best=33.96dB Time=155.8min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  39 Summary: Loss=0.026230 (L1:0.0153, Grad:0.1091, Thermal:0.0005) Val_PSNR=0.00dB Best=33.96dB Time=155.8min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  40 [   0/10697 (  0.0%)] Loss: 0.021129 L1: 0.012419 Grad: 0.086940 Thermal: 0.000321 LR: 2.55e-06\n",
      "Epoch  40 [   0/10697 (  0.0%)] Loss: 0.021129 L1: 0.012419 Grad: 0.086940 Thermal: 0.000321 LR: 2.55e-06\n",
      "Epoch  40 [  50/10697 (  0.5%)] Loss: 0.025082 L1: 0.014983 Grad: 0.100772 Thermal: 0.000434 LR: 2.55e-06\n",
      "Epoch  40 [  50/10697 (  0.5%)] Loss: 0.025082 L1: 0.014983 Grad: 0.100772 Thermal: 0.000434 LR: 2.55e-06\n",
      "Epoch  40 [ 100/10697 (  0.9%)] Loss: 0.025909 L1: 0.015139 Grad: 0.107485 Thermal: 0.000432 LR: 2.55e-06\n",
      "Epoch  40 [ 100/10697 (  0.9%)] Loss: 0.025909 L1: 0.015139 Grad: 0.107485 Thermal: 0.000432 LR: 2.55e-06\n",
      "Epoch  40 [ 150/10697 (  1.4%)] Loss: 0.028268 L1: 0.016519 Grad: 0.117253 Thermal: 0.000484 LR: 2.55e-06\n",
      "Epoch  40 [ 150/10697 (  1.4%)] Loss: 0.028268 L1: 0.016519 Grad: 0.117253 Thermal: 0.000484 LR: 2.55e-06\n",
      "Epoch  40 [ 200/10697 (  1.9%)] Loss: 0.024626 L1: 0.014516 Grad: 0.100908 Thermal: 0.000388 LR: 2.55e-06\n",
      "Epoch  40 [ 200/10697 (  1.9%)] Loss: 0.024626 L1: 0.014516 Grad: 0.100908 Thermal: 0.000388 LR: 2.55e-06\n",
      "Epoch  40 [ 250/10697 (  2.3%)] Loss: 0.023943 L1: 0.013901 Grad: 0.100237 Thermal: 0.000371 LR: 2.55e-06\n",
      "Epoch  40 [ 250/10697 (  2.3%)] Loss: 0.023943 L1: 0.013901 Grad: 0.100237 Thermal: 0.000371 LR: 2.55e-06\n",
      "Epoch  40 [ 300/10697 (  2.8%)] Loss: 0.025048 L1: 0.014913 Grad: 0.101156 Thermal: 0.000405 LR: 2.55e-06\n",
      "Epoch  40 [ 300/10697 (  2.8%)] Loss: 0.025048 L1: 0.014913 Grad: 0.101156 Thermal: 0.000405 LR: 2.55e-06\n",
      "Epoch  40 [ 350/10697 (  3.3%)] Loss: 0.025048 L1: 0.015211 Grad: 0.098168 Thermal: 0.000402 LR: 2.55e-06\n",
      "Epoch  40 [ 350/10697 (  3.3%)] Loss: 0.025048 L1: 0.015211 Grad: 0.098168 Thermal: 0.000402 LR: 2.55e-06\n",
      "Epoch  40 [ 400/10697 (  3.7%)] Loss: 0.024485 L1: 0.014150 Grad: 0.103145 Thermal: 0.000401 LR: 2.55e-06\n",
      "Epoch  40 [ 400/10697 (  3.7%)] Loss: 0.024485 L1: 0.014150 Grad: 0.103145 Thermal: 0.000401 LR: 2.55e-06\n",
      "Epoch  40 [ 450/10697 (  4.2%)] Loss: 0.026711 L1: 0.015203 Grad: 0.114850 Thermal: 0.000456 LR: 2.55e-06\n",
      "Epoch  40 [ 450/10697 (  4.2%)] Loss: 0.026711 L1: 0.015203 Grad: 0.114850 Thermal: 0.000456 LR: 2.55e-06\n",
      "Epoch  40 [ 500/10697 (  4.7%)] Loss: 0.030825 L1: 0.017332 Grad: 0.134672 Thermal: 0.000518 LR: 2.55e-06\n",
      "Epoch  40 [ 500/10697 (  4.7%)] Loss: 0.030825 L1: 0.017332 Grad: 0.134672 Thermal: 0.000518 LR: 2.55e-06\n",
      "Epoch  40 [ 550/10697 (  5.1%)] Loss: 0.026167 L1: 0.015308 Grad: 0.108377 Thermal: 0.000424 LR: 2.55e-06\n",
      "Epoch  40 [ 550/10697 (  5.1%)] Loss: 0.026167 L1: 0.015308 Grad: 0.108377 Thermal: 0.000424 LR: 2.55e-06\n",
      "Epoch  40 [ 600/10697 (  5.6%)] Loss: 0.024885 L1: 0.014154 Grad: 0.107114 Thermal: 0.000380 LR: 2.55e-06\n",
      "Epoch  40 [ 600/10697 (  5.6%)] Loss: 0.024885 L1: 0.014154 Grad: 0.107114 Thermal: 0.000380 LR: 2.55e-06\n",
      "Epoch  40 [ 650/10697 (  6.1%)] Loss: 0.029401 L1: 0.016753 Grad: 0.126187 Thermal: 0.000599 LR: 2.55e-06\n",
      "Epoch  40 [ 650/10697 (  6.1%)] Loss: 0.029401 L1: 0.016753 Grad: 0.126187 Thermal: 0.000599 LR: 2.55e-06\n",
      "Epoch  40 [ 700/10697 (  6.5%)] Loss: 0.025310 L1: 0.014959 Grad: 0.103295 Thermal: 0.000424 LR: 2.55e-06\n",
      "Epoch  40 [ 700/10697 (  6.5%)] Loss: 0.025310 L1: 0.014959 Grad: 0.103295 Thermal: 0.000424 LR: 2.55e-06\n",
      "Epoch  40 [ 750/10697 (  7.0%)] Loss: 0.026908 L1: 0.015376 Grad: 0.115117 Thermal: 0.000424 LR: 2.55e-06\n",
      "Epoch  40 [ 750/10697 (  7.0%)] Loss: 0.026908 L1: 0.015376 Grad: 0.115117 Thermal: 0.000424 LR: 2.55e-06\n",
      "Epoch  40 [ 800/10697 (  7.5%)] Loss: 0.028207 L1: 0.015736 Grad: 0.124447 Thermal: 0.000540 LR: 2.55e-06\n",
      "Epoch  40 [ 800/10697 (  7.5%)] Loss: 0.028207 L1: 0.015736 Grad: 0.124447 Thermal: 0.000540 LR: 2.55e-06\n",
      "Epoch  40 [ 850/10697 (  7.9%)] Loss: 0.027962 L1: 0.016530 Grad: 0.114076 Thermal: 0.000505 LR: 2.55e-06\n",
      "Epoch  40 [ 850/10697 (  7.9%)] Loss: 0.027962 L1: 0.016530 Grad: 0.114076 Thermal: 0.000505 LR: 2.55e-06\n",
      "Epoch  40 [ 900/10697 (  8.4%)] Loss: 0.026543 L1: 0.015536 Grad: 0.109858 Thermal: 0.000433 LR: 2.55e-06\n",
      "Epoch  40 [ 900/10697 (  8.4%)] Loss: 0.026543 L1: 0.015536 Grad: 0.109858 Thermal: 0.000433 LR: 2.55e-06\n",
      "Epoch  40 [ 950/10697 (  8.9%)] Loss: 0.026573 L1: 0.015612 Grad: 0.109391 Thermal: 0.000435 LR: 2.55e-06\n",
      "Epoch  40 [ 950/10697 (  8.9%)] Loss: 0.026573 L1: 0.015612 Grad: 0.109391 Thermal: 0.000435 LR: 2.55e-06\n",
      "Epoch  40 [1000/10697 (  9.3%)] Loss: 0.019060 L1: 0.010532 Grad: 0.085150 Thermal: 0.000249 LR: 2.55e-06\n",
      "Epoch  40 [1000/10697 (  9.3%)] Loss: 0.019060 L1: 0.010532 Grad: 0.085150 Thermal: 0.000249 LR: 2.55e-06\n",
      "Epoch  40 [1050/10697 (  9.8%)] Loss: 0.021073 L1: 0.012241 Grad: 0.088160 Thermal: 0.000314 LR: 2.55e-06\n",
      "Epoch  40 [1050/10697 (  9.8%)] Loss: 0.021073 L1: 0.012241 Grad: 0.088160 Thermal: 0.000314 LR: 2.55e-06\n",
      "Epoch  40 [1100/10697 ( 10.3%)] Loss: 0.020641 L1: 0.012005 Grad: 0.086208 Thermal: 0.000301 LR: 2.55e-06\n",
      "Epoch  40 [1100/10697 ( 10.3%)] Loss: 0.020641 L1: 0.012005 Grad: 0.086208 Thermal: 0.000301 LR: 2.55e-06\n",
      "Epoch  40 [1150/10697 ( 10.8%)] Loss: 0.028502 L1: 0.016487 Grad: 0.119885 Thermal: 0.000523 LR: 2.55e-06\n",
      "Epoch  40 [1150/10697 ( 10.8%)] Loss: 0.028502 L1: 0.016487 Grad: 0.119885 Thermal: 0.000523 LR: 2.55e-06\n",
      "Epoch  40 [1200/10697 ( 11.2%)] Loss: 0.024826 L1: 0.014292 Grad: 0.105147 Thermal: 0.000383 LR: 2.55e-06\n",
      "Epoch  40 [1200/10697 ( 11.2%)] Loss: 0.024826 L1: 0.014292 Grad: 0.105147 Thermal: 0.000383 LR: 2.55e-06\n",
      "Epoch  40 [1250/10697 ( 11.7%)] Loss: 0.026926 L1: 0.015662 Grad: 0.112420 Thermal: 0.000435 LR: 2.55e-06\n",
      "Epoch  40 [1250/10697 ( 11.7%)] Loss: 0.026926 L1: 0.015662 Grad: 0.112420 Thermal: 0.000435 LR: 2.55e-06\n",
      "Epoch  40 [1300/10697 ( 12.2%)] Loss: 0.024924 L1: 0.014499 Grad: 0.104051 Thermal: 0.000407 LR: 2.55e-06\n",
      "Epoch  40 [1300/10697 ( 12.2%)] Loss: 0.024924 L1: 0.014499 Grad: 0.104051 Thermal: 0.000407 LR: 2.55e-06\n",
      "Epoch  40 [1350/10697 ( 12.6%)] Loss: 0.024641 L1: 0.014493 Grad: 0.101283 Thermal: 0.000403 LR: 2.55e-06\n",
      "Epoch  40 [1350/10697 ( 12.6%)] Loss: 0.024641 L1: 0.014493 Grad: 0.101283 Thermal: 0.000403 LR: 2.55e-06\n",
      "Epoch  40 [1400/10697 ( 13.1%)] Loss: 0.027501 L1: 0.016165 Grad: 0.113132 Thermal: 0.000460 LR: 2.55e-06\n",
      "Epoch  40 [1400/10697 ( 13.1%)] Loss: 0.027501 L1: 0.016165 Grad: 0.113132 Thermal: 0.000460 LR: 2.55e-06\n",
      "Epoch  40 [1450/10697 ( 13.6%)] Loss: 0.030472 L1: 0.017956 Grad: 0.124865 Thermal: 0.000595 LR: 2.55e-06\n",
      "Epoch  40 [1450/10697 ( 13.6%)] Loss: 0.030472 L1: 0.017956 Grad: 0.124865 Thermal: 0.000595 LR: 2.55e-06\n",
      "Epoch  40 [1500/10697 ( 14.0%)] Loss: 0.026799 L1: 0.016087 Grad: 0.106887 Thermal: 0.000459 LR: 2.55e-06\n",
      "Epoch  40 [1500/10697 ( 14.0%)] Loss: 0.026799 L1: 0.016087 Grad: 0.106887 Thermal: 0.000459 LR: 2.55e-06\n",
      "Epoch  40 [1550/10697 ( 14.5%)] Loss: 0.023680 L1: 0.013577 Grad: 0.100830 Thermal: 0.000408 LR: 2.55e-06\n",
      "Epoch  40 [1550/10697 ( 14.5%)] Loss: 0.023680 L1: 0.013577 Grad: 0.100830 Thermal: 0.000408 LR: 2.55e-06\n",
      "Epoch  40 [1600/10697 ( 15.0%)] Loss: 0.029418 L1: 0.016693 Grad: 0.126998 Thermal: 0.000517 LR: 2.55e-06\n",
      "Epoch  40 [1600/10697 ( 15.0%)] Loss: 0.029418 L1: 0.016693 Grad: 0.126998 Thermal: 0.000517 LR: 2.55e-06\n",
      "Epoch  40 [1650/10697 ( 15.4%)] Loss: 0.028547 L1: 0.016087 Grad: 0.124342 Thermal: 0.000526 LR: 2.55e-06\n",
      "Epoch  40 [1650/10697 ( 15.4%)] Loss: 0.028547 L1: 0.016087 Grad: 0.124342 Thermal: 0.000526 LR: 2.55e-06\n",
      "Epoch  40 [1700/10697 ( 15.9%)] Loss: 0.024803 L1: 0.014741 Grad: 0.100403 Thermal: 0.000436 LR: 2.55e-06\n",
      "Epoch  40 [1700/10697 ( 15.9%)] Loss: 0.024803 L1: 0.014741 Grad: 0.100403 Thermal: 0.000436 LR: 2.55e-06\n",
      "Epoch  40 [1750/10697 ( 16.4%)] Loss: 0.028705 L1: 0.016625 Grad: 0.120563 Thermal: 0.000487 LR: 2.55e-06\n",
      "Epoch  40 [1750/10697 ( 16.4%)] Loss: 0.028705 L1: 0.016625 Grad: 0.120563 Thermal: 0.000487 LR: 2.55e-06\n",
      "Epoch  40 [1800/10697 ( 16.8%)] Loss: 0.031975 L1: 0.018413 Grad: 0.135294 Thermal: 0.000649 LR: 2.55e-06\n",
      "Epoch  40 [1800/10697 ( 16.8%)] Loss: 0.031975 L1: 0.018413 Grad: 0.135294 Thermal: 0.000649 LR: 2.55e-06\n",
      "Epoch  40 [1850/10697 ( 17.3%)] Loss: 0.030132 L1: 0.017513 Grad: 0.125923 Thermal: 0.000527 LR: 2.55e-06\n",
      "Epoch  40 [1850/10697 ( 17.3%)] Loss: 0.030132 L1: 0.017513 Grad: 0.125923 Thermal: 0.000527 LR: 2.55e-06\n",
      "Epoch  40 [1900/10697 ( 17.8%)] Loss: 0.022835 L1: 0.013431 Grad: 0.093879 Thermal: 0.000333 LR: 2.55e-06\n",
      "Epoch  40 [1900/10697 ( 17.8%)] Loss: 0.022835 L1: 0.013431 Grad: 0.093879 Thermal: 0.000333 LR: 2.55e-06\n",
      "Epoch  40 [1950/10697 ( 18.2%)] Loss: 0.027085 L1: 0.015748 Grad: 0.113137 Thermal: 0.000474 LR: 2.55e-06\n",
      "Epoch  40 [1950/10697 ( 18.2%)] Loss: 0.027085 L1: 0.015748 Grad: 0.113137 Thermal: 0.000474 LR: 2.55e-06\n",
      "Epoch  40 [2000/10697 ( 18.7%)] Loss: 0.029928 L1: 0.016726 Grad: 0.131682 Thermal: 0.000678 LR: 2.55e-06\n",
      "Epoch  40 [2000/10697 ( 18.7%)] Loss: 0.029928 L1: 0.016726 Grad: 0.131682 Thermal: 0.000678 LR: 2.55e-06\n",
      "Epoch  40 [2050/10697 ( 19.2%)] Loss: 0.025915 L1: 0.015288 Grad: 0.106064 Thermal: 0.000408 LR: 2.55e-06\n",
      "Epoch  40 [2050/10697 ( 19.2%)] Loss: 0.025915 L1: 0.015288 Grad: 0.106064 Thermal: 0.000408 LR: 2.55e-06\n",
      "Epoch  40 [2100/10697 ( 19.6%)] Loss: 0.028553 L1: 0.016341 Grad: 0.121850 Thermal: 0.000538 LR: 2.55e-06\n",
      "Epoch  40 [2100/10697 ( 19.6%)] Loss: 0.028553 L1: 0.016341 Grad: 0.121850 Thermal: 0.000538 LR: 2.55e-06\n",
      "Epoch  40 [2150/10697 ( 20.1%)] Loss: 0.028925 L1: 0.016483 Grad: 0.124189 Thermal: 0.000459 LR: 2.55e-06\n",
      "Epoch  40 [2150/10697 ( 20.1%)] Loss: 0.028925 L1: 0.016483 Grad: 0.124189 Thermal: 0.000459 LR: 2.55e-06\n",
      "Epoch  40 [2200/10697 ( 20.6%)] Loss: 0.025208 L1: 0.014653 Grad: 0.105345 Thermal: 0.000411 LR: 2.55e-06\n",
      "Epoch  40 [2200/10697 ( 20.6%)] Loss: 0.025208 L1: 0.014653 Grad: 0.105345 Thermal: 0.000411 LR: 2.55e-06\n",
      "Epoch  40 [2250/10697 ( 21.0%)] Loss: 0.023621 L1: 0.013517 Grad: 0.100867 Thermal: 0.000345 LR: 2.55e-06\n",
      "Epoch  40 [2250/10697 ( 21.0%)] Loss: 0.023621 L1: 0.013517 Grad: 0.100867 Thermal: 0.000345 LR: 2.55e-06\n",
      "Epoch  40 [2300/10697 ( 21.5%)] Loss: 0.028935 L1: 0.016446 Grad: 0.124588 Thermal: 0.000598 LR: 2.55e-06\n",
      "Epoch  40 [2300/10697 ( 21.5%)] Loss: 0.028935 L1: 0.016446 Grad: 0.124588 Thermal: 0.000598 LR: 2.55e-06\n",
      "Epoch  40 [2350/10697 ( 22.0%)] Loss: 0.022396 L1: 0.013241 Grad: 0.091364 Thermal: 0.000366 LR: 2.55e-06\n",
      "Epoch  40 [2350/10697 ( 22.0%)] Loss: 0.022396 L1: 0.013241 Grad: 0.091364 Thermal: 0.000366 LR: 2.55e-06\n",
      "Epoch  40 [2400/10697 ( 22.4%)] Loss: 0.024400 L1: 0.014146 Grad: 0.102337 Thermal: 0.000412 LR: 2.55e-06\n",
      "Epoch  40 [2400/10697 ( 22.4%)] Loss: 0.024400 L1: 0.014146 Grad: 0.102337 Thermal: 0.000412 LR: 2.55e-06\n",
      "Epoch  40 [2450/10697 ( 22.9%)] Loss: 0.019843 L1: 0.011541 Grad: 0.082873 Thermal: 0.000296 LR: 2.55e-06\n",
      "Epoch  40 [2450/10697 ( 22.9%)] Loss: 0.019843 L1: 0.011541 Grad: 0.082873 Thermal: 0.000296 LR: 2.55e-06\n",
      "Epoch  40 [2500/10697 ( 23.4%)] Loss: 0.027071 L1: 0.015793 Grad: 0.112525 Thermal: 0.000506 LR: 2.55e-06\n",
      "Epoch  40 [2500/10697 ( 23.4%)] Loss: 0.027071 L1: 0.015793 Grad: 0.112525 Thermal: 0.000506 LR: 2.55e-06\n",
      "Epoch  40 [2550/10697 ( 23.8%)] Loss: 0.020805 L1: 0.012123 Grad: 0.086671 Thermal: 0.000295 LR: 2.55e-06\n",
      "Epoch  40 [2550/10697 ( 23.8%)] Loss: 0.020805 L1: 0.012123 Grad: 0.086671 Thermal: 0.000295 LR: 2.55e-06\n",
      "Epoch  40 [2600/10697 ( 24.3%)] Loss: 0.033065 L1: 0.018970 Grad: 0.140613 Thermal: 0.000671 LR: 2.55e-06\n",
      "Epoch  40 [2600/10697 ( 24.3%)] Loss: 0.033065 L1: 0.018970 Grad: 0.140613 Thermal: 0.000671 LR: 2.55e-06\n",
      "Epoch  40 [2650/10697 ( 24.8%)] Loss: 0.023380 L1: 0.013503 Grad: 0.098595 Thermal: 0.000357 LR: 2.55e-06\n",
      "Epoch  40 [2650/10697 ( 24.8%)] Loss: 0.023380 L1: 0.013503 Grad: 0.098595 Thermal: 0.000357 LR: 2.55e-06\n",
      "Epoch  40 [2700/10697 ( 25.2%)] Loss: 0.032273 L1: 0.019031 Grad: 0.132069 Thermal: 0.000700 LR: 2.55e-06\n",
      "Epoch  40 [2700/10697 ( 25.2%)] Loss: 0.032273 L1: 0.019031 Grad: 0.132069 Thermal: 0.000700 LR: 2.55e-06\n",
      "Epoch  40 [2750/10697 ( 25.7%)] Loss: 0.020876 L1: 0.012363 Grad: 0.084987 Thermal: 0.000297 LR: 2.55e-06\n",
      "Epoch  40 [2750/10697 ( 25.7%)] Loss: 0.020876 L1: 0.012363 Grad: 0.084987 Thermal: 0.000297 LR: 2.55e-06\n",
      "Epoch  40 [2800/10697 ( 26.2%)] Loss: 0.026001 L1: 0.015023 Grad: 0.109544 Thermal: 0.000478 LR: 2.55e-06\n",
      "Epoch  40 [2800/10697 ( 26.2%)] Loss: 0.026001 L1: 0.015023 Grad: 0.109544 Thermal: 0.000478 LR: 2.55e-06\n",
      "Epoch  40 [2850/10697 ( 26.6%)] Loss: 0.034799 L1: 0.020099 Grad: 0.146616 Thermal: 0.000754 LR: 2.55e-06\n",
      "Epoch  40 [2850/10697 ( 26.6%)] Loss: 0.034799 L1: 0.020099 Grad: 0.146616 Thermal: 0.000754 LR: 2.55e-06\n",
      "Epoch  40 [2900/10697 ( 27.1%)] Loss: 0.029960 L1: 0.017656 Grad: 0.122736 Thermal: 0.000603 LR: 2.55e-06\n",
      "Epoch  40 [2900/10697 ( 27.1%)] Loss: 0.029960 L1: 0.017656 Grad: 0.122736 Thermal: 0.000603 LR: 2.55e-06\n",
      "Epoch  40 [2950/10697 ( 27.6%)] Loss: 0.022705 L1: 0.013123 Grad: 0.095646 Thermal: 0.000344 LR: 2.55e-06\n",
      "Epoch  40 [2950/10697 ( 27.6%)] Loss: 0.022705 L1: 0.013123 Grad: 0.095646 Thermal: 0.000344 LR: 2.55e-06\n",
      "Epoch  40 [3000/10697 ( 28.0%)] Loss: 0.026798 L1: 0.015920 Grad: 0.108550 Thermal: 0.000458 LR: 2.55e-06\n",
      "Epoch  40 [3000/10697 ( 28.0%)] Loss: 0.026798 L1: 0.015920 Grad: 0.108550 Thermal: 0.000458 LR: 2.55e-06\n",
      "Epoch  40 [3050/10697 ( 28.5%)] Loss: 0.025089 L1: 0.014484 Grad: 0.105793 Thermal: 0.000506 LR: 2.55e-06\n",
      "Epoch  40 [3050/10697 ( 28.5%)] Loss: 0.025089 L1: 0.014484 Grad: 0.105793 Thermal: 0.000506 LR: 2.55e-06\n",
      "Epoch  40 [3100/10697 ( 29.0%)] Loss: 0.026989 L1: 0.015492 Grad: 0.114724 Thermal: 0.000495 LR: 2.55e-06\n",
      "Epoch  40 [3100/10697 ( 29.0%)] Loss: 0.026989 L1: 0.015492 Grad: 0.114724 Thermal: 0.000495 LR: 2.55e-06\n",
      "Epoch  40 [3150/10697 ( 29.4%)] Loss: 0.026722 L1: 0.015909 Grad: 0.107899 Thermal: 0.000451 LR: 2.55e-06\n",
      "Epoch  40 [3150/10697 ( 29.4%)] Loss: 0.026722 L1: 0.015909 Grad: 0.107899 Thermal: 0.000451 LR: 2.55e-06\n",
      "Epoch  40 [3200/10697 ( 29.9%)] Loss: 0.022563 L1: 0.013269 Grad: 0.092775 Thermal: 0.000344 LR: 2.55e-06\n",
      "Epoch  40 [3200/10697 ( 29.9%)] Loss: 0.022563 L1: 0.013269 Grad: 0.092775 Thermal: 0.000344 LR: 2.55e-06\n",
      "Epoch  40 [3250/10697 ( 30.4%)] Loss: 0.026739 L1: 0.015946 Grad: 0.107705 Thermal: 0.000451 LR: 2.55e-06\n",
      "Epoch  40 [3250/10697 ( 30.4%)] Loss: 0.026739 L1: 0.015946 Grad: 0.107705 Thermal: 0.000451 LR: 2.55e-06\n",
      "Epoch  40 [3300/10697 ( 30.8%)] Loss: 0.016208 L1: 0.009242 Grad: 0.069568 Thermal: 0.000188 LR: 2.55e-06\n",
      "Epoch  40 [3300/10697 ( 30.8%)] Loss: 0.016208 L1: 0.009242 Grad: 0.069568 Thermal: 0.000188 LR: 2.55e-06\n",
      "Epoch  40 [3350/10697 ( 31.3%)] Loss: 0.026183 L1: 0.014598 Grad: 0.115627 Thermal: 0.000427 LR: 2.55e-06\n",
      "Epoch  40 [3350/10697 ( 31.3%)] Loss: 0.026183 L1: 0.014598 Grad: 0.115627 Thermal: 0.000427 LR: 2.55e-06\n",
      "Epoch  40 [3400/10697 ( 31.8%)] Loss: 0.028906 L1: 0.016574 Grad: 0.123068 Thermal: 0.000503 LR: 2.55e-06\n",
      "Epoch  40 [3400/10697 ( 31.8%)] Loss: 0.028906 L1: 0.016574 Grad: 0.123068 Thermal: 0.000503 LR: 2.55e-06\n",
      "Epoch  40 [3450/10697 ( 32.3%)] Loss: 0.022831 L1: 0.013475 Grad: 0.093373 Thermal: 0.000358 LR: 2.55e-06\n",
      "Epoch  40 [3450/10697 ( 32.3%)] Loss: 0.022831 L1: 0.013475 Grad: 0.093373 Thermal: 0.000358 LR: 2.55e-06\n",
      "Epoch  40 [3500/10697 ( 32.7%)] Loss: 0.026443 L1: 0.014954 Grad: 0.114667 Thermal: 0.000451 LR: 2.55e-06\n",
      "Epoch  40 [3500/10697 ( 32.7%)] Loss: 0.026443 L1: 0.014954 Grad: 0.114667 Thermal: 0.000451 LR: 2.55e-06\n",
      "Epoch  40 [3550/10697 ( 33.2%)] Loss: 0.029827 L1: 0.017832 Grad: 0.119612 Thermal: 0.000671 LR: 2.55e-06\n",
      "Epoch  40 [3550/10697 ( 33.2%)] Loss: 0.029827 L1: 0.017832 Grad: 0.119612 Thermal: 0.000671 LR: 2.55e-06\n",
      "Epoch  40 [3600/10697 ( 33.7%)] Loss: 0.024033 L1: 0.013834 Grad: 0.101803 Thermal: 0.000375 LR: 2.55e-06\n",
      "Epoch  40 [3600/10697 ( 33.7%)] Loss: 0.024033 L1: 0.013834 Grad: 0.101803 Thermal: 0.000375 LR: 2.55e-06\n",
      "Epoch  40 [3650/10697 ( 34.1%)] Loss: 0.026767 L1: 0.015941 Grad: 0.108038 Thermal: 0.000449 LR: 2.55e-06\n",
      "Epoch  40 [3650/10697 ( 34.1%)] Loss: 0.026767 L1: 0.015941 Grad: 0.108038 Thermal: 0.000449 LR: 2.55e-06\n",
      "Epoch  40 [3700/10697 ( 34.6%)] Loss: 0.028950 L1: 0.017204 Grad: 0.117165 Thermal: 0.000594 LR: 2.55e-06\n",
      "Epoch  40 [3700/10697 ( 34.6%)] Loss: 0.028950 L1: 0.017204 Grad: 0.117165 Thermal: 0.000594 LR: 2.55e-06\n",
      "Epoch  40 [3750/10697 ( 35.1%)] Loss: 0.022676 L1: 0.012724 Grad: 0.099339 Thermal: 0.000375 LR: 2.55e-06\n",
      "Epoch  40 [3750/10697 ( 35.1%)] Loss: 0.022676 L1: 0.012724 Grad: 0.099339 Thermal: 0.000375 LR: 2.55e-06\n",
      "Epoch  40 [3800/10697 ( 35.5%)] Loss: 0.028383 L1: 0.016001 Grad: 0.123571 Thermal: 0.000479 LR: 2.55e-06\n",
      "Epoch  40 [3800/10697 ( 35.5%)] Loss: 0.028383 L1: 0.016001 Grad: 0.123571 Thermal: 0.000479 LR: 2.55e-06\n",
      "Epoch  40 [3850/10697 ( 36.0%)] Loss: 0.022994 L1: 0.013001 Grad: 0.099731 Thermal: 0.000398 LR: 2.55e-06\n",
      "Epoch  40 [3850/10697 ( 36.0%)] Loss: 0.022994 L1: 0.013001 Grad: 0.099731 Thermal: 0.000398 LR: 2.55e-06\n",
      "Epoch  40 [3900/10697 ( 36.5%)] Loss: 0.025868 L1: 0.015068 Grad: 0.107789 Thermal: 0.000416 LR: 2.55e-06\n",
      "Epoch  40 [3900/10697 ( 36.5%)] Loss: 0.025868 L1: 0.015068 Grad: 0.107789 Thermal: 0.000416 LR: 2.55e-06\n",
      "Epoch  40 [3950/10697 ( 36.9%)] Loss: 0.032624 L1: 0.018765 Grad: 0.138262 Thermal: 0.000645 LR: 2.55e-06\n",
      "Epoch  40 [3950/10697 ( 36.9%)] Loss: 0.032624 L1: 0.018765 Grad: 0.138262 Thermal: 0.000645 LR: 2.55e-06\n",
      "Epoch  40 [4000/10697 ( 37.4%)] Loss: 0.024566 L1: 0.014316 Grad: 0.102310 Thermal: 0.000381 LR: 2.55e-06\n",
      "Epoch  40 [4000/10697 ( 37.4%)] Loss: 0.024566 L1: 0.014316 Grad: 0.102310 Thermal: 0.000381 LR: 2.55e-06\n",
      "Epoch  40 [4050/10697 ( 37.9%)] Loss: 0.022615 L1: 0.013178 Grad: 0.094178 Thermal: 0.000374 LR: 2.55e-06\n",
      "Epoch  40 [4050/10697 ( 37.9%)] Loss: 0.022615 L1: 0.013178 Grad: 0.094178 Thermal: 0.000374 LR: 2.55e-06\n",
      "Epoch  40 [4100/10697 ( 38.3%)] Loss: 0.026531 L1: 0.016018 Grad: 0.104904 Thermal: 0.000444 LR: 2.55e-06\n",
      "Epoch  40 [4100/10697 ( 38.3%)] Loss: 0.026531 L1: 0.016018 Grad: 0.104904 Thermal: 0.000444 LR: 2.55e-06\n",
      "Epoch  40 [4150/10697 ( 38.8%)] Loss: 0.027553 L1: 0.016069 Grad: 0.114610 Thermal: 0.000465 LR: 2.55e-06\n",
      "Epoch  40 [4150/10697 ( 38.8%)] Loss: 0.027553 L1: 0.016069 Grad: 0.114610 Thermal: 0.000465 LR: 2.55e-06\n",
      "Epoch  40 [4200/10697 ( 39.3%)] Loss: 0.023996 L1: 0.013847 Grad: 0.101286 Thermal: 0.000399 LR: 2.55e-06\n",
      "Epoch  40 [4200/10697 ( 39.3%)] Loss: 0.023996 L1: 0.013847 Grad: 0.101286 Thermal: 0.000399 LR: 2.55e-06\n",
      "Epoch  40 [4250/10697 ( 39.7%)] Loss: 0.025468 L1: 0.015093 Grad: 0.103540 Thermal: 0.000425 LR: 2.55e-06\n",
      "Epoch  40 [4250/10697 ( 39.7%)] Loss: 0.025468 L1: 0.015093 Grad: 0.103540 Thermal: 0.000425 LR: 2.55e-06\n",
      "Epoch  40 [4300/10697 ( 40.2%)] Loss: 0.020848 L1: 0.012027 Grad: 0.088048 Thermal: 0.000319 LR: 2.55e-06\n",
      "Epoch  40 [4300/10697 ( 40.2%)] Loss: 0.020848 L1: 0.012027 Grad: 0.088048 Thermal: 0.000319 LR: 2.55e-06\n",
      "Epoch  40 [4350/10697 ( 40.7%)] Loss: 0.026548 L1: 0.015574 Grad: 0.109510 Thermal: 0.000469 LR: 2.55e-06\n",
      "Epoch  40 [4350/10697 ( 40.7%)] Loss: 0.026548 L1: 0.015574 Grad: 0.109510 Thermal: 0.000469 LR: 2.55e-06\n",
      "Epoch  40 [4400/10697 ( 41.1%)] Loss: 0.025317 L1: 0.014567 Grad: 0.107305 Thermal: 0.000387 LR: 2.55e-06\n",
      "Epoch  40 [4400/10697 ( 41.1%)] Loss: 0.025317 L1: 0.014567 Grad: 0.107305 Thermal: 0.000387 LR: 2.55e-06\n",
      "Epoch  40 [4450/10697 ( 41.6%)] Loss: 0.030155 L1: 0.017172 Grad: 0.129563 Thermal: 0.000532 LR: 2.55e-06\n",
      "Epoch  40 [4450/10697 ( 41.6%)] Loss: 0.030155 L1: 0.017172 Grad: 0.129563 Thermal: 0.000532 LR: 2.55e-06\n",
      "Epoch  40 [4500/10697 ( 42.1%)] Loss: 0.025379 L1: 0.015124 Grad: 0.102333 Thermal: 0.000431 LR: 2.55e-06\n",
      "Epoch  40 [4500/10697 ( 42.1%)] Loss: 0.025379 L1: 0.015124 Grad: 0.102333 Thermal: 0.000431 LR: 2.55e-06\n",
      "Epoch  40 [4550/10697 ( 42.5%)] Loss: 0.023515 L1: 0.013285 Grad: 0.102145 Thermal: 0.000326 LR: 2.55e-06\n",
      "Epoch  40 [4550/10697 ( 42.5%)] Loss: 0.023515 L1: 0.013285 Grad: 0.102145 Thermal: 0.000326 LR: 2.55e-06\n",
      "Epoch  40 [4600/10697 ( 43.0%)] Loss: 0.029426 L1: 0.017239 Grad: 0.121607 Thermal: 0.000521 LR: 2.55e-06\n",
      "Epoch  40 [4600/10697 ( 43.0%)] Loss: 0.029426 L1: 0.017239 Grad: 0.121607 Thermal: 0.000521 LR: 2.55e-06\n",
      "Epoch  40 [4650/10697 ( 43.5%)] Loss: 0.022052 L1: 0.012824 Grad: 0.092137 Thermal: 0.000293 LR: 2.55e-06\n",
      "Epoch  40 [4650/10697 ( 43.5%)] Loss: 0.022052 L1: 0.012824 Grad: 0.092137 Thermal: 0.000293 LR: 2.55e-06\n",
      "Epoch  40 [4700/10697 ( 43.9%)] Loss: 0.027047 L1: 0.015847 Grad: 0.111783 Thermal: 0.000433 LR: 2.55e-06\n",
      "Epoch  40 [4700/10697 ( 43.9%)] Loss: 0.027047 L1: 0.015847 Grad: 0.111783 Thermal: 0.000433 LR: 2.55e-06\n",
      "Epoch  40 [4750/10697 ( 44.4%)] Loss: 0.029822 L1: 0.017104 Grad: 0.126896 Thermal: 0.000566 LR: 2.55e-06\n",
      "Epoch  40 [4750/10697 ( 44.4%)] Loss: 0.029822 L1: 0.017104 Grad: 0.126896 Thermal: 0.000566 LR: 2.55e-06\n",
      "Epoch  40 [4800/10697 ( 44.9%)] Loss: 0.024047 L1: 0.013980 Grad: 0.100472 Thermal: 0.000395 LR: 2.55e-06\n",
      "Epoch  40 [4800/10697 ( 44.9%)] Loss: 0.024047 L1: 0.013980 Grad: 0.100472 Thermal: 0.000395 LR: 2.55e-06\n",
      "Epoch  40 [4850/10697 ( 45.3%)] Loss: 0.025573 L1: 0.015232 Grad: 0.103202 Thermal: 0.000425 LR: 2.55e-06\n",
      "Epoch  40 [4850/10697 ( 45.3%)] Loss: 0.025573 L1: 0.015232 Grad: 0.103202 Thermal: 0.000425 LR: 2.55e-06\n",
      "Epoch  40 [4900/10697 ( 45.8%)] Loss: 0.033694 L1: 0.019575 Grad: 0.140832 Thermal: 0.000719 LR: 2.55e-06\n",
      "Epoch  40 [4900/10697 ( 45.8%)] Loss: 0.033694 L1: 0.019575 Grad: 0.140832 Thermal: 0.000719 LR: 2.55e-06\n",
      "Epoch  40 [4950/10697 ( 46.3%)] Loss: 0.027177 L1: 0.016282 Grad: 0.108696 Thermal: 0.000505 LR: 2.55e-06\n",
      "Epoch  40 [4950/10697 ( 46.3%)] Loss: 0.027177 L1: 0.016282 Grad: 0.108696 Thermal: 0.000505 LR: 2.55e-06\n",
      "Epoch  40 [5000/10697 ( 46.7%)] Loss: 0.026275 L1: 0.015386 Grad: 0.108678 Thermal: 0.000436 LR: 2.55e-06\n",
      "Epoch  40 [5000/10697 ( 46.7%)] Loss: 0.026275 L1: 0.015386 Grad: 0.108678 Thermal: 0.000436 LR: 2.55e-06\n",
      "Epoch  40 [5050/10697 ( 47.2%)] Loss: 0.027063 L1: 0.015982 Grad: 0.110575 Thermal: 0.000475 LR: 2.55e-06\n",
      "Epoch  40 [5050/10697 ( 47.2%)] Loss: 0.027063 L1: 0.015982 Grad: 0.110575 Thermal: 0.000475 LR: 2.55e-06\n",
      "Epoch  40 [5100/10697 ( 47.7%)] Loss: 0.019681 L1: 0.011532 Grad: 0.081330 Thermal: 0.000319 LR: 2.55e-06\n",
      "Epoch  40 [5100/10697 ( 47.7%)] Loss: 0.019681 L1: 0.011532 Grad: 0.081330 Thermal: 0.000319 LR: 2.55e-06\n",
      "Epoch  40 [5150/10697 ( 48.1%)] Loss: 0.032679 L1: 0.018683 Grad: 0.139608 Thermal: 0.000698 LR: 2.55e-06\n",
      "Epoch  40 [5150/10697 ( 48.1%)] Loss: 0.032679 L1: 0.018683 Grad: 0.139608 Thermal: 0.000698 LR: 2.55e-06\n",
      "Epoch  40 [5200/10697 ( 48.6%)] Loss: 0.026568 L1: 0.015189 Grad: 0.113582 Thermal: 0.000424 LR: 2.55e-06\n",
      "Epoch  40 [5200/10697 ( 48.6%)] Loss: 0.026568 L1: 0.015189 Grad: 0.113582 Thermal: 0.000424 LR: 2.55e-06\n",
      "Epoch  40 [5250/10697 ( 49.1%)] Loss: 0.024433 L1: 0.013986 Grad: 0.104284 Thermal: 0.000383 LR: 2.55e-06\n",
      "Epoch  40 [5250/10697 ( 49.1%)] Loss: 0.024433 L1: 0.013986 Grad: 0.104284 Thermal: 0.000383 LR: 2.55e-06\n",
      "Epoch  40 [5300/10697 ( 49.5%)] Loss: 0.025023 L1: 0.014731 Grad: 0.102701 Thermal: 0.000424 LR: 2.55e-06\n",
      "Epoch  40 [5300/10697 ( 49.5%)] Loss: 0.025023 L1: 0.014731 Grad: 0.102701 Thermal: 0.000424 LR: 2.55e-06\n",
      "Epoch  40 [5350/10697 ( 50.0%)] Loss: 0.014784 L1: 0.008476 Grad: 0.062988 Thermal: 0.000182 LR: 2.55e-06\n",
      "Epoch  40 [5350/10697 ( 50.0%)] Loss: 0.014784 L1: 0.008476 Grad: 0.062988 Thermal: 0.000182 LR: 2.55e-06\n",
      "Epoch  40 [5400/10697 ( 50.5%)] Loss: 0.025425 L1: 0.015052 Grad: 0.103516 Thermal: 0.000420 LR: 2.55e-06\n",
      "Epoch  40 [5400/10697 ( 50.5%)] Loss: 0.025425 L1: 0.015052 Grad: 0.103516 Thermal: 0.000420 LR: 2.55e-06\n",
      "Epoch  40 [5450/10697 ( 50.9%)] Loss: 0.025609 L1: 0.014702 Grad: 0.108853 Thermal: 0.000436 LR: 2.55e-06\n",
      "Epoch  40 [5450/10697 ( 50.9%)] Loss: 0.025609 L1: 0.014702 Grad: 0.108853 Thermal: 0.000436 LR: 2.55e-06\n",
      "Epoch  40 [5500/10697 ( 51.4%)] Loss: 0.023873 L1: 0.013518 Grad: 0.103341 Thermal: 0.000415 LR: 2.55e-06\n",
      "Epoch  40 [5500/10697 ( 51.4%)] Loss: 0.023873 L1: 0.013518 Grad: 0.103341 Thermal: 0.000415 LR: 2.55e-06\n",
      "Epoch  40 [5550/10697 ( 51.9%)] Loss: 0.023179 L1: 0.013483 Grad: 0.096770 Thermal: 0.000365 LR: 2.55e-06\n",
      "Epoch  40 [5550/10697 ( 51.9%)] Loss: 0.023179 L1: 0.013483 Grad: 0.096770 Thermal: 0.000365 LR: 2.55e-06\n",
      "Epoch  40 [5600/10697 ( 52.4%)] Loss: 0.030192 L1: 0.017376 Grad: 0.127830 Thermal: 0.000654 LR: 2.55e-06\n",
      "Epoch  40 [5600/10697 ( 52.4%)] Loss: 0.030192 L1: 0.017376 Grad: 0.127830 Thermal: 0.000654 LR: 2.55e-06\n",
      "Epoch  40 [5650/10697 ( 52.8%)] Loss: 0.025150 L1: 0.014629 Grad: 0.105018 Thermal: 0.000378 LR: 2.55e-06\n",
      "Epoch  40 [5650/10697 ( 52.8%)] Loss: 0.025150 L1: 0.014629 Grad: 0.105018 Thermal: 0.000378 LR: 2.55e-06\n",
      "Epoch  40 [5700/10697 ( 53.3%)] Loss: 0.020916 L1: 0.012184 Grad: 0.087174 Thermal: 0.000300 LR: 2.55e-06\n",
      "Epoch  40 [5700/10697 ( 53.3%)] Loss: 0.020916 L1: 0.012184 Grad: 0.087174 Thermal: 0.000300 LR: 2.55e-06\n",
      "Epoch  40 [5750/10697 ( 53.8%)] Loss: 0.025393 L1: 0.014714 Grad: 0.106585 Thermal: 0.000404 LR: 2.55e-06\n",
      "Epoch  40 [5750/10697 ( 53.8%)] Loss: 0.025393 L1: 0.014714 Grad: 0.106585 Thermal: 0.000404 LR: 2.55e-06\n",
      "Epoch  40 [5800/10697 ( 54.2%)] Loss: 0.027492 L1: 0.016022 Grad: 0.114465 Thermal: 0.000472 LR: 2.55e-06\n",
      "Epoch  40 [5800/10697 ( 54.2%)] Loss: 0.027492 L1: 0.016022 Grad: 0.114465 Thermal: 0.000472 LR: 2.55e-06\n",
      "Epoch  40 [5850/10697 ( 54.7%)] Loss: 0.019466 L1: 0.011140 Grad: 0.083120 Thermal: 0.000289 LR: 2.55e-06\n",
      "Epoch  40 [5850/10697 ( 54.7%)] Loss: 0.019466 L1: 0.011140 Grad: 0.083120 Thermal: 0.000289 LR: 2.55e-06\n",
      "Epoch  40 [5900/10697 ( 55.2%)] Loss: 0.026801 L1: 0.015794 Grad: 0.109834 Thermal: 0.000461 LR: 2.55e-06\n",
      "Epoch  40 [5900/10697 ( 55.2%)] Loss: 0.026801 L1: 0.015794 Grad: 0.109834 Thermal: 0.000461 LR: 2.55e-06\n",
      "Epoch  40 [5950/10697 ( 55.6%)] Loss: 0.024183 L1: 0.014410 Grad: 0.097542 Thermal: 0.000375 LR: 2.55e-06\n",
      "Epoch  40 [5950/10697 ( 55.6%)] Loss: 0.024183 L1: 0.014410 Grad: 0.097542 Thermal: 0.000375 LR: 2.55e-06\n",
      "Epoch  40 [6000/10697 ( 56.1%)] Loss: 0.031099 L1: 0.017930 Grad: 0.131380 Thermal: 0.000626 LR: 2.55e-06\n",
      "Epoch  40 [6000/10697 ( 56.1%)] Loss: 0.031099 L1: 0.017930 Grad: 0.131380 Thermal: 0.000626 LR: 2.55e-06\n",
      "Epoch  40 [6050/10697 ( 56.6%)] Loss: 0.021143 L1: 0.012491 Grad: 0.086351 Thermal: 0.000339 LR: 2.55e-06\n",
      "Epoch  40 [6050/10697 ( 56.6%)] Loss: 0.021143 L1: 0.012491 Grad: 0.086351 Thermal: 0.000339 LR: 2.55e-06\n",
      "Epoch  40 [6100/10697 ( 57.0%)] Loss: 0.024276 L1: 0.013953 Grad: 0.103009 Thermal: 0.000431 LR: 2.55e-06\n",
      "Epoch  40 [6100/10697 ( 57.0%)] Loss: 0.024276 L1: 0.013953 Grad: 0.103009 Thermal: 0.000431 LR: 2.55e-06\n",
      "Epoch  40 [6150/10697 ( 57.5%)] Loss: 0.025553 L1: 0.014975 Grad: 0.105547 Thermal: 0.000483 LR: 2.55e-06\n",
      "Epoch  40 [6150/10697 ( 57.5%)] Loss: 0.025553 L1: 0.014975 Grad: 0.105547 Thermal: 0.000483 LR: 2.55e-06\n",
      "Epoch  40 [6200/10697 ( 58.0%)] Loss: 0.023795 L1: 0.014011 Grad: 0.097654 Thermal: 0.000372 LR: 2.55e-06\n",
      "Epoch  40 [6200/10697 ( 58.0%)] Loss: 0.023795 L1: 0.014011 Grad: 0.097654 Thermal: 0.000372 LR: 2.55e-06\n",
      "Epoch  40 [6250/10697 ( 58.4%)] Loss: 0.031049 L1: 0.018015 Grad: 0.130038 Thermal: 0.000609 LR: 2.55e-06\n",
      "Epoch  40 [6250/10697 ( 58.4%)] Loss: 0.031049 L1: 0.018015 Grad: 0.130038 Thermal: 0.000609 LR: 2.55e-06\n",
      "Epoch  40 [6300/10697 ( 58.9%)] Loss: 0.027830 L1: 0.015541 Grad: 0.122648 Thermal: 0.000485 LR: 2.55e-06\n",
      "Epoch  40 [6300/10697 ( 58.9%)] Loss: 0.027830 L1: 0.015541 Grad: 0.122648 Thermal: 0.000485 LR: 2.55e-06\n",
      "Epoch  40 [6350/10697 ( 59.4%)] Loss: 0.023857 L1: 0.014027 Grad: 0.098117 Thermal: 0.000376 LR: 2.55e-06\n",
      "Epoch  40 [6350/10697 ( 59.4%)] Loss: 0.023857 L1: 0.014027 Grad: 0.098117 Thermal: 0.000376 LR: 2.55e-06\n",
      "Epoch  40 [6400/10697 ( 59.8%)] Loss: 0.027356 L1: 0.015932 Grad: 0.113998 Thermal: 0.000491 LR: 2.55e-06\n",
      "Epoch  40 [6400/10697 ( 59.8%)] Loss: 0.027356 L1: 0.015932 Grad: 0.113998 Thermal: 0.000491 LR: 2.55e-06\n",
      "Epoch  40 [6450/10697 ( 60.3%)] Loss: 0.027117 L1: 0.015936 Grad: 0.111522 Thermal: 0.000556 LR: 2.55e-06\n",
      "Epoch  40 [6450/10697 ( 60.3%)] Loss: 0.027117 L1: 0.015936 Grad: 0.111522 Thermal: 0.000556 LR: 2.55e-06\n",
      "Epoch  40 [6500/10697 ( 60.8%)] Loss: 0.027761 L1: 0.016529 Grad: 0.112077 Thermal: 0.000475 LR: 2.55e-06\n",
      "Epoch  40 [6500/10697 ( 60.8%)] Loss: 0.027761 L1: 0.016529 Grad: 0.112077 Thermal: 0.000475 LR: 2.55e-06\n",
      "Epoch  40 [6550/10697 ( 61.2%)] Loss: 0.027697 L1: 0.016142 Grad: 0.115294 Thermal: 0.000514 LR: 2.55e-06\n",
      "Epoch  40 [6550/10697 ( 61.2%)] Loss: 0.027697 L1: 0.016142 Grad: 0.115294 Thermal: 0.000514 LR: 2.55e-06\n",
      "Epoch  40 [6600/10697 ( 61.7%)] Loss: 0.024906 L1: 0.014771 Grad: 0.101145 Thermal: 0.000399 LR: 2.55e-06\n",
      "Epoch  40 [6600/10697 ( 61.7%)] Loss: 0.024906 L1: 0.014771 Grad: 0.101145 Thermal: 0.000399 LR: 2.55e-06\n",
      "Epoch  40 [6650/10697 ( 62.2%)] Loss: 0.030001 L1: 0.017203 Grad: 0.127705 Thermal: 0.000548 LR: 2.55e-06\n",
      "Epoch  40 [6650/10697 ( 62.2%)] Loss: 0.030001 L1: 0.017203 Grad: 0.127705 Thermal: 0.000548 LR: 2.55e-06\n",
      "Epoch  40 [6700/10697 ( 62.6%)] Loss: 0.022798 L1: 0.013026 Grad: 0.097542 Thermal: 0.000351 LR: 2.55e-06\n",
      "Epoch  40 [6700/10697 ( 62.6%)] Loss: 0.022798 L1: 0.013026 Grad: 0.097542 Thermal: 0.000351 LR: 2.55e-06\n",
      "Epoch  40 [6750/10697 ( 63.1%)] Loss: 0.032852 L1: 0.018895 Grad: 0.139252 Thermal: 0.000637 LR: 2.55e-06\n",
      "Epoch  40 [6750/10697 ( 63.1%)] Loss: 0.032852 L1: 0.018895 Grad: 0.139252 Thermal: 0.000637 LR: 2.55e-06\n",
      "Epoch  40 [6800/10697 ( 63.6%)] Loss: 0.027220 L1: 0.015890 Grad: 0.113079 Thermal: 0.000451 LR: 2.55e-06\n",
      "Epoch  40 [6800/10697 ( 63.6%)] Loss: 0.027220 L1: 0.015890 Grad: 0.113079 Thermal: 0.000451 LR: 2.55e-06\n",
      "Epoch  40 [6850/10697 ( 64.0%)] Loss: 0.024019 L1: 0.013688 Grad: 0.103124 Thermal: 0.000363 LR: 2.55e-06\n",
      "Epoch  40 [6850/10697 ( 64.0%)] Loss: 0.024019 L1: 0.013688 Grad: 0.103124 Thermal: 0.000363 LR: 2.55e-06\n",
      "Epoch  40 [6900/10697 ( 64.5%)] Loss: 0.030699 L1: 0.018323 Grad: 0.123411 Thermal: 0.000693 LR: 2.55e-06\n",
      "Epoch  40 [6900/10697 ( 64.5%)] Loss: 0.030699 L1: 0.018323 Grad: 0.123411 Thermal: 0.000693 LR: 2.55e-06\n",
      "Epoch  40 [6950/10697 ( 65.0%)] Loss: 0.028968 L1: 0.017039 Grad: 0.119037 Thermal: 0.000503 LR: 2.55e-06\n",
      "Epoch  40 [6950/10697 ( 65.0%)] Loss: 0.028968 L1: 0.017039 Grad: 0.119037 Thermal: 0.000503 LR: 2.55e-06\n",
      "Epoch  40 [7000/10697 ( 65.4%)] Loss: 0.028970 L1: 0.017277 Grad: 0.116671 Thermal: 0.000510 LR: 2.55e-06\n",
      "Epoch  40 [7000/10697 ( 65.4%)] Loss: 0.028970 L1: 0.017277 Grad: 0.116671 Thermal: 0.000510 LR: 2.55e-06\n",
      "Epoch  40 [7050/10697 ( 65.9%)] Loss: 0.021893 L1: 0.012759 Grad: 0.091179 Thermal: 0.000320 LR: 2.55e-06\n",
      "Epoch  40 [7050/10697 ( 65.9%)] Loss: 0.021893 L1: 0.012759 Grad: 0.091179 Thermal: 0.000320 LR: 2.55e-06\n",
      "Epoch  40 [7100/10697 ( 66.4%)] Loss: 0.026163 L1: 0.015051 Grad: 0.110886 Thermal: 0.000465 LR: 2.55e-06\n",
      "Epoch  40 [7100/10697 ( 66.4%)] Loss: 0.026163 L1: 0.015051 Grad: 0.110886 Thermal: 0.000465 LR: 2.55e-06\n",
      "Epoch  40 [7150/10697 ( 66.8%)] Loss: 0.027721 L1: 0.015943 Grad: 0.117510 Thermal: 0.000536 LR: 2.55e-06\n",
      "Epoch  40 [7150/10697 ( 66.8%)] Loss: 0.027721 L1: 0.015943 Grad: 0.117510 Thermal: 0.000536 LR: 2.55e-06\n",
      "Epoch  40 [7200/10697 ( 67.3%)] Loss: 0.025427 L1: 0.014802 Grad: 0.106040 Thermal: 0.000416 LR: 2.55e-06\n",
      "Epoch  40 [7200/10697 ( 67.3%)] Loss: 0.025427 L1: 0.014802 Grad: 0.106040 Thermal: 0.000416 LR: 2.55e-06\n",
      "Epoch  40 [7250/10697 ( 67.8%)] Loss: 0.022584 L1: 0.013338 Grad: 0.092292 Thermal: 0.000339 LR: 2.55e-06\n",
      "Epoch  40 [7250/10697 ( 67.8%)] Loss: 0.022584 L1: 0.013338 Grad: 0.092292 Thermal: 0.000339 LR: 2.55e-06\n",
      "Epoch  40 [7300/10697 ( 68.2%)] Loss: 0.027946 L1: 0.016602 Grad: 0.113192 Thermal: 0.000497 LR: 2.55e-06\n",
      "Epoch  40 [7300/10697 ( 68.2%)] Loss: 0.027946 L1: 0.016602 Grad: 0.113192 Thermal: 0.000497 LR: 2.55e-06\n",
      "Epoch  40 [7350/10697 ( 68.7%)] Loss: 0.029102 L1: 0.017263 Grad: 0.118135 Thermal: 0.000510 LR: 2.55e-06\n",
      "Epoch  40 [7350/10697 ( 68.7%)] Loss: 0.029102 L1: 0.017263 Grad: 0.118135 Thermal: 0.000510 LR: 2.55e-06\n",
      "Epoch  40 [7400/10697 ( 69.2%)] Loss: 0.025286 L1: 0.014520 Grad: 0.107453 Thermal: 0.000408 LR: 2.55e-06\n",
      "Epoch  40 [7400/10697 ( 69.2%)] Loss: 0.025286 L1: 0.014520 Grad: 0.107453 Thermal: 0.000408 LR: 2.55e-06\n",
      "Epoch  40 [7450/10697 ( 69.6%)] Loss: 0.027305 L1: 0.016575 Grad: 0.107049 Thermal: 0.000487 LR: 2.55e-06\n",
      "Epoch  40 [7450/10697 ( 69.6%)] Loss: 0.027305 L1: 0.016575 Grad: 0.107049 Thermal: 0.000487 LR: 2.55e-06\n",
      "Epoch  40 [7500/10697 ( 70.1%)] Loss: 0.025773 L1: 0.015108 Grad: 0.106440 Thermal: 0.000427 LR: 2.55e-06\n",
      "Epoch  40 [7500/10697 ( 70.1%)] Loss: 0.025773 L1: 0.015108 Grad: 0.106440 Thermal: 0.000427 LR: 2.55e-06\n",
      "Epoch  40 [7550/10697 ( 70.6%)] Loss: 0.026358 L1: 0.015365 Grad: 0.109699 Thermal: 0.000451 LR: 2.55e-06\n",
      "Epoch  40 [7550/10697 ( 70.6%)] Loss: 0.026358 L1: 0.015365 Grad: 0.109699 Thermal: 0.000451 LR: 2.55e-06\n",
      "Epoch  40 [7600/10697 ( 71.0%)] Loss: 0.025406 L1: 0.014864 Grad: 0.105181 Thermal: 0.000468 LR: 2.55e-06\n",
      "Epoch  40 [7600/10697 ( 71.0%)] Loss: 0.025406 L1: 0.014864 Grad: 0.105181 Thermal: 0.000468 LR: 2.55e-06\n",
      "Epoch  40 [7650/10697 ( 71.5%)] Loss: 0.027639 L1: 0.015787 Grad: 0.118291 Thermal: 0.000448 LR: 2.55e-06\n",
      "Epoch  40 [7650/10697 ( 71.5%)] Loss: 0.027639 L1: 0.015787 Grad: 0.118291 Thermal: 0.000448 LR: 2.55e-06\n",
      "Epoch  40 [7700/10697 ( 72.0%)] Loss: 0.031016 L1: 0.017989 Grad: 0.129991 Thermal: 0.000564 LR: 2.55e-06\n",
      "Epoch  40 [7700/10697 ( 72.0%)] Loss: 0.031016 L1: 0.017989 Grad: 0.129991 Thermal: 0.000564 LR: 2.55e-06\n",
      "Epoch  40 [7750/10697 ( 72.5%)] Loss: 0.026140 L1: 0.015484 Grad: 0.106330 Thermal: 0.000454 LR: 2.55e-06\n",
      "Epoch  40 [7750/10697 ( 72.5%)] Loss: 0.026140 L1: 0.015484 Grad: 0.106330 Thermal: 0.000454 LR: 2.55e-06\n",
      "Epoch  40 [7800/10697 ( 72.9%)] Loss: 0.032591 L1: 0.018582 Grad: 0.139754 Thermal: 0.000668 LR: 2.55e-06\n",
      "Epoch  40 [7800/10697 ( 72.9%)] Loss: 0.032591 L1: 0.018582 Grad: 0.139754 Thermal: 0.000668 LR: 2.55e-06\n",
      "Epoch  40 [7850/10697 ( 73.4%)] Loss: 0.024877 L1: 0.014239 Grad: 0.106175 Thermal: 0.000399 LR: 2.55e-06\n",
      "Epoch  40 [7850/10697 ( 73.4%)] Loss: 0.024877 L1: 0.014239 Grad: 0.106175 Thermal: 0.000399 LR: 2.55e-06\n",
      "Epoch  40 [7900/10697 ( 73.9%)] Loss: 0.027443 L1: 0.015365 Grad: 0.120534 Thermal: 0.000498 LR: 2.55e-06\n",
      "Epoch  40 [7900/10697 ( 73.9%)] Loss: 0.027443 L1: 0.015365 Grad: 0.120534 Thermal: 0.000498 LR: 2.55e-06\n",
      "Epoch  40 [7950/10697 ( 74.3%)] Loss: 0.026409 L1: 0.016053 Grad: 0.103333 Thermal: 0.000456 LR: 2.55e-06\n",
      "Epoch  40 [7950/10697 ( 74.3%)] Loss: 0.026409 L1: 0.016053 Grad: 0.103333 Thermal: 0.000456 LR: 2.55e-06\n",
      "Epoch  40 [8000/10697 ( 74.8%)] Loss: 0.023409 L1: 0.013539 Grad: 0.098529 Thermal: 0.000353 LR: 2.55e-06\n",
      "Epoch  40 [8000/10697 ( 74.8%)] Loss: 0.023409 L1: 0.013539 Grad: 0.098529 Thermal: 0.000353 LR: 2.55e-06\n",
      "Epoch  40 [8050/10697 ( 75.3%)] Loss: 0.021891 L1: 0.012756 Grad: 0.091172 Thermal: 0.000356 LR: 2.55e-06\n",
      "Epoch  40 [8050/10697 ( 75.3%)] Loss: 0.021891 L1: 0.012756 Grad: 0.091172 Thermal: 0.000356 LR: 2.55e-06\n",
      "Epoch  40 [8100/10697 ( 75.7%)] Loss: 0.026270 L1: 0.015245 Grad: 0.110026 Thermal: 0.000445 LR: 2.55e-06\n",
      "Epoch  40 [8100/10697 ( 75.7%)] Loss: 0.026270 L1: 0.015245 Grad: 0.110026 Thermal: 0.000445 LR: 2.55e-06\n",
      "Epoch  40 [8150/10697 ( 76.2%)] Loss: 0.027109 L1: 0.015780 Grad: 0.113073 Thermal: 0.000446 LR: 2.55e-06\n",
      "Epoch  40 [8150/10697 ( 76.2%)] Loss: 0.027109 L1: 0.015780 Grad: 0.113073 Thermal: 0.000446 LR: 2.55e-06\n",
      "Epoch  40 [8200/10697 ( 76.7%)] Loss: 0.023154 L1: 0.013279 Grad: 0.098566 Thermal: 0.000365 LR: 2.55e-06\n",
      "Epoch  40 [8200/10697 ( 76.7%)] Loss: 0.023154 L1: 0.013279 Grad: 0.098566 Thermal: 0.000365 LR: 2.55e-06\n",
      "Epoch  40 [8250/10697 ( 77.1%)] Loss: 0.027544 L1: 0.016016 Grad: 0.115038 Thermal: 0.000488 LR: 2.55e-06\n",
      "Epoch  40 [8250/10697 ( 77.1%)] Loss: 0.027544 L1: 0.016016 Grad: 0.115038 Thermal: 0.000488 LR: 2.55e-06\n",
      "Epoch  40 [8300/10697 ( 77.6%)] Loss: 0.024776 L1: 0.014588 Grad: 0.101671 Thermal: 0.000407 LR: 2.55e-06\n",
      "Epoch  40 [8300/10697 ( 77.6%)] Loss: 0.024776 L1: 0.014588 Grad: 0.101671 Thermal: 0.000407 LR: 2.55e-06\n",
      "Epoch  40 [8350/10697 ( 78.1%)] Loss: 0.026696 L1: 0.015864 Grad: 0.108074 Thermal: 0.000487 LR: 2.55e-06\n",
      "Epoch  40 [8350/10697 ( 78.1%)] Loss: 0.026696 L1: 0.015864 Grad: 0.108074 Thermal: 0.000487 LR: 2.55e-06\n",
      "Epoch  40 [8400/10697 ( 78.5%)] Loss: 0.029446 L1: 0.017396 Grad: 0.120224 Thermal: 0.000560 LR: 2.55e-06\n",
      "Epoch  40 [8400/10697 ( 78.5%)] Loss: 0.029446 L1: 0.017396 Grad: 0.120224 Thermal: 0.000560 LR: 2.55e-06\n",
      "Epoch  40 [8450/10697 ( 79.0%)] Loss: 0.025181 L1: 0.014820 Grad: 0.103409 Thermal: 0.000409 LR: 2.55e-06\n",
      "Epoch  40 [8450/10697 ( 79.0%)] Loss: 0.025181 L1: 0.014820 Grad: 0.103409 Thermal: 0.000409 LR: 2.55e-06\n",
      "Epoch  40 [8500/10697 ( 79.5%)] Loss: 0.026123 L1: 0.015384 Grad: 0.107172 Thermal: 0.000451 LR: 2.55e-06\n",
      "Epoch  40 [8500/10697 ( 79.5%)] Loss: 0.026123 L1: 0.015384 Grad: 0.107172 Thermal: 0.000451 LR: 2.55e-06\n",
      "Epoch  40 [8550/10697 ( 79.9%)] Loss: 0.027700 L1: 0.016048 Grad: 0.116264 Thermal: 0.000494 LR: 2.55e-06\n",
      "Epoch  40 [8550/10697 ( 79.9%)] Loss: 0.027700 L1: 0.016048 Grad: 0.116264 Thermal: 0.000494 LR: 2.55e-06\n",
      "Epoch  40 [8600/10697 ( 80.4%)] Loss: 0.021455 L1: 0.012873 Grad: 0.085647 Thermal: 0.000346 LR: 2.55e-06\n",
      "Epoch  40 [8600/10697 ( 80.4%)] Loss: 0.021455 L1: 0.012873 Grad: 0.085647 Thermal: 0.000346 LR: 2.55e-06\n",
      "Epoch  40 [8650/10697 ( 80.9%)] Loss: 0.028850 L1: 0.016446 Grad: 0.123778 Thermal: 0.000522 LR: 2.55e-06\n",
      "Epoch  40 [8650/10697 ( 80.9%)] Loss: 0.028850 L1: 0.016446 Grad: 0.123778 Thermal: 0.000522 LR: 2.55e-06\n",
      "Epoch  40 [8700/10697 ( 81.3%)] Loss: 0.031177 L1: 0.018040 Grad: 0.131074 Thermal: 0.000597 LR: 2.55e-06\n",
      "Epoch  40 [8700/10697 ( 81.3%)] Loss: 0.031177 L1: 0.018040 Grad: 0.131074 Thermal: 0.000597 LR: 2.55e-06\n",
      "Epoch  40 [8750/10697 ( 81.8%)] Loss: 0.027186 L1: 0.016014 Grad: 0.111467 Thermal: 0.000512 LR: 2.55e-06\n",
      "Epoch  40 [8750/10697 ( 81.8%)] Loss: 0.027186 L1: 0.016014 Grad: 0.111467 Thermal: 0.000512 LR: 2.55e-06\n",
      "Epoch  40 [8800/10697 ( 82.3%)] Loss: 0.028787 L1: 0.017010 Grad: 0.117513 Thermal: 0.000511 LR: 2.55e-06\n",
      "Epoch  40 [8800/10697 ( 82.3%)] Loss: 0.028787 L1: 0.017010 Grad: 0.117513 Thermal: 0.000511 LR: 2.55e-06\n",
      "Epoch  40 [8850/10697 ( 82.7%)] Loss: 0.033401 L1: 0.019444 Grad: 0.139231 Thermal: 0.000672 LR: 2.55e-06\n",
      "Epoch  40 [8850/10697 ( 82.7%)] Loss: 0.033401 L1: 0.019444 Grad: 0.139231 Thermal: 0.000672 LR: 2.55e-06\n",
      "Epoch  40 [8900/10697 ( 83.2%)] Loss: 0.026738 L1: 0.015414 Grad: 0.112996 Thermal: 0.000485 LR: 2.55e-06\n",
      "Epoch  40 [8900/10697 ( 83.2%)] Loss: 0.026738 L1: 0.015414 Grad: 0.112996 Thermal: 0.000485 LR: 2.55e-06\n",
      "Epoch  40 [8950/10697 ( 83.7%)] Loss: 0.023510 L1: 0.013609 Grad: 0.098832 Thermal: 0.000356 LR: 2.55e-06\n",
      "Epoch  40 [8950/10697 ( 83.7%)] Loss: 0.023510 L1: 0.013609 Grad: 0.098832 Thermal: 0.000356 LR: 2.55e-06\n",
      "Epoch  40 [9000/10697 ( 84.1%)] Loss: 0.027333 L1: 0.015946 Grad: 0.113643 Thermal: 0.000463 LR: 2.55e-06\n",
      "Epoch  40 [9000/10697 ( 84.1%)] Loss: 0.027333 L1: 0.015946 Grad: 0.113643 Thermal: 0.000463 LR: 2.55e-06\n",
      "Epoch  40 [9050/10697 ( 84.6%)] Loss: 0.024389 L1: 0.014466 Grad: 0.099035 Thermal: 0.000390 LR: 2.55e-06\n",
      "Epoch  40 [9050/10697 ( 84.6%)] Loss: 0.024389 L1: 0.014466 Grad: 0.099035 Thermal: 0.000390 LR: 2.55e-06\n",
      "Epoch  40 [9100/10697 ( 85.1%)] Loss: 0.032058 L1: 0.018685 Grad: 0.133404 Thermal: 0.000640 LR: 2.55e-06\n",
      "Epoch  40 [9100/10697 ( 85.1%)] Loss: 0.032058 L1: 0.018685 Grad: 0.133404 Thermal: 0.000640 LR: 2.55e-06\n",
      "Epoch  40 [9150/10697 ( 85.5%)] Loss: 0.026077 L1: 0.015176 Grad: 0.108762 Thermal: 0.000493 LR: 2.55e-06\n",
      "Epoch  40 [9150/10697 ( 85.5%)] Loss: 0.026077 L1: 0.015176 Grad: 0.108762 Thermal: 0.000493 LR: 2.55e-06\n",
      "Epoch  40 [9200/10697 ( 86.0%)] Loss: 0.032275 L1: 0.019126 Grad: 0.131169 Thermal: 0.000629 LR: 2.55e-06\n",
      "Epoch  40 [9200/10697 ( 86.0%)] Loss: 0.032275 L1: 0.019126 Grad: 0.131169 Thermal: 0.000629 LR: 2.55e-06\n",
      "Epoch  40 [9250/10697 ( 86.5%)] Loss: 0.020688 L1: 0.011829 Grad: 0.088435 Thermal: 0.000291 LR: 2.55e-06\n",
      "Epoch  40 [9250/10697 ( 86.5%)] Loss: 0.020688 L1: 0.011829 Grad: 0.088435 Thermal: 0.000291 LR: 2.55e-06\n",
      "Epoch  40 [9300/10697 ( 86.9%)] Loss: 0.031157 L1: 0.018185 Grad: 0.129428 Thermal: 0.000596 LR: 2.55e-06\n",
      "Epoch  40 [9300/10697 ( 86.9%)] Loss: 0.031157 L1: 0.018185 Grad: 0.129428 Thermal: 0.000596 LR: 2.55e-06\n",
      "Epoch  40 [9350/10697 ( 87.4%)] Loss: 0.025869 L1: 0.014927 Grad: 0.109190 Thermal: 0.000460 LR: 2.55e-06\n",
      "Epoch  40 [9350/10697 ( 87.4%)] Loss: 0.025869 L1: 0.014927 Grad: 0.109190 Thermal: 0.000460 LR: 2.55e-06\n",
      "Epoch  40 [9400/10697 ( 87.9%)] Loss: 0.027216 L1: 0.016070 Grad: 0.111222 Thermal: 0.000477 LR: 2.55e-06\n",
      "Epoch  40 [9400/10697 ( 87.9%)] Loss: 0.027216 L1: 0.016070 Grad: 0.111222 Thermal: 0.000477 LR: 2.55e-06\n",
      "Epoch  40 [9450/10697 ( 88.3%)] Loss: 0.028984 L1: 0.017261 Grad: 0.116959 Thermal: 0.000545 LR: 2.55e-06\n",
      "Epoch  40 [9450/10697 ( 88.3%)] Loss: 0.028984 L1: 0.017261 Grad: 0.116959 Thermal: 0.000545 LR: 2.55e-06\n",
      "Epoch  40 [9500/10697 ( 88.8%)] Loss: 0.031410 L1: 0.018264 Grad: 0.131167 Thermal: 0.000582 LR: 2.55e-06\n",
      "Epoch  40 [9500/10697 ( 88.8%)] Loss: 0.031410 L1: 0.018264 Grad: 0.131167 Thermal: 0.000582 LR: 2.55e-06\n",
      "Epoch  40 [9550/10697 ( 89.3%)] Loss: 0.027837 L1: 0.016065 Grad: 0.117498 Thermal: 0.000440 LR: 2.55e-06\n",
      "Epoch  40 [9550/10697 ( 89.3%)] Loss: 0.027837 L1: 0.016065 Grad: 0.117498 Thermal: 0.000440 LR: 2.55e-06\n",
      "Epoch  40 [9600/10697 ( 89.7%)] Loss: 0.030129 L1: 0.017798 Grad: 0.123018 Thermal: 0.000578 LR: 2.55e-06\n",
      "Epoch  40 [9600/10697 ( 89.7%)] Loss: 0.030129 L1: 0.017798 Grad: 0.123018 Thermal: 0.000578 LR: 2.55e-06\n",
      "Epoch  40 [9650/10697 ( 90.2%)] Loss: 0.025167 L1: 0.014768 Grad: 0.103778 Thermal: 0.000412 LR: 2.55e-06\n",
      "Epoch  40 [9650/10697 ( 90.2%)] Loss: 0.025167 L1: 0.014768 Grad: 0.103778 Thermal: 0.000412 LR: 2.55e-06\n",
      "Epoch  40 [9700/10697 ( 90.7%)] Loss: 0.018901 L1: 0.010942 Grad: 0.079460 Thermal: 0.000263 LR: 2.55e-06\n",
      "Epoch  40 [9700/10697 ( 90.7%)] Loss: 0.018901 L1: 0.010942 Grad: 0.079460 Thermal: 0.000263 LR: 2.55e-06\n",
      "Epoch  40 [9750/10697 ( 91.1%)] Loss: 0.022206 L1: 0.012989 Grad: 0.092010 Thermal: 0.000324 LR: 2.55e-06\n",
      "Epoch  40 [9750/10697 ( 91.1%)] Loss: 0.022206 L1: 0.012989 Grad: 0.092010 Thermal: 0.000324 LR: 2.55e-06\n",
      "Epoch  40 [9800/10697 ( 91.6%)] Loss: 0.034792 L1: 0.019731 Grad: 0.150280 Thermal: 0.000656 LR: 2.55e-06\n",
      "Epoch  40 [9800/10697 ( 91.6%)] Loss: 0.034792 L1: 0.019731 Grad: 0.150280 Thermal: 0.000656 LR: 2.55e-06\n",
      "Epoch  40 [9850/10697 ( 92.1%)] Loss: 0.032112 L1: 0.018463 Grad: 0.136169 Thermal: 0.000645 LR: 2.55e-06\n",
      "Epoch  40 [9850/10697 ( 92.1%)] Loss: 0.032112 L1: 0.018463 Grad: 0.136169 Thermal: 0.000645 LR: 2.55e-06\n",
      "Epoch  40 [9900/10697 ( 92.5%)] Loss: 0.025019 L1: 0.014742 Grad: 0.102561 Thermal: 0.000415 LR: 2.55e-06\n",
      "Epoch  40 [9900/10697 ( 92.5%)] Loss: 0.025019 L1: 0.014742 Grad: 0.102561 Thermal: 0.000415 LR: 2.55e-06\n",
      "Epoch  40 [9950/10697 ( 93.0%)] Loss: 0.023227 L1: 0.013410 Grad: 0.097991 Thermal: 0.000358 LR: 2.55e-06\n",
      "Epoch  40 [9950/10697 ( 93.0%)] Loss: 0.023227 L1: 0.013410 Grad: 0.097991 Thermal: 0.000358 LR: 2.55e-06\n",
      "Epoch  40 [10000/10697 ( 93.5%)] Loss: 0.022578 L1: 0.013137 Grad: 0.094255 Thermal: 0.000325 LR: 2.55e-06\n",
      "Epoch  40 [10000/10697 ( 93.5%)] Loss: 0.022578 L1: 0.013137 Grad: 0.094255 Thermal: 0.000325 LR: 2.55e-06\n",
      "Epoch  40 [10050/10697 ( 94.0%)] Loss: 0.020949 L1: 0.012193 Grad: 0.087398 Thermal: 0.000326 LR: 2.55e-06\n",
      "Epoch  40 [10050/10697 ( 94.0%)] Loss: 0.020949 L1: 0.012193 Grad: 0.087398 Thermal: 0.000326 LR: 2.55e-06\n",
      "Epoch  40 [10100/10697 ( 94.4%)] Loss: 0.030727 L1: 0.017999 Grad: 0.126966 Thermal: 0.000626 LR: 2.55e-06\n",
      "Epoch  40 [10100/10697 ( 94.4%)] Loss: 0.030727 L1: 0.017999 Grad: 0.126966 Thermal: 0.000626 LR: 2.55e-06\n",
      "Epoch  40 [10150/10697 ( 94.9%)] Loss: 0.022643 L1: 0.012851 Grad: 0.097750 Thermal: 0.000337 LR: 2.55e-06\n",
      "Epoch  40 [10150/10697 ( 94.9%)] Loss: 0.022643 L1: 0.012851 Grad: 0.097750 Thermal: 0.000337 LR: 2.55e-06\n",
      "Epoch  40 [10200/10697 ( 95.4%)] Loss: 0.035484 L1: 0.020331 Grad: 0.151117 Thermal: 0.000831 LR: 2.55e-06\n",
      "Epoch  40 [10200/10697 ( 95.4%)] Loss: 0.035484 L1: 0.020331 Grad: 0.151117 Thermal: 0.000831 LR: 2.55e-06\n",
      "Epoch  40 [10250/10697 ( 95.8%)] Loss: 0.025477 L1: 0.015039 Grad: 0.104184 Thermal: 0.000407 LR: 2.55e-06\n",
      "Epoch  40 [10250/10697 ( 95.8%)] Loss: 0.025477 L1: 0.015039 Grad: 0.104184 Thermal: 0.000407 LR: 2.55e-06\n",
      "Epoch  40 [10300/10697 ( 96.3%)] Loss: 0.026575 L1: 0.015632 Grad: 0.109221 Thermal: 0.000423 LR: 2.55e-06\n",
      "Epoch  40 [10300/10697 ( 96.3%)] Loss: 0.026575 L1: 0.015632 Grad: 0.109221 Thermal: 0.000423 LR: 2.55e-06\n",
      "Epoch  40 [10350/10697 ( 96.8%)] Loss: 0.023729 L1: 0.014033 Grad: 0.096772 Thermal: 0.000378 LR: 2.55e-06\n",
      "Epoch  40 [10350/10697 ( 96.8%)] Loss: 0.023729 L1: 0.014033 Grad: 0.096772 Thermal: 0.000378 LR: 2.55e-06\n",
      "Epoch  40 [10400/10697 ( 97.2%)] Loss: 0.025152 L1: 0.014878 Grad: 0.102538 Thermal: 0.000420 LR: 2.55e-06\n",
      "Epoch  40 [10400/10697 ( 97.2%)] Loss: 0.025152 L1: 0.014878 Grad: 0.102538 Thermal: 0.000420 LR: 2.55e-06\n",
      "Epoch  40 [10450/10697 ( 97.7%)] Loss: 0.028267 L1: 0.016248 Grad: 0.119922 Thermal: 0.000537 LR: 2.55e-06\n",
      "Epoch  40 [10450/10697 ( 97.7%)] Loss: 0.028267 L1: 0.016248 Grad: 0.119922 Thermal: 0.000537 LR: 2.55e-06\n",
      "Epoch  40 [10500/10697 ( 98.2%)] Loss: 0.023332 L1: 0.013117 Grad: 0.101959 Thermal: 0.000383 LR: 2.55e-06\n",
      "Epoch  40 [10500/10697 ( 98.2%)] Loss: 0.023332 L1: 0.013117 Grad: 0.101959 Thermal: 0.000383 LR: 2.55e-06\n",
      "Epoch  40 [10550/10697 ( 98.6%)] Loss: 0.028755 L1: 0.016804 Grad: 0.119241 Thermal: 0.000527 LR: 2.55e-06\n",
      "Epoch  40 [10550/10697 ( 98.6%)] Loss: 0.028755 L1: 0.016804 Grad: 0.119241 Thermal: 0.000527 LR: 2.55e-06\n",
      "Epoch  40 [10600/10697 ( 99.1%)] Loss: 0.025367 L1: 0.015238 Grad: 0.101085 Thermal: 0.000407 LR: 2.55e-06\n",
      "Epoch  40 [10600/10697 ( 99.1%)] Loss: 0.025367 L1: 0.015238 Grad: 0.101085 Thermal: 0.000407 LR: 2.55e-06\n",
      "Epoch  40 [10650/10697 ( 99.6%)] Loss: 0.026271 L1: 0.015648 Grad: 0.105995 Thermal: 0.000461 LR: 2.55e-06\n",
      "Epoch  40 [10650/10697 ( 99.6%)] Loss: 0.026271 L1: 0.015648 Grad: 0.105995 Thermal: 0.000461 LR: 2.55e-06\n",
      "üí´ New best model saved! PSNR: 33.97\n",
      "Epoch  40 Summary: Loss=0.026215 (L1:0.0153, Grad:0.1090, Thermal:0.0005) Val_PSNR=33.97dB Best=33.97dB Time=162.2min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "üí´ New best model saved! PSNR: 33.97\n",
      "Epoch  40 Summary: Loss=0.026215 (L1:0.0153, Grad:0.1090, Thermal:0.0005) Val_PSNR=33.97dB Best=33.97dB Time=162.2min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  41 [   0/10697 (  0.0%)] Loss: 0.027224 L1: 0.016243 Grad: 0.109564 Thermal: 0.000490 LR: 2.45e-06\n",
      "Epoch  41 [   0/10697 (  0.0%)] Loss: 0.027224 L1: 0.016243 Grad: 0.109564 Thermal: 0.000490 LR: 2.45e-06\n",
      "Epoch  41 [  50/10697 (  0.5%)] Loss: 0.024855 L1: 0.014791 Grad: 0.100436 Thermal: 0.000398 LR: 2.45e-06\n",
      "Epoch  41 [  50/10697 (  0.5%)] Loss: 0.024855 L1: 0.014791 Grad: 0.100436 Thermal: 0.000398 LR: 2.45e-06\n",
      "Epoch  41 [ 100/10697 (  0.9%)] Loss: 0.029500 L1: 0.017277 Grad: 0.121929 Thermal: 0.000599 LR: 2.45e-06\n",
      "Epoch  41 [ 100/10697 (  0.9%)] Loss: 0.029500 L1: 0.017277 Grad: 0.121929 Thermal: 0.000599 LR: 2.45e-06\n",
      "Epoch  41 [ 150/10697 (  1.4%)] Loss: 0.026675 L1: 0.015849 Grad: 0.108034 Thermal: 0.000448 LR: 2.45e-06\n",
      "Epoch  41 [ 150/10697 (  1.4%)] Loss: 0.026675 L1: 0.015849 Grad: 0.108034 Thermal: 0.000448 LR: 2.45e-06\n",
      "Epoch  41 [ 200/10697 (  1.9%)] Loss: 0.025673 L1: 0.015225 Grad: 0.104224 Thermal: 0.000521 LR: 2.45e-06\n",
      "Epoch  41 [ 200/10697 (  1.9%)] Loss: 0.025673 L1: 0.015225 Grad: 0.104224 Thermal: 0.000521 LR: 2.45e-06\n",
      "Epoch  41 [ 250/10697 (  2.3%)] Loss: 0.024207 L1: 0.014213 Grad: 0.099755 Thermal: 0.000377 LR: 2.45e-06\n",
      "Epoch  41 [ 250/10697 (  2.3%)] Loss: 0.024207 L1: 0.014213 Grad: 0.099755 Thermal: 0.000377 LR: 2.45e-06\n",
      "Epoch  41 [ 300/10697 (  2.8%)] Loss: 0.026333 L1: 0.015193 Grad: 0.111173 Thermal: 0.000466 LR: 2.45e-06\n",
      "Epoch  41 [ 300/10697 (  2.8%)] Loss: 0.026333 L1: 0.015193 Grad: 0.111173 Thermal: 0.000466 LR: 2.45e-06\n",
      "Epoch  41 [ 350/10697 (  3.3%)] Loss: 0.028858 L1: 0.016399 Grad: 0.124296 Thermal: 0.000592 LR: 2.45e-06\n",
      "Epoch  41 [ 350/10697 (  3.3%)] Loss: 0.028858 L1: 0.016399 Grad: 0.124296 Thermal: 0.000592 LR: 2.45e-06\n",
      "Epoch  41 [ 400/10697 (  3.7%)] Loss: 0.025191 L1: 0.014899 Grad: 0.102732 Thermal: 0.000383 LR: 2.45e-06\n",
      "Epoch  41 [ 400/10697 (  3.7%)] Loss: 0.025191 L1: 0.014899 Grad: 0.102732 Thermal: 0.000383 LR: 2.45e-06\n",
      "Epoch  41 [ 450/10697 (  4.2%)] Loss: 0.028175 L1: 0.016629 Grad: 0.115203 Thermal: 0.000525 LR: 2.45e-06\n",
      "Epoch  41 [ 450/10697 (  4.2%)] Loss: 0.028175 L1: 0.016629 Grad: 0.115203 Thermal: 0.000525 LR: 2.45e-06\n",
      "Epoch  41 [ 500/10697 (  4.7%)] Loss: 0.025322 L1: 0.014795 Grad: 0.105061 Thermal: 0.000419 LR: 2.45e-06\n",
      "Epoch  41 [ 500/10697 (  4.7%)] Loss: 0.025322 L1: 0.014795 Grad: 0.105061 Thermal: 0.000419 LR: 2.45e-06\n",
      "Epoch  41 [ 550/10697 (  5.1%)] Loss: 0.026055 L1: 0.015135 Grad: 0.108979 Thermal: 0.000442 LR: 2.45e-06\n",
      "Epoch  41 [ 550/10697 (  5.1%)] Loss: 0.026055 L1: 0.015135 Grad: 0.108979 Thermal: 0.000442 LR: 2.45e-06\n",
      "Epoch  41 [ 600/10697 (  5.6%)] Loss: 0.030510 L1: 0.017449 Grad: 0.130322 Thermal: 0.000570 LR: 2.45e-06\n",
      "Epoch  41 [ 600/10697 (  5.6%)] Loss: 0.030510 L1: 0.017449 Grad: 0.130322 Thermal: 0.000570 LR: 2.45e-06\n",
      "Epoch  41 [ 650/10697 (  6.1%)] Loss: 0.022802 L1: 0.013236 Grad: 0.095478 Thermal: 0.000353 LR: 2.45e-06\n",
      "Epoch  41 [ 650/10697 (  6.1%)] Loss: 0.022802 L1: 0.013236 Grad: 0.095478 Thermal: 0.000353 LR: 2.45e-06\n",
      "Epoch  41 [ 700/10697 (  6.5%)] Loss: 0.025514 L1: 0.014948 Grad: 0.105463 Thermal: 0.000400 LR: 2.45e-06\n",
      "Epoch  41 [ 700/10697 (  6.5%)] Loss: 0.025514 L1: 0.014948 Grad: 0.105463 Thermal: 0.000400 LR: 2.45e-06\n",
      "Epoch  41 [ 750/10697 (  7.0%)] Loss: 0.029314 L1: 0.017382 Grad: 0.119037 Thermal: 0.000574 LR: 2.45e-06\n",
      "Epoch  41 [ 750/10697 (  7.0%)] Loss: 0.029314 L1: 0.017382 Grad: 0.119037 Thermal: 0.000574 LR: 2.45e-06\n",
      "Epoch  41 [ 800/10697 (  7.5%)] Loss: 0.030332 L1: 0.017942 Grad: 0.123602 Thermal: 0.000593 LR: 2.45e-06\n",
      "Epoch  41 [ 800/10697 (  7.5%)] Loss: 0.030332 L1: 0.017942 Grad: 0.123602 Thermal: 0.000593 LR: 2.45e-06\n",
      "Epoch  41 [ 850/10697 (  7.9%)] Loss: 0.023330 L1: 0.013804 Grad: 0.095091 Thermal: 0.000336 LR: 2.45e-06\n",
      "Epoch  41 [ 850/10697 (  7.9%)] Loss: 0.023330 L1: 0.013804 Grad: 0.095091 Thermal: 0.000336 LR: 2.45e-06\n",
      "Epoch  41 [ 900/10697 (  8.4%)] Loss: 0.023388 L1: 0.013992 Grad: 0.093770 Thermal: 0.000380 LR: 2.45e-06\n",
      "Epoch  41 [ 900/10697 (  8.4%)] Loss: 0.023388 L1: 0.013992 Grad: 0.093770 Thermal: 0.000380 LR: 2.45e-06\n",
      "Epoch  41 [ 950/10697 (  8.9%)] Loss: 0.024683 L1: 0.014224 Grad: 0.104388 Thermal: 0.000398 LR: 2.45e-06\n",
      "Epoch  41 [ 950/10697 (  8.9%)] Loss: 0.024683 L1: 0.014224 Grad: 0.104388 Thermal: 0.000398 LR: 2.45e-06\n",
      "Epoch  41 [1000/10697 (  9.3%)] Loss: 0.022866 L1: 0.013412 Grad: 0.094365 Thermal: 0.000340 LR: 2.45e-06\n",
      "Epoch  41 [1000/10697 (  9.3%)] Loss: 0.022866 L1: 0.013412 Grad: 0.094365 Thermal: 0.000340 LR: 2.45e-06\n",
      "Epoch  41 [1050/10697 (  9.8%)] Loss: 0.020250 L1: 0.011704 Grad: 0.085317 Thermal: 0.000295 LR: 2.45e-06\n",
      "Epoch  41 [1050/10697 (  9.8%)] Loss: 0.020250 L1: 0.011704 Grad: 0.085317 Thermal: 0.000295 LR: 2.45e-06\n",
      "Epoch  41 [1100/10697 ( 10.3%)] Loss: 0.022870 L1: 0.012851 Grad: 0.100008 Thermal: 0.000364 LR: 2.45e-06\n",
      "Epoch  41 [1100/10697 ( 10.3%)] Loss: 0.022870 L1: 0.012851 Grad: 0.100008 Thermal: 0.000364 LR: 2.45e-06\n",
      "Epoch  41 [1150/10697 ( 10.8%)] Loss: 0.026611 L1: 0.015623 Grad: 0.109658 Thermal: 0.000448 LR: 2.45e-06\n",
      "Epoch  41 [1150/10697 ( 10.8%)] Loss: 0.026611 L1: 0.015623 Grad: 0.109658 Thermal: 0.000448 LR: 2.45e-06\n",
      "Epoch  41 [1200/10697 ( 11.2%)] Loss: 0.020775 L1: 0.012164 Grad: 0.085951 Thermal: 0.000312 LR: 2.45e-06\n",
      "Epoch  41 [1200/10697 ( 11.2%)] Loss: 0.020775 L1: 0.012164 Grad: 0.085951 Thermal: 0.000312 LR: 2.45e-06\n",
      "Epoch  41 [1250/10697 ( 11.7%)] Loss: 0.036022 L1: 0.020707 Grad: 0.152783 Thermal: 0.000745 LR: 2.45e-06\n",
      "Epoch  41 [1250/10697 ( 11.7%)] Loss: 0.036022 L1: 0.020707 Grad: 0.152783 Thermal: 0.000745 LR: 2.45e-06\n",
      "Epoch  41 [1300/10697 ( 12.2%)] Loss: 0.029587 L1: 0.017703 Grad: 0.118574 Thermal: 0.000522 LR: 2.45e-06\n",
      "Epoch  41 [1300/10697 ( 12.2%)] Loss: 0.029587 L1: 0.017703 Grad: 0.118574 Thermal: 0.000522 LR: 2.45e-06\n",
      "Epoch  41 [1350/10697 ( 12.6%)] Loss: 0.024752 L1: 0.014759 Grad: 0.099723 Thermal: 0.000420 LR: 2.45e-06\n",
      "Epoch  41 [1350/10697 ( 12.6%)] Loss: 0.024752 L1: 0.014759 Grad: 0.099723 Thermal: 0.000420 LR: 2.45e-06\n",
      "Epoch  41 [1400/10697 ( 13.1%)] Loss: 0.027818 L1: 0.016049 Grad: 0.117444 Thermal: 0.000482 LR: 2.45e-06\n",
      "Epoch  41 [1400/10697 ( 13.1%)] Loss: 0.027818 L1: 0.016049 Grad: 0.117444 Thermal: 0.000482 LR: 2.45e-06\n",
      "Epoch  41 [1450/10697 ( 13.6%)] Loss: 0.026308 L1: 0.015702 Grad: 0.105845 Thermal: 0.000446 LR: 2.45e-06\n",
      "Epoch  41 [1450/10697 ( 13.6%)] Loss: 0.026308 L1: 0.015702 Grad: 0.105845 Thermal: 0.000446 LR: 2.45e-06\n",
      "Epoch  41 [1500/10697 ( 14.0%)] Loss: 0.025454 L1: 0.015072 Grad: 0.103623 Thermal: 0.000405 LR: 2.45e-06\n",
      "Epoch  41 [1500/10697 ( 14.0%)] Loss: 0.025454 L1: 0.015072 Grad: 0.103623 Thermal: 0.000405 LR: 2.45e-06\n",
      "Epoch  41 [1550/10697 ( 14.5%)] Loss: 0.020963 L1: 0.012146 Grad: 0.088001 Thermal: 0.000334 LR: 2.45e-06\n",
      "Epoch  41 [1550/10697 ( 14.5%)] Loss: 0.020963 L1: 0.012146 Grad: 0.088001 Thermal: 0.000334 LR: 2.45e-06\n",
      "Epoch  41 [1600/10697 ( 15.0%)] Loss: 0.025578 L1: 0.014979 Grad: 0.105786 Thermal: 0.000404 LR: 2.45e-06\n",
      "Epoch  41 [1600/10697 ( 15.0%)] Loss: 0.025578 L1: 0.014979 Grad: 0.105786 Thermal: 0.000404 LR: 2.45e-06\n",
      "Epoch  41 [1650/10697 ( 15.4%)] Loss: 0.024504 L1: 0.014199 Grad: 0.102866 Thermal: 0.000374 LR: 2.45e-06\n",
      "Epoch  41 [1650/10697 ( 15.4%)] Loss: 0.024504 L1: 0.014199 Grad: 0.102866 Thermal: 0.000374 LR: 2.45e-06\n",
      "Epoch  41 [1700/10697 ( 15.9%)] Loss: 0.037431 L1: 0.021359 Grad: 0.160250 Thermal: 0.000933 LR: 2.45e-06\n",
      "Epoch  41 [1700/10697 ( 15.9%)] Loss: 0.037431 L1: 0.021359 Grad: 0.160250 Thermal: 0.000933 LR: 2.45e-06\n",
      "Epoch  41 [1750/10697 ( 16.4%)] Loss: 0.029125 L1: 0.017099 Grad: 0.119986 Thermal: 0.000535 LR: 2.45e-06\n",
      "Epoch  41 [1750/10697 ( 16.4%)] Loss: 0.029125 L1: 0.017099 Grad: 0.119986 Thermal: 0.000535 LR: 2.45e-06\n",
      "Epoch  41 [1800/10697 ( 16.8%)] Loss: 0.027221 L1: 0.016100 Grad: 0.110964 Thermal: 0.000507 LR: 2.45e-06\n",
      "Epoch  41 [1800/10697 ( 16.8%)] Loss: 0.027221 L1: 0.016100 Grad: 0.110964 Thermal: 0.000507 LR: 2.45e-06\n",
      "Epoch  41 [1850/10697 ( 17.3%)] Loss: 0.022846 L1: 0.013224 Grad: 0.096043 Thermal: 0.000360 LR: 2.45e-06\n",
      "Epoch  41 [1850/10697 ( 17.3%)] Loss: 0.022846 L1: 0.013224 Grad: 0.096043 Thermal: 0.000360 LR: 2.45e-06\n",
      "Epoch  41 [1900/10697 ( 17.8%)] Loss: 0.021828 L1: 0.012733 Grad: 0.090786 Thermal: 0.000343 LR: 2.45e-06\n",
      "Epoch  41 [1900/10697 ( 17.8%)] Loss: 0.021828 L1: 0.012733 Grad: 0.090786 Thermal: 0.000343 LR: 2.45e-06\n",
      "Epoch  41 [1950/10697 ( 18.2%)] Loss: 0.027790 L1: 0.016191 Grad: 0.115748 Thermal: 0.000489 LR: 2.45e-06\n",
      "Epoch  41 [1950/10697 ( 18.2%)] Loss: 0.027790 L1: 0.016191 Grad: 0.115748 Thermal: 0.000489 LR: 2.45e-06\n",
      "Epoch  41 [2000/10697 ( 18.7%)] Loss: 0.024316 L1: 0.014092 Grad: 0.102036 Thermal: 0.000404 LR: 2.45e-06\n",
      "Epoch  41 [2000/10697 ( 18.7%)] Loss: 0.024316 L1: 0.014092 Grad: 0.102036 Thermal: 0.000404 LR: 2.45e-06\n",
      "Epoch  41 [2050/10697 ( 19.2%)] Loss: 0.023076 L1: 0.013111 Grad: 0.099460 Thermal: 0.000371 LR: 2.45e-06\n",
      "Epoch  41 [2050/10697 ( 19.2%)] Loss: 0.023076 L1: 0.013111 Grad: 0.099460 Thermal: 0.000371 LR: 2.45e-06\n",
      "Epoch  41 [2100/10697 ( 19.6%)] Loss: 0.028876 L1: 0.016162 Grad: 0.126851 Thermal: 0.000577 LR: 2.45e-06\n",
      "Epoch  41 [2100/10697 ( 19.6%)] Loss: 0.028876 L1: 0.016162 Grad: 0.126851 Thermal: 0.000577 LR: 2.45e-06\n",
      "Epoch  41 [2150/10697 ( 20.1%)] Loss: 0.026134 L1: 0.015537 Grad: 0.105743 Thermal: 0.000458 LR: 2.45e-06\n",
      "Epoch  41 [2150/10697 ( 20.1%)] Loss: 0.026134 L1: 0.015537 Grad: 0.105743 Thermal: 0.000458 LR: 2.45e-06\n",
      "Epoch  41 [2200/10697 ( 20.6%)] Loss: 0.030417 L1: 0.017387 Grad: 0.130016 Thermal: 0.000560 LR: 2.45e-06\n",
      "Epoch  41 [2200/10697 ( 20.6%)] Loss: 0.030417 L1: 0.017387 Grad: 0.130016 Thermal: 0.000560 LR: 2.45e-06\n",
      "Epoch  41 [2250/10697 ( 21.0%)] Loss: 0.019166 L1: 0.010503 Grad: 0.086515 Thermal: 0.000238 LR: 2.45e-06\n",
      "Epoch  41 [2250/10697 ( 21.0%)] Loss: 0.019166 L1: 0.010503 Grad: 0.086515 Thermal: 0.000238 LR: 2.45e-06\n",
      "Epoch  41 [2300/10697 ( 21.5%)] Loss: 0.029179 L1: 0.016962 Grad: 0.121890 Thermal: 0.000562 LR: 2.45e-06\n",
      "Epoch  41 [2300/10697 ( 21.5%)] Loss: 0.029179 L1: 0.016962 Grad: 0.121890 Thermal: 0.000562 LR: 2.45e-06\n",
      "Epoch  41 [2350/10697 ( 22.0%)] Loss: 0.021578 L1: 0.012614 Grad: 0.089488 Thermal: 0.000305 LR: 2.45e-06\n",
      "Epoch  41 [2350/10697 ( 22.0%)] Loss: 0.021578 L1: 0.012614 Grad: 0.089488 Thermal: 0.000305 LR: 2.45e-06\n",
      "Epoch  41 [2400/10697 ( 22.4%)] Loss: 0.026714 L1: 0.015784 Grad: 0.109070 Thermal: 0.000459 LR: 2.45e-06\n",
      "Epoch  41 [2400/10697 ( 22.4%)] Loss: 0.026714 L1: 0.015784 Grad: 0.109070 Thermal: 0.000459 LR: 2.45e-06\n",
      "Epoch  41 [2450/10697 ( 22.9%)] Loss: 0.030917 L1: 0.017854 Grad: 0.130331 Thermal: 0.000595 LR: 2.45e-06\n",
      "Epoch  41 [2450/10697 ( 22.9%)] Loss: 0.030917 L1: 0.017854 Grad: 0.130331 Thermal: 0.000595 LR: 2.45e-06\n",
      "Epoch  41 [2500/10697 ( 23.4%)] Loss: 0.031262 L1: 0.018241 Grad: 0.129893 Thermal: 0.000642 LR: 2.45e-06\n",
      "Epoch  41 [2500/10697 ( 23.4%)] Loss: 0.031262 L1: 0.018241 Grad: 0.129893 Thermal: 0.000642 LR: 2.45e-06\n",
      "Epoch  41 [2550/10697 ( 23.8%)] Loss: 0.025716 L1: 0.015185 Grad: 0.105109 Thermal: 0.000414 LR: 2.45e-06\n",
      "Epoch  41 [2550/10697 ( 23.8%)] Loss: 0.025716 L1: 0.015185 Grad: 0.105109 Thermal: 0.000414 LR: 2.45e-06\n",
      "Epoch  41 [2600/10697 ( 24.3%)] Loss: 0.023056 L1: 0.013773 Grad: 0.092638 Thermal: 0.000383 LR: 2.45e-06\n",
      "Epoch  41 [2600/10697 ( 24.3%)] Loss: 0.023056 L1: 0.013773 Grad: 0.092638 Thermal: 0.000383 LR: 2.45e-06\n",
      "Epoch  41 [2650/10697 ( 24.8%)] Loss: 0.024138 L1: 0.013937 Grad: 0.101818 Thermal: 0.000374 LR: 2.45e-06\n",
      "Epoch  41 [2650/10697 ( 24.8%)] Loss: 0.024138 L1: 0.013937 Grad: 0.101818 Thermal: 0.000374 LR: 2.45e-06\n",
      "Epoch  41 [2700/10697 ( 25.2%)] Loss: 0.028069 L1: 0.016934 Grad: 0.111102 Thermal: 0.000491 LR: 2.45e-06\n",
      "Epoch  41 [2700/10697 ( 25.2%)] Loss: 0.028069 L1: 0.016934 Grad: 0.111102 Thermal: 0.000491 LR: 2.45e-06\n",
      "Epoch  41 [2750/10697 ( 25.7%)] Loss: 0.024209 L1: 0.014119 Grad: 0.100711 Thermal: 0.000391 LR: 2.45e-06\n",
      "Epoch  41 [2750/10697 ( 25.7%)] Loss: 0.024209 L1: 0.014119 Grad: 0.100711 Thermal: 0.000391 LR: 2.45e-06\n",
      "Epoch  41 [2800/10697 ( 26.2%)] Loss: 0.026311 L1: 0.015196 Grad: 0.110907 Thermal: 0.000480 LR: 2.45e-06\n",
      "Epoch  41 [2800/10697 ( 26.2%)] Loss: 0.026311 L1: 0.015196 Grad: 0.110907 Thermal: 0.000480 LR: 2.45e-06\n",
      "Epoch  41 [2850/10697 ( 26.6%)] Loss: 0.026079 L1: 0.015546 Grad: 0.105116 Thermal: 0.000426 LR: 2.45e-06\n",
      "Epoch  41 [2850/10697 ( 26.6%)] Loss: 0.026079 L1: 0.015546 Grad: 0.105116 Thermal: 0.000426 LR: 2.45e-06\n",
      "Epoch  41 [2900/10697 ( 27.1%)] Loss: 0.025677 L1: 0.014491 Grad: 0.111650 Thermal: 0.000430 LR: 2.45e-06\n",
      "Epoch  41 [2900/10697 ( 27.1%)] Loss: 0.025677 L1: 0.014491 Grad: 0.111650 Thermal: 0.000430 LR: 2.45e-06\n",
      "Epoch  41 [2950/10697 ( 27.6%)] Loss: 0.022370 L1: 0.012752 Grad: 0.096022 Thermal: 0.000320 LR: 2.45e-06\n",
      "Epoch  41 [2950/10697 ( 27.6%)] Loss: 0.022370 L1: 0.012752 Grad: 0.096022 Thermal: 0.000320 LR: 2.45e-06\n",
      "Epoch  41 [3000/10697 ( 28.0%)] Loss: 0.025480 L1: 0.015247 Grad: 0.102139 Thermal: 0.000399 LR: 2.45e-06\n",
      "Epoch  41 [3000/10697 ( 28.0%)] Loss: 0.025480 L1: 0.015247 Grad: 0.102139 Thermal: 0.000399 LR: 2.45e-06\n",
      "Epoch  41 [3050/10697 ( 28.5%)] Loss: 0.023131 L1: 0.013558 Grad: 0.095554 Thermal: 0.000352 LR: 2.45e-06\n",
      "Epoch  41 [3050/10697 ( 28.5%)] Loss: 0.023131 L1: 0.013558 Grad: 0.095554 Thermal: 0.000352 LR: 2.45e-06\n",
      "Epoch  41 [3100/10697 ( 29.0%)] Loss: 0.014459 L1: 0.008190 Grad: 0.062612 Thermal: 0.000156 LR: 2.45e-06\n",
      "Epoch  41 [3100/10697 ( 29.0%)] Loss: 0.014459 L1: 0.008190 Grad: 0.062612 Thermal: 0.000156 LR: 2.45e-06\n",
      "Epoch  41 [3150/10697 ( 29.4%)] Loss: 0.020867 L1: 0.012346 Grad: 0.085061 Thermal: 0.000293 LR: 2.45e-06\n",
      "Epoch  41 [3150/10697 ( 29.4%)] Loss: 0.020867 L1: 0.012346 Grad: 0.085061 Thermal: 0.000293 LR: 2.45e-06\n",
      "Epoch  41 [3200/10697 ( 29.9%)] Loss: 0.024474 L1: 0.014401 Grad: 0.100525 Thermal: 0.000416 LR: 2.45e-06\n",
      "Epoch  41 [3200/10697 ( 29.9%)] Loss: 0.024474 L1: 0.014401 Grad: 0.100525 Thermal: 0.000416 LR: 2.45e-06\n",
      "Epoch  41 [3250/10697 ( 30.4%)] Loss: 0.026905 L1: 0.015794 Grad: 0.110888 Thermal: 0.000435 LR: 2.45e-06\n",
      "Epoch  41 [3250/10697 ( 30.4%)] Loss: 0.026905 L1: 0.015794 Grad: 0.110888 Thermal: 0.000435 LR: 2.45e-06\n",
      "Epoch  41 [3300/10697 ( 30.8%)] Loss: 0.022589 L1: 0.013356 Grad: 0.092150 Thermal: 0.000366 LR: 2.45e-06\n",
      "Epoch  41 [3300/10697 ( 30.8%)] Loss: 0.022589 L1: 0.013356 Grad: 0.092150 Thermal: 0.000366 LR: 2.45e-06\n",
      "Epoch  41 [3350/10697 ( 31.3%)] Loss: 0.029785 L1: 0.016995 Grad: 0.127632 Thermal: 0.000521 LR: 2.45e-06\n",
      "Epoch  41 [3350/10697 ( 31.3%)] Loss: 0.029785 L1: 0.016995 Grad: 0.127632 Thermal: 0.000521 LR: 2.45e-06\n",
      "Epoch  41 [3400/10697 ( 31.8%)] Loss: 0.029028 L1: 0.016950 Grad: 0.120522 Thermal: 0.000517 LR: 2.45e-06\n",
      "Epoch  41 [3400/10697 ( 31.8%)] Loss: 0.029028 L1: 0.016950 Grad: 0.120522 Thermal: 0.000517 LR: 2.45e-06\n",
      "Epoch  41 [3450/10697 ( 32.3%)] Loss: 0.023956 L1: 0.014052 Grad: 0.098835 Thermal: 0.000406 LR: 2.45e-06\n",
      "Epoch  41 [3450/10697 ( 32.3%)] Loss: 0.023956 L1: 0.014052 Grad: 0.098835 Thermal: 0.000406 LR: 2.45e-06\n",
      "Epoch  41 [3500/10697 ( 32.7%)] Loss: 0.027322 L1: 0.016152 Grad: 0.111459 Thermal: 0.000480 LR: 2.45e-06\n",
      "Epoch  41 [3500/10697 ( 32.7%)] Loss: 0.027322 L1: 0.016152 Grad: 0.111459 Thermal: 0.000480 LR: 2.45e-06\n",
      "Epoch  41 [3550/10697 ( 33.2%)] Loss: 0.022549 L1: 0.013173 Grad: 0.093588 Thermal: 0.000359 LR: 2.45e-06\n",
      "Epoch  41 [3550/10697 ( 33.2%)] Loss: 0.022549 L1: 0.013173 Grad: 0.093588 Thermal: 0.000359 LR: 2.45e-06\n",
      "Epoch  41 [3600/10697 ( 33.7%)] Loss: 0.026015 L1: 0.015139 Grad: 0.108539 Thermal: 0.000436 LR: 2.45e-06\n",
      "Epoch  41 [3600/10697 ( 33.7%)] Loss: 0.026015 L1: 0.015139 Grad: 0.108539 Thermal: 0.000436 LR: 2.45e-06\n",
      "Epoch  41 [3650/10697 ( 34.1%)] Loss: 0.025489 L1: 0.014750 Grad: 0.107179 Thermal: 0.000438 LR: 2.45e-06\n",
      "Epoch  41 [3650/10697 ( 34.1%)] Loss: 0.025489 L1: 0.014750 Grad: 0.107179 Thermal: 0.000438 LR: 2.45e-06\n",
      "Epoch  41 [3700/10697 ( 34.6%)] Loss: 0.033356 L1: 0.018730 Grad: 0.145915 Thermal: 0.000685 LR: 2.45e-06\n",
      "Epoch  41 [3700/10697 ( 34.6%)] Loss: 0.033356 L1: 0.018730 Grad: 0.145915 Thermal: 0.000685 LR: 2.45e-06\n",
      "Epoch  41 [3750/10697 ( 35.1%)] Loss: 0.024497 L1: 0.014144 Grad: 0.103347 Thermal: 0.000376 LR: 2.45e-06\n",
      "Epoch  41 [3750/10697 ( 35.1%)] Loss: 0.024497 L1: 0.014144 Grad: 0.103347 Thermal: 0.000376 LR: 2.45e-06\n",
      "Epoch  41 [3800/10697 ( 35.5%)] Loss: 0.023094 L1: 0.013464 Grad: 0.096110 Thermal: 0.000385 LR: 2.45e-06\n",
      "Epoch  41 [3800/10697 ( 35.5%)] Loss: 0.023094 L1: 0.013464 Grad: 0.096110 Thermal: 0.000385 LR: 2.45e-06\n",
      "Epoch  41 [3850/10697 ( 36.0%)] Loss: 0.025310 L1: 0.014775 Grad: 0.105151 Thermal: 0.000401 LR: 2.45e-06\n",
      "Epoch  41 [3850/10697 ( 36.0%)] Loss: 0.025310 L1: 0.014775 Grad: 0.105151 Thermal: 0.000401 LR: 2.45e-06\n",
      "Epoch  41 [3900/10697 ( 36.5%)] Loss: 0.022511 L1: 0.013126 Grad: 0.093686 Thermal: 0.000324 LR: 2.45e-06\n",
      "Epoch  41 [3900/10697 ( 36.5%)] Loss: 0.022511 L1: 0.013126 Grad: 0.093686 Thermal: 0.000324 LR: 2.45e-06\n",
      "Epoch  41 [3950/10697 ( 36.9%)] Loss: 0.025671 L1: 0.015183 Grad: 0.104667 Thermal: 0.000426 LR: 2.45e-06\n",
      "Epoch  41 [3950/10697 ( 36.9%)] Loss: 0.025671 L1: 0.015183 Grad: 0.104667 Thermal: 0.000426 LR: 2.45e-06\n",
      "Epoch  41 [4000/10697 ( 37.4%)] Loss: 0.022787 L1: 0.012794 Grad: 0.099779 Thermal: 0.000314 LR: 2.45e-06\n",
      "Epoch  41 [4000/10697 ( 37.4%)] Loss: 0.022787 L1: 0.012794 Grad: 0.099779 Thermal: 0.000314 LR: 2.45e-06\n",
      "Epoch  41 [4050/10697 ( 37.9%)] Loss: 0.025600 L1: 0.014573 Grad: 0.110045 Thermal: 0.000447 LR: 2.45e-06\n",
      "Epoch  41 [4050/10697 ( 37.9%)] Loss: 0.025600 L1: 0.014573 Grad: 0.110045 Thermal: 0.000447 LR: 2.45e-06\n",
      "Epoch  41 [4100/10697 ( 38.3%)] Loss: 0.023156 L1: 0.013287 Grad: 0.098492 Thermal: 0.000392 LR: 2.45e-06\n",
      "Epoch  41 [4100/10697 ( 38.3%)] Loss: 0.023156 L1: 0.013287 Grad: 0.098492 Thermal: 0.000392 LR: 2.45e-06\n",
      "Epoch  41 [4150/10697 ( 38.8%)] Loss: 0.021978 L1: 0.012910 Grad: 0.090508 Thermal: 0.000343 LR: 2.45e-06\n",
      "Epoch  41 [4150/10697 ( 38.8%)] Loss: 0.021978 L1: 0.012910 Grad: 0.090508 Thermal: 0.000343 LR: 2.45e-06\n",
      "Epoch  41 [4200/10697 ( 39.3%)] Loss: 0.027633 L1: 0.016736 Grad: 0.108730 Thermal: 0.000481 LR: 2.45e-06\n",
      "Epoch  41 [4200/10697 ( 39.3%)] Loss: 0.027633 L1: 0.016736 Grad: 0.108730 Thermal: 0.000481 LR: 2.45e-06\n",
      "Epoch  41 [4250/10697 ( 39.7%)] Loss: 0.026620 L1: 0.015841 Grad: 0.107571 Thermal: 0.000434 LR: 2.45e-06\n",
      "Epoch  41 [4250/10697 ( 39.7%)] Loss: 0.026620 L1: 0.015841 Grad: 0.107571 Thermal: 0.000434 LR: 2.45e-06\n",
      "Epoch  41 [4300/10697 ( 40.2%)] Loss: 0.026693 L1: 0.015685 Grad: 0.109832 Thermal: 0.000480 LR: 2.45e-06\n",
      "Epoch  41 [4300/10697 ( 40.2%)] Loss: 0.026693 L1: 0.015685 Grad: 0.109832 Thermal: 0.000480 LR: 2.45e-06\n",
      "Epoch  41 [4350/10697 ( 40.7%)] Loss: 0.030308 L1: 0.017588 Grad: 0.126927 Thermal: 0.000549 LR: 2.45e-06\n",
      "Epoch  41 [4350/10697 ( 40.7%)] Loss: 0.030308 L1: 0.017588 Grad: 0.126927 Thermal: 0.000549 LR: 2.45e-06\n",
      "Epoch  41 [4400/10697 ( 41.1%)] Loss: 0.027200 L1: 0.015690 Grad: 0.114858 Thermal: 0.000478 LR: 2.45e-06\n",
      "Epoch  41 [4400/10697 ( 41.1%)] Loss: 0.027200 L1: 0.015690 Grad: 0.114858 Thermal: 0.000478 LR: 2.45e-06\n",
      "Epoch  41 [4450/10697 ( 41.6%)] Loss: 0.026620 L1: 0.015216 Grad: 0.113812 Thermal: 0.000461 LR: 2.45e-06\n",
      "Epoch  41 [4450/10697 ( 41.6%)] Loss: 0.026620 L1: 0.015216 Grad: 0.113812 Thermal: 0.000461 LR: 2.45e-06\n",
      "Epoch  41 [4500/10697 ( 42.1%)] Loss: 0.030250 L1: 0.017326 Grad: 0.128960 Thermal: 0.000567 LR: 2.45e-06\n",
      "Epoch  41 [4500/10697 ( 42.1%)] Loss: 0.030250 L1: 0.017326 Grad: 0.128960 Thermal: 0.000567 LR: 2.45e-06\n",
      "Epoch  41 [4550/10697 ( 42.5%)] Loss: 0.023388 L1: 0.013332 Grad: 0.100353 Thermal: 0.000416 LR: 2.45e-06\n",
      "Epoch  41 [4550/10697 ( 42.5%)] Loss: 0.023388 L1: 0.013332 Grad: 0.100353 Thermal: 0.000416 LR: 2.45e-06\n",
      "Epoch  41 [4600/10697 ( 43.0%)] Loss: 0.027235 L1: 0.015405 Grad: 0.118057 Thermal: 0.000485 LR: 2.45e-06\n",
      "Epoch  41 [4600/10697 ( 43.0%)] Loss: 0.027235 L1: 0.015405 Grad: 0.118057 Thermal: 0.000485 LR: 2.45e-06\n",
      "Epoch  41 [4650/10697 ( 43.5%)] Loss: 0.029194 L1: 0.016777 Grad: 0.123929 Thermal: 0.000499 LR: 2.45e-06\n",
      "Epoch  41 [4650/10697 ( 43.5%)] Loss: 0.029194 L1: 0.016777 Grad: 0.123929 Thermal: 0.000499 LR: 2.45e-06\n",
      "Epoch  41 [4700/10697 ( 43.9%)] Loss: 0.025848 L1: 0.015321 Grad: 0.105054 Thermal: 0.000436 LR: 2.45e-06\n",
      "Epoch  41 [4700/10697 ( 43.9%)] Loss: 0.025848 L1: 0.015321 Grad: 0.105054 Thermal: 0.000436 LR: 2.45e-06\n",
      "Epoch  41 [4750/10697 ( 44.4%)] Loss: 0.027313 L1: 0.016285 Grad: 0.110040 Thermal: 0.000474 LR: 2.45e-06\n",
      "Epoch  41 [4750/10697 ( 44.4%)] Loss: 0.027313 L1: 0.016285 Grad: 0.110040 Thermal: 0.000474 LR: 2.45e-06\n",
      "Epoch  41 [4800/10697 ( 44.9%)] Loss: 0.027175 L1: 0.016535 Grad: 0.106161 Thermal: 0.000487 LR: 2.45e-06\n",
      "Epoch  41 [4800/10697 ( 44.9%)] Loss: 0.027175 L1: 0.016535 Grad: 0.106161 Thermal: 0.000487 LR: 2.45e-06\n",
      "Epoch  41 [4850/10697 ( 45.3%)] Loss: 0.026981 L1: 0.015424 Grad: 0.115326 Thermal: 0.000501 LR: 2.45e-06\n",
      "Epoch  41 [4850/10697 ( 45.3%)] Loss: 0.026981 L1: 0.015424 Grad: 0.115326 Thermal: 0.000501 LR: 2.45e-06\n",
      "Epoch  41 [4900/10697 ( 45.8%)] Loss: 0.023154 L1: 0.013083 Grad: 0.100538 Thermal: 0.000354 LR: 2.45e-06\n",
      "Epoch  41 [4900/10697 ( 45.8%)] Loss: 0.023154 L1: 0.013083 Grad: 0.100538 Thermal: 0.000354 LR: 2.45e-06\n",
      "Epoch  41 [4950/10697 ( 46.3%)] Loss: 0.023856 L1: 0.013856 Grad: 0.099813 Thermal: 0.000379 LR: 2.45e-06\n",
      "Epoch  41 [4950/10697 ( 46.3%)] Loss: 0.023856 L1: 0.013856 Grad: 0.099813 Thermal: 0.000379 LR: 2.45e-06\n",
      "Epoch  41 [5000/10697 ( 46.7%)] Loss: 0.026056 L1: 0.014844 Grad: 0.111854 Thermal: 0.000533 LR: 2.45e-06\n",
      "Epoch  41 [5000/10697 ( 46.7%)] Loss: 0.026056 L1: 0.014844 Grad: 0.111854 Thermal: 0.000533 LR: 2.45e-06\n",
      "Epoch  41 [5050/10697 ( 47.2%)] Loss: 0.030243 L1: 0.017517 Grad: 0.126984 Thermal: 0.000556 LR: 2.45e-06\n",
      "Epoch  41 [5050/10697 ( 47.2%)] Loss: 0.030243 L1: 0.017517 Grad: 0.126984 Thermal: 0.000556 LR: 2.45e-06\n",
      "Epoch  41 [5100/10697 ( 47.7%)] Loss: 0.025205 L1: 0.014951 Grad: 0.102330 Thermal: 0.000414 LR: 2.45e-06\n",
      "Epoch  41 [5100/10697 ( 47.7%)] Loss: 0.025205 L1: 0.014951 Grad: 0.102330 Thermal: 0.000414 LR: 2.45e-06\n",
      "Epoch  41 [5150/10697 ( 48.1%)] Loss: 0.024474 L1: 0.014308 Grad: 0.101454 Thermal: 0.000412 LR: 2.45e-06\n",
      "Epoch  41 [5150/10697 ( 48.1%)] Loss: 0.024474 L1: 0.014308 Grad: 0.101454 Thermal: 0.000412 LR: 2.45e-06\n",
      "Epoch  41 [5200/10697 ( 48.6%)] Loss: 0.024873 L1: 0.014758 Grad: 0.100949 Thermal: 0.000405 LR: 2.45e-06\n",
      "Epoch  41 [5200/10697 ( 48.6%)] Loss: 0.024873 L1: 0.014758 Grad: 0.100949 Thermal: 0.000405 LR: 2.45e-06\n",
      "Epoch  41 [5250/10697 ( 49.1%)] Loss: 0.029151 L1: 0.017277 Grad: 0.118471 Thermal: 0.000534 LR: 2.45e-06\n",
      "Epoch  41 [5250/10697 ( 49.1%)] Loss: 0.029151 L1: 0.017277 Grad: 0.118471 Thermal: 0.000534 LR: 2.45e-06\n",
      "Epoch  41 [5300/10697 ( 49.5%)] Loss: 0.023158 L1: 0.013245 Grad: 0.098948 Thermal: 0.000352 LR: 2.45e-06\n",
      "Epoch  41 [5300/10697 ( 49.5%)] Loss: 0.023158 L1: 0.013245 Grad: 0.098948 Thermal: 0.000352 LR: 2.45e-06\n",
      "Epoch  41 [5350/10697 ( 50.0%)] Loss: 0.022160 L1: 0.012753 Grad: 0.093889 Thermal: 0.000363 LR: 2.45e-06\n",
      "Epoch  41 [5350/10697 ( 50.0%)] Loss: 0.022160 L1: 0.012753 Grad: 0.093889 Thermal: 0.000363 LR: 2.45e-06\n",
      "Epoch  41 [5400/10697 ( 50.5%)] Loss: 0.026451 L1: 0.015881 Grad: 0.105473 Thermal: 0.000459 LR: 2.45e-06\n",
      "Epoch  41 [5400/10697 ( 50.5%)] Loss: 0.026451 L1: 0.015881 Grad: 0.105473 Thermal: 0.000459 LR: 2.45e-06\n",
      "Epoch  41 [5450/10697 ( 50.9%)] Loss: 0.026936 L1: 0.016143 Grad: 0.107683 Thermal: 0.000493 LR: 2.45e-06\n",
      "Epoch  41 [5450/10697 ( 50.9%)] Loss: 0.026936 L1: 0.016143 Grad: 0.107683 Thermal: 0.000493 LR: 2.45e-06\n",
      "Epoch  41 [5500/10697 ( 51.4%)] Loss: 0.030723 L1: 0.017605 Grad: 0.130818 Thermal: 0.000710 LR: 2.45e-06\n",
      "Epoch  41 [5500/10697 ( 51.4%)] Loss: 0.030723 L1: 0.017605 Grad: 0.130818 Thermal: 0.000710 LR: 2.45e-06\n",
      "Epoch  41 [5550/10697 ( 51.9%)] Loss: 0.029509 L1: 0.017049 Grad: 0.124259 Thermal: 0.000668 LR: 2.45e-06\n",
      "Epoch  41 [5550/10697 ( 51.9%)] Loss: 0.029509 L1: 0.017049 Grad: 0.124259 Thermal: 0.000668 LR: 2.45e-06\n",
      "Epoch  41 [5600/10697 ( 52.4%)] Loss: 0.027213 L1: 0.016275 Grad: 0.109135 Thermal: 0.000492 LR: 2.45e-06\n",
      "Epoch  41 [5600/10697 ( 52.4%)] Loss: 0.027213 L1: 0.016275 Grad: 0.109135 Thermal: 0.000492 LR: 2.45e-06\n",
      "Epoch  41 [5650/10697 ( 52.8%)] Loss: 0.024828 L1: 0.014039 Grad: 0.107698 Thermal: 0.000383 LR: 2.45e-06\n",
      "Epoch  41 [5650/10697 ( 52.8%)] Loss: 0.024828 L1: 0.014039 Grad: 0.107698 Thermal: 0.000383 LR: 2.45e-06\n",
      "Epoch  41 [5700/10697 ( 53.3%)] Loss: 0.026958 L1: 0.016016 Grad: 0.109181 Thermal: 0.000480 LR: 2.45e-06\n",
      "Epoch  41 [5700/10697 ( 53.3%)] Loss: 0.026958 L1: 0.016016 Grad: 0.109181 Thermal: 0.000480 LR: 2.45e-06\n",
      "Epoch  41 [5750/10697 ( 53.8%)] Loss: 0.023929 L1: 0.014112 Grad: 0.097973 Thermal: 0.000384 LR: 2.45e-06\n",
      "Epoch  41 [5750/10697 ( 53.8%)] Loss: 0.023929 L1: 0.014112 Grad: 0.097973 Thermal: 0.000384 LR: 2.45e-06\n",
      "Epoch  41 [5800/10697 ( 54.2%)] Loss: 0.024513 L1: 0.014176 Grad: 0.103165 Thermal: 0.000408 LR: 2.45e-06\n",
      "Epoch  41 [5800/10697 ( 54.2%)] Loss: 0.024513 L1: 0.014176 Grad: 0.103165 Thermal: 0.000408 LR: 2.45e-06\n",
      "Epoch  41 [5850/10697 ( 54.7%)] Loss: 0.029389 L1: 0.016762 Grad: 0.126019 Thermal: 0.000500 LR: 2.45e-06\n",
      "Epoch  41 [5850/10697 ( 54.7%)] Loss: 0.029389 L1: 0.016762 Grad: 0.126019 Thermal: 0.000500 LR: 2.45e-06\n",
      "Epoch  41 [5900/10697 ( 55.2%)] Loss: 0.027083 L1: 0.015436 Grad: 0.116230 Thermal: 0.000481 LR: 2.45e-06\n",
      "Epoch  41 [5900/10697 ( 55.2%)] Loss: 0.027083 L1: 0.015436 Grad: 0.116230 Thermal: 0.000481 LR: 2.45e-06\n",
      "Epoch  41 [5950/10697 ( 55.6%)] Loss: 0.024783 L1: 0.014525 Grad: 0.102391 Thermal: 0.000381 LR: 2.45e-06\n",
      "Epoch  41 [5950/10697 ( 55.6%)] Loss: 0.024783 L1: 0.014525 Grad: 0.102391 Thermal: 0.000381 LR: 2.45e-06\n",
      "Epoch  41 [6000/10697 ( 56.1%)] Loss: 0.026290 L1: 0.014839 Grad: 0.114230 Thermal: 0.000577 LR: 2.45e-06\n",
      "Epoch  41 [6000/10697 ( 56.1%)] Loss: 0.026290 L1: 0.014839 Grad: 0.114230 Thermal: 0.000577 LR: 2.45e-06\n",
      "Epoch  41 [6050/10697 ( 56.6%)] Loss: 0.025267 L1: 0.015064 Grad: 0.101833 Thermal: 0.000403 LR: 2.45e-06\n",
      "Epoch  41 [6050/10697 ( 56.6%)] Loss: 0.025267 L1: 0.015064 Grad: 0.101833 Thermal: 0.000403 LR: 2.45e-06\n",
      "Epoch  41 [6100/10697 ( 57.0%)] Loss: 0.024981 L1: 0.014472 Grad: 0.104886 Thermal: 0.000389 LR: 2.45e-06\n",
      "Epoch  41 [6100/10697 ( 57.0%)] Loss: 0.024981 L1: 0.014472 Grad: 0.104886 Thermal: 0.000389 LR: 2.45e-06\n",
      "Epoch  41 [6150/10697 ( 57.5%)] Loss: 0.028486 L1: 0.016925 Grad: 0.115349 Thermal: 0.000530 LR: 2.45e-06\n",
      "Epoch  41 [6150/10697 ( 57.5%)] Loss: 0.028486 L1: 0.016925 Grad: 0.115349 Thermal: 0.000530 LR: 2.45e-06\n",
      "Epoch  41 [6200/10697 ( 58.0%)] Loss: 0.028289 L1: 0.016657 Grad: 0.116042 Thermal: 0.000562 LR: 2.45e-06\n",
      "Epoch  41 [6200/10697 ( 58.0%)] Loss: 0.028289 L1: 0.016657 Grad: 0.116042 Thermal: 0.000562 LR: 2.45e-06\n",
      "Epoch  41 [6250/10697 ( 58.4%)] Loss: 0.026411 L1: 0.015755 Grad: 0.106324 Thermal: 0.000475 LR: 2.45e-06\n",
      "Epoch  41 [6250/10697 ( 58.4%)] Loss: 0.026411 L1: 0.015755 Grad: 0.106324 Thermal: 0.000475 LR: 2.45e-06\n",
      "Epoch  41 [6300/10697 ( 58.9%)] Loss: 0.026468 L1: 0.015858 Grad: 0.105865 Thermal: 0.000461 LR: 2.45e-06\n",
      "Epoch  41 [6300/10697 ( 58.9%)] Loss: 0.026468 L1: 0.015858 Grad: 0.105865 Thermal: 0.000461 LR: 2.45e-06\n",
      "Epoch  41 [6350/10697 ( 59.4%)] Loss: 0.025448 L1: 0.014496 Grad: 0.109308 Thermal: 0.000426 LR: 2.45e-06\n",
      "Epoch  41 [6350/10697 ( 59.4%)] Loss: 0.025448 L1: 0.014496 Grad: 0.109308 Thermal: 0.000426 LR: 2.45e-06\n",
      "Epoch  41 [6400/10697 ( 59.8%)] Loss: 0.024150 L1: 0.013987 Grad: 0.101432 Thermal: 0.000387 LR: 2.45e-06\n",
      "Epoch  41 [6400/10697 ( 59.8%)] Loss: 0.024150 L1: 0.013987 Grad: 0.101432 Thermal: 0.000387 LR: 2.45e-06\n",
      "Epoch  41 [6450/10697 ( 60.3%)] Loss: 0.026162 L1: 0.014636 Grad: 0.115029 Thermal: 0.000462 LR: 2.45e-06\n",
      "Epoch  41 [6450/10697 ( 60.3%)] Loss: 0.026162 L1: 0.014636 Grad: 0.115029 Thermal: 0.000462 LR: 2.45e-06\n",
      "Epoch  41 [6500/10697 ( 60.8%)] Loss: 0.027372 L1: 0.016145 Grad: 0.112041 Thermal: 0.000460 LR: 2.45e-06\n",
      "Epoch  41 [6500/10697 ( 60.8%)] Loss: 0.027372 L1: 0.016145 Grad: 0.112041 Thermal: 0.000460 LR: 2.45e-06\n",
      "Epoch  41 [6550/10697 ( 61.2%)] Loss: 0.022830 L1: 0.013556 Grad: 0.092563 Thermal: 0.000369 LR: 2.45e-06\n",
      "Epoch  41 [6550/10697 ( 61.2%)] Loss: 0.022830 L1: 0.013556 Grad: 0.092563 Thermal: 0.000369 LR: 2.45e-06\n",
      "Epoch  41 [6600/10697 ( 61.7%)] Loss: 0.026448 L1: 0.015106 Grad: 0.113197 Thermal: 0.000431 LR: 2.45e-06\n",
      "Epoch  41 [6600/10697 ( 61.7%)] Loss: 0.026448 L1: 0.015106 Grad: 0.113197 Thermal: 0.000431 LR: 2.45e-06\n",
      "Epoch  41 [6650/10697 ( 62.2%)] Loss: 0.027653 L1: 0.016210 Grad: 0.114189 Thermal: 0.000477 LR: 2.45e-06\n",
      "Epoch  41 [6650/10697 ( 62.2%)] Loss: 0.027653 L1: 0.016210 Grad: 0.114189 Thermal: 0.000477 LR: 2.45e-06\n",
      "Epoch  41 [6700/10697 ( 62.6%)] Loss: 0.024927 L1: 0.014427 Grad: 0.104793 Thermal: 0.000427 LR: 2.45e-06\n",
      "Epoch  41 [6700/10697 ( 62.6%)] Loss: 0.024927 L1: 0.014427 Grad: 0.104793 Thermal: 0.000427 LR: 2.45e-06\n",
      "Epoch  41 [6750/10697 ( 63.1%)] Loss: 0.028850 L1: 0.016461 Grad: 0.123523 Thermal: 0.000728 LR: 2.45e-06\n",
      "Epoch  41 [6750/10697 ( 63.1%)] Loss: 0.028850 L1: 0.016461 Grad: 0.123523 Thermal: 0.000728 LR: 2.45e-06\n",
      "Epoch  41 [6800/10697 ( 63.6%)] Loss: 0.028795 L1: 0.016507 Grad: 0.122608 Thermal: 0.000533 LR: 2.45e-06\n",
      "Epoch  41 [6800/10697 ( 63.6%)] Loss: 0.028795 L1: 0.016507 Grad: 0.122608 Thermal: 0.000533 LR: 2.45e-06\n",
      "Epoch  41 [6850/10697 ( 64.0%)] Loss: 0.021780 L1: 0.012748 Grad: 0.090165 Thermal: 0.000311 LR: 2.45e-06\n",
      "Epoch  41 [6850/10697 ( 64.0%)] Loss: 0.021780 L1: 0.012748 Grad: 0.090165 Thermal: 0.000311 LR: 2.45e-06\n",
      "Epoch  41 [6900/10697 ( 64.5%)] Loss: 0.023844 L1: 0.013846 Grad: 0.099799 Thermal: 0.000374 LR: 2.45e-06\n",
      "Epoch  41 [6900/10697 ( 64.5%)] Loss: 0.023844 L1: 0.013846 Grad: 0.099799 Thermal: 0.000374 LR: 2.45e-06\n",
      "Epoch  41 [6950/10697 ( 65.0%)] Loss: 0.026473 L1: 0.015254 Grad: 0.111985 Thermal: 0.000407 LR: 2.45e-06\n",
      "Epoch  41 [6950/10697 ( 65.0%)] Loss: 0.026473 L1: 0.015254 Grad: 0.111985 Thermal: 0.000407 LR: 2.45e-06\n",
      "Epoch  41 [7000/10697 ( 65.4%)] Loss: 0.034919 L1: 0.021074 Grad: 0.138023 Thermal: 0.000858 LR: 2.45e-06\n",
      "Epoch  41 [7000/10697 ( 65.4%)] Loss: 0.034919 L1: 0.021074 Grad: 0.138023 Thermal: 0.000858 LR: 2.45e-06\n",
      "Epoch  41 [7050/10697 ( 65.9%)] Loss: 0.026699 L1: 0.016145 Grad: 0.105308 Thermal: 0.000453 LR: 2.45e-06\n",
      "Epoch  41 [7050/10697 ( 65.9%)] Loss: 0.026699 L1: 0.016145 Grad: 0.105308 Thermal: 0.000453 LR: 2.45e-06\n",
      "Epoch  41 [7100/10697 ( 66.4%)] Loss: 0.026193 L1: 0.015086 Grad: 0.110863 Thermal: 0.000406 LR: 2.45e-06\n",
      "Epoch  41 [7100/10697 ( 66.4%)] Loss: 0.026193 L1: 0.015086 Grad: 0.110863 Thermal: 0.000406 LR: 2.45e-06\n",
      "Epoch  41 [7150/10697 ( 66.8%)] Loss: 0.025263 L1: 0.014695 Grad: 0.105480 Thermal: 0.000392 LR: 2.45e-06\n",
      "Epoch  41 [7150/10697 ( 66.8%)] Loss: 0.025263 L1: 0.014695 Grad: 0.105480 Thermal: 0.000392 LR: 2.45e-06\n",
      "Epoch  41 [7200/10697 ( 67.3%)] Loss: 0.026806 L1: 0.015535 Grad: 0.112495 Thermal: 0.000441 LR: 2.45e-06\n",
      "Epoch  41 [7200/10697 ( 67.3%)] Loss: 0.026806 L1: 0.015535 Grad: 0.112495 Thermal: 0.000441 LR: 2.45e-06\n",
      "Epoch  41 [7250/10697 ( 67.8%)] Loss: 0.024046 L1: 0.014257 Grad: 0.097673 Thermal: 0.000433 LR: 2.45e-06\n",
      "Epoch  41 [7250/10697 ( 67.8%)] Loss: 0.024046 L1: 0.014257 Grad: 0.097673 Thermal: 0.000433 LR: 2.45e-06\n",
      "Epoch  41 [7300/10697 ( 68.2%)] Loss: 0.028803 L1: 0.017254 Grad: 0.115229 Thermal: 0.000522 LR: 2.45e-06\n",
      "Epoch  41 [7300/10697 ( 68.2%)] Loss: 0.028803 L1: 0.017254 Grad: 0.115229 Thermal: 0.000522 LR: 2.45e-06\n",
      "Epoch  41 [7350/10697 ( 68.7%)] Loss: 0.031330 L1: 0.017485 Grad: 0.138168 Thermal: 0.000578 LR: 2.45e-06\n",
      "Epoch  41 [7350/10697 ( 68.7%)] Loss: 0.031330 L1: 0.017485 Grad: 0.138168 Thermal: 0.000578 LR: 2.45e-06\n",
      "Epoch  41 [7400/10697 ( 69.2%)] Loss: 0.024950 L1: 0.014531 Grad: 0.103988 Thermal: 0.000404 LR: 2.45e-06\n",
      "Epoch  41 [7400/10697 ( 69.2%)] Loss: 0.024950 L1: 0.014531 Grad: 0.103988 Thermal: 0.000404 LR: 2.45e-06\n",
      "Epoch  41 [7450/10697 ( 69.6%)] Loss: 0.025043 L1: 0.014529 Grad: 0.104942 Thermal: 0.000399 LR: 2.45e-06\n",
      "Epoch  41 [7450/10697 ( 69.6%)] Loss: 0.025043 L1: 0.014529 Grad: 0.104942 Thermal: 0.000399 LR: 2.45e-06\n",
      "Epoch  41 [7500/10697 ( 70.1%)] Loss: 0.031220 L1: 0.018250 Grad: 0.129381 Thermal: 0.000636 LR: 2.45e-06\n",
      "Epoch  41 [7500/10697 ( 70.1%)] Loss: 0.031220 L1: 0.018250 Grad: 0.129381 Thermal: 0.000636 LR: 2.45e-06\n",
      "Epoch  41 [7550/10697 ( 70.6%)] Loss: 0.024855 L1: 0.014649 Grad: 0.101860 Thermal: 0.000402 LR: 2.45e-06\n",
      "Epoch  41 [7550/10697 ( 70.6%)] Loss: 0.024855 L1: 0.014649 Grad: 0.101860 Thermal: 0.000402 LR: 2.45e-06\n",
      "Epoch  41 [7600/10697 ( 71.0%)] Loss: 0.028007 L1: 0.016268 Grad: 0.117144 Thermal: 0.000483 LR: 2.45e-06\n",
      "Epoch  41 [7600/10697 ( 71.0%)] Loss: 0.028007 L1: 0.016268 Grad: 0.117144 Thermal: 0.000483 LR: 2.45e-06\n",
      "Epoch  41 [7650/10697 ( 71.5%)] Loss: 0.026894 L1: 0.016119 Grad: 0.107516 Thermal: 0.000469 LR: 2.45e-06\n",
      "Epoch  41 [7650/10697 ( 71.5%)] Loss: 0.026894 L1: 0.016119 Grad: 0.107516 Thermal: 0.000469 LR: 2.45e-06\n",
      "Epoch  41 [7700/10697 ( 72.0%)] Loss: 0.019701 L1: 0.011319 Grad: 0.083674 Thermal: 0.000291 LR: 2.45e-06\n",
      "Epoch  41 [7700/10697 ( 72.0%)] Loss: 0.019701 L1: 0.011319 Grad: 0.083674 Thermal: 0.000291 LR: 2.45e-06\n",
      "Epoch  41 [7750/10697 ( 72.5%)] Loss: 0.030591 L1: 0.018161 Grad: 0.123997 Thermal: 0.000601 LR: 2.45e-06\n",
      "Epoch  41 [7750/10697 ( 72.5%)] Loss: 0.030591 L1: 0.018161 Grad: 0.123997 Thermal: 0.000601 LR: 2.45e-06\n",
      "Epoch  41 [7800/10697 ( 72.9%)] Loss: 0.025790 L1: 0.015493 Grad: 0.102756 Thermal: 0.000424 LR: 2.45e-06\n",
      "Epoch  41 [7800/10697 ( 72.9%)] Loss: 0.025790 L1: 0.015493 Grad: 0.102756 Thermal: 0.000424 LR: 2.45e-06\n",
      "Epoch  41 [7850/10697 ( 73.4%)] Loss: 0.022859 L1: 0.013598 Grad: 0.092432 Thermal: 0.000355 LR: 2.45e-06\n",
      "Epoch  41 [7850/10697 ( 73.4%)] Loss: 0.022859 L1: 0.013598 Grad: 0.092432 Thermal: 0.000355 LR: 2.45e-06\n",
      "Epoch  41 [7900/10697 ( 73.9%)] Loss: 0.025923 L1: 0.014801 Grad: 0.111001 Thermal: 0.000437 LR: 2.45e-06\n",
      "Epoch  41 [7900/10697 ( 73.9%)] Loss: 0.025923 L1: 0.014801 Grad: 0.111001 Thermal: 0.000437 LR: 2.45e-06\n",
      "Epoch  41 [7950/10697 ( 74.3%)] Loss: 0.030176 L1: 0.017550 Grad: 0.125995 Thermal: 0.000531 LR: 2.45e-06\n",
      "Epoch  41 [7950/10697 ( 74.3%)] Loss: 0.030176 L1: 0.017550 Grad: 0.125995 Thermal: 0.000531 LR: 2.45e-06\n",
      "Epoch  41 [8000/10697 ( 74.8%)] Loss: 0.023289 L1: 0.013778 Grad: 0.094939 Thermal: 0.000356 LR: 2.45e-06\n",
      "Epoch  41 [8000/10697 ( 74.8%)] Loss: 0.023289 L1: 0.013778 Grad: 0.094939 Thermal: 0.000356 LR: 2.45e-06\n",
      "Epoch  41 [8050/10697 ( 75.3%)] Loss: 0.022791 L1: 0.012977 Grad: 0.097982 Thermal: 0.000314 LR: 2.45e-06\n",
      "Epoch  41 [8050/10697 ( 75.3%)] Loss: 0.022791 L1: 0.012977 Grad: 0.097982 Thermal: 0.000314 LR: 2.45e-06\n",
      "Epoch  41 [8100/10697 ( 75.7%)] Loss: 0.026854 L1: 0.015897 Grad: 0.109281 Thermal: 0.000576 LR: 2.45e-06\n",
      "Epoch  41 [8100/10697 ( 75.7%)] Loss: 0.026854 L1: 0.015897 Grad: 0.109281 Thermal: 0.000576 LR: 2.45e-06\n",
      "Epoch  41 [8150/10697 ( 76.2%)] Loss: 0.027502 L1: 0.015975 Grad: 0.115023 Thermal: 0.000494 LR: 2.45e-06\n",
      "Epoch  41 [8150/10697 ( 76.2%)] Loss: 0.027502 L1: 0.015975 Grad: 0.115023 Thermal: 0.000494 LR: 2.45e-06\n",
      "Epoch  41 [8200/10697 ( 76.7%)] Loss: 0.026044 L1: 0.015031 Grad: 0.109908 Thermal: 0.000439 LR: 2.45e-06\n",
      "Epoch  41 [8200/10697 ( 76.7%)] Loss: 0.026044 L1: 0.015031 Grad: 0.109908 Thermal: 0.000439 LR: 2.45e-06\n",
      "Epoch  41 [8250/10697 ( 77.1%)] Loss: 0.031526 L1: 0.018791 Grad: 0.127030 Thermal: 0.000656 LR: 2.45e-06\n",
      "Epoch  41 [8250/10697 ( 77.1%)] Loss: 0.031526 L1: 0.018791 Grad: 0.127030 Thermal: 0.000656 LR: 2.45e-06\n",
      "Epoch  41 [8300/10697 ( 77.6%)] Loss: 0.025648 L1: 0.014875 Grad: 0.107513 Thermal: 0.000424 LR: 2.45e-06\n",
      "Epoch  41 [8300/10697 ( 77.6%)] Loss: 0.025648 L1: 0.014875 Grad: 0.107513 Thermal: 0.000424 LR: 2.45e-06\n",
      "Epoch  41 [8350/10697 ( 78.1%)] Loss: 0.025273 L1: 0.015069 Grad: 0.101821 Thermal: 0.000429 LR: 2.45e-06\n",
      "Epoch  41 [8350/10697 ( 78.1%)] Loss: 0.025273 L1: 0.015069 Grad: 0.101821 Thermal: 0.000429 LR: 2.45e-06\n",
      "Epoch  41 [8400/10697 ( 78.5%)] Loss: 0.023541 L1: 0.013944 Grad: 0.095788 Thermal: 0.000368 LR: 2.45e-06\n",
      "Epoch  41 [8400/10697 ( 78.5%)] Loss: 0.023541 L1: 0.013944 Grad: 0.095788 Thermal: 0.000368 LR: 2.45e-06\n",
      "Epoch  41 [8450/10697 ( 79.0%)] Loss: 0.026992 L1: 0.015462 Grad: 0.115060 Thermal: 0.000470 LR: 2.45e-06\n",
      "Epoch  41 [8450/10697 ( 79.0%)] Loss: 0.026992 L1: 0.015462 Grad: 0.115060 Thermal: 0.000470 LR: 2.45e-06\n",
      "Epoch  41 [8500/10697 ( 79.5%)] Loss: 0.025867 L1: 0.014726 Grad: 0.111226 Thermal: 0.000368 LR: 2.45e-06\n",
      "Epoch  41 [8500/10697 ( 79.5%)] Loss: 0.025867 L1: 0.014726 Grad: 0.111226 Thermal: 0.000368 LR: 2.45e-06\n",
      "Epoch  41 [8550/10697 ( 79.9%)] Loss: 0.025141 L1: 0.014587 Grad: 0.105326 Thermal: 0.000429 LR: 2.45e-06\n",
      "Epoch  41 [8550/10697 ( 79.9%)] Loss: 0.025141 L1: 0.014587 Grad: 0.105326 Thermal: 0.000429 LR: 2.45e-06\n",
      "Epoch  41 [8600/10697 ( 80.4%)] Loss: 0.026288 L1: 0.015471 Grad: 0.107954 Thermal: 0.000425 LR: 2.45e-06\n",
      "Epoch  41 [8600/10697 ( 80.4%)] Loss: 0.026288 L1: 0.015471 Grad: 0.107954 Thermal: 0.000425 LR: 2.45e-06\n",
      "Epoch  41 [8650/10697 ( 80.9%)] Loss: 0.022166 L1: 0.012709 Grad: 0.094417 Thermal: 0.000302 LR: 2.45e-06\n",
      "Epoch  41 [8650/10697 ( 80.9%)] Loss: 0.022166 L1: 0.012709 Grad: 0.094417 Thermal: 0.000302 LR: 2.45e-06\n",
      "Epoch  41 [8700/10697 ( 81.3%)] Loss: 0.024032 L1: 0.014017 Grad: 0.099955 Thermal: 0.000399 LR: 2.45e-06\n",
      "Epoch  41 [8700/10697 ( 81.3%)] Loss: 0.024032 L1: 0.014017 Grad: 0.099955 Thermal: 0.000399 LR: 2.45e-06\n",
      "Epoch  41 [8750/10697 ( 81.8%)] Loss: 0.025292 L1: 0.014687 Grad: 0.105829 Thermal: 0.000434 LR: 2.45e-06\n",
      "Epoch  41 [8750/10697 ( 81.8%)] Loss: 0.025292 L1: 0.014687 Grad: 0.105829 Thermal: 0.000434 LR: 2.45e-06\n",
      "Epoch  41 [8800/10697 ( 82.3%)] Loss: 0.028997 L1: 0.016885 Grad: 0.120857 Thermal: 0.000523 LR: 2.45e-06\n",
      "Epoch  41 [8800/10697 ( 82.3%)] Loss: 0.028997 L1: 0.016885 Grad: 0.120857 Thermal: 0.000523 LR: 2.45e-06\n",
      "Epoch  41 [8850/10697 ( 82.7%)] Loss: 0.028574 L1: 0.016811 Grad: 0.117372 Thermal: 0.000512 LR: 2.45e-06\n",
      "Epoch  41 [8850/10697 ( 82.7%)] Loss: 0.028574 L1: 0.016811 Grad: 0.117372 Thermal: 0.000512 LR: 2.45e-06\n",
      "Epoch  41 [8900/10697 ( 83.2%)] Loss: 0.025378 L1: 0.015196 Grad: 0.101611 Thermal: 0.000419 LR: 2.45e-06\n",
      "Epoch  41 [8900/10697 ( 83.2%)] Loss: 0.025378 L1: 0.015196 Grad: 0.101611 Thermal: 0.000419 LR: 2.45e-06\n",
      "Epoch  41 [8950/10697 ( 83.7%)] Loss: 0.029090 L1: 0.017309 Grad: 0.117542 Thermal: 0.000539 LR: 2.45e-06\n",
      "Epoch  41 [8950/10697 ( 83.7%)] Loss: 0.029090 L1: 0.017309 Grad: 0.117542 Thermal: 0.000539 LR: 2.45e-06\n",
      "Epoch  41 [9000/10697 ( 84.1%)] Loss: 0.024705 L1: 0.014434 Grad: 0.102467 Thermal: 0.000486 LR: 2.45e-06\n",
      "Epoch  41 [9000/10697 ( 84.1%)] Loss: 0.024705 L1: 0.014434 Grad: 0.102467 Thermal: 0.000486 LR: 2.45e-06\n",
      "Epoch  41 [9050/10697 ( 84.6%)] Loss: 0.026816 L1: 0.016014 Grad: 0.107794 Thermal: 0.000465 LR: 2.45e-06\n",
      "Epoch  41 [9050/10697 ( 84.6%)] Loss: 0.026816 L1: 0.016014 Grad: 0.107794 Thermal: 0.000465 LR: 2.45e-06\n",
      "Epoch  41 [9100/10697 ( 85.1%)] Loss: 0.029465 L1: 0.017479 Grad: 0.119605 Thermal: 0.000519 LR: 2.45e-06\n",
      "Epoch  41 [9100/10697 ( 85.1%)] Loss: 0.029465 L1: 0.017479 Grad: 0.119605 Thermal: 0.000519 LR: 2.45e-06\n",
      "Epoch  41 [9150/10697 ( 85.5%)] Loss: 0.023562 L1: 0.013583 Grad: 0.099579 Thermal: 0.000434 LR: 2.45e-06\n",
      "Epoch  41 [9150/10697 ( 85.5%)] Loss: 0.023562 L1: 0.013583 Grad: 0.099579 Thermal: 0.000434 LR: 2.45e-06\n",
      "Epoch  41 [9200/10697 ( 86.0%)] Loss: 0.022289 L1: 0.012809 Grad: 0.094626 Thermal: 0.000350 LR: 2.45e-06\n",
      "Epoch  41 [9200/10697 ( 86.0%)] Loss: 0.022289 L1: 0.012809 Grad: 0.094626 Thermal: 0.000350 LR: 2.45e-06\n",
      "Epoch  41 [9250/10697 ( 86.5%)] Loss: 0.026817 L1: 0.015954 Grad: 0.108398 Thermal: 0.000463 LR: 2.45e-06\n",
      "Epoch  41 [9250/10697 ( 86.5%)] Loss: 0.026817 L1: 0.015954 Grad: 0.108398 Thermal: 0.000463 LR: 2.45e-06\n",
      "Epoch  41 [9300/10697 ( 86.9%)] Loss: 0.026756 L1: 0.015537 Grad: 0.111957 Thermal: 0.000461 LR: 2.45e-06\n",
      "Epoch  41 [9300/10697 ( 86.9%)] Loss: 0.026756 L1: 0.015537 Grad: 0.111957 Thermal: 0.000461 LR: 2.45e-06\n",
      "Epoch  41 [9350/10697 ( 87.4%)] Loss: 0.028191 L1: 0.016268 Grad: 0.118995 Thermal: 0.000474 LR: 2.45e-06\n",
      "Epoch  41 [9350/10697 ( 87.4%)] Loss: 0.028191 L1: 0.016268 Grad: 0.118995 Thermal: 0.000474 LR: 2.45e-06\n",
      "Epoch  41 [9400/10697 ( 87.9%)] Loss: 0.026286 L1: 0.014958 Grad: 0.113065 Thermal: 0.000426 LR: 2.45e-06\n",
      "Epoch  41 [9400/10697 ( 87.9%)] Loss: 0.026286 L1: 0.014958 Grad: 0.113065 Thermal: 0.000426 LR: 2.45e-06\n",
      "Epoch  41 [9450/10697 ( 88.3%)] Loss: 0.029589 L1: 0.017834 Grad: 0.117267 Thermal: 0.000564 LR: 2.45e-06\n",
      "Epoch  41 [9450/10697 ( 88.3%)] Loss: 0.029589 L1: 0.017834 Grad: 0.117267 Thermal: 0.000564 LR: 2.45e-06\n",
      "Epoch  41 [9500/10697 ( 88.8%)] Loss: 0.031232 L1: 0.018284 Grad: 0.129171 Thermal: 0.000619 LR: 2.45e-06\n",
      "Epoch  41 [9500/10697 ( 88.8%)] Loss: 0.031232 L1: 0.018284 Grad: 0.129171 Thermal: 0.000619 LR: 2.45e-06\n",
      "Epoch  41 [9550/10697 ( 89.3%)] Loss: 0.022659 L1: 0.013010 Grad: 0.096315 Thermal: 0.000345 LR: 2.45e-06\n",
      "Epoch  41 [9550/10697 ( 89.3%)] Loss: 0.022659 L1: 0.013010 Grad: 0.096315 Thermal: 0.000345 LR: 2.45e-06\n",
      "Epoch  41 [9600/10697 ( 89.7%)] Loss: 0.024454 L1: 0.014035 Grad: 0.103982 Thermal: 0.000426 LR: 2.45e-06\n",
      "Epoch  41 [9600/10697 ( 89.7%)] Loss: 0.024454 L1: 0.014035 Grad: 0.103982 Thermal: 0.000426 LR: 2.45e-06\n",
      "Epoch  41 [9650/10697 ( 90.2%)] Loss: 0.029365 L1: 0.016813 Grad: 0.125258 Thermal: 0.000522 LR: 2.45e-06\n",
      "Epoch  41 [9650/10697 ( 90.2%)] Loss: 0.029365 L1: 0.016813 Grad: 0.125258 Thermal: 0.000522 LR: 2.45e-06\n",
      "Epoch  41 [9700/10697 ( 90.7%)] Loss: 0.024837 L1: 0.014795 Grad: 0.100216 Thermal: 0.000412 LR: 2.45e-06\n",
      "Epoch  41 [9700/10697 ( 90.7%)] Loss: 0.024837 L1: 0.014795 Grad: 0.100216 Thermal: 0.000412 LR: 2.45e-06\n",
      "Epoch  41 [9750/10697 ( 91.1%)] Loss: 0.022814 L1: 0.013161 Grad: 0.096332 Thermal: 0.000397 LR: 2.45e-06\n",
      "Epoch  41 [9750/10697 ( 91.1%)] Loss: 0.022814 L1: 0.013161 Grad: 0.096332 Thermal: 0.000397 LR: 2.45e-06\n",
      "Epoch  41 [9800/10697 ( 91.6%)] Loss: 0.022806 L1: 0.013209 Grad: 0.095757 Thermal: 0.000414 LR: 2.45e-06\n",
      "Epoch  41 [9800/10697 ( 91.6%)] Loss: 0.022806 L1: 0.013209 Grad: 0.095757 Thermal: 0.000414 LR: 2.45e-06\n",
      "Epoch  41 [9850/10697 ( 92.1%)] Loss: 0.027876 L1: 0.016569 Grad: 0.112815 Thermal: 0.000510 LR: 2.45e-06\n",
      "Epoch  41 [9850/10697 ( 92.1%)] Loss: 0.027876 L1: 0.016569 Grad: 0.112815 Thermal: 0.000510 LR: 2.45e-06\n",
      "Epoch  41 [9900/10697 ( 92.5%)] Loss: 0.024700 L1: 0.014315 Grad: 0.103640 Thermal: 0.000422 LR: 2.45e-06\n",
      "Epoch  41 [9900/10697 ( 92.5%)] Loss: 0.024700 L1: 0.014315 Grad: 0.103640 Thermal: 0.000422 LR: 2.45e-06\n",
      "Epoch  41 [9950/10697 ( 93.0%)] Loss: 0.029266 L1: 0.017498 Grad: 0.117419 Thermal: 0.000523 LR: 2.45e-06\n",
      "Epoch  41 [9950/10697 ( 93.0%)] Loss: 0.029266 L1: 0.017498 Grad: 0.117419 Thermal: 0.000523 LR: 2.45e-06\n",
      "Epoch  41 [10000/10697 ( 93.5%)] Loss: 0.022568 L1: 0.012925 Grad: 0.096276 Thermal: 0.000309 LR: 2.45e-06\n",
      "Epoch  41 [10000/10697 ( 93.5%)] Loss: 0.022568 L1: 0.012925 Grad: 0.096276 Thermal: 0.000309 LR: 2.45e-06\n",
      "Epoch  41 [10050/10697 ( 94.0%)] Loss: 0.030013 L1: 0.017328 Grad: 0.126570 Thermal: 0.000563 LR: 2.45e-06\n",
      "Epoch  41 [10050/10697 ( 94.0%)] Loss: 0.030013 L1: 0.017328 Grad: 0.126570 Thermal: 0.000563 LR: 2.45e-06\n",
      "Epoch  41 [10100/10697 ( 94.4%)] Loss: 0.026348 L1: 0.015059 Grad: 0.112678 Thermal: 0.000424 LR: 2.45e-06\n",
      "Epoch  41 [10100/10697 ( 94.4%)] Loss: 0.026348 L1: 0.015059 Grad: 0.112678 Thermal: 0.000424 LR: 2.45e-06\n",
      "Epoch  41 [10150/10697 ( 94.9%)] Loss: 0.025338 L1: 0.014891 Grad: 0.104243 Thermal: 0.000449 LR: 2.45e-06\n",
      "Epoch  41 [10150/10697 ( 94.9%)] Loss: 0.025338 L1: 0.014891 Grad: 0.104243 Thermal: 0.000449 LR: 2.45e-06\n",
      "Epoch  41 [10200/10697 ( 95.4%)] Loss: 0.027759 L1: 0.015735 Grad: 0.119981 Thermal: 0.000513 LR: 2.45e-06\n",
      "Epoch  41 [10200/10697 ( 95.4%)] Loss: 0.027759 L1: 0.015735 Grad: 0.119981 Thermal: 0.000513 LR: 2.45e-06\n",
      "Epoch  41 [10250/10697 ( 95.8%)] Loss: 0.029074 L1: 0.016896 Grad: 0.121509 Thermal: 0.000548 LR: 2.45e-06\n",
      "Epoch  41 [10250/10697 ( 95.8%)] Loss: 0.029074 L1: 0.016896 Grad: 0.121509 Thermal: 0.000548 LR: 2.45e-06\n",
      "Epoch  41 [10300/10697 ( 96.3%)] Loss: 0.029655 L1: 0.017467 Grad: 0.121593 Thermal: 0.000565 LR: 2.45e-06\n",
      "Epoch  41 [10300/10697 ( 96.3%)] Loss: 0.029655 L1: 0.017467 Grad: 0.121593 Thermal: 0.000565 LR: 2.45e-06\n",
      "Epoch  41 [10350/10697 ( 96.8%)] Loss: 0.022796 L1: 0.013351 Grad: 0.094277 Thermal: 0.000350 LR: 2.45e-06\n",
      "Epoch  41 [10350/10697 ( 96.8%)] Loss: 0.022796 L1: 0.013351 Grad: 0.094277 Thermal: 0.000350 LR: 2.45e-06\n",
      "Epoch  41 [10400/10697 ( 97.2%)] Loss: 0.026107 L1: 0.015209 Grad: 0.108758 Thermal: 0.000429 LR: 2.45e-06\n",
      "Epoch  41 [10400/10697 ( 97.2%)] Loss: 0.026107 L1: 0.015209 Grad: 0.108758 Thermal: 0.000429 LR: 2.45e-06\n",
      "Epoch  41 [10450/10697 ( 97.7%)] Loss: 0.021674 L1: 0.012685 Grad: 0.089719 Thermal: 0.000329 LR: 2.45e-06\n",
      "Epoch  41 [10450/10697 ( 97.7%)] Loss: 0.021674 L1: 0.012685 Grad: 0.089719 Thermal: 0.000329 LR: 2.45e-06\n",
      "Epoch  41 [10500/10697 ( 98.2%)] Loss: 0.029081 L1: 0.017025 Grad: 0.120294 Thermal: 0.000520 LR: 2.45e-06\n",
      "Epoch  41 [10500/10697 ( 98.2%)] Loss: 0.029081 L1: 0.017025 Grad: 0.120294 Thermal: 0.000520 LR: 2.45e-06\n",
      "Epoch  41 [10550/10697 ( 98.6%)] Loss: 0.030002 L1: 0.016935 Grad: 0.130359 Thermal: 0.000623 LR: 2.45e-06\n",
      "Epoch  41 [10550/10697 ( 98.6%)] Loss: 0.030002 L1: 0.016935 Grad: 0.130359 Thermal: 0.000623 LR: 2.45e-06\n",
      "Epoch  41 [10600/10697 ( 99.1%)] Loss: 0.024284 L1: 0.014348 Grad: 0.099165 Thermal: 0.000381 LR: 2.45e-06\n",
      "Epoch  41 [10600/10697 ( 99.1%)] Loss: 0.024284 L1: 0.014348 Grad: 0.099165 Thermal: 0.000381 LR: 2.45e-06\n",
      "Epoch  41 [10650/10697 ( 99.6%)] Loss: 0.027074 L1: 0.015758 Grad: 0.112916 Thermal: 0.000491 LR: 2.45e-06\n",
      "Epoch  41 [10650/10697 ( 99.6%)] Loss: 0.027074 L1: 0.015758 Grad: 0.112916 Thermal: 0.000491 LR: 2.45e-06\n",
      "Epoch  41 Summary: Loss=0.026235 (L1:0.0153, Grad:0.1091, Thermal:0.0005) Val_PSNR=0.00dB Best=33.97dB Time=168.5min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  41 Summary: Loss=0.026235 (L1:0.0153, Grad:0.1091, Thermal:0.0005) Val_PSNR=0.00dB Best=33.97dB Time=168.5min\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch  42 [   0/10697 (  0.0%)] Loss: 0.028056 L1: 0.016736 Grad: 0.112965 Thermal: 0.000472 LR: 2.35e-06\n",
      "Epoch  42 [   0/10697 (  0.0%)] Loss: 0.028056 L1: 0.016736 Grad: 0.112965 Thermal: 0.000472 LR: 2.35e-06\n",
      "Epoch  42 [  50/10697 (  0.5%)] Loss: 0.025630 L1: 0.015122 Grad: 0.104873 Thermal: 0.000408 LR: 2.35e-06\n",
      "Epoch  42 [  50/10697 (  0.5%)] Loss: 0.025630 L1: 0.015122 Grad: 0.104873 Thermal: 0.000408 LR: 2.35e-06\n",
      "Epoch  42 [ 100/10697 (  0.9%)] Loss: 0.020334 L1: 0.011768 Grad: 0.085497 Thermal: 0.000309 LR: 2.35e-06\n",
      "Epoch  42 [ 100/10697 (  0.9%)] Loss: 0.020334 L1: 0.011768 Grad: 0.085497 Thermal: 0.000309 LR: 2.35e-06\n",
      "Epoch  42 [ 150/10697 (  1.4%)] Loss: 0.021111 L1: 0.011931 Grad: 0.091634 Thermal: 0.000341 LR: 2.35e-06\n",
      "Epoch  42 [ 150/10697 (  1.4%)] Loss: 0.021111 L1: 0.011931 Grad: 0.091634 Thermal: 0.000341 LR: 2.35e-06\n",
      "Epoch  42 [ 200/10697 (  1.9%)] Loss: 0.026990 L1: 0.016134 Grad: 0.108332 Thermal: 0.000469 LR: 2.35e-06\n",
      "Epoch  42 [ 200/10697 (  1.9%)] Loss: 0.026990 L1: 0.016134 Grad: 0.108332 Thermal: 0.000469 LR: 2.35e-06\n",
      "Epoch  42 [ 250/10697 (  2.3%)] Loss: 0.027771 L1: 0.015999 Grad: 0.117483 Thermal: 0.000469 LR: 2.35e-06\n",
      "Epoch  42 [ 250/10697 (  2.3%)] Loss: 0.027771 L1: 0.015999 Grad: 0.117483 Thermal: 0.000469 LR: 2.35e-06\n",
      "Epoch  42 [ 300/10697 (  2.8%)] Loss: 0.021049 L1: 0.012407 Grad: 0.086262 Thermal: 0.000315 LR: 2.35e-06\n",
      "Epoch  42 [ 300/10697 (  2.8%)] Loss: 0.021049 L1: 0.012407 Grad: 0.086262 Thermal: 0.000315 LR: 2.35e-06\n",
      "Epoch  42 [ 350/10697 (  3.3%)] Loss: 0.022635 L1: 0.013033 Grad: 0.095856 Thermal: 0.000331 LR: 2.35e-06\n",
      "Epoch  42 [ 350/10697 (  3.3%)] Loss: 0.022635 L1: 0.013033 Grad: 0.095856 Thermal: 0.000331 LR: 2.35e-06\n",
      "Epoch  42 [ 400/10697 (  3.7%)] Loss: 0.019068 L1: 0.011017 Grad: 0.080388 Thermal: 0.000251 LR: 2.35e-06\n",
      "Epoch  42 [ 400/10697 (  3.7%)] Loss: 0.019068 L1: 0.011017 Grad: 0.080388 Thermal: 0.000251 LR: 2.35e-06\n",
      "Epoch  42 [ 450/10697 (  4.2%)] Loss: 0.023026 L1: 0.013213 Grad: 0.097952 Thermal: 0.000367 LR: 2.35e-06\n",
      "Epoch  42 [ 450/10697 (  4.2%)] Loss: 0.023026 L1: 0.013213 Grad: 0.097952 Thermal: 0.000367 LR: 2.35e-06\n",
      "Epoch  42 [ 500/10697 (  4.7%)] Loss: 0.023606 L1: 0.013699 Grad: 0.098889 Thermal: 0.000369 LR: 2.35e-06\n",
      "Epoch  42 [ 500/10697 (  4.7%)] Loss: 0.023606 L1: 0.013699 Grad: 0.098889 Thermal: 0.000369 LR: 2.35e-06\n",
      "Epoch  42 [ 550/10697 (  5.1%)] Loss: 0.018221 L1: 0.010480 Grad: 0.077297 Thermal: 0.000232 LR: 2.35e-06\n",
      "Epoch  42 [ 550/10697 (  5.1%)] Loss: 0.018221 L1: 0.010480 Grad: 0.077297 Thermal: 0.000232 LR: 2.35e-06\n",
      "Epoch  42 [ 600/10697 (  5.6%)] Loss: 0.025104 L1: 0.014614 Grad: 0.104715 Thermal: 0.000375 LR: 2.35e-06\n",
      "Epoch  42 [ 600/10697 (  5.6%)] Loss: 0.025104 L1: 0.014614 Grad: 0.104715 Thermal: 0.000375 LR: 2.35e-06\n",
      "Epoch  42 [ 650/10697 (  6.1%)] Loss: 0.024727 L1: 0.014416 Grad: 0.102923 Thermal: 0.000379 LR: 2.35e-06\n",
      "Epoch  42 [ 650/10697 (  6.1%)] Loss: 0.024727 L1: 0.014416 Grad: 0.102923 Thermal: 0.000379 LR: 2.35e-06\n",
      "Epoch  42 [ 700/10697 (  6.5%)] Loss: 0.025634 L1: 0.014775 Grad: 0.108393 Thermal: 0.000401 LR: 2.35e-06\n",
      "Epoch  42 [ 700/10697 (  6.5%)] Loss: 0.025634 L1: 0.014775 Grad: 0.108393 Thermal: 0.000401 LR: 2.35e-06\n",
      "Epoch  42 [ 750/10697 (  7.0%)] Loss: 0.029839 L1: 0.017664 Grad: 0.121446 Thermal: 0.000609 LR: 2.35e-06\n",
      "Epoch  42 [ 750/10697 (  7.0%)] Loss: 0.029839 L1: 0.017664 Grad: 0.121446 Thermal: 0.000609 LR: 2.35e-06\n",
      "Epoch  42 [ 800/10697 (  7.5%)] Loss: 0.028683 L1: 0.016733 Grad: 0.119241 Thermal: 0.000517 LR: 2.35e-06\n",
      "Epoch  42 [ 800/10697 (  7.5%)] Loss: 0.028683 L1: 0.016733 Grad: 0.119241 Thermal: 0.000517 LR: 2.35e-06\n",
      "Epoch  42 [ 850/10697 (  7.9%)] Loss: 0.027188 L1: 0.016058 Grad: 0.111065 Thermal: 0.000450 LR: 2.35e-06\n",
      "Epoch  42 [ 850/10697 (  7.9%)] Loss: 0.027188 L1: 0.016058 Grad: 0.111065 Thermal: 0.000450 LR: 2.35e-06\n",
      "Epoch  42 [ 900/10697 (  8.4%)] Loss: 0.029107 L1: 0.016961 Grad: 0.121202 Thermal: 0.000509 LR: 2.35e-06\n",
      "Epoch  42 [ 900/10697 (  8.4%)] Loss: 0.029107 L1: 0.016961 Grad: 0.121202 Thermal: 0.000509 LR: 2.35e-06\n",
      "Epoch  42 [ 950/10697 (  8.9%)] Loss: 0.023053 L1: 0.013611 Grad: 0.094247 Thermal: 0.000356 LR: 2.35e-06\n",
      "Epoch  42 [ 950/10697 (  8.9%)] Loss: 0.023053 L1: 0.013611 Grad: 0.094247 Thermal: 0.000356 LR: 2.35e-06\n",
      "Epoch  42 [1000/10697 (  9.3%)] Loss: 0.025937 L1: 0.015354 Grad: 0.105606 Thermal: 0.000434 LR: 2.35e-06\n",
      "Epoch  42 [1000/10697 (  9.3%)] Loss: 0.025937 L1: 0.015354 Grad: 0.105606 Thermal: 0.000434 LR: 2.35e-06\n",
      "Epoch  42 [1050/10697 (  9.8%)] Loss: 0.026357 L1: 0.014995 Grad: 0.113391 Thermal: 0.000454 LR: 2.35e-06\n",
      "Epoch  42 [1050/10697 (  9.8%)] Loss: 0.026357 L1: 0.014995 Grad: 0.113391 Thermal: 0.000454 LR: 2.35e-06\n",
      "Epoch  42 [1100/10697 ( 10.3%)] Loss: 0.030297 L1: 0.017406 Grad: 0.128628 Thermal: 0.000558 LR: 2.35e-06\n",
      "Epoch  42 [1100/10697 ( 10.3%)] Loss: 0.030297 L1: 0.017406 Grad: 0.128628 Thermal: 0.000558 LR: 2.35e-06\n",
      "Epoch  42 [1150/10697 ( 10.8%)] Loss: 0.022196 L1: 0.012715 Grad: 0.094655 Thermal: 0.000312 LR: 2.35e-06\n",
      "Epoch  42 [1150/10697 ( 10.8%)] Loss: 0.022196 L1: 0.012715 Grad: 0.094655 Thermal: 0.000312 LR: 2.35e-06\n",
      "Epoch  42 [1200/10697 ( 11.2%)] Loss: 0.025598 L1: 0.015128 Grad: 0.104478 Thermal: 0.000429 LR: 2.35e-06\n",
      "Epoch  42 [1200/10697 ( 11.2%)] Loss: 0.025598 L1: 0.015128 Grad: 0.104478 Thermal: 0.000429 LR: 2.35e-06\n",
      "Epoch  42 [1250/10697 ( 11.7%)] Loss: 0.024814 L1: 0.014357 Grad: 0.104374 Thermal: 0.000396 LR: 2.35e-06\n",
      "Epoch  42 [1250/10697 ( 11.7%)] Loss: 0.024814 L1: 0.014357 Grad: 0.104374 Thermal: 0.000396 LR: 2.35e-06\n",
      "Epoch  42 [1300/10697 ( 12.2%)] Loss: 0.024660 L1: 0.014686 Grad: 0.099554 Thermal: 0.000383 LR: 2.35e-06\n",
      "Epoch  42 [1300/10697 ( 12.2%)] Loss: 0.024660 L1: 0.014686 Grad: 0.099554 Thermal: 0.000383 LR: 2.35e-06\n",
      "Epoch  42 [1350/10697 ( 12.6%)] Loss: 0.021904 L1: 0.013029 Grad: 0.088576 Thermal: 0.000341 LR: 2.35e-06\n",
      "Epoch  42 [1350/10697 ( 12.6%)] Loss: 0.021904 L1: 0.013029 Grad: 0.088576 Thermal: 0.000341 LR: 2.35e-06\n",
      "Epoch  42 [1400/10697 ( 13.1%)] Loss: 0.022732 L1: 0.013159 Grad: 0.095531 Thermal: 0.000396 LR: 2.35e-06\n",
      "Epoch  42 [1400/10697 ( 13.1%)] Loss: 0.022732 L1: 0.013159 Grad: 0.095531 Thermal: 0.000396 LR: 2.35e-06\n",
      "Epoch  42 [1450/10697 ( 13.6%)] Loss: 0.029535 L1: 0.017197 Grad: 0.123071 Thermal: 0.000609 LR: 2.35e-06\n",
      "Epoch  42 [1450/10697 ( 13.6%)] Loss: 0.029535 L1: 0.017197 Grad: 0.123071 Thermal: 0.000609 LR: 2.35e-06\n",
      "Epoch  42 [1500/10697 ( 14.0%)] Loss: 0.020475 L1: 0.011951 Grad: 0.085086 Thermal: 0.000305 LR: 2.35e-06\n",
      "Epoch  42 [1500/10697 ( 14.0%)] Loss: 0.020475 L1: 0.011951 Grad: 0.085086 Thermal: 0.000305 LR: 2.35e-06\n",
      "Epoch  42 [1550/10697 ( 14.5%)] Loss: 0.024859 L1: 0.014533 Grad: 0.103067 Thermal: 0.000396 LR: 2.35e-06\n",
      "Epoch  42 [1550/10697 ( 14.5%)] Loss: 0.024859 L1: 0.014533 Grad: 0.103067 Thermal: 0.000396 LR: 2.35e-06\n",
      "Epoch  42 [1600/10697 ( 15.0%)] Loss: 0.028917 L1: 0.017013 Grad: 0.118779 Thermal: 0.000528 LR: 2.35e-06\n",
      "Epoch  42 [1600/10697 ( 15.0%)] Loss: 0.028917 L1: 0.017013 Grad: 0.118779 Thermal: 0.000528 LR: 2.35e-06\n",
      "Epoch  42 [1650/10697 ( 15.4%)] Loss: 0.027522 L1: 0.016034 Grad: 0.114593 Thermal: 0.000584 LR: 2.35e-06\n",
      "Epoch  42 [1650/10697 ( 15.4%)] Loss: 0.027522 L1: 0.016034 Grad: 0.114593 Thermal: 0.000584 LR: 2.35e-06\n",
      "Epoch  42 [1700/10697 ( 15.9%)] Loss: 0.027596 L1: 0.016461 Grad: 0.111110 Thermal: 0.000481 LR: 2.35e-06\n",
      "Epoch  42 [1700/10697 ( 15.9%)] Loss: 0.027596 L1: 0.016461 Grad: 0.111110 Thermal: 0.000481 LR: 2.35e-06\n",
      "Epoch  42 [1750/10697 ( 16.4%)] Loss: 0.031463 L1: 0.017862 Grad: 0.135656 Thermal: 0.000713 LR: 2.35e-06\n",
      "Epoch  42 [1750/10697 ( 16.4%)] Loss: 0.031463 L1: 0.017862 Grad: 0.135656 Thermal: 0.000713 LR: 2.35e-06\n",
      "Epoch  42 [1800/10697 ( 16.8%)] Loss: 0.018203 L1: 0.010702 Grad: 0.074880 Thermal: 0.000251 LR: 2.35e-06\n",
      "Epoch  42 [1800/10697 ( 16.8%)] Loss: 0.018203 L1: 0.010702 Grad: 0.074880 Thermal: 0.000251 LR: 2.35e-06\n",
      "Epoch  42 [1850/10697 ( 17.3%)] Loss: 0.028615 L1: 0.015909 Grad: 0.126752 Thermal: 0.000616 LR: 2.35e-06\n",
      "Epoch  42 [1850/10697 ( 17.3%)] Loss: 0.028615 L1: 0.015909 Grad: 0.126752 Thermal: 0.000616 LR: 2.35e-06\n",
      "Epoch  42 [1900/10697 ( 17.8%)] Loss: 0.023213 L1: 0.013511 Grad: 0.096844 Thermal: 0.000348 LR: 2.35e-06\n",
      "Epoch  42 [1900/10697 ( 17.8%)] Loss: 0.023213 L1: 0.013511 Grad: 0.096844 Thermal: 0.000348 LR: 2.35e-06\n",
      "Epoch  42 [1950/10697 ( 18.2%)] Loss: 0.022458 L1: 0.012748 Grad: 0.096929 Thermal: 0.000328 LR: 2.35e-06\n",
      "Epoch  42 [1950/10697 ( 18.2%)] Loss: 0.022458 L1: 0.012748 Grad: 0.096929 Thermal: 0.000328 LR: 2.35e-06\n",
      "Epoch  42 [2000/10697 ( 18.7%)] Loss: 0.031782 L1: 0.018636 Grad: 0.131156 Thermal: 0.000613 LR: 2.35e-06\n",
      "Epoch  42 [2000/10697 ( 18.7%)] Loss: 0.031782 L1: 0.018636 Grad: 0.131156 Thermal: 0.000613 LR: 2.35e-06\n",
      "Epoch  42 [2050/10697 ( 19.2%)] Loss: 0.028594 L1: 0.017127 Grad: 0.114410 Thermal: 0.000526 LR: 2.35e-06\n",
      "Epoch  42 [2050/10697 ( 19.2%)] Loss: 0.028594 L1: 0.017127 Grad: 0.114410 Thermal: 0.000526 LR: 2.35e-06\n",
      "Epoch  42 [2100/10697 ( 19.6%)] Loss: 0.019654 L1: 0.011128 Grad: 0.085116 Thermal: 0.000294 LR: 2.35e-06\n",
      "Epoch  42 [2100/10697 ( 19.6%)] Loss: 0.019654 L1: 0.011128 Grad: 0.085116 Thermal: 0.000294 LR: 2.35e-06\n",
      "Epoch  42 [2150/10697 ( 20.1%)] Loss: 0.028443 L1: 0.015940 Grad: 0.124755 Thermal: 0.000537 LR: 2.35e-06\n",
      "Epoch  42 [2150/10697 ( 20.1%)] Loss: 0.028443 L1: 0.015940 Grad: 0.124755 Thermal: 0.000537 LR: 2.35e-06\n",
      "Epoch  42 [2200/10697 ( 20.6%)] Loss: 0.025105 L1: 0.014436 Grad: 0.106480 Thermal: 0.000419 LR: 2.35e-06\n",
      "Epoch  42 [2200/10697 ( 20.6%)] Loss: 0.025105 L1: 0.014436 Grad: 0.106480 Thermal: 0.000419 LR: 2.35e-06\n",
      "Epoch  42 [2250/10697 ( 21.0%)] Loss: 0.036849 L1: 0.020913 Grad: 0.158918 Thermal: 0.000878 LR: 2.35e-06\n",
      "Epoch  42 [2250/10697 ( 21.0%)] Loss: 0.036849 L1: 0.020913 Grad: 0.158918 Thermal: 0.000878 LR: 2.35e-06\n",
      "Epoch  42 [2300/10697 ( 21.5%)] Loss: 0.028060 L1: 0.016500 Grad: 0.115363 Thermal: 0.000474 LR: 2.35e-06\n",
      "Epoch  42 [2300/10697 ( 21.5%)] Loss: 0.028060 L1: 0.016500 Grad: 0.115363 Thermal: 0.000474 LR: 2.35e-06\n",
      "Epoch  42 [2350/10697 ( 22.0%)] Loss: 0.025101 L1: 0.014705 Grad: 0.103767 Thermal: 0.000398 LR: 2.35e-06\n",
      "Epoch  42 [2350/10697 ( 22.0%)] Loss: 0.025101 L1: 0.014705 Grad: 0.103767 Thermal: 0.000398 LR: 2.35e-06\n",
      "Epoch  42 [2400/10697 ( 22.4%)] Loss: 0.028707 L1: 0.016666 Grad: 0.120162 Thermal: 0.000494 LR: 2.35e-06\n",
      "Epoch  42 [2400/10697 ( 22.4%)] Loss: 0.028707 L1: 0.016666 Grad: 0.120162 Thermal: 0.000494 LR: 2.35e-06\n",
      "Epoch  42 [2450/10697 ( 22.9%)] Loss: 0.026895 L1: 0.015625 Grad: 0.112484 Thermal: 0.000424 LR: 2.35e-06\n",
      "Epoch  42 [2450/10697 ( 22.9%)] Loss: 0.026895 L1: 0.015625 Grad: 0.112484 Thermal: 0.000424 LR: 2.35e-06\n",
      "Epoch  42 [2500/10697 ( 23.4%)] Loss: 0.028009 L1: 0.016717 Grad: 0.112682 Thermal: 0.000481 LR: 2.35e-06\n",
      "Epoch  42 [2500/10697 ( 23.4%)] Loss: 0.028009 L1: 0.016717 Grad: 0.112682 Thermal: 0.000481 LR: 2.35e-06\n",
      "Epoch  42 [2550/10697 ( 23.8%)] Loss: 0.024349 L1: 0.014150 Grad: 0.101788 Thermal: 0.000401 LR: 2.35e-06\n",
      "Epoch  42 [2550/10697 ( 23.8%)] Loss: 0.024349 L1: 0.014150 Grad: 0.101788 Thermal: 0.000401 LR: 2.35e-06\n",
      "Epoch  42 [2600/10697 ( 24.3%)] Loss: 0.026534 L1: 0.015995 Grad: 0.105162 Thermal: 0.000468 LR: 2.35e-06\n",
      "Epoch  42 [2600/10697 ( 24.3%)] Loss: 0.026534 L1: 0.015995 Grad: 0.105162 Thermal: 0.000468 LR: 2.35e-06\n",
      "Epoch  42 [2650/10697 ( 24.8%)] Loss: 0.022008 L1: 0.012684 Grad: 0.093055 Thermal: 0.000381 LR: 2.35e-06\n",
      "Epoch  42 [2650/10697 ( 24.8%)] Loss: 0.022008 L1: 0.012684 Grad: 0.093055 Thermal: 0.000381 LR: 2.35e-06\n",
      "Epoch  42 [2700/10697 ( 25.2%)] Loss: 0.022811 L1: 0.013728 Grad: 0.090652 Thermal: 0.000371 LR: 2.35e-06\n",
      "Epoch  42 [2700/10697 ( 25.2%)] Loss: 0.022811 L1: 0.013728 Grad: 0.090652 Thermal: 0.000371 LR: 2.35e-06\n",
      "Epoch  42 [2750/10697 ( 25.7%)] Loss: 0.026205 L1: 0.015170 Grad: 0.110133 Thermal: 0.000430 LR: 2.35e-06\n",
      "Epoch  42 [2750/10697 ( 25.7%)] Loss: 0.026205 L1: 0.015170 Grad: 0.110133 Thermal: 0.000430 LR: 2.35e-06\n",
      "Epoch  42 [2800/10697 ( 26.2%)] Loss: 0.025171 L1: 0.014574 Grad: 0.105772 Thermal: 0.000405 LR: 2.35e-06\n",
      "Epoch  42 [2800/10697 ( 26.2%)] Loss: 0.025171 L1: 0.014574 Grad: 0.105772 Thermal: 0.000405 LR: 2.35e-06\n",
      "Epoch  42 [2850/10697 ( 26.6%)] Loss: 0.026793 L1: 0.015722 Grad: 0.110502 Thermal: 0.000430 LR: 2.35e-06\n",
      "Epoch  42 [2850/10697 ( 26.6%)] Loss: 0.026793 L1: 0.015722 Grad: 0.110502 Thermal: 0.000430 LR: 2.35e-06\n",
      "Epoch  42 [2900/10697 ( 27.1%)] Loss: 0.028367 L1: 0.016636 Grad: 0.117046 Thermal: 0.000527 LR: 2.35e-06\n",
      "Epoch  42 [2900/10697 ( 27.1%)] Loss: 0.028367 L1: 0.016636 Grad: 0.117046 Thermal: 0.000527 LR: 2.35e-06\n",
      "Epoch  42 [2950/10697 ( 27.6%)] Loss: 0.023099 L1: 0.013305 Grad: 0.097750 Thermal: 0.000375 LR: 2.35e-06\n",
      "Epoch  42 [2950/10697 ( 27.6%)] Loss: 0.023099 L1: 0.013305 Grad: 0.097750 Thermal: 0.000375 LR: 2.35e-06\n",
      "Epoch  42 [3000/10697 ( 28.0%)] Loss: 0.027355 L1: 0.016373 Grad: 0.109580 Thermal: 0.000476 LR: 2.35e-06\n",
      "Epoch  42 [3000/10697 ( 28.0%)] Loss: 0.027355 L1: 0.016373 Grad: 0.109580 Thermal: 0.000476 LR: 2.35e-06\n",
      "Epoch  42 [3050/10697 ( 28.5%)] Loss: 0.026512 L1: 0.015363 Grad: 0.111277 Thermal: 0.000435 LR: 2.35e-06\n",
      "Epoch  42 [3050/10697 ( 28.5%)] Loss: 0.026512 L1: 0.015363 Grad: 0.111277 Thermal: 0.000435 LR: 2.35e-06\n",
      "Epoch  42 [3100/10697 ( 29.0%)] Loss: 0.031316 L1: 0.018458 Grad: 0.128257 Thermal: 0.000643 LR: 2.35e-06\n",
      "Epoch  42 [3100/10697 ( 29.0%)] Loss: 0.031316 L1: 0.018458 Grad: 0.128257 Thermal: 0.000643 LR: 2.35e-06\n",
      "Epoch  42 [3150/10697 ( 29.4%)] Loss: 0.026924 L1: 0.015096 Grad: 0.118036 Thermal: 0.000478 LR: 2.35e-06\n",
      "Epoch  42 [3150/10697 ( 29.4%)] Loss: 0.026924 L1: 0.015096 Grad: 0.118036 Thermal: 0.000478 LR: 2.35e-06\n",
      "Epoch  42 [3200/10697 ( 29.9%)] Loss: 0.019289 L1: 0.010898 Grad: 0.083790 Thermal: 0.000231 LR: 2.35e-06\n",
      "Epoch  42 [3200/10697 ( 29.9%)] Loss: 0.019289 L1: 0.010898 Grad: 0.083790 Thermal: 0.000231 LR: 2.35e-06\n",
      "Epoch  42 [3250/10697 ( 30.4%)] Loss: 0.026396 L1: 0.015072 Grad: 0.112985 Thermal: 0.000499 LR: 2.35e-06\n",
      "Epoch  42 [3250/10697 ( 30.4%)] Loss: 0.026396 L1: 0.015072 Grad: 0.112985 Thermal: 0.000499 LR: 2.35e-06\n",
      "Epoch  42 [3300/10697 ( 30.8%)] Loss: 0.021461 L1: 0.012578 Grad: 0.088678 Thermal: 0.000297 LR: 2.35e-06\n",
      "Epoch  42 [3300/10697 ( 30.8%)] Loss: 0.021461 L1: 0.012578 Grad: 0.088678 Thermal: 0.000297 LR: 2.35e-06\n",
      "Epoch  42 [3350/10697 ( 31.3%)] Loss: 0.025522 L1: 0.015067 Grad: 0.104359 Thermal: 0.000399 LR: 2.35e-06\n",
      "Epoch  42 [3350/10697 ( 31.3%)] Loss: 0.025522 L1: 0.015067 Grad: 0.104359 Thermal: 0.000399 LR: 2.35e-06\n",
      "Epoch  42 [3400/10697 ( 31.8%)] Loss: 0.029245 L1: 0.016952 Grad: 0.122678 Thermal: 0.000511 LR: 2.35e-06\n",
      "Epoch  42 [3400/10697 ( 31.8%)] Loss: 0.029245 L1: 0.016952 Grad: 0.122678 Thermal: 0.000511 LR: 2.35e-06\n",
      "Epoch  42 [3450/10697 ( 32.3%)] Loss: 0.029985 L1: 0.017890 Grad: 0.120673 Thermal: 0.000542 LR: 2.35e-06\n",
      "Epoch  42 [3450/10697 ( 32.3%)] Loss: 0.029985 L1: 0.017890 Grad: 0.120673 Thermal: 0.000542 LR: 2.35e-06\n",
      "Epoch  42 [3500/10697 ( 32.7%)] Loss: 0.031025 L1: 0.017854 Grad: 0.131424 Thermal: 0.000579 LR: 2.35e-06\n",
      "Epoch  42 [3500/10697 ( 32.7%)] Loss: 0.031025 L1: 0.017854 Grad: 0.131424 Thermal: 0.000579 LR: 2.35e-06\n",
      "Epoch  42 [3550/10697 ( 33.2%)] Loss: 0.024183 L1: 0.014080 Grad: 0.100834 Thermal: 0.000384 LR: 2.35e-06\n",
      "Epoch  42 [3550/10697 ( 33.2%)] Loss: 0.024183 L1: 0.014080 Grad: 0.100834 Thermal: 0.000384 LR: 2.35e-06\n",
      "Epoch  42 [3600/10697 ( 33.7%)] Loss: 0.026203 L1: 0.014660 Grad: 0.115226 Thermal: 0.000408 LR: 2.35e-06\n",
      "Epoch  42 [3600/10697 ( 33.7%)] Loss: 0.026203 L1: 0.014660 Grad: 0.115226 Thermal: 0.000408 LR: 2.35e-06\n",
      "Epoch  42 [3650/10697 ( 34.1%)] Loss: 0.023635 L1: 0.013462 Grad: 0.101553 Thermal: 0.000352 LR: 2.35e-06\n",
      "Epoch  42 [3650/10697 ( 34.1%)] Loss: 0.023635 L1: 0.013462 Grad: 0.101553 Thermal: 0.000352 LR: 2.35e-06\n",
      "Epoch  42 [3700/10697 ( 34.6%)] Loss: 0.026703 L1: 0.014948 Grad: 0.117343 Thermal: 0.000421 LR: 2.35e-06\n",
      "Epoch  42 [3700/10697 ( 34.6%)] Loss: 0.026703 L1: 0.014948 Grad: 0.117343 Thermal: 0.000421 LR: 2.35e-06\n",
      "Epoch  42 [3750/10697 ( 35.1%)] Loss: 0.028308 L1: 0.016639 Grad: 0.116439 Thermal: 0.000485 LR: 2.35e-06\n",
      "Epoch  42 [3750/10697 ( 35.1%)] Loss: 0.028308 L1: 0.016639 Grad: 0.116439 Thermal: 0.000485 LR: 2.35e-06\n",
      "Epoch  42 [3800/10697 ( 35.5%)] Loss: 0.021765 L1: 0.013053 Grad: 0.086951 Thermal: 0.000338 LR: 2.35e-06\n",
      "Epoch  42 [3800/10697 ( 35.5%)] Loss: 0.021765 L1: 0.013053 Grad: 0.086951 Thermal: 0.000338 LR: 2.35e-06\n",
      "Epoch  42 [3850/10697 ( 36.0%)] Loss: 0.027293 L1: 0.016355 Grad: 0.109124 Thermal: 0.000505 LR: 2.35e-06\n",
      "Epoch  42 [3850/10697 ( 36.0%)] Loss: 0.027293 L1: 0.016355 Grad: 0.109124 Thermal: 0.000505 LR: 2.35e-06\n",
      "Epoch  42 [3900/10697 ( 36.5%)] Loss: 0.026839 L1: 0.015828 Grad: 0.109858 Thermal: 0.000489 LR: 2.35e-06\n",
      "Epoch  42 [3900/10697 ( 36.5%)] Loss: 0.026839 L1: 0.015828 Grad: 0.109858 Thermal: 0.000489 LR: 2.35e-06\n",
      "Epoch  42 [3950/10697 ( 36.9%)] Loss: 0.025644 L1: 0.014913 Grad: 0.107096 Thermal: 0.000422 LR: 2.35e-06\n",
      "Epoch  42 [3950/10697 ( 36.9%)] Loss: 0.025644 L1: 0.014913 Grad: 0.107096 Thermal: 0.000422 LR: 2.35e-06\n",
      "Epoch  42 [4000/10697 ( 37.4%)] Loss: 0.025014 L1: 0.014518 Grad: 0.104762 Thermal: 0.000410 LR: 2.35e-06\n",
      "Epoch  42 [4000/10697 ( 37.4%)] Loss: 0.025014 L1: 0.014518 Grad: 0.104762 Thermal: 0.000410 LR: 2.35e-06\n",
      "Epoch  42 [4050/10697 ( 37.9%)] Loss: 0.030045 L1: 0.017644 Grad: 0.123707 Thermal: 0.000597 LR: 2.35e-06\n",
      "Epoch  42 [4050/10697 ( 37.9%)] Loss: 0.030045 L1: 0.017644 Grad: 0.123707 Thermal: 0.000597 LR: 2.35e-06\n",
      "Epoch  42 [4100/10697 ( 38.3%)] Loss: 0.035828 L1: 0.020728 Grad: 0.150603 Thermal: 0.000807 LR: 2.35e-06\n",
      "Epoch  42 [4100/10697 ( 38.3%)] Loss: 0.035828 L1: 0.020728 Grad: 0.150603 Thermal: 0.000807 LR: 2.35e-06\n",
      "Epoch  42 [4150/10697 ( 38.8%)] Loss: 0.023358 L1: 0.013770 Grad: 0.095706 Thermal: 0.000353 LR: 2.35e-06\n",
      "Epoch  42 [4150/10697 ( 38.8%)] Loss: 0.023358 L1: 0.013770 Grad: 0.095706 Thermal: 0.000353 LR: 2.35e-06\n",
      "Epoch  42 [4200/10697 ( 39.3%)] Loss: 0.016116 L1: 0.009254 Grad: 0.068517 Thermal: 0.000204 LR: 2.35e-06\n",
      "Epoch  42 [4200/10697 ( 39.3%)] Loss: 0.016116 L1: 0.009254 Grad: 0.068517 Thermal: 0.000204 LR: 2.35e-06\n",
      "Epoch  42 [4250/10697 ( 39.7%)] Loss: 0.024617 L1: 0.014612 Grad: 0.099842 Thermal: 0.000401 LR: 2.35e-06\n",
      "Epoch  42 [4250/10697 ( 39.7%)] Loss: 0.024617 L1: 0.014612 Grad: 0.099842 Thermal: 0.000401 LR: 2.35e-06\n",
      "Epoch  42 [4300/10697 ( 40.2%)] Loss: 0.026649 L1: 0.015572 Grad: 0.110516 Thermal: 0.000515 LR: 2.35e-06\n",
      "Epoch  42 [4300/10697 ( 40.2%)] Loss: 0.026649 L1: 0.015572 Grad: 0.110516 Thermal: 0.000515 LR: 2.35e-06\n",
      "Epoch  42 [4350/10697 ( 40.7%)] Loss: 0.027451 L1: 0.015964 Grad: 0.114635 Thermal: 0.000455 LR: 2.35e-06\n",
      "Epoch  42 [4350/10697 ( 40.7%)] Loss: 0.027451 L1: 0.015964 Grad: 0.114635 Thermal: 0.000455 LR: 2.35e-06\n",
      "Epoch  42 [4400/10697 ( 41.1%)] Loss: 0.024530 L1: 0.014640 Grad: 0.098713 Thermal: 0.000382 LR: 2.35e-06\n",
      "Epoch  42 [4400/10697 ( 41.1%)] Loss: 0.024530 L1: 0.014640 Grad: 0.098713 Thermal: 0.000382 LR: 2.35e-06\n",
      "Epoch  42 [4450/10697 ( 41.6%)] Loss: 0.025031 L1: 0.014485 Grad: 0.105260 Thermal: 0.000401 LR: 2.35e-06\n",
      "Epoch  42 [4450/10697 ( 41.6%)] Loss: 0.025031 L1: 0.014485 Grad: 0.105260 Thermal: 0.000401 LR: 2.35e-06\n",
      "Epoch  42 [4500/10697 ( 42.1%)] Loss: 0.027041 L1: 0.015900 Grad: 0.111165 Thermal: 0.000488 LR: 2.35e-06\n",
      "Epoch  42 [4500/10697 ( 42.1%)] Loss: 0.027041 L1: 0.015900 Grad: 0.111165 Thermal: 0.000488 LR: 2.35e-06\n",
      "Epoch  42 [4550/10697 ( 42.5%)] Loss: 0.033191 L1: 0.019396 Grad: 0.137619 Thermal: 0.000667 LR: 2.35e-06\n",
      "Epoch  42 [4550/10697 ( 42.5%)] Loss: 0.033191 L1: 0.019396 Grad: 0.137619 Thermal: 0.000667 LR: 2.35e-06\n",
      "Epoch  42 [4600/10697 ( 43.0%)] Loss: 0.024500 L1: 0.014089 Grad: 0.103916 Thermal: 0.000389 LR: 2.35e-06\n",
      "Epoch  42 [4600/10697 ( 43.0%)] Loss: 0.024500 L1: 0.014089 Grad: 0.103916 Thermal: 0.000389 LR: 2.35e-06\n",
      "Epoch  42 [4650/10697 ( 43.5%)] Loss: 0.028158 L1: 0.016459 Grad: 0.116725 Thermal: 0.000511 LR: 2.35e-06\n",
      "Epoch  42 [4650/10697 ( 43.5%)] Loss: 0.028158 L1: 0.016459 Grad: 0.116725 Thermal: 0.000511 LR: 2.35e-06\n",
      "Epoch  42 [4700/10697 ( 43.9%)] Loss: 0.027572 L1: 0.015836 Grad: 0.117104 Thermal: 0.000515 LR: 2.35e-06\n",
      "Epoch  42 [4700/10697 ( 43.9%)] Loss: 0.027572 L1: 0.015836 Grad: 0.117104 Thermal: 0.000515 LR: 2.35e-06\n",
      "Epoch  42 [4750/10697 ( 44.4%)] Loss: 0.022057 L1: 0.012639 Grad: 0.094022 Thermal: 0.000325 LR: 2.35e-06\n",
      "Epoch  42 [4750/10697 ( 44.4%)] Loss: 0.022057 L1: 0.012639 Grad: 0.094022 Thermal: 0.000325 LR: 2.35e-06\n",
      "Epoch  42 [4800/10697 ( 44.9%)] Loss: 0.020591 L1: 0.011769 Grad: 0.088051 Thermal: 0.000335 LR: 2.35e-06\n",
      "Epoch  42 [4800/10697 ( 44.9%)] Loss: 0.020591 L1: 0.011769 Grad: 0.088051 Thermal: 0.000335 LR: 2.35e-06\n",
      "Epoch  42 [4850/10697 ( 45.3%)] Loss: 0.027555 L1: 0.016019 Grad: 0.115134 Thermal: 0.000448 LR: 2.35e-06\n",
      "Epoch  42 [4850/10697 ( 45.3%)] Loss: 0.027555 L1: 0.016019 Grad: 0.115134 Thermal: 0.000448 LR: 2.35e-06\n",
      "Epoch  42 [4900/10697 ( 45.8%)] Loss: 0.023081 L1: 0.013407 Grad: 0.096559 Thermal: 0.000357 LR: 2.35e-06\n",
      "Epoch  42 [4900/10697 ( 45.8%)] Loss: 0.023081 L1: 0.013407 Grad: 0.096559 Thermal: 0.000357 LR: 2.35e-06\n",
      "Epoch  42 [4950/10697 ( 46.3%)] Loss: 0.024073 L1: 0.014176 Grad: 0.098780 Thermal: 0.000375 LR: 2.35e-06\n",
      "Epoch  42 [4950/10697 ( 46.3%)] Loss: 0.024073 L1: 0.014176 Grad: 0.098780 Thermal: 0.000375 LR: 2.35e-06\n",
      "Epoch  42 [5000/10697 ( 46.7%)] Loss: 0.026701 L1: 0.015603 Grad: 0.110747 Thermal: 0.000461 LR: 2.35e-06\n",
      "Epoch  42 [5000/10697 ( 46.7%)] Loss: 0.026701 L1: 0.015603 Grad: 0.110747 Thermal: 0.000461 LR: 2.35e-06\n",
      "Epoch  42 [5050/10697 ( 47.2%)] Loss: 0.026973 L1: 0.016238 Grad: 0.107109 Thermal: 0.000478 LR: 2.35e-06\n",
      "Epoch  42 [5050/10697 ( 47.2%)] Loss: 0.026973 L1: 0.016238 Grad: 0.107109 Thermal: 0.000478 LR: 2.35e-06\n",
      "Epoch  42 [5100/10697 ( 47.7%)] Loss: 0.026263 L1: 0.015228 Grad: 0.110141 Thermal: 0.000425 LR: 2.35e-06\n",
      "Epoch  42 [5100/10697 ( 47.7%)] Loss: 0.026263 L1: 0.015228 Grad: 0.110141 Thermal: 0.000425 LR: 2.35e-06\n",
      "Epoch  42 [5150/10697 ( 48.1%)] Loss: 0.029738 L1: 0.017714 Grad: 0.119956 Thermal: 0.000570 LR: 2.35e-06\n",
      "Epoch  42 [5150/10697 ( 48.1%)] Loss: 0.029738 L1: 0.017714 Grad: 0.119956 Thermal: 0.000570 LR: 2.35e-06\n",
      "Epoch  42 [5200/10697 ( 48.6%)] Loss: 0.028414 L1: 0.016584 Grad: 0.118062 Thermal: 0.000478 LR: 2.35e-06\n",
      "Epoch  42 [5200/10697 ( 48.6%)] Loss: 0.028414 L1: 0.016584 Grad: 0.118062 Thermal: 0.000478 LR: 2.35e-06\n",
      "Epoch  42 [5250/10697 ( 49.1%)] Loss: 0.023885 L1: 0.013904 Grad: 0.099606 Thermal: 0.000396 LR: 2.35e-06\n",
      "Epoch  42 [5250/10697 ( 49.1%)] Loss: 0.023885 L1: 0.013904 Grad: 0.099606 Thermal: 0.000396 LR: 2.35e-06\n",
      "Epoch  42 [5300/10697 ( 49.5%)] Loss: 0.020929 L1: 0.012070 Grad: 0.088436 Thermal: 0.000300 LR: 2.35e-06\n",
      "Epoch  42 [5300/10697 ( 49.5%)] Loss: 0.020929 L1: 0.012070 Grad: 0.088436 Thermal: 0.000300 LR: 2.35e-06\n",
      "Epoch  42 [5350/10697 ( 50.0%)] Loss: 0.016960 L1: 0.009682 Grad: 0.072682 Thermal: 0.000207 LR: 2.35e-06\n",
      "Epoch  42 [5350/10697 ( 50.0%)] Loss: 0.016960 L1: 0.009682 Grad: 0.072682 Thermal: 0.000207 LR: 2.35e-06\n",
      "Epoch  42 [5400/10697 ( 50.5%)] Loss: 0.029959 L1: 0.017224 Grad: 0.127080 Thermal: 0.000538 LR: 2.35e-06\n",
      "Epoch  42 [5400/10697 ( 50.5%)] Loss: 0.029959 L1: 0.017224 Grad: 0.127080 Thermal: 0.000538 LR: 2.35e-06\n",
      "Epoch  42 [5450/10697 ( 50.9%)] Loss: 0.037458 L1: 0.021694 Grad: 0.157193 Thermal: 0.000890 LR: 2.35e-06\n",
      "Epoch  42 [5450/10697 ( 50.9%)] Loss: 0.037458 L1: 0.021694 Grad: 0.157193 Thermal: 0.000890 LR: 2.35e-06\n",
      "Epoch  42 [5500/10697 ( 51.4%)] Loss: 0.029549 L1: 0.017038 Grad: 0.124837 Thermal: 0.000544 LR: 2.35e-06\n",
      "Epoch  42 [5500/10697 ( 51.4%)] Loss: 0.029549 L1: 0.017038 Grad: 0.124837 Thermal: 0.000544 LR: 2.35e-06\n",
      "Epoch  42 [5550/10697 ( 51.9%)] Loss: 0.025057 L1: 0.014673 Grad: 0.103630 Thermal: 0.000413 LR: 2.35e-06\n",
      "Epoch  42 [5550/10697 ( 51.9%)] Loss: 0.025057 L1: 0.014673 Grad: 0.103630 Thermal: 0.000413 LR: 2.35e-06\n",
      "Epoch  42 [5600/10697 ( 52.4%)] Loss: 0.029202 L1: 0.017197 Grad: 0.119765 Thermal: 0.000562 LR: 2.35e-06\n",
      "Epoch  42 [5600/10697 ( 52.4%)] Loss: 0.029202 L1: 0.017197 Grad: 0.119765 Thermal: 0.000562 LR: 2.35e-06\n",
      "Epoch  42 [5650/10697 ( 52.8%)] Loss: 0.027263 L1: 0.016275 Grad: 0.109641 Thermal: 0.000473 LR: 2.35e-06\n",
      "Epoch  42 [5650/10697 ( 52.8%)] Loss: 0.027263 L1: 0.016275 Grad: 0.109641 Thermal: 0.000473 LR: 2.35e-06\n",
      "Epoch  42 [5700/10697 ( 53.3%)] Loss: 0.028454 L1: 0.016619 Grad: 0.118065 Thermal: 0.000556 LR: 2.35e-06\n",
      "Epoch  42 [5700/10697 ( 53.3%)] Loss: 0.028454 L1: 0.016619 Grad: 0.118065 Thermal: 0.000556 LR: 2.35e-06\n",
      "Epoch  42 [5750/10697 ( 53.8%)] Loss: 0.028977 L1: 0.016560 Grad: 0.123903 Thermal: 0.000538 LR: 2.35e-06\n",
      "Epoch  42 [5750/10697 ( 53.8%)] Loss: 0.028977 L1: 0.016560 Grad: 0.123903 Thermal: 0.000538 LR: 2.35e-06\n",
      "Epoch  42 [5800/10697 ( 54.2%)] Loss: 0.025586 L1: 0.014892 Grad: 0.106746 Thermal: 0.000385 LR: 2.35e-06\n",
      "Epoch  42 [5800/10697 ( 54.2%)] Loss: 0.025586 L1: 0.014892 Grad: 0.106746 Thermal: 0.000385 LR: 2.35e-06\n",
      "Epoch  42 [5850/10697 ( 54.7%)] Loss: 0.022570 L1: 0.013302 Grad: 0.092501 Thermal: 0.000362 LR: 2.35e-06\n",
      "Epoch  42 [5850/10697 ( 54.7%)] Loss: 0.022570 L1: 0.013302 Grad: 0.092501 Thermal: 0.000362 LR: 2.35e-06\n",
      "Epoch  42 [5900/10697 ( 55.2%)] Loss: 0.024280 L1: 0.014469 Grad: 0.097922 Thermal: 0.000359 LR: 2.35e-06\n",
      "Epoch  42 [5900/10697 ( 55.2%)] Loss: 0.024280 L1: 0.014469 Grad: 0.097922 Thermal: 0.000359 LR: 2.35e-06\n",
      "Epoch  42 [5950/10697 ( 55.6%)] Loss: 0.024005 L1: 0.013770 Grad: 0.102166 Thermal: 0.000369 LR: 2.35e-06\n",
      "Epoch  42 [5950/10697 ( 55.6%)] Loss: 0.024005 L1: 0.013770 Grad: 0.102166 Thermal: 0.000369 LR: 2.35e-06\n",
      "Epoch  42 [6000/10697 ( 56.1%)] Loss: 0.017712 L1: 0.010273 Grad: 0.074275 Thermal: 0.000225 LR: 2.35e-06\n",
      "Epoch  42 [6000/10697 ( 56.1%)] Loss: 0.017712 L1: 0.010273 Grad: 0.074275 Thermal: 0.000225 LR: 2.35e-06\n",
      "Epoch  42 [6050/10697 ( 56.6%)] Loss: 0.029612 L1: 0.017567 Grad: 0.120178 Thermal: 0.000537 LR: 2.35e-06\n",
      "Epoch  42 [6050/10697 ( 56.6%)] Loss: 0.029612 L1: 0.017567 Grad: 0.120178 Thermal: 0.000537 LR: 2.35e-06\n",
      "Epoch  42 [6100/10697 ( 57.0%)] Loss: 0.026369 L1: 0.015153 Grad: 0.111934 Thermal: 0.000453 LR: 2.35e-06\n",
      "Epoch  42 [6100/10697 ( 57.0%)] Loss: 0.026369 L1: 0.015153 Grad: 0.111934 Thermal: 0.000453 LR: 2.35e-06\n",
      "Epoch  42 [6150/10697 ( 57.5%)] Loss: 0.023353 L1: 0.013680 Grad: 0.096553 Thermal: 0.000356 LR: 2.35e-06\n",
      "Epoch  42 [6150/10697 ( 57.5%)] Loss: 0.023353 L1: 0.013680 Grad: 0.096553 Thermal: 0.000356 LR: 2.35e-06\n",
      "Epoch  42 [6200/10697 ( 58.0%)] Loss: 0.026584 L1: 0.015682 Grad: 0.108761 Thermal: 0.000520 LR: 2.35e-06\n",
      "Epoch  42 [6200/10697 ( 58.0%)] Loss: 0.026584 L1: 0.015682 Grad: 0.108761 Thermal: 0.000520 LR: 2.35e-06\n",
      "Epoch  42 [6250/10697 ( 58.4%)] Loss: 0.026715 L1: 0.015346 Grad: 0.113476 Thermal: 0.000421 LR: 2.35e-06\n",
      "Epoch  42 [6250/10697 ( 58.4%)] Loss: 0.026715 L1: 0.015346 Grad: 0.113476 Thermal: 0.000421 LR: 2.35e-06\n",
      "Epoch  42 [6300/10697 ( 58.9%)] Loss: 0.027087 L1: 0.016163 Grad: 0.109011 Thermal: 0.000463 LR: 2.35e-06\n",
      "Epoch  42 [6300/10697 ( 58.9%)] Loss: 0.027087 L1: 0.016163 Grad: 0.109011 Thermal: 0.000463 LR: 2.35e-06\n",
      "Epoch  42 [6350/10697 ( 59.4%)] Loss: 0.029107 L1: 0.017117 Grad: 0.119634 Thermal: 0.000532 LR: 2.35e-06\n",
      "Epoch  42 [6350/10697 ( 59.4%)] Loss: 0.029107 L1: 0.017117 Grad: 0.119634 Thermal: 0.000532 LR: 2.35e-06\n",
      "Epoch  42 [6400/10697 ( 59.8%)] Loss: 0.019302 L1: 0.011069 Grad: 0.082201 Thermal: 0.000265 LR: 2.35e-06\n",
      "Epoch  42 [6400/10697 ( 59.8%)] Loss: 0.019302 L1: 0.011069 Grad: 0.082201 Thermal: 0.000265 LR: 2.35e-06\n",
      "Epoch  42 [6450/10697 ( 60.3%)] Loss: 0.027341 L1: 0.016265 Grad: 0.110516 Thermal: 0.000500 LR: 2.35e-06\n",
      "Epoch  42 [6450/10697 ( 60.3%)] Loss: 0.027341 L1: 0.016265 Grad: 0.110516 Thermal: 0.000500 LR: 2.35e-06\n",
      "Epoch  42 [6500/10697 ( 60.8%)] Loss: 0.026430 L1: 0.015686 Grad: 0.107229 Thermal: 0.000430 LR: 2.35e-06\n",
      "Epoch  42 [6500/10697 ( 60.8%)] Loss: 0.026430 L1: 0.015686 Grad: 0.107229 Thermal: 0.000430 LR: 2.35e-06\n",
      "Epoch  42 [6550/10697 ( 61.2%)] Loss: 0.025907 L1: 0.015207 Grad: 0.106803 Thermal: 0.000404 LR: 2.35e-06\n",
      "Epoch  42 [6550/10697 ( 61.2%)] Loss: 0.025907 L1: 0.015207 Grad: 0.106803 Thermal: 0.000404 LR: 2.35e-06\n",
      "Epoch  42 [6600/10697 ( 61.7%)] Loss: 0.025642 L1: 0.015152 Grad: 0.104676 Thermal: 0.000443 LR: 2.35e-06\n",
      "Epoch  42 [6600/10697 ( 61.7%)] Loss: 0.025642 L1: 0.015152 Grad: 0.104676 Thermal: 0.000443 LR: 2.35e-06\n",
      "Epoch  42 [6650/10697 ( 62.2%)] Loss: 0.029417 L1: 0.017210 Grad: 0.121786 Thermal: 0.000561 LR: 2.35e-06\n",
      "Epoch  42 [6650/10697 ( 62.2%)] Loss: 0.029417 L1: 0.017210 Grad: 0.121786 Thermal: 0.000561 LR: 2.35e-06\n",
      "Epoch  42 [6700/10697 ( 62.6%)] Loss: 0.023331 L1: 0.013884 Grad: 0.094295 Thermal: 0.000351 LR: 2.35e-06\n",
      "Epoch  42 [6700/10697 ( 62.6%)] Loss: 0.023331 L1: 0.013884 Grad: 0.094295 Thermal: 0.000351 LR: 2.35e-06\n",
      "Epoch  42 [6750/10697 ( 63.1%)] Loss: 0.026846 L1: 0.015475 Grad: 0.113444 Thermal: 0.000524 LR: 2.35e-06\n",
      "Epoch  42 [6750/10697 ( 63.1%)] Loss: 0.026846 L1: 0.015475 Grad: 0.113444 Thermal: 0.000524 LR: 2.35e-06\n",
      "Epoch  42 [6800/10697 ( 63.6%)] Loss: 0.024868 L1: 0.014332 Grad: 0.105152 Thermal: 0.000430 LR: 2.35e-06\n",
      "Epoch  42 [6800/10697 ( 63.6%)] Loss: 0.024868 L1: 0.014332 Grad: 0.105152 Thermal: 0.000430 LR: 2.35e-06\n",
      "Epoch  42 [6850/10697 ( 64.0%)] Loss: 0.026050 L1: 0.015617 Grad: 0.104113 Thermal: 0.000441 LR: 2.35e-06\n",
      "Epoch  42 [6850/10697 ( 64.0%)] Loss: 0.026050 L1: 0.015617 Grad: 0.104113 Thermal: 0.000441 LR: 2.35e-06\n",
      "Epoch  42 [6900/10697 ( 64.5%)] Loss: 0.028145 L1: 0.016377 Grad: 0.117452 Thermal: 0.000463 LR: 2.35e-06\n",
      "Epoch  42 [6900/10697 ( 64.5%)] Loss: 0.028145 L1: 0.016377 Grad: 0.117452 Thermal: 0.000463 LR: 2.35e-06\n",
      "Epoch  42 [6950/10697 ( 65.0%)] Loss: 0.029140 L1: 0.016763 Grad: 0.123507 Thermal: 0.000519 LR: 2.35e-06\n",
      "Epoch  42 [6950/10697 ( 65.0%)] Loss: 0.029140 L1: 0.016763 Grad: 0.123507 Thermal: 0.000519 LR: 2.35e-06\n",
      "Epoch  42 [7000/10697 ( 65.4%)] Loss: 0.026669 L1: 0.015476 Grad: 0.111707 Thermal: 0.000459 LR: 2.35e-06\n",
      "Epoch  42 [7000/10697 ( 65.4%)] Loss: 0.026669 L1: 0.015476 Grad: 0.111707 Thermal: 0.000459 LR: 2.35e-06\n",
      "Epoch  42 [7050/10697 ( 65.9%)] Loss: 0.023785 L1: 0.013964 Grad: 0.098019 Thermal: 0.000371 LR: 2.35e-06\n",
      "Epoch  42 [7050/10697 ( 65.9%)] Loss: 0.023785 L1: 0.013964 Grad: 0.098019 Thermal: 0.000371 LR: 2.35e-06\n",
      "Epoch  42 [7100/10697 ( 66.4%)] Loss: 0.026854 L1: 0.016011 Grad: 0.108188 Thermal: 0.000481 LR: 2.35e-06\n",
      "Epoch  42 [7100/10697 ( 66.4%)] Loss: 0.026854 L1: 0.016011 Grad: 0.108188 Thermal: 0.000481 LR: 2.35e-06\n",
      "Epoch  42 [7150/10697 ( 66.8%)] Loss: 0.024897 L1: 0.014731 Grad: 0.101473 Thermal: 0.000380 LR: 2.35e-06\n",
      "Epoch  42 [7150/10697 ( 66.8%)] Loss: 0.024897 L1: 0.014731 Grad: 0.101473 Thermal: 0.000380 LR: 2.35e-06\n",
      "Epoch  42 [7200/10697 ( 67.3%)] Loss: 0.026816 L1: 0.016027 Grad: 0.107670 Thermal: 0.000449 LR: 2.35e-06\n",
      "Epoch  42 [7200/10697 ( 67.3%)] Loss: 0.026816 L1: 0.016027 Grad: 0.107670 Thermal: 0.000449 LR: 2.35e-06\n",
      "Epoch  42 [7250/10697 ( 67.8%)] Loss: 0.027203 L1: 0.016201 Grad: 0.109725 Thermal: 0.000593 LR: 2.35e-06\n",
      "Epoch  42 [7250/10697 ( 67.8%)] Loss: 0.027203 L1: 0.016201 Grad: 0.109725 Thermal: 0.000593 LR: 2.35e-06\n",
      "Epoch  42 [7300/10697 ( 68.2%)] Loss: 0.024455 L1: 0.014428 Grad: 0.100055 Thermal: 0.000427 LR: 2.35e-06\n",
      "Epoch  42 [7300/10697 ( 68.2%)] Loss: 0.024455 L1: 0.014428 Grad: 0.100055 Thermal: 0.000427 LR: 2.35e-06\n",
      "Epoch  42 [7350/10697 ( 68.7%)] Loss: 0.027542 L1: 0.016309 Grad: 0.112081 Thermal: 0.000491 LR: 2.35e-06\n",
      "Epoch  42 [7350/10697 ( 68.7%)] Loss: 0.027542 L1: 0.016309 Grad: 0.112081 Thermal: 0.000491 LR: 2.35e-06\n",
      "Epoch  42 [7400/10697 ( 69.2%)] Loss: 0.023492 L1: 0.013464 Grad: 0.100106 Thermal: 0.000340 LR: 2.35e-06\n",
      "Epoch  42 [7400/10697 ( 69.2%)] Loss: 0.023492 L1: 0.013464 Grad: 0.100106 Thermal: 0.000340 LR: 2.35e-06\n",
      "Epoch  42 [7450/10697 ( 69.6%)] Loss: 0.029026 L1: 0.016950 Grad: 0.120513 Thermal: 0.000507 LR: 2.35e-06\n",
      "Epoch  42 [7450/10697 ( 69.6%)] Loss: 0.029026 L1: 0.016950 Grad: 0.120513 Thermal: 0.000507 LR: 2.35e-06\n",
      "Epoch  42 [7500/10697 ( 70.1%)] Loss: 0.025893 L1: 0.015022 Grad: 0.108498 Thermal: 0.000440 LR: 2.35e-06\n",
      "Epoch  42 [7500/10697 ( 70.1%)] Loss: 0.025893 L1: 0.015022 Grad: 0.108498 Thermal: 0.000440 LR: 2.35e-06\n",
      "Epoch  42 [7550/10697 ( 70.6%)] Loss: 0.021986 L1: 0.012622 Grad: 0.093450 Thermal: 0.000373 LR: 2.35e-06\n",
      "Epoch  42 [7550/10697 ( 70.6%)] Loss: 0.021986 L1: 0.012622 Grad: 0.093450 Thermal: 0.000373 LR: 2.35e-06\n",
      "Epoch  42 [7600/10697 ( 71.0%)] Loss: 0.025924 L1: 0.015555 Grad: 0.103468 Thermal: 0.000431 LR: 2.35e-06\n",
      "Epoch  42 [7600/10697 ( 71.0%)] Loss: 0.025924 L1: 0.015555 Grad: 0.103468 Thermal: 0.000431 LR: 2.35e-06\n",
      "Epoch  42 [7650/10697 ( 71.5%)] Loss: 0.020567 L1: 0.011654 Grad: 0.088961 Thermal: 0.000339 LR: 2.35e-06\n",
      "Epoch  42 [7650/10697 ( 71.5%)] Loss: 0.020567 L1: 0.011654 Grad: 0.088961 Thermal: 0.000339 LR: 2.35e-06\n",
      "Epoch  42 [7700/10697 ( 72.0%)] Loss: 0.029526 L1: 0.017596 Grad: 0.118983 Thermal: 0.000631 LR: 2.35e-06\n",
      "Epoch  42 [7700/10697 ( 72.0%)] Loss: 0.029526 L1: 0.017596 Grad: 0.118983 Thermal: 0.000631 LR: 2.35e-06\n",
      "Epoch  42 [7750/10697 ( 72.5%)] Loss: 0.028456 L1: 0.016449 Grad: 0.119803 Thermal: 0.000530 LR: 2.35e-06\n",
      "Epoch  42 [7750/10697 ( 72.5%)] Loss: 0.028456 L1: 0.016449 Grad: 0.119803 Thermal: 0.000530 LR: 2.35e-06\n",
      "Epoch  42 [7800/10697 ( 72.9%)] Loss: 0.027205 L1: 0.016057 Grad: 0.111228 Thermal: 0.000504 LR: 2.35e-06\n",
      "Epoch  42 [7800/10697 ( 72.9%)] Loss: 0.027205 L1: 0.016057 Grad: 0.111228 Thermal: 0.000504 LR: 2.35e-06\n",
      "Epoch  42 [7850/10697 ( 73.4%)] Loss: 0.027724 L1: 0.016624 Grad: 0.110742 Thermal: 0.000516 LR: 2.35e-06\n",
      "Epoch  42 [7850/10697 ( 73.4%)] Loss: 0.027724 L1: 0.016624 Grad: 0.110742 Thermal: 0.000516 LR: 2.35e-06\n",
      "Epoch  42 [7900/10697 ( 73.9%)] Loss: 0.025891 L1: 0.014880 Grad: 0.109902 Thermal: 0.000409 LR: 2.35e-06\n",
      "Epoch  42 [7900/10697 ( 73.9%)] Loss: 0.025891 L1: 0.014880 Grad: 0.109902 Thermal: 0.000409 LR: 2.35e-06\n",
      "Epoch  42 [7950/10697 ( 74.3%)] Loss: 0.022575 L1: 0.013091 Grad: 0.094657 Thermal: 0.000371 LR: 2.35e-06\n",
      "Epoch  42 [7950/10697 ( 74.3%)] Loss: 0.022575 L1: 0.013091 Grad: 0.094657 Thermal: 0.000371 LR: 2.35e-06\n",
      "Epoch  42 [8000/10697 ( 74.8%)] Loss: 0.026126 L1: 0.014929 Grad: 0.111733 Thermal: 0.000459 LR: 2.35e-06\n",
      "Epoch  42 [8000/10697 ( 74.8%)] Loss: 0.026126 L1: 0.014929 Grad: 0.111733 Thermal: 0.000459 LR: 2.35e-06\n",
      "Epoch  42 [8050/10697 ( 75.3%)] Loss: 0.021779 L1: 0.012678 Grad: 0.090853 Thermal: 0.000316 LR: 2.35e-06\n",
      "Epoch  42 [8050/10697 ( 75.3%)] Loss: 0.021779 L1: 0.012678 Grad: 0.090853 Thermal: 0.000316 LR: 2.35e-06\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "set_random_seed(SEED)\n",
    "\n",
    "# Setup device\n",
    "if DEVICE == 'auto':\n",
    "\tdevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "else:\n",
    "\tdevice = torch.device(DEVICE)\n",
    "\n",
    "print(\"üî• IMDN Thermal Fine-tuning - FLIR ADAS v2 Optimized\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"üñ•Ô∏è  Device: {device}\")\n",
    "print(f\"üìä Scale factor: {SCALE}x\")\n",
    "print(f\"üìÅ Dataset: {DATASET_DIR}\")\n",
    "print(f\"üèãÔ∏è Pretrained model: {PRETRAINED_MODEL_DIR}\")\n",
    "print()\n",
    "\n",
    "# Create checkpoint directory\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "# Setup datasets\n",
    "print(\"üìÇ Loading FLIR thermal dataset...\")\n",
    "\n",
    "# Training dataset\n",
    "train_hr_dir = os.path.join(DATASET_DIR, 'train', 'HR')\n",
    "train_lr_dir = os.path.join(DATASET_DIR, 'train', f'LR_bicubic', f'X{SCALE}')\n",
    "\n",
    "# Create options object for ThermalDataset with FIXED repeat calculation\n",
    "class TrainOpt:\n",
    "\tdef __init__(self):\n",
    "\t\tself.scale = SCALE\n",
    "\t\tself.phase = 'train'\n",
    "\t\tself.hr_dir = train_hr_dir\n",
    "\t\tself.lr_dir = train_lr_dir\n",
    "\t\tself.ext = '.png'\n",
    "\t\tself.augment = True\n",
    "\t\tself.thermal_augment = True\n",
    "\t\tself.patch_size = PATCH_SIZE\n",
    "\t\tself.n_colors = 1\n",
    "\t\tself.rgb_range = 1\n",
    "\t\tself.batch_size = BATCH_SIZE\n",
    "\t\tself.test_every = max(1000, len(os.listdir(train_hr_dir)))  # Fix repeat calculation\n",
    "\n",
    "train_dataset = ThermalDataset(TrainOpt())\n",
    "\n",
    "# Validation dataset  \n",
    "val_hr_dir = os.path.join(DATASET_DIR, 'val', 'HR')\n",
    "val_lr_dir = os.path.join(DATASET_DIR, 'val', f'LR_bicubic', f'X{SCALE}')\n",
    "\n",
    "# Create options object for validation dataset\n",
    "class ValOpt:\n",
    "\tdef __init__(self):\n",
    "\t\tself.scale = SCALE\n",
    "\t\tself.phase = 'val'\n",
    "\t\tself.hr_dir = val_hr_dir\n",
    "\t\tself.lr_dir = val_lr_dir\n",
    "\t\tself.ext = '.png'\n",
    "\t\tself.augment = False\n",
    "\t\tself.thermal_augment = False\n",
    "\t\tself.patch_size = PATCH_SIZE\n",
    "\t\tself.n_colors = 1\n",
    "\t\tself.rgb_range = 1\n",
    "\t\tself.batch_size = BATCH_SIZE\n",
    "\t\tself.test_every = 1000\n",
    "\n",
    "val_dataset = ThermalDataset(ValOpt())\n",
    "\n",
    "print(f\"   ‚Ä¢ Training samples: {len(train_dataset)}\")\n",
    "print(f\"   ‚Ä¢ Validation samples: {len(val_dataset)}\")\n",
    "\n",
    "# Quick fix if training samples still 0\n",
    "if len(train_dataset) == 0:\n",
    "    print(\"‚ö†Ô∏è  Training dataset length is 0, fixing repeat calculation...\")\n",
    "    # Manually set repeat to 1 for training dataset\n",
    "    train_dataset.repeat = 1\n",
    "    print(f\"   ‚Ä¢ Fixed training samples: {len(train_dataset)}\")\n",
    "\n",
    "# Setup data loaders\n",
    "train_loader = DataLoader(\n",
    "\ttrain_dataset,\n",
    "\tbatch_size=BATCH_SIZE,\n",
    "\tshuffle=True,\n",
    "\tnum_workers=NUM_WORKERS,\n",
    "\tpin_memory=True,\n",
    "\tdrop_last=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "\tval_dataset,\n",
    "\tbatch_size=BATCH_SIZE,\n",
    "\tshuffle=False,\n",
    "\tnum_workers=NUM_WORKERS,\n",
    "\tpin_memory=True\n",
    ")\n",
    "\n",
    "# Setup model\n",
    "print(\"üèóÔ∏è Setting up IMDN model...\")\n",
    "model = IMDN(upscale=SCALE, in_nc=1, out_nc=1)  # Single channel for thermal\n",
    "\n",
    "# Load pretrained weights\n",
    "if os.path.exists(PRETRAINED_MODEL_DIR):\n",
    "\tprint(f\"üì• Loading pretrained weights from {PRETRAINED_MODEL_DIR}\")\n",
    "\ttry:\n",
    "\t\tcheckpoint = torch.load(PRETRAINED_MODEL_DIR, map_location='cpu', weights_only=True)\n",
    "\texcept:\n",
    "\t\t# Fallback for older PyTorch versions\n",
    "\t\tcheckpoint = torch.load(PRETRAINED_MODEL_DIR, map_location='cpu')\n",
    "\n",
    "\t# Extract state dict if it's wrapped in a checkpoint\n",
    "\tif isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
    "\t\tstate_dict = checkpoint['model_state_dict']\n",
    "\telse:\n",
    "\t\tstate_dict = checkpoint\n",
    "\n",
    "\t# Remove 'module.' prefix if present (from DataParallel training)\n",
    "\tif any(key.startswith('module.') for key in state_dict.keys()):\n",
    "\t\tstate_dict = {key.replace('module.', ''): value for key, value in state_dict.items()}\n",
    "\n",
    "\t# Universal weight adaptation for any scale factor\n",
    "\tadapted_state_dict = {}\n",
    "\ttarget_upsampler_channels = SCALE * SCALE  # For thermal: 1 channel * scale^2\n",
    "\t\n",
    "\tfor name, param in state_dict.items():\n",
    "\t\tif name == 'fea_conv.weight' and param.shape[1] == 3:  \n",
    "\t\t\t# RGB input layer -> thermal input layer (3->1 channel)\n",
    "\t\t\tadapted_param = param.mean(dim=1, keepdim=True)\n",
    "\t\t\tadapted_state_dict[name] = adapted_param\n",
    "\t\t\tprint(f\"   ‚Ä¢ Adapted {name}: {param.shape} -> {adapted_param.shape}\")\n",
    "\t\t\n",
    "\t\telif name.startswith('upsampler.') and 'weight' in name:\n",
    "\t\t\t# Handle upsampler weight - adapt from RGB to thermal\n",
    "\t\t\tsource_channels = param.shape[0]  # RGB: 3 * source_scale^2\n",
    "\t\t\t\n",
    "\t\t\tif source_channels % 3 == 0:  # Confirm it's RGB (divisible by 3)\n",
    "\t\t\t\tsource_scale_sq = source_channels // 3  # Get source scale^2\n",
    "\t\t\t\t\n",
    "\t\t\t\tif source_scale_sq == target_upsampler_channels:\n",
    "\t\t\t\t\t# Same scale: just average RGB channels to get thermal\n",
    "\t\t\t\t\tparam_reshaped = param.view(3, target_upsampler_channels, param.shape[1], param.shape[2], param.shape[3])\n",
    "\t\t\t\t\tadapted_param = param_reshaped.mean(dim=0)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\t# Different scales: need to adapt the scale\n",
    "\t\t\t\t\tif target_upsampler_channels <= source_scale_sq:\n",
    "\t\t\t\t\t\t# Target scale is smaller: downsample\n",
    "\t\t\t\t\t\tparam_reshaped = param.view(3, source_scale_sq, param.shape[1], param.shape[2], param.shape[3])\n",
    "\t\t\t\t\t\trgb_avg = param_reshaped.mean(dim=0)  # Average RGB channels first\n",
    "\t\t\t\t\t\tadapted_param = rgb_avg[:target_upsampler_channels]\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t# Target scale is larger: upsample by repeating\n",
    "\t\t\t\t\t\tparam_reshaped = param.view(3, source_scale_sq, param.shape[1], param.shape[2], param.shape[3])\n",
    "\t\t\t\t\t\trgb_avg = param_reshaped.mean(dim=0)  # Average RGB channels first\n",
    "\t\t\t\t\t\trepeat_factor = target_upsampler_channels // source_scale_sq\n",
    "\t\t\t\t\t\tremainder = target_upsampler_channels % source_scale_sq\n",
    "\t\t\t\t\t\tadapted_param = rgb_avg.repeat(repeat_factor, 1, 1, 1)\n",
    "\t\t\t\t\t\tif remainder > 0:\n",
    "\t\t\t\t\t\t\tadapted_param = torch.cat([adapted_param, rgb_avg[:remainder]], dim=0)\n",
    "\t\t\t\t\n",
    "\t\t\t\tadapted_state_dict[name] = adapted_param\n",
    "\t\t\t\tprint(f\"   ‚Ä¢ Adapted {name}: {param.shape} -> {adapted_param.shape}\")\n",
    "\t\t\telse:\n",
    "\t\t\t\tadapted_state_dict[name] = param\n",
    "\t\t\n",
    "\t\telif name.startswith('upsampler.') and 'bias' in name:\n",
    "\t\t\t# Handle upsampler bias - adapt from RGB to thermal\n",
    "\t\t\tsource_channels = param.shape[0]  # RGB: 3 * source_scale^2\n",
    "\t\t\t\n",
    "\t\t\tif source_channels % 3 == 0:  # Confirm it's RGB (divisible by 3)\n",
    "\t\t\t\tsource_scale_sq = source_channels // 3  # Get source scale^2\n",
    "\t\t\t\t\n",
    "\t\t\t\tif source_scale_sq == target_upsampler_channels:\n",
    "\t\t\t\t\t# Same scale: just average RGB channels to get thermal\n",
    "\t\t\t\t\tparam_reshaped = param.view(3, target_upsampler_channels)\n",
    "\t\t\t\t\tadapted_param = param_reshaped.mean(dim=0)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\t# Different scales: need to adapt the scale\n",
    "\t\t\t\t\tif target_upsampler_channels <= source_scale_sq:\n",
    "\t\t\t\t\t\t# Target scale is smaller: downsample\n",
    "\t\t\t\t\t\tparam_reshaped = param.view(3, source_scale_sq)\n",
    "\t\t\t\t\t\trgb_avg = param_reshaped.mean(dim=0)  # Average RGB channels first\n",
    "\t\t\t\t\t\tadapted_param = rgb_avg[:target_upsampler_channels]\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t# Target scale is larger: upsample by repeating\n",
    "\t\t\t\t\t\tparam_reshaped = param.view(3, source_scale_sq)\n",
    "\t\t\t\t\t\trgb_avg = param_reshaped.mean(dim=0)  # Average RGB channels first\n",
    "\t\t\t\t\t\trepeat_factor = target_upsampler_channels // source_scale_sq\n",
    "\t\t\t\t\t\tremainder = target_upsampler_channels % source_scale_sq\n",
    "\t\t\t\t\t\tadapted_param = rgb_avg.repeat(repeat_factor)\n",
    "\t\t\t\t\t\tif remainder > 0:\n",
    "\t\t\t\t\t\t\tadapted_param = torch.cat([adapted_param, rgb_avg[:remainder]], dim=0)\n",
    "\t\t\t\t\n",
    "\t\t\t\tadapted_state_dict[name] = adapted_param\n",
    "\t\t\t\tprint(f\"   ‚Ä¢ Adapted {name}: {param.shape} -> {adapted_param.shape}\")\n",
    "\t\t\telse:\n",
    "\t\t\t\tadapted_state_dict[name] = param\n",
    "\t\t\n",
    "\t\telse:\n",
    "\t\t\t# All other layers: keep as is\n",
    "\t\t\tadapted_state_dict[name] = param\n",
    "\n",
    "\t# Load adapted weights\n",
    "\tmissing_keys, unexpected_keys = model.load_state_dict(adapted_state_dict, strict=False)\n",
    "\tif missing_keys:\n",
    "\t\tprint(f\"   ‚ö†Ô∏è Missing keys: {missing_keys}\")\n",
    "\tif unexpected_keys:\n",
    "\t\tprint(f\"   ‚ö†Ô∏è Unexpected keys: {unexpected_keys}\")\n",
    "\t\n",
    "\tprint(f\"   ‚úÖ Successfully adapted pretrained model from RGB to thermal with {SCALE}x scaling\")\n",
    "else:\n",
    "\tprint(f\"‚ö†Ô∏è Pretrained model not found at {PRETRAINED_MODEL_DIR}\")\n",
    "\tprint(\"   üîÑ Training from scratch (this will take much longer)\")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Print model info\n",
    "sample_input = torch.randn(1, 1, 64, 64).to(device)\n",
    "print_model_info(model, sample_input)\n",
    "\n",
    "# Setup loss function\n",
    "criterion = ThermalLoss(\n",
    "\tl1_weight=L1_WEIGHT,\n",
    "\tgradient_weight=GRADIENT_WEIGHT,\n",
    "\tthermal_weight=THERMAL_WEIGHT\n",
    ").to(device)\n",
    "\n",
    "# Setup optimizer\n",
    "optimizer = optim.AdamW(\n",
    "\tmodel.parameters(),\n",
    "\tlr=LR,\n",
    "\tweight_decay=WEIGHT_DECAY,\n",
    "\tbetas=(0.9, 0.999)\n",
    ")\n",
    "\n",
    "# Setup learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "\toptimizer,\n",
    "\tT_max=EPOCHS,\n",
    "\teta_min=LR * 0.01\n",
    ")\n",
    "\n",
    "# Setup mixed precision training\n",
    "scaler = GradScaler() if MIXED_PRECISION and device.type == 'cuda' else None\n",
    "\n",
    "# Gradual unfreezing setup\n",
    "if GRADUAL_UNFREEZE:\n",
    "\tprint(\"üîê Starting with frozen backbone (gradual unfreezing enabled)\")\n",
    "\tfreeze_layers(model, freeze_backbone=True)\n",
    "\n",
    "# Memory optimization\n",
    "print(\"üß† Memory optimization enabled:\")\n",
    "print(f\"   ‚Ä¢ Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   ‚Ä¢ Patch size: {PATCH_SIZE}\")\n",
    "print(f\"   ‚Ä¢ Gradient accumulation: {GRADIENT_ACCUMULATION_STEPS}\")\n",
    "print(f\"   ‚Ä¢ Mixed precision: {MIXED_PRECISION}\")\n",
    "\n",
    "# Training loop with gradient accumulation\n",
    "print(\"üöÄ Starting training...\")\n",
    "print()\n",
    "\n",
    "best_psnr = 0\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\t# Gradual unfreezing\n",
    "\tif GRADUAL_UNFREEZE and epoch == FREEZE_EPOCHS:\n",
    "\t\tprint(\"üîì Unfreezing backbone layers\")\n",
    "\t\tfreeze_layers(model, freeze_backbone=False)\n",
    "\t\t# Reduce learning rate when unfreezing\n",
    "\t\tfor param_group in optimizer.param_groups:\n",
    "\t\t\tparam_group['lr'] *= 0.5\n",
    "\n",
    "\tmodel.train()\n",
    "\tepoch_loss = 0\n",
    "\tepoch_l1 = 0\n",
    "\tepoch_gradient = 0\n",
    "\tepoch_thermal = 0\n",
    "\t\n",
    "\t# Gradient accumulation setup\n",
    "\toptimizer.zero_grad()\n",
    "\n",
    "\tfor batch_idx, (lr, hr) in enumerate(train_loader):\n",
    "\t\tlr, hr = lr.to(device), hr.to(device)\n",
    "\t\t\n",
    "\t\t# Forward pass with mixed precision\n",
    "\t\tif scaler is not None:\n",
    "\t\t\twith autocast():\n",
    "\t\t\t\tsr = model(lr)\n",
    "\t\t\t\tloss, loss_components = criterion(sr, hr)\n",
    "\t\t\t\tloss = loss / GRADIENT_ACCUMULATION_STEPS  # Scale loss for accumulation\n",
    "\t\t\n",
    "\t\t\t# Backward pass\n",
    "\t\t\tscaler.scale(loss).backward()\n",
    "\t\telse:\n",
    "\t\t\tsr = model(lr)\n",
    "\t\t\tloss, loss_components = criterion(sr, hr)\n",
    "\t\t\tloss = loss / GRADIENT_ACCUMULATION_STEPS  # Scale loss for accumulation\n",
    "\t\t\tloss.backward()\n",
    "\t\t\n",
    "\t\t# Accumulate losses (scale back for logging)\n",
    "\t\tepoch_loss += loss.item() * GRADIENT_ACCUMULATION_STEPS\n",
    "\t\tepoch_l1 += loss_components['l1']\n",
    "\t\tepoch_gradient += loss_components['gradient']\n",
    "\t\tepoch_thermal += loss_components['thermal']\n",
    "\t\t\n",
    "\t\t# Update weights every GRADIENT_ACCUMULATION_STEPS\n",
    "\t\tif (batch_idx + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "\t\t\tif scaler is not None:\n",
    "\t\t\t\tscaler.step(optimizer)\n",
    "\t\t\t\tscaler.update()\n",
    "\t\t\telse:\n",
    "\t\t\t\toptimizer.step()\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\t\n",
    "\t\t\t# Clear cache periodically\n",
    "\t\t\tif batch_idx % 20 == 0:\n",
    "\t\t\t\ttorch.cuda.empty_cache()\n",
    "\t\t\n",
    "\t\t# Logging\n",
    "\t\tif batch_idx % LOG_INTERVAL == 0:\n",
    "\t\t\tprogress = 100.0 * batch_idx / len(train_loader)\n",
    "\t\t\tcurrent_lr = optimizer.param_groups[0]['lr']\n",
    "\t\t\tprint(f\"Epoch {epoch:3d} [{batch_idx:4d}/{len(train_loader)} ({progress:5.1f}%)] \"\n",
    "\t\t\t\t  f\"Loss: {loss.item() * GRADIENT_ACCUMULATION_STEPS:.6f} L1: {loss_components['l1']:.6f} \"\n",
    "\t\t\t\t  f\"Grad: {loss_components['gradient']:.6f} Thermal: {loss_components['thermal']:.6f} \"\n",
    "\t\t\t\t  f\"LR: {current_lr:.2e}\")\n",
    "\n",
    "\t# Update learning rate\n",
    "\tscheduler.step()\n",
    "\n",
    "\t# Calculate epoch averages\n",
    "\tavg_loss = epoch_loss / len(train_loader)\n",
    "\tavg_l1 = epoch_l1 / len(train_loader)\n",
    "\tavg_gradient = epoch_gradient / len(train_loader)\n",
    "\tavg_thermal = epoch_thermal / len(train_loader)\n",
    "\n",
    "\t# Validation\n",
    "\tval_loss, val_psnr = 0, 0\n",
    "\tif epoch % VAL_INTERVAL == 0:\n",
    "\t\tval_loss, val_psnr = validate_model(model, val_loader, criterion, device)\n",
    "\t\t\n",
    "\t\t# Save checkpoint if best\n",
    "\t\tis_best = val_psnr > best_psnr\n",
    "\t\tif is_best:\n",
    "\t\t\tbest_psnr = val_psnr\n",
    "\t\t\n",
    "\t\tsave_checkpoint(model, optimizer, epoch, val_loss, val_psnr, CHECKPOINT_DIR, is_best)\n",
    "\n",
    "\t# Epoch summary\n",
    "\telapsed = time.time() - start_time\n",
    "\tprint(f\"Epoch {epoch:3d} Summary: Loss={avg_loss:.6f} (L1:{avg_l1:.4f}, Grad:{avg_gradient:.4f}, Thermal:{avg_thermal:.4f}) \"\n",
    "\t\t  f\"Val_PSNR={val_psnr:.2f}dB Best={best_psnr:.2f}dB Time={elapsed/60:.1f}min\")\n",
    "\tprint(\"-\" * 100)\n",
    "\n",
    "# Final summary\n",
    "total_time = time.time() - start_time\n",
    "print()\n",
    "print(\"‚úÖ Training completed!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"üéØ Best validation PSNR: {best_psnr:.2f} dB\")\n",
    "print(f\"‚è±Ô∏è Total training time: {total_time/3600:.2f} hours\")\n",
    "print(f\"üíæ Best model saved at: {os.path.join(CHECKPOINT_DIR, 'thermal_best.pth')}\")\n",
    "print()\n",
    "print(\"üî• Your thermal super-resolution model is ready!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FLIR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
